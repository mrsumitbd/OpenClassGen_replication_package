id,repository_name,file_path,class_name,human_written_code,class_skeleton,total_program_units,total_doc_str,snippet_id,coverage,gpt-o4-mini_relevant,qwen-3-coder_relevant,claude-4-sonnet_relevant,docstr_type,rouge1_gpt-o4-mini,rouge2_gpt-o4-mini,rouge3_gpt-o4-mini,rougeL_gpt-o4-mini,bleu_gpt-o4-mini,bleu1_gpt-o4-mini,bleu2_gpt-o4-mini,bleu3_gpt-o4-mini,code_bert_prec_gpt-o4-mini,code_bert_recall_gpt-o4-mini,code_bert_f1_gpt-o4-mini,code_bert_f3_gpt-o4-mini,tsed_gpt-o4-mini,rouge1_qwen-3-coder,rouge2_qwen-3-coder,rouge3_qwen-3-coder,rougeL_qwen-3-coder,bleu_qwen-3-coder,bleu1_qwen-3-coder,bleu2_qwen-3-coder,bleu3_qwen-3-coder,code_bert_prec_qwen-3-coder,code_bert_recall_qwen-3-coder,code_bert_f1_qwen-3-coder,code_bert_f3_qwen-3-coder,tsed_qwen-3-coder,rouge1_claude-4-sonnet,rouge2_claude-4-sonnet,rouge3_claude-4-sonnet,rougeL_claude-4-sonnet,bleu_claude-4-sonnet,bleu1_claude-4-sonnet,bleu2_claude-4-sonnet,bleu3_claude-4-sonnet,code_bert_prec_claude-4-sonnet,code_bert_recall_claude-4-sonnet,code_bert_f1_claude-4-sonnet,code_bert_f3_claude-4-sonnet,tsed_claude-4-sonnet,gpt-o4-mini_code_bleu,gpt-o4-mini_ngram_match,gpt-o4-mini_weighted_ngram_match,gpt-o4-mini_syntax_match,gpt-o4-mini_dataflow_match,qwen-3-coder_code_bleu,qwen-3-coder_ngram_match,qwen-3-coder_weighted_ngram_match,qwen-3-coder_syntax_match,qwen-3-coder_dataflow_match,claude-4-sonnet_code_bleu,claude-4-sonnet_ngram_match,claude-4-sonnet_weighted_ngram_match,claude-4-sonnet_syntax_match,claude-4-sonnet_dataflow_match
175493,Qiskit/qiskit-terra,Qiskit_qiskit-terra/qiskit/transpiler/passes/optimization/template_matching/maximal_matches.py,qiskit.transpiler.passes.optimization.template_matching.maximal_matches.MaximalMatches,"class MaximalMatches:
    """"""
    Class MaximalMatches allows to sort and store the maximal matches from the list
    of matches obtained with the template matching algorithm.
    """"""

    def __init__(self, template_matches):
        """"""
        Initialize MaximalMatches with the necessary arguments.
        Args:
            template_matches (list): list of matches obtained from running the algorithm.
        """"""
        self.template_matches = template_matches

        self.max_match_list = []

    def run_maximal_matches(self):
        """"""
        Method that extracts and stores maximal matches in decreasing length order.
        """"""

        self.max_match_list = [
            Match(
                sorted(self.template_matches[0].match),
                self.template_matches[0].qubit,
                self.template_matches[0].clbit,
            )
        ]

        for matches in self.template_matches[1::]:
            present = False
            for max_match in self.max_match_list:
                for elem in matches.match:
                    if elem in max_match.match and len(matches.match) <= len(max_match.match):
                        present = True
            if not present:
                self.max_match_list.append(
                    Match(sorted(matches.match), matches.qubit, matches.clbit)
                )","class MaximalMatches:
    '''
    Class MaximalMatches allows to sort and store the maximal matches from the list
    of matches obtained with the template matching algorithm.
    '''

    def __init__(self, template_matches):
    '''
        Initialize MaximalMatches with the necessary arguments.
        Args:
            template_matches (list): list of matches obtained from running the algorithm.
        '''
        pass

    def run_maximal_matches(self):
    '''
        Method that extracts and stores maximal matches in decreasing length order.
        '''
        pass

",3,3,snippet_236,0.2,"class MaximalMatches:
    '''
    Class MaximalMatches allows to sort and store the maximal matches from the list
    of matches obtained with the template matching algorithm.
    '''

    def __init__(self, template_matches):
        '''
        Initialize MaximalMatches with the necessary arguments.
        Args:
            template_matches (list): list of matches obtained from running the algorithm.
        '''
        self.template_matches = template_matches
        self.maximal_matches = []

    def run_maximal_matches(self):
        '''
        Method that extracts and stores maximal matches in decreasing length order.
        '''
        # sort by decreasing length (assumes each match is (start, end, ...) or [start, end, ...])
        sorted_matches = sorted(
            self.template_matches,
            key=lambda m: (m[1] - m[0]) if len(m) >= 2 else 0,
            reverse=True
        )

        for match in sorted_matches:
            start, end = match[0], match[1]
            # check if this match is contained in any already selected maximal match
            contained = any(
                sel[0] <= start and sel[1] >= end
                for sel in self.maximal_matches
            )
            if not contained:
                self.maximal_matches.append(match)

        return self.maximal_matches","class MaximalMatches:
    '''
    Class MaximalMatches allows to sort and store the maximal matches from the list
    of matches obtained with the template matching algorithm.
    '''

    def __init__(self, template_matches):
        '''
        Initialize MaximalMatches with the necessary arguments.
        Args:
            template_matches (list): list of matches obtained from running the algorithm.
        '''
        self.template_matches = template_matches
        self.maximal_matches = []

    def run_maximal_matches(self):
        '''
        Method that extracts and stores maximal matches in decreasing length order.
        '''
        # Sort matches by length in descending order
        sorted_matches = sorted(self.template_matches, key=lambda x: len(x) if hasattr(x, '__len__') else 1, reverse=True)
        
        # Extract maximal matches
        maximal_matches = []
        for match in sorted_matches:
            is_maximal = True
            # Check if current match is contained in any already selected maximal match
            for maximal_match in maximal_matches:
                if self._is_contained(match, maximal_match):
                    is_maximal = False
                    break
            if is_maximal:
                maximal_matches.append(match)
        
        self.maximal_matches = maximal_matches

    def _is_contained(self, match, maximal_match):
        '''
        Helper method to check if a match is contained within a maximal match.
        '''
        # This is a generic implementation - can be customized based on match structure
        if isinstance(match, str) and isinstance(maximal_match, str):
            return match in maximal_match
        elif hasattr(match, '__iter__') and hasattr(maximal_match, '__iter__'):
            # For sequences, check if match is a subsequence of maximal_match
            match_iter = iter(match)
            maximal_iter = iter(maximal_match)
            try:
                match_item = next(match_iter)
                for maximal_item in maximal_iter:
                    if maximal_item == match_item:
                        match_item = next(match_iter)
            except StopIteration:
                return True
            return False
        else:
            return False","class MaximalMatches:
    '''
    Class MaximalMatches allows to sort and store the maximal matches from the list
    of matches obtained with the template matching algorithm.
    '''

    def __init__(self, template_matches):
        '''
        Initialize MaximalMatches with the necessary arguments.
        Args:
            template_matches (list): list of matches obtained from running the algorithm.
        '''
        self.template_matches = template_matches
        self.maximal_matches = []

    def run_maximal_matches(self):
        '''
        Method that extracts and stores maximal matches in decreasing length order.
        '''
        # Sort matches by length in decreasing order
        sorted_matches = sorted(self.template_matches, key=len, reverse=True)
        
        for match in sorted_matches:
            is_maximal = True
            # Check if current match is contained in any already selected maximal match
            for maximal_match in self.maximal_matches:
                if self._is_submatch(match, maximal_match):
                    is_maximal = False
                    break
            
            if is_maximal:
                self.maximal_matches.append(match)
    
    def _is_submatch(self, match1, match2):
        '''
        Helper method to check if match1 is a submatch of match2.
        '''
        if len(match1) > len(match2):
            return False
        
        match1_str = ''.join(str(x) for x in match1)
        match2_str = ''.join(str(x) for x in match2)
        
        return match1_str in match2_str",full_docstr,0.7000000000000001,0.5033557046979866,0.4459459459459459,0.6133333333333334,0.4919136407224862,0.7310606060606061,0.4714828897338403,0.37404580152671757,0.8784452676773071,0.9000434279441833,0.889113187789917,0.8978359699249268,0.8092124342105262,0.5771144278606964,0.3700000000000001,0.3316582914572864,0.47761194029850745,0.3184012296127312,0.46604215456674475,0.30985915492957744,0.2235294117647059,0.8251593112945557,0.8970571756362915,0.859607458114624,0.8893083333969116,0.7717740540540543,0.636085626911315,0.4492307692307692,0.4148606811145511,0.54434250764526,0.4521748303587447,0.6472602739726028,0.422680412371134,0.33793103448275863,0.8504800796508789,0.8917718529701233,0.8706366419792175,0.8874630928039551,0.7695496296296299,0.4374831405411289,0.3738634440992031,0.4975505995467939,0.36,0.5185185185185185,0.400819944311635,0.2434933505491011,0.510156797067809,0.3866666666666666,0.4629629629629629,0.4520458864216606,0.3463807286271994,0.5062472615038873,0.4,0.5555555555555556
250195,atztogo/phonopy,atztogo_phonopy/phonopy/phonon/dos.py,dos.CauchyDistribution,"class CauchyDistribution:
    """"""Class to represent Cauchy distribution.""""""

    def __init__(self, gamma):
        """"""Init method.""""""
        self._gamma = gamma

    def calc(self, x):
        """"""Return Cauchy distribution.""""""
        return self._gamma / np.pi / (x**2 + self._gamma**2)","class CauchyDistribution:
    '''Class to represent Cauchy distribution.'''

    def __init__(self, gamma):
    '''Init method.'''
        pass

    def calc(self, x):
    '''Return Cauchy distribution.'''
        pass

",3,3,snippet_353,1.0,"class CauchyDistribution:
    '''Class to represent Cauchy distribution.'''

    def __init__(self, gamma):
        '''Init method.'''
        if not isinstance(gamma, (int, float)):
            raise TypeError(""gamma must be a real number"")
        if gamma <= 0:
            raise ValueError(""gamma must be positive"")
        self.gamma = float(gamma)

    def calc(self, x):
        '''Return Cauchy distribution.'''
        if not isinstance(x, (int, float)):
            raise TypeError(""x must be a real number"")
        gamma = self.gamma
        return (1.0 / (math.pi * gamma)) * (gamma*gamma / (x*x + gamma*gamma))","class CauchyDistribution:
    '''Class to represent Cauchy distribution.'''

    def __init__(self, gamma):
        '''Init method.'''
        self.gamma = gamma

    def calc(self, x):
        '''Return Cauchy distribution.'''
        import math
        return 1 / (math.pi * self.gamma * (1 + (x / self.gamma) ** 2))","class CauchyDistribution:
    '''Class to represent Cauchy distribution.'''

    def __init__(self, gamma):
        '''Init method.'''
        self.gamma = gamma

    def calc(self, x):
        '''Return Cauchy distribution.'''
        return 1 / (math.pi * self.gamma * (1 + (x / self.gamma) ** 2))",full_docstr,0.5321100917431193,0.411214953271028,0.3238095238095238,0.5137614678899083,0.2605686447574697,0.4217687074829932,0.2534246575342466,0.16551724137931034,0.7839284539222717,0.899081826210022,0.8375656008720398,0.886066198348999,0.8039235294117647,0.8985507246376813,0.7462686567164178,0.6769230769230768,0.8695652173913043,0.47452877321136283,0.7972972972972973,0.5616438356164384,0.375,0.9414442777633667,0.9663251638412476,0.9537224769592285,0.9637780785560608,0.9417995238095238,0.9253731343283583,0.8,0.7301587301587302,0.8955223880597014,0.4723365369825719,0.8194444444444444,0.5774647887323944,0.38571428571428573,0.9535337090492249,0.9696412086486816,0.9615200161933899,0.9680060148239136,0.955556,0.2374269226879466,0.0367391212651673,0.0947867513048011,0.2727272727272727,0.5454545454545454,0.4348761155220302,0.1787993588239658,0.2425232850823366,0.5,0.8181818181818182,0.3920931109987488,0.1894855225490222,0.2425232850823366,0.5,0.6363636363636364
126075,HDI-Project/MLPrimitives,HDI-Project_MLPrimitives/mlprimitives/adapters/statsmodels.py,mlprimitives.adapters.statsmodels.ARIMA,"class ARIMA(object):
    """"""A Wrapper for the statsmodels.tsa.arima_model.ARIMA class.""""""

    def __init__(self, p, d, q, steps):
        """"""Initialize the ARIMA object.

        Args:
            p (int):
                Integer denoting the order of the autoregressive model.
            d (int):
                Integer denoting the degree of differencing.
            q (int):
                Integer denoting the order of the moving-average model.
            steps (int):
                Integer denoting the number of time steps to predict ahead.
        """"""
        self.p = p
        self.d = d
        self.q = q
        self.steps = steps

    def predict(self, X):
        """"""Predict values using the initialized object.

        Args:
            X (ndarray):
                N-dimensional array containing the input sequences for the model.

        Returns:
            ndarray:
                N-dimensional array containing the predictions for each input sequence.
        """"""
        arima_results = list()
        dimensions = len(X.shape)

        if dimensions > 2:
            raise ValueError(""Only 1D o 2D arrays are supported"")

        if dimensions == 1 or X.shape[1] == 1:
            X = np.expand_dims(X, axis=0)

        num_sequences = len(X)
        for sequence in range(num_sequences):
            arima = model.ARIMA(X[sequence], order=(self.p, self.d, self.q))
            arima_fit = arima.fit()
            arima_results.append(arima_fit.forecast(self.steps)[0])

        arima_results = np.asarray(arima_results)

        if dimensions == 1:
            arima_results = arima_results[0]

        return arima_results","class ARIMA(object):
    '''A Wrapper for the statsmodels.tsa.arima_model.ARIMA class.'''

    def __init__(self, p, d, q, steps):
    '''Initialize the ARIMA object.

        Args:
            p (int):
                Integer denoting the order of the autoregressive model.
            d (int):
                Integer denoting the degree of differencing.
            q (int):
                Integer denoting the order of the moving-average model.
            steps (int):
                Integer denoting the number of time steps to predict ahead.
        '''
        pass

    def predict(self, X):
    '''Predict values using the initialized object.

        Args:
            X (ndarray):
                N-dimensional array containing the input sequences for the model.

        Returns:
            ndarray:
                N-dimensional array containing the predictions for each input sequence.
        '''
        pass

",3,3,snippet_141,0.2307692307692307,"class ARIMA(object):
    '''A Wrapper for the statsmodels.tsa.arima_model.ARIMA class.'''

    def __init__(self, p, d, q, steps):
        '''Initialize the ARIMA object.

        Args:
            p (int):
                Integer denoting the order of the autoregressive model.
            d (int):
                Integer denoting the degree of differencing.
            q (int):
                Integer denoting the order of the moving-average model.
            steps (int):
                Integer denoting the number of time steps to predict ahead.
        '''
        self.p = p
        self.d = d
        self.q = q
        self.steps = steps

    def predict(self, X):
        '''Predict values using the initialized object.

        Args:
            X (ndarray):
                N-dimensional array containing the input sequences for the model.

        Returns:
            ndarray:
                N-dimensional array containing the predictions for each input sequence.
        '''
        arr = np.atleast_2d(X)
        results = []
        for series in arr:
            model = _ARIMA(series, order=(self.p, self.d, self.q))
            fitted = model.fit(disp=0)
            forecast = fitted.forecast(steps=self.steps)[0]
            results.append(forecast)
        return np.array(results)","class ARIMA(object):
    '''A Wrapper for the statsmodels.tsa.arima_model.ARIMA class.'''

    def __init__(self, p, d, q, steps):
        '''Initialize the ARIMA object.

        Args:
            p (int):
                Integer denoting the order of the autoregressive model.
            d (int):
                Integer denoting the degree of differencing.
            q (int):
                Integer denoting the order of the moving-average model.
            steps (int):
                Integer denoting the number of time steps to predict ahead.
        '''
        self.p = p
        self.d = d
        self.q = q
        self.steps = steps
        self.model = None

    def predict(self, X):
        '''Predict values using the initialized object.

        Args:
            X (ndarray):
                N-dimensional array containing the input sequences for the model.

        Returns:
            ndarray:
                N-dimensional array containing the predictions for each input sequence.
        '''
        predictions = []
        
        for sequence in X:
            try:
                # Fit the ARIMA model
                model = StatsmodelsARIMA(sequence, order=(self.p, self.d, self.q))
                fitted_model = model.fit()
                
                # Make predictions
                forecast = fitted_model.forecast(steps=self.steps)
                predictions.append(forecast)
            except:
                # If model fitting fails, return zeros
                predictions.append(np.zeros(self.steps))
        
        return np.array(predictions)","class ARIMA(object):
    '''A Wrapper for the statsmodels.tsa.arima_model.ARIMA class.'''

    def __init__(self, p, d, q, steps):
        '''Initialize the ARIMA object.

        Args:
            p (int):
                Integer denoting the order of the autoregressive model.
            d (int):
                Integer denoting the degree of differencing.
            q (int):
                Integer denoting the order of the moving-average model.
            steps (int):
                Integer denoting the number of time steps to predict ahead.
        '''
        self.p = p
        self.d = d
        self.q = q
        self.steps = steps

    def predict(self, X):
        '''Predict values using the initialized object.

        Args:
            X (ndarray):
                N-dimensional array containing the input sequences for the model.

        Returns:
            ndarray:
                N-dimensional array containing the predictions for each input sequence.
        '''
        if X.ndim == 1:
            X = X.reshape(1, -1)
        
        predictions = []
        
        for sequence in X:
            model = StatsARIMA(sequence, order=(self.p, self.d, self.q))
            fitted_model = model.fit()
            forecast = fitted_model.forecast(steps=self.steps)
            predictions.append(forecast)
        
        return np.array(predictions)",full_docstr,0.7920227920227921,0.6991404011461319,0.6743515850144093,0.7635327635327634,0.5369909940969078,0.9206349206349206,0.8007968127490039,0.728,0.9543247818946838,0.8996036052703857,0.9261566400527954,0.9047916531562805,0.8605456122448979,0.7445652173913043,0.6666666666666667,0.6373626373626373,0.717391304347826,0.5421595870805291,0.8447653429602888,0.6956521739130435,0.64,0.941415011882782,0.8926980495452881,0.9164094924926758,0.8973416090011597,0.8384369897959183,0.7909604519774012,0.7102272727272727,0.6742857142857143,0.7627118644067797,0.5398622581421106,0.914396887159533,0.7734375,0.7098039215686275,0.957039475440979,0.9024596214294434,0.9289485216140747,0.9076356887817383,0.8741509183673468,0.4906794592830095,0.5583182252262415,0.571946560262604,0.3958333333333333,0.4366197183098591,0.4854030775518417,0.5667733314772962,0.5674739552558925,0.4270833333333333,0.380281690140845,0.4973025418920373,0.5833717679738778,0.5948055357445062,0.4166666666666667,0.3943661971830985
354205,dvdme/forecastiopy,dvdme_forecastiopy/forecastiopy/FIOAlerts.py,forecastiopy.FIOAlerts.FIOAlerts,"class FIOAlerts(object):
    """"""
    This class recieves an ForecastIO object and holds the alerts weather
    conditions. It has one class for this purpose.
    """"""

    alerts = None

    def __init__(self, forecast_io):
        """"""
        Recieves an ForecastIO object and gets the alerts weather conditions
        if they are available in the object.
        """"""
        if forecast_io.has_alerts():
            self.alerts = forecast_io.get_alerts()

    def get(self, alert=None):
        """"""
        Returns a dictionary with alert weather conditions.
        Returns None is none are available.
        A day can be passed as an argument, is so function will call get_alert()
        to return that day.
        Look on function get_alert()
        """"""
        if alert is None:
            return self.alerts
        else:
            return self.get_alert(alert)

    def get_alert(self, alert):
        """"""
        Recieves a day as an argument and returns the prediction for that alert
        if is available. If not, function will return None.
        """"""
        if alert > self.alerts_count() or self.alerts_count() is None:
            return None
        else:
            return self.get()[alert - 1]

    def alerts_count(self):
        """"""
        Returns how many alerts of prediction are available.
        Returns None if none is available
        """"""
        if self.get() is None:
            return None
        else:
            return len(self.get())","class FIOAlerts(object):
    '''
    This class recieves an ForecastIO object and holds the alerts weather
    conditions. It has one class for this purpose.
    '''

    def __init__(self, forecast_io):
    '''
        Recieves an ForecastIO object and gets the alerts weather conditions
        if they are available in the object.
        '''
        pass

    def get(self, alert=None):
    '''
        Returns a dictionary with alert weather conditions.
        Returns None is none are available.
        A day can be passed as an argument, is so function will call get_alert()
        to return that day.
        Look on function get_alert()
        '''
        pass

    def get_alert(self, alert):
    '''
        Recieves a day as an argument and returns the prediction for that alert
        if is available. If not, function will return None.
        '''
        pass

    def alerts_count(self):
    '''
        Returns how many alerts of prediction are available.
        Returns None if none is available
        '''
        pass

",5,5,snippet_603,0.1666666666666666,"class FIOAlerts(object):
    '''
    This class receives a ForecastIO object and holds the alerts weather
    conditions. It has one class for this purpose.
    '''

    def __init__(self, forecast_io):
        '''
        Receives a ForecastIO object and gets the alerts weather conditions
        if they are available in the object.
        '''
        self._alerts = None
        data = None
        # Try to get JSON dict from forecast_io
        if hasattr(forecast_io, 'json'):
            try:
                j = forecast_io.json
                data = j() if callable(j) else j
            except Exception:
                data = None
        if data is None and hasattr(forecast_io, '_json'):
            data = forecast_io._json
        if isinstance(data, dict):
            self._alerts = data.get('alerts')
        else:
            self._alerts = None

    def get(self, alert=None):
        '''
        Returns a dictionary with alert weather conditions.
        Returns None if none are available.
        A day can be passed as an argument; in so doing the function will call get_alert()
        to return that day.
        '''
        if self._alerts is None:
            return None
        if alert is None:
            return self._alerts
        return self.get_alert(alert)

    def get_alert(self, alert):
        '''
        Receives a day (index or title) as an argument and returns the prediction for that alert
        if it is available. If not, function will return None.
        '''
        if not self._alerts:
            return None
        # If alert is integer index
        if isinstance(alert, int):
            if 0 <= alert < len(self._alerts):
                return self._alerts[alert]
            return None
        # Otherwise, try match by title
        for a in self._alerts:
            if isinstance(a, dict) and a.get('title') == alert:
                return a
        return None

    def alerts_count(self):
        '''
        Returns how many alerts of prediction are available.
        Returns None if none is available.
        '''
        if self._alerts is None:
            return None
        return len(self._alerts)","class FIOAlerts(object):
    '''
    This class recieves an ForecastIO object and holds the alerts weather
    conditions. It has one class for this purpose.
    '''

    def __init__(self, forecast_io):
        '''
        Recieves an ForecastIO object and gets the alerts weather conditions
        if they are available in the object.
        '''
        self.alerts = None
        if hasattr(forecast_io, 'alerts'):
            self.alerts = forecast_io.alerts

    def get(self, alert=None):
        '''
        Returns a dictionary with alert weather conditions.
        Returns None is none are available.
        A day can be passed as an argument, is so function will call get_alert()
        to return that day.
        Look on function get_alert()
        '''
        if self.alerts is None:
            return None
            
        if alert is None:
            return self.alerts
        else:
            return self.get_alert(alert)

    def get_alert(self, alert):
        '''
        Recieves a day as an argument and returns the prediction for that alert
        if is available. If not, function will return None.
        '''
        if self.alerts is None:
            return None
            
        if isinstance(alert, int) and 0 <= alert < len(self.alerts):
            return self.alerts[alert]
        return None

    def alerts_count(self):
        '''
        Returns how many alerts of prediction are available.
        Returns None if none is available
        '''
        if self.alerts is None:
            return None
        return len(self.alerts)","class FIOAlerts(object):
    '''
    This class recieves an ForecastIO object and holds the alerts weather
    conditions. It has one class for this purpose.
    '''

    def __init__(self, forecast_io):
        '''
        Recieves an ForecastIO object and gets the alerts weather conditions
        if they are available in the object.
        '''
        self.forecast_io = forecast_io
        self.alerts = None
        if hasattr(forecast_io, 'json') and forecast_io.json:
            if 'alerts' in forecast_io.json:
                self.alerts = forecast_io.json['alerts']

    def get(self, alert=None):
        '''
        Returns a dictionary with alert weather conditions.
        Returns None is none are available.
        A day can be passed as an argument, is so function will call get_alert()
        to return that day.
        Look on function get_alert()
        '''
        if alert is not None:
            return self.get_alert(alert)
        return self.alerts

    def get_alert(self, alert):
        '''
        Recieves a day as an argument and returns the prediction for that alert
        if is available. If not, function will return None.
        '''
        if self.alerts is None:
            return None
        if isinstance(alert, int) and 0 <= alert < len(self.alerts):
            return self.alerts[alert]
        return None

    def alerts_count(self):
        '''
        Returns how many alerts of prediction are available.
        Returns None if none is available
        '''
        if self.alerts is None:
            return None
        return len(self.alerts)",full_docstr,0.7521739130434784,0.611353711790393,0.5,0.6869565217391305,0.4892307352439685,0.6202830188679245,0.4799054373522459,0.3933649289099526,0.8751735687255859,0.9277063608169556,0.90067458152771,0.922170877456665,0.7953688416988425,0.917098445595855,0.8437500000000001,0.7748691099476439,0.8911917098445595,0.7241478097468116,0.8732876712328768,0.7628865979381443,0.6862068965517242,0.9485405683517456,0.9528104662895203,0.9506707787513733,0.9523817896842957,0.8619971337579618,0.8911392405063292,0.7989821882951653,0.7161125319693095,0.850632911392405,0.7131514297650314,0.8317152103559871,0.7077922077922078,0.6221498371335505,0.9322628974914551,0.9411720037460327,0.9366962313652039,0.9402735233306885,0.8284617543859648,0.4762991995280309,0.3850494987526447,0.5873987613477829,0.4605263157894737,0.4722222222222222,0.5584008560556086,0.6777268860294388,0.7298531463801302,0.3815789473684211,0.4444444444444444,0.5355400342770689,0.6335314869728126,0.694301164755346,0.3421052631578947,0.4722222222222222
212503,abourget/gevent-socketio,abourget_gevent-socketio/socketio/mixins.py,socketio.mixins.BroadcastMixin,"class BroadcastMixin(object):
    """"""Mix in this class with your Namespace to have a broadcast event method.

    Use it like this:
    class MyNamespace(BaseNamespace, BroadcastMixin):
        def on_chatmsg(self, event):
            self.broadcast_event('chatmsg', event)
    """"""
    def broadcast_event(self, event, *args):
        """"""
        This is sent to all in the sockets in this particular Namespace,
        including itself.
        """"""
        pkt = dict(type=""event"",
                   name=event,
                   args=args,
                   endpoint=self.ns_name)

        for sessid, socket in six.iteritems(self.socket.server.sockets):
            socket.send_packet(pkt)

    def broadcast_event_not_me(self, event, *args):
        """"""
        This is sent to all in the sockets in this particular Namespace,
        except itself.
        """"""
        pkt = dict(type=""event"",
                   name=event,
                   args=args,
                   endpoint=self.ns_name)

        for sessid, socket in six.iteritems(self.socket.server.sockets):
            if socket is not self.socket:
                socket.send_packet(pkt)","class BroadcastMixin(object):
    '''Mix in this class with your Namespace to have a broadcast event method.

    Use it like this:
    class MyNamespace(BaseNamespace, BroadcastMixin):
        def on_chatmsg(self, event):
            self.broadcast_event('chatmsg', event)
    '''

    def broadcast_event(self, event, *args):
    '''
        This is sent to all in the sockets in this particular Namespace,
        including itself.
        '''
        pass

    def broadcast_event_not_me(self, event, *args):
    '''
        This is sent to all in the sockets in this particular Namespace,
        except itself.
        '''
        pass

",3,3,snippet_288,0.25,"class BroadcastMixin(object):
    '''Mix in this class with your Namespace to have a broadcast event method.

    Use it like this:
    class MyNamespace(BaseNamespace, BroadcastMixin):
        def on_chatmsg(self, event):
            self.broadcast_event('chatmsg', event)
    '''

    def broadcast_event(self, event, *args):
        '''
        This is sent to all in the sockets in this particular Namespace,
        including itself.
        '''
        mgr = getattr(self, 'manager', None)
        if mgr is None:
            return
        ns_map = getattr(mgr, 'namespaces', {}).get(self.ns_name, {})
        for ns in ns_map.values():
            ns.emit(event, *args)

    def broadcast_event_not_me(self, event, *args):
        '''
        This is sent to all in the sockets in this particular Namespace,
        except itself.
        '''
        mgr = getattr(self, 'manager', None)
        if mgr is None:
            return
        ns_map = getattr(mgr, 'namespaces', {}).get(self.ns_name, {})
        for ns in ns_map.values():
            if ns is not self:
                ns.emit(event, *args)","class BroadcastMixin(object):
    '''Mix in this class with your Namespace to have a broadcast event method.

    Use it like this:
    class MyNamespace(BaseNamespace, BroadcastMixin):
        def on_chatmsg(self, event):
            self.broadcast_event('chatmsg', event)
    '''

    def broadcast_event(self, event, *args):
        '''
        This is sent to all in the sockets in this particular Namespace,
        including itself.
        '''
        if hasattr(self, 'socket') and hasattr(self.socket, 'server'):
            self.socket.server.broadcast(event, *args, namespace=self.__class__.__name__)
        elif hasattr(self, 'emit'):
            # Fallback to emit to all clients in this namespace
            self.emit(event, *args, broadcast=True)

    def broadcast_event_not_me(self, event, *args):
        '''
        This is sent to all in the sockets in this particular Namespace,
        except itself.
        '''
        if hasattr(self, 'socket') and hasattr(self.socket, 'server'):
            self.socket.server.broadcast(event, *args, namespace=self.__class__.__name__, skip_sid=self.socket.sid)
        elif hasattr(self, 'emit'):
            # Fallback to emit to all clients except sender
            self.emit(event, *args, broadcast=True, include_self=False)","class BroadcastMixin(object):
    '''Mix in this class with your Namespace to have a broadcast event method.

    Use it like this:
    class MyNamespace(BaseNamespace, BroadcastMixin):
        def on_chatmsg(self, event):
            self.broadcast_event('chatmsg', event)
    '''

    def broadcast_event(self, event, *args):
        '''
        This is sent to all in the sockets in this particular Namespace,
        including itself.
        '''
        for socket in self.socket.server.sockets.values():
            if hasattr(socket, 'active_ns') and self.ns_name in socket.active_ns:
                socket.active_ns[self.ns_name].emit(event, *args)

    def broadcast_event_not_me(self, event, *args):
        '''
        This is sent to all in the sockets in this particular Namespace,
        except itself.
        '''
        for socket in self.socket.server.sockets.values():
            if (hasattr(socket, 'active_ns') and 
                self.ns_name in socket.active_ns and 
                socket.active_ns[self.ns_name] != self):
                socket.active_ns[self.ns_name].emit(event, *args)",full_docstr,0.7032967032967034,0.6199261992619925,0.5724907063197027,0.6593406593406593,0.5515250926403902,0.6987951807228916,0.5201612903225806,0.46153846153846156,0.8797696828842163,0.8930100202560425,0.8863404393196106,0.8916680812835693,0.8201772368421052,0.6962457337883958,0.5567010309278351,0.5121107266435987,0.614334470989761,0.4971223355560297,0.6379310344827587,0.4740484429065744,0.40625,0.871596097946167,0.881613552570343,0.8765762448310852,0.8806014657020569,0.8095257142857143,0.776978417266187,0.6449275362318841,0.5693430656934306,0.6906474820143884,0.5885638547230898,0.7272727272727273,0.5674603174603174,0.4940239043824701,0.9119454026222229,0.8962769508361816,0.9040433168411255,0.8978193998336792,0.781692323943662,0.4968508262029795,0.4756278702720291,0.5988113444607654,0.2903225806451613,0.6226415094339622,0.4858715702797486,0.4535439988358106,0.5690658367567079,0.3548387096774194,0.5660377358490566,0.4917747020236024,0.5676971821317671,0.5917327276059777,0.3548387096774194,0.4528301886792453
1753,ANTsX/ANTsPy,ants/contrib/sampling/affine3d.py,ants.contrib.sampling.affine3d.Zoom3D,"class Zoom3D(object):
    """"""
    Create an ANTs Affine Transform with a specified level
    of zoom. Any value greater than 1 implies a ""zoom-out"" and anything
    less than 1 implies a ""zoom-in"".
    """"""

    def __init__(self, zoom, reference=None, lazy=False):
        """"""
        Initialize a Zoom3D object

        Arguments
        ---------
        zoom_range : list or tuple
            Lower and Upper bounds on zoom parameter.
            e.g. zoom_range = (0.7,0.9) will result in a random
            draw of the zoom parameters between 0.7 and 0.9

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        """"""
        if (not isinstance(zoom, (list, tuple))) or (len(zoom) != 3):
            raise ValueError(
                ""zoom_range argument must be list/tuple with three values!""
            )

        self.zoom = zoom
        self.lazy = lazy
        self.reference = reference

        self.tx = tio.ANTsTransform(
            precision=""float"", dimension=3, transform_type=""AffineTransform""
        )
        if self.reference is not None:
            self.tx.set_fixed_parameters(self.reference.get_center_of_mass())

    def transform(self, X=None, y=None):
        """"""
        Transform an image using an Affine transform with the given
        zoom parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('ch2'))
        >>> tx = ants.contrib.Zoom3D(zoom=(0.8,0.8,0.8))
        >>> img2 = tx.transform(img)
        """"""
        # unpack zoom range
        zoom_x, zoom_y, zoom_z = self.zoom

        self.params = (zoom_x, zoom_y, zoom_z)
        zoom_matrix = np.array(
            [[zoom_x, 0, 0, 0], [0, zoom_y, 0, 0], [0, 0, zoom_z, 0]]
        )
        self.tx.set_parameters(zoom_matrix)
        if self.lazy or X is None:
            return self.tx
        else:
            if y is None:
                return self.tx.apply_to_image(X, reference=self.reference)
            else:
                return (
                    self.tx.apply_to_image(X, reference=self.reference),
                    self.tx.apply_to_image(y, reference=self.reference),
                )","class Zoom3D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of zoom. Any value greater than 1 implies a ""zoom-out"" and anything
    less than 1 implies a ""zoom-in"".
    '''

    def __init__(self, zoom, reference=None, lazy=False):
    '''
        Initialize a Zoom3D object

        Arguments
        ---------
        zoom_range : list or tuple
            Lower and Upper bounds on zoom parameter.
            e.g. zoom_range = (0.7,0.9) will result in a random
            draw of the zoom parameters between 0.7 and 0.9

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        pass

    def transform(self, X=None, y=None):
    '''
        Transform an image using an Affine transform with the given
        zoom parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('ch2'))
        >>> tx = ants.contrib.Zoom3D(zoom=(0.8,0.8,0.8))
        >>> img2 = tx.transform(img)
        '''
        pass

",3,3,snippet_11,0.4285714285714285,"class Zoom3D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of zoom. Any value greater than 1 implies a ""zoom-out"" and anything
    less than 1 implies a ""zoom-in"".
    '''

    def __init__(self, zoom, reference=None, lazy=False):
        '''
        Initialize a Zoom3D object

        Arguments
        ---------
        zoom : scalar, 2-tuple, 3-tuple, or tuple of 3 2-tuples
            If scalar or 3-tuple of scalars, use fixed zoom factors.
            If 2-tuple of scalars, draw each of 3 axes from that range.
            If 3-tuple of 2-tuples, draw each axis from its own range.
        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.
        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        self.zoom = zoom
        self.reference = reference
        self.lazy = lazy
        self._last_zoom = None

    def _draw_zoom(self):
        z = self.zoom
        if np.isscalar(z):
            return [float(z)] * 3
        z = tuple(z)
        if len(z) == 2 and all(np.isscalar(v) for v in z):
            lo, hi = z
            return [float(np.random.uniform(lo, hi)) for _ in range(3)]
        if len(z) == 3:
            out = []
            for v in z:
                if np.isscalar(v):
                    out.append(float(v))
                elif len(v) == 2 and all(np.isscalar(x) for x in v):
                    out.append(float(np.random.uniform(v[0], v[1])))
                else:
                    raise ValueError(""Each element must be scalar or 2-tuple of scalars."")
            return out
        raise ValueError(""Invalid zoom specification."")

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        zoom parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform
        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types
        '''
        # draw zoom factors
        zoom_factors = self._draw_zoom()
        self._last_zoom = tuple(zoom_factors)

        # pick reference for center
        ref = self.reference
        if ref is None:
            if X is None:
                raise ValueError(""Reference image or X must be provided to build transform."")
            ref = X

        dim = ref.dimension
        if dim != 3:
            raise ValueError(""Zoom3D only supports 3D images."")

        # compute center in physical space
        origin = np.array(ref.origin)
        spacing = np.array(ref.spacing)
        shape = np.array(ref.shape)
        direction = np.array(ref.direction).reshape((dim, dim))
        idx_center = (shape - 1) / 2.0
        phys_center = origin + direction.dot(spacing * idx_center)

        # build affine matrix and translation
        S = np.diag(zoom_factors)
        M = S
        c = phys_center
        t = (np.eye(dim) - M).dot(c)

        # parameters: row-major matrix then translation
        params = list(M.flatten()) + list(t)
        fparams = list(phys_center)

        tx = ants.create_ants_transform('AffineTransform', dim, parameters=params, fixedParameters=fparams)

        # if requested to only return transform
        if X is None or self.lazy:
            return tx

        # apply to X (and y if provided)
        outX = ants.apply_ants_transform_to_image(tx, X, ref)
        if y is None:
            return outX
        outY = ants.apply_ants_transform_to_image(tx, y, ref)
        return outX, outY","class Zoom3D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of zoom. Any value greater than 1 implies a ""zoom-out"" and anything
    less than 1 implies a ""zoom-in"".
    '''

    def __init__(self, zoom, reference=None, lazy=False):
        '''
        Initialize a Zoom3D object

        Arguments
        ---------
        zoom : list or tuple
            Lower and Upper bounds on zoom parameter.
            e.g. zoom_range = (0.7,0.9) will result in a random
            draw of the zoom parameters between 0.7 and 0.9

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        self.zoom = zoom
        self.reference = reference
        self.lazy = lazy
        self.transform_ = None

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        zoom parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('ch2'))
        >>> tx = ants.contrib.Zoom3D(zoom=(0.8,0.8,0.8))
        >>> img2 = tx.transform(img)
        '''
        # Generate random zoom parameters if zoom is a range
        if isinstance(self.zoom, (list, tuple)) and len(self.zoom) == 2:
            zoom_params = [np.random.uniform(self.zoom[0], self.zoom[1]) for _ in range(3)]
        elif isinstance(self.zoom, (list, tuple)) and len(self.zoom) == 3:
            zoom_params = self.zoom
        else:
            zoom_params = [self.zoom, self.zoom, self.zoom]
        
        # Create affine transform matrix
        transform_matrix = np.array([
            [1.0/zoom_params[0], 0, 0, 0],
            [0, 1.0/zoom_params[1], 0, 0],
            [0, 0, 1.0/zoom_params[2], 0],
            [0, 0, 0, 1]
        ])
        
        # Create ANTs transform
        if self.reference is not None:
            tx = ants.create_ants_transform(transform_type='AffineTransform', 
                                          precision='float', 
                                          dimension=3,
                                          matrix=transform_matrix[:3,:3],
                                          offset=transform_matrix[:3,3],
                                          reference=self.reference)
        else:
            tx = ants.create_ants_transform(transform_type='AffineTransform', 
                                          precision='float', 
                                          dimension=3,
                                          matrix=transform_matrix[:3,:3],
                                          offset=transform_matrix[:3,3])
        
        self.transform_ = tx
        
        if X is None:
            return tx
        
        if self.lazy:
            return tx
        
        # Apply transform to image(s)
        X_transformed = ants.apply_ants_transform_to_image(tx, X, reference=X)
        
        if y is None:
            return X_transformed
        else:
            y_transformed = ants.apply_ants_transform_to_image(tx, y, reference=y)
            return (X_transformed, y_transformed)","class Zoom3D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of zoom. Any value greater than 1 implies a ""zoom-out"" and anything
    less than 1 implies a ""zoom-in"".
    '''

    def __init__(self, zoom, reference=None, lazy=False):
        '''
        Initialize a Zoom3D object

        Arguments
        ---------
        zoom_range : list or tuple
            Lower and Upper bounds on zoom parameter.
            e.g. zoom_range = (0.7,0.9) will result in a random
            draw of the zoom parameters between 0.7 and 0.9

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        self.zoom = zoom
        self.reference = reference
        self.lazy = lazy

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        zoom parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('ch2'))
        >>> tx = ants.contrib.Zoom3D(zoom=(0.8,0.8,0.8))
        >>> img2 = tx.transform(img)
        '''
        if isinstance(self.zoom, (list, tuple)) and len(self.zoom) == 3:
            zoom_params = self.zoom
        else:
            zoom_params = [self.zoom] * 3
        
        matrix = np.eye(4)
        matrix[0, 0] = zoom_params[0]
        matrix[1, 1] = zoom_params[1]
        matrix[2, 2] = zoom_params[2]
        
        tx = ants.create_ants_transform(transform_type='AffineTransform', 
                                       dimension=3, 
                                       matrix=matrix)
        
        if self.reference is not None:
            tx.set_fixed_parameters(self.reference.origin + self.reference.spacing + self.reference.direction.flatten().tolist())
        
        if X is None or self.lazy:
            return tx
        
        X_transformed = ants.apply_ants_transform_to_image(tx, X, X if self.reference is None else self.reference)
        
        if y is None:
            return X_transformed
        else:
            y_transformed = ants.apply_ants_transform_to_image(tx, y, y if self.reference is None else self.reference)
            return X_transformed, y_transformed",full_docstr,0.6025791324736224,0.3971797884841364,0.34628975265017664,0.4407971864009379,0.38144437100278955,0.5661057692307693,0.35379061371841153,0.27710843373493976,0.8357555866241455,0.8882522583007812,0.8612046241760254,0.8827076554298401,0.7437934117647057,0.8322496749024708,0.6544980443285527,0.580392156862745,0.6840052015604682,0.6075033648349517,0.7447405329593267,0.5912921348314607,0.509142053445851,0.91495680809021,0.9309124946594238,0.9228656888008118,0.9292919635772705,0.7533358000000001,0.8633093525179857,0.6955266955266955,0.6309696092619392,0.7194244604316548,0.6785672327031604,0.8776978417266187,0.7099099099099099,0.6191335740072202,0.9260572195053101,0.93315190076828,0.9295910596847534,0.932437539100647,0.736708210116732,0.4394643148102176,0.3262483809697559,0.5200704167326531,0.45,0.4615384615384615,0.5690562207542152,0.5882563131925339,0.6885180203737777,0.45,0.5494505494505495,0.5872463431510195,0.6670105500283388,0.6772129178138349,0.4333333333333333,0.5714285714285714
388755,fracpete/python-weka-wrapper3,fracpete_python-weka-wrapper3/python/weka/core/classes.py,python.weka.core.classes.JavaArrayIterator,"class JavaArrayIterator(object):
    """"""
    Iterator for elements in a Java array.
    """"""
    def __init__(self, data):
        """"""
        :param data: the Java array to iterate over
        :type data: JavaArray
        """"""
        self.data = data
        self.index = 0
        self.length = len(data)

    def __iter__(self):
        """"""
        Returns itself.
        """"""
        return self

    def __next__(self):
        """"""
        Returns the next element from the array.

        :return: the next array element object, wrapped as JavaObject if not null
        :rtype: JavaObject or None
        """"""
        if self.index < self.length:
            index = self.index
            self.index += 1
            return self.data[index]
        else:
            raise StopIteration()","class JavaArrayIterator(object):
    '''
    Iterator for elements in a Java array.
    '''

    def __init__(self, data):
    '''
        :param data: the Java array to iterate over
        :type data: JavaArray
        '''
        pass

    def __iter__(self):
    '''
        Returns itself.
        '''
        pass

    def __next__(self):
    '''
        Returns the next element from the array.

        :return: the next array element object, wrapped as JavaObject if not null
        :rtype: JavaObject or None
        '''
        pass

",4,4,snippet_669,1.0,"class JavaArrayIterator(object):
    '''
    Iterator for elements in a Java array.
    '''

    def __init__(self, data):
        '''
        :param data: the Java array to iterate over
        :type data: JavaArray
        '''
        self._data = data
        self._index = 0
        # Try to get Java-style length, else Python len()
        try:
            self._length = data.length
        except AttributeError:
            self._length = len(data)

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def __next__(self):
        '''
        Returns the next element from the array.

        :return: the next array element object, wrapped as JavaObject if not null
        :rtype: JavaObject or None
        '''
        if self._index >= self._length:
            raise StopIteration
        element = self._data[self._index]
        self._index += 1
        if element is None:
            return None
        # Assume JavaObject is available in scope
        return JavaObject(element)","class JavaArrayIterator(object):
    '''
    Iterator for elements in a Java array.
    '''

    def __init__(self, data):
        '''
        :param data: the Java array to iterate over
        :type data: JavaArray
        '''
        self.data = data
        self.index = 0
        self.length = data.length if hasattr(data, 'length') else len(data)

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def __next__(self):
        '''
        Returns the next element from the array.

        :return: the next array element object, wrapped as JavaObject if not null
        :rtype: JavaObject or None
        '''
        if self.index >= self.length:
            raise StopIteration
        
        try:
            element = self.data[self.index]
        except (IndexError, AttributeError):
            raise StopIteration
            
        self.index += 1
        return element","class JavaArrayIterator(object):
    '''
    Iterator for elements in a Java array.
    '''

    def __init__(self, data):
        '''
        :param data: the Java array to iterate over
        :type data: JavaArray
        '''
        self.data = data
        self.index = 0

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def __next__(self):
        '''
        Returns the next element from the array.

        :return: the next array element object, wrapped as JavaObject if not null
        :rtype: JavaObject or None
        '''
        if self.index >= len(self.data):
            raise StopIteration
        
        element = self.data[self.index]
        self.index += 1
        return element",full_docstr,0.8399999999999999,0.7777777777777778,0.7346938775510204,0.79,0.5852640910608639,0.7128712871287128,0.5920398009950248,0.475,0.8919172286987305,0.9545778632164001,0.9221842885017395,0.9479184746742249,0.8991606722689075,0.9130434782608695,0.8461538461538461,0.788888888888889,0.858695652173913,0.7277808792970377,0.8275862068965517,0.7283236994219653,0.6395348837209303,0.9398828744888306,0.9762066602706909,0.9577004909515381,0.9724482893943787,0.8898561739130435,0.9523809523809524,0.8674698795180723,0.8170731707317073,0.8809523809523809,0.6845399674357711,0.9251700680272109,0.815068493150685,0.696551724137931,0.9810693264007568,0.9741108417510986,0.9775777459144592,0.9748023152351379,0.8911575510204082,0.5036422010889301,0.4148682720408526,0.5643469969613326,0.5909090909090909,0.4444444444444444,0.6194756500967007,0.5566463024841696,0.6350610117073473,0.5454545454545454,0.7407407407407407,0.589567215395252,0.5877497006768965,0.6038524942374449,0.5,0.6666666666666666
388694,fracpete/python-weka-wrapper,fracpete_python-weka-wrapper/python/weka/core/dataset.py,python.weka.core.dataset.InstanceIterator,"class InstanceIterator(object):
    """"""
    Iterator for rows in an Instances object.
    """"""
    def __init__(self, data):
        """"""
        Initializes the iterator.

        :param data: the Instances object to iterate over
        :type data: Instances
        """"""
        self.data = data
        self.row = 0

    def __iter__(self):
        """"""
        Returns itself.
        """"""
        return self

    def next(self):
        """"""
        Returns the next row from the Instances object.

        :return: the next Instance object
        :rtype: Instance
        """"""
        if self.row < self.data.num_instances:
            index = self.row
            self.row += 1
            return self.data.get_instance(index)
        else:
            raise StopIteration()","class InstanceIterator(object):
    '''
    Iterator for rows in an Instances object.
    '''

    def __init__(self, data):
    '''
        Initializes the iterator.

        :param data: the Instances object to iterate over
        :type data: Instances
        '''
        pass

    def __iter__(self):
    '''
        Returns itself.
        '''
        pass

    def next(self):
    '''
        Returns the next row from the Instances object.

        :return: the next Instance object
        :rtype: Instance
        '''
        pass

",4,4,snippet_666,0.6666666666666666,"class InstanceIterator(object):
    '''
    Iterator for rows in an Instances object.
    '''

    def __init__(self, data):
        '''
        Initializes the iterator.

        :param data: the Instances object to iterate over
        :type data: Instances
        '''
        self._data = data
        self._index = 0

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def next(self):
        '''
        Returns the next row from the Instances object.

        :return: the next Instance object
        :rtype: Instance
        '''
        if self._index >= len(self._data):
            raise StopIteration
        inst = self._data[self._index]
        self._index += 1
        return inst

    __next__ = next","class InstanceIterator(object):
    '''
    Iterator for rows in an Instances object.
    '''

    def __init__(self, data):
        '''
        Initializes the iterator.

        :param data: the Instances object to iterate over
        :type data: Instances
        '''
        self._data = data
        self._index = 0

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def next(self):
        '''
        Returns the next row from the Instances object.

        :return: the next Instance object
        :rtype: Instance
        '''
        if self._index >= len(self._data):
            raise StopIteration
        instance = self._data.instance(self._index)
        self._index += 1
        return instance","class InstanceIterator(object):
    '''
    Iterator for rows in an Instances object.
    '''

    def __init__(self, data):
        '''
        Initializes the iterator.

        :param data: the Instances object to iterate over
        :type data: Instances
        '''
        self.data = data
        self.index = 0

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def next(self):
        '''
        Returns the next row from the Instances object.

        :return: the next Instance object
        :rtype: Instance
        '''
        if self.index >= len(self.data):
            raise StopIteration
        instance = self.data[self.index]
        self.index += 1
        return instance",full_docstr,0.8999999999999999,0.7974683544303798,0.717948717948718,0.825,0.616987861048239,0.8092105263157895,0.6556291390728477,0.54,0.96296226978302,0.9566413164138794,0.9597914218902588,0.9572696089744568,0.893618085106383,0.9182389937106918,0.8025477707006369,0.7225806451612904,0.8427672955974842,0.6280549027809428,0.8639455782312925,0.6986301369863014,0.5586206896551724,0.9722452163696289,0.9616846442222595,0.9669360518455505,0.9627304077148438,0.893618085106383,0.9240506329113924,0.8076923076923076,0.7272727272727272,0.8481012658227849,0.6242128003857886,0.8840579710144928,0.7445255474452555,0.625,0.9708477258682251,0.9590998888015747,0.9649380445480347,0.9602618217468262,0.9042562765957447,0.535840831087089,0.5226993787983726,0.5513057674961531,0.5476190476190477,0.5217391304347826,0.5511859728021719,0.5364608980396565,0.5513057674961531,0.5952380952380952,0.5217391304347826,0.6522311845976007,0.5453467061182866,0.5594372455226335,0.5476190476190477,0.9565217391304348
106298,CartoDB/carto-python,CartoDB_carto-python/carto/sql.py,carto.sql.SQLClient,"class SQLClient(object):
    """"""
    Allows you to send requests to CARTO's SQL API
    """"""
    def __init__(self, auth_client, api_version='v2'):
        """"""
        :param auth_client: Auth client to make authorized requests, such as
                            APIKeyAuthClient
        :param api_version: Current version is 'v2'. 'v1' can be used to avoid
                            caching, but it's not guaranteed to work
        :type auth_client: :class:`carto.auth.APIKeyAuthClient`
        :type api_version: str

        :return:
        """"""
        self.auth_client = auth_client
        self.api_url = SQL_API_URL.format(api_version=api_version)

        self.api_key = getattr(self.auth_client, 'api_key', None)
        self.username = getattr(self.auth_client, 'username', None)
        self.base_url = self.auth_client.base_url

    def send(self, sql, parse_json=True, do_post=True, format=None, **request_args):
        """"""
        Executes SQL query in a CARTO server

        :param sql: The SQL
        :param parse_json: Set it to False if you want raw reponse
        :param do_post: Set it to True to force post request
        :param format: Any of the data export formats allowed by CARTO's
                        SQL API
        :param request_args: Additional parameters to send with the request
        :type sql: str
        :type parse_json: boolean
        :type do_post: boolean
        :type format: str
        :type request_args: dictionary

        :return: response data, either as json or as a regular
                    response.content object
        :rtype: object

        :raise: CartoException
        """"""
        try:
            params = {'q': sql}
            if format:
                params['format'] = format
                if format not in ['json', 'geojson']:
                    parse_json = False

            if request_args is not None:
                for attr in request_args:
                    params[attr] = request_args[attr]

            if len(sql) < MAX_GET_QUERY_LEN and do_post is False:
                resp = self.auth_client.send(self.api_url,
                                             'GET',
                                             params=params)
            else:
                resp = self.auth_client.send(self.api_url, 'POST', data=params)

            return self.auth_client.get_response_data(resp, parse_json)
        except CartoRateLimitException as e:
            raise e
        except Exception as e:
            raise CartoException(e)","class SQLClient(object):
    '''
    Allows you to send requests to CARTO's SQL API
    '''

    def __init__(self, auth_client, api_version='v2'):
    '''
        :param auth_client: Auth client to make authorized requests, such as
                            APIKeyAuthClient
        :param api_version: Current version is 'v2'. 'v1' can be used to avoid
                            caching, but it's not guaranteed to work
        :type auth_client: :class:`carto.auth.APIKeyAuthClient`
        :type api_version: str

        :return:
        '''
        pass

    def send(self, sql, parse_json=True, do_post=True, format=None, **request_args):
    '''
        Executes SQL query in a CARTO server

        :param sql: The SQL
        :param parse_json: Set it to False if you want raw reponse
        :param do_post: Set it to True to force post request
        :param format: Any of the data export formats allowed by CARTO's
                        SQL API
        :param request_args: Additional parameters to send with the request
        :type sql: str
        :type parse_json: boolean
        :type do_post: boolean
        :type format: str
        :type request_args: dictionary

        :return: response data, either as json or as a regular
                    response.content object
        :rtype: object

        :raise: CartoException
        '''
        pass

",3,3,snippet_56,0.1578947368421052,"class SQLClient(object):
    '''
    Allows you to send requests to CARTO's SQL API
    '''

    def __init__(self, auth_client, api_version='v2'):
        '''
        :param auth_client: Auth client to make authorized requests, such as
                            APIKeyAuthClient
        :param api_version: Current version is 'v2'. 'v1' can be used to avoid
                            caching, but it's not guaranteed to work
        :type auth_client: :class:`carto.auth.APIKeyAuthClient`
        :type api_version: str

        :return:
        '''
        self.auth_client = auth_client
        self.api_version = api_version
        self._base_url = '{0}/api/{1}/sql'.format(
            self.auth_client.base_url.rstrip('/'),
            self.api_version
        )

    def send(self, sql, parse_json=True, do_post=True, format=None, **request_args):
        '''
        Executes SQL query in a CARTO server

        :param sql: The SQL
        :param parse_json: Set it to False if you want raw reponse
        :param do_post: Set it to True to force post request
        :param format: Any of the data export formats allowed by CARTO's
                        SQL API
        :param request_args: Additional parameters to send with the request
        :type sql: str
        :type parse_json: boolean
        :type do_post: boolean
        :type format: str
        :type request_args: dictionary

        :return: response data, either as json or as a regular
                    response.content object
        :rtype: object

        :raise: CartoException
        '''
        params = {}
        if format is not None:
            params['format'] = format
        params.update(request_args)

        api_key = getattr(self.auth_client, 'api_key', None)
        if api_key:
            params['api_key'] = api_key

        if do_post:
            data = {'q': sql}
            resp = self.auth_client.session.post(self._base_url, params=params, data=data)
        else:
            params['q'] = sql
            resp = self.auth_client.session.get(self._base_url, params=params)

        try:
            resp.raise_for_status()
        except Exception:
            raise CartoException(resp)

        if parse_json:
            return resp.json()
        return resp.content","class SQLClient(object):
    '''
    Allows you to send requests to CARTO's SQL API
    '''

    def __init__(self, auth_client, api_version='v2'):
        '''
        :param auth_client: Auth client to make authorized requests, such as
                            APIKeyAuthClient
        :param api_version: Current version is 'v2'. 'v1' can be used to avoid
                            caching, but it's not guaranteed to work
        :type auth_client: :class:`carto.auth.APIKeyAuthClient`
        :type api_version: str

        :return:
        '''
        self.auth_client = auth_client
        self.api_version = api_version

    def send(self, sql, parse_json=True, do_post=True, format=None, **request_args):
        '''
        Executes SQL query in a CARTO server

        :param sql: The SQL
        :param parse_json: Set it to False if you want raw reponse
        :param do_post: Set it to True to force post request
        :param format: Any of the data export formats allowed by CARTO's
                        SQL API
        :param request_args: Additional parameters to send with the request
        :type sql: str
        :type parse_json: boolean
        :type do_post: boolean
        :type format: str
        :type request_args: dictionary

        :return: response data, either as json or as a regular
                    response.content object
        :rtype: object

        :raise: CartoException
        '''
        from carto.exceptions import CartoException
        import json

        # Prepare the request parameters
        params = dict(request_args)
        params['q'] = sql
        
        if format is not None:
            params['format'] = format

        try:
            if do_post:
                response = self.auth_client.send(self.auth_client.api_url + '/sql/' + self.api_version + '/sql', 'POST', data=params)
            else:
                response = self.auth_client.send(self.auth_client.api_url + '/sql/' + self.api_version + '/sql', 'GET', params=params)
            
            if response.status_code != 200:
                raise CartoException('HTTP error {}: {}'.format(response.status_code, response.text))
            
            if parse_json:
                return response.json()
            else:
                return response.content
                
        except Exception as e:
            if isinstance(e, CartoException):
                raise
            else:
                raise CartoException(e)","class SQLClient(object):
    '''
    Allows you to send requests to CARTO's SQL API
    '''

    def __init__(self, auth_client, api_version='v2'):
        '''
        :param auth_client: Auth client to make authorized requests, such as
                            APIKeyAuthClient
        :param api_version: Current version is 'v2'. 'v1' can be used to avoid
                            caching, but it's not guaranteed to work
        :type auth_client: :class:`carto.auth.APIKeyAuthClient`
        :type api_version: str

        :return:
        '''
        self.auth_client = auth_client
        self.api_version = api_version

    def send(self, sql, parse_json=True, do_post=True, format=None, **request_args):
        '''
        Executes SQL query in a CARTO server

        :param sql: The SQL
        :param parse_json: Set it to False if you want raw reponse
        :param do_post: Set it to True to force post request
        :param format: Any of the data export formats allowed by CARTO's
                        SQL API
        :param request_args: Additional parameters to send with the request
        :type sql: str
        :type parse_json: boolean
        :type do_post: boolean
        :type format: str
        :type request_args: dictionary

        :return: response data, either as json or as a regular
                    response.content object
        :rtype: object

        :raise: CartoException
        '''
        url = ""{base_url}sql/{api_version}/"".format(
            base_url=self.auth_client.base_url,
            api_version=self.api_version
        )
        
        params = {'q': sql}
        if format:
            params['format'] = format
        params.update(request_args)
        
        try:
            if do_post:
                response = self.auth_client.send(url, 'POST', params, None)
            else:
                response = self.auth_client.send(url, 'GET', params, None)
            
            if response.status_code != 200:
                raise CartoException(""SQL API request failed with status code: {}"".format(response.status_code))
            
            if parse_json:
                try:
                    return response.json()
                except ValueError:
                    return response.content
            else:
                return response.content
                
        except Exception as e:
            if isinstance(e, CartoException):
                raise
            raise CartoException(""SQL API request failed: {}"".format(str(e)))",full_docstr,0.8779661016949153,0.7414965986394558,0.6723549488054607,0.7661016949152541,0.730624901392856,0.8957055214723927,0.7704918032786885,0.6837782340862423,0.949652910232544,0.935815691947937,0.9426835179328918,0.9371811747550964,0.8068802380952381,0.8436974789915966,0.7453625632377741,0.673434856175973,0.749579831932773,0.7006088039148092,0.8565573770491803,0.728952772073922,0.6707818930041153,0.9183492064476013,0.9218024015426636,0.920072615146637,0.9214558601379395,0.7632298809523811,0.8489932885906041,0.7239057239057238,0.6722972972972973,0.7416107382550335,0.7038469073256692,0.8678861788617886,0.7209775967413442,0.6612244897959184,0.9262980222702026,0.9197993874549866,0.9230372309684753,0.9204450845718384,0.7724890476190478,0.5323264708232314,0.6376660989763712,0.6321518030775468,0.4873949579831932,0.3720930232558139,0.5277031683999436,0.6320721067010673,0.6328347627165688,0.4621848739495798,0.3837209302325581,0.5320902596804231,0.6457319719660675,0.6419020782858186,0.4453781512605042,0.3953488372093023
149342,ManiacalLabs/BiblioPixel,ManiacalLabs_BiblioPixel/bibliopixel/util/log_errors.py,bibliopixel.util.log_errors.LogErrors,"class LogErrors:
    """"""
    Wraps a function call to catch and report exceptions.
    """"""

    def __init__(self, function, errors):
        """"""
        :param function: the function to wrap
        :param errors: either a number, indicating how many errors to report
           before ignoring them, or one of these strings:
           'raise', meaning to raise an exception
           'ignore', meaning to ignore all errors
           'report', meaning to report all errors
        """"""
        assert isinstance(errors, int) or errors in (
            'raise', 'ignore', 'report')
        self.function = function
        self.errors = errors
        self.error_count = 0

    def __call__(self, *args, **kwds):
        """"""
        Calls `self.function` with the given arguments and keywords, and
        returns its value - or if the call throws an exception, returns None.
        """"""
        try:
            return self.function(*args, **kwds)
        except Exception as e:
            self.error_count += 1
            if self.errors == 'raise':
                raise
            if self.errors == 'ignore':
                return
            args = (class_name.class_name(e),) + e.args

        if self.errors == 'report' or self.error_count <= self.errors:
            log.error(str(args))

        elif self.error_count == self.errors + 1:
            log.error('Exceeded errors of %d', self.errors)","class LogErrors:
    '''
    Wraps a function call to catch and report exceptions.
    '''

    def __init__(self, function, errors):
    '''
        :param function: the function to wrap
        :param errors: either a number, indicating how many errors to report
           before ignoring them, or one of these strings:
           'raise', meaning to raise an exception
           'ignore', meaning to ignore all errors
           'report', meaning to report all errors
        '''
        pass

    def __call__(self, *args, **kwds):
    '''
        Calls `self.function` with the given arguments and keywords, and
        returns its value - or if the call throws an exception, returns None.
        '''
        pass

",3,3,snippet_184,0.6111111111111112,"class LogErrors:
    '''
    Wraps a function call to catch and report exceptions.
    '''

    def __init__(self, function, errors):
        '''
        :param function: the function to wrap
        :param errors: either a number, indicating how many errors to report
           before ignoring them, or one of these strings:
           'raise', meaning to raise an exception
           'ignore', meaning to ignore all errors
           'report', meaning to report all errors
        '''
        self.function = function
        if isinstance(errors, str):
            if errors not in ('raise', 'ignore', 'report'):
                raise ValueError(""errors must be 'raise', 'ignore', 'report', or a non-negative integer"")
            self.mode = errors
        else:
            try:
                count = int(errors)
            except Exception:
                raise TypeError(""errors must be a string or an integer"")
            if count < 0:
                raise ValueError(""error count must be non-negative"")
            self.mode = 'count'
            self.errors_allowed = count
            self.error_count = 0

    def __call__(self, *args, **kwds):
        '''
        Calls `self.function` with the given arguments and keywords, and
        returns its value - or if the call throws an exception, returns None.
        '''
        try:
            return self.function(*args, **kwds)
        except Exception:
            if self.mode == 'raise':
                raise
            if self.mode == 'ignore':
                return None
            if self.mode == 'report':
                traceback.print_exc()
                return None
            # mode == 'count'
            if self.error_count < self.errors_allowed:
                traceback.print_exc()
                self.error_count += 1
            return None","class LogErrors:
    '''
    Wraps a function call to catch and report exceptions.
    '''

    def __init__(self, function, errors):
        '''
        :param function: the function to wrap
        :param errors: either a number, indicating how many errors to report
           before ignoring them, or one of these strings:
           'raise', meaning to raise an exception
           'ignore', meaning to ignore all errors
           'report', meaning to report all errors
        '''
        self.function = function
        self.errors = errors
        self.error_count = 0

    def __call__(self, *args, **kwds):
        '''
        Calls `self.function` with the given arguments and keywords, and
        returns its value - or if the call throws an exception, returns None.
        '''
        try:
            return self.function(*args, **kwds)
        except Exception as e:
            if self.errors == 'raise':
                raise
            elif self.errors == 'ignore':
                return None
            elif self.errors == 'report':
                print(f""Error in {self.function.__name__}: {e}"")
                return None
            elif isinstance(self.errors, (int, float)):
                if self.error_count < self.errors:
                    print(f""Error in {self.function.__name__}: {e}"")
                    self.error_count += 1
                return None
            else:
                return None","class LogErrors:
    '''
    Wraps a function call to catch and report exceptions.
    '''

    def __init__(self, function, errors):
        '''
        :param function: the function to wrap
        :param errors: either a number, indicating how many errors to report
           before ignoring them, or one of these strings:
           'raise', meaning to raise an exception
           'ignore', meaning to ignore all errors
           'report', meaning to report all errors
        '''
        self.function = function
        self.errors = errors
        self.error_count = 0

    def __call__(self, *args, **kwds):
        '''
        Calls `self.function` with the given arguments and keywords, and
        returns its value - or if the call throws an exception, returns None.
        '''
        try:
            return self.function(*args, **kwds)
        except Exception as e:
            if self.errors == 'raise':
                raise
            elif self.errors == 'ignore':
                return None
            elif self.errors == 'report':
                print(f""Error in {self.function.__name__}: {e}"")
                return None
            elif isinstance(self.errors, int):
                if self.error_count < self.errors:
                    print(f""Error in {self.function.__name__}: {e}"")
                    self.error_count += 1
                return None
            else:
                return None",full_docstr,0.7717391304347827,0.6557377049180328,0.576923076923077,0.6956521739130435,0.6207521136694553,0.7710843373493976,0.595166163141994,0.5212121212121212,0.8859713673591614,0.9142090678215027,0.8998687267303467,0.9113044738769531,0.8031027441860464,0.8685015290519879,0.7753846153846154,0.7058823529411765,0.7889908256880734,0.6934866625674527,0.8480565371024735,0.7198581560283688,0.6476868327402135,0.9404162168502808,0.9309463500976562,0.935657262802124,0.9318847060203552,0.8146186096256683,0.8711656441717791,0.7777777777777778,0.7080745341614907,0.7914110429447853,0.693604095328648,0.8494623655913979,0.7338129496402878,0.6642599277978339,0.9426092505455017,0.9313965439796448,0.9369693398475647,0.93250572681427,0.8146186096256683,0.6757628189749508,0.4849083277166556,0.6027583327985322,0.6153846153846154,0.0,0.6270064887621023,0.6469612552390455,0.6520396822737076,0.5494505494505495,0.6595744680851063,0.6269620602944513,0.646783541368442,0.6520396822737076,0.5494505494505495,0.6595744680851063
204645,TrafficSenseMSD/SumoTools,TrafficSenseMSD_SumoTools/sumolib/__init__.py,sumolib._Running,"class _Running:

    """"""
    A generator of running, numerical IDs
    Should be enhanced by:
    - a member method for returning the size
    - a member iterator over the stored ids
    """"""

    def __init__(self, orig_ids=False, warn=False):
        """"""Contructor""""""
        # whether original IDs shall be used instead of an index
        self.orig_ids = orig_ids
        # whether a warning for non-integer IDs shall be given
        self.warn = warn
        # running index of assigned numerical IDs
        self.index = 0
        # map from known IDs to assigned numerical IDs
        self._m = {}

    def g(self, id):
        """"""
        If the given id is known, the numerical representation is returned,
        otherwise a new running number is assigned to the id and returned""""""
        if id not in self._m:
            if self.orig_ids:
                self._m[id] = id
                if self.warn:
                    try:
                        int(id)
                    except:
                        sys.stderr.write(
                            'Warning: ID ""%s"" is not an integer.\n' % id)
                        self.warn = False
            else:
                self._m[id] = self.index
                self.index += 1
        return self._m[id]

    def k(self, id):
        """"""
        Returns whether the given id is known.""""""
        return id in self._m

    def d(self, id):
        """"""
        Removed the element.""""""
        del self._m[id]","class _Running:
    '''
    A generator of running, numerical IDs
    Should be enhanced by:
    - a member method for returning the size
    - a member iterator over the stored ids
    '''

    def __init__(self, orig_ids=False, warn=False):
    '''Contructor'''
        pass

    def g(self, id):
    '''
        If the given id is known, the numerical representation is returned,
        otherwise a new running number is assigned to the id and returned'''
        pass

    def k(self, id):
    '''
        Returns whether the given id is known.'''
        pass

    def d(self, id):
    '''
        Removed the element.'''
        pass

",5,5,snippet_270,1.0,"class _Running:
    '''
    A generator of running, numerical IDs
    Should be enhanced by:
    - a member method for returning the size
    - a member iterator over the stored ids
    '''

    def __init__(self, orig_ids=False, warn=False):
        '''Constructor'''
        self._warn = warn
        self._id2num = {}
        self._next = 1
        if orig_ids:
            if isinstance(orig_ids, dict):
                for key, val in orig_ids.items():
                    if key in self._id2num and self._warn:
                        warnings.warn(f""Duplicate id {key} in orig_ids"")
                    self._id2num[key] = val
                if self._id2num:
                    self._next = max(self._id2num.values()) + 1
            else:
                try:
                    for key in orig_ids:
                        if key in self._id2num and self._warn:
                            warnings.warn(f""Duplicate id {key} in orig_ids"")
                        self._id2num[key] = self._next
                        self._next += 1
                except TypeError:
                    raise ValueError(""orig_ids must be a dict or an iterable"")

    def g(self, id):
        '''
        If the given id is known, the numerical representation is returned,
        otherwise a new running number is assigned to the id and returned
        '''
        if id in self._id2num:
            return self._id2num[id]
        num = self._next
        self._id2num[id] = num
        self._next += 1
        return num

    def k(self, id):
        '''
        Returns whether the given id is known.
        '''
        return id in self._id2num

    def d(self, id):
        '''
        Removed the element.
        '''
        if id in self._id2num:
            del self._id2num[id]
        else:
            if self._warn:
                warnings.warn(f""id {id} not found"")

    def size(self):
        '''Return the number of stored ids.'''
        return len(self._id2num)

    def __len__(self):
        return len(self._id2num)

    def __iter__(self):
        return iter(self._id2num)","class _Running:
    '''
    A generator of running, numerical IDs
    Should be enhanced by:
    - a member method for returning the size
    - a member iterator over the stored ids
    '''

    def __init__(self, orig_ids=False, warn=False):
        '''Constructor'''
        self._id_map = {}
        self._next_id = 0
        self._orig_ids = orig_ids
        self._warn = warn

    def g(self, id):
        '''
        If the given id is known, the numerical representation is returned,
        otherwise a new running number is assigned to the id and returned'''
        if id in self._id_map:
            return self._id_map[id]
        else:
            num_id = self._next_id
            self._id_map[id] = num_id
            self._next_id += 1
            return num_id

    def k(self, id):
        '''
        Returns whether the given id is known.'''
        return id in self._id_map

    def d(self, id):
        '''
        Removed the element.'''
        if id in self._id_map:
            del self._id_map[id]

    def size(self):
        '''Returns the number of stored ids'''
        return len(self._id_map)

    def __iter__(self):
        '''Iterator over the stored ids'''
        return iter(self._id_map)","class _Running:
    '''
    A generator of running, numerical IDs
    Should be enhanced by:
    - a member method for returning the size
    - a member iterator over the stored ids
    '''

    def __init__(self, orig_ids=False, warn=False):
        '''Contructor'''
        self.orig_ids = orig_ids
        self.warn = warn
        self.id_to_num = {}
        self.num_to_id = {}
        self.next_num = 0

    def g(self, id):
        '''
        If the given id is known, the numerical representation is returned,
        otherwise a new running number is assigned to the id and returned'''
        if id in self.id_to_num:
            return self.id_to_num[id]
        else:
            num = self.next_num
            self.id_to_num[id] = num
            self.num_to_id[num] = id
            self.next_num += 1
            return num

    def k(self, id):
        '''
        Returns whether the given id is known.'''
        return id in self.id_to_num

    def d(self, id):
        '''
        Removed the element.'''
        if id in self.id_to_num:
            num = self.id_to_num[id]
            del self.id_to_num[id]
            del self.num_to_id[num]

    def size(self):
        return len(self.id_to_num)

    def __iter__(self):
        return iter(self.id_to_num.keys())",full_docstr,0.6270022883295194,0.4505747126436782,0.3695150115473441,0.517162471395881,0.37883816269051673,0.5098901098901099,0.3744493392070485,0.2847682119205298,0.827404260635376,0.8676708340644836,0.8470593094825745,0.863468587398529,0.7777800000000001,0.7005649717514124,0.5397727272727273,0.47428571428571425,0.6214689265536724,0.49825015481059576,0.7058823529411765,0.5416666666666666,0.42857142857142855,0.8897960186004639,0.8584707975387573,0.8738527894020081,0.8615037202835083,0.8399262711864406,0.6559139784946236,0.5135135135135135,0.45108695652173914,0.6075268817204301,0.4884642569024475,0.6461538461538462,0.48148148148148145,0.3746130030959752,0.8744379281997681,0.8601460456848145,0.8672330975532532,0.8615541458129883,0.8144348453608248,0.4328170875779477,0.3122920651989107,0.3942849270881888,0.6172839506172839,0.4074074074074074,0.417330744079326,0.36866456296974,0.3870781664339838,0.5802469135802469,0.3333333333333333,0.4542000893938886,0.3778024853719214,0.3957879956604232,0.5802469135802469,0.4629629629629629
397348,genialis/resolwe,resolwe/process/parser.py,resolwe.process.parser.SafeParser,"class SafeParser:
    """"""Safe parser for Python processes which doesn't evaluate any code.""""""

    def __init__(self, source):
        """"""Construct process parser.

        :param source: Process source code string
        """"""
        self._source = source

    def parse(self):
        """"""Parse process.

        :return: A list of discovered process descriptors
        """"""
        root = ast.parse(self._source)
        visitor = ProcessVisitor(source=self._source)
        visitor.visit(root)
        return visitor.processes

    def base_classes(self):
        """"""Parse process.

        :return: A list of the base classes for the processes.
        """"""
        root = ast.parse(self._source)
        visitor = ProcessVisitor(source=self._source)
        visitor.visit(root)
        return visitor.base_classes","class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
    '''Construct process parser.

        :param source: Process source code string
        '''
        pass

    def parse(self):
    '''Parse process.

        :return: A list of discovered process descriptors
        '''
        pass

    def base_classes(self):
    '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        pass

",4,4,snippet_703,1.0,"class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
        '''Construct process parser.

        :param source: Process source code string
        '''
        self.source = source
        try:
            self.tree = ast.parse(source)
        except SyntaxError:
            self.tree = None

    def parse(self):
        '''Parse process.

        :return: A list of discovered process descriptors
        '''
        if self.tree is None:
            return []

        descriptors = []
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                bases = [self._get_base_name(b) for b in node.bases]
                methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                descriptors.append({
                    'name': node.name,
                    'bases': bases,
                    'methods': methods
                })
        return descriptors

    def base_classes(self):
        '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        if self.tree is None:
            return []

        bases = set()
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                for b in node.bases:
                    bases.add(self._get_base_name(b))
        return list(bases)

    def _get_base_name(self, node):
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            parts = []
            while isinstance(node, ast.Attribute):
                parts.insert(0, node.attr)
                node = node.value
            if isinstance(node, ast.Name):
                parts.insert(0, node.id)
            return ""."".join(parts)
        else:
            return ast.dump(node)","class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
        '''Construct process parser.

        :param source: Process source code string
        '''
        self.source = source
        self.tree = ast.parse(source)
        self.processes = []

    def parse(self):
        '''Parse process.

        :return: A list of discovered process descriptors
        '''
        self.processes = []
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                # Check if this class inherits from a Process class
                base_classes = self._get_base_classes(node)
                if self._is_process_class(base_classes):
                    process_descriptor = {
                        'name': node.name,
                        'bases': base_classes,
                        'methods': self._get_methods(node),
                        'attributes': self._get_attributes(node)
                    }
                    self.processes.append(process_descriptor)
        
        return self.processes

    def base_classes(self):
        '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        processes = self.parse()
        all_base_classes = []
        
        for process in processes:
            all_base_classes.extend(process['bases'])
        
        # Remove duplicates while preserving order
        seen = set()
        unique_base_classes = []
        for base_class in all_base_classes:
            if base_class not in seen:
                seen.add(base_class)
                unique_base_classes.append(base_class)
        
        return unique_base_classes

    def _get_base_classes(self, class_node):
        '''Extract base classes from a class definition node.'''
        bases = []
        for base in class_node.bases:
            if isinstance(base, ast.Name):
                bases.append(base.id)
            elif isinstance(base, ast.Attribute):
                # Handle cases like module.Class
                bases.append(self._get_attribute_name(base))
            elif isinstance(base, ast.Call):
                # Handle cases like SomeClass()
                if isinstance(base.func, ast.Name):
                    bases.append(base.func.id)
                elif isinstance(base.func, ast.Attribute):
                    bases.append(self._get_attribute_name(base.func))
        return bases

    def _get_attribute_name(self, attr_node):
        '''Extract full attribute name (e.g., module.Class).'''
        if isinstance(attr_node, ast.Name):
            return attr_node.id
        elif isinstance(attr_node, ast.Attribute):
            return f""{self._get_attribute_name(attr_node.value)}.{attr_node.attr}""
        return """"

    def _is_process_class(self, base_classes):
        '''Determine if a class is a process class based on its base classes.'''
        process_indicators = ['Process', 'BaseProcess', 'multiprocessing.Process']
        for base in base_classes:
            if any(indicator in base for indicator in process_indicators):
                return True
        return False

    def _get_methods(self, class_node):
        '''Extract method names from a class definition.'''
        methods = []
        for item in class_node.body:
            if isinstance(item, ast.FunctionDef):
                methods.append(item.name)
        return methods

    def _get_attributes(self, class_node):
        '''Extract attribute names from a class definition.'''
        attributes = []
        for item in class_node.body:
            if isinstance(item, ast.Assign):
                for target in item.targets:
                    if isinstance(target, ast.Name):
                        attributes.append(target.id)
            elif isinstance(item, ast.AnnAssign):
                if isinstance(item.target, ast.Name):
                    attributes.append(item.target.id)
        return attributes","class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
        '''Construct process parser.

        :param source: Process source code string
        '''
        self.source = source
        self.tree = None
        try:
            self.tree = ast.parse(source)
        except SyntaxError:
            self.tree = None

    def parse(self):
        '''Parse process.

        :return: A list of discovered process descriptors
        '''
        if self.tree is None:
            return []
        
        processes = []
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                process_info = {
                    'name': node.name,
                    'lineno': node.lineno,
                    'bases': [self._get_base_name(base) for base in node.bases],
                    'methods': [],
                    'attributes': []
                }
                
                for item in node.body:
                    if isinstance(item, ast.FunctionDef):
                        method_info = {
                            'name': item.name,
                            'lineno': item.lineno,
                            'args': [arg.arg for arg in item.args.args]
                        }
                        process_info['methods'].append(method_info)
                    elif isinstance(item, ast.Assign):
                        for target in item.targets:
                            if isinstance(target, ast.Name):
                                process_info['attributes'].append(target.id)
                
                processes.append(process_info)
        
        return processes

    def base_classes(self):
        '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        if self.tree is None:
            return []
        
        base_classes = set()
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                for base in node.bases:
                    base_name = self._get_base_name(base)
                    if base_name:
                        base_classes.add(base_name)
        
        return list(base_classes)
    
    def _get_base_name(self, base_node):
        '''Extract base class name from AST node.'''
        if isinstance(base_node, ast.Name):
            return base_node.id
        elif isinstance(base_node, ast.Attribute):
            parts = []
            node = base_node
            while isinstance(node, ast.Attribute):
                parts.append(node.attr)
                node = node.value
            if isinstance(node, ast.Name):
                parts.append(node.id)
            return '.'.join(reversed(parts))
        return None",full_docstr,0.45637583892617456,0.3716216216216216,0.3469387755102041,0.4429530201342282,0.24595473944278337,0.3394736842105263,0.24010554089709762,0.18253968253968253,0.7655090689659119,0.896241307258606,0.8257328271865845,0.8811924457550049,0.7631050943396229,0.2674199623352166,0.22306238185255198,0.19734345351043645,0.256120527306968,0.12797819936040453,0.1662531017369727,0.1267080745341615,0.09950248756218906,0.7445294260978699,0.8995617628097534,0.8147361278533936,0.8812124133110046,0.7213524083769633,0.3814713896457766,0.3178082191780822,0.2865013774104683,0.3705722070844687,0.1856457038576293,0.2509727626459144,0.18128654970760233,0.140625,0.7446741461753845,0.8976362943649292,0.8140318989753723,0.8795692324638367,0.7404843356643361,0.4481743963531025,0.2078778585885664,0.4804212106606217,0.5098039215686274,0.5945945945945946,0.4673660376112425,0.1102936022114811,0.4804212106606217,0.5490196078431373,0.7297297297297297,0.4336855808946388,0.1647609645342557,0.4804212106606217,0.5490196078431373,0.5405405405405406
327676,damianbraun/nominatim,damianbraun_nominatim/nominatim/nominatim.py,nominatim.nominatim.NominatimRequest,"class NominatimRequest(object):
    """"""
    Abstract base class for connections to a Nominatim instance
    """"""
    def __init__(self, base_url=None):
        """"""
        Provide logging and set the Nominatim instance
        (defaults to http://nominatim.openstreetmap.org )
        """"""
        self.logger = logging.getLogger(__name__)
        self.url = base_url.rstrip('/') if base_url is not None else default_url

    def request(self, url):
        """"""
        Send a http request to the given *url*, try to decode
        the reply assuming it's JSON in UTF-8, and return the result

        :returns: Decoded result, or None in case of an error
        :rtype: mixed
        """"""
        self.logger.debug('url:\n' + url)
        try:
            response = urlopen(url)
            return json.loads(response.read().decode('utf-8'))
        except URLError:
            self.logger.info('Server connection problem')
        except Exception:
            self.logger.info('Server format problem')","class NominatimRequest(object):
    '''
    Abstract base class for connections to a Nominatim instance
    '''

    def __init__(self, base_url=None):
    '''
        Provide logging and set the Nominatim instance
        (defaults to http://nominatim.openstreetmap.org )
        '''
        pass

    def request(self, url):
    '''
        Send a http request to the given *url*, try to decode
        the reply assuming it's JSON in UTF-8, and return the result

        :returns: Decoded result, or None in case of an error
        :rtype: mixed
        '''
        pass

",3,3,snippet_568,0.25,"class NominatimRequest(object):
    '''
    Abstract base class for connections to a Nominatim instance
    '''

    def __init__(self, base_url=None):
        '''
        Provide logging and set the Nominatim instance
        (defaults to http://nominatim.openstreetmap.org )
        '''
        self.logger = logging.getLogger(self.__class__.__name__)
        self.base_url = base_url or 'http://nominatim.openstreetmap.org'

    def request(self, url):
        '''
        Send a http request to the given *url*, try to decode
        the reply assuming it's JSON in UTF-8, and return the result

        :returns: Decoded result, or None in case of an error
        :rtype: mixed
        '''
        try:
            self.logger.debug(""Requesting URL: %s"", url)
            with urllib.request.urlopen(url) as response:
                raw = response.read()
            text = raw.decode('utf-8')
            return json.loads(text)
        except Exception as e:
            self.logger.error(""Error fetching URL %s: %s"", url, e)
            return None","class NominatimRequest(object):
    '''
    Abstract base class for connections to a Nominatim instance
    '''

    def __init__(self, base_url=None):
        '''
        Provide logging and set the Nominatim instance
        (defaults to http://nominatim.openstreetmap.org )
        '''
        self.logger = logging.getLogger(__name__)
        self.base_url = base_url or 'http://nominatim.openstreetmap.org'

    def request(self, url):
        '''
        Send a http request to the given *url*, try to decode
        the reply assuming it's JSON in UTF-8, and return the result

        :returns: Decoded result, or None in case of an error
        :rtype: mixed
        '''
        try:
            with urllib.request.urlopen(url) as response:
                data = response.read()
                return json.loads(data.decode('utf-8'))
        except Exception as e:
            self.logger.error(f""Error making request to {url}: {e}"")
            return None","class NominatimRequest(object):
    '''
    Abstract base class for connections to a Nominatim instance
    '''

    def __init__(self, base_url=None):
        '''
        Provide logging and set the Nominatim instance
        (defaults to http://nominatim.openstreetmap.org )
        '''
        self.logger = logging.getLogger(__name__)
        if base_url is None:
            self.base_url = ""http://nominatim.openstreetmap.org""
        else:
            self.base_url = base_url

    def request(self, url):
        '''
        Send a http request to the given *url*, try to decode
        the reply assuming it's JSON in UTF-8, and return the result

        :returns: Decoded result, or None in case of an error
        :rtype: mixed
        '''
        try:
            with urllib.request.urlopen(url) as response:
                data = response.read().decode('utf-8')
                return json.loads(data)
        except (urllib.error.URLError, urllib.error.HTTPError, json.JSONDecodeError, UnicodeDecodeError) as e:
            self.logger.error(f""Request failed: {e}"")
            return None",full_docstr,0.831372549019608,0.6877470355731224,0.5976095617529881,0.7607843137254903,0.6584922957957104,0.7869565217391304,0.6462882096069869,0.5614035087719298,0.935854434967041,0.939690351486206,0.9377684593200684,0.9393054246902466,0.8523824285714285,0.8114754098360655,0.7190082644628099,0.6416666666666666,0.7704918032786884,0.6513779509299836,0.8374384236453202,0.7029702970297029,0.6318407960199005,0.9510093927383423,0.9387596845626831,0.9448448419570923,0.9399703741073608,0.8695665217391304,0.8093385214007782,0.6901960784313725,0.6324110671936759,0.7392996108949416,0.654692180308616,0.7801724137931034,0.6363636363636364,0.5652173913043478,0.9122216701507568,0.9340515732765198,0.923007607460022,0.9318217039108276,0.8379645833333333,0.4474292728221339,0.5275407779770264,0.5644151192816587,0.4477611940298507,0.25,0.5358796555660462,0.5649688199364916,0.5696878620291856,0.4776119402985074,0.53125,0.6621913792405567,0.5539259095628609,0.5873769208322016,0.5074626865671642,0.0
157253,NikolayDachev/jadm,NikolayDachev_jadm/lib/paramiko-1.14.1/paramiko/server.py,paramiko.server.InteractiveQuery,"class InteractiveQuery (object):
    """"""
    A query (set of prompts) for a user during interactive authentication.
    """"""
    
    def __init__(self, name='', instructions='', *prompts):
        """"""
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.
        
        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        """"""
        self.name = name
        self.instructions = instructions
        self.prompts = []
        for x in prompts:
            if isinstance(x, string_types):
                self.add_prompt(x)
            else:
                self.add_prompt(x[0], x[1])
    
    def add_prompt(self, prompt, echo=True):
        """"""
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.
        
        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        """"""
        self.prompts.append((prompt, echo))","class InteractiveQuery (object):
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name='', instructions='', *prompts):
    '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.
        
        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        pass

    def add_prompt(self, prompt, echo=True):
    '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.
        
        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        pass

",3,3,snippet_203,0.7142857142857143,"class InteractiveQuery(object):
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name='', instructions='', *prompts):
        '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.

        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        self.name = name
        self.instructions = instructions
        self.prompts = []
        for p in prompts:
            self.add_prompt(p)

    def add_prompt(self, prompt, echo=True):
        '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.

        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        self.prompts.append({'prompt': prompt, 'echo': bool(echo)})","class InteractiveQuery(object):
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name='', instructions='', *prompts):
        '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.
        
        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        self.name = name
        self.instructions = instructions
        self.prompts = []
        
        for prompt in prompts:
            self.add_prompt(prompt)

    def add_prompt(self, prompt, echo=True):
        '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.
        
        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        self.prompts.append((prompt, echo))","class InteractiveQuery (object):
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name='', instructions='', *prompts):
        '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.
        
        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        self.name = name
        self.instructions = instructions
        self.prompts = []
        for prompt in prompts:
            self.add_prompt(prompt)

    def add_prompt(self, prompt, echo=True):
        '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.
        
        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        self.prompts.append((prompt, echo))",full_docstr,0.9476744186046512,0.9239766081871345,0.9,0.941860465116279,0.7932995030790617,0.9505703422053232,0.8969465648854962,0.8544061302681992,0.9729719758033752,0.9563150405883789,0.9645715951919556,0.9579550623893738,0.8919763888888889,0.9560117302052785,0.9321533923303835,0.9139465875370919,0.9560117302052785,0.8007218224978951,0.97265625,0.9372549019607843,0.9015748031496063,0.9795529246330261,0.9587755799293518,0.9690529108047485,0.960813581943512,0.9351858333333333,0.9560117302052785,0.9321533923303835,0.9139465875370919,0.9560117302052785,0.8007218224978951,0.97265625,0.9372549019607843,0.9015748031496063,0.9787992835044861,0.9583374261856079,0.9684603214263916,0.9603449702262878,0.9351858333333333,0.7174041113580352,0.8302884349303497,0.8326613438351244,0.54,0.6666666666666666,0.7568773383320486,0.8342967299616284,0.836242926396869,0.66,0.696969696969697,0.7604153661516566,0.8418094231831181,0.8428823444538113,0.66,0.696969696969697
349342,doloopwhile/Python-CoffeeScript,doloopwhile_Python-CoffeeScript/coffeescript/__init__.py,coffeescript.Compiler,"class Compiler:
    '''Wrapper of execution of CoffeeScript compiler script'''
    def __init__(self, compiler_script, runtime):
        '''compiler_script is a CoffeeScript compiler script in JavaScript.
        runtime is a instance of execjs.Runtime.
        '''
        self._compiler_script = compiler_script
        self._runtime = runtime

    def compile(self, script, bare=False):
        '''compile a CoffeeScript code to a JavaScript code.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        if not hasattr(self, '_context'):
            self._context = self._runtime.compile(self._compiler_script)
        return self._context.call(
            ""CoffeeScript.compile"", script, {'bare': bare})

    def compile_file(self, filename, encoding=""utf-8"", bare=False):
        '''compile a CoffeeScript script file to a JavaScript code.

        filename can be a list or tuple of filenames,
        then contents of files are concatenated with line feeds.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        if isinstance(filename, _BaseString):
            filename = [filename]

        scripts = []
        for f in filename:
            with io.open(f, encoding=encoding) as fp:
                scripts.append(fp.read())

        return self.compile('\n\n'.join(scripts), bare=bare)","class Compiler:
    '''Wrapper of execution of CoffeeScript compiler script'''

    def __init__(self, compiler_script, runtime):
    '''compiler_script is a CoffeeScript compiler script in JavaScript.
        runtime is a instance of execjs.Runtime.
        '''
        pass

    def compile(self, script, bare=False):
    '''compile a CoffeeScript code to a JavaScript code.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        pass

    def compile_file(self, filename, encoding=""utf-8"", bare=False):
    '''compile a CoffeeScript script file to a JavaScript code.

        filename can be a list or tuple of filenames,
        then contents of files are concatenated with line feeds.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        pass

",4,4,snippet_592,0.3636363636363636,"class Compiler:
    '''Wrapper of execution of CoffeeScript compiler script'''

    def __init__(self, compiler_script, runtime):
        '''compiler_script is a CoffeeScript compiler script in JavaScript.
           runtime is a instance of execjs.Runtime.
        '''
        self.compiler_script = compiler_script
        self.runtime = runtime
        self._context = self.runtime.compile(self.compiler_script)

    def compile(self, script, bare=False):
        '''compile a CoffeeScript code to a JavaScript code.

           if bare is True, then compile the JavaScript without the top-level
           function safety wrapper (like the coffee command).
        '''
        return self._context.call('CoffeeScript.compile', script, {'bare': bare})

    def compile_file(self, filename, encoding=""utf-8"", bare=False):
        '''compile a CoffeeScript script file to a JavaScript code.

           filename can be a list or tuple of filenames,
           then contents of files are concatenated with line feeds.

           if bare is True, then compile the JavaScript without the top-level
           function safety wrapper (like the coffee command).
        '''
        if isinstance(filename, (list, tuple)):
            parts = []
            for fn in filename:
                with open(fn, 'r', encoding=encoding) as f:
                    parts.append(f.read())
            source = ""\n"".join(parts)
        else:
            with open(filename, 'r', encoding=encoding) as f:
                source = f.read()
        return self.compile(source, bare=bare)","class Compiler:
    '''Wrapper of execution of CoffeeScript compiler script'''

    def __init__(self, compiler_script, runtime):
        '''compiler_script is a CoffeeScript compiler script in JavaScript.
        runtime is a instance of execjs.Runtime.
        '''
        self.compiler_script = compiler_script
        self.runtime = runtime
        self.context = self.runtime.compile(compiler_script)

    def compile(self, script, bare=False):
        '''compile a CoffeeScript code to a JavaScript code.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        if bare:
            return self.context.call('CoffeeScript.compile', script, {'bare': True})
        else:
            return self.context.call('CoffeeScript.compile', script)

    def compile_file(self, filename, encoding=""utf-8"", bare=False):
        '''compile a CoffeeScript script file to a JavaScript code.

        filename can be a list or tuple of filenames,
        then contents of files are concatenated with line feeds.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        if isinstance(filename, (list, tuple)):
            script_content = []
            for fname in filename:
                with open(fname, 'r', encoding=encoding) as f:
                    script_content.append(f.read())
            script = '\n'.join(script_content)
        else:
            with open(filename, 'r', encoding=encoding) as f:
                script = f.read()
        
        return self.compile(script, bare)","class Compiler:
    '''Wrapper of execution of CoffeeScript compiler script'''

    def __init__(self, compiler_script, runtime):
        '''compiler_script is a CoffeeScript compiler script in JavaScript.
        runtime is a instance of execjs.Runtime.
        '''
        self.runtime = runtime
        self.context = runtime.compile(compiler_script)

    def compile(self, script, bare=False):
        '''compile a CoffeeScript code to a JavaScript code.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        options = {'bare': bare}
        return self.context.call('CoffeeScript.compile', script, options)

    def compile_file(self, filename, encoding=""utf-8"", bare=False):
        '''compile a CoffeeScript script file to a JavaScript code.

        filename can be a list or tuple of filenames,
        then contents of files are concatenated with line feeds.

        if bare is True, then compile the JavaScript without the top-level
        function safety wrapper (like the coffee command).
        '''
        if isinstance(filename, (list, tuple)):
            contents = []
            for fname in filename:
                with open(fname, 'r', encoding=encoding) as f:
                    contents.append(f.read())
            script = '\n'.join(contents)
        else:
            with open(filename, 'r', encoding=encoding) as f:
                script = f.read()
        
        return self.compile(script, bare=bare)",full_docstr,0.9056603773584906,0.8292682926829269,0.784741144414169,0.8355795148247978,0.7990412014199079,0.8921568627450981,0.7901639344262295,0.7236842105263158,0.9588501453399658,0.9587720632553101,0.9588111042976379,0.9587798714637756,0.8308224623115577,0.8848167539267017,0.7894736842105263,0.7354497354497356,0.8219895287958116,0.7366199429898759,0.8452012383900929,0.7298136645962733,0.6479750778816199,0.9516701102256775,0.9562263488769531,0.9539427161216736,0.9557687044143677,0.8325525352112676,0.8907103825136612,0.7857142857142856,0.7182320441988951,0.8087431693989071,0.7614363848180846,0.8873720136518771,0.773972602739726,0.6907216494845361,0.9521341323852539,0.953894853591919,0.9530136585235596,0.9537184834480286,0.8376527461139897,0.6715746045886835,0.7480182155018551,0.7853497999224756,0.5952380952380952,0.5576923076923077,0.6296376688535461,0.708043922380101,0.7766239691512996,0.4761904761904761,0.5576923076923077,0.6589160114660587,0.7256417871201282,0.7635021122239601,0.5119047619047619,0.6346153846153846
312293,cohorte/cohorte-herald,python/herald/remote/herald_jsonrpc.py,herald.remote.herald_jsonrpc._JsonRpcEndpointProxy,"class _JsonRpcEndpointProxy(object):
    """"""
    Proxy to use JSON-RPC over Herald
    """"""
    def __init__(self, name, peer, subject, send_method):
        """"""
        Sets up the endpoint proxy

        :param name: End point name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        """"""
        self.__name = name
        self.__peer = peer
        self.__subject = subject
        self.__send = send_method
        self.__cache = {}

    def __getattr__(self, name):
        """"""
        Prefixes the requested attribute name by the endpoint name
        """"""
        return self.__cache.setdefault(
            name, _JsonRpcMethod(""{0}.{1}"".format(self.__name, name),
                                 self.__peer, self.__subject, self.__send))","class _JsonRpcEndpointProxy(object):
    '''
    Proxy to use JSON-RPC over Herald
    '''

    def __init__(self, name, peer, subject, send_method):
    '''
        Sets up the endpoint proxy

        :param name: End point name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        pass

    def __getattr__(self, name):
    '''
        Prefixes the requested attribute name by the endpoint name
        '''
        pass

",3,3,snippet_528,1.0,"class _JsonRpcEndpointProxy(object):
    '''
    Proxy to use JSON-RPC over Herald
    '''

    def __init__(self, name, peer, subject, send_method):
        '''
        Sets up the endpoint proxy

        :param name: End point name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self._name = name
        self._peer = peer
        self._subject = subject
        self._send_method = send_method
        self._lock = threading.Lock()
        self._id_counter = 0

    def __getattr__(self, name):
        '''
        Prefixes the requested attribute name by the endpoint name
        '''
        method_name = f""{self._name}.{name}""

        def rpc_method(*args, **kwargs):
            with self._lock:
                self._id_counter += 1
                req_id = self._id_counter

            request = {
                ""jsonrpc"": ""2.0"",
                ""method"": method_name,
                ""id"": req_id
            }
            if args and kwargs:
                raise ValueError(""Cannot mix positional and keyword parameters in JSON-RPC call"")
            if args:
                request[""params""] = list(args)
            elif kwargs:
                request[""params""] = kwargs

            return self._send_method(self._peer, self._subject, request)

        setattr(self, name, rpc_method)
        return rpc_method","class _JsonRpcEndpointProxy(object):
    '''
    Proxy to use JSON-RPC over Herald
    '''

    def __init__(self, name, peer, subject, send_method):
        '''
        Sets up the endpoint proxy

        :param name: End point name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self._name = name
        self._peer = peer
        self._subject = subject
        self._send_method = send_method

    def __getattr__(self, name):
        '''
        Prefixes the requested attribute name by the endpoint name
        '''
        prefixed_name = '{}.{}'.format(self._name, name)
        return _JsonRpcMethodProxy(prefixed_name, self._peer, self._subject, self._send_method)","class _JsonRpcEndpointProxy(object):
    '''
    Proxy to use JSON-RPC over Herald
    '''

    def __init__(self, name, peer, subject, send_method):
        '''
        Sets up the endpoint proxy

        :param name: End point name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self.__name = name
        self.__peer = peer
        self.__subject = subject
        self.__send_method = send_method

    def __getattr__(self, name):
        '''
        Prefixes the requested attribute name by the endpoint name
        '''
        method_name = ""{0}.{1}"".format(self.__name, name)
        return lambda *args, **kwargs: self.__send_method(
            self.__peer, self.__subject, method_name, args, kwargs
        )",full_docstr,0.7121212121212122,0.6412213740458015,0.5923076923076923,0.6818181818181818,0.4941703101887588,0.6410256410256411,0.48231511254019294,0.3903225806451613,0.8264597058296204,0.9490512609481812,0.8835232257843018,0.9351794123649597,0.8045996551724139,0.9285714285714285,0.8865979381443299,0.8333333333333333,0.9183673469387756,0.6786398898481889,0.9217877094972067,0.8089887640449438,0.6949152542372882,0.9709131717681885,0.9623676538467407,0.9666215181350708,0.9632153511047363,0.9191927272727273,0.9207920792079209,0.87,0.8080808080808082,0.891089108910891,0.7605148127144,0.8939393939393939,0.7918781725888325,0.7346938775510204,0.946733832359314,0.9674743413925171,0.9569917321205139,0.965359628200531,0.8956239393939394,0.5978973222174064,0.3870693204931699,0.6241846025227973,0.5365853658536586,0.84375,0.6727496531714958,0.6150298175632443,0.6224626975617632,0.6097560975609756,0.84375,0.700059228924419,0.6554828484610805,0.6912479696756199,0.6097560975609756,0.84375
135511,JdeRobot/base,src/libs/comm_py/comm/ice/sonarIceClient.py,comm.ice.sonarIceClient.SonarIceClient,"class SonarIceClient:
    '''
        Sonar Ice Client. Recives LaserData from Ice interface running Sonar update method in a thread.
    '''
    def __init__(self,ic,prefix, start = False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.sonar = Sonar(ic,prefix)

        self.kill_event = threading.Event()
        self.thread = ThreadSensor(self.sonar, self.kill_event)
        self.thread.daemon = True

        if start:
            self.start()

    
    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.clear()
        self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.set()

    def getSonarData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        return self.sonar.getSonarData()

    def hasproxy (self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.sonar.hasproxy()","class SonarIceClient:
    '''
        Sonar Ice Client. Recives LaserData from Ice interface running Sonar update method in a thread.
    '''

    def __init__(self,ic,prefix, start = False):
    '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        pass

    def start(self):
    '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def stop(self):
    '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def getSonarData(self):
    '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        pass

    def hasproxy (self):
    '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        pass

",6,6,snippet_153,0.25,"class SonarIceClient:
    '''
        Sonar Ice Client. Recives LaserData from Ice interface running Sonar update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        self.ic = ic
        self.prefix = prefix
        self._sonarData = None
        self._running = False
        self._thread = threading.Thread(target=self._update_loop)
        self._thread.daemon = True

        props = ic.getProperties()
        proxy_str = props.getProperty(prefix + "".Proxy"")
        self.proxy = SonarPrx.checkedCast(ic.stringToProxy(proxy_str))
        if not self.proxy:
            raise RuntimeError(""Invalid proxy: "" + proxy_str)

        period_ms = props.getProperty(prefix + "".Period"", ""100"")
        try:
            self._period = float(period_ms) / 1000.0
        except:
            self._period = 0.1

        if start:
            self.start()

    def _update_loop(self):
        while self._running:
            try:
                self._sonarData = self.proxy.getSonarData()
            except Ice.Exception:
                pass
            time.sleep(self._period)

    def start(self):
        self._running = True
        self._thread.start()

    def stop(self):
        self._running = False
        self._thread.join()

    def getSonarData(self):
        return self._sonarData

    def hasproxy(self):
        return self.proxy is not None","class SonarIceClient:
    '''
        Sonar Ice Client. Recives LaserData from Ice interface running Sonar update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.sonarData = jderobot.SonarData()
        self.lock = threading.Lock()
        self.running = False
        self.proxy = None
        self.hasproxy_ = False
        
        # Get property values
        prop = self.ic.getProperties()
        proxy_str = prop.getProperty(prefix + "".Proxy"")
        
        if proxy_str:
            try:
                self.proxy = self.ic.stringToProxy(proxy_str)
                self.sonarProxy = jderobot.SonarPrx.checkedCast(self.proxy)
                if self.sonarProxy:
                    self.hasproxy_ = True
            except Exception as e:
                print(""Error creating proxy: "", e)
                self.hasproxy_ = False
        
        self.thread = None
        if start and self.hasproxy_:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if not self.running and self.hasproxy_:
            self.running = True
            self.thread = threading.Thread(target=self.updateSonar)
            self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if self.running:
            self.running = False
            if self.thread and self.thread.is_alive():
                self.thread.join()

    def getSonarData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        with self.lock:
            return self.sonarData

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.hasproxy_

    def updateSonar(self):
        '''
        Internal method to update sonar data in a thread
        '''
        while self.running:
            if self.sonarProxy:
                try:
                    data = self.sonarProxy.getSonarData()
                    with self.lock:
                        self.sonarData = data
                except Exception as e:
                    print(""Error getting sonar data: "", e)
            time.sleep(0.05)","class SonarIceClient:
    '''
        Sonar Ice Client. Recives LaserData from Ice interface running Sonar update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.proxy = None
        self.sonarData = None
        self.lock = threading.Lock()
        self.running = False
        self.thread = None
        
        try:
            proxyString = self.ic.getProperties().getProperty(self.prefix + "".Proxy"")
            if proxyString:
                self.proxy = self.ic.stringToProxy(proxyString)
        except:
            self.proxy = None
            
        if start:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if not self.running and self.proxy:
            self.running = True
            self.thread = threading.Thread(target=self._update_thread)
            self.thread.daemon = True
            self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.running = False
        if self.thread:
            self.thread.join()

    def getSonarData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        with self.lock:
            return self.sonarData

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.proxy is not None

    def _update_thread(self):
        while self.running:
            try:
                if self.proxy:
                    data = self.proxy.getSonarData()
                    with self.lock:
                        self.sonarData = data
            except:
                pass
            time.sleep(0.1)",full_docstr,0.4753086419753087,0.2919254658385093,0.2125,0.3827160493827161,0.36976424377120165,0.5475409836065573,0.34539473684210525,0.26732673267326734,0.8165150880813599,0.7952276468276978,0.8057307600975037,0.7973062992095947,0.8000020000000001,0.6623931623931624,0.575107296137339,0.5344827586206896,0.641025641025641,0.4744801450393573,0.5318725099601593,0.46706586826347307,0.43,0.8730673789978027,0.9386906623840332,0.9046905636787415,0.9316877126693726,0.7863496542553192,0.7338129496402876,0.6650602409638555,0.6246973365617433,0.7146282973621103,0.5818568225203901,0.6414634146341464,0.5721271393643031,0.5367647058823529,0.9018369913101196,0.9469026327133179,0.9238205552101135,0.942194402217865,0.8100018999999999,0.3287471201966233,0.1585376487620246,0.184524118076478,0.6527777777777778,0.3191489361702128,0.569637410322916,0.4636320031099866,0.800437732744325,0.6527777777777778,0.3617021276595745,0.6105725707039038,0.5710921009893897,0.8150516097222066,0.6944444444444444,0.3617021276595745
268430,bninja/pwho,bninja_pwho/pwho/__init__.py,pwho.StreamRequestMixin,"class StreamRequestMixin(object):
    """"""
    `SocketServer.StreamRequestHandler` mixin for adding PROXY protocol
    parsing, e.g.:

    .. code:: python

        import netaddr
        import pwho

        class MyRequestHandler(
                  SocketServer.StreamRequestHandler, pwho.StreamRequestMixin
              ):

            def proxy_authenticate(self, info):
                if not super(MyRequestHandler, self).proxy_authenticate(info):
                    return False
                destination_ip = netaddr.IPAddress(info.destination_address)
                return destination_ip in netaddr.IPNetwork('10/8')

            def handle(self)
                proxy_info = self.proxy_protocol(default='peer', authenticate=True)
                ...

    """"""

    def proxy_authenticate(self, info):
        """"""
        Authentication hook for parsed proxy information. Defaults to ensuring
        destination (i.e. proxy) is the peer.

        :param info: Parsed ``ProxyInfo`` instance.

        :returns: ``True`` if authenticated, otherwise ``False``.
        """"""
        return (info.destination_address, info.destination_port) == self.client_address

    def proxy_protocol(self, error='raise', default=None, limit=None, authenticate=False):
        """"""
        Parses, and optionally authenticates, proxy protocol information from
        request. Note that ``self.request`` is wrapped by ``SocketBuffer``.

        :param error:
            How read (``exc.ReadError``) and parse (``exc.ParseError``) errors
            are handled. One of:
            - ""raise"" to propagate.
            - ""unread"" to suppress exceptions and unread back to socket.
        :param default:
            What to return when no ``ProxyInfo`` was found. Only meaningful
            with error ""unread"".
        :param limit:
            Maximum number of bytes to read when probing request for
            ``ProxyInfo``.

        :returns: Parsed ``ProxyInfo`` instance or **default** if none found.
        """"""
        if error not in ('raise', 'unread'):
            raise ValueError('error=""{0}"" is not  ""raise"" or ""unread""""')
        if not isinstance(self.request, SocketBuffer):
            self.request = SocketBuffer(self.request)
        if default == 'peer':
            default = ProxyInfo(
                self.client_address[0], self.client_address[1],
                self.client_address[0], self.client_address[1],
            )
        try:
            line = read_line(
                self.request.sock,
                self.request.buf,
                limit=limit,
            )
        except exc.ReadError:
            if error == 'raise':
                raise
            return default
        try:
            info = parse_line(line)
        except exc.ParseError:
            if error == 'raise':
                raise
            self.request.unread(line)
            return default
        if authenticate and not self.proxy_authenticate(info):
            logger.info('authentication failed - %s', info)
            return default
        return info","class StreamRequestMixin(object):
    '''
    `SocketServer.StreamRequestHandler` mixin for adding PROXY protocol
    parsing, e.g.:

    .. code:: python

        import netaddr
        import pwho

        class MyRequestHandler(
                  SocketServer.StreamRequestHandler, pwho.StreamRequestMixin
              ):

            def proxy_authenticate(self, info):
                if not super(MyRequestHandler, self).proxy_authenticate(info):
                    return False
                destination_ip = netaddr.IPAddress(info.destination_address)
                return destination_ip in netaddr.IPNetwork('10/8')

            def handle(self)
                proxy_info = self.proxy_protocol(default='peer', authenticate=True)
                ...

    '''

            def proxy_authenticate(self, info):
    '''
        Authentication hook for parsed proxy information. Defaults to ensuring
        destination (i.e. proxy) is the peer.

        :param info: Parsed ``ProxyInfo`` instance.

        :returns: ``True`` if authenticated, otherwise ``False``.
        '''
                        pass

    def proxy_protocol(self, error='raise', default=None, limit=None, authenticate=False):
    '''
        Parses, and optionally authenticates, proxy protocol information from
        request. Note that ``self.request`` is wrapped by ``SocketBuffer``.

        :param error:
            How read (``exc.ReadError``) and parse (``exc.ParseError``) errors
            are handled. One of:
            - ""raise"" to propagate.
            - ""unread"" to suppress exceptions and unread back to socket.
        :param default:
            What to return when no ``ProxyInfo`` was found. Only meaningful
            with error ""unread"".
        :param limit:
            Maximum number of bytes to read when probing request for
            ``ProxyInfo``.

        :returns: Parsed ``ProxyInfo`` instance or **default** if none found.
        '''
        pass

",3,3,snippet_451,0.238095238095238,"class StreamRequestMixin(object):
    """"""
    `SocketServer.StreamRequestHandler` mixin for adding PROXY protocol
    parsing.
    """"""

    class ProxyInfo(object):
        __slots__ = (
            'command', 'family',
            'source_address', 'source_port',
            'destination_address', 'destination_port',
            'raw',
        )
        def __init__(self, command, family,
                     source_address, source_port,
                     destination_address, destination_port,
                     raw):
            self.command = command
            self.family = family
            self.source_address = source_address
            self.source_port = source_port
            self.destination_address = destination_address
            self.destination_port = destination_port
            self.raw = raw

    def proxy_authenticate(self, info):
        """"""
        Authentication hook for parsed proxy information.
        Defaults to ensuring destination (i.e. proxy) is the peer.
        """"""
        # default: require that the proxy's destination is the real peer
        peer_ip, peer_port = self.client_address[:2]
        return (
            info.destination_address == peer_ip and
            int(info.destination_port) == int(peer_port)
        )

    def proxy_protocol(self, error='raise', default=None,
                       limit=None, authenticate=False):
        """"""
        Parses, and optionally authenticates, PROXY protocol information
        from request. Note that `self.request` is wrapped by SocketBuffer.
        """"""
        ppv1_sig = b""PROXY ""
        ppv2_sig = b""\r\n\r\n\0\r\nQUIT\n""
        sock = self.request

        def _unread(data):
            # attempt to unread data if wrapper supports it
            if not data:
                return
            u = getattr(sock, 'unread', None)
            if callable(u):
                try:
                    u(data)
                except Exception:
                    pass

        try:
            # peek first 12 bytes to identify
            head = sock.recv(12, socket.MSG_PEEK)
            if not head:
                return default

            # PROXY v1
            if head.startswith(ppv1_sig):
                # read until CRLF, up to limit
                max_bytes = limit or 108
                buf = b''
                while b'\r\n' not in buf:
                    if len(buf) >= max_bytes:
                        raise ValueError(""PROXY v1 header too long"")
                    chunk = sock.recv(1)
                    if not chunk:
                        raise ValueError(""Unexpected EOF reading PROXY v1"")
                    buf += chunk
                line, _ = buf.split(b'\r\n', 1)
                parts = line.split()
                if len(parts) != 6:
                    raise ValueError(""Invalid PROXY v1 header"")
                # parts: [b'PROXY', fam, src, dst, sport, dport]
                fam = parts[1].decode('ascii', 'ignore')
                src = parts[2].decode('ascii', 'ignore')
                dst = parts[3].decode('ascii', 'ignore')
                sport = int(parts[4])
                dport = int(parts[5])
                info = StreamRequestMixin.ProxyInfo(
                    command='PROXY',
                    family=fam,
                    source_address=src,
                    source_port=sport,
                    destination_address=dst,
                    destination_port=dport,
                    raw=buf
                )

            # PROXY v2
            elif head.startswith(ppv2_sig):
                # need 16 bytes to read length
                hdr16 = sock.recv(16, socket.MSG_PEEK)
                if len(hdr16) < 16:
                    raise ValueError(""Incomplete PROXY v2 header"")
                ver_cmd = hdr16[12]
                fam_proto = hdr16[13]
                length = struct.unpack('!H', hdr16[14:16])[0]
                total = 16 + length
                # peek entire header
                hdr = sock.recv(total, socket.MSG_PEEK)
                if len(hdr) < total:
                    raise ValueError(""Incomplete PROXY v2 full header"")
                # now consume it
                buf = sock.recv(total)
                cmd = ver_cmd & 0x0F
                if (ver_cmd >> 4) != 0x2 or cmd not in (0x0, 0x1):
                    # invalid version or command
                    info = StreamRequestMixin.ProxyInfo(
                        command='LOCAL',
                        family=None,
                        source_address=None,
                        source_port=None,
                        destination_address=None,
                        destination_port=None,
                        raw=buf
                    )
                else:
                    command = 'PROXY' if cmd == 0x1 else 'LOCAL'
                    af = fam_proto & 0xF0
                    if af == 0x10 and length >= 12:
                        # IPv4
                        src = socket.inet_ntop(socket.AF_INET, buf[16:20])
                        dst = socket.inet_ntop(socket.AF_INET, buf[20:24])
                        sport, dport = struct.unpack('!HH', buf[24:28])
                        famstr = 'TCP4'
                    elif af == 0x20 and length >= 36:
                        # IPv6
                        src = socket.inet_ntop(socket.AF_INET6, buf[16:32])
                        dst = socket.inet_ntop(socket.AF_INET6, buf[32:48])
                        sport, dport = struct.unpack('!HH', buf[48:52])
                        famstr = 'TCP6'
                    else:
                        # unsupported family/proto
                        src = dst = None
                        sport = dport = None
                        famstr = None
                    info = StreamRequestMixin.ProxyInfo(
                        command=command,
                        family=famstr,
                        source_address=src,
                        source_port=sport,
                        destination_address=dst,
                        destination_port=dport,
                        raw=buf
                    )

            # no PROXY header
            else:
                return default

            # at this point, info is built
            if authenticate:
                ok = False
                try:
                    ok = self.proxy_authenticate(info)
                except Exception:
                    ok = False
                if not ok:
                    # undo and return default or raise
                    _unread(info.raw)
                    if error == 'raise':
                        raise RuntimeError(""PROXY authentication failed"")
                    return default

            return info

        except Exception as e:
            # on error, either raise or unread+return default
            if error == 'raise':
                raise
            # unread any bytes we consumed
            # hard to know exactly, so best effort skip
            # here we did no partial consume on peek,
            # but v1 reads into buf and consumed them
            # so unread buf if present
            try:
                _unread(buf)
            except NameError:
                pass
            return default","class StreamRequestMixin(object):
    '''
    `SocketServer.StreamRequestHandler` mixin for adding PROXY protocol
    parsing, e.g.:

    .. code:: python

        import netaddr
        import pwho

        class MyRequestHandler(
                  SocketServer.StreamRequestHandler, pwho.StreamRequestMixin
              ):

            def proxy_authenticate(self, info):
                if not super(MyRequestHandler, self).proxy_authenticate(info):
                    return False
                destination_ip = netaddr.IPAddress(info.destination_address)
                return destination_ip in netaddr.IPNetwork('10/8')

            def handle(self)
                proxy_info = self.proxy_protocol(default='peer', authenticate=True)
                ...

    '''

    def proxy_authenticate(self, info):
        '''
        Authentication hook for parsed proxy information. Defaults to ensuring
        destination (i.e. proxy) is the peer.

        :param info: Parsed ``ProxyInfo`` instance.

        :returns: ``True`` if authenticated, otherwise ``False``.
        '''
        return info.destination_address == info.peer_address

    def proxy_protocol(self, error='raise', default=None, limit=None, authenticate=False):
        '''
        Parses, and optionally authenticates, proxy protocol information from
        request. Note that ``self.request`` is wrapped by ``SocketBuffer``.

        :param error:
            How read (``exc.ReadError``) and parse (``exc.ParseError``) errors
            are handled. One of:
            - ""raise"" to propagate.
            - ""unread"" to suppress exceptions and unread back to socket.
        :param default:
            What to return when no ``ProxyInfo`` was found. Only meaningful
            with error ""unread"".
        :param limit:
            Maximum number of bytes to read when probing request for
            ``ProxyInfo``.

        :returns: Parsed ``ProxyInfo`` instance or **default** if none found.
        '''
        import pwho
        import pwho.exc as exc
        
        try:
            info = pwho.parse(self.request, limit=limit)
            if info is None:
                if error == 'unread':
                    return default
                else:
                    raise exc.ParseError(""No proxy protocol header found"")
            
            if authenticate and not self.proxy_authenticate(info):
                raise exc.AuthError(""Proxy authentication failed"")
                
            return info
            
        except (exc.ReadError, exc.ParseError) as e:
            if error == 'unread':
                # Unread the data back to socket buffer
                if hasattr(self.request, 'unread'):
                    self.request.unread(e.data or b'')
                return default
            else:
                raise
        except exc.AuthError:
            if error == 'unread':
                return default
            else:
                raise","class StreamRequestMixin(object):
    '''
    `SocketServer.StreamRequestHandler` mixin for adding PROXY protocol
    parsing, e.g.:

    .. code:: python

        import netaddr
        import pwho

        class MyRequestHandler(
                  SocketServer.StreamRequestHandler, pwho.StreamRequestMixin
              ):

            def proxy_authenticate(self, info):
                if not super(MyRequestHandler, self).proxy_authenticate(info):
                    return False
                destination_ip = netaddr.IPAddress(info.destination_address)
                return destination_ip in netaddr.IPNetwork('10/8')

            def handle(self)
                proxy_info = self.proxy_protocol(default='peer', authenticate=True)
                ...

    '''

    def proxy_authenticate(self, info):
        '''
        Authentication hook for parsed proxy information. Defaults to ensuring
        destination (i.e. proxy) is the peer.

        :param info: Parsed ``ProxyInfo`` instance.

        :returns: ``True`` if authenticated, otherwise ``False``.
        '''
        peer_address = self.client_address[0]
        return info.destination_address == peer_address

    def proxy_protocol(self, error='raise', default=None, limit=None, authenticate=False):
        '''
        Parses, and optionally authenticates, proxy protocol information from
        request. Note that ``self.request`` is wrapped by ``SocketBuffer``.

        :param error:
            How read (``exc.ReadError``) and parse (``exc.ParseError``) errors
            are handled. One of:
            - ""raise"" to propagate.
            - ""unread"" to suppress exceptions and unread back to socket.
        :param default:
            What to return when no ``ProxyInfo`` was found. Only meaningful
            with error ""unread"".
        :param limit:
            Maximum number of bytes to read when probing request for
            ``ProxyInfo``.

        :returns: Parsed ``ProxyInfo`` instance or **default** if none found.
        '''
        if not hasattr(self, '_socket_buffer'):
            self._socket_buffer = SocketBuffer(self.request)
            self.request = self._socket_buffer
        
        if limit is None:
            limit = 1024
        
        try:
            data = self.request.read(limit)
            if not data:
                if error == 'raise':
                    raise exc.ReadError(""No data received"")
                elif error == 'unread':
                    return default
            
            info = parse_proxy_protocol(data)
            
            if info is None:
                if error == 'raise':
                    raise exc.ParseError(""No proxy protocol found"")
                elif error == 'unread':
                    self.request.unread(data)
                    return default
            
            if authenticate and not self.proxy_authenticate(info):
                if error == 'raise':
                    raise exc.ParseError(""Proxy authentication failed"")
                elif error == 'unread':
                    self.request.unread(data)
                    return default
            
            remaining_data = data[info.consumed_bytes:]
            if remaining_data:
                self.request.unread(remaining_data)
            
            return info
            
        except (exc.ReadError, exc.ParseError) as e:
            if error == 'raise':
                raise
            elif error == 'unread':
                if 'data' in locals():
                    self.request.unread(data)
                return default",full_docstr,0.40280561122244485,0.1927710843373494,0.14688128772635817,0.2444889779559118,0.1944653693904649,0.34417129262490087,0.176984126984127,0.12073073868149325,0.7503771185874939,0.8443231582641602,0.7945828437805176,0.8338831067085266,0.7205237381203836,0.8442211055276382,0.7462184873949581,0.6812816188870152,0.7504187604690117,0.7111141511306,0.9034090909090909,0.8026565464895635,0.747148288973384,0.9510811567306519,0.9433810710906982,0.9472154378890991,0.9441454410552979,0.7801746120689659,0.8461538461538463,0.7160493827160493,0.6470588235294118,0.7415384615384615,0.7176620819381562,0.8242612752721618,0.6993769470404985,0.641185647425897,0.9357141256332397,0.9519490003585815,0.9437617659568787,0.9503002166748047,0.7703726666666669,0.3197282757722143,0.1048308733376924,0.2696574509901027,0.504424778761062,0.4,0.5596373695450451,0.6698926937843411,0.6819311206790248,0.4867256637168141,0.4,0.6237284777924855,0.6094459233490346,0.7068333481243207,0.5929203539823009,0.5857142857142857
3945,Alignak-monitoring/alignak,Alignak-monitoring_alignak/alignak/alignakobject.py,alignak.alignakobject.AlignakObject,"class AlignakObject(object):
    """"""This class provides a generic way to instantiate alignak objects.
    Attributes are serialized dynamically, whether we un-serialize
    them create them at run / parsing time

    """"""

    properties = {}
    macros = {}

    def __init__(self, params=None, parsing=True):  # pylint: disable=unused-argument
        """"""
        If parsing is True, then the objects are created from an initial configuration
        read by the Alignak arbiter else the objects are restored from a previously
        serialized instance sent by the arbiter to another daemon.

        This function checks the object uuid in the following manner:
        - in parsing mode, this function simply creates an object uuid
        - in non parsing mode, this function restore the object attributes from the provided params

        :param params: initialization parameters
        :type params: dict
        :param parsing: configuration parsing phase
        :type parsing: bool
        """"""
        if parsing:
            # Do not manage anything in the properties, it is the job of the Item __init__ function
            if not hasattr(self, 'uuid'):
                self.uuid = get_a_new_object_id()
            return

        # Fill the default if we are not parsing a configuration.
        # This will define some probable missing properties
        self.fill_default()

        if params is None:
            # Object is created without any parameters
            return

        if 'uuid' not in params:
            self.uuid = get_a_new_object_id()

        all_props = {}
        all_props.update(getattr(self, ""properties"", {}))
        all_props.update(getattr(self, ""running_properties"", {}))

        for key, value in params.items():
            setattr(self, key, value)

    # pylint: disable=unused-argument
    def serialize(self, no_json=True, printing=False):
        """"""This function serializes into a simple dictionary object.

        It is used when transferring data to other daemons over the network (http)

        Here is the generic function that simply export attributes declared in the
        properties dictionary of the object.

        :return: Dictionary containing key and value from properties
        :rtype: dict
        """"""
        # uuid is not in *_properties
        res = {
            'uuid': self.uuid
        }
        for prop in self.__class__.properties:
            if not hasattr(self, prop):
                continue

            res[prop] = getattr(self, prop)

        return res

    def fill_default(self):
        """"""
        Define the object properties with a default value when the property is not yet defined

        :return: None
        """"""
        for prop, entry in self.__class__.properties.items():
            if hasattr(self, prop):
                continue
            if not hasattr(entry, 'default'):
                continue
            if not entry.has_default:
                continue

            if hasattr(entry.default, '__iter__'):
                setattr(self, prop, copy(entry.default))
            else:
                setattr(self, prop, entry.default)","class AlignakObject(object):
    '''This class provides a generic way to instantiate alignak objects.
    Attributes are serialized dynamically, whether we un-serialize
    them create them at run / parsing time

    '''

    def __init__(self, params=None, parsing=True):
    '''
        If parsing is True, then the objects are created from an initial configuration
        read by the Alignak arbiter else the objects are restored from a previously
        serialized instance sent by the arbiter to another daemon.

        This function checks the object uuid in the following manner:
        - in parsing mode, this function simply creates an object uuid
        - in non parsing mode, this function restore the object attributes from the provided params

        :param params: initialization parameters
        :type params: dict
        :param parsing: configuration parsing phase
        :type parsing: bool
        '''
        pass

    def serialize(self, no_json=True, printing=False):
    '''This function serializes into a simple dictionary object.

        It is used when transferring data to other daemons over the network (http)

        Here is the generic function that simply export attributes declared in the
        properties dictionary of the object.

        :return: Dictionary containing key and value from properties
        :rtype: dict
        '''
        pass

    def fill_default(self):
    '''
        Define the object properties with a default value when the property is not yet defined

        :return: None
        '''
        pass

",4,4,snippet_20,0.3461538461538461,"class AlignakObject(object):
    '''This class provides a generic way to instantiate alignak objects.
    Attributes are serialized dynamically, whether we un-serialize
    them create them at run / parsing time
    '''

    def __init__(self, params=None, parsing=True):
        '''
            If parsing is True, then the objects are created from an initial configuration
            read by the Alignak arbiter else the objects are restored from a previously
            serialized instance sent by the arbiter to another daemon.

            This function checks the object uuid in the following manner:
            - in parsing mode, this function simply creates an object uuid
            - in non parsing mode, this function restore the object attributes from the provided params

            :param params: initialization parameters
            :type params: dict
            :param parsing: configuration parsing phase
            :type parsing: bool
        '''
        if parsing:
            self.uuid = str(uuid.uuid4())
        else:
            if not isinstance(params, dict):
                raise ValueError(""params must be a dict when parsing is False"")
            for key, value in params.items():
                setattr(self, key, value)
            if not hasattr(self, 'uuid'):
                self.uuid = str(uuid.uuid4())
        # Ensure a properties dict exists (can be overridden in subclasses)
        self.properties = getattr(self, 'properties', {})
        self.fill_default()

    def serialize(self, no_json=True, printing=False):
        '''This function serializes into a simple dictionary object.

            It is used when transferring data to other daemons over the network (http)

            Here is the generic function that simply export attributes declared in the
            properties dictionary of the object.

            :return: Dictionary containing key and value from properties
            :rtype: dict
        '''
        data = {}
        for prop in self.properties:
            if hasattr(self, prop):
                data[prop] = getattr(self, prop)
        data['uuid'] = self.uuid
        if printing:
            print(data)
        if no_json:
            return data
        return json.dumps(data)

    def fill_default(self):
        '''
            Define the object properties with a default value when the property is not yet defined

            :return: None
        '''
        for prop, default in self.properties.items():
            if not hasattr(self, prop):
                setattr(self, prop, default)","class AlignakObject(object):
    '''This class provides a generic way to instantiate alignak objects.
    Attributes are serialized dynamically, whether we un-serialize
    them create them at run / parsing time

    '''

    properties = {}

    def __init__(self, params=None, parsing=True):
        '''
        If parsing is True, then the objects are created from an initial configuration
        read by the Alignak arbiter else the objects are restored from a previously
        serialized instance sent by the arbiter to another daemon.

        This function checks the object uuid in the following manner:
        - in parsing mode, this function simply creates an object uuid
        - in non parsing mode, this function restore the object attributes from the provided params

        :param params: initialization parameters
        :type params: dict
        :param parsing: configuration parsing phase
        :type parsing: bool
        '''
        if params is None:
            params = {}
            
        if parsing:
            # Create a new UUID for parsing mode
            self.uuid = str(uuid.uuid4())
            # Set attributes from params
            for key, value in params.items():
                setattr(self, key, value)
            # Fill default values for missing properties
            self.fill_default()
        else:
            # Restore attributes from params in non-parsing mode
            for key, value in params.items():
                setattr(self, key, value)

    def serialize(self, no_json=True, printing=False):
        '''This function serializes into a simple dictionary object.

        It is used when transferring data to other daemons over the network (http)

        Here is the generic function that simply export attributes declared in the
        properties dictionary of the object.

        :return: Dictionary containing key and value from properties
        :rtype: dict
        '''
        result = {}
        # Serialize attributes that are declared in properties
        for prop_name in self.properties:
            if hasattr(self, prop_name):
                result[prop_name] = getattr(self, prop_name)
        
        # Always include uuid if it exists
        if hasattr(self, 'uuid'):
            result['uuid'] = self.uuid
            
        return result

    def fill_default(self):
        '''
        Define the object properties with a default value when the property is not yet defined

        :return: None
        '''
        for prop_name, prop_info in self.properties.items():
            if not hasattr(self, prop_name):
                # Get default value from property info, default to None if not specified
                default_value = prop_info.get('default', None)
                setattr(self, prop_name, default_value)","class AlignakObject(object):
    '''This class provides a generic way to instantiate alignak objects.
    Attributes are serialized dynamically, whether we un-serialize
    them create them at run / parsing time

    '''

    properties = {}
    
    def __init__(self, params=None, parsing=True):
        '''
        If parsing is True, then the objects are created from an initial configuration
        read by the Alignak arbiter else the objects are restored from a previously
        serialized instance sent by the arbiter to another daemon.

        This function checks the object uuid in the following manner:
        - in parsing mode, this function simply creates an object uuid
        - in non parsing mode, this function restore the object attributes from the provided params

        :param params: initialization parameters
        :type params: dict
        :param parsing: configuration parsing phase
        :type parsing: bool
        '''
        if params is None:
            params = {}
            
        if parsing:
            self.uuid = str(uuid.uuid4())
            for key, value in params.items():
                setattr(self, key, value)
        else:
            for key, value in params.items():
                setattr(self, key, value)
            if not hasattr(self, 'uuid'):
                self.uuid = str(uuid.uuid4())

    def serialize(self, no_json=True, printing=False):
        '''This function serializes into a simple dictionary object.

        It is used when transferring data to other daemons over the network (http)

        Here is the generic function that simply export attributes declared in the
        properties dictionary of the object.

        :return: Dictionary containing key and value from properties
        :rtype: dict
        '''
        result = {}
        
        # Always include uuid
        if hasattr(self, 'uuid'):
            result['uuid'] = self.uuid
            
        # Serialize properties defined in the properties dictionary
        for prop_name in getattr(self.__class__, 'properties', {}):
            if hasattr(self, prop_name):
                value = getattr(self, prop_name)
                result[prop_name] = value
                
        # Serialize any other attributes not in properties
        for attr_name in dir(self):
            if not attr_name.startswith('_') and attr_name != 'uuid':
                if attr_name not in getattr(self.__class__, 'properties', {}):
                    if not callable(getattr(self, attr_name)):
                        result[attr_name] = getattr(self, attr_name)
        
        if no_json:
            return result
        else:
            return json.dumps(result)

    def fill_default(self):
        '''
        Define the object properties with a default value when the property is not yet defined

        :return: None
        '''
        properties = getattr(self.__class__, 'properties', {})
        for prop_name, prop_config in properties.items():
            if not hasattr(self, prop_name):
                if isinstance(prop_config, dict) and 'default' in prop_config:
                    setattr(self, prop_name, prop_config['default'])
                elif isinstance(prop_config, tuple) and len(prop_config) > 1:
                    setattr(self, prop_name, prop_config[1])",full_docstr,0.8046989720998532,0.7010309278350515,0.6440177252584933,0.7195301027900147,0.5685270835508734,0.9041394335511983,0.7729257641921398,0.7024070021881839,0.9271306395530701,0.8893489837646484,0.9078468680381775,0.8929879665374756,0.7851357142857144,0.7944055944055944,0.6844319775596074,0.59915611814346,0.7216783216783217,0.5810526503234359,0.8654618473895582,0.704225352112676,0.6290322580645161,0.9258096218109131,0.8931029438972473,0.9091622829437256,0.8962693214416504,0.8060414285714286,0.7591623036649214,0.6535433070866141,0.5763157894736842,0.6596858638743456,0.6164263823618342,0.7574334898278561,0.5987460815047022,0.5164835164835165,0.9014139771461487,0.8992579579353333,0.9003346562385559,0.8994731307029724,0.773482928176796,0.4790568874743769,0.570033202302976,0.5810055134401804,0.5238095238095238,0.2413793103448276,0.5276532807869245,0.5869654984248012,0.5855758442865846,0.4897959183673469,0.4482758620689655,0.5042966408479829,0.5929662962659786,0.6010910154252724,0.4897959183673469,0.3333333333333333
312316,cohorte/cohorte-herald,python/herald/remote/herald_jabsorbrpc.py,herald.remote.herald_jabsorbrpc._JsonRpcMethod,"class _JsonRpcMethod(object):
    """"""
    Represents a method in a call proxy
    """"""
    def __init__(self, method_name, peer, subject, send_method):
        """"""
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        """"""
        self.__name = method_name
        self.__peer = peer
        self.__subject = subject
        self.__send = send_method

    def __call__(self, *args, **kwargs):
        """"""
        Method is being called
        """"""
        # Forge the request
        if args:
            args = [jabsorb.to_jabsorb(arg) for arg in args]
        elif kwargs:
            kwargs = {key: jabsorb.to_jabsorb(value)
                      for key, value in kwargs.items()}

        request = jsonrpclib.dumps(args or kwargs,
                                   self.__name, encoding='utf-8')

        # Send it
        reply_message = self.__send(self.__peer, self.__subject, request)

        # Parse the reply and check for errors
        result = jabsorb.from_jabsorb(jsonrpclib.loads(reply_message.content))
        jsonrpclib.jsonrpc.check_for_errors(result)
        return result['result']","class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
    '''
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        pass

    def __call__(self, *args, **kwargs):
    '''
        Method is being called
        '''
        pass

",3,3,snippet_533,0.6923076923076923,"class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
        '''
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self.method_name = method_name
        self.peer = peer
        self.subject = subject
        self.send_method = send_method

    def __call__(self, *args, **kwargs):
        '''
        Method is being called
        '''
        # Generate a unique request ID
        request_id = uuid.uuid4().hex

        # Build params according to JSON-RPC 2.0
        if args and not kwargs:
            params = list(args)
        elif kwargs and not args:
            params = kwargs
        elif args and kwargs:
            params = {
                ""args"": list(args),
                ""kwargs"": kwargs
            }
        else:
            params = []

        # Construct the request object
        request = {
            ""jsonrpc"": ""2.0"",
            ""id"": request_id,
            ""method"": self.method_name,
            ""params"": params
        }

        # Send the request and return the result
        return self.send_method(self.peer, self.subject, request)","class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
        '''
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self.method_name = method_name
        self.peer = peer
        self.subject = subject
        self.send_method = send_method

    def __call__(self, *args, **kwargs):
        '''
        Method is being called
        '''
        return self.send_method(self.method_name, self.peer, self.subject, *args, **kwargs)","class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
        '''
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self._method_name = method_name
        self._peer = peer
        self._subject = subject
        self._send_method = send_method

    def __call__(self, *args, **kwargs):
        '''
        Method is being called
        '''
        return self._send_method(self._peer, self._subject, self._method_name, *args, **kwargs)",full_docstr,0.686084142394822,0.5537459283387622,0.4918032786885246,0.627831715210356,0.511437325384672,0.7644927536231884,0.5163636363636364,0.4124087591240876,0.8895272612571716,0.8471646308898926,0.8678292632102966,0.8512185215950012,0.8106079545454545,0.721311475409836,0.6446280991735537,0.6083333333333334,0.6885245901639344,0.36000542386858825,0.9212121212121213,0.7804878048780488,0.6871165644171779,0.9616438746452332,0.7982096672058105,0.872337818145752,0.8120099902153015,0.8092504624277456,0.721311475409836,0.6446280991735537,0.6083333333333334,0.680327868852459,0.4063485045935657,0.9248554913294798,0.8255813953488372,0.7251461988304093,0.9618649482727051,0.7989578247070312,0.8728755116462708,0.8127225637435913,0.8092504624277456,0.437974763272913,0.3715293999152337,0.4392982246049897,0.5125,0.4285714285714285,0.372093693572521,0.3607703385715453,0.4010171341312369,0.425,0.3015873015873015,0.4117762332550606,0.3607703385715453,0.4010171341312369,0.425,0.4603174603174603
353146,druids/django-chamber,druids_django-chamber/chamber/commands/__init__.py,chamber.commands.ProgressBarStream,"class ProgressBarStream:
    """"""
    OutputStream wrapper to remove default linebreak at line endings.
    """"""

    def __init__(self, stream):
        """"""
        Wrap the given stream.
        """"""
        self.stream = stream

    def write(self, *args, **kwargs):
        """"""
        Call the stream's write method without linebreaks at line endings.
        """"""
        return self.stream.write(ending="""", *args, **kwargs)

    def flush(self):
        """"""
        Call the stream's flush method without any extra arguments.
        """"""
        return self.stream.flush()","class ProgressBarStream:
    '''
    OutputStream wrapper to remove default linebreak at line endings.
    '''

    def __init__(self, stream):
    '''
        Wrap the given stream.
        '''
        pass

    def write(self, *args, **kwargs):
    '''
        Call the stream's write method without linebreaks at line endings.
        '''
        pass

    def flush(self):
    '''
        Call the stream's flush method without any extra arguments.
        '''
        pass

",4,4,snippet_600,1.0,"class ProgressBarStream:
    '''
    OutputStream wrapper to remove default linebreak at line endings.
    '''

    def __init__(self, stream):
        '''
        Wrap the given stream.
        '''
        self._stream = stream

    def write(self, *args, **kwargs):
        '''
        Call the stream's write method without linebreaks at line endings.
        '''
        if not args:
            return
        data = args[0]
        if isinstance(data, str):
            data = data.rstrip('\n')
            args = (data,) + args[1:]
        return self._stream.write(*args, **kwargs)

    def flush(self):
        '''
        Call the stream's flush method without any extra arguments.
        '''
        return self._stream.flush()","class ProgressBarStream:
    '''
    OutputStream wrapper to remove default linebreak at line endings.
    '''

    def __init__(self, stream):
        '''
        Wrap the given stream.
        '''
        self.stream = stream

    def write(self, *args, **kwargs):
        '''
        Call the stream's write method without linebreaks at line endings.
        '''
        # Get the text to write
        if args:
            text = args[0]
            # Remove trailing newlines
            if isinstance(text, str) and text.endswith('\n'):
                text = text[:-1]
                args = (text,) + args[1:]
        return self.stream.write(*args, **kwargs)

    def flush(self):
        '''
        Call the stream's flush method without any extra arguments.
        '''
        return self.stream.flush()","class ProgressBarStream:
    '''
    OutputStream wrapper to remove default linebreak at line endings.
    '''

    def __init__(self, stream):
        '''
        Wrap the given stream.
        '''
        self.stream = stream

    def write(self, *args, **kwargs):
        '''
        Call the stream's write method without linebreaks at line endings.
        '''
        if args:
            text = args[0].rstrip('\n\r')
            return self.stream.write(text, *args[1:], **kwargs)
        return self.stream.write(*args, **kwargs)

    def flush(self):
        '''
        Call the stream's flush method without any extra arguments.
        '''
        return self.stream.flush()",full_docstr,0.8591549295774648,0.8285714285714285,0.7971014492753623,0.8591549295774648,0.5698196125579167,0.6666666666666666,0.5704697986577181,0.4864864864864865,0.8981181979179382,0.9644668102264404,0.93011075258255,0.957394003868103,0.8618632432432433,0.8079470198675496,0.7785234899328859,0.7482993197278912,0.8079470198675496,0.5513297535224049,0.6211180124223602,0.55,0.49056603773584906,0.868762195110321,0.9574763774871826,0.9109644889831543,0.9477978944778442,0.8518533333333332,0.8776978417266188,0.8467153284671532,0.8148148148148148,0.8776978417266188,0.6218372603718904,0.6944444444444444,0.6223776223776224,0.5563380281690141,0.9332358837127686,0.970573902130127,0.9515388011932373,0.9667060971260071,0.8793662857142858,0.6203732234022675,0.4436792887597635,0.5826164722328193,0.6774193548387096,0.7777777777777778,0.6589706589717295,0.4085279303920578,0.6054909062117058,0.6774193548387096,0.9444444444444444,0.6881585601162183,0.5252795349700132,0.6054909062117058,0.6774193548387096,0.9444444444444444
353940,dturanski/springcloudstream,dturanski_springcloudstream/springcloudstream/grpc/stream.py,springcloudstream.grpc.stream.BaseStreamComponent,"class BaseStreamComponent:
    """"""
    The Base class for Stream Components.
    """"""
    def __init__(self, handler_function, args=[]):
        """"""
        :param handler_function: The function to execute on each message
        :param args: command line options or list representing as sys.argv
        """"""
        opts = Options(args)
        opts.validate()
        self.options = opts.options
        self.handler_function = handler_function

    def start(self):
        """"""
        Start the server and run forever.
        """"""
        Server().start(self.options,self.handler_function, self.__class__.component_type)","class BaseStreamComponent:
    '''
    The Base class for Stream Components.
    '''

    def __init__(self, handler_function, args=[]):
    '''
        :param handler_function: The function to execute on each message
        :param args: command line options or list representing as sys.argv
        '''
        pass

    def start(self):
    '''
        Start the server and run forever.
        '''
        pass

",3,3,snippet_602,0.75,"class BaseStreamComponent:
    '''
    The Base class for Stream Components.
    '''

    def __init__(self, handler_function, args=None):
        '''
        :param handler_function: The function to execute on each message
        :param args: command line options or list representing as sys.argv
        '''
        self.handler_function = handler_function
        # if no args provided, take from sys.argv
        self.args = args if args is not None else sys.argv[1:]

    def start(self):
        '''
        Start the server and run forever.
        '''
        try:
            for line in sys.stdin:
                msg = line.rstrip('\n')
                # call handler with message and any args
                self.handler_function(msg, *self.args)
        except KeyboardInterrupt:
            pass","class BaseStreamComponent:
    '''
    The Base class for Stream Components.
    '''

    def __init__(self, handler_function, args=[]):
        '''
        :param handler_function: The function to execute on each message
        :param args: command line options or list representing as sys.argv
        '''
        self.handler_function = handler_function
        self.args = args

    def start(self):
        '''
        Start the server and run forever.
        '''
        raise NotImplementedError(""Subclasses must implement start() method"")","class BaseStreamComponent:
    '''
    The Base class for Stream Components.
    '''

    def __init__(self, handler_function, args=[]):
        '''
        :param handler_function: The function to execute on each message
        :param args: command line options or list representing as sys.argv
        '''
        self.handler_function = handler_function
        self.args = args
        self.running = False
        self.message_queue = Queue()
        self.worker_thread = None

    def start(self):
        '''
        Start the server and run forever.
        '''
        self.running = True
        self.worker_thread = threading.Thread(target=self._process_messages)
        self.worker_thread.daemon = True
        self.worker_thread.start()
        
        try:
            while self.running:
                time.sleep(0.1)
        except KeyboardInterrupt:
            self.stop()

    def stop(self):
        self.running = False
        if self.worker_thread:
            self.worker_thread.join()

    def _process_messages(self):
        while self.running:
            try:
                message = self.message_queue.get(timeout=0.1)
                if message is not None:
                    self.handler_function(message)
                self.message_queue.task_done()
            except Empty:
                continue

    def send_message(self, message):
        if self.running:
            self.message_queue.put(message)",full_docstr,0.6666666666666666,0.5766871165644172,0.5217391304347827,0.6424242424242425,0.5058087411777665,0.643312101910828,0.48717948717948717,0.4129032258064516,0.8389623165130615,0.9168854355812073,0.8761948347091675,0.9084477424621582,0.8243745161290323,0.8124999999999999,0.746031746031746,0.7096774193548386,0.7812499999999999,0.5033165660182127,0.8737864077669902,0.7352941176470589,0.6435643564356436,0.9281684756278992,0.9167210459709167,0.9224092364311218,0.9178529977798462,0.8691996202531646,0.5066666666666666,0.43946188340807174,0.4072398190045249,0.4888888888888889,0.3116734284082136,0.3929824561403509,0.3028169014084507,0.254416961130742,0.7716422080993652,0.9077102541923523,0.8341637849807739,0.8919814229011536,0.7599412385321099,0.4376084727119204,0.3570709142252199,0.565585198844684,0.2777777777777778,0.55,0.4269740523972598,0.5654585286873088,0.581326569790619,0.3611111111111111,0.2,0.4955959116060054,0.293573379948165,0.5832547109203009,0.5555555555555556,0.55
103591,Bouke/django-two-factor-auth,two_factor/admin.py,two_factor.admin.AdminSiteOTPRequiredMixin,"class AdminSiteOTPRequiredMixin:
    """"""
    Mixin for enforcing OTP verified staff users.

    Custom admin views should either be wrapped using :meth:`admin_view` or
    use :meth:`has_permission` in order to secure those views.
    """"""

    def has_permission(self, request):
        """"""
        Returns True if the given HttpRequest has permission to view
        *at least one* page in the admin site.
        """"""
        if not super().has_permission(request):
            return False
        return request.user.is_verified()

    def login(self, request, extra_context=None):
        """"""
        Redirects to the site login page for the given HttpRequest.
        """"""
        redirect_to = request.POST.get(REDIRECT_FIELD_NAME, request.GET.get(REDIRECT_FIELD_NAME))

        if not redirect_to or not url_has_allowed_host_and_scheme(url=redirect_to, allowed_hosts=[request.get_host()]):
            redirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)

        return redirect_to_login(redirect_to)","class AdminSiteOTPRequiredMixin:
    '''
    Mixin for enforcing OTP verified staff users.

    Custom admin views should either be wrapped using :meth:`admin_view` or
    use :meth:`has_permission` in order to secure those views.
    '''

    def has_permission(self, request):
    '''
        Returns True if the given HttpRequest has permission to view
        *at least one* page in the admin site.
        '''
        pass

    def login(self, request, extra_context=None):
    '''
        Redirects to the site login page for the given HttpRequest.
        '''
        pass

",3,3,snippet_46,0.25,"class AdminSiteOTPRequiredMixin:
    '''
    Mixin for enforcing OTP verified staff users.

    Custom admin views should either be wrapped using :meth:`admin_view` or
    use :meth:`has_permission` in order to secure those views.
    '''

    def has_permission(self, request):
        '''
        Returns True if the given HttpRequest has permission to view
        *at least one* page in the admin site.
        '''
        # first check the normal admin permissions
        has_basic = False
        try:
            has_basic = super().has_permission(request)
        except AttributeError:
            user = getattr(request, 'user', None)
            has_basic = bool(user and user.is_active and user.is_staff)
        if not has_basic:
            return False

        user = request.user
        # superusers bypass OTP
        if user.is_superuser:
            return True
        # must have at least one OTP device
        if not user_has_device(user):
            return False
        # must have completed OTP verification in this session
        is_verified = getattr(user, 'is_verified', None)
        if callable(is_verified):
            return is_verified()
        return False

    def login(self, request, extra_context=None):
        '''
        Redirects to the site login page for the given HttpRequest.
        '''
        extra_context = extra_context.copy() if extra_context else {}
        extra_context['otp_required'] = True
        return super().login(request, extra_context)","class AdminSiteOTPRequiredMixin:
    '''
    Mixin for enforcing OTP verified staff users.

    Custom admin views should either be wrapped using :meth:`admin_view` or
    use :meth:`has_permission` in order to secure those views.
    '''

    def has_permission(self, request):
        '''
        Returns True if the given HttpRequest has permission to view
        *at least one* page in the admin site.
        '''
        if not request.user.is_active or not request.user.is_staff:
            return False
        if hasattr(request.user, 'otp_device') and request.user.otp_device:
            return True
        return False

    def login(self, request, extra_context=None):
        '''
        Redirects to the site login page for the given HttpRequest.
        '''
        from django.shortcuts import redirect
        from django.urls import reverse
        
        return redirect(reverse('admin:login'))","class AdminSiteOTPRequiredMixin:
    '''
    Mixin for enforcing OTP verified staff users.

    Custom admin views should either be wrapped using :meth:`admin_view` or
    use :meth:`has_permission` in order to secure those views.
    '''

    def has_permission(self, request):
        '''
        Returns True if the given HttpRequest has permission to view
        *at least one* page in the admin site.
        '''
        from django_otp import user_has_device
        from django_otp.decorators import otp_required
        
        has_basic_permission = super().has_permission(request)
        if not has_basic_permission:
            return False
            
        if not request.user.is_authenticated:
            return False
            
        if not user_has_device(request.user):
            return False
            
        return request.user.is_verified()

    def login(self, request, extra_context=None):
        '''
        Redirects to the site login page for the given HttpRequest.
        '''
        from django.contrib.auth.views import redirect_to_login
        from django.urls import reverse
        from django_otp import user_has_device
        
        if request.user.is_authenticated and request.user.is_staff:
            if user_has_device(request.user) and not request.user.is_verified():
                return redirect_to_login(
                    request.get_full_path(),
                    reverse('two_factor:login')
                )
        
        return super().login(request, extra_context)",full_docstr,0.5841269841269842,0.49840255591054317,0.45016077170418006,0.5333333333333333,0.45473322747046535,0.6,0.42517006802721086,0.36860068259385664,0.8384606242179871,0.8446558713912964,0.841546893119812,0.8440322279930115,0.7425175449101801,0.728744939271255,0.6204081632653061,0.5761316872427983,0.6639676113360323,0.44756283657302415,0.8103448275862069,0.6358381502890174,0.5465116279069767,0.9192835688591003,0.8792767524719238,0.8988351821899414,0.8831201195716858,0.7777799999999999,0.6369426751592356,0.5512820512820513,0.503225806451613,0.6178343949044587,0.4901877371109399,0.6153846153846154,0.4697986577181208,0.4074074074074074,0.8547201156616211,0.8805203437805176,0.8674284219741821,0.8778703808784485,0.8112468674698795,0.5502926138658691,0.3552945106038273,0.6310611300448346,0.4,0.8148148148148148,0.504721012144286,0.5926423201797955,0.6343225364781567,0.2363636363636363,0.5555555555555556,0.5993116938922864,0.4763508420890311,0.6710642836484648,0.509090909090909,0.7407407407407407
312474,cokelaer/spectrum,cokelaer_spectrum/src/spectrum/datasets.py,spectrum.datasets.TimeSeries,"class TimeSeries(object):
    """"""A simple Base Class for various data sets.

    .. doctest::

        >>> from spectrum import TimeSeries
        >>> data = [1, 2, 3, 4, 3, 2, 1, 0 ]
        >>> ts = TimeSeries(data, sampling=1)
        >>> ts.plot()
        >>> ts.dt
        1.0

    """"""

    def __init__(self, data, sampling=1):
        """"""

        :param array data: input data (list or numpy.array)
        :param sampling: the sampling frequency of the data (default 1Hz)

        """"""
        self.data = data
        self.N = len(data)
        self.sampling = sampling
        self.dt = 1.0 / sampling

    def plot(self, **kargs):
        """"""Plot the data set, using the sampling information to set the x-axis
        correctly.""""""
        from pylab import grid, linspace, plot, xlabel, ylabel

        time = linspace(1 * self.dt, self.N * self.dt, self.N)
        plot(time, self.data, **kargs)
        xlabel(""Time"")
        ylabel(""Amplitude"")
        grid(True)","class TimeSeries(object):
    '''A simple Base Class for various data sets.

    .. doctest::

        >>> from spectrum import TimeSeries
        >>> data = [1, 2, 3, 4, 3, 2, 1, 0 ]
        >>> ts = TimeSeries(data, sampling=1)
        >>> ts.plot()
        >>> ts.dt
        1.0

    '''

    def __init__(self, data, sampling=1):
    '''

        :param array data: input data (list or numpy.array)
        :param sampling: the sampling frequency of the data (default 1Hz)

        '''
        pass

    def plot(self, **kargs):
    '''Plot the data set, using the sampling information to set the x-axis
        correctly.'''
        pass

",3,3,snippet_540,1.0,"class TimeSeries(object):
    '''A simple Base Class for various data sets.

    .. doctest::

        >>> from spectrum import TimeSeries
        >>> data = [1, 2, 3, 4, 3, 2, 1, 0 ]
        >>> ts = TimeSeries(data, sampling=1)
        >>> ts.plot()
        >>> ts.dt
        1.0

    '''

    def __init__(self, data, sampling=1):
        '''
        :param array data: input data (list or numpy.array)
        :param sampling: the sampling frequency of the data (default 1Hz)
        '''
        self.data = np.asarray(data, dtype=float)
        self.sampling = float(sampling)
        if self.sampling == 0:
            raise ValueError(""Sampling frequency must be non-zero"")
        self.dt = 1.0 / self.sampling
        self.t = np.arange(self.data.size) * self.dt

    def plot(self, **kargs):
        '''Plot the data set, using the sampling information to set the x-axis correctly.'''
        plt.figure()
        plt.plot(self.t, self.data, **kargs)
        plt.xlabel('Time [s]')
        plt.ylabel('Amplitude')
        plt.grid(True)
        plt.show()","class TimeSeries(object):
    '''A simple Base Class for various data sets.

    .. doctest::

        >>> from spectrum import TimeSeries
        >>> data = [1, 2, 3, 4, 3, 2, 1, 0 ]
        >>> ts = TimeSeries(data, sampling=1)
        >>> ts.plot()
        >>> ts.dt
        1.0

    '''

    def __init__(self, data, sampling=1):
        '''

        :param array data: input data (list or numpy.array)
        :param sampling: the sampling frequency of the data (default 1Hz)

        '''
        self.data = np.array(data)
        self.sampling = sampling
        self.dt = 1.0 / sampling

    def plot(self, **kargs):
        '''Plot the data set, using the sampling information to set the x-axis
        correctly.'''
        time = np.arange(len(self.data)) * self.dt
        plt.plot(time, self.data, **kargs)
        plt.xlabel('Time')
        plt.ylabel('Amplitude')
        plt.show()","class TimeSeries(object):
    '''A simple Base Class for various data sets.

    .. doctest::

        >>> from spectrum import TimeSeries
        >>> data = [1, 2, 3, 4, 3, 2, 1, 0 ]
        >>> ts = TimeSeries(data, sampling=1)
        >>> ts.plot()
        >>> ts.dt
        1.0

    '''

    def __init__(self, data, sampling=1):
        '''

        :param array data: input data (list or numpy.array)
        :param sampling: the sampling frequency of the data (default 1Hz)

        '''
        self.data = np.array(data)
        self.sampling = sampling
        self.dt = 1.0 / sampling

    def plot(self, **kargs):
        '''Plot the data set, using the sampling information to set the x-axis
        correctly.'''
        N = len(self.data)
        time_axis = np.arange(N) * self.dt
        plt.plot(time_axis, self.data, **kargs)
        plt.xlabel('Time')
        plt.ylabel('Amplitude')
        plt.show()",full_docstr,0.816793893129771,0.6923076923076923,0.6201550387596899,0.7786259541984734,0.6658598458910893,0.7677902621722846,0.6616541353383458,0.5811320754716981,0.9055846929550171,0.9336044788360596,0.9193811416625977,0.9307247996330261,0.8280271974522293,0.8823529411764707,0.8135593220338984,0.7606837606837608,0.865546218487395,0.7041705465976392,0.9004524886877828,0.8,0.7397260273972602,0.9587651491165161,0.9423597455024719,0.9504916667938232,0.9439749717712402,0.8956753435114503,0.8842975206611571,0.8,0.7394957983193277,0.8512396694214875,0.7117709165594321,0.8859649122807017,0.7797356828193832,0.7168141592920354,0.9567427635192871,0.9480793476104736,0.9523913860321045,0.9489386081695557,0.8956753435114503,0.5299928834375588,0.6036786763170201,0.6056867968271543,0.4333333333333333,0.4772727272727273,0.5832267132001155,0.6460276452856121,0.6520307226663652,0.4666666666666667,0.5681818181818182,0.582736008232325,0.6461380813004954,0.6499574667803193,0.4666666666666667,0.5681818181818182
262299,bindlock/vklancer,bindlock_vklancer/vklancer/api.py,vklancer.api.API,"class API(object):

    """"""Wrapper for vk.com API.""""""

    def __init__(self, token=None, version='5.49', **kwargs):
        """"""
        Override __init__.

        :param token (optional): `str` OAuth2 access token.
        :param version (optional): `str` API version.
        """"""
        self.__token = token
        self.__version = version
        self.__method = kwargs.get('method', '')

    def get_url(self, method=None, **kwargs):
        """"""Return url for call method.

        :param method (optional): `str` method name.
        :returns: `str` URL.
        """"""
        kwargs.setdefault('v', self.__version)

        if self.__token is not None:
            kwargs.setdefault('access_token', self.__token)

        return 'https://api.vk.com/method/{}?{}'.format(
            method or self.__method, urlencode(kwargs)
        )

    def request(self, method, **kwargs):
        """"""
        Send request to API.

        :param method: `str` method name.
        :returns: `dict` response.
        """"""
        kwargs.setdefault('v', self.__version)

        if self.__token is not None:
            kwargs.setdefault('access_token', self.__token)

        return requests.get(self.get_url(method, **kwargs)).json()

    def __getattr__(self, attr):
        """"""Override __getattr__.""""""
        method = ('{}.{}'.format(self.__method, attr)).lstrip('.')
        return API(self.__token, version=self.__version, method=method)

    def __call__(self, **kwargs):
        """"""Override __call__.""""""
        return self.request(self.__method, **kwargs)","class API(object):
    '''Wrapper for vk.com API.'''

    def __init__(self, token=None, version='5.49', **kwargs):
    '''
        Override __init__.

        :param token (optional): `str` OAuth2 access token.
        :param version (optional): `str` API version.
        '''
        pass

    def get_url(self, method=None, **kwargs):
    '''Return url for call method.

        :param method (optional): `str` method name.
        :returns: `str` URL.
        '''
        pass

    def request(self, method, **kwargs):
    '''
        Send request to API.

        :param method: `str` method name.
        :returns: `dict` response.
        '''
        pass

    def __getattr__(self, attr):
    '''Override __getattr__.'''
        pass

    def __call__(self, **kwargs):
    '''Override __call__.'''
        pass

",6,6,snippet_441,1.0,"class API(object):
    '''Wrapper for vk.com API.'''

    def __init__(self, token=None, version='5.49', **kwargs):
        """"""
        Override __init__.

        :param token (optional): `str` OAuth2 access token.
        :param version (optional): `str` API version.
        """"""
        self.token = token
        self.version = version
        self.base_url = 'https://api.vk.com/method'
        self._session = requests.Session()
        self._method = None

    def get_url(self, method=None, **kwargs):
        '''Return url for call method.

        :param method (optional): `str` method name.
        :returns: `str` URL.
        '''
        m = method or self._method or ''
        url = f""{self.base_url}/{m}""
        params = {}
        if self.token:
            params['access_token'] = self.token
        params['v'] = self.version
        params.update(kwargs)
        query = urlencode(params, doseq=True)
        return f""{url}?{query}""

    def request(self, method, **kwargs):
        '''
        Send request to API.

        :param method: `str` method name.
        :returns: `dict` response.
        '''
        url = self.get_url(method, **kwargs)
        resp = self._session.get(url)
        resp.raise_for_status()
        data = resp.json()
        if 'error' in data:
            err = data['error']
            code = err.get('error_code')
            msg = err.get('error_msg')
            raise Exception(f""VK API error {code}: {msg}"")
        return data.get('response', data)

    def __getattr__(self, attr):
        '''Override __getattr__.'''
        if attr.startswith('_'):
            raise AttributeError(attr)
        new = self.__class__(token=self.token, version=self.version)
        new._session = self._session
        if self._method:
            new._method = f""{self._method}.{attr}""
        else:
            new._method = attr
        return new

    def __call__(self, **kwargs):
        '''Override __call__.'''
        if not self._method:
            raise ValueError(""API method is not specified"")
        return self.request(self._method, **kwargs)","class API(object):
    '''Wrapper for vk.com API.'''

    def __init__(self, token=None, version='5.49', **kwargs):
        '''
        Override __init__.

        :param token (optional): `str` OAuth2 access token.
        :param version (optional): `str` API version.
        '''
        self.token = token
        self.version = version
        self.base_url = 'https://api.vk.com/method/'
        
    def get_url(self, method=None, **kwargs):
        '''Return url for call method.

        :param method (optional): `str` method name.
        :returns: `str` URL.
        '''
        params = kwargs.copy()
        if self.token:
            params['access_token'] = self.token
        params['v'] = self.version
        
        url = self.base_url + method
        if params:
            url += '?' + urlencode(params)
        return url
        
    def request(self, method, **kwargs):
        '''
        Send request to API.

        :param method: `str` method name.
        :returns: `dict` response.
        '''
        url = self.get_url(method, **kwargs)
        response = requests.get(url)
        return response.json()
        
    def __getattr__(self, attr):
        '''Override __getattr__.'''
        return APIMethod(self, attr)
        
    def __call__(self, **kwargs):
        '''Override __call__.'''
        pass","class API(object):
    '''Wrapper for vk.com API.'''

    def __init__(self, token=None, version='5.49', **kwargs):
        '''
        Override __init__.

        :param token (optional): `str` OAuth2 access token.
        :param version (optional): `str` API version.
        '''
        self.token = token
        self.version = version
        self.method_name = kwargs.get('method_name', '')
        self.base_url = 'https://api.vk.com/method/'

    def get_url(self, method=None, **kwargs):
        '''Return url for call method.

        :param method (optional): `str` method name.
        :returns: `str` URL.
        '''
        if method:
            return self.base_url + method
        elif self.method_name:
            return self.base_url + self.method_name
        else:
            return self.base_url

    def request(self, method, **kwargs):
        '''
        Send request to API.

        :param method: `str` method name.
        :returns: `dict` response.
        '''
        url = self.get_url(method)
        params = kwargs.copy()
        params['v'] = self.version
        if self.token:
            params['access_token'] = self.token
        
        response = requests.get(url, params=params)
        return response.json()

    def __getattr__(self, attr):
        '''Override __getattr__.'''
        method_name = self.method_name + '.' + attr if self.method_name else attr
        return API(token=self.token, version=self.version, method_name=method_name)

    def __call__(self, **kwargs):
        '''Override __call__.'''
        return self.request(self.method_name, **kwargs)",full_docstr,0.7383863080684596,0.5749385749385748,0.4938271604938271,0.5916870415647922,0.5585672959385929,0.726078799249531,0.5469924812030075,0.4387947269303202,0.8574786186218262,0.9123144745826721,0.8840470314025879,0.9065172672271729,0.7966686999999999,0.7845659163987138,0.6601941747572815,0.5928338762214984,0.7009646302250805,0.4867482781801585,0.8670886075949367,0.7238095238095238,0.6337579617834395,0.9340736865997314,0.9185315370559692,0.9262374043464661,0.9200623631477356,0.839648068181818,0.8146067415730338,0.6836158192090396,0.5965909090909091,0.747191011235955,0.5752106120438988,0.8190954773869347,0.6297229219143576,0.5303030303030303,0.9233320355415344,0.927715003490448,0.9255183339118958,0.927274763584137,0.8686881818181817,0.5742397100412774,0.3023563466452358,0.4691787647063145,0.5254237288135594,0.0,0.57206715507536,0.4088747218097996,0.4132922035763858,0.4661016949152542,0.0,0.580445975416054,0.3613584288438164,0.4180525914644672,0.5423728813559322,0.0
236849,aouyar/PyMunin,aouyar_PyMunin/pysysinfo/phpopc.py,pysysinfo.phpopc.OPCinfo,"class OPCinfo:
    """"""Class to retrieve stats from APC from Web Server.""""""

    def __init__(self, host=None, port=None, user=None, password=None,
                 monpath=None, ssl=False, extras=False, autoInit=True):
        """"""Initialize URL for APC stats access.
        
        @param host:     Web Server Host. (Default: 127.0.0.1)
        @param port:     Web Server Port. (Default: 80, SSL: 443)
        @param user:     Username. (Not needed unless authentication is required 
                         to access status page.
        @param password: Password. (Not needed unless authentication is required 
                         to access status page.
        @param monpath:  APC status script path relative to Document Root.
                         (Default: apcinfo.php)
        @param ssl:      Use SSL if True. (Default: False)
        @param extras:   Include extra metrics, which can be computationally more 
                         expensive.
        @param autoInit: If True connect to Web Server on instantiation.
            
        """"""
        if host is not None:
            self._host = host
        else:
            self._host = '127.0.0.1'
        if port is not None:
            self._port = int(port)
        else:
            if ssl:
                self._port = defaultHTTPSport
            else:
                self._port = defaultHTTPport
        self._user = user
        self._password = password
        if ssl:
            self._proto = 'https'
        else:
            self._proto = 'http'
        if monpath:
            self._monpath = monpath
        else:
            self._monpath = 'opcinfo.php'
        self._extras = extras
        self._statusDict = None
        if autoInit:
            self.initStats()

    def initStats(self, extras=None):
        """"""Query and parse Web Server Status Page.
        
        @param extras: Include extra metrics, which can be computationally more 
                       expensive.
        
        """"""
        url = ""%s://%s:%d/%s"" % (self._proto, self._host, self._port, self._monpath)
        response = util.get_url(url, self._user, self._password)
        #with open('/tmp/opcinfo.json') as f:
        #    response = f.read()
        self._statusDict = json.loads(response)
    
    def getAllStats(self):
        """"""Return All Stats for APC.
        
        @return: Nested dictionary of stats.
        
        """"""
        return self._statusDict;","class OPCinfo:
    '''Class to retrieve stats from APC from Web Server.'''

    def __init__(self, host=None, port=None, user=None, password=None,
                 monpath=None, ssl=False, extras=False, autoInit=True):
    '''Initialize URL for APC stats access.
        
        @param host:     Web Server Host. (Default: 127.0.0.1)
        @param port:     Web Server Port. (Default: 80, SSL: 443)
        @param user:     Username. (Not needed unless authentication is required 
                         to access status page.
        @param password: Password. (Not needed unless authentication is required 
                         to access status page.
        @param monpath:  APC status script path relative to Document Root.
                         (Default: apcinfo.php)
        @param ssl:      Use SSL if True. (Default: False)
        @param extras:   Include extra metrics, which can be computationally more 
                         expensive.
        @param autoInit: If True connect to Web Server on instantiation.
            
        '''
        pass

    def initStats(self, extras=None):
    '''Query and parse Web Server Status Page.
        
        @param extras: Include extra metrics, which can be computationally more 
                       expensive.
        
        '''
        pass

    def getAllStats(self):
    '''Return All Stats for APC.
        
        @return: Nested dictionary of stats.
        
        '''
        pass

",4,4,snippet_336,1.0,"class OPCinfo:
    '''Class to retrieve stats from APC from Web Server.'''

    def __init__(self, host=None, port=None, user=None, password=None,
                 monpath=None, ssl=False, extras=False, autoInit=True):
        '''Initialize URL for APC stats access.
        
        @param host:     Web Server Host. (Default: 127.0.0.1)
        @param port:     Web Server Port. (Default: 80, SSL: 443)
        @param user:     Username. (Not needed unless authentication is required 
                         to access status page.
        @param password: Password. (Not needed unless authentication is required 
                         to access status page.
        @param monpath:  APC status script path relative to Document Root.
                         (Default: apcinfo.php)
        @param ssl:      Use SSL if True. (Default: False)
        @param extras:   Include extra metrics, which can be computationally more 
                         expensive.
        @param autoInit: If True connect to Web Server on instantiation.
            
        '''
        self.host = host or '127.0.0.1'
        self.ssl = bool(ssl)
        if port is None:
            self.port = 443 if self.ssl else 80
        else:
            self.port = int(port)
        self.user = user
        self.password = password
        self.monpath = monpath or 'apcinfo.php'
        # ensure leading slash
        if not self.monpath.startswith('/'):
            self.monpath = '/' + self.monpath
        self.extras = bool(extras)
        self.stats = {}
        # build base URL
        scheme = 'https' if self.ssl else 'http'
        self.url = f""{scheme}://{self.host}:{self.port}{self.monpath}""
        if autoInit:
            self.initStats()

    def initStats(self, extras=None):
        '''Query and parse Web Server Status Page.
        
        @param extras: Include extra metrics, which can be computationally more 
                       expensive.
        
        '''
        if extras is not None:
            self.extras = bool(extras)
        headers = {}
        if self.user and self.password:
            auth = f""{self.user}:{self.password}""
            token = base64.b64encode(auth.encode('utf-8')).decode('ascii')
            headers['Authorization'] = f""Basic {token}""
        req = urllib.request.Request(self.url, headers=headers)
        ctx = None
        if self.ssl:
            ctx = _ssl._create_unverified_context()
        try:
            with urllib.request.urlopen(req, context=ctx) as resp:
                content = resp.read().decode('utf-8', errors='ignore')
        except urllib.error.URLError as e:
            raise RuntimeError(f""Failed to retrieve data: {e}"")
        self._parseStats(content)

    def getAllStats(self):
        '''Return All Stats for APC.
        
        @return: Nested dictionary of stats.
        
        '''
        return self.stats

    def _parseStats(self, html_text):
        # find the main table with id=""apcinfo""
        table_match = re.search(r'<table[^>]+id=[""\']?apcinfo[""\']?[^>]*>(.*?)</table>', html_text, re.S | re.I)
        target = table_match.group(1) if table_match else html_text
        rows = re.findall(r'<tr[^>]*>(.*?)</tr>', target, re.S | re.I)
        data = {}
        for row in rows:
            cols = re.findall(r'<t[dh][^>]*>(.*?)</t[dh]>', row, re.S | re.I)
            if len(cols) >= 2:
                key = html.unescape(re.sub(r'<[^>]+>', '', cols[0])).strip().rstrip(':')
                val = html.unescape(re.sub(r'<[^>]+>', '', cols[1])).strip()
                # optionally skip extras if flag is False (not implemented filtering here)
                data[key] = val
        self.stats = data","class OPCinfo:
    '''Class to retrieve stats from APC from Web Server.'''

    def __init__(self, host=None, port=None, user=None, password=None,
                 monpath=None, ssl=False, extras=False, autoInit=True):
        '''Initialize URL for APC stats access.
        
        @param host:     Web Server Host. (Default: 127.0.0.1)
        @param port:     Web Server Port. (Default: 80, SSL: 443)
        @param user:     Username. (Not needed unless authentication is required 
                         to access status page.
        @param password: Password. (Not needed unless authentication is required 
                         to access status page.
        @param monpath:  APC status script path relative to Document Root.
                         (Default: apcinfo.php)
        @param ssl:      Use SSL if True. (Default: False)
        @param extras:   Include extra metrics, which can be computationally more 
                         expensive.
        @param autoInit: If True connect to Web Server on instantiation.
            
        '''
        self.host = host or '127.0.0.1'
        self.port = port or (443 if ssl else 80)
        self.user = user
        self.password = password
        self.monpath = monpath or 'apcinfo.php'
        self.ssl = ssl
        self.extras = extras
        self.stats = {}
        
        protocol = 'https' if ssl else 'http'
        self.url = f""{protocol}://{self.host}:{self.port}/{self.monpath}""
        
        if autoInit:
            self.initStats()

    def initStats(self, extras=None):
        '''Query and parse Web Server Status Page.
        
        @param extras: Include extra metrics, which can be computationally more 
                       expensive.
        
        '''
        if extras is None:
            extras = self.extras
            
        try:
            # Create request
            request = urllib.request.Request(self.url)
            
            # Add authentication if provided
            if self.user and self.password:
                import base64
                credentials = f""{self.user}:{self.password}""
                encoded_credentials = base64.b64encode(credentials.encode('utf-8')).decode('utf-8')
                request.add_header('Authorization', f'Basic {encoded_credentials}')
            
            # Handle SSL context
            context = None
            if self.ssl:
                context = ssl.create_default_context()
                context.check_hostname = False
                context.verify_mode = ssl.CERT_NONE
            
            # Make request
            response = urllib.request.urlopen(request, context=context)
            content = response.read().decode('utf-8')
            
            # Parse content
            self.stats = self._parseStats(content, extras)
            
        except Exception as e:
            self.stats = {'error': str(e)}

    def _parseStats(self, content, extras):
        '''Parse the HTML content to extract APC stats.'''
        stats = {}
        
        # Simple parsing for common APC info patterns
        # Look for key: value patterns
        lines = content.split('\n')
        current_section = 'general'
        stats[current_section] = {}
        
        for line in lines:
            # Look for patterns like ""APC Version: 3.1.13""
            match = re.search(r'([^:]+):\s*(.+)', line)
            if match:
                key = match.group(1).strip()
                value = match.group(2).strip()
                stats[current_section][key] = value
            
            # Look for section headers
            if '<h2>' in line.lower() or '<h1>' in line.lower():
                section_match = re.search(r'<h[12]>([^<]+)', line, re.IGNORECASE)
                if section_match:
                    current_section = section_match.group(1).strip().lower().replace(' ', '_')
                    stats[current_section] = {}
        
        # Try to extract structured data if available
        # Look for table data
        table_parser = APCTableParser()
        table_parser.feed(content)
        if table_parser.data:
            for section, data in table_parser.data.items():
                if section not in stats:
                    stats[section] = {}
                stats[section].update(data)
        
        return stats

    def getAllStats(self):
        '''Return All Stats for APC.
        
        @return: Nested dictionary of stats.
        
        '''
        return self.stats","class OPCinfo:
    '''Class to retrieve stats from APC from Web Server.'''

    def __init__(self, host=None, port=None, user=None, password=None,
                 monpath=None, ssl=False, extras=False, autoInit=True):
        '''Initialize URL for APC stats access.
        
        @param host:     Web Server Host. (Default: 127.0.0.1)
        @param port:     Web Server Port. (Default: 80, SSL: 443)
        @param user:     Username. (Not needed unless authentication is required 
                         to access status page.
        @param password: Password. (Not needed unless authentication is required 
                         to access status page.
        @param monpath:  APC status script path relative to Document Root.
                         (Default: apcinfo.php)
        @param ssl:      Use SSL if True. (Default: False)
        @param extras:   Include extra metrics, which can be computationally more 
                         expensive.
        @param autoInit: If True connect to Web Server on instantiation.
            
        '''
        self._host = host or '127.0.0.1'
        self._ssl = ssl
        self._port = port or (443 if ssl else 80)
        self._user = user
        self._password = password
        self._monpath = monpath or 'apcinfo.php'
        self._extras = extras
        self._stats = {}
        
        if autoInit:
            self.initStats(extras)

    def initStats(self, extras=None):
        '''Query and parse Web Server Status Page.
        
        @param extras: Include extra metrics, which can be computationally more 
                       expensive.
        
        '''
        if extras is not None:
            self._extras = extras
            
        protocol = 'https' if self._ssl else 'http'
        url = f""{protocol}://{self._host}:{self._port}/{self._monpath}""
        
        if self._extras:
            url += ""?extras=1""
            
        request = urllib.request.Request(url)
        
        if self._user and self._password:
            credentials = base64.b64encode(f""{self._user}:{self._password}"".encode()).decode()
            request.add_header('Authorization', f'Basic {credentials}')
            
        try:
            if self._ssl:
                context = ssl.create_default_context()
                context.check_hostname = False
                context.verify_mode = ssl.CERT_NONE
                response = urllib.request.urlopen(request, context=context)
            else:
                response = urllib.request.urlopen(request)
                
            data = response.read().decode('utf-8')
            self._stats = json.loads(data)
            
        except (urllib.error.URLError, urllib.error.HTTPError, json.JSONDecodeError) as e:
            self._stats = {}

    def getAllStats(self):
        '''Return All Stats for APC.
        
        @return: Nested dictionary of stats.
        
        '''
        return self._stats",full_docstr,0.6854724964739068,0.5629420084865628,0.5134751773049645,0.5952045133991537,0.37654893190412325,0.4890929965556831,0.3620689655172414,0.30149597238204834,0.8152629733085632,0.9297348856925964,0.8687442541122437,0.9168611764907837,0.7703726666666671,0.6194926568758345,0.5113788487282463,0.46979865771812085,0.54739652870494,0.36396040928641854,0.481651376146789,0.3455797933409874,0.2896551724137931,0.815567135810852,0.9198394417762756,0.8645706176757812,0.9082274436950684,0.7641896859504141,0.8054607508532423,0.6575342465753424,0.6082474226804123,0.720136518771331,0.6042887914251212,0.7277486910994765,0.5909090909090909,0.5131348511383538,0.875293493270874,0.9273748397827148,0.9005817770957947,0.9218894839286804,0.7931055172413796,0.6589654602479829,0.4050884645776402,0.6206038848888674,0.6101694915254238,0.0,0.6360725325574954,0.351109817052644,0.6084345504654733,0.5847457627118644,0.0,0.6972137139180759,0.5654103911201974,0.6217495492978687,0.6016949152542372,0.0
400591,git-afsantos/bonsai,git-afsantos_bonsai/bonsai/model.py,bonsai.model.CodeStatementGroup,"class CodeStatementGroup(object):
    """"""This class is meant to provide common utility methods for
        objects that group multiple program statements together
        (e.g. functions, code blocks).

        It is not meant to be instantiated directly, only used for
        inheritance purposes.

        It defines the length of a statement group, and provides methods
        for integer-based indexing of program statements (as if using a list).
    """"""

    def statement(self, i):
        """"""Return the *i*-th statement from the object's `body`.""""""
        return self.body.statement(i)

    def statement_after(self, i):
        """"""Return the statement after the *i*-th one, or `None`.""""""
        try:
            return self.statement(i + 1)
        except IndexError as e:
            return None

    def __getitem__(self, i):
        """"""Return the *i*-th statement from the object's `body`.""""""
        return self.statement(i)

    def __len__(self):
        """"""Return the length of the statement group.""""""
        return len(self.body)","class CodeStatementGroup(object):
    '''This class is meant to provide common utility methods for
        objects that group multiple program statements together
        (e.g. functions, code blocks).

        It is not meant to be instantiated directly, only used for
        inheritance purposes.

        It defines the length of a statement group, and provides methods
        for integer-based indexing of program statements (as if using a list).
    '''

    def statement(self, i):
    '''Return the *i*-th statement from the object's `body`.'''
        pass

    def statement_after(self, i):
    '''Return the statement after the *i*-th one, or `None`.'''
        pass

    def __getitem__(self, i):
    '''Return the *i*-th statement from the object's `body`.'''
        pass

    def __len__(self):
    '''Return the length of the statement group.'''
        pass

",5,5,snippet_718,0.8571428571428571,"class CodeStatementGroup(object):
    '''This class is meant to provide common utility methods for
        objects that group multiple program statements together
        (e.g. functions, code blocks).

        It is not meant to be instantiated directly, only used for
        inheritance purposes.

        It defines the length of a statement group, and provides methods
        for integer-based indexing of program statements (as if using a list).
    '''

    def statement(self, i):
        '''Return the *i*-th statement from the object's `body`.'''
        return self.body[i]

    def statement_after(self, i):
        '''Return the statement after the *i*-th one, or `None`.'''
        try:
            return self.body[i + 1]
        except (IndexError, TypeError):
            return None

    def __getitem__(self, i):
        '''Return the *i*-th statement from the object's `body`.'''
        return self.statement(i)

    def __len__(self):
        '''Return the length of the statement group.'''
        return len(self.body)","class CodeStatementGroup(object):
    '''This class is meant to provide common utility methods for
        objects that group multiple program statements together
        (e.g. functions, code blocks).

        It is not meant to be instantiated directly, only used for
        inheritance purposes.

        It defines the length of a statement group, and provides methods
        for integer-based indexing of program statements (as if using a list).
    '''

    def statement(self, i):
        '''Return the *i*-th statement from the object's `body`.'''
        return self.body[i]

    def statement_after(self, i):
        '''Return the statement after the *i*-th one, or `None`.'''
        if i + 1 < len(self.body):
            return self.body[i + 1]
        return None

    def __getitem__(self, i):
        '''Return the *i*-th statement from the object's `body`.'''
        return self.body[i]

    def __len__(self):
        '''Return the length of the statement group.'''
        return len(self.body)","class CodeStatementGroup(object):
    '''This class is meant to provide common utility methods for
        objects that group multiple program statements together
        (e.g. functions, code blocks).

        It is not meant to be instantiated directly, only used for
        inheritance purposes.

        It defines the length of a statement group, and provides methods
        for integer-based indexing of program statements (as if using a list).
    '''

    def statement(self, i):
        '''Return the *i*-th statement from the object's `body`.'''
        return self.body[i]

    def statement_after(self, i):
        '''Return the statement after the *i*-th one, or `None`.'''
        if i + 1 < len(self.body):
            return self.body[i + 1]
        return None

    def __getitem__(self, i):
        '''Return the *i*-th statement from the object's `body`.'''
        return self.body[i]

    def __len__(self):
        '''Return the length of the statement group.'''
        return len(self.body)",full_docstr,0.9782608695652174,0.9562043795620438,0.9338235294117647,0.9782608695652174,0.7479859074182172,0.9205607476635514,0.8356807511737089,0.7735849056603774,0.9921417236328125,0.9890205264091492,0.9905786514282227,0.989331841468811,0.9722225,0.9424460431654677,0.9057971014492753,0.8686131386861314,0.9424460431654677,0.7195047738635919,0.880184331797235,0.7916666666666666,0.7255813953488373,0.9864569902420044,0.976653516292572,0.9815308451652527,0.9776251316070557,0.9097231250000001,0.9424460431654677,0.9057971014492753,0.8686131386861314,0.9424460431654677,0.7195047738635919,0.880184331797235,0.7916666666666666,0.7255813953488373,0.9864569902420044,0.976653516292572,0.9815308451652527,0.9776251316070557,0.9097231250000001,0.7181568123101512,0.7015614008301312,0.7100902386543759,0.5609756097560976,0.9,0.6767200185534529,0.6774069157720853,0.6904487681978236,0.4390243902439024,0.9,0.6767200185534529,0.6774069157720853,0.6904487681978236,0.4390243902439024,0.9
147485,LudovicRousseau/pyscard,LudovicRousseau_pyscard/src/smartcard/sw/ErrorCheckingChain.py,smartcard.sw.ErrorCheckingChain.ErrorCheckingChain,"class ErrorCheckingChain:
    """"""The error checking chain is a list of response apdu status word
    (sw1, sw2) error check strategies. Each strategy in the chain is
    called until an error is detected. A L{smartcard.sw.SWExceptions}
    exception is raised when an error is detected. No exception is
    raised if no error is detected.

    Implementation derived from Bruce Eckel, Thinking in Python. The
    L{ErrorCheckingChain} implements the Chain Of Responsibility design
    pattern.
    """"""

    def __init__(self, chain, strategy):
        """"""constructor. Appends a strategy to the L{ErrorCheckingChain}
        chain.""""""
        self.strategy = strategy
        self.chain = chain
        self.chain.append(self)
        self.excludes = []

    def next(self):
        """"""Returns next error checking strategy.""""""
        # Where this link is in the chain:
        location = self.chain.index(self)
        if not self.end():
            return self.chain[location + 1]

    def addFilterException(self, exClass):
        """"""Add an exception filter to the error checking chain.

        @param exClass:    the exception to exclude, e.g.
        L{smartcard.sw.SWExceptions.WarningProcessingException} A filtered
        exception will not be raised when the sw1,sw2 conditions that
        would raise the exception are met.
        """"""

        self.excludes.append(exClass)
        if self.end():
            return
        self.next().addFilterException(exClass)

    def end(self):
        """"""Returns True if this is the end of the error checking
        strategy chain.""""""
        return self.chain.index(self) + 1 >= len(self.chain)

    def __call__(self, data, sw1, sw2):
        """"""Called to test data, sw1 and sw2 for error on the chain.""""""
        try:
            self.strategy(data, sw1, sw2)
        except tuple(self.excludes) as exc:
            # The following additional filter may look redundant, it isn't.
            # It checks that type(exc) is *equal* to any of self.excludes,
            # rather than equal-or-subclass to any of self.excludes.
            # This maintains backward compatibility with the behaviour of
            # pyscard <= 1.6.16.
            # if exception is filtered, return
            for exception in self.excludes:
                if exception == exc_info()[0]:
                    return
            # otherwise reraise exception
            raise

        # if not done, call next strategy
        if self.end():
            return
        return self.next()(data, sw1, sw2)","class ErrorCheckingChain:
    '''The error checking chain is a list of response apdu status word
    (sw1, sw2) error check strategies. Each strategy in the chain is
    called until an error is detected. A L{smartcard.sw.SWExceptions}
    exception is raised when an error is detected. No exception is
    raised if no error is detected.

    Implementation derived from Bruce Eckel, Thinking in Python. The
    L{ErrorCheckingChain} implements the Chain Of Responsibility design
    pattern.
    '''

    def __init__(self, chain, strategy):
    '''constructor. Appends a strategy to the L{ErrorCheckingChain}
        chain.'''
        pass

    def next(self):
    '''Returns next error checking strategy.'''
        pass

    def addFilterException(self, exClass):
    '''Add an exception filter to the error checking chain.

        @param exClass:    the exception to exclude, e.g.
        L{smartcard.sw.SWExceptions.WarningProcessingException} A filtered
        exception will not be raised when the sw1,sw2 conditions that
        would raise the exception are met.
        '''
        pass

    def end(self):
    '''Returns True if this is the end of the error checking
        strategy chain.'''
        pass

    def __call__(self, data, sw1, sw2):
    '''Called to test data, sw1 and sw2 for error on the chain.'''
        pass

",6,6,snippet_178,0.5625,"class ErrorCheckingChain:
    '''The error checking chain is a list of response apdu status word
    (sw1, sw2) error check strategies. Each strategy in the chain is
    called until an error is detected. A L{smartcard.sw.SWExceptions}
    exception is raised when an error is detected. No exception is
    raised if no error is detected.

    Implementation derived from Bruce Eckel, Thinking in Python. The
    L{ErrorCheckingChain} implements the Chain Of Responsibility design
    pattern.
    '''

    def __init__(self, chain, strategy):
        '''constructor. Appends a strategy to the L{ErrorCheckingChain}
           chain.'''
        if chain is None:
            self._filters = []
        else:
            self._filters = chain._filters
        self._chain = chain
        self._strategy = strategy

    def next(self):
        '''Returns next error checking strategy.'''
        return self._chain

    def addFilterException(self, exClass):
        '''Add an exception filter to the error checking chain.

        @param exClass:    the exception to exclude, e.g.
        L{smartcard.sw.SWExceptions.WarningProcessingException} A filtered
        exception will not be raised when the sw1,sw2 conditions that
        would raise the exception are met.
        '''
        self._filters.append(exClass)

    def end(self):
        '''Returns True if this is the end of the error checking
        strategy chain.'''
        return self._chain is None

    def __call__(self, data, sw1, sw2):
        '''Called to test data, sw1 and sw2 for error on the chain.'''
        try:
            if self._strategy:
                self._strategy(data, sw1, sw2)
        except Exception as ex:
            for filt in self._filters:
                if isinstance(ex, filt):
                    if self._chain:
                        return self._chain(data, sw1, sw2)
                    return
            raise
        else:
            if self._chain:
                return self._chain(data, sw1, sw2)","class ErrorCheckingChain:
    '''The error checking chain is a list of response apdu status word
    (sw1, sw2) error check strategies. Each strategy in the chain is
    called until an error is detected. A L{smartcard.sw.SWExceptions}
    exception is raised when an error is detected. No exception is
    raised if no error is detected.

    Implementation derived from Bruce Eckel, Thinking in Python. The
    L{ErrorCheckingChain} implements the Chain Of Responsibility design
    pattern.
    '''

    def __init__(self, chain, strategy):
        '''constructor. Appends a strategy to the L{ErrorCheckingChain}
        chain.'''
        self.chain = chain
        self.strategy = strategy
        self.filterExceptions = []

    def next(self):
        '''Returns next error checking strategy.'''
        return self.chain

    def addFilterException(self, exClass):
        '''Add an exception filter to the error checking chain.

        @param exClass:    the exception to exclude, e.g.
        L{smartcard.sw.SWExceptions.WarningProcessingException} A filtered
        exception will not be raised when the sw1,sw2 conditions that
        would raise the exception are met.
        '''
        self.filterExceptions.append(exClass)

    def end(self):
        '''Returns True if this is the end of the error checking
        strategy chain.'''
        return self.chain is None

    def __call__(self, data, sw1, sw2):
        '''Called to test data, sw1 and sw2 for error on the chain.'''
        try:
            # Apply the current strategy
            self.strategy(data, sw1, sw2)
        except Exception as e:
            # Check if the exception is filtered
            for exClass in self.filterExceptions:
                if isinstance(e, exClass):
                    # If filtered, don't raise and continue to next chain
                    if not self.end():
                        return self.next()(data, sw1, sw2)
                    return
            # If not filtered, re-raise the exception
            raise
        
        # If no exception from current strategy, continue to next chain
        if not self.end():
            return self.next()(data, sw1, sw2)","class ErrorCheckingChain:
    '''The error checking chain is a list of response apdu status word
    (sw1, sw2) error check strategies. Each strategy in the chain is
    called until an error is detected. A L{smartcard.sw.SWExceptions}
    exception is raised when an error is detected. No exception is
    raised if no error is detected.

    Implementation derived from Bruce Eckel, Thinking in Python. The
    L{ErrorCheckingChain} implements the Chain Of Responsibility design
    pattern.
    '''

    def __init__(self, chain, strategy):
        '''constructor. Appends a strategy to the L{ErrorCheckingChain}
        chain.'''
        self.strategy = strategy
        self.chain = chain
        self.filteredExceptions = []

    def next(self):
        '''Returns next error checking strategy.'''
        return self.chain

    def addFilterException(self, exClass):
        '''Add an exception filter to the error checking chain.

        @param exClass:    the exception to exclude, e.g.
        L{smartcard.sw.SWExceptions.WarningProcessingException} A filtered
        exception will not be raised when the sw1,sw2 conditions that
        would raise the exception are met.
        '''
        self.filteredExceptions.append(exClass)

    def end(self):
        '''Returns True if this is the end of the error checking
        strategy chain.'''
        return self.chain is None

    def __call__(self, data, sw1, sw2):
        '''Called to test data, sw1 and sw2 for error on the chain.'''
        try:
            self.strategy(data, sw1, sw2)
        except Exception as e:
            filtered = False
            for exClass in self.filteredExceptions:
                if isinstance(e, exClass):
                    filtered = True
                    break
            if not filtered:
                raise
        
        if not self.end():
            self.next()(data, sw1, sw2)",full_docstr,0.8007117437722421,0.7071428571428571,0.6415770609318996,0.7402135231316725,0.5122790726742142,0.8743455497382199,0.7270341207349081,0.6368421052631579,0.9419269561767578,0.886569619178772,0.9134103655815125,0.8918108344078064,0.8275879310344827,0.8163265306122449,0.7133105802047781,0.6643835616438356,0.7346938775510203,0.5674799456456392,0.8822055137844611,0.7613065326633166,0.6876574307304786,0.9336017370223999,0.8904702663421631,0.911526083946228,0.8946032524108887,0.8505762068965517,0.7897623400365631,0.7339449541284403,0.6961325966850829,0.7714808043875686,0.49686232639125366,0.9244186046511628,0.8279883381924198,0.7602339181286549,0.941790759563446,0.8812753558158875,0.9105286598205566,0.8869746923446655,0.8548865086206896,0.4619104002346397,0.4674269885310603,0.502338506212808,0.4778761061946903,0.4,0.5696063409469082,0.5228140270064825,0.5395557109910111,0.6017699115044248,0.6142857142857143,0.5399705832564069,0.485788117440684,0.5220082484547287,0.5663716814159292,0.5857142857142857
268311,bmweiner/skillful,bmweiner_skillful/skillful/validate.py,skillful.validate.Valid,"class Valid(object):
    """"""Alexa request validator.

    Attributes:
        app_id: str. Skill application ID.
        url: str. SignatureCertChainUrl header value sent by request.
            PEM-encoded X.509 certificate chain that Alexa used to sign the
            message. Used to cache valid url.
        cert: cryptography.hazmat.backends.openssl.x509._Certificate. The Amazon
            signing certificate. Used to cache valid cert.
    """"""
    def __init__(self, app_id=None):
        """"""Init validator.""""""
        self.app_id = app_id
        self.url = None
        self.cert = None

    def application_id(self, app_id):
        """"""Validate request application id matches true application id.

        Verifying the Application ID matches: https://goo.gl/qAdqe4.

        Args:
            app_id: str. Request application_id.

        Returns:
            bool: True if valid, False otherwise.
        """"""
        if self.app_id != app_id:
            warnings.warn('Application ID is invalid.')
            return False
        return True

    def sender(self, body, stamp, url, sig):
        """"""Validate request is from Alexa.

        Verifying that the Request was Sent by Alexa: https://goo.gl/AcrzB5.
        Checking the Signature of the Request: https://goo.gl/FDkjBN.
        Checking the Timestamp of the Request: https://goo.gl/Z5JhqZ

        Args:
            body: str. HTTPS request body.
            stamp: str. Value of timestamp within request object of HTTPS
                request body.
            url: str. SignatureCertChainUrl header value sent
                by request.
            sig: str. Signature header value sent by request.

        Returns:
            bool: True if valid, False otherwise.
        """"""
        if not timestamp(stamp):
            return False

        if self.url != url:
            if not signature_cert_chain_url(url):
                return False

            certs = retrieve(url)
            if not certs:
                return False

            if not cert_chain(certs):
                return False

            self.url = url
            self.cert = certs[0]

        if not signature(self.cert, sig, body):
            return False

        return True

    def request(self, app_id=None, body=None, stamp=None, url=None, sig=None):
        """"""Validate application ID and request is from Alexa.""""""
        if self.app_id:
            if not self.application_id(app_id):
                return False

        if (url or sig):
            if not (body and stamp and url and sig):
                raise ValueError('Unable to validate sender, check arguments.')
            else:
                if not self.sender(body, stamp, url, sig):
                    return False

        return True","class Valid(object):
    '''Alexa request validator.

    Attributes:
        app_id: str. Skill application ID.
        url: str. SignatureCertChainUrl header value sent by request.
            PEM-encoded X.509 certificate chain that Alexa used to sign the
            message. Used to cache valid url.
        cert: cryptography.hazmat.backends.openssl.x509._Certificate. The Amazon
            signing certificate. Used to cache valid cert.
    '''

    def __init__(self, app_id=None):
    '''Init validator.'''
        pass

    def application_id(self, app_id):
    '''Validate request application id matches true application id.

        Verifying the Application ID matches: https://goo.gl/qAdqe4.

        Args:
            app_id: str. Request application_id.

        Returns:
            bool: True if valid, False otherwise.
        '''
        pass

    def sender(self, body, stamp, url, sig):
    '''Validate request is from Alexa.

        Verifying that the Request was Sent by Alexa: https://goo.gl/AcrzB5.
        Checking the Signature of the Request: https://goo.gl/FDkjBN.
        Checking the Timestamp of the Request: https://goo.gl/Z5JhqZ

        Args:
            body: str. HTTPS request body.
            stamp: str. Value of timestamp within request object of HTTPS
                request body.
            url: str. SignatureCertChainUrl header value sent
                by request.
            sig: str. Signature header value sent by request.

        Returns:
            bool: True if valid, False otherwise.
        '''
        pass

    def request(self, app_id=None, body=None, stamp=None, url=None, sig=None):
    '''Validate application ID and request is from Alexa.'''
        pass

",5,5,snippet_450,0.5428571428571428,"class Valid(object):
    '''Alexa request validator.

    Attributes:
        app_id: str. Skill application ID.
        url: str. SignatureCertChainUrl header value sent by request.
            PEM-encoded X.509 certificate chain that Alexa used to sign the
            message. Used to cache valid url.
        cert: cryptography.hazmat.backends.openssl.x509._Certificate. The Amazon
            signing certificate. Used to cache valid cert.
    '''

    def __init__(self, app_id=None):
        '''Init validator.'''
        self.app_id = app_id
        self.url = None
        self.cert = None

    def application_id(self, app_id):
        '''Validate request application id matches true application id.

        Verifying the Application ID matches: https://goo.gl/qAdqe4.

        Args:
            app_id: str. Request application_id.

        Returns:
            bool: True if valid, False otherwise.
        '''
        return bool(self.app_id and app_id == self.app_id)

    def _validate_timestamp(self, stamp):
        try:
            ts = datetime.fromisoformat(stamp.replace('Z', '+00:00'))
        except Exception:
            return False
        now = datetime.now(timezone.utc)
        diff = abs((now - ts).total_seconds())
        return diff <= 150

    def _validate_url(self, url):
        p = urlparse(url)
        if p.scheme != 'https':
            return False
        host = p.hostname or ''
        valid_hosts = (
            's3.amazonaws.com',
            's3.dualstack.us-east-1.amazonaws.com'
        )
        if host not in valid_hosts:
            return False
        if not p.path.startswith('/echo.api/'):
            return False
        return True

    def _fetch_cert(self, url):
        resp = requests.get(url)
        resp.raise_for_status()
        pem_data = resp.content
        certs = []
        for chunk in pem_data.split(b'-----END CERTIFICATE-----'):
            if b'-----BEGIN CERTIFICATE-----' in chunk:
                chunk = chunk + b'-----END CERTIFICATE-----'
                certs.append(x509.load_pem_x509_certificate(chunk))
        if not certs:
            raise ValueError('No certificates found')
        leaf = certs[0]
        # validity period
        now = datetime.now(timezone.utc)
        if leaf.not_valid_before > now or leaf.not_valid_after < now:
            raise ValueError('Certificate not valid now')
        # SAN check
        try:
            ext = leaf.extensions.get_extension_for_oid(
                ExtensionOID.SUBJECT_ALTERNATIVE_NAME
            )
            dns = ext.value.get_values_for_type(x509.DNSName)
        except x509.ExtensionNotFound:
            dns = []
        if 'echo-api.amazon.com' not in dns:
            raise ValueError('SAN mismatch')
        return leaf

    def sender(self, body, stamp, url, sig):
        '''Validate request is from Alexa.

        Verifying that the Request was Sent by Alexa: https://goo.gl/AcrzB5.
        Checking the Signature of the Request: https://goo.gl/FDkjBN.
        Checking the Timestamp of the Request: https://goo.gl/Z5JhqZ

        Args:
            body: str. HTTPS request body.
            stamp: str. Value of timestamp within request object of HTTPS
                request body.
            url: str. SignatureCertChainUrl header value sent
                by request.
            sig: str. Signature header value sent by request.

        Returns:
            bool: True if valid, False otherwise.
        '''
        if not all((body, stamp, url, sig)):
            return False
        if not self._validate_timestamp(stamp):
            return False
        if not self._validate_url(url):
            return False
        if url != self.url or self.cert is None:
            try:
                self.cert = self._fetch_cert(url)
                self.url = url
            except Exception:
                return False
        try:
            signature = base64.b64decode(sig)
            pub = self.cert.public_key()
            pub.verify(
                signature,
                body.encode('utf-8'),
                padding.PKCS1v15(),
                hashes.SHA1()
            )
            return True
        except Exception:
            return False

    def request(self, app_id=None, body=None, stamp=None, url=None, sig=None):
        '''Validate application ID and request is from Alexa.'''
        if not self.application_id(app_id):
            return False
        return self.sender(body, stamp, url, sig)","class Valid(object):
    '''Alexa request validator.

    Attributes:
        app_id: str. Skill application ID.
        url: str. SignatureCertChainUrl header value sent by request.
            PEM-encoded X.509 certificate chain that Alexa used to sign the
            message. Used to cache valid url.
        cert: cryptography.hazmat.backends.openssl.x509._Certificate. The Amazon
            signing certificate. Used to cache valid cert.
    '''

    def __init__(self, app_id=None):
        '''Init validator.'''
        self.app_id = app_id
        self.url = None
        self.cert = None

    def application_id(self, app_id):
        '''Validate request application id matches true application id.

        Verifying the Application ID matches: https://goo.gl/qAdqe4.

        Args:
            app_id: str. Request application_id.

        Returns:
            bool: True if valid, False otherwise.
        '''
        if self.app_id is None:
            return True
        return self.app_id == app_id

    def _validate_certificate_url(self, url):
        '''Validate the certificate URL.'''
        parsed_url = urlparse(url)
        if parsed_url.scheme != 'https':
            return False
        if parsed_url.hostname != 's3.amazonaws.com':
            return False
        if not parsed_url.path.startswith('/echo.api/'):
            return False
        if ':' in parsed_url.netloc and not parsed_url.netloc.endswith(':443'):
            return False
        return True

    def _get_certificate(self, url):
        '''Get and cache the certificate.'''
        if self.url == url and self.cert is not None:
            return self.cert
        
        if not self._validate_certificate_url(url):
            return None
            
        try:
            response = requests.get(url, timeout=10)
            if response.status_code != 200:
                return None
                
            cert_data = response.content
            cert = x509.load_pem_x509_certificate(cert_data, default_backend())
            
            # Validate certificate
            if cert.not_valid_after < datetime.utcnow():
                return None
                
            # Check subject alt names
            try:
                ext = cert.extensions.get_extension_for_oid(x509.OID_SUBJECT_ALTERNATIVE_NAME)
                san = ext.value
                if 'echo-api.amazon.com' not in [name.value for name in san.get_values_for_type(x509.DNSName)]:
                    return None
            except x509.ExtensionNotFound:
                return None
            
            self.url = url
            self.cert = cert
            return cert
        except Exception:
            return None

    def _validate_signature(self, cert, signature, body):
        '''Validate the request signature.'''
        try:
            decoded_signature = base64.b64decode(signature)
            public_key = cert.public_key()
            public_key.verify(decoded_signature, body.encode('utf-8'), hashes.SHA1())
            return True
        except (InvalidSignature, ValueError, Exception):
            return False

    def _validate_timestamp(self, timestamp):
        '''Validate the request timestamp.'''
        try:
            request_time = datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%SZ')
            current_time = datetime.utcnow()
            time_diff = abs((current_time - request_time).total_seconds())
            return time_diff <= 150  # 150 seconds = 2.5 minutes
        except ValueError:
            return False

    def sender(self, body, stamp, url, sig):
        '''Validate request is from Alexa.

        Verifying that the Request was Sent by Alexa: https://goo.gl/AcrzB5.
        Checking the Signature of the Request: https://goo.gl/FDkjBN.
        Checking the Timestamp of the Request: https://goo.gl/Z5JhqZ

        Args:
            body: str. HTTPS request body.
            stamp: str. Value of timestamp within request object of HTTPS
                request body.
            url: str. SignatureCertChainUrl header value sent
                by request.
            sig: str. Signature header value sent by request.

        Returns:
            bool: True if valid, False otherwise.
        '''
        # Validate timestamp
        if not self._validate_timestamp(stamp):
            return False
            
        # Get and validate certificate
        cert = self._get_certificate(url)
        if cert is None:
            return False
            
        # Validate signature
        if not self._validate_signature(cert, sig, body):
            return False
            
        return True

    def request(self, app_id=None, body=None, stamp=None, url=None, sig=None):
        '''Validate application ID and request is from Alexa.'''
        # Validate application ID
        if app_id is not None and not self.application_id(app_id):
            return False
            
        # Validate sender
        if body is not None and stamp is not None and url is not None and sig is not None:
            if not self.sender(body, stamp, url, sig):
                return False
        elif body is not None or stamp is not None or url is not None or sig is not None:
            # If any sender validation parameters are provided, all must be provided
            return False
            
        return True","class Valid(object):
    '''Alexa request validator.

    Attributes:
        app_id: str. Skill application ID.
        url: str. SignatureCertChainUrl header value sent by request.
            PEM-encoded X.509 certificate chain that Alexa used to sign the
            message. Used to cache valid url.
        cert: cryptography.hazmat.backends.openssl.x509._Certificate. The Amazon
            signing certificate. Used to cache valid cert.
    '''

    def __init__(self, app_id=None):
        '''Init validator.'''
        self.app_id = app_id
        self.url = None
        self.cert = None

    def application_id(self, app_id):
        '''Validate request application id matches true application id.

        Verifying the Application ID matches: https://goo.gl/qAdqe4.

        Args:
            app_id: str. Request application_id.

        Returns:
            bool: True if valid, False otherwise.
        '''
        if self.app_id is None:
            return True
        return self.app_id == app_id

    def sender(self, body, stamp, url, sig):
        '''Validate request is from Alexa.

        Verifying that the Request was Sent by Alexa: https://goo.gl/AcrzB5.
        Checking the Signature of the Request: https://goo.gl/FDkjBN.
        Checking the Timestamp of the Request: https://goo.gl/Z5JhqZ

        Args:
            body: str. HTTPS request body.
            stamp: str. Value of timestamp within request object of HTTPS
                request body.
            url: str. SignatureCertChainUrl header value sent
                by request.
            sig: str. Signature header value sent by request.

        Returns:
            bool: True if valid, False otherwise.
        '''
        try:
            # Check timestamp
            timestamp = datetime.datetime.fromisoformat(stamp.replace('Z', '+00:00'))
            now = datetime.datetime.now(datetime.timezone.utc)
            if abs((now - timestamp).total_seconds()) > 150:
                return False

            # Validate certificate URL
            if not self._validate_cert_url(url):
                return False

            # Get certificate
            cert = self._get_cert(url)
            if not cert:
                return False

            # Validate certificate
            if not self._validate_cert(cert):
                return False

            # Verify signature
            signature = base64.b64decode(sig)
            public_key = cert.public_key()
            public_key.verify(
                signature,
                body.encode('utf-8'),
                padding.PKCS1v15(),
                hashes.SHA1()
            )
            return True

        except Exception:
            return False

    def request(self, app_id=None, body=None, stamp=None, url=None, sig=None):
        '''Validate application ID and request is from Alexa.'''
        if app_id is not None and not self.application_id(app_id):
            return False
        if body is not None and stamp is not None and url is not None and sig is not None:
            return self.sender(body, stamp, url, sig)
        return True

    def _validate_cert_url(self, url):
        if not url.startswith('https://s3.amazonaws.com/echo.api/'):
            return False
        if '/..' in url or url.count('//') > 1:
            return False
        return True

    def _get_cert(self, url):
        if self.url == url and self.cert:
            return self.cert
        
        try:
            with urllib.request.urlopen(url) as response:
                cert_data = response.read()
            cert = x509.load_pem_x509_certificate(cert_data, default_backend())
            self.url = url
            self.cert = cert
            return cert
        except Exception:
            return None

    def _validate_cert(self, cert):
        try:
            # Check if certificate is valid (not expired)
            now = datetime.datetime.now(datetime.timezone.utc)
            if cert.not_valid_after.replace(tzinfo=datetime.timezone.utc) < now:
                return False
            if cert.not_valid_before.replace(tzinfo=datetime.timezone.utc) > now:
                return False

            # Check subject alternative names
            try:
                san_ext = cert.extensions.get_extension_for_oid(x509.oid.ExtensionOID.SUBJECT_ALTERNATIVE_NAME)
                dns_names = san_ext.value.get_values_for_type(x509.DNSName)
                if 'echo-api.amazon.com' not in dns_names:
                    return False
            except x509.ExtensionNotFound:
                return False

            return True
        except Exception:
            return False",full_docstr,0.7374562427071178,0.6385964912280702,0.5767878077373975,0.6231038506417736,0.49905209811958035,0.5665188470066519,0.4961154273029967,0.44222222222222224,0.8312761187553406,0.9373281598091125,0.8811224699020386,0.925520658493042,0.7550083392226151,0.6590436590436589,0.6,0.5407098121085595,0.5883575883575884,0.4368035570458272,0.49279538904899134,0.43173076923076925,0.3917228103946102,0.8515937328338623,0.9563801288604736,0.9009503722190857,0.9447552561759949,0.7644767790893767,0.7146118721461188,0.6361556064073226,0.5779816513761468,0.6438356164383562,0.480442530409556,0.5442764578833693,0.47783783783783784,0.4264069264069264,0.8529891967773438,0.9594451785087585,0.90309077501297,0.9476186037063599,0.7742950000000003,0.6540014304424828,0.462202289849006,0.6868180038699238,0.6475409836065574,0.8194444444444444,0.6326992996348433,0.3947800321488869,0.7270918476291021,0.6311475409836066,0.7777777777777778,0.657149824087174,0.4571838750994369,0.6948671516682027,0.5737704918032787,0.9027777777777778
239487,apache/incubator-mxnet,apache_incubator-mxnet/python/mxnet/kvstore/kvstore_server.py,mxnet.kvstore.kvstore_server.KVStoreServer,"class KVStoreServer(object):
    """"""The key-value store server.""""""
    def __init__(self, kvstore):
        """"""Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        """"""
        self.kvstore = kvstore
        self.handle = kvstore.handle
        self.init_logginig = False

    def _controller(self):
        """"""Return the server controller.""""""
        def server_controller(cmd_id, cmd_body, _):
            """"""Server controler.""""""
            if not self.init_logginig:
                # the reason put the codes here is because we cannot get
                # kvstore.rank earlier
                head = '%(asctime)-15s Server[' + str(
                    self.kvstore.rank) + '] %(message)s'
                logging.basicConfig(level=logging.DEBUG, format=head)
                self.init_logginig = True

            if cmd_id == 0:
                try:
                    optimizer = pickle.loads(cmd_body)
                except:
                    raise
                self.kvstore.set_optimizer(optimizer)
            else:
                print(f""server {self.kvstore.rank}, unknown command ({cmd_id}, {cmd_body})"")
        return server_controller

    def run(self):
        """"""Run the server, whose behavior is like.


        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        """"""
        _ctrl_proto = ctypes.CFUNCTYPE(None, ctypes.c_int, ctypes.c_char_p, ctypes.c_void_p)
        check_call(_LIB.MXKVStoreRunServer(self.handle, _ctrl_proto(self._controller()), None))","class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
    '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        pass

    def _controller(self):
    '''Return the server controller.'''
        pass

        def server_controller(cmd_id, cmd_body, _):
    '''Server controler.'''
                pass

    def run(self):
    '''Run the server, whose behavior is like.


        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        pass

",5,5,snippet_343,0.3333333333333333,"class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
        '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        self.kvstore = kvstore
        self.controller = self._controller()

    def _controller(self):
        '''Return the server controller.'''
        def server_controller(cmd_id, cmd_body, _):
            action = cmd_body.get('action')
            if action == 'GET':
                key = cmd_body.get('key')
                value = self.kvstore.get(key)
                return {'cmd_id': cmd_id, 'value': value}
            elif action == 'PUT':
                key = cmd_body.get('key')
                value = cmd_body.get('value')
                self.kvstore.put(key, value)
                return {'cmd_id': cmd_id, 'status': 'OK'}
            elif action == 'DELETE':
                key = cmd_body.get('key')
                self.kvstore.delete(key)
                return {'cmd_id': cmd_id, 'status': 'OK'}
            else:
                return {'cmd_id': cmd_id, 'error': 'UNKNOWN_ACTION'}
        return server_controller

    def run(self):
        '''Run the server, whose behavior is like.

        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        while True:
            msg = self.receive()
            if msg is None:
                break
            if self.is_command(msg):
                cmd_id, cmd_body, ctx = msg
                response = self.controller(cmd_id, cmd_body, ctx)
                if response is not None:
                    self.send(response)
            else:
                key, value = msg
                self.kvstore.put(key, value)","class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
        '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        self.kvstore = kvstore
        self.running = False

    def _controller(self):
        '''Return the server controller.'''
        def server_controller(cmd_id, cmd_body, _):
            '''Server controller.'''
            # Handle different command types based on cmd_id
            if cmd_id == 'GET':
                key = cmd_body.get('key')
                return self.kvstore.get(key)
            elif cmd_id == 'PUT':
                key = cmd_body.get('key')
                value = cmd_body.get('value')
                self.kvstore.put(key, value)
                return 'OK'
            elif cmd_id == 'DELETE':
                key = cmd_body.get('key')
                self.kvstore.delete(key)
                return 'OK'
            else:
                return 'UNKNOWN_COMMAND'
        return server_controller

    def run(self):
        '''Run the server, whose behavior is like.


        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        self.running = True
        controller = self._controller()
        
        while self.running:
            try:
                x = self._receive()  # Assuming this method exists to receive data
                if self._is_command(x):
                    response = controller(x['cmd_id'], x['cmd_body'], None)
                    self._send_response(response)  # Assuming this method exists to send response
                elif self._is_key_value(x):
                    self._updater(x)  # Assuming this method exists to handle key-value updates
            except Exception as e:
                # Handle exceptions and potentially break the loop if needed
                if not self.running:
                    break

    def _receive(self):
        '''Placeholder for receiving data - should be implemented based on actual communication method.'''
        # This would typically block and wait for incoming data
        pass

    def _is_command(self, x):
        '''Check if received data is a command.'''
        # Implementation depends on the data format
        return isinstance(x, dict) and 'cmd_id' in x and 'cmd_body' in x

    def _is_key_value(self, x):
        '''Check if received data is key-value data.'''
        # Implementation depends on the data format
        return isinstance(x, dict) and 'key' in x and 'value' in x

    def _updater(self, x):
        '''Handle key-value updates.'''
        key = x.get('key')
        value = x.get('value')
        self.kvstore.put(key, value)

    def _send_response(self, response):
        '''Placeholder for sending response - should be implemented based on actual communication method.'''
        pass

    def stop(self):
        '''Stop the server.'''
        self.running = False","class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
        '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        self.kvstore = kvstore

    def _controller(self):
        '''Return the server controller.'''
        def server_controller(cmd_id, cmd_body, _):
            '''Server controler.'''
            if cmd_id == 0:  # init
                self.kvstore.init_keys(cmd_body)
            elif cmd_id == 1:  # push
                self.kvstore.push(cmd_body)
            elif cmd_id == 2:  # pull
                self.kvstore.pull(cmd_body)
        
        return server_controller

    def run(self):
        '''Run the server, whose behavior is like.

        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        import mxnet as mx
        controller = self._controller()
        
        def updater(key, recv, local):
            local += recv
        
        server = mx.kv.create('dist_sync')
        server.set_controller(controller)
        server.set_updater(updater)
        server.run()",full_docstr,0.5449591280653951,0.4,0.3471074380165289,0.4850136239782017,0.4333465584748442,0.6569148936170213,0.3893333333333333,0.3181818181818182,0.8652973175048828,0.8016953468322754,0.8322830200195312,0.8076317310333252,0.779856822429907,0.42366412213740456,0.30268199233716475,0.24999999999999994,0.3396946564885497,0.2932866562552954,0.43463497453310695,0.27040816326530615,0.21465076660988075,0.7982124090194702,0.8084768652915955,0.8033118844032288,0.8074385523796082,0.7441886046511627,0.6026490066225165,0.5133333333333334,0.4496644295302013,0.5496688741721855,0.3818930543930918,0.8023715415019763,0.5793650793650794,0.4940239043824701,0.8794116973876953,0.7872511148452759,0.8307833075523376,0.7955886721611023,0.7906997674418604,0.3706226040293654,0.2461681715680925,0.3106079588350833,0.39,0.5357142857142857,0.3779050231543498,0.1385143710723267,0.3438200072593583,0.44,0.5892857142857143,0.3771052226520247,0.2949187020463076,0.3135021885617913,0.4,0.5
109735,Colorless-Green-Ideas/MaterialDjango,Colorless-Green-Ideas_MaterialDjango/node_modules/node-gyp/gyp/pylib/gyp/MSVSToolFile.py,gyp.MSVSToolFile.Writer,"class Writer(object):
  """"""Visual Studio XML tool file writer.""""""

  def __init__(self, tool_file_path, name):
    """"""Initializes the tool file.

    Args:
      tool_file_path: Path to the tool file.
      name: Name of the tool file.
    """"""
    self.tool_file_path = tool_file_path
    self.name = name
    self.rules_section = ['Rules']

  def AddCustomBuildRule(self, name, cmd, description,
                         additional_dependencies,
                         outputs, extensions):
    """"""Adds a rule to the tool file.

    Args:
      name: Name of the rule.
      description: Description of the rule.
      cmd: Command line of the rule.
      additional_dependencies: other files which may trigger the rule.
      outputs: outputs of the rule.
      extensions: extensions handled by the rule.
    """"""
    rule = ['CustomBuildRule',
            {'Name': name,
             'ExecutionDescription': description,
             'CommandLine': cmd,
             'Outputs': ';'.join(outputs),
             'FileExtensions': ';'.join(extensions),
             'AdditionalDependencies':
                 ';'.join(additional_dependencies)
            }]
    self.rules_section.append(rule)

  def WriteIfChanged(self):
    """"""Writes the tool file.""""""
    content = ['VisualStudioToolFile',
               {'Version': '8.00',
                'Name': self.name
               },
               self.rules_section
               ]
    easy_xml.WriteXmlIfChanged(content, self.tool_file_path,
                               encoding=""Windows-1252"")","class Writer(object):
    '''Visual Studio XML tool file writer.'''

  def __init__(self, tool_file_path, name):
    '''Initializes the tool file.

    Args:
      tool_file_path: Path to the tool file.
      name: Name of the tool file.
    '''
    pass

  def AddCustomBuildRule(self, name, cmd, description,
                         additional_dependencies,
                         outputs, extensions):
    '''Adds a rule to the tool file.

    Args:
      name: Name of the rule.
      description: Description of the rule.
      cmd: Command line of the rule.
      additional_dependencies: other files which may trigger the rule.
      outputs: outputs of the rule.
      extensions: extensions handled by the rule.
    '''
    pass

  def WriteIfChanged(self):
    '''Writes the tool file.'''
    pass

",4,4,snippet_70,1.0,"class Writer(object):
    '''Visual Studio XML tool file writer.'''

    def __init__(self, tool_file_path, name):
        '''Initializes the tool file.

        Args:
          tool_file_path: Path to the tool file.
          name: Name of the tool file.
        '''
        self.tool_file_path = tool_file_path
        self.name = name
        self._rules = []

    def AddCustomBuildRule(self, name, cmd, description,
                           additional_dependencies,
                           outputs, extensions):
        '''Adds a rule to the tool file.'''
        def _join(x):
            if isinstance(x, str) or not hasattr(x, '__iter__'):
                return x or ''
            return ';'.join(x)
        rule = {
            'Name': name or '',
            'CommandLine': cmd or '',
            'Description': description or '',
            'AdditionalDependencies': _join(additional_dependencies),
            'Outputs': _join(outputs),
            'Extensions': _join(extensions),
        }
        self._rules.append(rule)

    def WriteIfChanged(self):
        '''Writes the tool file.'''
        doc = xml.dom.minidom.Document()
        root = doc.createElement('VisualStudioToolFile')
        root.setAttribute('Name', self.name)
        doc.appendChild(root)
        for r in self._rules:
            elem = doc.createElement('CustomBuildRule')
            for attr in ('Name', 'CommandLine', 'Description',
                         'AdditionalDependencies', 'Outputs', 'Extensions'):
                elem.setAttribute(attr, r[attr])
            root.appendChild(elem)
        xml_bytes = doc.toprettyxml(indent='  ', encoding='utf-8')
        # Ensure directory exists
        d = os.path.dirname(self.tool_file_path)
        if d and not os.path.isdir(d):
            os.makedirs(d)
        # Write only if changed
        if os.path.exists(self.tool_file_path):
            with open(self.tool_file_path, 'rb') as f:
                existing = f.read()
            if existing == xml_bytes:
                return
        with open(self.tool_file_path, 'wb') as f:
            f.write(xml_bytes)","class Writer(object):
    '''Visual Studio XML tool file writer.'''

    def __init__(self, tool_file_path, name):
        '''Initializes the tool file.

        Args:
          tool_file_path: Path to the tool file.
          name: Name of the tool file.
        '''
        self.tool_file_path = tool_file_path
        self.name = name
        self.rules = []
        
    def AddCustomBuildRule(self, name, cmd, description,
                         additional_dependencies,
                         outputs, extensions):
        '''Adds a rule to the tool file.

        Args:
          name: Name of the rule.
          description: Description of the rule.
          cmd: Command line of the rule.
          additional_dependencies: other files which may trigger the rule.
          outputs: outputs of the rule.
          extensions: extensions handled by the rule.
        '''
        rule = {
            'name': name,
            'cmd': cmd,
            'description': description,
            'additional_dependencies': additional_dependencies,
            'outputs': outputs,
            'extensions': extensions
        }
        self.rules.append(rule)
        
    def WriteIfChanged(self):
        '''Writes the tool file.'''
        # Create the root element
        root = ET.Element('VisualStudioToolFile')
        root.set('Version', '8.00')
        root.set('Name', self.name)
        
        # Create the Rules element
        rules_element = ET.SubElement(root, 'Rules')
        
        # Add each rule
        for rule in self.rules:
            rule_element = ET.SubElement(rules_element, 'Rule')
            rule_element.set('Name', rule['name'])
            rule_element.set('FriendlyName', rule['name'])
            rule_element.set('Description', rule['description'])
            
            # Add additional dependencies
            if rule['additional_dependencies']:
                rule_element.set('AdditionalDependencies', rule['additional_dependencies'])
            
            # Add outputs
            if rule['outputs']:
                rule_element.set('Outputs', rule['outputs'])
            
            # Add extensions
            if rule['extensions']:
                rule_element.set('FileExtensions', rule['extensions'])
            
            # Add command
            if rule['cmd']:
                cmd_element = ET.SubElement(rule_element, 'ExecutionDescription')
                cmd_element.text = rule['cmd']
        
        # Format the XML
        rough_string = ET.tostring(root, 'utf-8')
        reparsed = minidom.parseString(rough_string)
        formatted_xml = reparsed.toprettyxml(indent=""  "", encoding='utf-8')
        
        # Remove empty lines
        lines = [line for line in formatted_xml.decode('utf-8').split('\n') if line.strip()]
        formatted_xml = '\n'.join(lines).encode('utf-8')
        
        # Write to file if content has changed
        if not os.path.exists(self.tool_file_path):
            with open(self.tool_file_path, 'wb') as f:
                f.write(formatted_xml)
            return True
        else:
            with open(self.tool_file_path, 'rb') as f:
                existing_content = f.read()
            if existing_content != formatted_xml:
                with open(self.tool_file_path, 'wb') as f:
                    f.write(formatted_xml)
                return True
        return False","class Writer(object):
    '''Visual Studio XML tool file writer.'''

    def __init__(self, tool_file_path, name):
        '''Initializes the tool file.

        Args:
          tool_file_path: Path to the tool file.
          name: Name of the tool file.
        '''
        self.tool_file_path = tool_file_path
        self.name = name
        self.rules = []

    def AddCustomBuildRule(self, name, cmd, description,
                           additional_dependencies,
                           outputs, extensions):
        '''Adds a rule to the tool file.

        Args:
          name: Name of the rule.
          description: Description of the rule.
          cmd: Command line of the rule.
          additional_dependencies: other files which may trigger the rule.
          outputs: outputs of the rule.
          extensions: extensions handled by the rule.
        '''
        rule = {
            'name': name,
            'cmd': cmd,
            'description': description,
            'additional_dependencies': additional_dependencies,
            'outputs': outputs,
            'extensions': extensions
        }
        self.rules.append(rule)

    def WriteIfChanged(self):
        '''Writes the tool file.'''
        # Create the root element
        root = ET.Element('VisualStudioToolFile')
        root.set('Name', self.name)
        root.set('Version', '8.00')
        
        # Create Rules element
        rules_elem = ET.SubElement(root, 'Rules')
        
        # Add each custom build rule
        for rule in self.rules:
            rule_elem = ET.SubElement(rules_elem, 'CustomBuildRule')
            rule_elem.set('Name', rule['name'])
            rule_elem.set('DisplayName', rule['name'])
            rule_elem.set('CommandLine', rule['cmd'])
            rule_elem.set('Description', rule['description'])
            rule_elem.set('FileExtensions', rule['extensions'])
            rule_elem.set('AdditionalDependencies', rule['additional_dependencies'])
            rule_elem.set('Outputs', rule['outputs'])
            rule_elem.set('ExecutionDescription', rule['description'])
        
        # Convert to string with proper formatting
        rough_string = ET.tostring(root, 'unicode')
        reparsed = minidom.parseString(rough_string)
        pretty_xml = reparsed.toprettyxml(indent='  ')
        
        # Remove empty lines
        pretty_xml = '\n'.join([line for line in pretty_xml.split('\n') if line.strip()])
        
        # Check if file exists and content is different
        should_write = True
        if os.path.exists(self.tool_file_path):
            try:
                with open(self.tool_file_path, 'r', encoding='utf-8') as f:
                    existing_content = f.read()
                if existing_content == pretty_xml:
                    should_write = False
            except:
                pass
        
        # Write file if changed or doesn't exist
        if should_write:
            # Ensure directory exists
            os.makedirs(os.path.dirname(self.tool_file_path), exist_ok=True)
            
            with open(self.tool_file_path, 'w', encoding='utf-8') as f:
                f.write(pretty_xml)",full_docstr,0.5744125326370757,0.4566929133858268,0.39050131926121373,0.5065274151436031,0.37425182814123265,0.5022522522522522,0.35214446952595935,0.29638009049773756,0.7950631380081177,0.8974997997283936,0.8431816101074219,0.8860833644866943,0.7821803960396043,0.5625,0.4705882352941177,0.4330708661417323,0.5234375,0.3245359747306898,0.40873634945397813,0.3125,0.2676056338028169,0.8092315196990967,0.9316751956939697,0.8661474585533142,0.9177883267402649,0.7509250000000001,0.5805168986083499,0.4790419161676646,0.4408817635270541,0.5248508946322067,0.3325582663253598,0.4230769230769231,0.3162118780096308,0.27491961414790994,0.8021857738494873,0.9339710474014282,0.8630767464637756,0.9188754558563232,0.7572775595238093,0.4962333848875848,0.217720718573168,0.301885695272687,0.5974025974025974,0.8679245283018868,0.5736877124503134,0.287340890455086,0.5999117971310242,0.5584415584415584,0.8490566037735849,0.5718499552594991,0.2988577862201305,0.5999117971310242,0.5584415584415584,0.8301886792452831
38319,Azure/azure-event-hubs-python,Azure_azure-event-hubs-python/azure/eventprocessorhost/checkpoint.py,azure.eventprocessorhost.checkpoint.Checkpoint,"class Checkpoint:
    """"""
    Contains checkpoint metadata.
    """"""

    def __init__(self, partition_id, offset=""-1"", sequence_number=""0""):
        """"""Initialize Checkpoint.

        :param partition_id: The parition ID of the checkpoint.
        :type partition_id: str
        :param offset: The receive offset of the checkpoint.
        :type offset: str
        :param sequence_number: The sequence number of the checkpoint.
        :type sequence_number: str
        """"""
        self.partition_id = partition_id
        self.offset = offset
        self.sequence_number = sequence_number

    def from_source(self, checkpoint):
        """"""
        Creates a new Checkpoint from an existing checkpoint.

        :param checkpoint: Existing checkpoint.
        :type checkpoint: ~azure.eventprocessorhost.checkpoint.Checkpoint
        """"""
        self.partition_id = checkpoint.partition_id
        self.offset = checkpoint.offset
        self.sequence_number = checkpoint.sequence_number","class Checkpoint:
    '''
    Contains checkpoint metadata.
    '''

    def __init__(self, partition_id, offset=""-1"", sequence_number=""0""):
    '''Initialize Checkpoint.

        :param partition_id: The parition ID of the checkpoint.
        :type partition_id: str
        :param offset: The receive offset of the checkpoint.
        :type offset: str
        :param sequence_number: The sequence number of the checkpoint.
        :type sequence_number: str
        '''
        pass

    def from_source(self, checkpoint):
    '''
        Creates a new Checkpoint from an existing checkpoint.

        :param checkpoint: Existing checkpoint.
        :type checkpoint: ~azure.eventprocessorhost.checkpoint.Checkpoint
        '''
        pass

",3,3,snippet_32,1.0,"class Checkpoint:
    '''
    Contains checkpoint metadata.
    '''

    def __init__(self, partition_id, offset=""-1"", sequence_number=""0""):
        '''Initialize Checkpoint.

        :param partition_id: The parition ID of the checkpoint.
        :type partition_id: str
        :param offset: The receive offset of the checkpoint.
        :type offset: str
        :param sequence_number: The sequence number of the checkpoint.
        :type sequence_number: str
        '''
        self.partition_id = str(partition_id)
        self.offset = str(offset)
        self.sequence_number = str(sequence_number)

    def from_source(self, checkpoint):
        '''
        Creates a new Checkpoint from an existing checkpoint.

        :param checkpoint: Existing checkpoint.
        :type checkpoint: ~azure.eventprocessorhost.checkpoint.Checkpoint
        '''
        return Checkpoint(
            checkpoint.partition_id,
            checkpoint.offset,
            checkpoint.sequence_number
        )","class Checkpoint:
    '''
    Contains checkpoint metadata.
    '''

    def __init__(self, partition_id, offset=""-1"", sequence_number=""0""):
        '''Initialize Checkpoint.

        :param partition_id: The parition ID of the checkpoint.
        :type partition_id: str
        :param offset: The receive offset of the checkpoint.
        :type offset: str
        :param sequence_number: The sequence number of the checkpoint.
        :type sequence_number: str
        '''
        self.partition_id = partition_id
        self.offset = offset
        self.sequence_number = sequence_number

    def from_source(self, checkpoint):
        '''
        Creates a new Checkpoint from an existing checkpoint.

        :param checkpoint: Existing checkpoint.
        :type checkpoint: ~azure.eventprocessorhost.checkpoint.Checkpoint
        '''
        self.partition_id = checkpoint.partition_id
        self.offset = checkpoint.offset
        self.sequence_number = checkpoint.sequence_number","class Checkpoint:
    '''
    Contains checkpoint metadata.
    '''

    def __init__(self, partition_id, offset=""-1"", sequence_number=""0""):
        '''Initialize Checkpoint.

        :param partition_id: The parition ID of the checkpoint.
        :type partition_id: str
        :param offset: The receive offset of the checkpoint.
        :type offset: str
        :param sequence_number: The sequence number of the checkpoint.
        :type sequence_number: str
        '''
        self.partition_id = partition_id
        self.offset = offset
        self.sequence_number = sequence_number

    def from_source(self, checkpoint):
        '''
        Creates a new Checkpoint from an existing checkpoint.

        :param checkpoint: Existing checkpoint.
        :type checkpoint: ~azure.eventprocessorhost.checkpoint.Checkpoint
        '''
        return Checkpoint(checkpoint.partition_id, checkpoint.offset, checkpoint.sequence_number)",full_docstr,0.9377990430622011,0.8985507246376812,0.8292682926829268,0.9377990430622011,0.75482047556781,0.8888888888888888,0.8138297872340425,0.7433155080213903,0.9810882806777954,0.9843354225158691,0.9827091693878174,0.9840096235275269,0.8980402352941177,1.0,1.0,1.0,1.0,0.8738095996859977,0.968421052631579,0.9365079365079365,0.9042553191489362,0.9962081909179688,0.9962081909179688,0.9962081909179688,0.9962081909179688,1.0,0.9514563106796116,0.9411764705882354,0.900990099009901,0.9514563106796116,0.780334558155771,0.9333333333333333,0.888268156424581,0.8426966292134831,0.985012948513031,0.9856574535369873,0.9853350520133972,0.9855929017066956,0.9333339999999999,0.4998996450176394,0.651113614805882,0.6573084946764406,0.4411764705882353,0.25,0.9109734144194528,0.8207451393459267,0.823148518331885,1.0,1.0,0.5815700218284333,0.7323554079721949,0.7388826625348158,0.6764705882352942,0.1785714285714285
2367,ARMmbed/mbed-cloud-sdk-python,ARMmbed_mbed-cloud-sdk-python/scripts/foundation/render_sdk.py,render_sdk.TemplateRenderer,"class TemplateRenderer(object):
    """"""Foundation Interface Template Renderer for jinja2""""""

    def __init__(self, output_root_dir):
        """"""Setup the jinja2 environment

        :param str output_root_dir: Root directory in which to write the Foundation interface.
        """"""
        self.output_root_dir = output_root_dir

        self.jinja_env = jinja2.Environment(loader=jinja2.FileSystemLoader(TEMPLATE_DIR))
        self.jinja_env.filters['repr'] = repr
        self.jinja_env.filters['pargs_kwargs'] = sort_parg_kwarg
        self.jinja_env.filters.update(dict(
            repr=repr,
            sort_parg_kwarg=sort_parg_kwarg,
            to_snake=to_snake_case,
            to_pascal=to_pascal_case,
            to_singular_name=to_singular_name,
        ))

    def render_template(self, template_filename, group=""group"", entity=""entity"", template_data=None):
        """"""Render one or more jinja2 templates.

        The output filename is relative to the `output_root_dir` defined in the class instance but is also defined by
        the `template_filename`. The `template_filename` should be interspersed with `.` to indicate subdirectories.

        Two place holders are also supported in the template filename:
        - `group`: which will be replaced by the `group` parameter
        - `entity`: which will be replaced by the `entity` parameter

        :param str template_filename: name of template to render, this also defines the output path and filename.
        :param str group: This should be supplied when the template filename contains `group` .
        :param str entity: This should be supplied when the template filename contains `entity`.
        :param dict template_data: Data to pass to the template.
        """"""
        template = self.jinja_env.get_template(template_filename)

        # Remove template extension (we'll append .py later).
        output_path = template_filename.replace("".jinja2"", """")

        # Covert the template filename to a path (which will be relative to the output_root_dir).
        output_path = output_path.replace(""."", os.path.sep)

        # If `group` or `entity` exist in the path name replace them with the provided group and entity parameters
        output_path = output_path.replace(""group"", to_snake_case(group))
        output_path = output_path.replace(""entity"", to_snake_case(entity))

        # Combine the root directory with the directory defined by the template filename
        output_path = os.path.join(self.output_root_dir, output_path) + "".py""

        output_dir = os.path.dirname(output_path)
        if not os.path.exists(output_dir):
            logger.info(""Creating subdirectory '%s'"", output_dir)
            os.makedirs(output_dir)

        logger.info(""Rendering template from '%s' to '%s'"", template_filename, output_path)
        rendered = template.render(template_data)
        with open(output_path, ""w"") as output_fh:
            output_fh.write(rendered)","class TemplateRenderer(object):
    '''Foundation Interface Template Renderer for jinja2'''

    def __init__(self, output_root_dir):
    '''Setup the jinja2 environment

        :param str output_root_dir: Root directory in which to write the Foundation interface.
        '''
        pass

    def render_template(self, template_filename, group=""group"", entity=""entity"", template_data=None):
    '''Render one or more jinja2 templates.

        The output filename is relative to the `output_root_dir` defined in the class instance but is also defined by
        the `template_filename`. The `template_filename` should be interspersed with `.` to indicate subdirectories.

        Two place holders are also supported in the template filename:
        - `group`: which will be replaced by the `group` parameter
        - `entity`: which will be replaced by the `entity` parameter

        :param str template_filename: name of template to render, this also defines the output path and filename.
        :param str group: This should be supplied when the template filename contains `group` .
        :param str entity: This should be supplied when the template filename contains `entity`.
        :param dict template_data: Data to pass to the template.
        '''
        pass

",3,3,snippet_14,0.4285714285714285,"class TemplateRenderer(object):
    '''Foundation Interface Template Renderer for jinja2'''

    def __init__(self, output_root_dir):
        '''Setup the jinja2 environment

        :param str output_root_dir: Root directory in which to write the Foundation interface.
        '''
        self.output_root_dir = os.path.abspath(output_root_dir)
        template_dir = os.path.join(os.path.dirname(__file__), 'templates')
        self.env = Environment(
            loader=FileSystemLoader(template_dir),
            undefined=StrictUndefined,
            keep_trailing_newline=True,
            trim_blocks=True,
            lstrip_blocks=True
        )

    def render_template(self, template_filename, group=""group"", entity=""entity"", template_data=None):
        '''Render one or more jinja2 templates.

        The output filename is relative to the `output_root_dir` defined in the class instance but is also defined by
        the `template_filename`. The `template_filename` should be interspersed with `.` to indicate subdirectories.

        Two place holders are also supported in the template filename:
        - `group`: which will be replaced by the `group` parameter
        - `entity`: which will be replaced by the `entity` parameter

        :param str template_filename: name of template to render, this also defines the output path and filename.
        :param str group: This should be supplied when the template filename contains `group` .
        :param str entity: This should be supplied when the template filename contains `entity`.
        :param dict template_data: Data to pass to the template.
        '''
        # replace placeholders
        fname = template_filename.replace('group', group).replace('entity', entity)
        # split off extension
        parts = fname.split('.')
        if len(parts) > 1:
            ext = parts[-1]
            path_parts = parts[:-1]
            rel_path = os.path.join(*path_parts) + '.' + ext
        else:
            rel_path = fname
        # load and render
        tpl = self.env.get_template(rel_path)
        data = template_data or {}
        rendered = tpl.render(**data)
        # write output
        out_path = os.path.join(self.output_root_dir, rel_path)
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, 'w', encoding='utf-8') as f:
            f.write(rendered)","class TemplateRenderer(object):
    '''Foundation Interface Template Renderer for jinja2'''

    def __init__(self, output_root_dir):
        '''Setup the jinja2 environment

        :param str output_root_dir: Root directory in which to write the Foundation interface.
        '''
        self.output_root_dir = output_root_dir
        self.env = jinja2.Environment(
            loader=jinja2.FileSystemLoader('.'),
            keep_trailing_newline=True
        )

    def render_template(self, template_filename, group=""group"", entity=""entity"", template_data=None):
        '''Render one or more jinja2 templates.

        The output filename is relative to the `output_root_dir` defined in the class instance but is also defined by
        the `template_filename`. The `template_filename` should be interspersed with `.` to indicate subdirectories.

        Two place holders are also supported in the template filename:
        - `group`: which will be replaced by the `group` parameter
        - `entity`: which will be replaced by the `entity` parameter

        :param str template_filename: name of template to render, this also defines the output path and filename.
        :param str group: This should be supplied when the template filename contains `group` .
        :param str entity: This should be supplied when the template filename contains `entity`.
        :param dict template_data: Data to pass to the template.
        '''
        if template_data is None:
            template_data = {}

        # Process template filename to create output path
        processed_filename = template_filename.replace('group', group).replace('entity', entity)
        path_parts = processed_filename.split('.')
        
        # Separate template name from path parts
        template_name = path_parts[-1]
        path_parts = path_parts[:-1]
        
        # Create output directory
        output_dir = os.path.join(self.output_root_dir, *path_parts)
        os.makedirs(output_dir, exist_ok=True)
        
        # Create output file path
        output_file = os.path.join(output_dir, template_name)
        
        # Render template
        template = self.env.get_template(template_filename)
        rendered_content = template.render(**template_data)
        
        # Write rendered content to file
        with open(output_file, 'w') as f:
            f.write(rendered_content)","class TemplateRenderer(object):
    '''Foundation Interface Template Renderer for jinja2'''

    def __init__(self, output_root_dir):
        '''Setup the jinja2 environment

        :param str output_root_dir: Root directory in which to write the Foundation interface.
        '''
        self.output_root_dir = output_root_dir
        self.env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(searchpath="".""),
            autoescape=jinja2.select_autoescape(['html', 'xml'])
        )

    def render_template(self, template_filename, group=""group"", entity=""entity"", template_data=None):
        '''Render one or more jinja2 templates.

        The output filename is relative to the `output_root_dir` defined in the class instance but is also defined by
        the `template_filename`. The `template_filename` should be interspersed with `.` to indicate subdirectories.

        Two place holders are also supported in the template filename:
        - `group`: which will be replaced by the `group` parameter
        - `entity`: which will be replaced by the `entity` parameter

        :param str template_filename: name of template to render, this also defines the output path and filename.
        :param str group: This should be supplied when the template filename contains `group` .
        :param str entity: This should be supplied when the template filename contains `entity`.
        :param dict template_data: Data to pass to the template.
        '''
        if template_data is None:
            template_data = {}
        
        # Replace placeholders in template filename
        output_filename = template_filename.replace('group', group).replace('entity', entity)
        
        # Convert dots to directory separators
        output_path = output_filename.replace('.', os.sep)
        
        # Create full output path
        full_output_path = os.path.join(self.output_root_dir, output_path)
        
        # Create output directory if it doesn't exist
        output_dir = os.path.dirname(full_output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # Load and render template
        template = self.env.get_template(template_filename)
        rendered_content = template.render(template_data)
        
        # Write rendered content to file
        with open(full_output_path, 'w') as f:
            f.write(rendered_content)",full_docstr,0.690856313497823,0.5735080058224162,0.5197080291970803,0.618287373004354,0.49490595316018865,0.8462998102466793,0.6673003802281369,0.579047619047619,0.8840768337249756,0.861117959022522,0.8724463582038879,0.8633599877357483,0.8273632899022803,0.7426900584795322,0.6187683284457479,0.5647058823529412,0.6754385964912281,0.48600155573686316,0.8832997987927566,0.7036290322580645,0.6343434343434343,0.9005489349365234,0.8586077094078064,0.8790783286094666,0.862625241279602,0.8284490553745928,0.7698986975397973,0.6589259796806967,0.5997088791848618,0.703328509406657,0.5258764750334566,0.900398406374502,0.7684630738522954,0.692,0.9124817848205566,0.8694446086883545,0.8904435038566589,0.8735647797584534,0.8501643648208468,0.5000164630318034,0.5124944265422299,0.528829595519624,0.5763888888888888,0.3823529411764705,0.4811644255923178,0.5245450112156277,0.5365505996503755,0.5694444444444444,0.2941176470588235,0.5255083399215037,0.5307896277599594,0.5455084378084086,0.6041666666666666,0.4215686274509804
391317,futurecolors/suds,futurecolors_suds/suds/resolver.py,suds.resolver.Resolver,"class Resolver:
    """"""
    An I{abstract} schema-type resolver.
    @ivar schema: A schema object.
    @type schema: L{xsd.schema.Schema}
    """"""

    def __init__(self, schema):
        """"""
        @param schema: A schema object.
        @type schema: L{xsd.schema.Schema}
        """"""
        self.schema = schema
        
    def find(self, name, resolved=True):
        """"""
        Get the definition object for the schema object by name.
        @param name: The name of a schema object.
        @type name: basestring
        @param resolved: A flag indicating that the fully resolved type
            should be returned.
        @type resolved: boolean
        @return: The found schema I{type}
        @rtype: L{xsd.sxbase.SchemaObject}
        """"""
        log.debug('searching schema for (%s)', name)
        qref = qualify(name, self.schema.root, self.schema.tns)
        query = BlindQuery(qref)
        result = query.execute(self.schema)
        if result is None:
            log.error('(%s) not-found', name)
            return None
        log.debug('found (%s) as (%s)', name, Repr(result))
        if resolved:
            result = result.resolve()
        return result","class Resolver:
    '''
    An I{abstract} schema-type resolver.
    @ivar schema: A schema object.
    @type schema: L{xsd.schema.Schema}
    '''

    def __init__(self, schema):
    '''
        @param schema: A schema object.
        @type schema: L{xsd.schema.Schema}
        '''
        pass

    def find(self, name, resolved=True):
    '''
        Get the definition object for the schema object by name.
        @param name: The name of a schema object.
        @type name: basestring
        @param resolved: A flag indicating that the fully resolved type
            should be returned.
        @type resolved: boolean
        @return: The found schema I{type}
        @rtype: L{xsd.sxbase.SchemaObject}
        '''
        pass

",3,3,snippet_679,0.4285714285714285,"class Resolver:
    '''
    An I{abstract} schema-type resolver.
    @ivar schema: A schema object.
    @type schema: L{xsd.schema.Schema}
    '''

    def __init__(self, schema):
        '''
        @param schema: A schema object.
        @type schema: L{xsd.schema.Schema}
        '''
        self.schema = schema

    def find(self, name, resolved=True):
        '''
        Get the definition object for the schema object by name.
        @param name: The name of a schema object.
        @type name: basestring
        @param resolved: A flag indicating that the fully resolved type
            should be returned.
        @type resolved: boolean
        @return: The found schema I{type}
        @rtype: L{xsd.sxbase.SchemaObject}
        '''
        if not isinstance(name, basestring):
            raise TypeError(""Schema object name must be a string"")
        obj = None
        for attr in ('types', 'elements', 'attributes',
                     'groups', 'attribute_groups', 'model_groups'):
            mapping = getattr(self.schema, attr, None)
            if mapping and name in mapping:
                obj = mapping[name]
                break
        if obj is None:
            raise KeyError(""No such schema object: %r"" % (name,))
        if not resolved:
            return obj
        visited = set()
        while True:
            key = (id(obj), getattr(obj, 'name', None))
            if key in visited:
                break
            visited.add(key)
            new_obj = None
            if hasattr(obj, 'type') and isinstance(obj.type, basestring):
                new_obj = self.find(obj.type)
            elif hasattr(obj, 'restriction') and obj.restriction is not None:
                base = getattr(obj.restriction, 'base', None)
                if isinstance(base, basestring):
                    new_obj = self.find(base)
            elif hasattr(obj, 'list') and obj.list is not None:
                it = getattr(obj.list, 'itemType', None)
                if isinstance(it, basestring):
                    new_obj = self.find(it)
            elif hasattr(obj, 'content') and obj.content is not None:
                content = obj.content
                ext = getattr(content, 'extension', None)
                if ext is not None and isinstance(getattr(ext, 'base', None), basestring):
                    new_obj = self.find(ext.base)
                else:
                    restr = getattr(content, 'restriction', None)
                    if restr is not None and isinstance(getattr(restr, 'base', None), basestring):
                        new_obj = self.find(restr.base)
            if new_obj is None:
                break
            obj = new_obj
        return obj","class Resolver:
    '''
    An I{abstract} schema-type resolver.
    @ivar schema: A schema object.
    @type schema: L{xsd.schema.Schema}
    '''

    def __init__(self, schema):
        '''
        @param schema: A schema object.
        @type schema: L{xsd.schema.Schema}
        '''
        self.schema = schema

    def find(self, name, resolved=True):
        '''
        Get the definition object for the schema object by name.
        @param name: The name of a schema object.
        @type name: basestring
        @param resolved: A flag indicating that the fully resolved type
            should be returned.
        @type resolved: boolean
        @return: The found schema I{type}
        @rtype: L{xsd.sxbase.SchemaObject}
        '''
        raise NotImplementedError(""find method must be implemented in subclass"")","class Resolver:
    '''
    An I{abstract} schema-type resolver.
    @ivar schema: A schema object.
    @type schema: L{xsd.schema.Schema}
    '''

    def __init__(self, schema):
        '''
        @param schema: A schema object.
        @type schema: L{xsd.schema.Schema}
        '''
        self.schema = schema

    def find(self, name, resolved=True):
        '''
        Get the definition object for the schema object by name.
        @param name: The name of a schema object.
        @type name: basestring
        @param resolved: A flag indicating that the fully resolved type
            should be returned.
        @type resolved: boolean
        @return: The found schema I{type}
        @rtype: L{xsd.sxbase.SchemaObject}
        '''
        raise NotImplementedError(""Subclasses must implement find method"")",full_docstr,0.49115044247787615,0.4088888888888889,0.39732142857142855,0.4646017699115044,0.3178850999999048,0.40816326530612246,0.2955390334572491,0.26629422718808193,0.8023075461387634,0.9109653234481812,0.8531908988952637,0.8987928032875061,0.7525879952267301,0.7489711934156379,0.7468879668049792,0.7447698744769875,0.7489711934156379,0.4681151913626044,0.9112426035502958,0.8571428571428571,0.8263473053892215,0.9516850709915161,0.8696510195732117,0.9088206887245178,0.8772124648094177,0.7853556818181817,0.7551867219917012,0.7531380753138076,0.7510548523206751,0.7551867219917012,0.464636786465537,0.9221556886227545,0.8674698795180723,0.8363636363636363,0.9518290758132935,0.8695887327194214,0.9088522791862488,0.8771677017211914,0.7853556818181817,0.4861369735656884,0.2680189411837282,0.6015289530790257,0.5,0.575,0.3890394377123448,0.5420788549800666,0.547412229202646,0.3166666666666666,0.15,0.3880347566773304,0.5380601308400093,0.547412229202646,0.3166666666666666,0.15
147517,LudovicRousseau/pyscard,LudovicRousseau_pyscard/src/smartcard/AbstractCardRequest.py,smartcard.AbstractCardRequest.AbstractCardRequest,"class AbstractCardRequest:
    """"""The base class for xxxCardRequest classes.

    A CardRequest is used for waitForCard() invocations and specifies what
    kind of smart card an application is waited for.""""""

    def __init__(
        self,
        newcardonly=False,
        readers=None,
        cardType=None,
        cardServiceClass=None,
        timeout=1,
    ):
        """"""Construct new CardRequest.

        @param newcardonly: if True, request a new card; default is
                            False, i.e. accepts cards already inserted

        @param readers:     the list of readers to consider for
                            requesting a card; default is to consider
                            all readers

        @param cardType:    the L{smartcard.CardType.CardType} to wait for;
                            default is L{smartcard.CardType.AnyCardType},
                            i.e. the request will succeed with any card

        @param cardServiceClass: the specific card service class to create
                            and bind to the card;default is to create
                            and bind a L{smartcard.PassThruCardService}

        @param timeout:     the time in seconds we are ready to wait for
                            connecting to the requested card.  default
                            is to wait one second; to wait forever, set
                            timeout to None
        """"""
        self.newcardonly = newcardonly
        self.readersAsked = readers
        self.cardType = cardType
        self.cardServiceClass = cardServiceClass
        self.timeout = timeout

        # if no CardType requested, use AnyCardType
        if self.cardType is None:
            self.cardType = AnyCardType()

        # if no card service requested, use pass-thru card service
        if self.cardServiceClass is None:
            self.cardServiceClass = PassThruCardService

    def getReaders(self):
        """"""Returns the list or readers on which to wait for cards.""""""
        # if readers not given, use all readers
        if self.readersAsked is None:
            return smartcard.System.readers()
        else:
            return self.readersAsked

    def waitforcard(self):
        """"""Wait for card insertion and returns a card service.""""""
        pass

    def waitforcardevent(self):
        """"""Wait for card insertion or removal.""""""
        pass","class AbstractCardRequest:
    '''The base class for xxxCardRequest classes.

    A CardRequest is used for waitForCard() invocations and specifies what
    kind of smart card an application is waited for.'''

    def __init__(
        self,
        newcardonly=False,
        readers=None,
        cardType=None,
        cardServiceClass=None,
        timeout=1,
    ):
    '''Construct new CardRequest.

        @param newcardonly: if True, request a new card; default is
                            False, i.e. accepts cards already inserted

        @param readers:     the list of readers to consider for
                            requesting a card; default is to consider
                            all readers

        @param cardType:    the L{smartcard.CardType.CardType} to wait for;
                            default is L{smartcard.CardType.AnyCardType},
                            i.e. the request will succeed with any card

        @param cardServiceClass: the specific card service class to create
                            and bind to the card;default is to create
                            and bind a L{smartcard.PassThruCardService}

        @param timeout:     the time in seconds we are ready to wait for
                            connecting to the requested card.  default
                            is to wait one second; to wait forever, set
                            timeout to None
        '''
                                                        pass

    def getReaders(self):
    '''Returns the list or readers on which to wait for cards.'''
        pass

    def waitforcard(self):
    '''Wait for card insertion and returns a card service.'''
        pass

    def waitforcardevent(self):
    '''Wait for card insertion or removal.'''
        pass

",5,5,snippet_180,1.0,"class AbstractCardRequest:
    '''The base class for xxxCardRequest classes.

    A CardRequest is used for waitForCard() invocations and specifies what
    kind of smart card an application is waited for.'''

    def __init__(
        self,
        newcardonly=False,
        readers=None,
        cardType=None,
        cardServiceClass=None,
        timeout=1,
    ):
        '''Construct new CardRequest.

        @param newcardonly: if True, request a new card; default is
                            False, i.e. accepts cards already inserted

        @param readers:     the list of readers to consider for
                            requesting a card; default is to consider
                            all readers

        @param cardType:    the L{smartcard.CardType.CardType} to wait for;
                            default is L{smartcard.CardType.AnyCardType},
                            i.e. the request will succeed with any card

        @param cardServiceClass: the specific card service class to create
                            and bind to the card;default is to create
                            and bind a L{smartcard.PassThruCardService}

        @param timeout:     the time in seconds we are ready to wait for
                            connecting to the requested card.  default
                            is to wait one second; to wait forever, set
                            timeout to None
        '''
        self.newcardonly = bool(newcardonly)
        self._requested_readers = readers[:] if readers is not None else None
        self.cardType = cardType or AnyCardType()
        self.cardServiceClass = cardServiceClass or PassThruCardService
        self.timeout = timeout

        # Track initial card presence per reader (for newcardonly)
        self._initial_atrs = {}
        if self.newcardonly:
            for rdr in self.getReaders():
                try:
                    con = rdr.createConnection()
                    con.connect()
                    atr = tuple(con.getATR())
                    self._initial_atrs[rdr.name] = atr
                    con.disconnect()
                except Exception:
                    pass

        # Track reader insertion state for waitforcardevent
        self._reader_states = {}
        for rdr in self.getReaders():
            try:
                con = rdr.createConnection()
                con.connect()
                self._reader_states[rdr.name] = True
                con.disconnect()
            except Exception:
                self._reader_states[rdr.name] = False

    def getReaders(self):
        '''Returns the list or readers on which to wait for cards.'''
        all_rdrs = _get_readers()
        if not all_rdrs:
            raise NoReadersException(""No smartcard readers available"")
        if self._requested_readers is None:
            return all_rdrs
        selected = []
        names = set(self._requested_readers)
        for rdr in all_rdrs:
            if rdr.name in names:
                selected.append(rdr)
        if not selected:
            raise NoReadersException(
                ""No readers matching %r found"" % (self._requested_readers,)
            )
        return selected

    def waitforcard(self):
        '''Wait for card insertion and returns a card service.'''
        deadline = None
        if self.timeout is not None:
            deadline = time.time() + float(self.timeout)
        while True:
            if deadline is not None and time.time() > deadline:
                raise CardRequestTimeoutException(""Timeout waiting for card"")
            for rdr in self.getReaders():
                try:
                    con = rdr.createConnection()
                    con.connect()
                    atr = tuple(con.getATR())
                except Exception:
                    continue
                # ATR must match requested cardType
                if not self.cardType.match(atr):
                    try:
                        con.disconnect()
                    except Exception:
                        pass
                    continue
                # If newcardonly, skip cards present at init
                if self.newcardonly:
                    init = self._initial_atrs.get(rdr.name)
                    if init is not None and init == atr:
                        try:
                            con.disconnect()
                        except Exception:
                            pass
                        continue
                # success: bind and return
                return self.cardServiceClass(con)
            time.sleep(0.1)

    def waitforcardevent(self):
        '''Wait for card insertion or removal.'''
        deadline = None
        if self.timeout is not None:
            deadline = time.time() + float(self.timeout)
        while True:
            if deadline is not None and time.time() > deadline:
                raise CardRequestTimeoutException(""Timeout waiting for card event"")
            for rdr in self.getReaders():
                name = rdr.name
                old_state = self._reader_states.get(name, False)
                new_state = False
                try:
                    con = rdr.createConnection()
                    con.connect()
                    new_state = True
                    con.disconnect()
                except Exception:
                    new_state = False
                if new_state != old_state:
                    self._reader_states[name] = new_state
                    return (rdr, new_state)
            time.sleep(0.1)","class AbstractCardRequest:
    '''The base class for xxxCardRequest classes.

    A CardRequest is used for waitForCard() invocations and specifies what
    kind of smart card an application is waited for.'''

    def __init__(
        self,
        newcardonly=False,
        readers=None,
        cardType=None,
        cardServiceClass=None,
        timeout=1,
    ):
        '''Construct new CardRequest.

        @param newcardonly: if True, request a new card; default is
                            False, i.e. accepts cards already inserted

        @param readers:     the list of readers to consider for
                            requesting a card; default is to consider
                            all readers

        @param cardType:    the L{smartcard.CardType.CardType} to wait for;
                            default is L{smartcard.CardType.AnyCardType},
                            i.e. the request will succeed with any card

        @param cardServiceClass: the specific card service class to create
                            and bind to the card;default is to create
                            and bind a L{smartcard.PassThruCardService}

        @param timeout:     the time in seconds we are ready to wait for
                            connecting to the requested card.  default
                            is to wait one second; to wait forever, set
                            timeout to None
        '''
        self.newcardonly = newcardonly
        self.readers = readers
        self.cardType = cardType
        self.cardServiceClass = cardServiceClass
        self.timeout = timeout

    def getReaders(self):
        '''Returns the list or readers on which to wait for cards.'''
        return self.readers

    def waitforcard(self):
        '''Wait for card insertion and returns a card service.'''
        raise NotImplementedError(""waitforcard method must be implemented in subclass"")

    def waitforcardevent(self):
        '''Wait for card insertion or removal.'''
        raise NotImplementedError(""waitforcardevent method must be implemented in subclass"")","class AbstractCardRequest:
    '''The base class for xxxCardRequest classes.

    A CardRequest is used for waitForCard() invocations and specifies what
    kind of smart card an application is waited for.'''

    def __init__(
        self,
        newcardonly=False,
        readers=None,
        cardType=None,
        cardServiceClass=None,
        timeout=1,
    ):
        '''Construct new CardRequest.

        @param newcardonly: if True, request a new card; default is
                            False, i.e. accepts cards already inserted

        @param readers:     the list of readers to consider for
                            requesting a card; default is to consider
                            all readers

        @param cardType:    the L{smartcard.CardType.CardType} to wait for;
                            default is L{smartcard.CardType.AnyCardType},
                            i.e. the request will succeed with any card

        @param cardServiceClass: the specific card service class to create
                            and bind to the card;default is to create
                            and bind a L{smartcard.PassThruCardService}

        @param timeout:     the time in seconds we are ready to wait for
                            connecting to the requested card.  default
                            is to wait one second; to wait forever, set
                            timeout to None
        '''
        self.newcardonly = newcardonly
        self.readers = readers
        self.cardType = cardType
        self.cardServiceClass = cardServiceClass
        self.timeout = timeout

    def getReaders(self):
        '''Returns the list or readers on which to wait for cards.'''
        return self.readers

    def waitforcard(self):
        '''Wait for card insertion and returns a card service.'''
        raise NotImplementedError(""Subclasses must implement waitforcard()"")

    def waitforcardevent(self):
        '''Wait for card insertion or removal.'''
        raise NotImplementedError(""Subclasses must implement waitforcardevent()"")",full_docstr,0.6091245376078914,0.5142150803461064,0.47335811648079307,0.5524044389642417,0.32686265563950767,0.38411316648531013,0.31699346405228757,0.28680479825517996,0.8321170806884766,0.953266978263855,0.8885816335678101,0.9395872950553894,0.7369859903381649,0.8588957055214723,0.8295687885010268,0.8082474226804124,0.8507157464212679,0.6844295137679189,0.9135802469135802,0.848297213622291,0.8074534161490683,0.952023446559906,0.9443759918212891,0.9481842517852783,0.945135235786438,0.8558572972972972,0.8695652173913044,0.8399168399168399,0.8183716075156576,0.8612836438923396,0.6851253262085027,0.9192546583850931,0.8598130841121495,0.8125,0.9549767374992371,0.9443792700767517,0.9496484398841858,0.9454284906387329,0.8558572972972972,0.5617375825863903,0.3471907729213001,0.6982091698273618,0.6666666666666666,0.5348837209302325,0.6435481986929242,0.6717091683583262,0.6745061775056895,0.5303030303030303,0.6976744186046512,0.6427464853794425,0.6685023151043987,0.6745061775056895,0.5303030303030303,0.6976744186046512
315454,connectordb/connectordb-python,connectordb_connectordb-python/connectordb/query/merge.py,connectordb.query.merge.Merge,"class Merge(object):
    """"""Merge represents a query which allows to merge multiple streams into one
    when reading, with all the streams merged together by increasing timestamp.
    The merge query is used as a constructor-type object::

        m = Merge(cdb)
        m.addStream(""mystream1"",t1=time.time()-10)
        m.addStream(""mystream2"",t1=time.time()-10)
        result = m.run()
    """"""

    def __init__(self, cdb):
        """"""Given a ConnectorDB object, begins the construction of a Merge query""""""
        self.cdb = cdb

        self.query = []

    def addStream(self, stream, t1=None, t2=None, limit=None, i1=None, i2=None, transform=None):
        """"""Adds the given stream to the query construction. The function supports both stream
        names and Stream objects.""""""
        params = query_maker(t1, t2, limit, i1, i2, transform)

        params[""stream""] = get_stream(self.cdb, stream)

        # Now add the stream to the query parameters
        self.query.append(params)

    def run(self):
        """"""Runs the merge query, and returns the result""""""
        return self.cdb.db.query(""merge"", self.query)","class Merge(object):
    '''Merge represents a query which allows to merge multiple streams into one
    when reading, with all the streams merged together by increasing timestamp.
    The merge query is used as a constructor-type object::

        m = Merge(cdb)
        m.addStream(""mystream1"",t1=time.time()-10)
        m.addStream(""mystream2"",t1=time.time()-10)
        result = m.run()
    '''

    def __init__(self, cdb):
    '''Given a ConnectorDB object, begins the construction of a Merge query'''
        pass

    def addStream(self, stream, t1=None, t2=None, limit=None, i1=None, i2=None, transform=None):
    '''Adds the given stream to the query construction. The function supports both stream
        names and Stream objects.'''
        pass

    def run(self):
    '''Runs the merge query, and returns the result'''
        pass

",4,4,snippet_547,1.0,"class Merge(object):
    '''Merge represents a query which allows to merge multiple streams into one
    when reading, with all the streams merged together by increasing timestamp.
    The merge query is used as a constructor-type object::

        m = Merge(cdb)
        m.addStream(""mystream1"",t1=time.time()-10)
        m.addStream(""mystream2"",t1=time.time()-10)
        result = m.run()
    '''

    def __init__(self, cdb):
        '''Given a ConnectorDB object, begins the construction of a Merge query'''
        self.cdb = cdb
        self._streams = []

    def addStream(self, stream, t1=None, t2=None, limit=None,
                  i1=None, i2=None, transform=None):
        '''Adds the given stream to the query construction. The function supports both stream
        names and Stream objects.'''
        self._streams.append({
            'stream': stream,
            't1': t1,
            't2': t2,
            'limit': limit,
            'i1': i1,
            'i2': i2,
            'transform': transform
        })
        return self

    def run(self):
        '''Runs the merge query, and returns the result'''
        iterators = []

        for spec in self._streams:
            src = spec['stream']
            t1, t2 = spec['t1'], spec['t2']
            limit, i1, i2 = spec['limit'], spec['i1'], spec['i2']
            transform = spec['transform']

            # obtain a raw iterator of rows
            if isinstance(src, str):
                # assume cdb.get_stream returns an iterator of dicts with a 't' timestamp key
                rows = self.cdb.get_stream(src,
                                           t1=t1, t2=t2,
                                           limit=limit,
                                           i1=i1, i2=i2)
            elif hasattr(src, 'run') and callable(src.run):
                # assume it's another query object
                rows = src.run()
            else:
                raise TypeError(""Stream must be a name or an object with run()"")

            # apply transform if provided
            if transform is not None:
                rows = map(transform, rows)

            # wrap each row as (timestamp, row) for merging
            def wrapped(r_iter):
                for r in r_iter:
                    if 't' not in r:
                        raise KeyError(""Each row must have a 't' timestamp field"")
                    yield (r['t'], r)

            iterators.append(wrapped(rows))

        # merge all iterators by the timestamp key
        merged = heapq.merge(*iterators, key=lambda x: x[0])

        # return only the row dicts, in order
        return [row for (_, row) in merged]","class Merge(object):
    '''Merge represents a query which allows to merge multiple streams into one
    when reading, with all the streams merged together by increasing timestamp.
    The merge query is used as a constructor-type object::

        m = Merge(cdb)
        m.addStream(""mystream1"",t1=time.time()-10)
        m.addStream(""mystream2"",t1=time.time()-10)
        result = m.run()
    '''

    def __init__(self, cdb):
        '''Given a ConnectorDB object, begins the construction of a Merge query'''
        self.cdb = cdb
        self.streams = []

    def addStream(self, stream, t1=None, t2=None, limit=None, i1=None, i2=None, transform=None):
        '''Adds the given stream to the query construction. The function supports both stream
        names and Stream objects.'''
        stream_spec = {
            'stream': stream,
            't1': t1,
            't2': t2,
            'limit': limit,
            'i1': i1,
            'i2': i2,
            'transform': transform
        }
        self.streams.append(stream_spec)

    def run(self):
        '''Runs the merge query, and returns the result'''
        all_data = []
        
        for stream_spec in self.streams:
            stream = stream_spec['stream']
            t1 = stream_spec['t1']
            t2 = stream_spec['t2']
            limit = stream_spec['limit']
            i1 = stream_spec['i1']
            i2 = stream_spec['i2']
            transform = stream_spec['transform']
            
            # Handle both stream names and Stream objects
            if isinstance(stream, str):
                # Assume stream is a name and fetch from cdb
                stream_data = self.cdb.read(stream, t1=t1, t2=t2, limit=limit, i1=i1, i2=i2)
            else:
                # Assume stream is a Stream object
                stream_data = stream.read(t1=t1, t2=t2, limit=limit, i1=i1, i2=i2)
            
            # Apply transform if provided
            if transform and callable(transform):
                stream_data = transform(stream_data)
            
            all_data.extend(stream_data)
        
        # Sort by timestamp
        all_data.sort(key=lambda x: x['t'] if isinstance(x, dict) and 't' in x else getattr(x, 't', 0))
        
        return all_data","class Merge(object):
    '''Merge represents a query which allows to merge multiple streams into one
    when reading, with all the streams merged together by increasing timestamp.
    The merge query is used as a constructor-type object::

        m = Merge(cdb)
        m.addStream(""mystream1"",t1=time.time()-10)
        m.addStream(""mystream2"",t1=time.time()-10)
        result = m.run()
    '''

    def __init__(self, cdb):
        '''Given a ConnectorDB object, begins the construction of a Merge query'''
        self.cdb = cdb
        self.streams = []

    def addStream(self, stream, t1=None, t2=None, limit=None, i1=None, i2=None, transform=None):
        '''Adds the given stream to the query construction. The function supports both stream
        names and Stream objects.'''
        stream_info = {
            'stream': stream,
            't1': t1,
            't2': t2,
            'limit': limit,
            'i1': i1,
            'i2': i2,
            'transform': transform
        }
        self.streams.append(stream_info)

    def run(self):
        '''Runs the merge query, and returns the result'''
        all_data = []
        
        for stream_info in self.streams:
            stream = stream_info['stream']
            if isinstance(stream, str):
                stream_obj = self.cdb[stream]
            else:
                stream_obj = stream
            
            params = {}
            for key in ['t1', 't2', 'limit', 'i1', 'i2', 'transform']:
                if stream_info[key] is not None:
                    params[key] = stream_info[key]
            
            data = stream_obj.read(**params)
            all_data.extend(data)
        
        all_data.sort(key=lambda x: x['t'])
        return all_data",full_docstr,0.5991561181434599,0.5254237288135594,0.4893617021276596,0.5485232067510549,0.3810237845782751,0.44756554307116103,0.3714821763602251,0.33270676691729323,0.8331837058067322,0.9481058716773987,0.8869376182556152,0.935206413269043,0.7565567415730341,0.6238532110091742,0.566820276497696,0.5231481481481481,0.5963302752293578,0.414963567665437,0.4801670146137787,0.40794979079497906,0.36477987421383645,0.8737815618515015,0.9488215446472168,0.9097567796707153,0.9407424330711365,0.764528348623854,0.7582417582417582,0.6795580110497238,0.6555555555555557,0.7087912087912088,0.5337821081224582,0.6294277929155313,0.5218579234972678,0.46301369863013697,0.8916685581207275,0.9510873556137085,0.9204199910163879,0.9447914361953735,0.7941587649402391,0.5954653838266617,0.2884971770137265,0.6528992420138504,0.58,0.8604651162790697,0.6147882804918482,0.3533648268679934,0.6485789927738177,0.62,0.8372093023255814,0.645542750638233,0.4743901217910696,0.6505715784362809,0.62,0.8372093023255814
252270,aws/sagemaker-python-sdk,aws_sagemaker-python-sdk/src/sagemaker/lineage/query.py,sagemaker.lineage.query.Edge,"class Edge:
    """"""A connecting edge for a lineage graph.""""""

    def __init__(
        self,
        source_arn: str,
        destination_arn: str,
        association_type: str,
    ):
        """"""Initialize ``Edge`` instance.""""""
        self.source_arn = source_arn
        self.destination_arn = destination_arn
        self.association_type = association_type

    def __hash__(self):
        """"""Define hash function for ``Edge``.""""""
        return hash(
            (
                ""source_arn"",
                self.source_arn,
                ""destination_arn"",
                self.destination_arn,
                ""association_type"",
                self.association_type,
            )
        )

    def __eq__(self, other):
        """"""Define equal function for ``Edge``.""""""
        return (
            self.association_type == other.association_type
            and self.source_arn == other.source_arn
            and self.destination_arn == other.destination_arn
        )

    def __str__(self):
        """"""Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        """"""
        return str(self.__dict__)

    def __repr__(self):
        """"""Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        """"""
        return ""\n\t"" + str(self.__dict__)","class Edge:
    '''A connecting edge for a lineage graph.'''

    def __init__(
        self,
        source_arn: str,
        destination_arn: str,
        association_type: str,
    ):
    '''Initialize ``Edge`` instance.'''
        pass

    def __hash__(self):
    '''Define hash function for ``Edge``.'''
        pass

    def __eq__(self, other):
    '''Define equal function for ``Edge``.'''
        pass

    def __str__(self):
    '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        pass

    def __repr__(self):
    '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        pass

",6,6,snippet_376,1.0,"class Edge:
    '''A connecting edge for a lineage graph.'''

    def __init__(
        self,
        source_arn: str,
        destination_arn: str,
        association_type: str,
    ):
        '''Initialize ``Edge`` instance.'''
        self.source_arn = source_arn
        self.destination_arn = destination_arn
        self.association_type = association_type

    def __hash__(self):
        '''Define hash function for ``Edge``.'''
        return hash((self.source_arn, self.destination_arn, self.association_type))

    def __eq__(self, other):
        '''Define equal function for ``Edge``.'''
        if not isinstance(other, Edge):
            return False
        return (
            self.source_arn == other.source_arn
            and self.destination_arn == other.destination_arn
            and self.association_type == other.association_type
        )

    def __str__(self):
        '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        return (
            ""{\n""
            f""    'source_arn': '{self.source_arn}',\n""
            f""    'destination_arn': '{self.destination_arn}',\n""
            f""    'association_type': '{self.association_type}'\n""
            ""}""
        )

    def __repr__(self):
        '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        return self.__str__()","class Edge:
    '''A connecting edge for a lineage graph.'''

    def __init__(
        self,
        source_arn: str,
        destination_arn: str,
        association_type: str,
    ):
        '''Initialize ``Edge`` instance.'''
        self.source_arn = source_arn
        self.destination_arn = destination_arn
        self.association_type = association_type

    def __hash__(self):
        '''Define hash function for ``Edge``.'''
        return hash((self.source_arn, self.destination_arn, self.association_type))

    def __eq__(self, other):
        '''Define equal function for ``Edge``.'''
        if not isinstance(other, Edge):
            return False
        return (self.source_arn == other.source_arn and
                self.destination_arn == other.destination_arn and
                self.association_type == other.association_type)

    def __str__(self):
        '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        return str({
            'source_arn': self.source_arn,
            'destination_arn': self.destination_arn,
            'association_type': self.association_type
        })

    def __repr__(self):
        '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        return str({
            'source_arn': self.source_arn,
            'destination_arn': self.destination_arn,
            'association_type': self.association_type
        })","class Edge:
    '''A connecting edge for a lineage graph.'''

    def __init__(
        self,
        source_arn: str,
        destination_arn: str,
        association_type: str,
    ):
        '''Initialize ``Edge`` instance.'''
        self.source_arn = source_arn
        self.destination_arn = destination_arn
        self.association_type = association_type

    def __hash__(self):
        '''Define hash function for ``Edge``.'''
        return hash((self.source_arn, self.destination_arn, self.association_type))

    def __eq__(self, other):
        '''Define equal function for ``Edge``.'''
        if not isinstance(other, Edge):
            return False
        return (self.source_arn == other.source_arn and 
                self.destination_arn == other.destination_arn and 
                self.association_type == other.association_type)

    def __str__(self):
        '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        return str({
            'source_arn': self.source_arn,
            'destination_arn': self.destination_arn,
            'association_type': self.association_type
        })

    def __repr__(self):
        '''Define string representation of ``Edge``.

        Format:
            {
                'source_arn': 'string',
                'destination_arn': 'string',
                'association_type': 'string'
            }

        '''
        return str({
            'source_arn': self.source_arn,
            'destination_arn': self.destination_arn,
            'association_type': self.association_type
        })",full_docstr,0.9158249158249159,0.8542372881355933,0.7849829351535836,0.8148148148148149,0.7342190800736639,0.840782122905028,0.7254901960784313,0.648876404494382,0.9435240030288696,0.9539588093757629,0.9487126469612122,0.9529048800468445,0.8770065775401069,0.8918032786885245,0.8448844884488449,0.7906976744186046,0.8065573770491803,0.7356199055703245,0.8290598290598291,0.7285714285714285,0.6590257879656161,0.9512726068496704,0.9533050656318665,0.9522877335548401,0.953101396560669,0.8866339593908629,0.8918032786885245,0.8448844884488449,0.7906976744186046,0.8065573770491803,0.7356199055703245,0.8290598290598291,0.7285714285714285,0.6590257879656161,0.9510154724121094,0.9529659748077393,0.9519897699356079,0.9527705907821655,0.8866339593908629,0.5670853672404859,0.5025012537633771,0.5558673522406286,0.6417910447761194,0.5681818181818182,0.5764381289372453,0.4755897041527717,0.5292808577291811,0.6417910447761194,0.6590909090909091,0.5764381289372453,0.4755897041527717,0.5292808577291811,0.6417910447761194,0.6590909090909091
206148,Unidata/MetPy,Unidata_MetPy/src/metpy/io/_tools.py,metpy.io._tools.Enum,"class Enum:
    """"""Map values to specific strings.""""""

    def __init__(self, *args, **kwargs):
        """"""Initialize the mapping.""""""
        # Assign values for args in order starting at 0
        self.val_map = dict(enumerate(args))

        # Invert the kwargs dict so that we can map from value to name
        self.val_map.update(zip(kwargs.values(), kwargs.keys(), strict=False))

    def __call__(self, val):
        """"""Map an integer to the string representation.""""""
        return self.val_map.get(val, f'Unknown ({val})')","class Enum:
    '''Map values to specific strings.'''

    def __init__(self, *args, **kwargs):
    '''Initialize the mapping.'''
        pass

    def __call__(self, val):
    '''Map an integer to the string representation.'''
        pass

",3,3,snippet_272,1.0,"class Enum:
    '''Map values to specific strings.'''

    def __init__(self, *args, **kwargs):
        '''Initialize the mapping.'''
        self._name_to_val = {}
        self._val_to_name = {}
        next_val = 0
        # assign positional args
        for name in args:
            if not isinstance(name, str):
                raise TypeError('Enum names must be strings')
            if name in self._name_to_val:
                raise ValueError(f'Duplicate enum name: {name}')
            self._name_to_val[name] = next_val
            self._val_to_name[next_val] = name
            next_val += 1
        # assign keyword args
        for name, val in kwargs.items():
            if not isinstance(name, str):
                raise TypeError('Enum names must be strings')
            if not isinstance(val, int):
                raise TypeError('Enum values must be integers')
            if name in self._name_to_val:
                # remove old mapping
                old_val = self._name_to_val[name]
                del self._val_to_name[old_val]
            if val in self._val_to_name:
                raise ValueError(f'Duplicate enum value: {val}')
            self._name_to_val[name] = val
            self._val_to_name[val] = name
        # set attributes
        for name, val in self._name_to_val.items():
            setattr(self, name, val)

    def __call__(self, val):
        '''Map an integer to the string representation.'''
        try:
            return self._val_to_name[val]
        except KeyError:
            raise KeyError(f'Invalid enum value: {val}')","class Enum:
    '''Map values to specific strings.'''

    def __init__(self, *args, **kwargs):
        '''Initialize the mapping.'''
        self._mapping = {}
        
        # Handle positional arguments
        for i, arg in enumerate(args):
            self._mapping[i] = arg
            
        # Handle keyword arguments
        for key, value in kwargs.items():
            if isinstance(key, int):
                self._mapping[key] = value
            else:
                # If key is not an integer, use its position
                self._mapping[len(self._mapping)] = key

    def __call__(self, val):
        '''Map an integer to the string representation.'''
        return self._mapping.get(val, None)","class Enum:
    '''Map values to specific strings.'''

    def __init__(self, *args, **kwargs):
        '''Initialize the mapping.'''
        self._mapping = {}
        
        # Handle positional arguments (list of strings)
        for i, value in enumerate(args):
            self._mapping[i] = value
        
        # Handle keyword arguments (explicit key-value pairs)
        for key, value in kwargs.items():
            if isinstance(key, str) and key.isdigit():
                self._mapping[int(key)] = value
            else:
                # For non-numeric string keys, we need to handle them appropriately
                # This assumes the key should be converted to its hash or some numeric representation
                self._mapping[hash(key) % 1000] = value

    def __call__(self, val):
        '''Map an integer to the string representation.'''
        return self._mapping.get(val, str(val))",full_docstr,0.3418181818181818,0.21978021978021978,0.16974169741697417,0.3272727272727273,0.16726389739616898,0.2768817204301075,0.15633423180592992,0.10810810810810811,0.7343541383743286,0.7914825677871704,0.7618488669395447,0.7853728532791138,0.7503398785425104,0.4935064935064935,0.368421052631579,0.32,0.4805194805194805,0.3807807542019686,0.5705128205128205,0.3548387096774194,0.2727272727272727,0.825732946395874,0.8206701874732971,0.8231937885284424,0.8211737275123596,0.8181836363636363,0.47252747252747246,0.31111111111111106,0.2696629213483146,0.4285714285714285,0.3234030268919997,0.5181347150259067,0.296875,0.2198952879581152,0.7757836580276489,0.812524676322937,0.7937292456626892,0.8086946606636047,0.82385,0.2549723944995787,0.0629925909673539,0.1716405767745508,0.4102564102564102,0.375,0.3083031143122943,0.1282054653304999,0.1691095560212412,0.4358974358974359,0.5,0.332128690495422,0.0959767493097011,0.1716405767745508,0.4358974358974359,0.625
378036,fabioz/PyDev.Debugger,fabioz_PyDev.Debugger/pydevd_attach_to_process/winappdbg/util.py,winappdbg.util.Regenerator,"class Regenerator(object):
    """"""
    Calls a generator and iterates it. When it's finished iterating, the
    generator is called again. This allows you to iterate a generator more
    than once (well, sort of).
    """"""

    def __init__(self, g_function, *v_args, **d_args):
        """"""
        @type  g_function: function
        @param g_function: Function that when called returns a generator.

        @type  v_args: tuple
        @param v_args: Variable arguments to pass to the generator function.

        @type  d_args: dict
        @param d_args: Variable arguments to pass to the generator function.
        """"""
        self.__g_function = g_function
        self.__v_args = v_args
        self.__d_args = d_args
        self.__g_object = None

    def __iter__(self):
        ""x.__iter__() <==> iter(x)""
        return self

    def next(self):
        ""x.next() -> the next value, or raise StopIteration""
        if self.__g_object is None:
            self.__g_object = self.__g_function(*self.__v_args, **self.__d_args)
        try:
            return self.__g_object.next()
        except StopIteration:
            self.__g_object = None
            raise","class Regenerator(object):
    '''
    Calls a generator and iterates it. When it's finished iterating, the
    generator is called again. This allows you to iterate a generator more
    than once (well, sort of).
    '''

    def __init__(self, g_function, *v_args, **d_args):
    '''
        @type  g_function: function
        @param g_function: Function that when called returns a generator.

        @type  v_args: tuple
        @param v_args: Variable arguments to pass to the generator function.

        @type  d_args: dict
        @param d_args: Variable arguments to pass to the generator function.
        '''
        pass

    def __iter__(self):
    '''x.__iter__() <==> iter(x)'''
        pass

    def next(self):
    '''x.next() -> the next value, or raise StopIteration'''
        pass

",4,4,snippet_640,0.625,"class Regenerator(object):
    '''
    Calls a generator and iterates it. When it's finished iterating, the
    generator is called again. This allows you to iterate a generator more
    than once (well, sort of).
    '''

    def __init__(self, g_function, *v_args, **d_args):
        '''
            @type  g_function: function
            @param g_function: Function that when called returns a generator.

            @type  v_args: tuple
            @param v_args: Variable arguments to pass to the generator function.

            @type  d_args: dict
            @param d_args: Variable arguments to pass to the generator function.
        '''
        self._g_function = g_function
        self._v_args = v_args
        self._d_args = d_args
        self._reset()

    def _reset(self):
        self._generator = self._g_function(*self._v_args, **self._d_args)

    def __iter__(self):
        '''x.__iter__() <==> iter(x)'''
        return self

    def next(self):
        '''x.next() -> the next value, or raise StopIteration'''
        try:
            return next(self._generator)
        except StopIteration:
            self._reset()
            return next(self._generator)

    __next__ = next","class Regenerator(object):
    '''
    Calls a generator and iterates it. When it's finished iterating, the
    generator is called again. This allows you to iterate a generator more
    than once (well, sort of).
    '''

    def __init__(self, g_function, *v_args, **d_args):
        '''
        @type  g_function: function
        @param g_function: Function that when called returns a generator.

        @type  v_args: tuple
        @param v_args: Variable arguments to pass to the generator function.

        @type  d_args: dict
        @param d_args: Variable arguments to pass to the generator function.
        '''
        self.g_function = g_function
        self.v_args = v_args
        self.d_args = d_args
        self.generator = None

    def __iter__(self):
        '''x.__iter__() <==> iter(x)'''
        return self

    def next(self):
        '''x.next() -> the next value, or raise StopIteration'''
        if self.generator is None:
            self.generator = self.g_function(*self.v_args, **self.d_args)
        
        try:
            return next(self.generator)
        except StopIteration:
            self.generator = None
            raise

    def __next__(self):
        '''Python 3 compatibility'''
        return self.next()","class Regenerator(object):
    '''
    Calls a generator and iterates it. When it's finished iterating, the
    generator is called again. This allows you to iterate a generator more
    than once (well, sort of).
    '''

    def __init__(self, g_function, *v_args, **d_args):
        '''
        @type  g_function: function
        @param g_function: Function that when called returns a generator.

        @type  v_args: tuple
        @param v_args: Variable arguments to pass to the generator function.

        @type  d_args: dict
        @param d_args: Variable arguments to pass to the generator function.
        '''
        self.g_function = g_function
        self.v_args = v_args
        self.d_args = d_args
        self.generator = None

    def __iter__(self):
        '''x.__iter__() <==> iter(x)'''
        return self

    def next(self):
        '''x.next() -> the next value, or raise StopIteration'''
        if self.generator is None:
            self.generator = self.g_function(*self.v_args, **self.d_args)
        
        try:
            return next(self.generator)
        except StopIteration:
            self.generator = self.g_function(*self.v_args, **self.d_args)
            return next(self.generator)",full_docstr,0.9084967320261438,0.8552631578947368,0.8278145695364238,0.8366013071895425,0.7774238619608042,0.9041095890410958,0.8419243986254296,0.7586206896551724,0.9550748467445374,0.9519513845443726,0.9535105228424072,0.9522628784179688,0.833335,0.9235668789808916,0.8846153846153846,0.8451612903225806,0.9171974522292995,0.7579856058789498,0.9059233449477352,0.8321678321678322,0.7508771929824561,0.9635648131370544,0.9782669544219971,0.9708601832389832,0.976776659488678,0.9494954545454545,0.9113924050632912,0.8726114649681528,0.8397435897435896,0.9050632911392404,0.7462703505673195,0.8775510204081632,0.7918088737201365,0.7191780821917808,0.9640305042266846,0.9743229150772095,0.9691493511199951,0.9732837677001953,0.9402991044776119,0.6907899192439008,0.6467691487341809,0.6410658529167469,0.6181818181818182,0.8571428571428571,0.6722310495215335,0.6402623069470249,0.6876229301001479,0.8181818181818182,0.5428571428571428,0.6541976437044735,0.6569528100417575,0.6715260764644484,0.7454545454545455,0.5428571428571428
217190,aheadley/python-crunchyroll,aheadley_python-crunchyroll/crunchyroll/subtitles.py,crunchyroll.subtitles.SubtitleFormatter,"class SubtitleFormatter(object):
    """"""Base subtitle formatter class
    """"""

    def format(self, subtitles):
        """"""Turn a string containing the subs xml document into the formatted
        subtitle string

        @param str|crunchyroll.models.StyledSubtitle sub_xml_text
        @return str
        """"""
        logger.debug('Formatting subtitles (id=%s) with %s',
            subtitles.id, self.__class__.__name__)
        return self._format(subtitles).encode('utf-8')

    def _format(self, styled_subtitle):
        """"""Do the actual formatting on the parsed xml document, should be
        overridden by subclasses

        @param crunchyroll.models.StyledSubtitle styled_subtitle
        @return str
        """"""
        raise NotImplemented","class SubtitleFormatter(object):
    '''Base subtitle formatter class
    '''

    def format(self, subtitles):
    '''Turn a string containing the subs xml document into the formatted
        subtitle string

        @param str|crunchyroll.models.StyledSubtitle sub_xml_text
        @return str
        '''
        pass

    def _format(self, styled_subtitle):
    '''Do the actual formatting on the parsed xml document, should be
        overridden by subclasses

        @param crunchyroll.models.StyledSubtitle styled_subtitle
        @return str
        '''
        pass

",3,3,snippet_307,0.75,"class SubtitleFormatter(object):
    '''Base subtitle formatter class
    '''

    def format(self, subtitles):
        '''Turn a string containing the subs xml document into the formatted
        subtitle string

        @param str|crunchyroll.models.StyledSubtitle sub_xml_text
        @return str
        '''
        if isinstance(subtitles, StyledSubtitle):
            styled = subtitles
        elif isinstance(subtitles, str):
            styled = StyledSubtitle.from_string(subtitles)
        else:
            raise TypeError(
                ""subtitles must be a StyledSubtitle or XML string""
            )
        return self._format(styled)

    def _format(self, styled_subtitle):
        '''Do the actual formatting on the parsed xml document, should be
        overridden by subclasses

        @param crunchyroll.models.StyledSubtitle styled_subtitle
        @return str
        '''
        raise NotImplementedError(""Subclasses must implement _format()"")","class SubtitleFormatter(object):
    '''Base subtitle formatter class
    '''

    def format(self, subtitles):
        '''Turn a string containing the subs xml document into the formatted
        subtitle string

        @param str|crunchyroll.models.StyledSubtitle sub_xml_text
        @return str
        '''
        if hasattr(subtitles, 'xml_text'):
            # Assume it's a StyledSubtitle object
            return self._format(subtitles)
        else:
            # Assume it's a string containing XML text
            from crunchyroll.models import StyledSubtitle
            styled_subtitle = StyledSubtitle(subtitles)
            return self._format(styled_subtitle)

    def _format(self, styled_subtitle):
        '''Do the actual formatting on the parsed xml document, should be
        overridden by subclasses

        @param crunchyroll.models.StyledSubtitle styled_subtitle
        @return str
        '''
        raise NotImplementedError(""Subclasses must implement _format method"")","class SubtitleFormatter(object):
    '''Base subtitle formatter class
    '''

    def format(self, subtitles):
        '''Turn a string containing the subs xml document into the formatted
        subtitle string

        @param str|crunchyroll.models.StyledSubtitle sub_xml_text
        @return str
        '''
        if isinstance(subtitles, str):
            from crunchyroll.models import StyledSubtitle
            styled_subtitle = StyledSubtitle(subtitles)
        else:
            styled_subtitle = subtitles
        
        return self._format(styled_subtitle)

    def _format(self, styled_subtitle):
        '''Do the actual formatting on the parsed xml document, should be
        overridden by subclasses

        @param crunchyroll.models.StyledSubtitle styled_subtitle
        @return str
        '''
        raise NotImplementedError(""Subclasses must implement _format method"")",full_docstr,0.7555555555555555,0.6966292134831461,0.6704545454545455,0.7444444444444445,0.5922134195765786,0.7133757961783439,0.5641025641025641,0.5161290322580645,0.9095619916915894,0.9190518856048584,0.9142822623252869,0.9180939197540283,0.8352957647058824,0.7513227513227513,0.6737967914438503,0.6486486486486486,0.7301587301587301,0.5900281652657813,0.7080745341614907,0.5625,0.5157232704402516,0.9126068353652954,0.9240682721138,0.9183017611503601,0.922909140586853,0.841465,0.7861271676300577,0.7251461988304092,0.6982248520710058,0.7745664739884394,0.5909761323347803,0.7816901408450704,0.6170212765957447,0.5642857142857143,0.9359408617019653,0.9241673946380615,0.9300168752670288,0.9253313541412354,0.8333349999999999,0.5727031427081175,0.4575267690493614,0.6110635795608863,0.4444444444444444,0.7777777777777778,0.6218201082829641,0.4338759294245357,0.6089600592628762,0.4444444444444444,1.0,0.6146832185411444,0.5143359612703583,0.6110635795608863,0.4444444444444444,0.8888888888888888
129217,IRC-SPHERE/HyperStream,IRC-SPHERE_HyperStream/hyperstream/workflow/workflow.py,hyperstream.workflow.workflow.WorkflowMonitor,"class WorkflowMonitor(object):
    """"""
    Small helper class that provides logging output to monitor workflow progress
    """"""

    def __init__(self, workflow):
        """"""
        Initialise the workflow monitor

        :type workflow: Workflow
        """"""
        self.monitor = workflow.monitor
        self.name = workflow.name

    def __enter__(self):
        """"""
        Entry point - called when workflow computation starts

        :return: self
        """"""
        if self.monitor:
            try:
                logging.monitor(self.name, extra=dict(n=""workflow_start""))
            except AttributeError:
                pass
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """"""
        Exit point - called when workflow computation ends

        :param exc_type: exception type
        :param exc_val: exception value
        :param exc_tb: exception traceback
        :return: self
        """"""
        if self.monitor:
            try:
                logging.monitor(self.name, extra=dict(n=""workflow_end""))
            except AttributeError:
                pass

        # Re-raise any other errors
        return exc_val is None","class WorkflowMonitor(object):
    '''
    Small helper class that provides logging output to monitor workflow progress
    '''

    def __init__(self, workflow):
    '''
        Initialise the workflow monitor

        :type workflow: Workflow
        '''
        pass

    def __enter__(self):
    '''
        Entry point - called when workflow computation starts

        :return: self
        '''
        pass

    def __exit__(self, exc_type, exc_val, exc_tb):
    '''
        Exit point - called when workflow computation ends

        :param exc_type: exception type
        :param exc_val: exception value
        :param exc_tb: exception traceback
        :return: self
        '''
        pass

",4,4,snippet_145,0.2727272727272727,"class WorkflowMonitor(object):
    '''
    Small helper class that provides logging output to monitor workflow progress
    '''

    def __init__(self, workflow):
        '''
        Initialise the workflow monitor

        :type workflow: Workflow
        '''
        self.workflow = workflow
        self.logger = logging.getLogger(workflow.__class__.__name__)
        self.start_time = None

    def __enter__(self):
        '''
        Entry point - called when workflow computation starts

        :return: self
        '''
        self.start_time = time.time()
        name = getattr(self.workflow, 'name', repr(self.workflow))
        self.logger.info(f""Starting workflow: {name}"")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        '''
        Exit point - called when workflow computation ends

        :param exc_type: exception type
        :param exc_val: exception value
        :param exc_tb: exception traceback
        :return: False (so exceptions are propagated)
        '''
        elapsed = time.time() - (self.start_time or time.time())
        name = getattr(self.workflow, 'name', repr(self.workflow))
        if exc_type:
            self.logger.exception(f""Workflow {name} failed after {elapsed:.2f}s"")
        else:
            self.logger.info(f""Workflow {name} completed in {elapsed:.2f}s"")
        return False","class WorkflowMonitor(object):
    '''
    Small helper class that provides logging output to monitor workflow progress
    '''

    def __init__(self, workflow):
        '''
        Initialise the workflow monitor

        :type workflow: Workflow
        '''
        self.workflow = workflow
        self.logger = workflow.logger if hasattr(workflow, 'logger') else None

    def __enter__(self):
        '''
        Entry point - called when workflow computation starts

        :return: self
        '''
        if self.logger:
            self.logger.info(f""Starting workflow: {self.workflow}"")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        '''
        Exit point - called when workflow computation ends

        :param exc_type: exception type
        :param exc_val: exception value
        :param exc_tb: exception traceback
        :return: self
        '''
        if exc_type is None:
            if self.logger:
                self.logger.info(f""Workflow completed successfully: {self.workflow}"")
        else:
            if self.logger:
                self.logger.error(f""Workflow failed: {self.workflow}"", exc_info=(exc_type, exc_val, exc_tb))
        return self","class WorkflowMonitor(object):
    '''
    Small helper class that provides logging output to monitor workflow progress
    '''

    def __init__(self, workflow):
        '''
        Initialise the workflow monitor

        :type workflow: Workflow
        '''
        self.workflow = workflow
        self.start_time = None
        self.logger = logging.getLogger(__name__)

    def __enter__(self):
        '''
        Entry point - called when workflow computation starts

        :return: self
        '''
        self.start_time = time.time()
        self.logger.info(f""Starting workflow: {self.workflow}"")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        '''
        Exit point - called when workflow computation ends

        :param exc_type: exception type
        :param exc_val: exception value
        :param exc_tb: exception traceback
        :return: self
        '''
        end_time = time.time()
        duration = end_time - self.start_time if self.start_time else 0
        
        if exc_type is None:
            self.logger.info(f""Workflow completed successfully in {duration:.2f} seconds: {self.workflow}"")
        else:
            self.logger.error(f""Workflow failed after {duration:.2f} seconds: {self.workflow} - {exc_type.__name__}: {exc_val}"")
        
        return False",full_docstr,0.6642599277978339,0.509090909090909,0.4835164835164835,0.6209386281588447,0.4446425099748795,0.5915032679738562,0.4262295081967213,0.34868421052631576,0.8394874930381775,0.8920043706893921,0.8649495244026184,0.8864588737487793,0.7950020499999999,0.6926070038910506,0.596078431372549,0.5533596837944664,0.6692607003891051,0.5468205729828367,0.7068273092369478,0.5241935483870968,0.44129554655870445,0.8953304886817932,0.8876327276229858,0.8914649486541748,0.8883965611457825,0.8187937583892617,0.6886446886446886,0.5461254612546126,0.5055762081784386,0.6227106227106227,0.46155170697062836,0.6190476190476191,0.4334470989761092,0.3664383561643836,0.8535103797912598,0.8868038654327393,0.8698386549949646,0.8833580613136292,0.7950212068965516,0.4514766362481641,0.4264620984735239,0.5078758190681522,0.2833333333333333,0.5882352941176471,0.5294337166390831,0.4949932216023153,0.5286239978951934,0.3,0.7941176470588235,0.4636310776855348,0.4415865873567499,0.5286239978951934,0.2666666666666666,0.6176470588235294
307778,cltk/cltk,src/cltk/text/akk.py,cltk.text.akk.ATFConverter,"class ATFConverter:  # pylint: disable=too-few-public-methods
    """"""Class to convert tokens to unicode.

    Transliterates ATF data from CDLI into readable unicode.
        sz = 
        s, = 
        t, = 
        ' = 
        Sign values for 2-3 take accent aigu and accent grave standards,
        otherwise signs are printed as subscript.

    For in depth reading on ATF-formatting for CDLI and ORACC:
        Oracc ATF Primer = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/index.html
        ATF Structure = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/structuretutorial/index.html
        ATF Inline = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/inlinetutorial/index.html
    """"""

    def __init__(self, two_three: bool = True):
        """"""
        :param two_three: turns on or off accent marking.
        """"""

        self.two_three: bool = two_three

    def _convert_num(self, sign: str) -> str:
        """"""
        Converts number registered in get_number_from_sign.
        """"""

        # Check if there's a number at the end
        new_sign, num = _get_number_from_sign(sign)
        if num < 2:  # ""ab"" -> ""ab""
            return new_sign.replace(str(num), _convert_number_to_subscript(num))
        if num > 3:  # ""buru14"" -> ""buru""
            return new_sign.replace(str(num), _convert_number_to_subscript(num))
        if self.two_three:  # pylint: disable=no-else-return
            return new_sign.replace(str(num), _convert_number_to_subscript(num))
        else:
            # ""bad3"" -> ""bd""
            for i, character in enumerate(new_sign):
                new_vowel = """"
                if character in VOWELS:
                    if num == 2:
                        # noinspection PyUnusedLocal
                        new_vowel = character + chr(0x0301)
                    elif num == 3:
                        new_vowel = character + chr(0x0300)
                    break
            return (
                new_sign[:i]
                + normalize(""NFC"", new_vowel)
                + new_sign[i + 1 :].replace(str(num), """")
            )

    def process(self, tokens: list[str]) -> list[str]:
        """"""
        Expects a list of tokens, will return the list converted from ATF
        format to print-format.

        >>> c = ATFConverter()
        >>> c.process([""a"", ""a2"", ""a3"", ""geme2"", ""bad3"", ""buru14""])
        ['a', 'a', 'a', 'geme', 'bad', 'buru']
        """"""

        return [self._convert_num(_convert_consonant(token)) for token in tokens]","class ATFConverter:
    '''Class to convert tokens to unicode.

    Transliterates ATF data from CDLI into readable unicode.
        sz = 
        s, = 
        t, = 
        ' = 
        Sign values for 2-3 take accent aigu and accent grave standards,
        otherwise signs are printed as subscript.

    For in depth reading on ATF-formatting for CDLI and ORACC:
        Oracc ATF Primer = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/index.html
        ATF Structure = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/structuretutorial/index.html
        ATF Inline = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/inlinetutorial/index.html
    '''

    def __init__(self, two_three: bool = True):
    '''
        :param two_three: turns on or off accent marking.
        '''
        pass

    def _convert_num(self, sign: str) -> str:
    '''
        Converts number registered in get_number_from_sign.
        '''
        pass

    def process(self, tokens: list[str]) -> list[str]:
    '''
        Expects a list of tokens, will return the list converted from ATF
        format to print-format.

        >>> c = ATFConverter()
        >>> c.process([""a"", ""a2"", ""a3"", ""geme2"", ""bad3"", ""buru14""])
        ['a', 'a', 'a', 'geme', 'bad', 'buru']
        '''
        pass

",4,4,snippet_515,0.3,"class ATFConverter:
    '''Class to convert tokens to unicode.

    Transliterates ATF data from CDLI into readable unicode.
        sz = 
        s, = 
        t, = 
        ' = 
        Sign values for 2-3 take accent aigu and accent grave standards,
        otherwise signs are printed as subscript.

    For in depth reading on ATF-formatting for CDLI and ORACC:
        Oracc ATF Primer = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/index.html
        ATF Structure = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/structuretutorial/index.html
        ATF Inline = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/inlinetutorial/index.html
    '''

    _subscript_digits = {
        '0': '', '1': '', '2': '', '3': '',
        '4': '', '5': '', '6': '', '7': '',
        '8': '', '9': ''
    }
    _accent_map = {
        '2': '\u0301',  # combining acute
        '3': '\u0300'   # combining grave
    }

    def __init__(self, two_three: bool = True):
        '''
        :param two_three: turns on or off accent marking.
        '''
        self.two_three = two_three

    def _convert_num(self, sign: str) -> str:
        '''
        Converts number registered in get_number_from_sign.
        '''
        # If accent mapping is enabled for 2/3, use combining accent
        if not self.two_three and sign in ('2', '3'):
            return self._accent_map[sign]
        # Otherwise, map each digit to its subscript equivalent
        return ''.join(self._subscript_digits.get(d, '') for d in sign)

    def process(self, tokens: list[str]) -> list[str]:
        '''
        Expects a list of tokens, will return the list converted from ATF
        format to print-format.

        >>> c = ATFConverter()
        >>> c.process([""a"", ""a2"", ""a3"", ""geme2"", ""bad3"", ""buru14""])
        ['a', 'a', 'a', 'geme', 'bad', 'buru']
        '''
        out = []
        num_re = re.compile(r'(\d+)$')
        for tok in tokens:
            m = num_re.search(tok)
            if m:
                base, num = tok[:m.start()], m.group(1)
            else:
                base, num = tok, None
            # transliterate base
            base = base.replace('sz', '')
            base = base.replace('s,', '')
            base = base.replace('t,', '')
            base = base.replace(""'"", '')
            if num:
                suffix = self._convert_num(num)
                out.append(base + suffix)
            else:
                out.append(base)
        return out","class ATFConverter:
    '''Class to convert tokens to unicode.

    Transliterates ATF data from CDLI into readable unicode.
        sz = 
        s, = 
        t, = 
        ' = 
        Sign values for 2-3 take accent aigu and accent grave standards,
        otherwise signs are printed as subscript.

    For in depth reading on ATF-formatting for CDLI and ORACC:
        Oracc ATF Primer = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/index.html
        ATF Structure = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/structuretutorial/index.html
        ATF Inline = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/inlinetutorial/index.html
    '''

    def __init__(self, two_three: bool = True):
        '''
        :param two_three: turns on or off accent marking.
        '''
        self.two_three = two_three
        self.replacements = {
            'sz': '',
            's,': '',
            't,': '',
            ""'"": ''
        }

    def _convert_num(self, sign: str) -> str:
        '''
        Converts number registered in get_number_from_sign.
        '''
        if not sign:
            return ''
        
        num = int(sign)
        if self.two_three:
            if num == 2:
                return ''  # Combining acute accent
            elif num == 3:
                return ''  # Combining grave accent
        
        # Convert to subscript numbers
        subscript_map = {
            '0': '', '1': '', '2': '', '3': '', '4': '',
            '5': '', '6': '', '7': '', '8': '', '9': ''
        }
        return ''.join(subscript_map.get(digit, digit) for digit in str(num))

    def process(self, tokens: list[str]) -> list[str]:
        '''
        Expects a list of tokens, will return the list converted from ATF
        format to print-format.

        >>> c = ATFConverter()
        >>> c.process([""a"", ""a2"", ""a3"", ""geme2"", ""bad3"", ""buru14""])
        ['a', 'a', 'a', 'geme', 'bad', 'buru']
        '''
        import re
        
        result = []
        
        for token in tokens:
            # Apply character replacements first
            converted_token = token
            for atf_char, unicode_char in self.replacements.items():
                converted_token = converted_token.replace(atf_char, unicode_char)
            
            # Handle numbers in the token
            # Find all sequences of digits
            def replace_numbers(match):
                number = match.group()
                return self._convert_num(number)
            
            # Replace digits that are not part of a larger alphanumeric sequence
            # This regex looks for digits that may be at the beginning, middle, or end
            converted_token = re.sub(r'\d+', replace_numbers, converted_token)
            
            result.append(converted_token)
        
        return result","class ATFConverter:
    '''Class to convert tokens to unicode.

    Transliterates ATF data from CDLI into readable unicode.
        sz = 
        s, = 
        t, = 
        ' = 
        Sign values for 2-3 take accent aigu and accent grave standards,
        otherwise signs are printed as subscript.

    For in depth reading on ATF-formatting for CDLI and ORACC:
        Oracc ATF Primer = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/index.html
        ATF Structure = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/structuretutorial/index.html
        ATF Inline = http://oracc.museum.upenn.edu/doc/help/editinginatf/
        primer/inlinetutorial/index.html
    '''

    def __init__(self, two_three: bool = True):
        '''
        :param two_three: turns on or off accent marking.
        '''
        self.two_three = two_three
        self.char_map = {
            'sz': '',
            's,': '',
            't,': '',
            ""'"": ''
        }
        self.subscript_map = {
            '0': '', '1': '', '2': '', '3': '', '4': '',
            '5': '', '6': '', '7': '', '8': '', '9': ''
        }
        self.accent_map = {
            '2': '',
            '3': ''
        }

    def _convert_num(self, sign: str) -> str:
        '''
        Converts number registered in get_number_from_sign.
        '''
        match = re.search(r'(\d+)$', sign)
        if not match:
            return sign
        
        number = match.group(1)
        base = sign[:-len(number)]
        
        if self.two_three and number in ['2', '3'] and len(number) == 1:
            if base.endswith('a'):
                return base[:-1] + self.accent_map[number]
            else:
                return base + ''.join(self.subscript_map[d] for d in number)
        else:
            return base + ''.join(self.subscript_map[d] for d in number)

    def process(self, tokens: list[str]) -> list[str]:
        '''
        Expects a list of tokens, will return the list converted from ATF
        format to print-format.

        >>> c = ATFConverter()
        >>> c.process([""a"", ""a2"", ""a3"", ""geme2"", ""bad3"", ""buru14""])
        ['a', 'a', 'a', 'geme', 'bad', 'buru']
        '''
        result = []
        for token in tokens:
            converted = token
            
            # Apply character mappings
            for atf_char, unicode_char in self.char_map.items():
                converted = converted.replace(atf_char, unicode_char)
            
            # Convert numbers
            converted = self._convert_num(converted)
            
            result.append(converted)
        
        return result",full_docstr,0.7043189368770764,0.5666666666666667,0.5284280936454849,0.6146179401993356,0.5819295475281278,0.7260726072607261,0.5537190082644629,0.5049668874172185,0.8799999952316284,0.8734809160232544,0.876728355884552,0.8741284608840942,0.7195661964735518,0.7094703049759229,0.5797101449275361,0.5363489499192245,0.6163723916532905,0.5917861832729004,0.7201309328968903,0.5573770491803278,0.5188834154351396,0.8944834470748901,0.8851218223571777,0.8897780179977417,0.886049211025238,0.7154958028169017,0.7066666666666668,0.5752508361204014,0.5402684563758389,0.6266666666666667,0.5708365244870104,0.7100494233937397,0.5379537953795379,0.4991735537190083,0.8989778757095337,0.8795706033706665,0.8891683220863342,0.8814734816551208,0.7257308980582521,0.3719344094915213,0.4675243908830118,0.5287257918859409,0.3387096774193548,0.1527777777777778,0.4443376846751826,0.4477057239426746,0.5550034376971238,0.4274193548387097,0.3472222222222222,0.4316947971146027,0.4770450505169439,0.5306481164360903,0.4274193548387097,0.2916666666666667
318415,cqlengine/cqlengine,cqlengine_cqlengine/cqlengine/models.py,cqlengine.models.ColumnDescriptor,"class ColumnDescriptor(object):
    """"""
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    """"""

    def __init__(self, column):
        """"""
        :param column:
        :type column: columns.Column
        :return:
        """"""
        self.column = column
        self.query_evaluator = ColumnQueryEvaluator(self.column)

    def __get__(self, instance, owner):
        """"""
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        """"""
        try:
            return instance._values[self.column.column_name].getval()
        except AttributeError as e:
            return self.query_evaluator

    def __set__(self, instance, value):
        """"""
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        """"""
        if instance:
            return instance._values[self.column.column_name].setval(value)
        else:
            raise AttributeError('cannot reassign column values')

    def __delete__(self, instance):
        """"""
        Sets the column value to None, if possible
        """"""
        if instance:
            if self.column.can_delete:
                instance._values[self.column.column_name].delval()
            else:
                raise AttributeError('cannot delete {} columns'.format(self.column.column_name))","class ColumnDescriptor(object):
    '''
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    '''

    def __init__(self, column):
    '''
        :param column:
        :type column: columns.Column
        :return:
        '''
        pass

    def __get__(self, instance, owner):
    '''
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        '''
        pass

    def __set__(self, instance, value):
    '''
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        '''
        pass

    def __delete__(self, instance):
    '''
        Sets the column value to None, if possible
        '''
        pass

",5,5,snippet_560,0.2727272727272727,"class ColumnDescriptor(object):
    """"""
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    """"""
    def __init__(self, column):
        """"""
        :param column:
        :type column: columns.Column
        """"""
        self.column = column
        self.name = column.name

    def __get__(self, instance, owner):
        """"""
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        """"""
        if instance is None:
            return self.column
        values = getattr(instance, '_values', None)
        if values is None:
            raise AttributeError(""Instance has no value manager"")
        return values.get(self.name, self.column.default)

    def __set__(self, instance, value):
        """"""
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        """"""
        if instance is None:
            raise AttributeError(""Cannot set value on class"")
        if getattr(self.column, 'read_only', False) and self.name in getattr(instance, '_values', {}):
            raise AttributeError(""Column '%s' is read-only"" % self.name)
        if not hasattr(instance, '_values'):
            setattr(instance, '_values', {})
        instance._values[self.name] = value

    def __delete__(self, instance):
        """"""
        Sets the column value to None, if possible
        """"""
        if instance is None:
            raise AttributeError(""Cannot delete column on class"")
        if getattr(self.column, 'read_only', False):
            raise AttributeError(""Column '%s' is read-only"" % self.name)
        if not getattr(self.column, 'nullable', True):
            raise AttributeError(""Column '%s' is not nullable"" % self.name)
        if not hasattr(instance, '_values'):
            setattr(instance, '_values', {})
        instance._values[self.name] = None","class ColumnDescriptor(object):
    '''
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    '''

    def __init__(self, column):
        '''
        :param column:
        :type column: columns.Column
        :return:
        '''
        self.column = column

    def __get__(self, instance, owner):
        '''
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        '''
        if instance is None:
            return self.column
        return instance._values[self.column.name]

    def __set__(self, instance, value):
        '''
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        '''
        if instance is None:
            raise AttributeError(""Cannot set column value on class"")
        instance._values[self.column.name] = value

    def __delete__(self, instance):
        '''
        Sets the column value to None, if possible
        '''
        if instance is None:
            raise AttributeError(""Cannot delete column value on class"")
        instance._values[self.column.name] = None","class ColumnDescriptor(object):
    '''
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    '''

    def __init__(self, column):
        '''
        :param column:
        :type column: columns.Column
        :return:
        '''
        self.column = column

    def __get__(self, instance, owner):
        '''
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        '''
        if instance is None:
            return self.column
        return instance._values.get(self.column.column_name)

    def __set__(self, instance, value):
        '''
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        '''
        if instance is None:
            raise AttributeError(""Cannot set attribute on class"")
        instance._values[self.column.column_name] = value

    def __delete__(self, instance):
        '''
        Sets the column value to None, if possible
        '''
        if instance is None:
            raise AttributeError(""Cannot delete attribute on class"")
        instance._values[self.column.column_name] = None",full_docstr,0.7201946472019465,0.5916870415647921,0.5110565110565111,0.6374695863746959,0.5294531723775778,0.6325167037861915,0.5066964285714286,0.46308724832214765,0.8819710612297058,0.9194806218147278,0.9003353118896484,0.9155867695808411,0.7755353535353535,0.8544891640866873,0.778816199376947,0.6959247648902821,0.7863777089783281,0.5897110236350973,0.888,0.7550200803212851,0.6693548387096774,0.9507836103439331,0.9146876931190491,0.9323864579200745,0.9181734919548035,0.8148166666666665,0.8553846153846153,0.7863777089783281,0.7165109034267914,0.7999999999999999,0.6201070580094347,0.88671875,0.7725490196078432,0.6968503937007874,0.9500831365585327,0.9183011651039124,0.9339218139648438,0.9213833808898926,0.8109180701754386,0.5942585618563196,0.4807265808742632,0.7438686421607716,0.4024390243902439,0.75,0.4956799392875365,0.5783907378439327,0.6016682654259472,0.4390243902439024,0.3636363636363636,0.5002760473117502,0.5853080206055166,0.6009402928099989,0.4512195121951219,0.3636363636363636
253114,aws/sagemaker-python-sdk,aws_sagemaker-python-sdk/src/sagemaker/experiments/_helper.py,sagemaker.experiments._helper._LineageArtifactTracker,"class _LineageArtifactTracker(object):
    """"""Lineage Artifact Tracker""""""

    def __init__(self, trial_component_arn, sagemaker_session):
        """"""Initialize a `_LineageArtifactTracker` instance.

        Args:
            trial_component_arn (str): The ARN of the trial component to be
                associated with the input/output artifacts.
            sagemaker_session (sagemaker.session.Session): Session object which
                manages interactions with Amazon SageMaker APIs and any other
                AWS services needed.
        """"""
        self.trial_component_arn = trial_component_arn
        self.sagemaker_session = sagemaker_session
        self.artifacts = []

    def add_input_artifact(self, name, source_uri, etag, artifact_type):
        """"""Add a Lineage input artifact locally

        Args:
            name (str): The name of the Lineage input artifact to be added.
            source_uri (str): The source URI used to create the Lineage input artifact.
            etag (str): The S3 Etag used to create the Lineage input artifact.
            artifact_type (str): The type of the Lineage input artifact.
        """"""
        artifact = _LineageArtifactManager(
            name, source_uri, etag, dest_arn=self.trial_component_arn, artifact_type=artifact_type
        )
        self.artifacts.append(artifact)

    def add_output_artifact(self, name, source_uri, etag, artifact_type):
        """"""Add a Lineage output artifact locally

        Args:
            name (str): The name of the Lineage output artifact to be added.
            source_uri (str): The source URI used to create the Lineage output artifact.
            etag (str): The S3 Etag used to create the Lineage output artifact.
            artifact_type (str): The type of the Lineage output artifact.
        """"""
        artifact = _LineageArtifactManager(
            name, source_uri, etag, source_arn=self.trial_component_arn, artifact_type=artifact_type
        )
        self.artifacts.append(artifact)

    def save(self):
        """"""Persist any artifact data saved locally""""""
        for artifact in self.artifacts:
            artifact.create_artifact(self.sagemaker_session)
            artifact.add_association(self.sagemaker_session)","class _LineageArtifactTracker(object):
    '''Lineage Artifact Tracker'''

    def __init__(self, trial_component_arn, sagemaker_session):
    '''Initialize a `_LineageArtifactTracker` instance.

        Args:
            trial_component_arn (str): The ARN of the trial component to be
                associated with the input/output artifacts.
            sagemaker_session (sagemaker.session.Session): Session object which
                manages interactions with Amazon SageMaker APIs and any other
                AWS services needed.
        '''
        pass

    def add_input_artifact(self, name, source_uri, etag, artifact_type):
    '''Add a Lineage input artifact locally

        Args:
            name (str): The name of the Lineage input artifact to be added.
            source_uri (str): The source URI used to create the Lineage input artifact.
            etag (str): The S3 Etag used to create the Lineage input artifact.
            artifact_type (str): The type of the Lineage input artifact.
        '''
        pass

    def add_output_artifact(self, name, source_uri, etag, artifact_type):
    '''Add a Lineage output artifact locally

        Args:
            name (str): The name of the Lineage output artifact to be added.
            source_uri (str): The source URI used to create the Lineage output artifact.
            etag (str): The S3 Etag used to create the Lineage output artifact.
            artifact_type (str): The type of the Lineage output artifact.
        '''
        pass

    def save(self):
    '''Persist any artifact data saved locally'''
        pass

",5,5,snippet_401,0.8571428571428571,"class _LineageArtifactTracker(object):
    '''Lineage Artifact Tracker'''

    def __init__(self, trial_component_arn, sagemaker_session):
        self.trial_component_arn = trial_component_arn
        self.sagemaker_session = sagemaker_session
        self._input_artifacts = []
        self._output_artifacts = []

    def add_input_artifact(self, name, source_uri, etag, artifact_type):
        self._input_artifacts.append({
            'Name': name,
            'SourceUri': source_uri,
            'Etag': etag,
            'ArtifactType': artifact_type
        })

    def add_output_artifact(self, name, source_uri, etag, artifact_type):
        self._output_artifacts.append({
            'Name': name,
            'SourceUri': source_uri,
            'Etag': etag,
            'ArtifactType': artifact_type
        })

    def save(self):
        # save input artifacts
        for art in self._input_artifacts:
            src = {
                'SourceUri': art['SourceUri'],
                'S3Uri': art['SourceUri'],
                'S3ExecutionContext': {'Etag': art['Etag']}
            }
            art_arn = self.sagemaker_session.create_artifact(
                artifact_name=art['Name'],
                artifact_type=art['ArtifactType'],
                source=src,
                properties={}
            )
            self.sagemaker_session.add_association(
                source_arn=art_arn,
                destination_arn=self.trial_component_arn,
                association_type='ContributedTo'
            )

        # save output artifacts
        for art in self._output_artifacts:
            src = {
                'SourceUri': art['SourceUri'],
                'S3Uri': art['SourceUri'],
                'S3ExecutionContext': {'Etag': art['Etag']}
            }
            art_arn = self.sagemaker_session.create_artifact(
                artifact_name=art['Name'],
                artifact_type=art['ArtifactType'],
                source=src,
                properties={}
            )
            self.sagemaker_session.add_association(
                source_arn=self.trial_component_arn,
                destination_arn=art_arn,
                association_type='ContributedTo'
            )

        self._input_artifacts.clear()
        self._output_artifacts.clear()","class _LineageArtifactTracker(object):
    '''Lineage Artifact Tracker'''

    def __init__(self, trial_component_arn, sagemaker_session):
        '''Initialize a `_LineageArtifactTracker` instance.

        Args:
            trial_component_arn (str): The ARN of the trial component to be
                associated with the input/output artifacts.
            sagemaker_session (sagemaker.session.Session): Session object which
                manages interactions with Amazon SageMaker APIs and any other
                AWS services needed.
        '''
        self.trial_component_arn = trial_component_arn
        self.sagemaker_session = sagemaker_session
        self.input_artifacts = []
        self.output_artifacts = []

    def add_input_artifact(self, name, source_uri, etag, artifact_type):
        '''Add a Lineage input artifact locally

        Args:
            name (str): The name of the Lineage input artifact to be added.
            source_uri (str): The source URI used to create the Lineage input artifact.
            etag (str): The S3 Etag used to create the Lineage input artifact.
            artifact_type (str): The type of the Lineage input artifact.
        '''
        artifact = {
            'name': name,
            'source_uri': source_uri,
            'etag': etag,
            'artifact_type': artifact_type
        }
        self.input_artifacts.append(artifact)

    def add_output_artifact(self, name, source_uri, etag, artifact_type):
        '''Add a Lineage output artifact locally

        Args:
            name (str): The name of the Lineage output artifact to be added.
            source_uri (str): The source URI used to create the Lineage output artifact.
            etag (str): The S3 Etag used to create the Lineage output artifact.
            artifact_type (str): The type of the Lineage output artifact.
        '''
        artifact = {
            'name': name,
            'source_uri': source_uri,
            'etag': etag,
            'artifact_type': artifact_type
        }
        self.output_artifacts.append(artifact)

    def save(self):
        '''Persist any artifact data saved locally'''
        # Implementation would typically involve calling SageMaker APIs
        # to persist the artifacts and their associations with the trial component
        # This is a placeholder implementation
        pass","class _LineageArtifactTracker(object):
    '''Lineage Artifact Tracker'''

    def __init__(self, trial_component_arn, sagemaker_session):
        '''Initialize a `_LineageArtifactTracker` instance.

        Args:
            trial_component_arn (str): The ARN of the trial component to be
                associated with the input/output artifacts.
            sagemaker_session (sagemaker.session.Session): Session object which
                manages interactions with Amazon SageMaker APIs and any other
                AWS services needed.
        '''
        self.trial_component_arn = trial_component_arn
        self.sagemaker_session = sagemaker_session
        self.input_artifacts = []
        self.output_artifacts = []

    def add_input_artifact(self, name, source_uri, etag, artifact_type):
        '''Add a Lineage input artifact locally

        Args:
            name (str): The name of the Lineage input artifact to be added.
            source_uri (str): The source URI used to create the Lineage input artifact.
            etag (str): The S3 Etag used to create the Lineage input artifact.
            artifact_type (str): The type of the Lineage input artifact.
        '''
        artifact = {
            'name': name,
            'source_uri': source_uri,
            'etag': etag,
            'artifact_type': artifact_type
        }
        self.input_artifacts.append(artifact)

    def add_output_artifact(self, name, source_uri, etag, artifact_type):
        '''Add a Lineage output artifact locally

        Args:
            name (str): The name of the Lineage output artifact to be added.
            source_uri (str): The source URI used to create the Lineage output artifact.
            etag (str): The S3 Etag used to create the Lineage output artifact.
            artifact_type (str): The type of the Lineage output artifact.
        '''
        artifact = {
            'name': name,
            'source_uri': source_uri,
            'etag': etag,
            'artifact_type': artifact_type
        }
        self.output_artifacts.append(artifact)

    def save(self):
        '''Persist any artifact data saved locally'''
        for artifact in self.input_artifacts:
            self._create_artifact_and_association(artifact, 'input')
        
        for artifact in self.output_artifacts:
            self._create_artifact_and_association(artifact, 'output')
        
        self.input_artifacts.clear()
        self.output_artifacts.clear()

    def _create_artifact_and_association(self, artifact, association_type):
        try:
            artifact_arn = self.sagemaker_session.sagemaker_client.create_artifact(
                ArtifactName=artifact['name'],
                Source={
                    'SourceUri': artifact['source_uri'],
                    'SourceTypes': [
                        {
                            'SourceIdType': 'S3ETag',
                            'Value': artifact['etag']
                        }
                    ]
                },
                ArtifactType=artifact['artifact_type']
            )['ArtifactArn']
        except Exception:
            artifacts = self.sagemaker_session.sagemaker_client.list_artifacts(
                SourceUri=artifact['source_uri']
            )['ArtifactSummaries']
            
            if artifacts:
                artifact_arn = artifacts[0]['ArtifactArn']
            else:
                return

        association_type_mapping = {
            'input': 'ContributedTo',
            'output': 'Produced'
        }

        try:
            self.sagemaker_session.sagemaker_client.add_association(
                SourceArn=artifact_arn if association_type == 'input' else self.trial_component_arn,
                DestinationArn=self.trial_component_arn if association_type == 'input' else artifact_arn,
                AssociationType=association_type_mapping[association_type]
            )
        except Exception:
            pass",full_docstr,0.5720338983050848,0.34468085106382973,0.23931623931623933,0.3898305084745763,0.42527340515590795,0.6167800453514739,0.43863636363636366,0.33712984054669703,0.876647412776947,0.8322381973266602,0.8538657426834106,0.8364756107330322,0.7727722253521123,0.8946395563770794,0.8497217068645639,0.8193668528864061,0.876155268022181,0.7298866206111183,0.8535469107551488,0.7729357798165137,0.7195402298850575,0.951632022857666,0.9591162204742432,0.9553594589233398,0.9583625793457031,0.852762208588957,0.7987897125567323,0.7496206373292867,0.7001522070015221,0.762481089258699,0.5538068936739443,0.6054131054131054,0.5563480741797432,0.5042857142857143,0.9118927717208862,0.962856650352478,0.9366819858551025,0.9575053453445435,0.7725802709359612,0.3922308135803277,0.0856071851676232,0.1087128945505127,0.5079365079365079,0.8666666666666667,0.635104910764932,0.6684470425216054,0.7640360926016146,0.5079365079365079,0.6,0.6630602343436844,0.549765264704429,0.777872498067134,0.5079365079365079,0.8166666666666667
294139,clld/clldutils,clld_clldutils/src/clldutils/misc.py,clldutils.misc.UnicodeMixin,"class UnicodeMixin(object):
    """"""Portable label mixin.""""""

    def __unicode__(self):
        """"""a human readable label for the object.""""""
        return '%s' % self  # pragma: no cover

    def __str__(self):
        """"""a human readable label for the object, appropriately encoded (or not).""""""
        deprecated(""Use of deprecated class UnicodeMixin! Use object instead."")
        return self.__unicode__()","class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
    '''a human readable label for the object.'''
        pass

    def __str__(self):
    '''a human readable label for the object, appropriately encoded (or not).'''
        pass

",3,3,snippet_506,1.0,"class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
        '''a human readable label for the object.'''
        raise NotImplementedError(
            '%s must implement __unicode__()' % self.__class__.__name__
        )

    def __str__(self):
        '''a human readable label for the object, appropriately encoded (or not).'''
        text = self.__unicode__()
        if sys.version_info[0] < 3:
            return text.encode('utf-8')
        return text.decode('utf-8') if isinstance(text, bytes) else text","class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
        '''a human readable label for the object.'''
        raise NotImplementedError

    def __str__(self):
        '''a human readable label for the object, appropriately encoded (or not).'''
        return str(self.__unicode__())","class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
        '''a human readable label for the object.'''
        return str(self)

    def __str__(self):
        '''a human readable label for the object, appropriately encoded (or not).'''
        return '<%s: %s>' % (self.__class__.__name__, id(self))",full_docstr,0.6607142857142857,0.5272727272727272,0.4814814814814815,0.6071428571428571,0.42680019805945124,0.5298507462686567,0.42105263157894735,0.3484848484848485,0.8158788681030273,0.888241171836853,0.8505235910415649,0.8804324269294739,0.8501887640449438,0.7857142857142857,0.7073170731707318,0.65,0.7857142857142857,0.4543140163423545,0.875,0.7464788732394366,0.6571428571428571,0.9372556209564209,0.8983287811279297,0.9173794388771057,0.9020754098892212,0.8930828301886793,0.8089887640449439,0.7126436781609196,0.6352941176470588,0.7640449438202247,0.4866735593462495,0.7526881720430108,0.5543478260869565,0.45054945054945056,0.9490230679512024,0.8967903852462769,0.9221676588058472,0.9017535448074341,0.8742150943396226,0.5021360249902282,0.2606726173778942,0.3193000540115904,0.4285714285714285,1.0,0.4256269704663379,0.2752695959817061,0.3081906668360266,0.2857142857142857,0.8333333333333334,0.3073049807781496,0.2923891578131963,0.3177831462517832,0.2857142857142857,0.3333333333333333
231254,andreikop/qutepart,andreikop_qutepart/qutepart/syntax/colortheme.py,qutepart.syntax.colortheme.ColorTheme,"class ColorTheme:
    """"""Color theme.
    """"""
    def __init__(self, textFormatClass):
        """"""Constructor gets TextFormat class as parameter for avoid cross-import problems
        """"""
        self.format = {
            'dsNormal':         textFormatClass(),
            'dsKeyword':        textFormatClass(bold=True),
            'dsFunction':       textFormatClass(color='#644a9a'),
            'dsVariable':       textFormatClass(color='#0057ad'),
            'dsControlFlow':    textFormatClass(bold=True),
            'dsOperator':       textFormatClass(),
            'dsBuiltIn':        textFormatClass(color='#644a9a', bold=True),
            'dsExtension':      textFormatClass(color='#0094fe', bold=True),
            'dsPreprocessor':   textFormatClass(color='#006e28'),
            'dsAttribute':      textFormatClass(color='#0057ad'),

            'dsChar':           textFormatClass(color='#914c9c'),
            'dsSpecialChar':    textFormatClass(color='#3dade8'),
            'dsString':         textFormatClass(color='#be0303'),
            'dsVerbatimString': textFormatClass(color='#be0303'),
            'dsSpecialString':  textFormatClass(color='#fe5500'),
            'dsImport':         textFormatClass(color='#b969c3'),

            'dsDataType':       textFormatClass(color='#0057ad'),
            'dsDecVal':         textFormatClass(color='#af8000'),
            'dsBaseN':          textFormatClass(color='#af8000'),
            'dsFloat':          textFormatClass(color='#af8000'),

            'dsConstant':       textFormatClass(bold=True),

            'dsComment':        textFormatClass(color='#888786'),
            'dsDocumentation':  textFormatClass(color='#608880'),
            'dsAnnotation':     textFormatClass(color='#0094fe'),
            'dsCommentVar':     textFormatClass(color='#c960c9'),

            'dsRegionMarker':   textFormatClass(color='#0057ad', background='#e0e9f8'),
            'dsInformation':    textFormatClass(color='#af8000'),
            'dsWarning':        textFormatClass(color='#be0303'),
            'dsAlert':          textFormatClass(color='#bf0303', background='#f7e6e6', bold=True),
            'dsOthers':         textFormatClass(color='#006e28'),
            'dsError':          textFormatClass(color='#bf0303', underline=True),
        }

    def getFormat(self, styleName):
        """"""Returns TextFormat for particular style
        """"""
        return self.format[styleName]","class ColorTheme:
    '''Color theme.
    '''

    def __init__(self, textFormatClass):
    '''Constructor gets TextFormat class as parameter for avoid cross-import problems
        '''
        pass

    def getFormat(self, styleName):
    '''Returns TextFormat for particular style
        '''
        pass

",3,3,snippet_318,0.75,"class ColorTheme:
    '''Color theme.
    '''

    def __init__(self, textFormatClass):
        '''Constructor gets TextFormat class as parameter for avoid cross-import problems'''
        self._textFormatClass = textFormatClass
        self._formats = {}

    def getFormat(self, styleName):
        '''Returns TextFormat for particular style'''
        if styleName not in self._formats:
            self._formats[styleName] = self._textFormatClass(styleName)
        return self._formats[styleName]","class ColorTheme:
    '''Color theme.
    '''

    def __init__(self, textFormatClass):
        '''Constructor gets TextFormat class as parameter for avoid cross-import problems
        '''
        self.textFormatClass = textFormatClass
        self.formats = {}

    def getFormat(self, styleName):
        '''Returns TextFormat for particular style
        '''
        if styleName not in self.formats:
            self.formats[styleName] = self.textFormatClass()
        return self.formats[styleName]","class ColorTheme:
    '''Color theme.
    '''

    def __init__(self, textFormatClass):
        '''Constructor gets TextFormat class as parameter for avoid cross-import problems
        '''
        self._textFormatClass = textFormatClass
        self._formats = {}
        self._initializeDefaultFormats()
    
    def _initializeDefaultFormats(self):
        '''Initialize default text formats for common styles
        '''
        self._formats = {
            'default': self._textFormatClass(),
            'keyword': self._textFormatClass(color='blue', bold=True),
            'string': self._textFormatClass(color='green'),
            'comment': self._textFormatClass(color='gray', italic=True),
            'number': self._textFormatClass(color='red'),
            'operator': self._textFormatClass(color='black', bold=True),
            'function': self._textFormatClass(color='purple'),
            'class': self._textFormatClass(color='darkblue', bold=True),
            'error': self._textFormatClass(color='red', bold=True),
            'warning': self._textFormatClass(color='orange')
        }

    def getFormat(self, styleName):
        '''Returns TextFormat for particular style
        '''
        return self._formats.get(styleName, self._formats['default'])",full_docstr,0.32558139534883723,0.26291079812206575,0.23696682464454974,0.31627906976744186,0.009304886388270005,0.6363636363636364,0.4482758620689655,0.32558139534883723,0.856861412525177,0.6789315342903137,0.7575893998146057,0.6933286786079407,0.6902808750000009,0.32710280373831774,0.2641509433962264,0.23809523809523808,0.3177570093457944,0.00786318749205002,0.6987951807228916,0.5121951219512195,0.38271604938271603,0.8582517504692078,0.68227219581604,0.7602105736732483,0.6965546607971191,0.6895864375000009,0.4444444444444444,0.30324909747292417,0.19636363636363638,0.43010752688172044,0.18675087029128998,0.6166666666666667,0.39330543933054396,0.2773109243697479,0.8555725812911987,0.7818180322647095,0.8170342445373535,0.7886162996292114,0.7722245000000003,0.0639328771318952,0.0642289293602843,0.1262316432067054,0.0295566502463054,0.0357142857142857,0.0788763551636054,0.0826014798115727,0.1506379309906324,0.0394088669950738,0.0428571428571428,0.3000326718222934,0.1432456382943493,0.1674761819997505,0.6108374384236454,0.2785714285714286
229137,ambitioninc/django-query-builder,ambitioninc_django-query-builder/querybuilder/query.py,querybuilder.query.Limit,"class Limit(object):
    """"""
    Used internally by the Query class to set a limit and/or offset on the query.
    """"""

    def __init__(self, limit=None, offset=None):
        """"""
        Initializes the instance variables

        :param limit: the number of rows to return
        :type limit: int

        :param offset: the number of rows to start returning rows from
        :type limit: int
        """"""
        self.limit = limit
        self.offset = offset

    def get_sql(self):
        """"""
        Generates the sql used for the limit clause of a Query

        :return: the sql for the limit clause of a Query
        :rtype: str
        """"""
        sql = ''
        if self.limit and self.limit > 0:
            sql += 'LIMIT {0} '.format(self.limit)
        if self.offset and self.offset > 0:
            sql += 'OFFSET {0} '.format(self.offset)
        return sql","class Limit(object):
    '''
    Used internally by the Query class to set a limit and/or offset on the query.
    '''

    def __init__(self, limit=None, offset=None):
    '''
        Initializes the instance variables

        :param limit: the number of rows to return
        :type limit: int

        :param offset: the number of rows to start returning rows from
        :type limit: int
        '''
        pass

    def get_sql(self):
    '''
        Generates the sql used for the limit clause of a Query

        :return: the sql for the limit clause of a Query
        :rtype: str
        '''
        pass

",3,3,snippet_313,1.0,"class Limit(object):
    '''
    Used internally by the Query class to set a limit and/or offset on the query.
    '''

    def __init__(self, limit=None, offset=None):
        '''
        Initializes the instance variables

        :param limit: the number of rows to return
        :type limit: int

        :param offset: the number of rows to start returning rows from
        :type limit: int
        '''
        if limit is not None:
            if not isinstance(limit, int):
                raise TypeError(""limit must be an integer"")
            if limit < 0:
                raise ValueError(""limit must be non-negative"")
        if offset is not None:
            if not isinstance(offset, int):
                raise TypeError(""offset must be an integer"")
            if offset < 0:
                raise ValueError(""offset must be non-negative"")

        self.limit = limit
        self.offset = offset

    def get_sql(self):
        '''
        Generates the sql used for the limit clause of a Query

        :return: the sql for the limit clause of a Query
        :rtype: str
        '''
        parts = []
        if self.limit is not None:
            parts.append(f""LIMIT {self.limit}"")
        if self.offset is not None:
            parts.append(f""OFFSET {self.offset}"")
        return "" "".join(parts)","class Limit(object):
    '''
    Used internally by the Query class to set a limit and/or offset on the query.
    '''

    def __init__(self, limit=None, offset=None):
        '''
        Initializes the instance variables

        :param limit: the number of rows to return
        :type limit: int

        :param offset: the number of rows to start returning rows from
        :type limit: int
        '''
        self.limit = limit
        self.offset = offset

    def get_sql(self):
        '''
        Generates the sql used for the limit clause of a Query

        :return: the sql for the limit clause of a Query
        :rtype: str
        '''
        if self.limit is None and self.offset is None:
            return """"
        
        if self.offset is not None:
            if self.limit is not None:
                return f""LIMIT {self.offset}, {self.limit}""
            else:
                return f""LIMIT {self.offset}, 18446744073709551615""  # MySQL syntax for offset without limit
        else:
            return f""LIMIT {self.limit}""","class Limit(object):
    '''
    Used internally by the Query class to set a limit and/or offset on the query.
    '''

    def __init__(self, limit=None, offset=None):
        '''
        Initializes the instance variables

        :param limit: the number of rows to return
        :type limit: int

        :param offset: the number of rows to start returning rows from
        :type limit: int
        '''
        self.limit = limit
        self.offset = offset

    def get_sql(self):
        '''
        Generates the sql used for the limit clause of a Query

        :return: the sql for the limit clause of a Query
        :rtype: str
        '''
        sql_parts = []
        
        if self.limit is not None:
            sql_parts.append(f""LIMIT {self.limit}"")
        
        if self.offset is not None:
            sql_parts.append(f""OFFSET {self.offset}"")
        
        return "" "".join(sql_parts)",full_docstr,0.7317073170731708,0.6736842105263158,0.6289752650176679,0.7038327526132404,0.5237677072866062,0.6394052044609665,0.5,0.449438202247191,0.8502612113952637,0.9243647456169128,0.885765790939331,0.9163781404495239,0.7861293063583814,0.8346456692913387,0.7619047619047619,0.7119999999999999,0.7952755905511811,0.6586901931540469,0.7688679245283019,0.6398104265402843,0.580952380952381,0.8976820111274719,0.9496474266052246,0.9229338765144348,0.9441816210746765,0.8305101694915253,0.8860759493670887,0.8170212765957446,0.7896995708154507,0.8860759493670887,0.6940417411501244,0.841025641025641,0.6907216494845361,0.6217616580310881,0.9523632526397705,0.9645017981529236,0.9583941102027893,0.9632740616798401,0.866044953271028,0.5445152752793776,0.4832040767052065,0.6636070244123037,0.4375,0.59375,0.5685114912130564,0.592927956062523,0.6707013421230358,0.4166666666666667,0.59375,0.5737704171297904,0.654816933599429,0.6610980682530654,0.4791666666666667,0.5
102995,BlueBrain/NeuroM,BlueBrain_NeuroM/neurom/io/utils.py,neurom.io.utils.MorphLoader,"class MorphLoader:
    """"""Caching morphology loader.

    Arguments:
        directory: path to directory with morphology files
        file_ext: file extension to look for (if not set, will pick any of .swc|.h5|.asc)
        cache_size: size of LRU cache (if not set, no caching done)
    """"""

    def __init__(self, directory, file_ext=None, cache_size=None):
        """"""Initialize a MorphLoader object.""""""
        self.directory = Path(directory)
        self.file_ext = file_ext
        if cache_size is not None:
            self.get = lru_cache(maxsize=cache_size)(self.get)

    def _filepath(self, name):
        """"""File path to `name` morphology file.""""""
        if self.file_ext is None:
            candidates = self.directory.glob(name + "".*"")
            try:
                return next(filter(_is_morphology_file, candidates))
            except StopIteration as e:
                raise NeuroMError(""Can not find morphology file for '%s' "" % name) from e
        else:
            return Path(self.directory, name + self.file_ext)

    # pylint:disable=method-hidden
    def get(self, name):
        """"""Get `name` morphology data.""""""
        return load_morphology(self._filepath(name))","class MorphLoader:
    '''Caching morphology loader.

    Arguments:
        directory: path to directory with morphology files
        file_ext: file extension to look for (if not set, will pick any of .swc|.h5|.asc)
        cache_size: size of LRU cache (if not set, no caching done)
    '''

    def __init__(self, directory, file_ext=None, cache_size=None):
    '''Initialize a MorphLoader object.'''
        pass

    def _filepath(self, name):
    '''File path to `name` morphology file.'''
        pass

    def get(self, name):
    '''Get `name` morphology data.'''
        pass

",4,4,snippet_45,0.2222222222222222,"class MorphLoader:
    '''Caching morphology loader.

    Arguments:
        directory: path to directory with morphology files
        file_ext: file extension to look for (if not set, will pick any of .swc|.h5|.asc)
        cache_size: size of LRU cache (if not set, no caching done)
    '''

    def __init__(self, directory, file_ext=None, cache_size=None):
        '''Initialize a MorphLoader object.'''
        self.directory = Path(directory)
        if file_ext:
            file_ext = file_ext if file_ext.startswith('.') else f'.{file_ext}'
        self.file_ext = file_ext
        self.cache_size = cache_size
        if cache_size:
            self._cache = OrderedDict()

    def _filepath(self, name):
        '''File path to `name` morphology file.'''
        if self.file_ext:
            candidate = self.directory / f""{name}{self.file_ext}""
            if candidate.is_file():
                return candidate
            else:
                raise FileNotFoundError(f""No file {candidate}"")
        else:
            for ext in ('.swc', '.h5', '.asc'):
                candidate = self.directory / f""{name}{ext}""
                if candidate.is_file():
                    return candidate
            raise FileNotFoundError(f""No morphology file for {name} in {self.directory}"")

    def get(self, name):
        '''Get `name` morphology data.'''
        if self.cache_size:
            if name in self._cache:
                self._cache.move_to_end(name)
                return self._cache[name]
        path = self._filepath(name)
        data = path.read_bytes()
        if self.cache_size:
            self._cache[name] = data
            if len(self._cache) > self.cache_size:
                self._cache.popitem(last=False)
        return data","class MorphLoader:
    '''Caching morphology loader.

    Arguments:
        directory: path to directory with morphology files
        file_ext: file extension to look for (if not set, will pick any of .swc|.h5|.asc)
        cache_size: size of LRU cache (if not set, no caching done)
    '''

    def __init__(self, directory, file_ext=None, cache_size=None):
        '''Initialize a MorphLoader object.'''
        self.directory = directory
        self.file_ext = file_ext
        self.cache_size = cache_size
        
        if cache_size is not None:
            self._cached_get = lru_cache(maxsize=cache_size)(self._load_morphology)
        else:
            self._cached_get = self._load_morphology

    def _filepath(self, name):
        '''File path to `name` morphology file.'''
        if self.file_ext is not None:
            return os.path.join(self.directory, f""{name}{self.file_ext}"")
        
        # Check for supported extensions in order
        for ext in ['.swc', '.h5', '.asc']:
            filepath = os.path.join(self.directory, f""{name}{ext}"")
            if os.path.exists(filepath):
                return filepath
        
        # If no file found, return with default extension preference
        return os.path.join(self.directory, f""{name}.swc"")

    def _load_morphology(self, name):
        '''Load morphology data from file.'''
        filepath = self._filepath(name)
        
        # Check if file exists
        if not os.path.exists(filepath):
            raise FileNotFoundError(f""Morphology file not found: {filepath}"")
        
        # Get file extension
        _, ext = os.path.splitext(filepath)
        
        # Load based on extension
        if ext == '.swc':
            return self._load_swc(filepath)
        elif ext == '.h5':
            return self._load_h5(filepath)
        elif ext == '.asc':
            return self._load_asc(filepath)
        else:
            raise ValueError(f""Unsupported file extension: {ext}"")

    def _load_swc(self, filepath):
        '''Load SWC format morphology data.'''
        # Placeholder implementation - in real usage this would parse SWC files
        with open(filepath, 'r') as f:
            data = f.read()
        return {'type': 'swc', 'data': data, 'filepath': filepath}

    def _load_h5(self, filepath):
        '''Load HDF5 format morphology data.'''
        # Placeholder implementation - in real usage this would parse HDF5 files
        return {'type': 'h5', 'filepath': filepath}

    def _load_asc(self, filepath):
        '''Load ASC format morphology data.'''
        # Placeholder implementation - in real usage this would parse ASC files
        with open(filepath, 'r') as f:
            data = f.read()
        return {'type': 'asc', 'data': data, 'filepath': filepath}

    def get(self, name):
        '''Get `name` morphology data.'''
        return self._cached_get(name)","class MorphLoader:
    '''Caching morphology loader.

    Arguments:
        directory: path to directory with morphology files
        file_ext: file extension to look for (if not set, will pick any of .swc|.h5|.asc)
        cache_size: size of LRU cache (if not set, no caching done)
    '''

    def __init__(self, directory, file_ext=None, cache_size=None):
        '''Initialize a MorphLoader object.'''
        self.directory = directory
        self.file_ext = file_ext
        self.cache_size = cache_size
        
        if cache_size is not None:
            self._cached_load = lru_cache(maxsize=cache_size)(self._load_morphology)
        else:
            self._cached_load = self._load_morphology

    def _filepath(self, name):
        '''File path to `name` morphology file.'''
        if self.file_ext:
            return os.path.join(self.directory, f""{name}.{self.file_ext}"")
        else:
            # Look for any of the supported extensions
            for ext in ['swc', 'h5', 'asc']:
                filepath = os.path.join(self.directory, f""{name}.{ext}"")
                if os.path.exists(filepath):
                    return filepath
            # If no file found, return the first extension as default
            return os.path.join(self.directory, f""{name}.swc"")

    def _load_morphology(self, filepath):
        '''Load morphology from file.'''
        return morphio.Morphology(filepath)

    def get(self, name):
        '''Get `name` morphology data.'''
        filepath = self._filepath(name)
        return self._cached_load(filepath)",full_docstr,0.6575342465753425,0.5399449035812672,0.47645429362880887,0.6027397260273973,0.4310789502736483,0.559322033898305,0.4174757281553398,0.34306569343065696,0.8655077219009399,0.8761981725692749,0.8708201050758362,0.8751172423362732,0.7691424734982332,0.5267326732673266,0.42544731610337966,0.37524950099800397,0.4752475247524752,0.29994766716512195,0.38354037267080743,0.28771384136858474,0.24454828660436137,0.8257732391357422,0.8965531587600708,0.8597087860107422,0.8889338374137878,0.749090765864332,0.7277936962750716,0.5936599423631124,0.5333333333333333,0.659025787965616,0.5141424662383047,0.6473829201101928,0.4889502762430939,0.4293628808864266,0.8824684023857117,0.8872579336166382,0.8848567605018616,0.8867766857147217,0.8164482378854625,0.4789964533063249,0.3303057081123218,0.4350642036572107,0.3421052631578947,0.8085106382978723,0.4221562438194667,0.1867726056850117,0.471897162426002,0.4342105263157895,0.5957446808510638,0.4352689339377718,0.3697011373047586,0.4528415637318828,0.4078947368421052,0.5106382978723404
169082,PredixDev/predixpy,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/PredixDev_predixpy/predix/data/eventhub/client.py,PredixDev_predixpy.predix.data.eventhub.client.Eventhub.GrpcManager,"class GrpcManager:
    """"""
    Class for managing GRPC calls by turing the generators grpc uses into function calls
    This allows the sdk to man in the middle the messages
    """"""

    def __init__(self, stub_call, on_msg_callback, metadata, tx_stream=True, initial_message=None):
        """"""
        :param stub_call: the call on the grpc stub to build the generator on
        :param on_msg_callback: the callback to pass any received functions on
        :param metadata: metadata to attach to the stub call
        """"""
        self._tx_stream = tx_stream
        self._stub_call = stub_call
        self._on_msg_callback = on_msg_callback
        self._metadata = metadata
        self._initial_message = initial_message
        self._grpc_rx_thread = threading.Thread(
            target=self._grpc_rx_receiver)
        self._grpc_rx_thread.daemon = True
        self._grpc_rx_thread.start()
        self._grpc_tx_queue = []
        self._run_generator = True
        time.sleep(1)

    def send_message(self, tx_message):
        """"""
        Add a message onto the tx queue to be sent on the stub
        :param tx_message:
        :return: None
        """"""
        self._grpc_tx_queue.append(tx_message)

    def _grpc_rx_receiver(self):
        """"""
        Blocking Function that opens the stubs generator and pass any messages onto the callback
        :return: None
        """"""
        logging.debug(""grpc rx stream metadata: "" + str(self._metadata))
        if self._tx_stream:
            if self._initial_message is not None:
                self.send_message(self._initial_message)
            msgs = self._stub_call(
                request_iterator=self._grpc_tx_generator(), metadata=self._metadata)
        else:
            msgs = self._stub_call(
                self._initial_message, metadata=self._metadata)

        for m in msgs:
            self._on_msg_callback(m)

    def stop_generator(self):
        """"""
        Call this to close the generator
        :return:
        """"""
        logging.debug('stopping generator')
        self._run_generator = False

    def _grpc_tx_generator(self):
        """"""
        the generator taking and messages added to the grpc_tx_queue
        and yield them to grpc
        :return: grpc messages
        """"""
        while self._run_generator:
            while len(self._grpc_tx_queue) != 0:
                yield self._grpc_tx_queue.pop(0)
        return
","class GrpcManager:
    '''
    Class for managing GRPC calls by turing the generators grpc uses into function calls
    This allows the sdk to man in the middle the messages
    '''


    def __init__(self, stub_call, on_msg_callback, metadata, tx_stream=True, initial_message=None):
    '''
        :param stub_call: the call on the grpc stub to build the generator on
        :param on_msg_callback: the callback to pass any received functions on
        :param metadata: metadata to attach to the stub call
        '''
        pass


    def send_message(self, tx_message):
    '''
        Add a message onto the tx queue to be sent on the stub
        :param tx_message:
        :return: None
        '''
        pass


    def _grpc_rx_receiver(self):
    '''
        Blocking Function that opens the stubs generator and pass any messages onto the callback
        :return: None
        '''
        pass


    def stop_generator(self):
    '''
        Call this to close the generator
        :return:
        '''
        pass


    def _grpc_tx_generator(self):
    '''
        the generator taking and messages added to the grpc_tx_queue
        and yield them to grpc
        :return: grpc messages
        '''
        pass

",6,6,snippet_214,0.1578947368421052,"class GrpcManager:
    '''
    Class for managing GRPC calls by turning the generators grpc uses into function calls.
    This allows the sdk to man in the middle the messages.
    '''

    def __init__(self, stub_call, on_msg_callback, metadata, tx_stream=True, initial_message=None):
        '''
        :param stub_call: the call on the grpc stub to build the generator on
        :param on_msg_callback: the callback to pass any received messages on
        :param metadata: metadata to attach to the stub call
        :param tx_stream: whether this is a streaming (bi-di) call
        :param initial_message: optional first message to send on tx_stream
        '''
        self.stub_call = stub_call
        self.on_msg_callback = on_msg_callback
        self.metadata = metadata
        self.tx_stream = tx_stream
        self.initial_message = initial_message

        self._stop_event = threading.Event()
        self._grpc_tx_queue = queue.Queue()
        self._sentinel = object()
        self._thread = None

        if self.tx_stream:
            # start the streaming call
            self._call = self.stub_call(
                self._grpc_tx_generator(),
                metadata=self.metadata
            )
            self._thread = threading.Thread(target=self._grpc_rx_receiver, daemon=True)
            self._thread.start()
        else:
            # unary or server-streaming with a single request
            resp = self.stub_call(self.initial_message, metadata=self.metadata)
            # if it's a generator, iterate; else treat as single response
            if hasattr(resp, '__iter__') and not isinstance(resp, (bytes, str)):
                for msg in resp:
                    self.on_msg_callback(msg)
            else:
                self.on_msg_callback(resp)

    def send_message(self, tx_message):
        '''
        Add a message onto the tx queue to be sent on the stub
        :param tx_message:
        :return: None
        '''
        if not self.tx_stream:
            raise RuntimeError(""send_message called on non-streaming GrpcManager"")
        if self._stop_event.is_set():
            raise RuntimeError(""Cannot send message after stop_generator()"")
        self._grpc_tx_queue.put(tx_message)

    def _grpc_rx_receiver(self):
        '''
        Blocking function that opens the stub's generator and passes any messages onto the callback
        :return: None
        '''
        try:
            for msg in self._call:
                if self._stop_event.is_set():
                    break
                self.on_msg_callback(msg)
        finally:
            # ensure we mark stop and unblock tx_generator
            self._stop_event.set()
            # put sentinel in case tx_generator is waiting
            self._grpc_tx_queue.put(self._sentinel)

    def stop_generator(self):
        '''
        Call this to close the generator
        :return: None
        '''
        if not self.tx_stream:
            return
        # signal stop
        self._stop_event.set()
        # unblock tx generator if waiting
        self._grpc_tx_queue.put(self._sentinel)
        # wait for rx thread to finish
        if self._thread is not None:
            self._thread.join()
            self._thread = None

    def _grpc_tx_generator(self):
        '''
        The generator taking any messages added to the grpc_tx_queue
        and yielding them to grpc
        :return: grpc messages
        '''
        # send initial message if provided
        if self.initial_message is not None:
            yield self.initial_message
            self.initial_message = None

        while not self._stop_event.is_set():
            msg = self._grpc_tx_queue.get()
            if msg is self._sentinel:
                break
            yield msg

        # clean up remaining items if any
        while not self._grpc_tx_queue.empty():
            try:
                m = self._grpc_tx_queue.get_nowait()
                if m is self._sentinel:
                    break
            except queue.Empty:
                break","class GrpcManager:
    '''
    Class for managing GRPC calls by turing the generators grpc uses into function calls
    This allows the sdk to man in the middle the messages
    '''

    def __init__(self, stub_call, on_msg_callback, metadata, tx_stream=True, initial_message=None):
        '''
        :param stub_call: the call on the grpc stub to build the generator on
        :param on_msg_callback: the callback to pass any received functions on
        :param metadata: metadata to attach to the stub call
        '''
        self.stub_call = stub_call
        self.on_msg_callback = on_msg_callback
        self.metadata = metadata
        self.tx_stream = tx_stream
        self.initial_message = initial_message
        
        self.grpc_tx_queue = queue.Queue()
        self.generator = None
        self.rx_thread = None
        self.stop_event = threading.Event()
        
        # Start the grpc communication
        self._start_grpc_communication()

    def send_message(self, tx_message):
        '''
        Add a message onto the tx queue to be sent on the stub
        :param tx_message:
        :return: None
        '''
        self.grpc_tx_queue.put(tx_message)

    def _grpc_rx_receiver(self):
        '''
        Blocking Function that opens the stubs generator and pass any messages onto the callback
        :return: None
        '''
        try:
            for message in self.generator:
                if self.stop_event.is_set():
                    break
                if self.on_msg_callback:
                    self.on_msg_callback(message)
        except Exception:
            pass  # Handle generator closing or errors

    def stop_generator(self):
        '''
        Call this to close the generator
        :return:
        '''
        self.stop_event.set()
        if self.rx_thread and self.rx_thread.is_alive():
            self.rx_thread.join()

    def _grpc_tx_generator(self):
        '''
        the generator taking and messages added to the grpc_tx_queue
        and yield them to grpc
        :return: grpc messages
        '''
        if self.initial_message is not None:
            yield self.initial_message
            
        while not self.stop_event.is_set():
            try:
                message = self.grpc_tx_queue.get(timeout=0.1)
                yield message
            except queue.Empty:
                continue

    def _start_grpc_communication(self):
        '''
        Internal method to start the grpc communication threads
        '''
        if self.tx_stream:
            self.generator = self.stub_call(self._grpc_tx_generator(), metadata=self.metadata)
        else:
            self.generator = self.stub_call(metadata=self.metadata)
            
        self.rx_thread = threading.Thread(target=self._grpc_rx_receiver)
        self.rx_thread.daemon = True
        self.rx_thread.start()","class GrpcManager:
    '''
    Class for managing GRPC calls by turing the generators grpc uses into function calls
    This allows the sdk to man in the middle the messages
    '''

    def __init__(self, stub_call, on_msg_callback, metadata, tx_stream=True, initial_message=None):
        '''
        :param stub_call: the call on the grpc stub to build the generator on
        :param on_msg_callback: the callback to pass any received functions on
        :param metadata: metadata to attach to the stub call
        '''
        self.stub_call = stub_call
        self.on_msg_callback = on_msg_callback
        self.metadata = metadata
        self.tx_stream = tx_stream
        self.initial_message = initial_message
        
        self.grpc_tx_queue = queue.Queue()
        self.generator_active = True
        self.rx_thread = None
        self.generator = None
        
        if self.initial_message:
            self.grpc_tx_queue.put(self.initial_message)
        
        if self.tx_stream:
            self.generator = self.stub_call(self._grpc_tx_generator(), metadata=self.metadata)
        else:
            self.generator = self.stub_call(metadata=self.metadata)
        
        self.rx_thread = threading.Thread(target=self._grpc_rx_receiver)
        self.rx_thread.daemon = True
        self.rx_thread.start()

    def send_message(self, tx_message):
        '''
        Add a message onto the tx queue to be sent on the stub
        :param tx_message:
        :return: None
        '''
        if self.generator_active and self.tx_stream:
            self.grpc_tx_queue.put(tx_message)

    def _grpc_rx_receiver(self):
        '''
        Blocking Function that opens the stubs generator and pass any messages onto the callback
        :return: None
        '''
        try:
            for message in self.generator:
                if not self.generator_active:
                    break
                if self.on_msg_callback:
                    self.on_msg_callback(message)
        except Exception as e:
            if self.generator_active:
                if self.on_msg_callback:
                    self.on_msg_callback(e)

    def stop_generator(self):
        '''
        Call this to close the generator
        :return:
        '''
        self.generator_active = False
        if self.tx_stream:
            self.grpc_tx_queue.put(None)
        if self.generator:
            try:
                self.generator.cancel()
            except:
                pass

    def _grpc_tx_generator(self):
        '''
        the generator taking and messages added to the grpc_tx_queue
        and yield them to grpc
        :return: grpc messages
        '''
        while self.generator_active:
            try:
                message = self.grpc_tx_queue.get(timeout=1)
                if message is None or not self.generator_active:
                    break
                yield message
            except queue.Empty:
                continue
            except:
                break",full_docstr,0.6773006134969325,0.5682656826568265,0.48335388409371155,0.5447852760736196,0.48311393380621476,0.5796766743648961,0.4774566473988439,0.4074074074074074,0.8606969714164734,0.9220775365829468,0.8903306126594543,0.9155483245849609,0.7889146908315567,0.8295625942684767,0.7201210287443268,0.6464339908952959,0.645550527903469,0.6605851531381085,0.7953410981697171,0.65,0.5575959933222037,0.9162122011184692,0.9332233667373657,0.9246395826339722,0.931493878364563,0.8107862058823534,0.8214285714285714,0.7164179104477612,0.6347305389221557,0.6815476190476191,0.6489469617746125,0.7843137254901961,0.6382978723404256,0.5459016393442623,0.9201034307479858,0.931222677230835,0.9256296753883362,0.9300986528396606,0.7981755342465758,0.4861385230654214,0.2691956973607413,0.4679209869480725,0.5785714285714286,0.6288659793814433,0.5639038060316341,0.4879616689732862,0.568169019070776,0.55,0.6494845360824743,0.5823382680069793,0.4915219339811609,0.5717044811984499,0.5857142857142857,0.6804123711340206
229505,amelchio/pysonos,amelchio_pysonos/pysonos/music_services/data_structures.py,pysonos.music_services.data_structures.MetadataDictBase,"class MetadataDictBase:
    """"""Class used to parse metadata from kwargs""""""

    # The following two fields should be overwritten in subclasses

    # _valid_fields is a set of valid fields
    _valid_fields = {}

    # _types is a dict of fields with non-string types and their convertion
    # callables
    _types = {}

    def __init__(self, metadata_dict):
        """"""Initialize local variables""""""
        _LOG.debug(""MetadataDictBase.__init__ with: %s"", metadata_dict)
        for key in metadata_dict:
            # Check for invalid fields
            if key not in self._valid_fields:
                message = '%s instantiated with invalid field ""%s"" and value: ""%s""'
                # Really wanted to raise exceptions here, but as it
                # turns out I have already encountered invalid fields
                # from music services.
                _LOG.debug(message, self.__class__, key, metadata_dict[key])

        # Convert names and create metadata dict
        self.metadata = {}
        for key, value in metadata_dict.items():
            if key in self._types:
                convertion_callable = self._types[key]
                value = convertion_callable(value)
            self.metadata[camel_to_underscore(key)] = value

    def __getattr__(self, key):
        """"""Return item from metadata in case of unknown attribute""""""
        try:
            return self.metadata[key]
        except KeyError as error:
            message = 'Class {} has no attribute ""{}""'
            raise AttributeError(
                message.format(self.__class__.__name__, key)
            ) from error","class MetadataDictBase:
    '''Class used to parse metadata from kwargs'''

    def __init__(self, metadata_dict):
    '''Initialize local variables'''
        pass

    def __getattr__(self, key):
    '''Return item from metadata in case of unknown attribute'''
        pass

",3,3,snippet_315,0.1666666666666666,"class MetadataDictBase:
    '''Class used to parse metadata from kwargs'''

    def __init__(self, metadata_dict):
        '''Initialize local variables'''
        if metadata_dict is None:
            metadata_dict = {}
        if not isinstance(metadata_dict, dict):
            raise TypeError(""metadata_dict must be a dict"")
        self._metadata = metadata_dict

    def __getattr__(self, key):
        '''Return item from metadata in case of unknown attribute'''
        if key in self._metadata:
            return self._metadata[key]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{key}'"")","class MetadataDictBase:
    '''Class used to parse metadata from kwargs'''

    def __init__(self, metadata_dict):
        '''Initialize local variables'''
        self.metadata_dict = metadata_dict

    def __getattr__(self, key):
        '''Return item from metadata in case of unknown attribute'''
        if key in self.metadata_dict:
            return self.metadata_dict[key]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{key}'"")","class MetadataDictBase:
    '''Class used to parse metadata from kwargs'''

    def __init__(self, metadata_dict):
        '''Initialize local variables'''
        self._metadata_dict = metadata_dict or {}

    def __getattr__(self, key):
        '''Return item from metadata in case of unknown attribute'''
        if key in self._metadata_dict:
            return self._metadata_dict[key]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{key}'"")",full_docstr,0.5114503816793894,0.36153846153846153,0.24031007751937983,0.41221374045801523,0.1394414996247544,0.8951048951048951,0.5915492957746479,0.4326241134751773,0.8578792810440063,0.7410774827003479,0.7952122092247009,0.7513066530227661,0.7664806779661019,0.4508196721311476,0.3636363636363636,0.25,0.3688524590163934,0.07516431089367241,0.9174311926605505,0.7129629629629629,0.5700934579439252,0.86537104845047,0.7112702131271362,0.7807897329330444,0.7241657972335815,0.7551813559322039,0.44897959183673464,0.36213991769547327,0.24896265560165978,0.3673469387755102,0.08759385308798806,0.9130434782608695,0.6929824561403509,0.5575221238938053,0.8607509136199951,0.7119306325912476,0.7792994379997253,0.724456250667572,0.7532981355932208,0.1690400238058708,0.0404368168951333,0.0985929387883717,0.3734939759036144,0.1636363636363636,0.1174800552305147,0.0170815782116899,0.0907356854266888,0.253012048192771,0.109090909090909,0.1412220832267271,0.0198796976350321,0.0922156451294888,0.2891566265060241,0.1636363636363636
393007,gabstopper/smc-python,gabstopper_smc-python/smc/administration/certificates/tls_common.py,smc.administration.certificates.tls_common.ImportExportCertificate,"class ImportExportCertificate(object):
    """"""
    Mixin to provide certificate import and export methods to relevant
    classes.
    """"""
    def import_certificate(self, certificate):
        """"""
        Import a valid certificate. Certificate can be either a file path
        or a string of the certificate. If string certificate, it must include
        the -----BEGIN CERTIFICATE----- string.
        
        :param str certificate_file: fully qualified path to certificate file
        :raises CertificateImportError: failure to import cert with reason
        :raises IOError: file not found, permissions, etc.
        :return: None
        """"""
        multi_part = 'signed_certificate' if self.typeof == 'tls_server_credentials'\
            else 'certificate'
        self.make_request(
            CertificateImportError,
            method='create',
            resource='certificate_import',
            headers = {'content-type': 'multipart/form-data'}, 
            files={ 
                    multi_part: open(certificate, 'rb') if not \
                        pem_as_string(certificate) else certificate
                })
    
    def export_certificate(self, filename=None):
        """"""
        Export the certificate. Returned certificate will be in string
        format. If filename is provided, the certificate will also be saved
        to the file specified.
        
        :raises CertificateExportError: error exporting certificate
        :rtype: str or None
        """"""
        result = self.make_request(
            CertificateExportError,
            raw_result=True,
            resource='certificate_export')
            
        if filename is not None:
            save_to_file(filename, result.content)
            return
    
        return result.content","class ImportExportCertificate(object):
    '''
    Mixin to provide certificate import and export methods to relevant
    classes.
    '''

    def import_certificate(self, certificate):
    '''
        Import a valid certificate. Certificate can be either a file path
        or a string of the certificate. If string certificate, it must include
        the -----BEGIN CERTIFICATE----- string.
        
        :param str certificate_file: fully qualified path to certificate file
        :raises CertificateImportError: failure to import cert with reason
        :raises IOError: file not found, permissions, etc.
        :return: None
        '''
        pass

    def export_certificate(self, filename=None):
    '''
        Export the certificate. Returned certificate will be in string
        format. If filename is provided, the certificate will also be saved
        to the file specified.
        
        :raises CertificateExportError: error exporting certificate
        :rtype: str or None
        '''
        pass

",3,3,snippet_690,0.25,"class ImportExportCertificate(object):
    '''
    Mixin to provide certificate import and export methods to relevant
    classes.
    '''

    def import_certificate(self, certificate):
        '''
        Import a valid certificate. Certificate can be either a file path
        or a string of the certificate. If string certificate, it must include
        the -----BEGIN CERTIFICATE----- string.
        
        :param str certificate_file: fully qualified path to certificate file
        :raises CertificateImportError: failure to import cert with reason
        :raises IOError: file not found, permissions, etc.
        :return: None
        '''
        cert_str = None
        # Determine if input is a cert string
        if isinstance(certificate, str) and '-----BEGIN CERTIFICATE-----' in certificate:
            cert_str = certificate
        else:
            # Treat as file path
            try:
                with open(certificate, 'r') as f:
                    cert_str = f.read()
            except IOError:
                raise
        if not cert_str or '-----BEGIN CERTIFICATE-----' not in cert_str:
            raise CertificateImportError(""Invalid certificate format"")
        self._certificate = cert_str

    def export_certificate(self, filename=None):
        '''
        Export the certificate. Returned certificate will be in string
        format. If filename is provided, the certificate will also be saved
        to the file specified.
        
        :raises CertificateExportError: error exporting certificate
        :rtype: str or None
        '''
        cert = getattr(self, '_certificate', None)
        if not cert:
            raise CertificateExportError(""No certificate to export"")
        if filename:
            try:
                with open(filename, 'w') as f:
                    f.write(cert)
            except IOError as e:
                raise CertificateExportError(f""Failed to write to {filename}: {e}"")
            return None
        return cert","class ImportExportCertificate(object):
    '''
    Mixin to provide certificate import and export methods to relevant
    classes.
    '''

    def import_certificate(self, certificate):
        '''
        Import a valid certificate. Certificate can be either a file path
        or a string of the certificate. If string certificate, it must include
        the -----BEGIN CERTIFICATE----- string.
        
        :param str certificate_file: fully qualified path to certificate file
        :raises CertificateImportError: failure to import cert with reason
        :raises IOError: file not found, permissions, etc.
        :return: None
        '''
        if certificate is None:
            raise CertificateImportError(""Certificate cannot be None"")
            
        # Check if certificate is a file path
        if '\n' not in certificate and '\r' not in certificate:
            # Treat as file path
            try:
                with open(certificate, 'r') as f:
                    cert_data = f.read()
            except IOError:
                raise
            except Exception as e:
                raise CertificateImportError(""Failed to read certificate file: {}"".format(str(e)))
        else:
            # Treat as certificate string
            cert_data = certificate
            
        # Validate certificate format
        if ""-----BEGIN CERTIFICATE-----"" not in cert_data:
            raise CertificateImportError(""Invalid certificate format: missing BEGIN CERTIFICATE header"")
            
        if ""-----END CERTIFICATE-----"" not in cert_data:
            raise CertificateImportError(""Invalid certificate format: missing END CERTIFICATE footer"")
            
        # Store the certificate data (assuming the class has a certificate attribute)
        self._certificate = cert_data

    def export_certificate(self, filename=None):
        '''
        Export the certificate. Returned certificate will be in string
        format. If filename is provided, the certificate will also be saved
        to the file specified.
        
        :raises CertificateExportError: error exporting certificate
        :rtype: str or None
        '''
        if not hasattr(self, '_certificate') or self._certificate is None:
            raise CertificateExportError(""No certificate available to export"")
            
        cert_data = self._certificate
        
        if filename is not None:
            try:
                with open(filename, 'w') as f:
                    f.write(cert_data)
            except IOError:
                raise
            except Exception as e:
                raise CertificateExportError(""Failed to write certificate to file: {}"".format(str(e)))
                
        return cert_data","class ImportExportCertificate(object):
    '''
    Mixin to provide certificate import and export methods to relevant
    classes.
    '''

    def __init__(self):
        self._certificate = None

    def import_certificate(self, certificate):
        '''
        Import a valid certificate. Certificate can be either a file path
        or a string of the certificate. If string certificate, it must include
        the -----BEGIN CERTIFICATE----- string.
        
        :param str certificate: fully qualified path to certificate file or certificate string
        :raises CertificateImportError: failure to import cert with reason
        :raises IOError: file not found, permissions, etc.
        :return: None
        '''
        try:
            if '-----BEGIN CERTIFICATE-----' in certificate:
                # Certificate is provided as string
                cert_data = certificate.encode('utf-8')
            else:
                # Certificate is provided as file path
                if not os.path.exists(certificate):
                    raise IOError(f""Certificate file not found: {certificate}"")
                
                with open(certificate, 'rb') as cert_file:
                    cert_data = cert_file.read()
            
            # Parse the certificate
            self._certificate = x509.load_pem_x509_certificate(cert_data, default_backend())
            
        except IOError:
            raise
        except Exception as e:
            raise CertificateImportError(f""Failed to import certificate: {str(e)}"")

    def export_certificate(self, filename=None):
        '''
        Export the certificate. Returned certificate will be in string
        format. If filename is provided, the certificate will also be saved
        to the file specified.
        
        :raises CertificateExportError: error exporting certificate
        :rtype: str or None
        '''
        try:
            if self._certificate is None:
                raise CertificateExportError(""No certificate available to export"")
            
            # Convert certificate to PEM format string
            cert_pem = self._certificate.public_bytes(x509.Encoding.PEM)
            cert_string = cert_pem.decode('utf-8')
            
            if filename:
                with open(filename, 'w') as cert_file:
                    cert_file.write(cert_string)
                return None
            else:
                return cert_string
                
        except Exception as e:
            raise CertificateExportError(f""Failed to export certificate: {str(e)}"")",full_docstr,0.7139240506329113,0.5852417302798981,0.557544757033248,0.6632911392405063,0.52946486151478,0.6779141104294478,0.48923076923076925,0.44753086419753085,0.8811843395233154,0.8881682753562927,0.8846625089645386,0.8874649405479431,0.760143492063492,0.6094420600858369,0.5086206896551724,0.4805194805194805,0.5793991416309013,0.4092262648669818,0.5363636363636364,0.37813211845102507,0.3378995433789954,0.8557950258255005,0.8925478458404541,0.873785138130188,0.8887311816215515,0.772070790513834,0.6577181208053692,0.5213483146067416,0.4650112866817156,0.5816554809843401,0.4194020354229968,0.544392523364486,0.3981264637002342,0.3403755868544601,0.852131724357605,0.8811445236206055,0.8663952946662903,0.8781546354293823,0.7536838554216869,0.475967919345672,0.4895459916381847,0.6580756857445035,0.35,0.40625,0.5230805363188541,0.3815751813526988,0.6711636305893842,0.3833333333333333,0.65625,0.5042893759520495,0.4234420405463148,0.6332987965952166,0.3666666666666666,0.59375
155792,Nachtfeuer/pipeline,Nachtfeuer_pipeline/spline/tools/logger.py,spline.tools.logger.NoLogger,"class NoLogger(object):
    """"""A logger that does nothing.""""""

    def info(self, *args, **kwargs):
        """"""Hide information messages.""""""
        pass

    def warning(self, *args, **kwargs):
        """"""Hide warning messages.""""""
        pass

    def severe(self, *args, **kwargs):
        """"""Hide severe messages.""""""
        pass","class NoLogger(object):
    '''A logger that does nothing.'''

    def info(self, *args, **kwargs):
    '''Hide information messages.'''
        pass

    def warning(self, *args, **kwargs):
    '''Hide warning messages.'''
        pass

    def severe(self, *args, **kwargs):
    '''Hide severe messages.'''
        pass

",4,4,snippet_199,1.0,"class NoLogger(object):
    """"""A logger that does nothing.""""""

    def info(self, *args, **kwargs):
        """"""Hide information messages.""""""
        pass

    def warning(self, *args, **kwargs):
        """"""Hide warning messages.""""""
        pass

    def severe(self, *args, **kwargs):
        """"""Hide severe messages.""""""
        pass","class NoLogger(object):
    '''A logger that does nothing.'''

    def info(self, *args, **kwargs):
        '''Hide information messages.'''
        pass

    def warning(self, *args, **kwargs):
        '''Hide warning messages.'''
        pass

    def severe(self, *args, **kwargs):
        '''Hide severe messages.'''
        pass","class NoLogger(object):
    '''A logger that does nothing.'''

    def info(self, *args, **kwargs):
        '''Hide information messages.'''
        pass

    def warning(self, *args, **kwargs):
        '''Hide warning messages.'''
        pass

    def severe(self, *args, **kwargs):
        '''Hide severe messages.'''
        pass",full_docstr,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9999999403953552,0.9999999403953552,0.9999999403953552,0.9999998807907104,1.0,1.0,1.0,1.0,1.0,0.5785551309114549,0.8873239436619719,0.7714285714285715,0.6666666666666666,0.9970725178718567,0.9970725178718567,0.9970725178718567,0.9970725178718567,1.0,1.0,1.0,1.0,1.0,0.5785551309114549,0.8873239436619719,0.7714285714285715,0.6666666666666666,0.9970725178718567,0.9970725178718567,0.9970725178718567,0.9970725178718567,1.0,1.0,1.0,1.0,1.0,1.0,0.6897145116345679,0.3721837024726832,0.3866743440655883,1.0,1.0,0.6897145116345679,0.3721837024726832,0.3866743440655883,1.0,1.0
398390,geopython/OWSLib,geopython_OWSLib/owslib/coverage/wcsBase.py,owslib.coverage.wcsBase.WCSCapabilitiesReader,"class WCSCapabilitiesReader(object):
    """"""Read and parses WCS capabilities document into a lxml.etree infoset
    """"""

    def __init__(self, version=None, cookies=None, auth=None, timeout=30, headers=None):
        """"""Initialize
        @type version: string
        @param version: WCS Version parameter e.g '1.0.0'
        """"""
        self.version = version
        self._infoset = None
        self.cookies = cookies
        self.headers = headers
        self.timeout = timeout
        self.auth = auth or Authentication()

    def capabilities_url(self, service_url):
        """"""Return a capabilities url
        @type service_url: string
        @param service_url: base url of WCS service
        @rtype: string
        @return: getCapabilities URL
        """"""
        qs = []
        if service_url.find('?') != -1:
            qs = parse_qsl(service_url.split('?')[1])

        params = [x[0] for x in qs]

        if 'service' not in params:
            qs.append(('service', 'WCS'))
        if 'request' not in params:
            qs.append(('request', 'GetCapabilities'))
        if ('version' not in params) and (self.version is not None):
            qs.append(('version', self.version))

        urlqs = urlencode(tuple(qs))
        return service_url.split('?')[0] + '?' + urlqs

    def read(self, service_url, timeout=30):
        """"""Get and parse a WCS capabilities document, returning an
        elementtree tree

        @type service_url: string
        @param service_url: The base url, to which is appended the service,
        version, and request parameters
        @rtype: elementtree tree
        @return: An elementtree tree representation of the capabilities document
        """"""
        request = self.capabilities_url(service_url)
        u = openURL(request, timeout=timeout, cookies=self.cookies, auth=self.auth, headers=self.headers)
        return getXMLTree(u)

    def readString(self, st):
        """"""Parse a WCS capabilities document, returning an
        instance of WCSCapabilitiesInfoset
        string should be an XML capabilities document
        """"""
        return etree.fromstring(st)","class WCSCapabilitiesReader(object):
    '''Read and parses WCS capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version=None, cookies=None, auth=None, timeout=30, headers=None):
    '''Initialize
        @type version: string
        @param version: WCS Version parameter e.g '1.0.0'
        '''
        pass

    def capabilities_url(self, service_url):
    '''Return a capabilities url
        @type service_url: string
        @param service_url: base url of WCS service
        @rtype: string
        @return: getCapabilities URL
        '''
        pass

    def read(self, service_url, timeout=30):
    '''Get and parse a WCS capabilities document, returning an
        elementtree tree

        @type service_url: string
        @param service_url: The base url, to which is appended the service,
        version, and request parameters
        @rtype: elementtree tree
        @return: An elementtree tree representation of the capabilities document
        '''
        pass

    def readString(self, st):
    '''Parse a WCS capabilities document, returning an
        instance of WCSCapabilitiesInfoset
        string should be an XML capabilities document
        '''
        pass

",5,5,snippet_706,0.7777777777777778,"class WCSCapabilitiesReader(object):
    '''Read and parses WCS capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version=None, cookies=None, auth=None, timeout=30, headers=None):
        '''Initialize
        @type version: string
        @param version: WCS Version parameter e.g '1.0.0'
        '''
        self.version = version
        self.cookies = cookies
        self.auth = auth
        self.timeout = timeout
        self.headers = headers or {}

    def capabilities_url(self, service_url):
        '''Return a capabilities url
        @type service_url: string
        @param service_url: base url of WCS service
        @rtype: string
        @return: getCapabilities URL
        '''
        base = service_url.rstrip('?&')
        delim = '?' if '?' not in base else '&'
        params = [('service', 'WCS'), ('request', 'GetCapabilities')]
        if self.version:
            params.append(('version', self.version))
        return base + delim + urlencode(params)

    def read(self, service_url, timeout=None):
        '''Get and parse a WCS capabilities document, returning an
        elementtree tree

        @type service_url: string
        @param service_url: The base url, to which is appended the service,
        version, and request parameters
        @rtype: elementtree tree
        @return: An elementtree tree representation of the capabilities document
        '''
        url = self.capabilities_url(service_url)
        to = timeout if timeout is not None else self.timeout
        resp = requests.get(url, headers=self.headers, cookies=self.cookies,
                            auth=self.auth, timeout=to)
        resp.raise_for_status()
        return self.readString(resp.content)

    def readString(self, st):
        '''Parse a WCS capabilities document, returning an
        instance of WCSCapabilitiesInfoset
        string should be an XML capabilities document
        '''
        if isinstance(st, str):
            st = st.encode('utf-8')
        parser = etree.XMLParser(ns_clean=True, recover=True)
        root = etree.fromstring(st, parser=parser)
        return etree.ElementTree(root)","class WCSCapabilitiesReader(object):
    '''Read and parses WCS capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version=None, cookies=None, auth=None, timeout=30, headers=None):
        '''Initialize
        @type version: string
        @param version: WCS Version parameter e.g '1.0.0'
        '''
        self.version = version
        self.cookies = cookies
        self.auth = auth
        self.timeout = timeout
        self.headers = headers or {}

    def capabilities_url(self, service_url):
        '''Return a capabilities url
        @type service_url: string
        @param service_url: base url of WCS service
        @rtype: string
        @return: getCapabilities URL
        '''
        # Parse the service URL to handle existing query parameters
        parsed_url = urllib.parse.urlparse(service_url)
        query_params = urllib.parse.parse_qs(parsed_url.query)
        
        # Add or update WCS parameters
        query_params['service'] = 'WCS'
        if self.version:
            query_params['version'] = self.version
        query_params['request'] = 'GetCapabilities'
        
        # Reconstruct the query string
        query_string = urllib.parse.urlencode(query_params, doseq=True)
        
        # Reconstruct the full URL
        new_url = urllib.parse.urlunparse((
            parsed_url.scheme,
            parsed_url.netloc,
            parsed_url.path,
            parsed_url.params,
            query_string,
            parsed_url.fragment
        ))
        
        return new_url

    def read(self, service_url, timeout=30):
        '''Get and parse a WCS capabilities document, returning an
        elementtree tree

        @type service_url: string
        @param service_url: The base url, to which is appended the service,
        version, and request parameters
        @rtype: elementtree tree
        @return: An elementtree tree representation of the capabilities document
        '''
        # Get the capabilities URL
        url = self.capabilities_url(service_url)
        
        # Create request with headers
        request = urllib.request.Request(url, headers=self.headers)
        
        # Handle authentication if provided
        if self.auth:
            # Add authentication handler
            password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
            password_mgr.add_password(None, url, self.auth[0], self.auth[1])
            handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
            opener = urllib.request.build_opener(handler)
            urllib.request.install_opener(opener)
        
        # Make the request
        response = urllib.request.urlopen(request, timeout=timeout)
        
        # Parse the response
        return etree.parse(response)

    def readString(self, st):
        '''Parse a WCS capabilities document, returning an
        instance of WCSCapabilitiesInfoset
        string should be an XML capabilities document
        '''
        # Parse the XML string directly
        return etree.parse(io.StringIO(st))","class WCSCapabilitiesReader(object):
    '''Read and parses WCS capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version=None, cookies=None, auth=None, timeout=30, headers=None):
        '''Initialize
        @type version: string
        @param version: WCS Version parameter e.g '1.0.0'
        '''
        self.version = version or '1.0.0'
        self.cookies = cookies
        self.auth = auth
        self.timeout = timeout
        self.headers = headers or {}

    def capabilities_url(self, service_url):
        '''Return a capabilities url
        @type service_url: string
        @param service_url: base url of WCS service
        @rtype: string
        @return: getCapabilities URL
        '''
        params = {
            'service': 'WCS',
            'version': self.version,
            'request': 'GetCapabilities'
        }
        
        if '?' in service_url:
            separator = '&'
        else:
            separator = '?'
            
        query_string = urllib.parse.urlencode(params)
        return service_url + separator + query_string

    def read(self, service_url, timeout=30):
        '''Get and parse a WCS capabilities document, returning an
        elementtree tree

        @type service_url: string
        @param service_url: The base url, to which is appended the service,
        version, and request parameters
        @rtype: elementtree tree
        @return: An elementtree tree representation of the capabilities document
        '''
        capabilities_url = self.capabilities_url(service_url)
        
        request = urllib.request.Request(capabilities_url, headers=self.headers)
        
        if self.auth:
            import base64
            credentials = base64.b64encode(f""{self.auth[0]}:{self.auth[1]}"".encode()).decode()
            request.add_header('Authorization', f'Basic {credentials}')
        
        if self.cookies:
            cookie_string = '; '.join([f""{k}={v}"" for k, v in self.cookies.items()])
            request.add_header('Cookie', cookie_string)
        
        with urllib.request.urlopen(request, timeout=timeout or self.timeout) as response:
            content = response.read()
        
        return etree.fromstring(content)

    def readString(self, st):
        '''Parse a WCS capabilities document, returning an
        instance of WCSCapabilitiesInfoset
        string should be an XML capabilities document
        '''
        return etree.fromstring(st.encode() if isinstance(st, str) else st)",full_docstr,0.824,0.6907630522088354,0.6088709677419355,0.74,0.6476987379173562,0.8425925925925926,0.6821345707656613,0.5906976744186047,0.9130966067314148,0.9139764308929443,0.9135362505912781,0.9138882756233215,0.8106079545454545,0.7018739352640545,0.5743589743589743,0.5077186963979416,0.6303236797274275,0.5057787893252047,0.6395759717314488,0.4814159292035398,0.42021276595744683,0.8484753370285034,0.8971359729766846,0.8721274137496948,0.8920202255249023,0.7829479069767444,0.7916666666666665,0.6501901140684411,0.5801526717557252,0.6742424242424242,0.585489498263276,0.7595959595959596,0.5566801619433198,0.4746450304259635,0.8797778487205505,0.9020394682884216,0.8907696008682251,0.899762749671936,0.7805347933884299,0.563935472717948,0.5273664644872246,0.5285127890219302,0.5625,0.6373626373626373,0.4952399981734188,0.4116001883647279,0.5095307444998874,0.4444444444444444,0.6153846153846154,0.5297394856066056,0.498484958155452,0.5247770135749997,0.4583333333333333,0.6373626373626373
388390,fossasia/AYABInterface,fossasia_AYABInterface/AYABInterface/communication/cache.py,AYABInterface.communication.cache.NeedlePositionCache,"class NeedlePositionCache(object):

    """"""Convert and cache needle positions.""""""

    def __init__(self, get_needle_positions, machine):
        """"""Create a new NeedlePositions object.""""""
        self._get = get_needle_positions
        self._machine = machine
        self._get_cache = {}
        self._needle_position_bytes_cache = {}
        self._line_configuration_message_cache = {}

    def get(self, line_number):
        """"""Return the needle positions or None.

        :param int line_number: the number of the line
        :rtype: list
        :return: the needle positions for a specific line specified by
          :paramref:`line_number` or :obj:`None` if no were given
        """"""
        if line_number not in self._get_cache:
            self._get_cache[line_number] = self._get(line_number)
        return self._get_cache[line_number]

    def is_last(self, line_number):
        """"""Whether the line number is has no further lines.

        :rtype: bool
        :return: is the next line above the line number are not specified
        """"""
        return self.get(line_number + 1) is None

    def get_bytes(self, line_number):
        """"""Get the bytes representing needle positions or None.

        :param int line_number: the line number to take the bytes from
        :rtype: bytes
        :return: the bytes that represent the message or :obj:`None` if no
          data is there for the line.

        Depending on the :attr:`machine`, the length and result may vary.
        """"""
        if line_number not in self._needle_position_bytes_cache:
            line = self._get(line_number)
            if line is None:
                line_bytes = None
            else:
                line_bytes = self._machine.needle_positions_to_bytes(line)
            self._needle_position_bytes_cache[line_number] = line_bytes
        return self._needle_position_bytes_cache[line_number]

    def get_line_configuration_message(self, line_number):
        """"""Return the cnfLine content without id for the line.

        :param int line_number: the number of the line
        :rtype: bytes
        :return: a cnfLine message without id as defined in :ref:`cnfLine`
        """"""
        if line_number not in self._line_configuration_message_cache:
            line_bytes = self.get_bytes(line_number)
            if line_bytes is not None:
                line_bytes = bytes([line_number & 255]) + line_bytes
                line_bytes += bytes([self.is_last(line_number)])
                line_bytes += crc8(line_bytes).digest()
            self._line_configuration_message_cache[line_number] = line_bytes
            del line_bytes
        line = self._line_configuration_message_cache[line_number]
        if line is None:
            # no need to cache a lot of empty lines
            line = (bytes([line_number & 255]) +
                    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00' +
                    b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x01')
            line += crc8(line).digest()
        return line","class NeedlePositionCache(object):
    '''Convert and cache needle positions.'''

    def __init__(self, get_needle_positions, machine):
    '''Create a new NeedlePositions object.'''
        pass

    def get(self, line_number):
    '''Return the needle positions or None.

        :param int line_number: the number of the line
        :rtype: list
        :return: the needle positions for a specific line specified by
          :paramref:`line_number` or :obj:`None` if no were given
        '''
        pass

    def is_last(self, line_number):
    '''Whether the line number is has no further lines.

        :rtype: bool
        :return: is the next line above the line number are not specified
        '''
        pass

    def get_bytes(self, line_number):
    '''Get the bytes representing needle positions or None.

        :param int line_number: the line number to take the bytes from
        :rtype: bytes
        :return: the bytes that represent the message or :obj:`None` if no
          data is there for the line.

        Depending on the :attr:`machine`, the length and result may vary.
        '''
        pass

    def get_line_configuration_message(self, line_number):
    '''Return the cnfLine content without id for the line.

        :param int line_number: the number of the line
        :rtype: bytes
        :return: a cnfLine message without id as defined in :ref:`cnfLine`
        '''
        pass

",6,6,snippet_658,0.4375,"class NeedlePositionCache(object):
    '''Convert and cache needle positions.'''

    def __init__(self, get_needle_positions, machine):
        '''Create a new NeedlePositions object.'''
        self._get_callback = get_needle_positions
        self.machine = machine
        self._cache = {}
        self._bytes_cache = {}
        self._msg_cache = {}

    def get(self, line_number):
        '''Return the needle positions or None.

            :param int line_number: the number of the line
            :rtype: list
            :return: the needle positions for a specific line specified by
              :paramref:`line_number` or :obj:`None` if none were given
        '''
        if line_number in self._cache:
            return self._cache[line_number]
        pos = self._get_callback(line_number)
        if pos is not None:
            pos = list(pos)
        self._cache[line_number] = pos
        return pos

    def is_last(self, line_number):
        '''Whether the line number has no further lines.

            :rtype: bool
            :return: is the next line above the line number not specified
        '''
        # If the very next line has no positions, we consider this the last
        return self.get(line_number + 1) is None

    def get_bytes(self, line_number):
        '''Get the bytes representing needle positions or None.

            :param int line_number: the line number to take the bytes from
            :rtype: bytes
            :return: the bytes that represent the message or :obj:`None` if no
              data is there for the line.

            Depending on the :attr:`machine`, the length and result may vary.
        '''
        if line_number in self._bytes_cache:
            return self._bytes_cache[line_number]

        positions = self.get(line_number)
        if positions is None:
            self._bytes_cache[line_number] = None
            return None

        # Determine byte-array length
        if hasattr(self.machine, 'needle_byte_size'):
            size = self.machine.needle_byte_size
        elif hasattr(self.machine, 'needle_array_length'):
            size = self.machine.needle_array_length
        elif hasattr(self.machine, 'needle_count'):
            size = math.ceil(self.machine.needle_count / 8)
        else:
            max_needle = max(positions) if positions else -1
            size = math.ceil((max_needle + 1) / 8)

        ba = bytearray(size)
        for n in positions:
            if n < 0:
                continue
            idx = n // 8
            bit = n % 8
            if idx < size:
                ba[idx] |= (1 << bit)

        data = bytes(ba)
        self._bytes_cache[line_number] = data
        return data

    def get_line_configuration_message(self, line_number):
        '''Return the cnfLine content without id for the line.

            :param int line_number: the number of the line
            :rtype: bytes
            :return: a cnfLine message without id as defined in :ref:`cnfLine`
        '''
        if line_number in self._msg_cache:
            return self._msg_cache[line_number]

        bts = self.get_bytes(line_number)
        if bts is None:
            self._msg_cache[line_number] = None
            return None

        # pack line number as little-endian unsigned short, then data
        msg = struct.pack('<H', line_number) + bts
        self._msg_cache[line_number] = msg
        return msg","class NeedlePositionCache(object):
    '''Convert and cache needle positions.'''

    def __init__(self, get_needle_positions, machine):
        '''Create a new NeedlePositions object.'''
        self._get_needle_positions = get_needle_positions
        self.machine = machine
        self._cache = {}
        self._bytes_cache = {}

    def get(self, line_number):
        '''Return the needle positions or None.

        :param int line_number: the number of the line
        :rtype: list
        :return: the needle positions for a specific line specified by
          :paramref:`line_number` or :obj:`None` if no were given
        '''
        if line_number not in self._cache:
            self._cache[line_number] = self._get_needle_positions(line_number)
        return self._cache[line_number]

    def is_last(self, line_number):
        '''Whether the line number is has no further lines.

        :rtype: bool
        :return: is the next line above the line number are not specified
        '''
        current = self.get(line_number)
        next_line = self.get(line_number + 1)
        return current is not None and next_line is None

    def get_bytes(self, line_number):
        '''Get the bytes representing needle positions or None.

        :param int line_number: the line number to take the bytes from
        :rtype: bytes
        :return: the bytes that represent the message or :obj:`None` if no
          data is there for the line.

        Depending on the :attr:`machine`, the length and result may vary.
        '''
        if line_number not in self._bytes_cache:
            positions = self.get(line_number)
            if positions is None:
                self._bytes_cache[line_number] = None
            else:
                # Convert needle positions to bytes based on machine type
                if hasattr(self.machine, 'get_bytes_for_needle_positions'):
                    self._bytes_cache[line_number] = self.machine.get_bytes_for_needle_positions(positions)
                else:
                    # Default implementation - convert to bytes
                    self._bytes_cache[line_number] = bytes(positions)
        return self._bytes_cache[line_number]

    def get_line_configuration_message(self, line_number):
        '''Return the cnfLine content without id for the line.

        :param int line_number: the number of the line
        :rtype: bytes
        :return: a cnfLine message without id as defined in :ref:`cnfLine`
        '''
        needle_bytes = self.get_bytes(line_number)
        if needle_bytes is None:
            return None
        
        # Create cnfLine message without id
        # This is a basic implementation - in practice this would follow specific protocol
        if hasattr(self.machine, 'create_cnf_line_message'):
            return self.machine.create_cnf_line_message(needle_bytes)
        else:
            # Default implementation
            return needle_bytes","class NeedlePositionCache(object):
    '''Convert and cache needle positions.'''

    def __init__(self, get_needle_positions, machine):
        '''Create a new NeedlePositions object.'''
        self._get_needle_positions = get_needle_positions
        self._machine = machine
        self._cache = {}

    def get(self, line_number):
        '''Return the needle positions or None.

        :param int line_number: the number of the line
        :rtype: list
        :return: the needle positions for a specific line specified by
          :paramref:`line_number` or :obj:`None` if no were given
        '''
        if line_number not in self._cache:
            self._cache[line_number] = self._get_needle_positions(line_number)
        return self._cache[line_number]

    def is_last(self, line_number):
        '''Whether the line number is has no further lines.

        :rtype: bool
        :return: is the next line above the line number are not specified
        '''
        return self.get(line_number + 1) is None

    def get_bytes(self, line_number):
        '''Get the bytes representing needle positions or None.

        :param int line_number: the line number to take the bytes from
        :rtype: bytes
        :return: the bytes that represent the message or :obj:`None` if no
          data is there for the line.

        Depending on the :attr:`machine`, the length and result may vary.
        '''
        positions = self.get(line_number)
        if positions is None:
            return None
        return self._machine.needle_positions_to_bytes(positions)

    def get_line_configuration_message(self, line_number):
        '''Return the cnfLine content without id for the line.

        :param int line_number: the number of the line
        :rtype: bytes
        :return: a cnfLine message without id as defined in :ref:`cnfLine`
        '''
        positions = self.get(line_number)
        if positions is None:
            return b''
        return self._machine.get_line_configuration_message(positions)",full_docstr,0.7181926278240189,0.5935637663885579,0.5113500597371564,0.6634958382877527,0.6178840679051705,0.7446236559139785,0.6177658142664872,0.5296495956873315,0.8793009519577026,0.8815105557441711,0.8804042935371399,0.8812891244888306,0.7973876470588239,0.8138639281129654,0.6743886743886743,0.6038709677419355,0.7291399229781771,0.616879566770677,0.8731942215088283,0.7604501607717041,0.6586151368760065,0.9329275488853455,0.8840959072113037,0.9078555703163147,0.8887478113174438,0.8226317431192661,0.7619047619047619,0.7014925373134328,0.658682634730539,0.744047619047619,0.4294196883752848,0.9452054794520548,0.8832951945080092,0.8188073394495413,0.9554203748703003,0.8695567846298218,0.9104686379432678,0.8774424195289612,0.8318059633027526,0.5163537139853617,0.4209016118246404,0.5419052106121424,0.5686274509803921,0.5339805825242718,0.5234930672634294,0.5384852052897013,0.5695742520373835,0.5490196078431373,0.4368932038834951,0.4866177596944857,0.5180258860016815,0.5525012477061427,0.5555555555555556,0.3203883495145631
289340,chimera0/accel-brain-code,Reinforcement-Learning/pyqlearning/misc/beta_dist.py,beta_dist.BetaDist,"class BetaDist(object):
    '''
    Beta Distribusion for Thompson Sampling.
    '''
    # Alpha
    __default_alpha = 1
    # Beta
    __default_beta = 1
    # The number of success.
    __success = 0
    # The number of failure.
    __failure = 0

    def __init__(self, default_alpha=1, default_beta=1):
        '''
        Initialization

        Args:
            default_alpha:      Alpha
            default_beta:       Beta

        '''
        if isinstance(default_alpha, int) is False:
            if isinstance(default_alpha, float) is False:
                raise TypeError()
        if isinstance(default_beta, int) is False:
            if isinstance(default_beta, float) is False:
                raise TypeError()

        if default_alpha <= 0:
            raise ValueError()
        if default_beta <= 0:
            raise ValueError()

        self.__success += 0
        self.__failure += 0
        self.__default_alpha = default_alpha
        self.__default_beta = default_beta

    def observe(self, success, failure):
        '''
        Observation data.

        Args:
            success:      The number of success.
            failure:      The number of failure.

        '''
        if isinstance(success, int) is False:
            if isinstance(success, float) is False:
                raise TypeError()
        if isinstance(failure, int) is False:
            if isinstance(failure, float) is False:
                raise TypeError()

        if success <= 0:
            raise ValueError()
        if failure <= 0:
            raise ValueError()

        self.__success += success
        self.__failure += failure

    def likelihood(self):
        '''
        Compute likelihood.

        Returns:
            likelihood.
        '''
        try:
            likelihood = self.__success / (self.__success + self.__failure)
        except ZeroDivisionError:
            likelihood = 0.0
        return likelihood

    def expected_value(self):
        '''
        Compute expected value.

        Returns:
            Expected value.
        '''
        alpha = self.__success + self.__default_alpha
        beta = self.__failure + self.__default_beta

        try:
            expected_value = alpha / (alpha + beta)
        except ZeroDivisionError:
            expected_value = 0.0
        return expected_value

    def variance(self):
        '''
        Compute variance.

        Returns:
            variance.
        '''
        alpha = self.__success + self.__default_alpha
        beta = self.__failure + self.__default_beta

        try:
            variance = alpha * beta / ((alpha + beta) ** 2) * (alpha + beta + 1)
        except ZeroDivisionError:
            variance = 0.0
        return variance","class BetaDist(object):
    '''
    Beta Distribusion for Thompson Sampling.
    '''

    def __init__(self, default_alpha=1, default_beta=1):
    '''
        Initialization

        Args:
            default_alpha:      Alpha
            default_beta:       Beta

        '''
                        pass

    def observe(self, success, failure):
    '''
        Observation data.

        Args:
            success:      The number of success.
            failure:      The number of failure.

        '''
        pass

    def likelihood(self):
    '''
        Compute likelihood.

        Returns:
            likelihood.
        '''
        pass

    def expected_value(self):
    '''
        Compute expected value.

        Returns:
            Expected value.
        '''
        pass

    def variance(self):
    '''
        Compute variance.

        Returns:
            variance.
        '''
        pass

",6,6,snippet_492,0.84375,"class BetaDist(object):
    '''
    Beta Distribution for Thompson Sampling.
    '''

    def __init__(self, default_alpha=1, default_beta=1):
        '''
        Initialization

        Args:
            default_alpha: Alpha
            default_beta:  Beta
        '''
        self.default_alpha = default_alpha
        self.default_beta = default_beta
        self.alpha = default_alpha
        self.beta = default_beta

    def observe(self, success, failure):
        '''
        Observation data.

        Args:
            success: The number of successes.
            failure: The number of failures.
        '''
        self.alpha += success
        self.beta += failure

    def likelihood(self):
        '''
        Compute likelihood (normalization constant B(alpha, beta)).

        Returns:
            likelihood.
        '''
        return math.gamma(self.alpha) * math.gamma(self.beta) / math.gamma(self.alpha + self.beta)

    def expected_value(self):
        '''
        Compute expected value.

        Returns:
            Expected value.
        '''
        total = self.alpha + self.beta
        return self.alpha / total if total > 0 else 0

    def variance(self):
        '''
        Compute variance.

        Returns:
            variance.
        '''
        total = self.alpha + self.beta
        return (self.alpha * self.beta) / (total**2 * (total + 1)) if total > 0 else 0","class BetaDist(object):
    '''
    Beta Distribution for Thompson Sampling.
    '''

    def __init__(self, default_alpha=1, default_beta=1):
        '''
        Initialization

        Args:
            default_alpha:      Alpha
            default_beta:       Beta

        '''
        self.alpha = default_alpha
        self.beta = default_beta

    def observe(self, success, failure):
        '''
        Observation data.

        Args:
            success:      The number of success.
            failure:      The number of failure.

        '''
        self.alpha += success
        self.beta += failure

    def likelihood(self):
        '''
        Compute likelihood.

        Returns:
            likelihood.
        '''
        return stats.beta.pdf(np.linspace(0, 1, 1000), self.alpha, self.beta)

    def expected_value(self):
        '''
        Compute expected value.

        Returns:
            Expected value.
        '''
        return self.alpha / (self.alpha + self.beta)

    def variance(self):
        '''
        Compute variance.

        Returns:
            variance.
        '''
        return (self.alpha * self.beta) / ((self.alpha + self.beta) ** 2 * (self.alpha + self.beta + 1))","class BetaDist(object):
    '''
    Beta Distribusion for Thompson Sampling.
    '''

    def __init__(self, default_alpha=1, default_beta=1):
        '''
        Initialization

        Args:
            default_alpha:      Alpha
            default_beta:       Beta

        '''
        self.alpha = default_alpha
        self.beta = default_beta

    def observe(self, success, failure):
        '''
        Observation data.

        Args:
            success:      The number of success.
            failure:      The number of failure.

        '''
        self.alpha += success
        self.beta += failure

    def likelihood(self):
        '''
        Compute likelihood.

        Returns:
            likelihood.
        '''
        return random.betavariate(self.alpha, self.beta)

    def expected_value(self):
        '''
        Compute expected value.

        Returns:
            Expected value.
        '''
        return self.alpha / (self.alpha + self.beta)

    def variance(self):
        '''
        Compute variance.

        Returns:
            variance.
        '''
        return (self.alpha * self.beta) / ((self.alpha + self.beta) ** 2 * (self.alpha + self.beta + 1))",full_docstr,0.605911330049261,0.38118811881188125,0.2935323383084577,0.5123152709359606,0.27575576658439893,0.9094202898550725,0.68,0.5072992700729927,0.8972752690315247,0.8197768926620483,0.8567771315574646,0.8269190788269043,0.7956423705722069,0.582010582010582,0.3936170212765957,0.31016042780748665,0.5026455026455026,0.22428838924061428,0.9744680851063829,0.7564102564102564,0.6223175965665236,0.9201659560203552,0.8113521337509155,0.8623400330543518,0.8210616111755371,0.7747524795640324,0.5806451612903225,0.41081081081081083,0.33152173913043476,0.5161290322580645,0.20764407594204956,0.990990990990991,0.8099547511312217,0.6727272727272727,0.9254574775695801,0.8091447353363037,0.863401472568512,0.8194436430931091,0.7811102724795638,0.2115362353471072,0.167207587782792,0.2155476966675928,0.2698412698412698,0.1935483870967742,0.1731916252320729,0.1417569934902575,0.2345305861204032,0.2116402116402116,0.1048387096774193,0.1758520199863249,0.1421003806263372,0.2448287780013316,0.2116402116402116,0.1048387096774193
307739,cltk/cltk,src/cltk/tokenizers/line.py,cltk.tokenizers.line.LineTokenizer,"class LineTokenizer:
    """"""Tokenize text by line; designed for study of poetry.""""""

    def __init__(self, language):
        """"""Lower incoming language name and assemble variables.
        :type language: str
        :param language : Language for sentences tokenization.
        """"""
        self.language = (
            language.lower()
        )  # Keep in case there winds up being a need for language-specific line tokenization

    def tokenize(self, untokenized_string: str, include_blanks=False):
        """"""Tokenize lines by '\n'.

        :type untokenized_string: str
        :param untokenized_string: A string containing one of more sentences.
        :param include_blanks: Boolean; If True, blanks will be preserved by """" in returned list of strings; Default is False.
        :rtype : list of strings
        """"""

        # load tokenizer
        assert isinstance(
            untokenized_string, str
        ), ""Incoming argument must be a string.""

        # make list of tokenized sentences
        if include_blanks:
            tokenized_lines = untokenized_string.splitlines()
        else:
            tokenized_lines = [
                line for line in untokenized_string.splitlines() if line != """"
            ]
        return tokenized_lines","class LineTokenizer:
    '''Tokenize text by line; designed for study of poetry.'''

    def __init__(self, language):
    '''Lower incoming language name and assemble variables.
        :type language: str
        :param language : Language for sentences tokenization.
        '''
        pass

    def tokenize(self, untokenized_string: str, include_blanks=False):
    '''Tokenize lines by '
'.

        :type untokenized_string: str
        :param untokenized_string: A string containing one of more sentences.
        :param include_blanks: Boolean; If True, blanks will be preserved by """" in returned list of strings; Default is False.
        :rtype : list of strings
        '''
        pass

",3,3,snippet_514,1.0,"class LineTokenizer:
    '''Tokenize text by line; designed for study of poetry.'''

    def __init__(self, language):
        '''Lower incoming language name and assemble variables.
        :type language: str
        :param language : Language for sentences tokenization.
        '''
        self.language = language.lower()

    def tokenize(self, untokenized_string: str, include_blanks=False):
        '''Tokenize lines by '\\n'.

        :type untokenized_string: str
        :param untokenized_string: A string containing one of more sentences.
        :param include_blanks: Boolean; If True, blanks will be preserved by """" in returned list of strings; Default is False.
        :rtype : list of strings
        '''
        text = untokenized_string.replace('\r\n', '\n').replace('\r', '\n')
        lines = text.split('\n')
        if not include_blanks:
            lines = [ln for ln in lines if ln.strip() != """"]
        return lines","class LineTokenizer:
    '''Tokenize text by line; designed for study of poetry.'''

    def __init__(self, language):
        '''Lower incoming language name and assemble variables.
        :type language: str
        :param language : Language for sentences tokenization.
        '''
        self.language = language.lower()

    def tokenize(self, untokenized_string: str, include_blanks=False):
        '''Tokenize lines by '
'.

        :type untokenized_string: str
        :param untokenized_string: A string containing one of more sentences.
        :param include_blanks: Boolean; If True, blanks will be preserved by """" in returned list of strings; Default is False.
        :rtype : list of strings
        '''
        lines = untokenized_string.split('\n')
        
        if include_blanks:
            return lines
        else:
            return [line for line in lines if line.strip()]","class LineTokenizer:
    '''Tokenize text by line; designed for study of poetry.'''

    def __init__(self, language):
        '''Lower incoming language name and assemble variables.
        :type language: str
        :param language : Language for sentences tokenization.
        '''
        self.language = language.lower()

    def tokenize(self, untokenized_string: str, include_blanks=False):
        '''Tokenize lines by '\n'.

        :type untokenized_string: str
        :param untokenized_string: A string containing one of more sentences.
        :param include_blanks: Boolean; If True, blanks will be preserved by """" in returned list of strings; Default is False.
        :rtype : list of strings
        '''
        lines = untokenized_string.split('\n')
        
        if include_blanks:
            return [line if line.strip() else """" for line in lines]
        else:
            return [line for line in lines if line.strip()]",full_docstr,0.763779527559055,0.6746031746031746,0.648,0.7559055118110235,0.5939113448865369,0.8221153846153846,0.6956521739130435,0.6262135922330098,0.9386917352676392,0.9010838270187378,0.919503390789032,0.9047083854675293,0.8672329661016949,0.8278688524590163,0.7355371900826446,0.6833333333333333,0.7950819672131147,0.5515558636283207,0.9371428571428572,0.8218390804597702,0.7283236994219653,0.9605300426483154,0.9004889726638794,0.9295409917831421,0.9061532020568848,0.8842116842105262,0.8221343873517787,0.7250996015936256,0.6827309236947792,0.7747035573122529,0.5889553762675068,0.900523560209424,0.7736842105263158,0.6878306878306878,0.9539735913276672,0.9037389755249023,0.9281771183013916,0.9085231423377991,0.880702947368421,0.4423644472786667,0.4462311172979319,0.4733323800619779,0.3953488372093023,0.4545454545454545,0.4488655957277446,0.44258161545219,0.4807877442029745,0.3720930232558139,0.5,0.464199048272463,0.475785003309489,0.5089181665245494,0.3720930232558139,0.5
289277,chimera0/accel-brain-code,Automatic-Summarization/pysummarization/web_scraping.py,Automatic-Summarization.pysummarization.web_scraping.WebScraping,"class WebScraping(object):
    '''
    Object of Web-scraping.

    This is only a demo.
    '''

    # List of scraped dom objects.
    __dom_object_list = [""body""]
    # List of not scraped dom objects.
    __remove_object_list = [""script"", ""style""]

    # Object of ReadableWebPdf.
    __readable_web_pdf = None

    def get_readable_web_pdf(self):
        ''' getter '''
        if isinstance(self.__readable_web_pdf, ReadableWebPDF) is False and self.__readable_web_pdf is not None:
            raise TypeError(""The type of __readable_web_pdf must be ReadableWebPDF."")
        return self.__readable_web_pdf

    def set_readable_web_pdf(self, value):
        ''' setter '''
        if isinstance(value, ReadableWebPDF) is False and value is not None:
            raise TypeError(""The type of __readable_web_pdf must be ReadableWebPDF."")
        self.__readable_web_pdf = value

    readable_web_pdf = property(get_readable_web_pdf, set_readable_web_pdf)

    def scrape(self, url):
        '''
        Execute Web-Scraping.
        The target dom objects are in self.__dom_object_list.

        Args:
            url:    Web site url.

        Returns:
            The result. this is a string.

        @TODO(chimera0): check URLs format.
        '''
        if isinstance(url, str) is False:
            raise TypeError(""The type of url must be str."")

        if self.readable_web_pdf is not None and self.readable_web_pdf.is_pdf_url(url) is True:
            web_data = self.readable_web_pdf.url_to_text(url)
        else:
            web_data = """"
            req = urllib.request.Request(url=url)
            with urllib.request.urlopen(req) as f:
                web = f.read().decode('utf-8')
                dom = pq(web)
                [dom(remove_object).remove() for remove_object in self.__remove_object_list]

                for dom_object in self.__dom_object_list:
                    web_data += dom(dom_object).text()

        sleep(1)
        return web_data","class WebScraping(object):
    '''
    Object of Web-scraping.

    This is only a demo.
    '''

    def get_readable_web_pdf(self):
    ''' getter '''
        pass

    def set_readable_web_pdf(self, value):
    ''' setter '''
        pass

    def scrape(self, url):
    '''
        Execute Web-Scraping.
        The target dom objects are in self.__dom_object_list.

        Args:
            url:    Web site url.

        Returns:
            The result. this is a string.

        @TODO(chimera0): check URLs format.
        '''
        pass

",4,4,snippet_491,0.1818181818181818,"class WebScraping(object):
    '''
    Object of Web-scraping.

    This is only a demo.
    '''
    def __init__(self, dom_object_list=None):
        self.__dom_object_list = dom_object_list or ['title', 'h1', 'h2', 'h3', 'p']
        self.__readable_web_pdf = False

    def get_readable_web_pdf(self):
        ''' getter '''
        return self.__readable_web_pdf

    def set_readable_web_pdf(self, value):
        ''' setter '''
        self.__readable_web_pdf = bool(value)

    def scrape(self, url):
        '''
        Execute Web-Scraping.
        The target dom objects are in self.__dom_object_list.

        Args:
            url:    Web site url.

        Returns:
            The result. this is a string.
        '''
        if not url.startswith(('http://', 'https://')):
            raise ValueError(f""Invalid URL format: {url}"")
        resp = requests.get(url)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, 'html.parser')
        texts = []
        for tag in self.__dom_object_list:
            for elem in soup.find_all(tag):
                txt = elem.get_text(strip=True)
                if txt:
                    texts.append(txt)
        return '\n'.join(texts)","class WebScraping(object):
    '''
    Object of Web-scraping.

    This is only a demo.
    '''

    def __init__(self):
        self.__readable_web_pdf = None
        self.__dom_object_list = []

    def get_readable_web_pdf(self):
        ''' getter '''
        return self.__readable_web_pdf

    def set_readable_web_pdf(self, value):
        ''' setter '''
        self.__readable_web_pdf = value

    def scrape(self, url):
        '''
        Execute Web-Scraping.
        The target dom objects are in self.__dom_object_list.

        Args:
            url:    Web site url.

        Returns:
            The result. this is a string.

        @TODO(chimera0): check URLs format.
        '''
        import requests
        from bs4 import BeautifulSoup
        
        try:
            response = requests.get(url)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extract text from DOM objects
            result = """"
            for dom_obj in self.__dom_object_list:
                elements = soup.select(dom_obj) if isinstance(dom_obj, str) else [soup.find(dom_obj)]
                for element in elements:
                    if element:
                        result += element.get_text() + ""\n""
            
            return result.strip()
        except Exception as e:
            return f""Error scraping {url}: {str(e)}""","class WebScraping(object):
    '''
    Object of Web-scraping.

    This is only a demo.
    '''
    
    def __init__(self):
        self.__readable_web_pdf = None
        self.__dom_object_list = ['p', 'div', 'span', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']

    def get_readable_web_pdf(self):
        ''' getter '''
        return self.__readable_web_pdf

    def set_readable_web_pdf(self, value):
        ''' setter '''
        self.__readable_web_pdf = value

    def scrape(self, url):
        '''
        Execute Web-Scraping.
        The target dom objects are in self.__dom_object_list.

        Args:
            url:    Web site url.

        Returns:
            The result. this is a string.

        @TODO(chimera0): check URLs format.
        '''
        try:
            response = requests.get(url)
            response.raise_for_status()
            
            if url.lower().endswith('.pdf'):
                pdf_reader = PyPDF2.PdfReader(BytesIO(response.content))
                text = """"
                for page in pdf_reader.pages:
                    text += page.extract_text()
                self.set_readable_web_pdf(text)
                return text
            else:
                soup = BeautifulSoup(response.content, 'html.parser')
                scraped_text = """"
                
                for dom_object in self.__dom_object_list:
                    elements = soup.find_all(dom_object)
                    for element in elements:
                        scraped_text += element.get_text().strip() + ""\n""
                
                return scraped_text.strip()
                
        except Exception as e:
            return f""Error scraping {url}: {str(e)}""",full_docstr,0.5232273838630805,0.36363636363636365,0.30617283950617286,0.4498777506112469,0.3267515367789384,0.8172757475083057,0.5733333333333334,0.4782608695652174,0.8376169204711914,0.81232088804245,0.824774980545044,0.8147815465927124,0.7673884172661877,0.5263157894736842,0.3846153846153847,0.3285024154589372,0.430622009569378,0.34286249460337476,0.819078947368421,0.5907590759075908,0.5099337748344371,0.846347987651825,0.8216067552566528,0.8337939381599426,0.8240156173706055,0.7649903597122305,0.526077097505669,0.3826879271070615,0.33409610983981697,0.44897959183673475,0.40917302680968487,0.7814207650273224,0.5260273972602739,0.45054945054945056,0.834081768989563,0.829107940196991,0.8315874338150024,0.8296026587486267,0.7530000719424468,0.2704619228336283,0.2252808106189016,0.2712935121089097,0.2642857142857143,0.3209876543209876,0.3009780714097597,0.2811094606386802,0.3011978867287539,0.35,0.2716049382716049,0.3328098181125919,0.2965753881094424,0.3071506568276977,0.3571428571428571,0.3703703703703703
258893,baverman/covador,baverman_covador/covador/types.py,covador.types.ItemGetter,"class ItemGetter(object):
    """"""Default `Map` item getter.

    Treats data as a dict and invokes ``data.get`` with ``item.src`` key.
    """"""
    def get(self, data, item):
        """"""Get corresponding data for an item.

        Subsclasses can override this method to implement map access to more complex
        structures then plain dict.

        :param data: source data.
        :param item: item to get.
        """"""
        return data.get(item.src)

    def to_dict(self, data, multi=False):
        """"""Returns map data as a dict.""""""
        return data","class ItemGetter(object):
    '''Default `Map` item getter.

    Treats data as a dict and invokes ``data.get`` with ``item.src`` key.
    '''

    def get(self, data, item):
    '''Get corresponding data for an item.

        Subsclasses can override this method to implement map access to more complex
        structures then plain dict.

        :param data: source data.
        :param item: item to get.
        '''
        pass

    def to_dict(self, data, multi=False):
    '''Returns map data as a dict.'''
        pass

",3,3,snippet_428,1.0,"class ItemGetter(object):
    '''Default `Map` item getter.

    Treats data as a dict and invokes ``data.get`` with ``item.src`` key.
    '''

    def get(self, data, item):
        '''Get corresponding data for an item.

        Subclasses can override this method to implement map access to more complex
        structures than plain dict.

        :param data: source data.
        :param item: item to get.
        '''
        if data is None:
            return None
        try:
            return data.get(item.src)
        except Exception:
            return None

    def to_dict(self, data, multi=False):
        '''Returns map data as a dict.'''
        if multi:
            if data is None:
                return []
            result = []
            for element in data:
                result.append(self.to_dict(element, multi=False))
            return result

        if data is None:
            return {}
        # If it's already a dict or mapping, make a shallow copy
        try:
            return dict(data)
        except Exception:
            return {}","class ItemGetter(object):
    '''Default `Map` item getter.

    Treats data as a dict and invokes ``data.get`` with ``item.src`` key.
    '''

    def get(self, data, item):
        '''Get corresponding data for an item.

        Subsclasses can override this method to implement map access to more complex
        structures then plain dict.

        :param data: source data.
        :param item: item to get.
        '''
        return data.get(item.src)

    def to_dict(self, data, multi=False):
        '''Returns map data as a dict.'''
        if multi:
            return {key: values for key, values in data.items()}
        else:
            return {key: value for key, value in data.items()}","class ItemGetter(object):
    '''Default `Map` item getter.

    Treats data as a dict and invokes ``data.get`` with ``item.src`` key.
    '''

    def get(self, data, item):
        '''Get corresponding data for an item.

        Subsclasses can override this method to implement map access to more complex
        structures then plain dict.

        :param data: source data.
        :param item: item to get.
        '''
        if hasattr(data, 'get'):
            return data.get(item.src)
        else:
            return getattr(data, item.src, None)

    def to_dict(self, data, multi=False):
        '''Returns map data as a dict.'''
        if hasattr(data, 'to_dict'):
            return data.to_dict(multi=multi)
        elif isinstance(data, dict):
            return data
        else:
            return dict(data) if data else {}",full_docstr,0.7149758454106281,0.6536585365853658,0.6108374384236454,0.7149758454106281,0.5016792835919215,0.5507246376811594,0.5,0.4585365853658537,0.8463562726974487,0.9698876142501831,0.9039209485054016,0.9559351205825806,0.8057990434782608,0.888888888888889,0.8639053254437871,0.8622754491017964,0.888888888888889,0.695625225580731,0.7388535031847133,0.6923076923076923,0.6580645161290323,0.9351941347122192,0.989501416683197,0.9615816473960876,0.9837885499000549,0.8691996202531646,0.8216216216216217,0.8087431693989071,0.7734806629834254,0.8216216216216217,0.592864145942023,0.6304347826086957,0.5956284153005464,0.554945054945055,0.904410719871521,0.9771277904510498,0.9393640756607056,0.9693341255187988,0.8190494285714286,0.6526952276789658,0.3714337980288638,0.675621622490921,0.6470588235294118,0.9166666666666666,0.7586648162551531,0.6115905732759654,0.7760098682152353,0.6470588235294118,1.0,0.735816000047012,0.5601349083136072,0.7605800722665976,0.7058823529411765,0.9166666666666666
116987,Duke-GCB/DukeDSClient,Duke-GCB_DukeDSClient/ddsc/core/parallel.py,ddsc.core.parallel.Task,"class Task(object):
    """"""
    Represents a task that has a unique task id, a command specifying foreground code to run and
    a function that will be run in a background process.
    Command must have similar interface with before_run, create_context and after_run.
    """"""
    def __init__(self, task_id, wait_for_task_id, command):
        """"""
        Setup task so it can be executed.
        :param task_id: int: unique id of this task
        :param wait_for_task_id: int: unique id of the task that this one is waiting for
        :param command: object with foreground setup/teardown methods and background function
        """"""
        self.id = task_id
        self.wait_for_task_id = wait_for_task_id
        self.command = command
        self.func = command.func

    def before_run(self, parent_task_result):
        """"""
        Run in main process before run method.
        :param parent_task_result: object: result of previous task or None if no previous task
        """"""
        self.command.before_run(parent_task_result)

    def create_context(self, message_queue):
        """"""
        Run serially before the run method.
        :return object: context object passing state to the thread
        """"""
        return self.command.create_context(message_queue, self.id)

    def after_run(self, results):
        """"""
        Run in main process after run method.
        :param results: object: results from run method.
        """"""
        return self.command.after_run(results)

    def on_message(self, data):
        """"""
        Call on_message on our command passing data
        :param data: object: parameter passed to the on_message member of this task's command
        """"""
        self.command.on_message(data)","class Task(object):
    '''
    Represents a task that has a unique task id, a command specifying foreground code to run and
    a function that will be run in a background process.
    Command must have similar interface with before_run, create_context and after_run.
    '''

    def __init__(self, task_id, wait_for_task_id, command):
    '''
        Setup task so it can be executed.
        :param task_id: int: unique id of this task
        :param wait_for_task_id: int: unique id of the task that this one is waiting for
        :param command: object with foreground setup/teardown methods and background function
        '''
        pass

    def before_run(self, parent_task_result):
    '''
        Run in main process before run method.
        :param parent_task_result: object: result of previous task or None if no previous task
        '''
        pass

    def create_context(self, message_queue):
    '''
        Run serially before the run method.
        :return object: context object passing state to the thread
        '''
        pass

    def after_run(self, results):
    '''
        Run in main process after run method.
        :param results: object: results from run method.
        '''
        pass

    def on_message(self, data):
    '''
        Call on_message on our command passing data
        :param data: object: parameter passed to the on_message member of this task's command
        '''
        pass

",6,6,snippet_104,0.4285714285714285,"class Task(object):
    '''
    Represents a task that has a unique task id, a command specifying foreground code to run and
    a function that will be run in a background process.
    Command must have similar interface with before_run, create_context and after_run.
    '''

    def __init__(self, task_id, wait_for_task_id, command):
        '''
        Setup task so it can be executed.
        :param task_id: int: unique id of this task
        :param wait_for_task_id: int: unique id of the task that this one is waiting for
        :param command: object with foreground setup/teardown methods and background function
        '''
        self.task_id = task_id
        self.wait_for_task_id = wait_for_task_id
        self.command = command
        self.context = None

    def before_run(self, parent_task_result):
        '''
        Run in main process before run method.
        :param parent_task_result: object: result of previous task or None if no previous task
        '''
        return self.command.before_run(parent_task_result)

    def create_context(self, message_queue):
        '''
        Run serially before the run method.
        :return object: context object passing state to the thread
        '''
        self.context = self.command.create_context(message_queue)
        return self.context

    def after_run(self, results):
        '''
        Run in main process after run method.
        :param results: object: results from run method.
        '''
        return self.command.after_run(results)

    def on_message(self, data):
        '''
        Call on_message on our command passing data
        :param data: object: parameter passed to the on_message member of this task's command
        '''
        return self.command.on_message(data)","class Task(object):
    '''
    Represents a task that has a unique task id, a command specifying foreground code to run and
    a function that will be run in a background process.
    Command must have similar interface with before_run, create_context and after_run.
    '''

    def __init__(self, task_id, wait_for_task_id, command):
        '''
        Setup task so it can be executed.
        :param task_id: int: unique id of this task
        :param wait_for_task_id: int: unique id of the task that this one is waiting for
        :param command: object with foreground setup/teardown methods and background function
        '''
        self.task_id = task_id
        self.wait_for_task_id = wait_for_task_id
        self.command = command

    def before_run(self, parent_task_result):
        '''
        Run in main process before run method.
        :param parent_task_result: object: result of previous task or None if no previous task
        '''
        return self.command.before_run(parent_task_result)

    def create_context(self, message_queue):
        '''
        Run serially before the run method.
        :return object: context object passing state to the thread
        '''
        return self.command.create_context(message_queue)

    def after_run(self, results):
        '''
        Run in main process after run method.
        :param results: object: results from run method.
        '''
        return self.command.after_run(results)

    def on_message(self, data):
        '''
        Call on_message on our command passing data
        :param data: object: parameter passed to the on_message member of this task's command
        '''
        return self.command.on_message(data)","class Task(object):
    '''
    Represents a task that has a unique task id, a command specifying foreground code to run and
    a function that will be run in a background process.
    Command must have similar interface with before_run, create_context and after_run.
    '''

    def __init__(self, task_id, wait_for_task_id, command):
        '''
        Setup task so it can be executed.
        :param task_id: int: unique id of this task
        :param wait_for_task_id: int: unique id of the task that this one is waiting for
        :param command: object with foreground setup/teardown methods and background function
        '''
        self.task_id = task_id
        self.wait_for_task_id = wait_for_task_id
        self.command = command

    def before_run(self, parent_task_result):
        '''
        Run in main process before run method.
        :param parent_task_result: object: result of previous task or None if no previous task
        '''
        return self.command.before_run(parent_task_result)

    def create_context(self, message_queue):
        '''
        Run serially before the run method.
        :return object: context object passing state to the thread
        '''
        return self.command.create_context(message_queue)

    def after_run(self, results):
        '''
        Run in main process after run method.
        :param results: object: results from run method.
        '''
        return self.command.after_run(results)

    def on_message(self, data):
        '''
        Call on_message on our command passing data
        :param data: object: parameter passed to the on_message member of this task's command
        '''
        return self.command.on_message(data)",full_docstr,0.9753086419753086,0.9462809917355373,0.9211618257261411,0.97119341563786,0.8494978713234571,0.941952506596306,0.8915343915343915,0.8488063660477454,0.9863166809082031,0.9866069555282593,0.9864618182182312,0.9865779280662537,0.9607847058823529,0.9812108559498955,0.9601677148846961,0.9389473684210526,0.9812108559498955,0.8403296593392116,0.9564032697547684,0.9153005464480874,0.873972602739726,0.9911847114562988,0.9889267683029175,0.9900544881820679,0.9891521334648132,0.9674188721804511,0.9812108559498955,0.9601677148846961,0.9389473684210526,0.9812108559498955,0.8403296593392116,0.9564032697547684,0.9153005464480874,0.873972602739726,0.9911847114562988,0.9889267683029175,0.9900544881820679,0.9891521334648132,0.9674188721804511,0.7823789652177529,0.7886790816313363,0.8108942033578048,0.660377358490566,0.8695652173913043,0.7696820665786251,0.803872073768969,0.8101310079680089,0.660377358490566,0.8043478260869565,0.7696820665786251,0.803872073768969,0.8101310079680089,0.660377358490566,0.8043478260869565
307978,cltl/KafNafParserPy,cltl_KafNafParserPy/KafNafParserPy/attribution_data.py,KafNafParserPy.attribution_data.Cstatement_target,"class Cstatement_target:
    '''Represents the statement_target element'''

    def __init__(self, node=None, type='NAF'):
        """"""
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        """"""
        self.type = type
        if node is None:
            self.node = etree.Element('statement_target')
        else:
            self.node = node

    def get_node(self):
        """"""
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        """"""
        return self.node

    def get_span(self):
        """"""
        Returns the span of the statement_target element
        @rtype: L{Cspan}
        @return: span object
        """"""
        span_obj = self.node.find('span')
        if span_obj is not None:
            return Cspan(span_obj)
        return None

    def set_span(self,my_span):
        """"""
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_target
        """"""
        self.node.append(my_span.get_node())","class Cstatement_target:
    '''Represents the statement_target element'''

    def __init__(self, node=None, type='NAF'):
    '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        pass

    def get_node(self):
    '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        pass

    def get_span(self):
    '''
        Returns the span of the statement_target element
        @rtype: L{Cspan}
        @return: span object
        '''
        pass

    def set_span(self,my_span):
    '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_target
        '''
        pass

",5,5,snippet_521,0.875,"class Cstatement_target:
    '''Represents the statement_target element'''

    def __init__(self, node=None, type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        self.type = type
        if node is None:
            self.node = ET.Element('statement_target')
            self.span = None
        else:
            self.node = node
            span_elem = self.node.find('span')
            if span_elem is not None:
                self.span = Cspan(span_elem, type)
            else:
                self.span = None

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def get_span(self):
        '''
        Returns the span of the statement_target element
        @rtype: L{Cspan}
        @return: span object
        '''
        return self.span

    def set_span(self, my_span):
        '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_target
        '''
        # Remove existing span if any
        for existing in self.node.findall('span'):
            self.node.remove(existing)
        # Attach new span
        self.node.append(my_span.get_node())
        self.span = my_span","class Cstatement_target:
    '''Represents the statement_target element'''

    def __init__(self, node=None, type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        self.type = type
        if node is None:
            self.node = etree.Element('statement_target')
        else:
            self.node = node

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def get_span(self):
        '''
        Returns the span of the statement_target element
        @rtype: L{Cspan}
        @return: span object
        '''
        span_node = self.node.find('span')
        if span_node is not None:
            from span import Cspan
            return Cspan(span_node)
        return None

    def set_span(self, my_span):
        '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_target
        '''
        from span import Cspan
        # Remove existing span if any
        existing_span = self.node.find('span')
        if existing_span is not None:
            self.node.remove(existing_span)
        
        # Add the new span
        self.node.append(my_span.get_node())","class Cstatement_target:
    '''Represents the statement_target element'''

    def __init__(self, node=None, type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        self.type = type
        if node is None:
            from xml.etree.ElementTree import Element
            self.node = Element('statement_target')
        else:
            self.node = node

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def get_span(self):
        '''
        Returns the span of the statement_target element
        @rtype: L{Cspan}
        @return: span object
        '''
        span_node = self.node.find('span')
        if span_node is not None:
            from Cspan import Cspan
            return Cspan(span_node, self.type)
        return None

    def set_span(self, my_span):
        '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_target
        '''
        existing_span = self.node.find('span')
        if existing_span is not None:
            self.node.remove(existing_span)
        self.node.append(my_span.get_node())",full_docstr,0.8847184986595175,0.8355795148247979,0.7859078590785908,0.8203753351206434,0.7396453344290614,0.790273556231003,0.7408536585365854,0.691131498470948,0.9281178712844849,0.9609501361846924,0.9442486763000488,0.9575627446174622,0.832443743315508,0.893048128342246,0.8655913978494625,0.8378378378378378,0.893048128342246,0.7749980081672033,0.8136645962732919,0.7757009345794392,0.7375,0.9520305395126343,0.9866071939468384,0.9690104722976685,0.9830369353294373,0.9238102857142857,0.9076086956521738,0.8688524590163934,0.8296703296703296,0.9021739130434783,0.7806860941219328,0.8264984227129337,0.7816455696202531,0.7365079365079366,0.9526044130325317,0.9773787260055542,0.964832603931427,0.974843442440033,0.9147735795454545,0.7653699255344975,0.6441569196908347,0.7761463118589198,0.7,0.9411764705882352,0.8324900940172191,0.6679668989433585,0.8119934771255177,0.85,1.0,0.7628095638997844,0.6847229870668403,0.7841623273558266,0.7,0.8823529411764706
292692,citronneur/rdpy,citronneur_rdpy/rdpy/protocol/rdp/lic.py,rdpy.protocol.rdp.lic.LicenseManager,"class LicenseManager(object):
    """"""
    @summary: handle license automata (client side)
    @see: http://msdn.microsoft.com/en-us/library/cc241890.aspx
    """"""
    def __init__(self, transport):
        """"""
        @param transport: layer use to send packet
        """"""
        self._transport = transport
        self._username = """"
        self._hostname = """"
 
    def recv(self, s):
        """"""
        @summary: receive license packet from PDU layer
        @return true when license automata is finish
        """"""            
        licPacket = LicPacket()
        s.readType(licPacket)
        
        #end of automata
        if licPacket.bMsgtype.value == MessageType.ERROR_ALERT and licPacket.licensingMessage.dwErrorCode.value == ErrorCode.STATUS_VALID_CLIENT and licPacket.licensingMessage.dwStateTransition.value == StateTransition.ST_NO_TRANSITION:
            return True
        
        elif licPacket.bMsgtype.value == MessageType.LICENSE_REQUEST:
            self.sendClientNewLicenseRequest(licPacket.licensingMessage)
            return False
            
        elif licPacket.bMsgtype.value == MessageType.PLATFORM_CHALLENGE:
            self.sendClientChallengeResponse(licPacket.licensingMessage)
            return False
        
        #yes get a new license
        elif licPacket.bMsgtype.value == MessageType.NEW_LICENSE:
            return True
        
        else:
            raise InvalidExpectedDataException(""Not a valid license packet"")
        
    
    def sendClientNewLicenseRequest(self, licenseRequest):
        """"""
        @summary: Create new license request in response to server license request
        @param licenseRequest: {ServerLicenseRequest}
        @see: http://msdn.microsoft.com/en-us/library/cc241989.aspx
        @see: http://msdn.microsoft.com/en-us/library/cc241918.aspx
        """"""
        #get server information
        serverRandom = licenseRequest.serverRandom.value
        if self._transport.getGCCServerSettings().SC_SECURITY.serverCertificate._is_readed:
            serverCertificate = self._transport.getGCCServerSettings().SC_SECURITY.serverCertificate
        else:
            s = Stream(licenseRequest.serverCertificate.blobData.value)
            serverCertificate = gcc.ServerCertificate()
            s.readType(serverCertificate)
        
        #generate crypto values
        clientRandom = rsa.random(256)
        preMasterSecret = rsa.random(384)
        masterSecret = sec.masterSecret(preMasterSecret, clientRandom, serverRandom)
        sessionKeyBlob = sec.masterSecret(masterSecret, serverRandom, clientRandom)
        self._macSalt = sessionKeyBlob[:16]
        self._licenseKey = sec.finalHash(sessionKeyBlob[16:32], clientRandom, serverRandom)
        
        #format message
        message = ClientNewLicenseRequest()
        message.clientRandom.value = clientRandom
        message.encryptedPreMasterSecret.blobData.value = rsa.encrypt(preMasterSecret[::-1], serverCertificate.certData.getPublicKey())[::-1] + ""\x00"" * 8
        message.ClientMachineName.blobData.value = self._hostname + ""\x00""
        message.ClientUserName.blobData.value = self._username + ""\x00""
        self._transport.sendFlagged(sec.SecurityFlag.SEC_LICENSE_PKT, LicPacket(message))
        
    def sendClientChallengeResponse(self, platformChallenge):
        """"""
        @summary: generate valid challenge response
        @param platformChallenge: {ServerPlatformChallenge}
        """"""
        serverEncryptedChallenge = platformChallenge.encryptedPlatformChallenge.blobData.value
        #decrypt server challenge
        #it should be TEST word in unicode format
        serverChallenge = rc4.crypt(rc4.RC4Key(self._licenseKey), serverEncryptedChallenge)
        if serverChallenge != ""T\x00E\x00S\x00T\x00\x00\x00"":
            raise InvalidExpectedDataException(""bad license server challenge"")
        
        #generate hwid
        s = Stream()
        s.writeType((UInt32Le(2), String(self._hostname + self._username + ""\x00"" * 16)))
        hwid = s.getvalue()[:20]
        
        message = ClientPLatformChallengeResponse()
        message.encryptedPlatformChallengeResponse.blobData.value = serverEncryptedChallenge
        message.encryptedHWID.blobData.value = rc4.crypt(rc4.RC4Key(self._licenseKey), hwid)
        message.MACData.value = sec.macData(self._macSalt, serverChallenge + hwid)
        
        self._transport.sendFlagged(sec.SecurityFlag.SEC_LICENSE_PKT, LicPacket(message))","class LicenseManager(object):
    '''
    @summary: handle license automata (client side)
    @see: http://msdn.microsoft.com/en-us/library/cc241890.aspx
    '''

    def __init__(self, transport):
    '''
        @param transport: layer use to send packet
        '''
        pass

    def recv(self, s):
    '''
        @summary: receive license packet from PDU layer
        @return true when license automata is finish
        '''
        pass

    def sendClientNewLicenseRequest(self, licenseRequest):
    '''
        @summary: Create new license request in response to server license request
        @param licenseRequest: {ServerLicenseRequest}
        @see: http://msdn.microsoft.com/en-us/library/cc241989.aspx
        @see: http://msdn.microsoft.com/en-us/library/cc241918.aspx
        '''
        pass

    def sendClientChallengeResponse(self, platformChallenge):
    '''
        @summary: generate valid challenge response
        @param platformChallenge: {ServerPlatformChallenge}
        '''
        pass

",5,5,snippet_499,0.1578947368421052,"class LicenseManager(object):
    """"""
    @summary: handle license automata (client side)
    @see: http://msdn.microsoft.com/en-us/library/cc241890.aspx
    """"""

    # internal states
    _STATE_INIT = 0
    _STATE_NEW_LICENSE_SENT = 1
    _STATE_CHALLENGE_RESP_SENT = 2
    _STATE_FINISHED = 3
    _STATE_ERROR = -1

    def __init__(self, transport):
        """"""
        @param transport: layer use to send packet
        """"""
        self.transport = transport
        self._state = self._STATE_INIT

    def recv(self, s):
        """"""
        @summary: receive license packet from PDU layer
        @return true when license automata is finish
        """"""
        # detect packet type by class name
        clsname = s.__class__.__name__
        if self._state == self._STATE_INIT and clsname == 'ServerLicenseRequest':
            self.sendClientNewLicenseRequest(s)
            self._state = self._STATE_NEW_LICENSE_SENT
            return False
        elif self._state == self._STATE_NEW_LICENSE_SENT and clsname == 'ServerPlatformChallenge':
            self.sendClientChallengeResponse(s)
            self._state = self._STATE_CHALLENGE_RESP_SENT
            # after challenge response, client waits no furtherfinished
            self._state = self._STATE_FINISHED
            return True
        else:
            self._state = self._STATE_ERROR
            return True

    def sendClientNewLicenseRequest(self, licenseRequest):
        """"""
        @summary: Create new license request in response to server license request
        @param licenseRequest: {ServerLicenseRequest}
        @see: http://msdn.microsoft.com/en-us/library/cc241989.aspx
        @see: http://msdn.microsoft.com/en-us/library/cc241918.aspx
        """"""
        # build a ClientNewLicenseRequest PDU
        pdu = {
            'type': 'ClientNewLicenseRequest',
            'version': licenseRequest.version,
            'clientRandom': licenseRequest.clientRandom,
            'requestedProductId': licenseRequest.productId,
            'platformId': licenseRequest.platformId,
            'hardwareId': licenseRequest.hardwareId,
        }
        data = self._serialize_pdu(pdu)
        self.transport.send(data)

    def sendClientChallengeResponse(self, platformChallenge):
        """"""
        @summary: generate valid challenge response
        @param platformChallenge: {ServerPlatformChallenge}
        """"""
        # build a ClientPlatformChallengeResponse PDU
        # echo back serverRandom encrypted with client secret (stubbed here)
        resp = {
            'type': 'ClientPlatformChallengeResponse',
            'serverRandom': platformChallenge.serverRandom,
            'clientSecretProof': self._compute_proof(platformChallenge.serverRandom)
        }
        data = self._serialize_pdu(resp)
        self.transport.send(data)

    def _serialize_pdu(self, pdu):
        # stub serialization to bytes
        import json
        return json.dumps(pdu).encode('utf-8')

    def _compute_proof(self, serverRandom):
        # stubbed proof computation
        # in real implementation, would use licensing keys and HMAC
        return (serverRandom[::-1] + b'PROOF')[:16]","class LicenseManager(object):
    '''
    @summary: handle license automata (client side)
    @see: http://msdn.microsoft.com/en-us/library/cc241890.aspx
    '''

    def __init__(self, transport):
        '''
        @param transport: layer use to send packet
        '''
        self.transport = transport
        self.state = 0  # 0: initial, 1: waiting for challenge, 2: finished

    def recv(self, s):
        '''
        @summary: receive license packet from PDU layer
        @return true when license automata is finish
        '''
        # Parse the incoming license packet and handle based on current state
        # This is a simplified implementation - actual implementation would
        # parse the packet structure and handle different license packet types
        if self.state == 0:
            # Initial state - expect server license request
            self.sendClientNewLicenseRequest(None)
            self.state = 1
            return False
        elif self.state == 1:
            # Waiting for challenge - expect server platform challenge
            self.sendClientChallengeResponse(None)
            self.state = 2
            return True
        else:
            return True

    def sendClientNewLicenseRequest(self, licenseRequest):
        '''
        @summary: Create new license request in response to server license request
        @param licenseRequest: {ServerLicenseRequest}
        @see: http://msdn.microsoft.com/en-us/library/cc241989.aspx
        @see: http://msdn.microsoft.com/en-us/library/cc241918.aspx
        '''
        # Create and send client license request packet
        # This would typically involve:
        # 1. Generating client random
        # 2. Creating preferred security protocol mask
        # 3. Building the CLIENT_NEW_LICENSE_REQUEST structure
        # 4. Sending it via transport layer
        packet = b""""  # Placeholder for actual license request packet
        self.transport.send(packet)

    def sendClientChallengeResponse(self, platformChallenge):
        '''
        @summary: generate valid challenge response
        @param platformChallenge: {ServerPlatformChallenge}
        '''
        # Create and send client challenge response packet
        # This would typically involve:
        # 1. Decrypting the platform challenge
        # 2. Generating encrypted platform challenge response
        # 3. Creating encrypted hardware id
        # 4. Building the CLIENT_PLATFORM_CHALLENGE_RESPONSE structure
        # 5. Sending it via transport layer
        packet = b""""  # Placeholder for actual challenge response packet
        self.transport.send(packet)","class LicenseManager(object):
    '''
    @summary: handle license automata (client side)
    @see: http://msdn.microsoft.com/en-us/library/cc241890.aspx
    '''

    def __init__(self, transport):
        '''
        @param transport: layer use to send packet
        '''
        self.transport = transport
        self.state = ""INITIAL""
        self.client_random = None
        self.server_random = None
        self.premaster_secret = None
        self.master_secret = None
        self.session_key_blob = None
        self.mac_salt_key = None
        self.licensing_encryption_key = None

    def recv(self, s):
        '''
        @summary: receive license packet from PDU layer
        @return true when license automata is finish
        '''
        if not s:
            return False
            
        packet_type = s[0] if len(s) > 0 else 0
        
        if packet_type == 0x01:  # LICENSE_REQUEST
            self.sendClientNewLicenseRequest(s)
            return False
        elif packet_type == 0x02:  # PLATFORM_CHALLENGE
            self.sendClientChallengeResponse(s)
            return False
        elif packet_type == 0x03:  # NEW_LICENSE
            self.state = ""LICENSED""
            return True
        elif packet_type == 0x04:  # UPGRADE_LICENSE
            self.state = ""LICENSED""
            return True
        elif packet_type == 0xFF:  # ERROR_ALERT
            self.state = ""ERROR""
            return True
        
        return False

    def sendClientNewLicenseRequest(self, licenseRequest):
        '''
        @summary: Create new license request in response to server license request
        @param licenseRequest: {ServerLicenseRequest}
        @see: http://msdn.microsoft.com/en-us/library/cc241989.aspx
        @see: http://msdn.microsoft.com/en-us/library/cc241918.aspx
        '''
        import os
        import struct
        
        # Generate client random
        self.client_random = os.urandom(32)
        
        # Create client license info
        client_license_info = b""CLIENT_LICENSE_INFO""
        
        # Create client machine name
        machine_name = b""CLIENT_MACHINE""
        
        # Create client user name
        user_name = b""CLIENT_USER""
        
        # Build the packet
        packet = bytearray()
        packet.append(0x12)  # CLIENT_NEW_LICENSE_REQUEST
        packet.append(0x00)  # flags
        packet.extend(struct.pack('<H', len(packet) + 4))  # packet length placeholder
        
        # Add client random
        packet.extend(self.client_random)
        
        # Add client license info
        packet.extend(struct.pack('<H', len(client_license_info)))
        packet.extend(client_license_info)
        
        # Add machine name
        packet.extend(struct.pack('<H', len(machine_name)))
        packet.extend(machine_name)
        
        # Add user name
        packet.extend(struct.pack('<H', len(user_name)))
        packet.extend(user_name)
        
        # Update packet length
        struct.pack_into('<H', packet, 2, len(packet))
        
        self.transport.send(bytes(packet))
        self.state = ""LICENSE_REQUEST_SENT""

    def sendClientChallengeResponse(self, platformChallenge):
        '''
        @summary: generate valid challenge response
        @param platformChallenge: {ServerPlatformChallenge}
        '''
        import os
        import struct
        import hashlib
        
        # Extract challenge data from platform challenge
        challenge_data = platformChallenge[4:] if len(platformChallenge) > 4 else b""""
        
        # Generate response data
        response_data = hashlib.md5(challenge_data + self.client_random).digest()
        
        # Create hardware ID
        hardware_id = os.urandom(20)
        
        # Build the packet
        packet = bytearray()
        packet.append(0x15)  # CLIENT_PLATFORM_CHALLENGE_RESPONSE
        packet.append(0x00)  # flags
        packet.extend(struct.pack('<H', 0))  # packet length placeholder
        
        # Add response data length and data
        packet.extend(struct.pack('<H', len(response_data)))
        packet.extend(response_data)
        
        # Add hardware ID length and data
        packet.extend(struct.pack('<H', len(hardware_id)))
        packet.extend(hardware_id)
        
        # Update packet length
        struct.pack_into('<H', packet, 2, len(packet))
        
        self.transport.send(bytes(packet))
        self.state = ""CHALLENGE_RESPONSE_SENT""",full_docstr,0.4767277856135402,0.3083451202263084,0.26666666666666666,0.3638928067700988,0.3560999087345467,0.7054908485856906,0.49333333333333335,0.4056761268781302,0.8476884365081787,0.7963880300521851,0.8212378621101379,0.8012370467185974,0.7509603448275864,0.44281524926686217,0.338235294117647,0.29498525073746307,0.3724340175953079,0.2077063914295732,0.6414253897550112,0.45982142857142855,0.3870246085011186,0.8556838631629944,0.7720734477043152,0.8117313385009766,0.7796919941902161,0.737824187192119,0.39362912400455063,0.26225769669327254,0.22857142857142854,0.3185437997724687,0.306205522161705,0.5411111111111111,0.26918798665183535,0.19710467706013363,0.8208110332489014,0.8189363479614258,0.8198726177215576,0.8191235065460205,0.7545871359223312,0.3099571198064532,0.2928576984695919,0.3089613065289334,0.401294498381877,0.2367149758454106,0.218290977392016,0.2175972718035436,0.2304458648176606,0.3333333333333333,0.0917874396135265,0.4791444591456569,0.1783410749256309,0.2463273765437283,0.4919093851132686,0.0
135520,JdeRobot/base,src/libs/comm_py/comm/ice/pose3dIceClient.py,comm.ice.pose3dIceClient.Pose3dIceClient,"class Pose3dIceClient:
    '''
        Pose3d Ice Client. Recives Pose3d from Ice interface running Pose3d update method in a thread.
    '''
    def __init__(self,ic,prefix, start = False):
        '''
        Pose3dIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.pose3d = Pose3D(ic,prefix)

        self.kill_event = threading.Event()
        self.thread = ThreadSensor(self.pose3d, self.kill_event)
        self.thread.daemon = True

        if start:
            self.start()


    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.clear()
        self.thread.start()

    
    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.set()

    def getPose3d(self):
        '''
        Returns last Pose3d. 

        @return last JdeRobotTypes Pose3d saved

        '''
        return self.pose3d.getPose3d()

    def hasproxy (self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.pose3d.hasproxy()","class Pose3dIceClient:
    '''
        Pose3d Ice Client. Recives Pose3d from Ice interface running Pose3d update method in a thread.
    '''

    def __init__(self,ic,prefix, start = False):
    '''
        Pose3dIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        pass

    def start(self):
    '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def stop(self):
    '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def getPose3d(self):
    '''
        Returns last Pose3d. 

        @return last JdeRobotTypes Pose3d saved

        '''
        pass

    def hasproxy (self):
    '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        pass

",6,6,snippet_157,0.25,"class Pose3dIceClient:
    '''
        Pose3d Ice Client. Recives Pose3d from Ice interface running Pose3d update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
            Pose3dIceClient Contructor.

            @param ic: Ice Communicator
            @param prefix: prefix name of client in config file
            @param start: indicates if start automatically the client

            @type ic: Ice Communicator
            @type prefix: String
            @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        props = ic.getProperties()
        proxy_prop = props.getProperty(prefix + "".Proxy"")
        prx = ic.propertyToProxy(prefix + "".Proxy"")
        self.proxy = JdeRobotTypes.Pose3dPrx.checkedCast(prx)
        if not self.proxy:
            raise RuntimeError(""Invalid proxy for {}"".format(proxy_prop))
        period_str = props.getProperty(prefix + "".Period"", ""100"")
        try:
            self.period = int(period_str)
        except ValueError:
            self.period = 100
        self._pose = None
        self._run = False
        self._thread = None
        if start:
            self.start()

    def start(self):
        '''
            Starts the client. If client is stopped you can not start again, Threading.Thread raised error
        '''
        if self._thread is None:
            self._thread = threading.Thread(target=self._run_loop)
            self._thread.daemon = True
            self._run = True
        self._thread.start()

    def stop(self):
        '''
            Stops the client. If client is stopped you can not start again, Threading.Thread raised error
        '''
        self._run = False
        if self._thread:
            self._thread.join()

    def getPose3d(self):
        '''
            Returns last Pose3d. 

            @return last JdeRobotTypes Pose3d saved
        '''
        return self._pose

    def hasproxy(self):
        '''
            Returns if proxy has ben created or not. 

            @return if proxy has ben created or not (Boolean)
        '''
        return self.proxy is not None

    def _run_loop(self):
        while self._run:
            try:
                p = self.proxy.getPose3d()
                self._pose = p
            except Ice.Exception:
                pass
            time.sleep(self.period / 1000.0)","class Pose3dIceClient:
    '''
        Pose3d Ice Client. Recives Pose3d from Ice interface running Pose3d update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        Pose3dIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.pose3d = None
        self.proxy = None
        self.topic = False
        self.started = False
        self.running = False
        self.thread = None
        
        # Try to create proxy
        try:
            proxy_name = prefix + "".Proxy""
            self.proxy = self.ic.propertyToProxy(proxy_name)
            if self.proxy:
                self.topic = True
        except Exception:
            self.topic = False
            
        if start and self.topic:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if not self.started and self.topic:
            self.running = True
            self.started = True
            self.thread = threading.Thread(target=self.update_pose3d)
            self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if self.started:
            self.running = False
            if self.thread and self.thread.is_alive():
                self.thread.join()
            self.started = False

    def getPose3d(self):
        '''
        Returns last Pose3d. 

        @return last JdeRobotTypes Pose3d saved

        '''
        return self.pose3d

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.topic

    def update_pose3d(self):
        '''
        Internal method to update pose3d in a separate thread
        '''
        # This is a placeholder implementation
        # In a real implementation, this would interface with Ice to get pose3d data
        while self.running:
            try:
                # Simulate getting pose3d data from Ice interface
                # self.pose3d = get_pose3d_from_ice_interface(self.proxy)
                time.sleep(0.05)  # 20 Hz update rate
            except Exception:
                break","class Pose3dIceClient:
    '''
        Pose3d Ice Client. Recives Pose3d from Ice interface running Pose3d update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        Pose3dIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.proxy = None
        self.pose3d = None
        self.lock = threading.Lock()
        self.running = False
        self.thread = None
        
        try:
            proxyString = self.ic.getProperties().getProperty(self.prefix + "".Proxy"")
            if proxyString:
                self.proxy = self.ic.stringToProxy(proxyString)
        except:
            self.proxy = None
            
        if start and self.proxy:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if self.proxy and not self.running:
            self.running = True
            self.thread = threading.Thread(target=self._update_pose3d)
            self.thread.daemon = True
            self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.running = False
        if self.thread:
            self.thread.join()

    def getPose3d(self):
        '''
        Returns last Pose3d. 

        @return last JdeRobotTypes Pose3d saved

        '''
        with self.lock:
            return self.pose3d

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.proxy is not None

    def _update_pose3d(self):
        while self.running:
            try:
                if self.proxy:
                    pose = self.proxy.getPose3DData()
                    with self.lock:
                        self.pose3d = pose
            except:
                pass
            time.sleep(0.05)",full_docstr,0.7083333333333333,0.641860465116279,0.6121495327102804,0.6851851851851851,0.5108204067950576,0.5689655172413793,0.5010799136069114,0.4675324675324675,0.8717378377914429,0.9380335807800293,0.903671383857727,0.9309536814689636,0.7951090825688074,0.6680942184154175,0.5978494623655913,0.548596112311015,0.6466809421841541,0.5046901924153587,0.5683760683760684,0.4925053533190578,0.4592274678111588,0.8782224059104919,0.9386672973632812,0.9074393510818481,0.9322509765625,0.7993217346938775,0.7476190476190476,0.6746411483253589,0.6153846153846154,0.719047619047619,0.5792268272999349,0.642512077294686,0.5690072639225182,0.5315533980582524,0.904331624507904,0.948861837387085,0.9260616898536682,0.9442123770713806,0.8081159539473685,0.6074265157503259,0.5300780515911375,0.8074294298498822,0.6666666666666666,0.425531914893617,0.5614850543456157,0.4511077747559895,0.8081303149668985,0.625,0.3617021276595745,0.6025440859610489,0.5607601078543607,0.8071585527747046,0.6805555555555556,0.3617021276595745
292768,citronneur/rdpy,citronneur_rdpy/rdpy/protocol/rdp/pdu/layer.py,rdpy.protocol.rdp.pdu.layer.PDUClientListener,"class PDUClientListener(object):
    """"""
    @summary: Interface for PDU client automata listener
    """"""
    def onReady(self):
        """"""
        @summary: Event call when PDU layer is ready to send events
        """"""
        raise CallPureVirtualFuntion(""%s:%s defined by interface %s""%(self.__class__, ""onReady"", ""PDUClientListener""))
    
    def onSessionReady(self):
        """"""
        @summary: Event call when Windows session is ready
        """"""
        raise CallPureVirtualFuntion(""%s:%s defined by interface %s""%(self.__class__, ""onSessionReady"", ""PDUClientListener""))
    
    
    def onUpdate(self, rectangles):
        """"""
        @summary: call when a bitmap data is received from update PDU
        @param rectangles: [pdu.BitmapData] struct
        """"""
        raise CallPureVirtualFuntion(""%s:%s defined by interface %s""%(self.__class__, ""onUpdate"", ""PDUClientListener""))
    
    def recvDstBltOrder(self, order):
        """"""
        @param order: rectangle order
        """"""
        pass","class PDUClientListener(object):
    '''
    @summary: Interface for PDU client automata listener
    '''

    def onReady(self):
    '''
        @summary: Event call when PDU layer is ready to send events
        '''
        pass

    def onSessionReady(self):
    '''
        @summary: Event call when Windows session is ready
        '''
        pass

    def onUpdate(self, rectangles):
    '''
        @summary: call when a bitmap data is received from update PDU
        @param rectangles: [pdu.BitmapData] struct
        '''
        pass

    def recvDstBltOrder(self, order):
    '''
        @param order: rectangle order
        '''
        pass

",5,5,snippet_500,1.0,"class PDUClientListener(ABC):
    """"""
    @summary: Interface for PDU client automata listener
    """"""

    @abstractmethod
    def onReady(self):
        """"""
        @summary: Event call when PDU layer is ready to send events
        """"""
        raise NotImplementedError()

    @abstractmethod
    def onSessionReady(self):
        """"""
        @summary: Event call when Windows session is ready
        """"""
        raise NotImplementedError()

    @abstractmethod
    def onUpdate(self, rectangles):
        """"""
        @summary: call when a bitmap data is received from update PDU
        @param rectangles: [pdu.BitmapData] struct
        """"""
        raise NotImplementedError()

    @abstractmethod
    def recvDstBltOrder(self, order):
        """"""
        @param order: rectangle order
        """"""
        raise NotImplementedError()","class PDUClientListener(object):
    '''
    @summary: Interface for PDU client automata listener
    '''

    def onReady(self):
        '''
        @summary: Event call when PDU layer is ready to send events
        '''
        pass

    def onSessionReady(self):
        '''
        @summary: Event call when Windows session is ready
        '''
        pass

    def onUpdate(self, rectangles):
        '''
        @summary: call when a bitmap data is received from update PDU
        @param rectangles: [pdu.BitmapData] struct
        '''
        pass

    def recvDstBltOrder(self, order):
        '''
        @param order: rectangle order
        '''
        pass","class PDUClientListener(object):
    '''
    @summary: Interface for PDU client automata listener
    '''

    def onReady(self):
        '''
        @summary: Event call when PDU layer is ready to send events
        '''
        pass

    def onSessionReady(self):
        '''
        @summary: Event call when Windows session is ready
        '''
        pass

    def onUpdate(self, rectangles):
        '''
        @summary: call when a bitmap data is received from update PDU
        @param rectangles: [pdu.BitmapData] struct
        '''
        pass

    def recvDstBltOrder(self, order):
        '''
        @param order: rectangle order
        '''
        pass",full_docstr,0.7428571428571429,0.6820809248554912,0.6198830409356725,0.7428571428571429,0.4912949626199538,0.9066666666666666,0.8187919463087249,0.7837837837837838,0.881749153137207,0.8645641207695007,0.8730720281600952,0.8662524223327637,0.8091187179487179,0.7664670658682635,0.7272727272727273,0.6871165644171779,0.7664670658682635,0.26453040735848643,0.8818181818181818,0.7889908256880734,0.7037037037037037,0.9508886337280273,0.851284921169281,0.898334264755249,0.8602963089942932,0.8205146153846153,0.7664670658682635,0.7272727272727273,0.6871165644171779,0.7664670658682635,0.26453040735848643,0.8818181818181818,0.7889908256880734,0.7037037037037037,0.9508886337280273,0.851284921169281,0.898334264755249,0.8602963089942932,0.8205146153846153,0.5568483991216983,0.6618364661296918,0.6826899974899685,0.1136363636363636,0.7692307692307693,0.3518228177503945,0.4465090976208059,0.4712716838702825,0.1818181818181818,0.3076923076923077,0.3518228177503945,0.4465090976208059,0.4712716838702825,0.1818181818181818,0.3076923076923077
125352,GoogleCloudPlatform/appengine-mapreduce,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/GoogleCloudPlatform_appengine-mapreduce/python/src/mapreduce/map_job_context.py,mapreduce.map_job_context.SliceContext,"class SliceContext(object):
    """"""Context for map job.""""""

    def __init__(self, shard_context, shard_state, tstate):
        """"""Init.

        The signature of __init__ is subject to change.

        Read only properties:
          job_context: JobContext object.
          shard_context: ShardContext object.
          number: int. slice number. 0 indexed.
          attempt: int. The current attempt at executing this slice.
            starting at 1.

        Args:
          shard_context: map_job.JobConfig.
          shard_state: model.ShardState.
          tstate: model.TransientShardstate.
        """"""
        self._tstate = tstate
        self.job_context = shard_context.job_context
        self.shard_context = shard_context
        self.number = shard_state.slice_id
        self.attempt = shard_state.slice_retries + 1

    def incr(self, counter_name, delta=1):
        """"""See shard_context.count.""""""
        self.shard_context.incr(counter_name, delta)

    def counter(self, counter_name, default=0):
        """"""See shard_context.count.""""""
        return self.shard_context.counter(counter_name, default)

    def emit(self, value):
        """"""Emits a value to output writer.

        Args:
          value: a value of type expected by the output writer.
        """"""
        if not self._tstate.output_writer:
            logging.error(""emit is called, but no output writer is set."")
            return
        self._tstate.output_writer.write(value)","class SliceContext(object):
    '''Context for map job.'''


    def __init__(self, shard_context, shard_state, tstate):
    '''Init.

        The signature of __init__ is subject to change.

        Read only properties:
          job_context: JobContext object.
          shard_context: ShardContext object.
          number: int. slice number. 0 indexed.
          attempt: int. The current attempt at executing this slice.
            starting at 1.

        Args:
          shard_context: map_job.JobConfig.
          shard_state: model.ShardState.
          tstate: model.TransientShardstate.
        '''
        pass


    def incr(self, counter_name, delta=1):
    '''See shard_context.count.'''
        pass


    def counter(self, counter_name, default=0):
    '''See shard_context.count.'''
        pass


    def emit(self, value):
    '''Emits a value to output writer.

        Args:
          value: a value of type expected by the output writer.
        '''
        pass

",5,5,snippet_132,0.4285714285714285,"class SliceContext(object):
    '''Context for map job.'''

    def __init__(self, shard_context, shard_state, tstate):
        '''Init.

        The signature of __init__ is subject to change.

        Read only properties:
          job_context: JobContext object.
          shard_context: ShardContext object.
          number: int. slice number. 0 indexed.
          attempt: int. The current attempt at executing this slice.
            starting at 1.

        Args:
          shard_context: map_job.JobConfig.
          shard_state: model.ShardState.
          tstate: model.TransientShardstate.
        '''
        self._shard_context = shard_context
        self._shard_state = shard_state
        self._tstate = tstate

    @property
    def job_context(self):
        return self._shard_context.job_context

    @property
    def shard_context(self):
        return self._shard_context

    @property
    def number(self):
        # slice number, 0-indexed
        return getattr(self._tstate, 'slice_number', None)

    @property
    def attempt(self):
        # current attempt at this slice, starting at 1
        return getattr(self._tstate, 'slice_attempt', None)

    def incr(self, counter_name, delta=1):
        '''See shard_context.count.'''
        return self._shard_context.count(counter_name, delta)

    def counter(self, counter_name, default=0):
        '''See shard_context.count.'''
        cnt = self._shard_context.count(counter_name)
        return default if cnt is None else cnt

    def emit(self, value):
        '''Emits a value to output writer.

        Args:
          value: a value of type expected by the output writer.
        '''
        # assume shard_context has an output writer attribute
        writer = getattr(self._shard_context, 'output_writer', None)
        if writer is None:
            writer = getattr(self._shard_context, 'writer', None)
        if writer is None:
            raise RuntimeError(""No output writer available on shard_context"")
        writer.write(value)","class SliceContext(object):
    '''Context for map job.'''

    def __init__(self, shard_context, shard_state, tstate):
        '''Init.

        The signature of __init__ is subject to change.

        Read only properties:
          job_context: JobContext object.
          shard_context: ShardContext object.
          number: int. slice number. 0 indexed.
          attempt: int. The current attempt at executing this slice.
            starting at 1.

        Args:
          shard_context: map_job.JobConfig.
          shard_state: model.ShardState.
          tstate: model.TransientShardstate.
        '''
        self._shard_context = shard_context
        self._shard_state = shard_state
        self._tstate = tstate

    @property
    def job_context(self):
        return self._shard_context.job_context

    @property
    def shard_context(self):
        return self._shard_context

    @property
    def number(self):
        return self._tstate.slice_id

    @property
    def attempt(self):
        return self._tstate.retry_count + 1

    def incr(self, counter_name, delta=1):
        '''See shard_context.count.'''
        self._shard_context.incr(counter_name, delta)

    def counter(self, counter_name, default=0):
        '''See shard_context.count.'''
        return self._shard_context.counter(counter_name, default)

    def emit(self, value):
        '''Emits a value to output writer.

        Args:
          value: a value of type expected by the output writer.
        '''
        self._tstate.output_writer.write(value)","class SliceContext(object):
    '''Context for map job.'''

    def __init__(self, shard_context, shard_state, tstate):
        '''Init.

        The signature of __init__ is subject to change.

        Read only properties:
          job_context: JobContext object.
          shard_context: ShardContext object.
          number: int. slice number. 0 indexed.
          attempt: int. The current attempt at executing this slice.
            starting at 1.

        Args:
          shard_context: map_job.JobConfig.
          shard_state: model.ShardState.
          tstate: model.TransientShardstate.
        '''
        self._shard_context = shard_context
        self._shard_state = shard_state
        self._tstate = tstate

    @property
    def job_context(self):
        return self._shard_context.job_context

    @property
    def shard_context(self):
        return self._shard_context

    @property
    def number(self):
        return self._tstate.slice_id

    @property
    def attempt(self):
        return self._tstate.slice_attempt_count

    def incr(self, counter_name, delta=1):
        '''See shard_context.count.'''
        self._shard_context.incr(counter_name, delta)

    def counter(self, counter_name, default=0):
        '''See shard_context.count.'''
        return self._shard_context.counter(counter_name, default)

    def emit(self, value):
        '''Emits a value to output writer.

        Args:
          value: a value of type expected by the output writer.
        '''
        self._tstate.output_writer.write(value)",full_docstr,0.7894736842105263,0.6730769230769232,0.5845410628019323,0.722488038277512,0.5661671613538585,0.6736596736596736,0.5584112149532711,0.48243559718969553,0.8987901210784912,0.936016321182251,0.917025625705719,0.9321555495262146,0.8282845454545457,0.8882681564245811,0.8202247191011236,0.768361581920904,0.8268156424581005,0.7407891749967188,0.8397626112759644,0.7470238095238095,0.6776119402985075,0.9515379071235657,0.9460536241531372,0.9487878084182739,0.9465992450714111,0.8591283928571429,0.8882681564245811,0.8146067415730337,0.7627118644067795,0.8268156424581005,0.7388274892966165,0.8367952522255193,0.7470238095238095,0.6746268656716418,0.9520063996315002,0.9440381526947021,0.9480055570602417,0.9448289275169373,0.8574311445783133,0.5383802312918764,0.3968982025213634,0.5942452716657497,0.59375,0.5686274509803921,0.5873660443396309,0.5899162812970021,0.5934939744928941,0.65625,0.5098039215686274,0.5805704273027801,0.5782417110632474,0.5779860765792453,0.65625,0.5098039215686274
361265,eirannejad/Revit-Journal-Maker,rjm/__init__.py,rjm.JournalReader,"class JournalReader(object):
    """"""Handle reading and interpretting a journal file from Autodesk Revit.""""""

    def __init__(self, journal_file):
        """"""Initialize the reader object with path to the target journal file.

        Args:
            journal_file (str): full path to target journal file
        """"""
        self._jrnl_file = journal_file

    def _read_journal(self):
        """"""Private method that reads the journal file contents.

        Returns:
            str: journal file contents
        """"""
        with open(self._jrnl_file, 'r') as jrn_file:
            return jrn_file.read()

    def endswith(self, search_str):
        """"""Check whether the provided string exists in Journal file.

        Only checks the last 5 lines of the journal file. This method is
        usually used when tracking a journal from an active Revit session.

        Args:
            search_str (str): string to search for

        Returns:
            bool: if True the search string is found
        """"""
        for entry in reversed(list(open(self._jrnl_file, 'r'))[-5:]):
            if search_str in entry:
                return True

        return False

    def is_stopped(self):
        """"""Check whether the journal execution has stopped.

        Returns:
            bool: True if the journal execution has stopped
        """"""
        return self.endswith(entries.MODAL_OPEN)","class JournalReader(object):
    '''Handle reading and interpretting a journal file from Autodesk Revit.'''

    def __init__(self, journal_file):
    '''Initialize the reader object with path to the target journal file.

        Args:
            journal_file (str): full path to target journal file
        '''
        pass

    def _read_journal(self):
    '''Private method that reads the journal file contents.

        Returns:
            str: journal file contents
        '''
        pass

    def endswith(self, search_str):
    '''Check whether the provided string exists in Journal file.

        Only checks the last 5 lines of the journal file. This method is
        usually used when tracking a journal from an active Revit session.

        Args:
            search_str (str): string to search for

        Returns:
            bool: if True the search string is found
        '''
        pass

    def is_stopped(self):
    '''Check whether the journal execution has stopped.

        Returns:
            bool: True if the journal execution has stopped
        '''
        pass

",5,5,snippet_622,0.4,"class JournalReader(object):
    '''Handle reading and interpretting a journal file from Autodesk Revit.'''

    def __init__(self, journal_file):
        '''Initialize the reader object with path to the target journal file.

        Args:
            journal_file (str): full path to target journal file
        '''
        self.journal_file = journal_file

    def _read_journal(self):
        '''Private method that reads the journal file contents.

        Returns:
            str: journal file contents
        '''
        with open(self.journal_file, 'r', encoding='utf-8', errors='ignore') as f:
            return f.read()

    def endswith(self, search_str):
        '''Check whether the provided string exists in Journal file.

        Only checks the last 5 lines of the journal file. This method is
        usually used when tracking a journal from an active Revit session.

        Args:
            search_str (str): string to search for

        Returns:
            bool: if True the search string is found
        '''
        content = self._read_journal()
        lines = content.splitlines()[-5:]
        return any(search_str in line for line in lines)

    def is_stopped(self):
        '''Check whether the journal execution has stopped.

        Returns:
            bool: True if the journal execution has stopped
        '''
        stop_keywords = [
            'Application: Exit',
            'JournalEngine Ended',
            'Journal ended'
        ]
        return any(self.endswith(k) for k in stop_keywords)","class JournalReader(object):
    '''Handle reading and interpretting a journal file from Autodesk Revit.'''

    def __init__(self, journal_file):
        '''Initialize the reader object with path to the target journal file.

        Args:
            journal_file (str): full path to target journal file
        '''
        self.journal_file = journal_file

    def _read_journal(self):
        '''Private method that reads the journal file contents.

        Returns:
            str: journal file contents
        '''
        with open(self.journal_file, 'r', encoding='utf-8') as f:
            return f.read()

    def endswith(self, search_str):
        '''Check whether the provided string exists in Journal file.

        Only checks the last 5 lines of the journal file. This method is
        usually used when tracking a journal from an active Revit session.

        Args:
            search_str (str): string to search for

        Returns:
            bool: if True the search string is found
        '''
        try:
            content = self._read_journal()
            lines = content.splitlines()
            last_lines = lines[-5:] if len(lines) >= 5 else lines
            return any(search_str in line for line in last_lines)
        except FileNotFoundError:
            return False

    def is_stopped(self):
        '''Check whether the journal execution has stopped.

        Returns:
            bool: True if the journal execution has stopped
        '''
        return self.endswith('Jrn.Data ""Finish"" , ""Success.""')","class JournalReader(object):
    '''Handle reading and interpretting a journal file from Autodesk Revit.'''

    def __init__(self, journal_file):
        '''Initialize the reader object with path to the target journal file.

        Args:
            journal_file (str): full path to target journal file
        '''
        self.journal_file = journal_file

    def _read_journal(self):
        '''Private method that reads the journal file contents.

        Returns:
            str: journal file contents
        '''
        with open(self.journal_file, 'r', encoding='utf-8') as f:
            return f.read()

    def endswith(self, search_str):
        '''Check whether the provided string exists in Journal file.

        Only checks the last 5 lines of the journal file. This method is
        usually used when tracking a journal from an active Revit session.

        Args:
            search_str (str): string to search for

        Returns:
            bool: if True the search string is found
        '''
        content = self._read_journal()
        lines = content.splitlines()
        last_5_lines = lines[-5:] if len(lines) >= 5 else lines
        
        for line in last_5_lines:
            if search_str in line:
                return True
        return False

    def is_stopped(self):
        '''Check whether the journal execution has stopped.

        Returns:
            bool: True if the journal execution has stopped
        '''
        return self.endswith('Jrn.Command ""SystemMenu"" , ""Quit the application; prompts to save projects , ID_APP_EXIT""')",full_docstr,0.8484848484848485,0.7700831024930747,0.7353760445682451,0.8319559228650137,0.6945671763224843,0.8090277777777778,0.6933797909407665,0.6293706293706294,0.9336520433425903,0.9387267231941223,0.93618243932724,0.9382167458534241,0.8605678431372549,0.8657534246575342,0.7933884297520662,0.7590027700831025,0.8438356164383561,0.702538301996234,0.8169491525423729,0.6870748299319728,0.6177474402730375,0.9313837289810181,0.9375156164169312,0.9344395995140076,0.9368987679481506,0.8820873469387756,0.8502673796791445,0.7903225806451614,0.7567567567567568,0.839572192513369,0.6882682714739708,0.7980456026058632,0.6699346405228758,0.6098360655737705,0.9296264052391052,0.9415407776832581,0.9355456233024597,0.9403356313705444,0.8997679020979021,0.6249818776495637,0.6240429665664399,0.6986867418340129,0.4464285714285714,0.7307692307692307,0.6548151422065565,0.6281399902009625,0.7191425566472412,0.4642857142857143,0.8076923076923077,0.6754964023386356,0.6187314091563133,0.7398476067916354,0.5357142857142857,0.8076923076923077
356487,ebroecker/canmatrix,ebroecker_canmatrix/src/canmatrix/canmatrix.py,canmatrix.canmatrix.Define,"class Define(object):
    """"""
    Hold the defines and default-values.
    """"""

    def __init__(self, definition):  # type (str) -> None
        """"""Initialize Define object.

        :param str definition: definition string. Ex: ""INT -5 10""
        """"""
        definition = definition.strip()
        self.definition = definition
        self.type = None  # type: typing.Optional[str]
        self.defaultValue = None  # type: typing.Any

        def safe_convert_str_to_int(inStr):  # type: (str) -> int
            """"""Convert string to int safely. Check that it isn't float.

            :param str inStr: integer represented as string.
            :rtype: int
            """"""
            out = int(defaultFloatFactory(inStr))
            if out != defaultFloatFactory(inStr):
                logger.warning(""Warning, integer was expected but got float: got: {0} using {1}\n"".format(inStr, str(out)))
            return out

        # for any known type:
        if definition[0:3] == 'INT':
            self.type = 'INT'
            min, max = definition[4:].split(' ', 2)
            self.min = safe_convert_str_to_int(min)
            self.max = safe_convert_str_to_int(max)

        elif definition[0:6] == 'STRING':
            self.type = 'STRING'
            self.min = None
            self.max = None

        elif definition[0:4] == 'ENUM':
            self.type = 'ENUM'
            tempValues = canmatrix.utils.quote_aware_comma_split(definition[5:])
            self.values = []  # type: typing.List[str]
            for value in tempValues:
                value = value.replace(""vector_leerstring"", """")
                self.values.append(value)

        elif definition[0:3] == 'HEX':  # differently rendered in DBC editor, but values are saved like for an INT
            self.type = 'HEX'
            min, max = definition[4:].split(' ', 2)
            self.min = safe_convert_str_to_int(min)
            self.max = safe_convert_str_to_int(max)

        elif definition[0:5] == 'FLOAT':
            self.type = 'FLOAT'
            min, max = definition[6:].split(' ', 2)
            self.min = defaultFloatFactory(min)
            self.max = defaultFloatFactory(max)

    def set_default(self, default):  # type: (typing.Any) -> None
        """"""Set Definition default value.

        :param default: default value; number, str or quoted str (""value"")
        """"""
        if default is not None and len(default) > 1 and default[0] == '""' and default[-1] == '""':
            default = default[1:-1]
        self.defaultValue = default

    def update(self):  # type: () -> None
        """"""Update definition string for type ENUM.

        For type ENUM rebuild the definition string from current values. Otherwise do nothing.
        """"""
        if self.type != 'ENUM':
            return
        self.definition = 'ENUM ""' + '"",""' .join(self.values) +'""'","class Define(object):
    '''
    Hold the defines and default-values.
    '''

    def __init__(self, definition):
    '''Initialize Define object.

        :param str definition: definition string. Ex: ""INT -5 10""
        '''
        pass

        def safe_convert_str_to_int(inStr):
    '''Convert string to int safely. Check that it isn't float.

            :param str inStr: integer represented as string.
            :rtype: int
            '''
                pass

    def set_default(self, default):
    '''Set Definition default value.

        :param default: default value; number, str or quoted str (""value"")
        '''
        pass

    def update(self):
    '''Update definition string for type ENUM.

        For type ENUM rebuild the definition string from current values. Otherwise do nothing.
        '''
        pass

",5,5,snippet_611,0.5384615384615384,"class Define(object):
    '''
    Hold the defines and default-values.
    '''

    def __init__(self, definition):
        '''Initialize Define object.

        :param str definition: definition string. Ex: ""INT -5 10""
        '''
        self.definition = definition.strip()
        parts = self.definition.split()
        if not parts:
            raise ValueError(""Empty definition"")
        self._type = parts[0].upper()
        self._default = None

        if self._type == ""INT"":
            if len(parts) != 3:
                raise ValueError(""INT definition must have exactly two bounds"")
            self._min = self.safe_convert_str_to_int(parts[1])
            self._max = self.safe_convert_str_to_int(parts[2])
        elif self._type == ""ENUM"":
            if len(parts) < 2:
                raise ValueError(""ENUM definition must have at least one value"")
            # store enum values in order
            self.enums = parts[1:]
        else:
            # for other types just keep raw parts
            self._params = parts[1:]

    @staticmethod
    def safe_convert_str_to_int(inStr):
        '''Convert string to int safely. Check that it isn't float.

        :param str inStr: integer represented as string.
        :rtype: int
        '''
        s = inStr.strip()
        if not s:
            raise ValueError(""Empty string cannot be converted to int"")
        # Reject floats like ""1.0"" or ""2e3""
        if any(c in s for c in ('.', 'e', 'E')):
            raise ValueError(f""String '{inStr}' looks like a float, not an int"")
        try:
            return int(s)
        except ValueError:
            raise ValueError(f""Cannot convert '{inStr}' to int"")

    def set_default(self, default):
        '''Set Definition default value.

        :param default: default value; number, str or quoted str (""value"")
        '''
        # If it's a quoted string, strip quotes
        if isinstance(default, str) and len(default) >= 2 and default[0] == '""' and default[-1] == '""':
            val = default[1:-1]
        else:
            val = default

        if self._type == ""INT"":
            # try converting to int
            try:
                ival = self.safe_convert_str_to_int(str(val))
            except ValueError:
                raise ValueError(""Default for INT must be integer"")
            if ival < self._min or ival > self._max:
                raise ValueError(f""Default {ival} out of bounds [{self._min}, {self._max}]"")
            self._default = ival

        elif self._type == ""ENUM"":
            # default must be one of enums
            if val not in self.enums:
                raise ValueError(f""Default '{val}' not in ENUM values {self.enums}"")
            self._default = val

        else:
            # for other types, accept as-is
            self._default = val

    def update(self):
        '''Update definition string for type ENUM.

        For type ENUM rebuild the definition string from current values. Otherwise do nothing.
        '''
        if self._type == ""ENUM"":
            self.definition = ""ENUM "" + "" "".join(self.enums)","class Define(object):
    '''
    Hold the defines and default-values.
    '''

    def __init__(self, definition):
        '''Initialize Define object.

        :param str definition: definition string. Ex: ""INT -5 10""
        '''
        self.definition = definition
        self.default = None
        parts = definition.split()
        if parts:
            self.type = parts[0]
            if self.type == 'ENUM':
                self.values = parts[1:]
            elif len(parts) >= 3:
                self.min_val = self.safe_convert_str_to_int(parts[1])
                self.max_val = self.safe_convert_str_to_int(parts[2])
    
    def safe_convert_str_to_int(self, inStr):
        '''Convert string to int safely. Check that it isn't float.

        :param str inStr: integer represented as string.
        :rtype: int
        '''
        if '.' in inStr:
            raise ValueError(""String represents a float, not an integer"")
        return int(inStr)

    def set_default(self, default):
        '''Set Definition default value.

        :param default: default value; number, str or quoted str (""value"")
        '''
        self.default = default

    def update(self):
        '''Update definition string for type ENUM.

        For type ENUM rebuild the definition string from current values. Otherwise do nothing.
        '''
        if self.type == 'ENUM':
            self.definition = 'ENUM ' + ' '.join(self.values)","class Define(object):
    '''
    Hold the defines and default-values.
    '''

    def __init__(self, definition):
        '''Initialize Define object.

        :param str definition: definition string. Ex: ""INT -5 10""
        '''
        self.definition = definition
        self.original_definition = definition
        parts = definition.split()
        self.type = parts[0]
        self.default = None
        
        if self.type == ""INT"":
            self.min_val = int(parts[1])
            self.max_val = int(parts[2])
        elif self.type == ""ENUM"":
            self.values = parts[1:]
        elif self.type == ""STRING"":
            pass

    def safe_convert_str_to_int(self, inStr):
        '''Convert string to int safely. Check that it isn't float.

        :param str inStr: integer represented as string.
        :rtype: int
        '''
        if '.' in inStr:
            raise ValueError(""Float value not allowed"")
        return int(inStr)

    def set_default(self, default):
        '''Set Definition default value.

        :param default: default value; number, str or quoted str (""value"")
        '''
        self.default = default

    def update(self):
        '''Update definition string for type ENUM.

        For type ENUM rebuild the definition string from current values. Otherwise do nothing.
        '''
        if self.type == ""ENUM"":
            self.definition = self.type + "" "" + "" "".join(self.values)",full_docstr,0.6097902097902098,0.3870967741935484,0.2981715893108299,0.4055944055944056,0.43297023018202285,0.7138810198300283,0.40425531914893614,0.28125,0.8405596613883972,0.8530533313751221,0.8467603921890259,0.8517873287200928,0.7434867901234566,0.6257425742574257,0.46123260437375746,0.375249500998004,0.47128712871287126,0.2126344505221009,0.922077922077922,0.7296416938110749,0.5915032679738562,0.9105221629142761,0.8327614068984985,0.869907557964325,0.8399346470832825,0.7685973553719004,0.616,0.45381526104417674,0.35483870967741943,0.4799999999999999,0.2033972619924481,0.9155844155844156,0.6970684039087948,0.545751633986928,0.9132342338562012,0.8316842913627625,0.8705535531044006,0.8391779661178589,0.7741069421487601,0.5043568125658621,0.2392089219138787,0.2824918326230739,0.4957264957264957,0.0,0.4673120261379491,0.1782998127067133,0.250777351674143,0.4401709401709401,0.0,0.4662180175027509,0.1838670423161211,0.2493810960709508,0.4316239316239316,0.0
345289,djangobot/djangobot,djangobot_djangobot/djangobot/client.py,djangobot.client.Client,"class Client(object):
    """"""
    Main client to instantiate the SlackAPI and client factory
    """"""

    def __init__(self, channel_layer, token, channel_name=u'slack.send'):
        """"""
        Args:
            channel_layer: channel layer on which this client will communicate to Django
            token: {str} Slack token
            channel_name: {str} channel name to send messages that will come back to slack
        """"""
        self.channel_layer = channel_layer
        self.token = token
        # TODO: Surface this channel_name in the CLI args
        self.channel_name = channel_name

    def run(self):
        """"""
        Main interface. Instantiate the SlackAPI, connect to RTM
        and start the client.
        """"""
        slack = SlackAPI(token=self.token)
        rtm = slack.rtm_start()

        factory = SlackClientFactory(rtm['url'])
        # Attach attributes
        factory.protocol = SlackClientProtocol
        factory.protocol.slack = slack
        factory.protocol.channel_layer = self.channel_layer
        factory.channel_name = self.channel_name

        # Here we go
        factory.run()","class Client(object):
    '''
    Main client to instantiate the SlackAPI and client factory
    '''

    def __init__(self, channel_layer, token, channel_name=u'slack.send'):
    '''
        Args:
            channel_layer: channel layer on which this client will communicate to Django
            token: {str} Slack token
            channel_name: {str} channel name to send messages that will come back to slack
        '''
        pass

    def run(self):
    '''
        Main interface. Instantiate the SlackAPI, connect to RTM
        and start the client.
        '''
        pass

",3,3,snippet_590,1.0,"class Client(object):
    '''
    Main client to instantiate the SlackAPI and client factory
    '''

    def __init__(self, channel_layer, token, channel_name=u'slack.send'):
        '''
        Args:
            channel_layer: channel layer on which this client will communicate to Django
            token: {str} Slack token
            channel_name: {str} channel name to send messages that will come back to slack
        '''
        self.channel_layer = channel_layer
        self.token = token
        self.channel_name = channel_name
        self._send = async_to_sync(self.channel_layer.send)

    def run(self):
        '''
        Main interface. Instantiate the SlackAPI, connect to RTM
        and start the client.
        '''
        sc = SlackClient(self.token)
        if not sc.rtm_connect():
            raise RuntimeError(""Unable to connect to Slack RTM"")
        while True:
            for event in sc.rtm_read():
                self._send(self.channel_name, {
                    ""type"": ""slack.event"",
                    ""event"": event
                })
            time.sleep(1)","class Client(object):
    '''
    Main client to instantiate the SlackAPI and client factory
    '''

    def __init__(self, channel_layer, token, channel_name=u'slack.send'):
        '''
        Args:
            channel_layer: channel layer on which this client will communicate to Django
            token: {str} Slack token
            channel_name: {str} channel name to send messages that will come back to slack
        '''
        self.channel_layer = channel_layer
        self.token = token
        self.channel_name = channel_name
        self.slack_api = None

    def run(self):
        '''
        Main interface. Instantiate the SlackAPI, connect to RTM
        and start the client.
        '''
        from slack import WebClient
        from slack.rtm.client import RTMClient
        
        # Instantiate the Slack API client
        self.slack_api = WebClient(token=self.token)
        
        # Create RTM client
        rtm_client = RTMClient(token=self.token)
        
        # Start the RTM client
        rtm_client.start()","class Client(object):
    '''
    Main client to instantiate the SlackAPI and client factory
    '''

    def __init__(self, channel_layer, token, channel_name=u'slack.send'):
        '''
        Args:
            channel_layer: channel layer on which this client will communicate to Django
            token: {str} Slack token
            channel_name: {str} channel name to send messages that will come back to slack
        '''
        self.channel_layer = channel_layer
        self.token = token
        self.channel_name = channel_name
        self.slack_api = None

    def run(self):
        '''
        Main interface. Instantiate the SlackAPI, connect to RTM
        and start the client.
        '''
        from slack_sdk import WebClient
        from slack_sdk.rtm import RTMClient
        
        self.slack_api = WebClient(token=self.token)
        rtm_client = RTMClient(token=self.token)
        
        @rtm_client.on('message')
        def handle_message(**payload):
            data = payload.get('data', {})
            if data.get('type') == 'message' and 'text' in data:
                self.channel_layer.send(self.channel_name, {
                    'type': 'slack.message',
                    'text': data['text'],
                    'channel': data.get('channel'),
                    'user': data.get('user'),
                    'ts': data.get('ts')
                })
        
        rtm_client.start()",full_docstr,0.7384615384615385,0.6744186046511628,0.6171875,0.7076923076923077,0.6083774076973621,0.7510917030567685,0.5921052631578947,0.5198237885462555,0.9007962942123413,0.8983125686645508,0.8995527625083923,0.8985604047775269,0.8502430434782609,0.7529411764705881,0.6561264822134387,0.6215139442231076,0.7058823529411765,0.5866982379989308,0.8282828282828283,0.6751269035532995,0.5969387755102041,0.9346468448638916,0.9085630774497986,0.9214203357696533,0.911105751991272,0.8501306976744186,0.7034482758620689,0.6041666666666666,0.5664335664335665,0.6482758620689655,0.5082015654970768,0.6258741258741258,0.4842105263157895,0.43309859154929575,0.8711021542549133,0.9110822677612305,0.890643835067749,0.9069198966026306,0.8138546753246756,0.5409554207721645,0.5104314182499416,0.523888349129904,0.5517241379310345,0.5777777777777777,0.5386818867119675,0.5198874089836255,0.5252615938029418,0.6206896551724138,0.4888888888888889,0.5753478068960115,0.4801310607219395,0.5266241515364358,0.6724137931034483,0.6222222222222222
387700,flowersteam/explauto,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/flowersteam_explauto/explauto/sensorimotor_model/inverse/cma.py,explauto.sensorimotor_model.inverse.cma.FFWrapper.FitnessTransformation,"class FitnessTransformation(object):
    """"""This class does nothing but serve as an interface template.
    Typical use-case::

      f = FitnessTransformation(f, parameters_if_needed)``

    See: class ``TransformSearchSpace``

    """"""

    def __init__(self, fitness_function, *args, **kwargs):
        """"""`fitness_function` must be callable (e.g. a function
        or a callable class instance)""""""
        # the original fitness to be called
        self.inner_fitness = fitness_function
        # self.condition_number = ...

    def __call__(self, x, *args):
        """"""identity as default transformation""""""
        if hasattr(self, 'x_transformation'):
            x = self.x_transformation(x)
        f = self.inner_fitness(x, *args)
        if hasattr(self, 'f_transformation'):
            f = self.f_transformation(f)
        return f
","class FitnessTransformation(object):
    '''This class does nothing but serve as an interface template.
    Typical use-case::

      f = FitnessTransformation(f, parameters_if_needed)``

    See: class ``TransformSearchSpace``

    '''


    def __init__(self, fitness_function, *args, **kwargs):
    '''`fitness_function` must be callable (e.g. a function
        or a callable class instance)'''
        pass


    def __call__(self, x, *args):
    '''identity as default transformation'''
        pass

",3,3,snippet_653,0.5714285714285714,"class FitnessTransformation(object):
    '''This class does nothing but serve as an interface template.
    Typical use-case::

      f = FitnessTransformation(f, parameters_if_needed)

    See: class ``TransformSearchSpace``
    '''

    def __init__(self, fitness_function, *args, **kwargs):
        '''`fitness_function` must be callable (e.g. a function
        or a callable class instance)'''
        if not callable(fitness_function):
            raise TypeError(""fitness_function must be callable"")
        self._fitness = fitness_function
        self._args = args
        self._kwargs = kwargs

    def __call__(self, x, *args):
        '''identity as default transformation'''
        return self._fitness(x, *(self._args + args), **self._kwargs)","class FitnessTransformation(object):
    '''This class does nothing but serve as an interface template.
    Typical use-case::

      f = FitnessTransformation(f, parameters_if_needed)``

    See: class ``TransformSearchSpace``

    '''


    def __init__(self, fitness_function, *args, **kwargs):
        '''`fitness_function` must be callable (e.g. a function
        or a callable class instance)'''
        self.fitness_function = fitness_function


    def __call__(self, x, *args):
        '''identity as default transformation'''
        return self.fitness_function(x, *args)","class FitnessTransformation(object):
    '''This class does nothing but serve as an interface template.
    Typical use-case::

      f = FitnessTransformation(f, parameters_if_needed)``

    See: class ``TransformSearchSpace``

    '''

    def __init__(self, fitness_function, *args, **kwargs):
        '''`fitness_function` must be callable (e.g. a function
        or a callable class instance)'''
        self.fitness_function = fitness_function
        self.args = args
        self.kwargs = kwargs

    def __call__(self, x, *args):
        '''identity as default transformation'''
        return self.fitness_function(x, *args)",full_docstr,0.7759562841530054,0.6408839779005524,0.5921787709497206,0.73224043715847,0.5593196546482022,0.8546511627906976,0.6491228070175439,0.5529411764705883,0.9424854516983032,0.9127236008644104,0.927365779876709,0.915614902973175,0.7755124489795918,0.7852760736196319,0.6832298136645962,0.6415094339622642,0.7730061349693252,0.46606905249194136,0.937984496124031,0.828125,0.7559055118110236,0.9784804582595825,0.9028924703598022,0.9391680359840393,0.9099216461181641,0.8469403061224489,0.7810650887573964,0.6706586826347305,0.6303030303030304,0.757396449704142,0.49590949477989443,0.9136690647482014,0.782608695652174,0.7007299270072993,0.9717603921890259,0.9081413149833679,0.9388744235038757,0.914125919342041,0.8231310204081632,0.400183070235434,0.3923934785364383,0.4131688560725605,0.3720930232558139,0.4230769230769231,0.405447587786491,0.3914788317813581,0.4422972080944807,0.4418604651162791,0.3461538461538461,0.4093247918431655,0.4124586356912096,0.4448763098567657,0.3953488372093023,0.3846153846153846
117058,Duke-GCB/DukeDSClient,Duke-GCB_DukeDSClient/ddsc/core/projectuploader.py,ddsc.core.projectuploader.CreateProjectCommand,"class CreateProjectCommand(object):
    """"""
    Create project in DukeDS.
    """"""
    def __init__(self, settings, local_project):
        """"""
        Setup passing in all necessary data to create project and update external state.
        :param settings: UploadSettings: settings to be used/updated when we upload the project.
        :param local_project: LocalProject: information about the project(holds remote_id when done)
        """"""
        self.settings = settings
        self.local_project = local_project
        if not settings.project_name_or_id.is_name:
            raise ValueError('Programming Error: CreateProjectCommand called without project name.')
        self.func = upload_project_run

    def before_run(self, parent_task_result):
        """"""
        Notify progress bar that we are creating the project.
        """"""
        self.settings.watcher.transferring_item(self.local_project)

    def create_context(self, message_queue, task_id):
        """"""
        Create data needed by upload_project_run(DukeDS connection info).
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        """"""
        return UploadContext(self.settings, (), message_queue, task_id)

    def after_run(self, result_id):
        """"""
        Save uuid associated with project we just created.
        :param result_id: str: uuid of the project
        """"""
        self.local_project.set_remote_id_after_send(result_id)
        self.settings.project_id = result_id","class CreateProjectCommand(object):
    '''
    Create project in DukeDS.
    '''

    def __init__(self, settings, local_project):
    '''
        Setup passing in all necessary data to create project and update external state.
        :param settings: UploadSettings: settings to be used/updated when we upload the project.
        :param local_project: LocalProject: information about the project(holds remote_id when done)
        '''
        pass

    def before_run(self, parent_task_result):
    '''
        Notify progress bar that we are creating the project.
        '''
        pass

    def create_context(self, message_queue, task_id):
    '''
        Create data needed by upload_project_run(DukeDS connection info).
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        pass

    def after_run(self, result_id):
    '''
        Save uuid associated with project we just created.
        :param result_id: str: uuid of the project
        '''
        pass

",5,5,snippet_109,0.2857142857142857,"class CreateProjectCommand(object):
    '''
    Create project in DukeDS.
    '''

    def __init__(self, settings, local_project):
        '''
        Setup passing in all necessary data to create project and update external state.
        :param settings: UploadSettings: settings to be used/updated when we upload the project.
        :param local_project: LocalProject: information about the project(holds remote_id when done)
        '''
        self.settings = settings
        self.local_project = local_project

    def before_run(self, parent_task_result):
        '''
        Notify progress bar that we are creating the project.
        '''
        # If this is a Celery AsyncResult-like, update progress
        if hasattr(parent_task_result, 'update_state'):
            try:
                parent_task_result.update_state(
                    state='PROGRESS',
                    meta={'status': 'Creating project in DukeDS...', 'current': 0, 'total': 1}
                )
            except Exception:
                pass

    def create_context(self, message_queue, task_id):
        '''
        Create data needed by upload_project_run(DukeDS connection info).
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        return {
            'settings': self.settings,
            'local_project': self.local_project,
            'message_queue': message_queue,
            'task_id': task_id,
        }

    def after_run(self, result_id):
        '''
        Save uuid associated with project we just created.
        :param result_id: str: uuid of the project
        '''
        # Store on the local project
        setattr(self.local_project, 'remote_id', result_id)
        if hasattr(self.local_project, 'save'):
            try:
                self.local_project.save()
            except Exception:
                pass

        # Also persist to upload settings if desired
        setattr(self.settings, 'project_remote_id', result_id)
        if hasattr(self.settings, 'save'):
            try:
                self.settings.save()
            except Exception:
                pass","class CreateProjectCommand(object):
    '''
    Create project in DukeDS.
    '''

    def __init__(self, settings, local_project):
        '''
        Setup passing in all necessary data to create project and update external state.
        :param settings: UploadSettings: settings to be used/updated when we upload the project.
        :param local_project: LocalProject: information about the project(holds remote_id when done)
        '''
        self.settings = settings
        self.local_project = local_project

    def before_run(self, parent_task_result):
        '''
        Notify progress bar that we are creating the project.
        '''
        if self.settings.progress_bar:
            self.settings.progress_bar.update_create_project()

    def create_context(self, message_queue, task_id):
        '''
        Create data needed by upload_project_run(DukeDS connection info).
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        return {
            'dds_connection': self.settings.get_connection(),
            'project_name': self.local_project.name
        }

    def after_run(self, result_id):
        '''
        Save uuid associated with project we just created.
        :param result_id: str: uuid of the project
        '''
        self.local_project.remote_id = result_id","class CreateProjectCommand(object):
    '''
    Create project in DukeDS.
    '''

    def __init__(self, settings, local_project):
        '''
        Setup passing in all necessary data to create project and update external state.
        :param settings: UploadSettings: settings to be used/updated when we upload the project.
        :param local_project: LocalProject: information about the project(holds remote_id when done)
        '''
        self.settings = settings
        self.local_project = local_project

    def before_run(self, parent_task_result):
        '''
        Notify progress bar that we are creating the project.
        '''
        if hasattr(self.settings, 'progress_queue') and self.settings.progress_queue:
            self.settings.progress_queue.put({
                'type': 'creating_project',
                'message': 'Creating project...'
            })

    def create_context(self, message_queue, task_id):
        '''
        Create data needed by upload_project_run(DukeDS connection info).
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        return {
            'message_queue': message_queue,
            'task_id': task_id,
            'settings': self.settings,
            'local_project': self.local_project
        }

    def after_run(self, result_id):
        '''
        Save uuid associated with project we just created.
        :param result_id: str: uuid of the project
        '''
        self.local_project.remote_id = result_id",full_docstr,0.7902869757174393,0.7139689578713969,0.6592427616926504,0.7328918322295805,0.5902530164328846,0.6995305164319249,0.571764705882353,0.5141509433962265,0.8852185606956482,0.9215772747993469,0.903032124042511,0.9178075194358826,0.7898571739130438,0.8859416445623343,0.8426666666666667,0.7828418230563003,0.8435013262599469,0.666931560410071,0.9146757679180887,0.8047945205479452,0.738831615120275,0.9644809365272522,0.9358257055282593,0.9499372243881226,0.9386144280433655,0.8473297709923664,0.8849104859335037,0.8174807197943444,0.7596899224806201,0.823529411764706,0.6953112119686894,0.8695652173913043,0.7476635514018691,0.684375,0.9522172212600708,0.9283807873725891,0.940147876739502,0.9307105541229248,0.8138546753246753,0.6189804210396006,0.5056615808325873,0.679351012416724,0.4727272727272727,0.8181818181818182,0.6228587161238681,0.6771687827488785,0.6809327484132609,0.5272727272727272,0.6060606060606061,0.6518923242340797,0.6710679013873336,0.6819559410035304,0.5272727272727272,0.7272727272727273
235719,anrosent/LT-code,anrosent_LT-code/lt/sampler.py,lt.sampler.PRNG,"class PRNG(object):
    """"""A Pseudorandom Number Generator that yields samples
    from the set of source blocks using the RSD degree
    distribution described above.
    """"""

    def __init__(self, params):
        """"""Provide RSD parameters on construction
        """"""

        self.state = None  # Seed is set by interfacing code using set_seed
        K, delta, c = params
        self.K = K
        self.cdf = gen_rsd_cdf(K, delta, c)

    def _get_next(self):
        """"""Executes the next iteration of the PRNG
        evolution process, and returns the result
        """"""

        self.state = PRNG_A * self.state % PRNG_M
        return self.state

    def _sample_d(self):
        """"""Samples degree given the precomputed
        distributions above and the linear PRNG output
        """"""

        p = self._get_next() / PRNG_MAX_RAND
        for ix, v in enumerate(self.cdf):
            if v > p:
                return ix + 1
        return ix + 1

    def set_seed(self, seed):
        """"""Reset the state of the PRNG to the 
        given seed
        """"""

        self.state = seed

    
    def get_src_blocks(self, seed=None):
        """"""Returns the indices of a set of `d` source blocks
        sampled from indices i = 1, ..., K-1 uniformly, where
        `d` is sampled from the RSD described above.
        """"""

        if seed:
            self.state = seed

        blockseed = self.state
        d = self._sample_d()
        have = 0
        nums = set()
        while have < d:
            num = self._get_next() % self.K
            if num not in nums:
                nums.add(num)
                have += 1
        return blockseed, d, nums","class PRNG(object):
    '''A Pseudorandom Number Generator that yields samples
    from the set of source blocks using the RSD degree
    distribution described above.
    '''

    def __init__(self, params):
    '''Provide RSD parameters on construction
        '''
        pass

    def _get_next(self):
    '''Executes the next iteration of the PRNG
        evolution process, and returns the result
        '''
        pass

    def _sample_d(self):
    '''Samples degree given the precomputed
        distributions above and the linear PRNG output
        '''
        pass

    def set_seed(self, seed):
    '''Reset the state of the PRNG to the 
        given seed
        '''
        pass

    def get_src_blocks(self, seed=None):
    '''Returns the indices of a set of `d` source blocks
        sampled from indices i = 1, ..., K-1 uniformly, where
        `d` is sampled from the RSD described above.
        '''
        pass

",6,6,snippet_333,0.1764705882352941,"class PRNG(object):
    """"""A Pseudorandom Number Generator that yields samples
    from the set of source blocks using the RSD degree
    distribution described above.
    """"""
    def __init__(self, params):
        self.K = int(params['K'])
        self.c = float(params['c'])
        self.delta = float(params['delta'])
        # LCG parameters
        self._mod = 2**31
        self._a = 1103515245
        self._inc = 12345
        self._state = params.get('seed', 1) % self._mod
        # compute RSD
        K, c, delta = self.K, self.c, self.delta
        R = c * math.log(K / delta) * math.sqrt(K)
        S = int(R)
        # ideal soliton rho
        rho = [0.0] * (K + 1)
        rho[1] = 1.0 / K
        for d in range(2, K + 1):
            rho[d] = 1.0 / (d * (d - 1))
        # spike tau
        tau = [0.0] * (K + 1)
        if S >= 1:
            bound = int(K / R)
            for d in range(1, bound):
                tau[d] = R / (d * K)
            if bound <= K:
                tau[bound] = R * math.log(R / delta) / K
        # combine and normalize
        beta = sum(rho[1:]) + sum(tau[1:])
        mu = [0.0] * (K + 1)
        for d in range(1, K + 1):
            mu[d] = (rho[d] + tau[d]) / beta
        # cumulative distribution
        cdf = [0.0] * (K + 1)
        cum = 0.0
        for d in range(1, K + 1):
            cum += mu[d]
            cdf[d] = cum
        cdf[K] = 1.0
        self._cdf = cdf

    def _get_next(self):
        self._state = (self._a * self._state + self._inc) % self._mod
        return self._state / float(self._mod)

    def _sample_d(self):
        u = self._get_next()
        # binary search in cdf
        lo, hi = 1, self.K
        while lo < hi:
            mid = (lo + hi) // 2
            if self._cdf[mid] < u:
                lo = mid + 1
            else:
                hi = mid
        return lo

    def set_seed(self, seed):
        self._state = seed % self._mod

    def get_src_blocks(self, seed=None):
        if seed is not None:
            self.set_seed(seed)
        d = self._sample_d()
        K = self.K
        idx = list(range(K))
        for i in range(d):
            j = i + int(self._get_next() * (K - i))
            idx[i], idx[j] = idx[j], idx[i]
        return idx[:d]","class PRNG(object):
    '''A Pseudorandom Number Generator that yields samples
    from the set of source blocks using the RSD degree
    distribution described above.
    '''

    def __init__(self, params):
        '''Provide RSD parameters on construction
        '''
        self.params = params
        self.K = params['K']  # number of source blocks
        self.S = params.get('S', 8)  # security parameter
        self.seed = None
        self._precompute_rsd()
        
    def _precompute_rsd(self):
        '''Precompute the RSD distribution'''
        K = self.K
        S = self.S
        
        # Ideal Soliton distribution
        rho = [0] * (K + 1)
        rho[1] = 1.0 / K
        for i in range(2, K + 1):
            rho[i] = 1.0 / (i * (i - 1))
        
        # Robust Soliton distribution
        R = S * math.ceil(math.sqrt(K * math.log(K) / S))
        tau = [0] * (K + 1)
        for i in range(1, min(R, K) + 1):
            tau[i] = S / (i * R)
        if R < K:
            tau[R] = math.log(K / R) * S / R
        
        # Combine distributions
        beta = sum(rho[i] + tau[i] for i in range(1, K + 1))
        self.rsd = [0] * (K + 1)
        for i in range(1, K + 1):
            self.rsd[i] = (rho[i] + tau[i]) / beta
    
    def _get_next(self):
        '''Executes the next iteration of the PRNG
        evolution process, and returns the result
        '''
        if self.seed is None:
            self.seed = random.randint(0, 2**32 - 1)
        
        # Simple linear congruential generator
        a = 1664525
        c = 1013904223
        m = 2**32
        self.seed = (a * self.seed + c) % m
        return self.seed / m

    def _sample_d(self):
        '''Samples degree given the precomputed
        distributions above and the linear PRNG output
        '''
        u = self._get_next()
        cumulative = 0.0
        for i in range(1, len(self.rsd)):
            cumulative += self.rsd[i]
            if u <= cumulative:
                return i
        return len(self.rsd) - 1

    def set_seed(self, seed):
        '''Reset the state of the PRNG to the 
        given seed
        '''
        self.seed = seed

    def get_src_blocks(self, seed=None):
        '''Returns the indices of a set of `d` source blocks
        sampled from indices i = 1, ..., K-1 uniformly, where
        `d` is sampled from the RSD described above.
        '''
        if seed is not None:
            self.set_seed(seed)
        
        d = self._sample_d()
        # Sample d distinct indices from 0 to K-1
        if d >= self.K:
            return list(range(self.K))
        else:
            return random.sample(range(self.K), d)","class PRNG(object):
    '''A Pseudorandom Number Generator that yields samples
    from the set of source blocks using the RSD degree
    distribution described above.
    '''

    def __init__(self, params):
        '''Provide RSD parameters on construction
        '''
        self.K = params['K']
        self.c = params.get('c', 0.1)
        self.delta = params.get('delta', 0.5)
        self.state = 1
        self._precompute_distributions()

    def _precompute_distributions(self):
        '''Precompute the RSD distribution'''
        import math
        
        # Ideal soliton distribution
        rho = [0] * (self.K + 1)
        rho[1] = 1.0 / self.K
        for i in range(2, self.K + 1):
            rho[i] = 1.0 / (i * (i - 1))
        
        # Robust soliton distribution
        R = self.c * math.log(self.K / self.delta) * math.sqrt(self.K)
        tau = [0] * (self.K + 1)
        
        for i in range(1, int(self.K / R) + 1):
            tau[i] = R / (i * self.K)
        tau[int(self.K / R)] = R * math.log(R / self.delta) / self.K
        
        # Combine distributions
        mu = [rho[i] + tau[i] for i in range(self.K + 1)]
        beta = sum(mu)
        
        # Normalize
        self.distribution = [mu[i] / beta for i in range(self.K + 1)]
        
        # Create cumulative distribution
        self.cumulative = [0] * (self.K + 1)
        for i in range(1, self.K + 1):
            self.cumulative[i] = self.cumulative[i-1] + self.distribution[i]

    def _get_next(self):
        '''Executes the next iteration of the PRNG
        evolution process, and returns the result
        '''
        # Linear congruential generator
        a = 1664525
        c = 1013904223
        m = 2**32
        self.state = (a * self.state + c) % m
        return self.state / m

    def _sample_d(self):
        '''Samples degree given the precomputed
        distributions above and the linear PRNG output
        '''
        rand_val = self._get_next()
        for i in range(1, self.K + 1):
            if rand_val <= self.cumulative[i]:
                return i
        return self.K

    def set_seed(self, seed):
        '''Reset the state of the PRNG to the 
        given seed
        '''
        self.state = seed if seed is not None else 1

    def get_src_blocks(self, seed=None):
        '''Returns the indices of a set of `d` source blocks
        sampled from indices i = 1, ..., K-1 uniformly, where
        `d` is sampled from the RSD described above.
        '''
        if seed is not None:
            self.set_seed(seed)
        
        d = self._sample_d()
        blocks = set()
        
        while len(blocks) < d:
            rand_val = self._get_next()
            block_idx = int(rand_val * self.K)
            if block_idx == 0:
                block_idx = 1
            blocks.add(block_idx)
        
        return list(blocks)",full_docstr,0.4501845018450184,0.2703703703703704,0.17472118959107805,0.34686346863468637,0.250851478986933,0.3746177370030581,0.23889739663093415,0.17638036809815952,0.7862943410873413,0.8164402842521667,0.8010838031768799,0.8133220672607422,0.7489589803220039,0.5862068965517242,0.44636678200692037,0.3993055555555556,0.5379310344827587,0.33118972373384337,0.44043887147335425,0.3218210361067504,0.2562893081761006,0.8251187801361084,0.8807827830314636,0.8520426154136658,0.8748806715011597,0.7607385889570554,0.6023294509151415,0.4607679465776294,0.39530988274706863,0.5457570715474209,0.331455570279193,0.42752562225475843,0.32404692082111436,0.26284875183553597,0.821368932723999,0.8860828876495361,0.8524995446205139,0.879156231880188,0.7690410112359549,0.2967377516437718,0.1207435190091129,0.1958371171956038,0.5,0.3703703703703703,0.3901094252992731,0.2656118668932993,0.4655285883398806,0.5576923076923077,0.2716049382716049,0.3986451896642372,0.2647812078922341,0.4650084776403084,0.4326923076923077,0.4320987654320987
135530,JdeRobot/base,src/libs/comm_py/comm/ice/irIceClient.py,comm.ice.irIceClient.IRIceClient,"class IRIceClient:
    '''
        IR Ice Client. Recives LaserData from Ice interface running IR update method in a thread.
    '''
    def __init__(self,ic,prefix, start = False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ir = IR(ic,prefix)

        self.kill_event = threading.Event()
        self.thread = ThreadSensor(self.ir, self.kill_event)
        self.thread.daemon = True

        if start:
            self.start()

    
    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.clear()
        self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.set()

    def getIRData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        return self.ir.getIRData()

    def hasproxy (self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.ir.hasproxy()","class IRIceClient:
    '''
        IR Ice Client. Recives LaserData from Ice interface running IR update method in a thread.
    '''

    def __init__(self,ic,prefix, start = False):
    '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        pass

    def start(self):
    '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def stop(self):
    '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def getIRData(self):
    '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        pass

    def hasproxy (self):
    '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        pass

",6,6,snippet_160,0.25,"class IRIceClient:
    '''
        IR Ice Client. Recives LaserData from Ice interface running IR update method in a thread.
    '''

    def __init__(self, ic, prefix, start = False):
        '''
            LaserIceClient Contructor.

            @param ic: Ice Communicator
            @param prefix: prefix name of client in config file
            @param start: indicates if start automatically the client

            @type ic: Ice Communicator
            @type prefix: String
            @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self._proxy = None
        self._lastData = None
        self._lock = threading.Lock()
        self._thread = None
        self._running = False

        # try to create the proxy
        try:
            props = self.ic.getProperties()
            proxy_str = props.getProperty(self.prefix + "".Proxy"")
            base = self.ic.stringToProxy(proxy_str)
            # you must replace 'Jderobot.IRPrx' with your actual IR proxy class
            self._proxy = Jderobot.IRPrx.checkedCast(base)
            if not self._proxy:
                raise RuntimeError(""Invalid IR proxy"")
        except Exception:
            self._proxy = None

        if start:
            self.start()

    def start(self):
        '''
            Starts the client. If client is stopped you can not start again, Threading.Thread raised error
        '''
        if not self.hasproxy():
            raise RuntimeError(""Cannot start, proxy not initialized"")
        if self._thread and self._thread.is_alive():
            raise RuntimeError(""Client already started"")
        self._running = True
        self._thread = threading.Thread(target=self._run)
        self._thread.daemon = True
        self._thread.start()

    def stop(self):
        '''
            Stops the client. If client is stopped you can not start again, Threading.Thread raised error
        '''
        if not self._thread or not self._thread.is_alive():
            return
        self._running = False
        self._thread.join()

    def getIRData(self):
        '''
            Returns last LaserData. 

            @return last JdeRobotTypes LaserData saved
        '''
        with self._lock:
            return self._lastData

    def hasproxy(self):
        '''
            Returns if proxy has ben created or not. 

            @return if proxy has ben created or not (Boolean)
        '''
        return self._proxy is not None

    def _run(self):
        while self._running:
            try:
                # replace 'update' with the actual method name of your IR interface
                data = self._proxy.update()
                with self._lock:
                    self._lastData = data
            except Exception:
                # ignore errors during update
                pass","class IRIceClient:
    '''
        IR Ice Client. Recives LaserData from Ice interface running IR update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.irData = None
        self.proxy = None
        self.topic = False
        self._lock = threading.Lock()
        self._running = False
        self._thread = None
        
        # Try to create proxy
        try:
            proxy_str = self.ic.propertyToProxy(self.prefix + "".Proxy"")
            if proxy_str:
                self.proxy = self.ic.stringToProxy(proxy_str)
                self.topic = True
        except Exception as e:
            logging.warning(""IR Ice Client: Could not create proxy: "" + str(e))
            self.topic = False
            
        if start and self.topic:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if not self._running and self.topic:
            self._running = True
            self._thread = threading.Thread(target=self._run)
            self._thread.daemon = True
            self._thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self._running = False
        if self._thread and self._thread.is_alive():
            self._thread.join()

    def getIRData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        with self._lock:
            return self.irData

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.topic

    def _run(self):
        '''
        Main thread loop to receive IR data
        '''
        while self._running:
            try:
                if self.proxy:
                    # Simulate getting IR data - in a real implementation this would call the Ice interface
                    # self.irData = self.proxy.getLaserData()
                    pass
                time.sleep(0.05)  # 20 Hz update rate
            except Exception as e:
                logging.error(""IR Ice Client error: "" + str(e))
                time.sleep(1)","class IRIceClient:
    '''
        IR Ice Client. Recives LaserData from Ice interface running IR update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.proxy = None
        self.ir_data = None
        self.lock = threading.Lock()
        self.running = False
        self.thread = None
        
        try:
            proxystr = self.ic.getProperties().getProperty(self.prefix + "".Proxy"")
            if proxystr:
                self.proxy = self.ic.stringToProxy(proxystr)
        except:
            self.proxy = None
            
        if start:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if not self.running and self.proxy:
            self.running = True
            self.thread = threading.Thread(target=self._update_loop)
            self.thread.daemon = True
            self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.running = False
        if self.thread:
            self.thread.join()

    def getIRData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        with self.lock:
            return self.ir_data

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.proxy is not None

    def _update_loop(self):
        '''
        Internal method that runs in a separate thread to continuously update IR data
        '''
        while self.running:
            try:
                if self.proxy:
                    data = self.proxy.getLaserData()
                    with self.lock:
                        self.ir_data = data
            except:
                pass
            time.sleep(0.1)",full_docstr,0.6473029045643153,0.5708333333333334,0.5355648535564853,0.6265560165975104,0.4415330396629827,0.49625468164794007,0.4352720450281426,0.39849624060150374,0.858863890171051,0.9373222589492798,0.8963795304298401,0.928837239742279,0.7867805307262569,0.65,0.5732217573221758,0.5336134453781513,0.6291666666666667,0.44942014791873003,0.5047984644913628,0.4423076923076923,0.40655105973025046,0.855169415473938,0.934868335723877,0.8932446241378784,0.926236093044281,0.7917881375358166,0.720554272517321,0.654292343387471,0.6060606060606061,0.697459584295612,0.5571725609508483,0.617169373549884,0.5465116279069767,0.5128205128205128,0.8917549848556519,0.9490757584571838,0.9195228815078735,0.9430142045021057,0.812023737704918,0.5764525608406075,0.4440144041779048,0.819538155969395,0.6805555555555556,0.3617021276595745,0.5606951851299043,0.4299359477369581,0.7918637053122101,0.6805555555555556,0.3404255319148936,0.601281258253237,0.5339268511867223,0.8150516097222066,0.6944444444444444,0.3617021276595745
117234,Duke-GCB/DukeDSClient,Duke-GCB_DukeDSClient/ddsc/sdk/client.py,ddsc.sdk.client.BaseResponseItem,"class BaseResponseItem(object):
    """"""
    Base class for responses from DDSConnection API converts dict into properties for subclasses.
    """"""
    def __init__(self, dds_connection, data_dict):
        """"""
        :param dds_connection: DDSConnection
        :param data_dict: dict: dictionary response from DDSConnection API
        """"""
        self.dds_connection = dds_connection
        self._data_dict = dict(data_dict)

    def __getattr__(self, key):
        """"""
        Return property from the dictionary passed to the constructor.
        """"""
        try:
            return self._data_dict[key]
        except KeyError:
            msg = ""'{}' object has no attribute '{}'"".format(self.__class__.__name__, key)
            raise AttributeError(msg)","class BaseResponseItem(object):
    '''
    Base class for responses from DDSConnection API converts dict into properties for subclasses.
    '''

    def __init__(self, dds_connection, data_dict):
    '''
        :param dds_connection: DDSConnection
        :param data_dict: dict: dictionary response from DDSConnection API
        '''
        pass

    def __getattr__(self, key):
    '''
        Return property from the dictionary passed to the constructor.
        '''
        pass

",3,3,snippet_116,1.0,"class BaseResponseItem(object):
    '''
    Base class for responses from DDSConnection API converts dict into properties for subclasses.
    '''
    def __init__(self, dds_connection, data_dict):
        '''
        :param dds_connection: DDSConnection
        :param data_dict: dict: dictionary response from DDSConnection API
        '''
        self._dds_connection = dds_connection
        self._data = data_dict or {}

    def __getattr__(self, key):
        '''
        Return property from the dictionary passed to the constructor.
        '''
        if key in self._data:
            return self._data[key]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{key}'"")","class BaseResponseItem(object):
    '''
    Base class for responses from DDSConnection API converts dict into properties for subclasses.
    '''

    def __init__(self, dds_connection, data_dict):
        '''
        :param dds_connection: DDSConnection
        :param data_dict: dict: dictionary response from DDSConnection API
        '''
        self.dds_connection = dds_connection
        self.data_dict = data_dict

    def __getattr__(self, key):
        '''
        Return property from the dictionary passed to the constructor.
        '''
        if 'data_dict' in self.__dict__ and key in self.data_dict:
            return self.data_dict[key]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{key}'"")","class BaseResponseItem(object):
    '''
    Base class for responses from DDSConnection API converts dict into properties for subclasses.
    '''

    def __init__(self, dds_connection, data_dict):
        '''
        :param dds_connection: DDSConnection
        :param data_dict: dict: dictionary response from DDSConnection API
        '''
        self.dds_connection = dds_connection
        self.data_dict = data_dict

    def __getattr__(self, key):
        '''
        Return property from the dictionary passed to the constructor.
        '''
        if key in self.data_dict:
            return self.data_dict[key]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{key}'"")",full_docstr,0.8999999999999999,0.810126582278481,0.7307692307692307,0.8374999999999999,0.6886874902757536,0.9044585987261147,0.7756410256410257,0.6709677419354839,0.9713132977485657,0.9678599238395691,0.9695835113525391,0.9682042002677917,0.87805,0.8928571428571429,0.8313253012048193,0.7682926829268293,0.8214285714285715,0.7121235386421213,0.8630952380952381,0.7425149700598802,0.6506024096385542,0.9671605825424194,0.9711585640907288,0.9691554307937622,0.9707573056221008,0.8488387209302325,0.9259259259259259,0.8625,0.7974683544303798,0.8518518518518519,0.7017570596065444,0.9230769230769231,0.7935483870967742,0.6948051948051948,0.9777050018310547,0.9708788394927979,0.9742799997329712,0.9715571403503418,0.87805,0.5073865037867757,0.5271085552265765,0.5403162477993142,0.4166666666666667,0.5454545454545454,0.4943777686830199,0.5292246008141517,0.5492965749280289,0.4444444444444444,0.4545454545454545,0.4893679926687097,0.5369632745346888,0.5492965749280289,0.4166666666666667,0.4545454545454545
232557,andymccurdy/redis-py,andymccurdy_redis-py/redis/cluster.py,redis.cluster.NodeCommands,"class NodeCommands:
    """""" """"""

    def __init__(self, parse_response, connection_pool, connection):
        """""" """"""
        self.parse_response = parse_response
        self.connection_pool = connection_pool
        self.connection = connection
        self.commands = []

    def append(self, c):
        """""" """"""
        self.commands.append(c)

    def write(self):
        """"""
        Code borrowed from Redis so it can be fixed
        """"""
        connection = self.connection
        commands = self.commands

        # We are going to clobber the commands with the write, so go ahead
        # and ensure that nothing is sitting there from a previous run.
        for c in commands:
            c.result = None

        # build up all commands into a single request to increase network perf
        # send all the commands and catch connection and timeout errors.
        try:
            connection.send_packed_command(
                connection.pack_commands([c.args for c in commands])
            )
        except (ConnectionError, TimeoutError) as e:
            for c in commands:
                c.result = e

    def read(self):
        """""" """"""
        connection = self.connection
        for c in self.commands:
            # if there is a result on this command,
            # it means we ran into an exception
            # like a connection error. Trying to parse
            # a response on a connection that
            # is no longer open will result in a
            # connection error raised by redis-py.
            # but redis-py doesn't check in parse_response
            # that the sock object is
            # still set and if you try to
            # read from a closed connection, it will
            # result in an AttributeError because
            # it will do a readline() call on None.
            # This can have all kinds of nasty side-effects.
            # Treating this case as a connection error
            # is fine because it will dump
            # the connection object back into the
            # pool and on the next write, it will
            # explicitly open the connection and all will be well.
            if c.result is None:
                try:
                    c.result = self.parse_response(connection, c.args[0], **c.options)
                except (ConnectionError, TimeoutError) as e:
                    for c in self.commands:
                        c.result = e
                    return
                except RedisError:
                    c.result = sys.exc_info()[1]","class NodeCommands:
    ''' '''

    def __init__(self, parse_response, connection_pool, connection):
    ''' '''
        pass

    def append(self, c):
    ''' '''
        pass

    def write(self):
    '''
        Code borrowed from Redis so it can be fixed
        '''
        pass

    def read(self):
    ''' '''
        pass

",5,5,snippet_322,0.4090909090909091,"class NodeCommands:
    '''Node-level command pipeline for Redis-like connections'''

    def __init__(self, parse_response, connection_pool, connection=None):
        self.parse_response = parse_response
        self.connection_pool = connection_pool
        self.connection = connection
        self._commands = []
        self._pending_count = 0

    def append(self, c):
        self._commands.append(c)

    def write(self):
        if not self.connection:
            self.connection = self.connection_pool.get_connection()
        try:
            self._pending_count = len(self._commands)
            for cmd in self._commands:
                # each cmd is expected to be bytes or bytearray
                self.connection.sendall(cmd)
        except Exception:
            try:
                self.connection.disconnect()
            except Exception:
                pass
            self.connection = None
            raise
        finally:
            self._commands = []

    def read(self):
        if not self.connection:
            raise RuntimeError(""No connection available for reading"")
        results = []
        try:
            for _ in range(self._pending_count):
                results.append(self.parse_response(self.connection))
            return results
        finally:
            self._pending_count = 0
            try:
                self.connection_pool.release(self.connection)
            except Exception:
                pass
            self.connection = None","class NodeCommands:
    ''' '''

    def __init__(self, parse_response, connection_pool, connection):
        ''' '''
        self.parse_response = parse_response
        self.connection_pool = connection_pool
        self.connection = connection
        self.commands = []

    def append(self, c):
        ''' '''
        self.commands.append(c)

    def write(self):
        '''
        Code borrowed from Redis so it can be fixed
        '''
        if not self.commands:
            return
        
        # Get a connection from the pool if we don't have one
        connection = self.connection or self.connection_pool.get_connection()
        
        try:
            # Write all commands to the connection
            for command in self.commands:
                connection.send_command(*command)
        except Exception:
            # If there's an error, make sure to release the connection
            if not self.connection:
                self.connection_pool.release(connection)
            raise
        
        # If we're using a connection from the pool, release it
        if not self.connection:
            self.connection_pool.release(connection)

    def read(self):
        ''' '''
        if not self.commands:
            return []
        
        results = []
        # Get a connection from the pool if we don't have one
        connection = self.connection or self.connection_pool.get_connection()
        
        try:
            # Read responses for all commands
            for _ in self.commands:
                response = connection.read_response()
                if self.parse_response:
                    response = self.parse_response(response)
                results.append(response)
        finally:
            # If we're using a connection from the pool, release it
            if not self.connection:
                self.connection_pool.release(connection)
        
        return results","class NodeCommands:
    ''' '''

    def __init__(self, parse_response, connection_pool, connection):
        ''' '''
        self.parse_response = parse_response
        self.connection_pool = connection_pool
        self.connection = connection
        self.commands = []

    def append(self, c):
        ''' '''
        self.commands.append(c)

    def write(self):
        '''
        Code borrowed from Redis so it can be fixed
        '''
        if not self.commands:
            return
        
        if self.connection is None:
            self.connection = self.connection_pool.get_connection()
        
        try:
            for command in self.commands:
                self.connection.send_command(*command)
        except Exception as e:
            self.connection.disconnect()
            raise e

    def read(self):
        ''' '''
        if not self.commands:
            return []
        
        responses = []
        try:
            for _ in self.commands:
                response = self.connection.read_response()
                if self.parse_response:
                    response = self.parse_response(response)
                responses.append(response)
        except Exception as e:
            self.connection.disconnect()
            raise e
        finally:
            self.commands.clear()
            if self.connection:
                self.connection_pool.release(self.connection)
        
        return responses",full_docstr,0.3973799126637555,0.206140350877193,0.15418502202643172,0.296943231441048,0.20526592672553237,0.7096774193548387,0.381294964028777,0.27075812274368233,0.8378857970237732,0.757352352142334,0.7955862283706665,0.7647022604942322,0.7809545714285714,0.4796905222437138,0.2757281553398058,0.1949317738791423,0.33268858800773693,0.2902753195861512,0.6871345029239766,0.39296187683284456,0.29705882352941176,0.8626347780227661,0.7850431203842163,0.8220120072364807,0.7921684980392456,0.8116549999999999,0.45393258426966293,0.29345372460496616,0.23129251700680273,0.36404494382022473,0.2362234962122225,0.789272030651341,0.5076923076923077,0.39768339768339767,0.8952633142471313,0.7576513290405273,0.8207289576530457,0.7694790363311768,0.812246775510204,0.2428099331590246,0.0254037916473954,0.0610245240671944,0.4403669724770642,0.4444444444444444,0.3172314233012427,0.1050513071094225,0.1280832432707663,0.4678899082568807,0.5679012345679012,0.3232507059227333,0.0481535822021931,0.1166354007366731,0.4862385321100917,0.6419753086419753
199441,SuperCowPowers/bat,SuperCowPowers_bat/zat/log_to_sparkdf.py,zat.log_to_sparkdf.LogToSparkDF,"class LogToSparkDF(object):
    """"""LogToSparkDF: Converts a Zeek log to a Spark DataFrame""""""

    def __init__(self, spark):
        """"""Initialize the LogToSparkDF class""""""

        # Grab the spark context
        self.spark = spark

        # First Level Type Mapping
        #    This map defines the types used when first reading in the Zeek log into a 'chunk' dataframes.
        #    Types (like time and interval) will be defined as one type at first but then
        #    will undergo further processing to produce correct types with correct values.
        # See: https://spark.apache.org/docs/latest/sql-reference.html
        #      for more info on supported types.
        self.type_map = {'bool': StringType(),   # Secondary Processing into BooleanType()
                         'count': LongType(),
                         'int': IntegerType(),
                         'double': FloatType(),
                         'time': DoubleType(),    # Secondary Processing into TimestampType()
                         'interval': FloatType(),
                         'port': IntegerType(),
                         'enum': StringType(),
                         'addr': StringType(),
                         'string': StringType()
                         }

    def create_dataframe(self, log_filename, fillna=True):
        """""" Create a Spark dataframe from a Bro/Zeek log file
            Args:
               log_fllename (string): The full path to the Zeek log
               fillna (bool): Fill in NA/NaN values (default=True)
        """"""

        # Create a Zeek log reader just to read in the header for names and types
        _zeek_reader = zeek_log_reader.ZeekLogReader(log_filename)
        _, field_names, field_types, _ = _zeek_reader._parse_zeek_header(log_filename)

        # Get the appropriate types for the Spark Dataframe
        spark_schema = self.build_spark_schema(field_names, field_types)

        # Now actually read the Zeek Log using Spark read CSV
        _df = self.spark.read.csv(log_filename, schema=spark_schema, sep='\t', comment=""#"", nullValue='-')

        ''' Secondary processing (cleanup)
            - Fix column names with '.' in them
            - Fill in Nulls (optional)
            - timestamp convert
            - boolean convert
        '''

        # Fix column names
        ''' Note: Yes column names with '.' in them can be escaped with backticks when selecting them BUT
                  many pipeline operations will FAIL internally if the column names have a '.' in them.
        '''
        fixed_columns = list(map(lambda x: x.replace('.', '_'), _df.columns))
        _df = _df.toDF(*fixed_columns)

        # Fill in NULL values
        if fillna:
            _df = _df.na.fill(0)    # For numeric columns
            _df = _df.na.fill('-')  # For string columns

        # Convert timestamp and boolean columns
        for name, f_type in zip(field_names, field_types):
            # Some field names may have '.' in them, so we create a reference name to those fields
            ref_name = name.replace('.', '_')
            if f_type == 'time':
                _df = _df.withColumn(name, _df[ref_name].cast('timestamp'))
            if f_type == 'bool':
                _df = _df.withColumn(name, when(col(ref_name) == 'T', 'true').when(col(ref_name) == 'F', 'false')
                                     .otherwise('null').cast('boolean'))

        # Return the spark dataframe
        return _df

    def build_spark_schema(self, column_names, column_types, verbose=False):
        """"""Given a set of names and types, construct a dictionary to be used
           as the Spark read_csv dtypes argument""""""

        # If we don't know the type put it into a string
        unknown_type = StringType()

        schema = StructType()
        for name, zeek_type in zip(column_names, column_types):

            # Grab the type
            spark_type = self.type_map.get(zeek_type)

            # Sanity Check
            if not spark_type:
                if verbose:
                    print('Could not find type for {:s} using StringType...'.format(zeek_type))
                spark_type = unknown_type

            # Add the Spark type for this column
            schema.add(name, spark_type)

        # Return the Spark schema
        return schema","class LogToSparkDF(object):
    '''LogToSparkDF: Converts a Zeek log to a Spark DataFrame'''

    def __init__(self, spark):
    '''Initialize the LogToSparkDF class'''
        pass

    def create_dataframe(self, log_filename, fillna=True):
    ''' Create a Spark dataframe from a Bro/Zeek log file
            Args:
               log_fllename (string): The full path to the Zeek log
               fillna (bool): Fill in NA/NaN values (default=True)
        '''
        pass

    def build_spark_schema(self, column_names, column_types, verbose=False):
    '''Given a set of names and types, construct a dictionary to be used
           as the Spark read_csv dtypes argument'''
        pass

",4,4,snippet_259,0.1666666666666666,"class LogToSparkDF(object):
    '''LogToSparkDF: Converts a Zeek log to a Spark DataFrame'''
    def __init__(self, spark):
        '''Initialize the LogToSparkDF class'''
        self.spark = spark

    def create_dataframe(self, log_filename, fillna=True):
        ''' Create a Spark dataframe from a Bro/Zeek log file
            Args:
               log_filename (string): The full path to the Zeek log
               fillna (bool): Fill in NA/NaN values (default=True)
        '''
        sep = None
        empty_field = None
        unset_field = None
        fields = []
        types = []
        with open(log_filename, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.startswith('#'):
                    break
                parts = line.rstrip('\n').split(' ', 1)
                tag = parts[0]
                if len(parts) > 1:
                    val = parts[1]
                else:
                    continue
                if tag == '#separator':
                    sep = val.encode('utf-8').decode('unicode_escape')
                elif tag == '#empty_field':
                    empty_field = val
                elif tag == '#unset_field':
                    unset_field = val
                elif tag == '#fields':
                    fields = val.split(sep)
                elif tag == '#types':
                    types = val.split(sep)
        if sep is None:
            sep = '\t'
        if unset_field is None:
            unset_field = '-'
        schema = self.build_spark_schema(fields, types)
        df = (
            self.spark.read
                .options(header=False, sep=sep, comment='#', nullValue=unset_field)
                .schema(schema)
                .csv(log_filename)
                .toDF(*fields)
        )
        if fillna:
            fill_map = {}
            for name, t in zip(fields, types):
                tl = t.lower()
                if tl in ('count', 'int', 'uint', 'port'):
                    fill_map[name] = 0
                elif tl == 'double' or tl == 'interval':
                    fill_map[name] = 0.0
                elif tl == 'bool':
                    fill_map[name] = False
                else:
                    fill_map[name] = ''  # strings and others
            df = df.fillna(fill_map)
        return df

    def build_spark_schema(self, column_names, column_types, verbose=False):
        '''Given a set of names and types, construct a Spark StructType schema'''
        mapping = {
            'string': StringType(),
            'enum': StringType(),
            'sub': StringType(),
            'file': StringType(),
            'pattern': StringType(),
            'addr': StringType(),
            'bool': BooleanType(),
            'count': LongType(),
            'int': LongType(),
            'uint': LongType(),
            'port': LongType(),
            'double': DoubleType(),
            'time': TimestampType(),
            'interval': DoubleType()
        }
        fields = []
        for name, t in zip(column_names, column_types):
            spark_type = mapping.get(t.lower(), StringType())
            fields.append(StructField(name, spark_type, nullable=True))
            if verbose and t.lower() not in mapping:
                print(f""Type '{t}' not in mapping, defaulting to StringType for column '{name}'"")
        return StructType(fields)","class LogToSparkDF(object):
    '''LogToSparkDF: Converts a Zeek log to a Spark DataFrame'''

    def __init__(self, spark):
        '''Initialize the LogToSparkDF class'''
        self.spark = spark

    def create_dataframe(self, log_filename, fillna=True):
        ''' Create a Spark dataframe from a Bro/Zeek log file
            Args:
               log_filename (string): The full path to the Zeek log
               fillna (bool): Fill in NA/NaN values (default=True)
        '''
        # Read the log file to get column names and types
        with open(log_filename, 'r') as f:
            lines = f.readlines()
        
        # Find the header lines
        fields_line = None
        types_line = None
        
        for line in lines:
            if line.startswith('#fields'):
                fields_line = line.strip()
            elif line.startswith('#types'):
                types_line = line.strip()
            if fields_line and types_line:
                break
        
        if not fields_line or not types_line:
            raise ValueError(""Could not find #fields and #types lines in log file"")
        
        # Extract column names and types
        column_names = fields_line.split('\t')[1:]  # Skip '#fields'
        column_types = types_line.split('\t')[1:]   # Skip '#types'
        
        # Build Spark schema
        schema_dict = self.build_spark_schema(column_names, column_types)
        
        # Read the actual data (skip comment lines)
        data_lines = []
        for line in lines:
            if not line.startswith('#'):
                data_lines.append(line.strip())
        
        # Create RDD from data lines
        rdd = self.spark.sparkContext.parallelize(data_lines)
        rdd = rdd.map(lambda line: line.split('\t'))
        
        # Create DataFrame
        df = self.spark.createDataFrame(rdd, list(schema_dict.keys()))
        
        # Fill NA/NaN values if requested
        if fillna:
            df = df.fillna('')
        
        return df

    def build_spark_schema(self, column_names, column_types, verbose=False):
        '''Given a set of names and types, construct a dictionary to be used
           as the Spark read_csv dtypes argument'''
        # Mapping from Zeek types to Spark types
        type_mapping = {
            'bool': 'boolean',
            'count': 'integer',
            'int': 'integer',
            'double': 'double',
            'time': 'double',
            'interval': 'double',
            'string': 'string',
            'addr': 'string',
            'port': 'integer',
            'subnet': 'string',
            'enum': 'string',
            'function': 'string',
            'record': 'string',
            'vector': 'string',
            'set': 'string',
            'table': 'string'
        }
        
        schema_dict = {}
        for i, (name, zeek_type) in enumerate(zip(column_names, column_types)):
            # Handle complex types (vectors, sets, etc.) by treating as string
            spark_type = type_mapping.get(zeek_type, 'string')
            schema_dict[name] = spark_type
            
            if verbose:
                print(f""Column '{name}': Zeek type '{zeek_type}' -> Spark type '{spark_type}'"")
        
        return schema_dict","class LogToSparkDF(object):
    '''LogToSparkDF: Converts a Zeek log to a Spark DataFrame'''

    def __init__(self, spark):
        '''Initialize the LogToSparkDF class'''
        self.spark = spark

    def create_dataframe(self, log_filename, fillna=True):
        ''' Create a Spark dataframe from a Bro/Zeek log file
            Args:
               log_filename (string): The full path to the Zeek log
               fillna (bool): Fill in NA/NaN values (default=True)
        '''
        # Read the log file to extract header information
        with open(log_filename, 'r') as f:
            lines = f.readlines()
        
        # Parse header lines to get column names and types
        column_names = None
        column_types = None
        separator = '\t'
        
        for line in lines:
            if line.startswith('#fields'):
                column_names = line.strip().split('\t')[1:]
            elif line.startswith('#types'):
                column_types = line.strip().split('\t')[1:]
            elif line.startswith('#separator'):
                separator = line.strip().split(' ')[1]
                if separator == '\\x09':
                    separator = '\t'
            elif not line.startswith('#'):
                break
        
        # Build Spark schema
        schema = self.build_spark_schema(column_names, column_types)
        
        # Read the CSV data
        df = self.spark.read.csv(
            log_filename,
            sep=separator,
            header=False,
            schema=schema,
            comment='#'
        )
        
        # Fill NA values if requested
        if fillna:
            # Replace '-' with None/null values
            for col_name in df.columns:
                df = df.withColumn(col_name, 
                    when(col(col_name) == '-', None).otherwise(col(col_name)))
            
            # Fill null values based on column type
            for field in df.schema.fields:
                if isinstance(field.dataType, StringType):
                    df = df.fillna('', subset=[field.name])
                elif isinstance(field.dataType, (IntegerType, LongType, DoubleType, FloatType)):
                    df = df.fillna(0, subset=[field.name])
                elif isinstance(field.dataType, BooleanType):
                    df = df.fillna(False, subset=[field.name])
        
        return df

    def build_spark_schema(self, column_names, column_types, verbose=False):
        '''Given a set of names and types, construct a dictionary to be used
           as the Spark read_csv dtypes argument'''
        
        # Mapping from Zeek types to Spark types
        type_mapping = {
            'bool': BooleanType(),
            'count': LongType(),
            'int': IntegerType(),
            'double': DoubleType(),
            'time': DoubleType(),
            'interval': DoubleType(),
            'string': StringType(),
            'addr': StringType(),
            'port': IntegerType(),
            'enum': StringType(),
            'set': StringType(),
            'vector': StringType(),
            'subnet': StringType()
        }
        
        fields = []
        for name, zeek_type in zip(column_names, column_types):
            # Handle vector types like vector[string]
            if zeek_type.startswith('vector[') or zeek_type.startswith('set['):
                spark_type = StringType()
            else:
                spark_type = type_mapping.get(zeek_type, StringType())
            
            fields.append(StructField(name, spark_type, True))
            
            if verbose:
                print(f""Column: {name}, Zeek Type: {zeek_type}, Spark Type: {spark_type}"")
        
        return StructType(fields)",full_docstr,0.4935672514619883,0.27432590855803046,0.20211515863689777,0.3345029239766082,0.31344114541999624,0.7056277056277056,0.3959537572254335,0.29232995658465993,0.8445156812667847,0.8209207057952881,0.8325510621070862,0.8232206702232361,0.7446606730769245,0.5251141552511416,0.3112128146453089,0.23853211009174313,0.363013698630137,0.2886015003889706,0.7315233785822021,0.38972809667673713,0.26777609682299547,0.8548377752304077,0.8260902166366577,0.840218186378479,0.8288776874542236,0.7270982456140354,0.6256983240223464,0.35610302351623746,0.26487093153759816,0.4022346368715084,0.3961782405261455,0.7585301837270341,0.45729303547963207,0.33157894736842103,0.8669523596763611,0.8437857627868652,0.8552122116088867,0.8460465669631958,0.7553335353535358,0.302356435321697,0.1156649226975078,0.1368131083664608,0.5851528384279476,0.3717948717948718,0.2637860568523872,0.1413873818860239,0.163252982574247,0.4235807860262008,0.3269230769230769,0.3089189211521315,0.1647553717749319,0.187088715028197,0.5633187772925764,0.3205128205128205
135535,JdeRobot/base,src/libs/comm_py/comm/ice/sonarIceClient.py,comm.ice.sonarIceClient.Sonar,"class Sonar:
    '''
        Sonar Connector. Recives LaserData from Ice interface when you run update method.
    '''

    def __init__(self, jdrc, prefix):
        '''
        Laser Contructor.
        Exits When it receives a Exception diferent to Ice.ConnectionRefusedException

        @param jdrc: Comm Communicator
        @param prefix: prefix name of client in config file

        @type ic: Ice Communicator
        @type prefix: String
        '''
        self.lock = threading.Lock()
        self.sonar = SonarData()

        try:
            ic = jdrc.getIc()
            proxyStr = jdrc.getConfig().getProperty(prefix+"".Proxy"")
            base = ic.stringToProxy(proxyStr)
            self.proxy = jderobot.SonarPrx.checkedCast(base)

            self.update()

            if not self.proxy:
                print ('Interface ' + prefix + ' not configured')

        except Ice.ConnectionRefusedException:
            print(prefix + ': connection refused')

        except:
            traceback.print_exc()
            exit(-1)

    def update(self):
        '''
        Updates LaserData.
        '''
        if self.hasproxy():
            sonarD = SonarData()
            range = 0
            data = self.proxy.getSonarData()

            sonarD.range = data.range
            sonarD.maxAngle = data.maxAngle
            sonarD.minAngle = data.minAngle
            sonarD.maxRange = data.maxRange
            sonarD.minRange = data.minRange


            self.lock.acquire()
            self.sonar = sonarD
            self.lock.release()

    def hasproxy (self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''

        return hasattr(self,""proxy"") and self.proxy

    def getSonarData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''     
        if self.hasproxy():
            self.lock.acquire()
            sonar = self.sonar
            self.lock.release()
            return sonar

        return None","class Sonar:
    '''
        Sonar Connector. Recives LaserData from Ice interface when you run update method.
    '''

    def __init__(self, jdrc, prefix):
    '''
        Laser Contructor.
        Exits When it receives a Exception diferent to Ice.ConnectionRefusedException

        @param jdrc: Comm Communicator
        @param prefix: prefix name of client in config file

        @type ic: Ice Communicator
        @type prefix: String
        '''
        pass

    def update(self):
    '''
        Updates LaserData.
        '''
        pass

    def hasproxy (self):
    '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        pass

    def getSonarData(self):
    '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        pass

",5,5,snippet_163,0.1666666666666666,"class Sonar:
    '''
        Sonar Connector. Receives LaserData from Ice interface when you run update method.
    '''

    def __init__(self, jdrc, prefix):
        '''
            Laser Constructor.
            Exits when it receives an exception different from Ice.ConnectionRefusedException

            @param jdrc: Ice Communicator
            @param prefix: prefix name of client in config file
        '''
        self._data = None
        try:
            props = jdrc.getProperties()
            proxy_str = props.getProperty(prefix + "".Proxy"")
            base = jdrc.stringToProxy(proxy_str)
            self._proxy = JdeRobot.SonarPrx.ice_checkedCast(base)
        except Ice.ConnectionRefusedException:
            self._proxy = None
        except Exception:
            sys.exit(1)

    def update(self):
        '''
            Updates LaserData.
        '''
        if not self.hasproxy():
            return
        try:
            self._data = self._proxy.getLaserData()
        except Exception:
            self._data = None

    def hasproxy(self):
        '''
            Returns if proxy has been created or not.
            @return Boolean
        '''
        return self._proxy is not None

    def getSonarData(self):
        '''
            Returns last LaserData.
            @return JdeRobotTypes.LaserData
        '''
        return self._data","class Sonar:
    '''
        Sonar Connector. Recives LaserData from Ice interface when you run update method.
    '''

    def __init__(self, jdrc, prefix):
        '''
        Laser Contructor.
        Exits When it receives a Exception diferent to Ice.ConnectionRefusedException

        @param jdrc: Comm Communicator
        @param prefix: prefix name of client in config file

        @type ic: Ice Communicator
        @type prefix: String
        '''
        self.jdrc = jdrc
        self.prefix = prefix
        self.proxy = None
        self.sonarData = None
        self.hasproxyflag = False
        
        try:
            self.proxy = self.jdrc.getProxy(self.prefix)
            if self.proxy:
                self.hasproxyflag = True
        except Ice.ConnectionRefusedException:
            pass
        except Exception as e:
            exit()

    def update(self):
        '''
        Updates LaserData.
        '''
        if self.hasproxy() and self.proxy:
            try:
                self.sonarData = self.proxy.getLaserData()
            except Ice.ConnectionRefusedException:
                pass
            except Exception as e:
                exit()

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.hasproxyflag

    def getSonarData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        return self.sonarData","class Sonar:
    '''
        Sonar Connector. Recives LaserData from Ice interface when you run update method.
    '''

    def __init__(self, jdrc, prefix):
        '''
        Laser Contructor.
        Exits When it receives a Exception diferent to Ice.ConnectionRefusedException

        @param jdrc: Comm Communicator
        @param prefix: prefix name of client in config file

        @type ic: Ice Communicator
        @type prefix: String
        '''
        self.lock = threading.Lock()
        self.sonarData = jderobot.LaserData()
        self.proxy = None
        
        try:
            base = jdrc.getIceComm().stringToProxy(jdrc.getConfig().getProperty(prefix + "".Proxy""))
            self.proxy = jderobot.LaserPrx.checkedCast(base)
            if not self.proxy:
                raise Exception(""Invalid proxy"")
        except Ice.ConnectionRefusedException:
            print(prefix + "": connection refused"")
        except Exception as e:
            print(prefix + "": "" + str(e))
            exit(-1)

    def update(self):
        '''
        Updates LaserData.
        '''
        if self.hasproxy():
            try:
                self.lock.acquire()
                self.sonarData = self.proxy.getLaserData()
                self.lock.release()
            except Ice.Exception:
                self.lock.release()

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.proxy is not None

    def getSonarData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        self.lock.acquire()
        sonarData = self.sonarData
        self.lock.release()
        return sonarData",full_docstr,0.6606606606606605,0.44108761329305135,0.31610942249240126,0.5705705705705706,0.3645676812132048,0.8516949152542372,0.6297872340425532,0.48717948717948717,0.9190114140510559,0.8484108448028564,0.8823010921478271,0.8549789786338806,0.8107545806451613,0.725212464589235,0.5527065527065527,0.492836676217765,0.6402266288951842,0.45959507684663753,0.8906882591093117,0.7439024390243902,0.6408163265306123,0.9165789484977722,0.8464698791503906,0.880130410194397,0.852994441986084,0.8075288064516128,0.8042328042328042,0.6648936170212766,0.5882352941176471,0.7513227513227513,0.6839460484890872,0.8950617283950617,0.7801857585139319,0.6894409937888198,0.9340862035751343,0.8996800184249878,0.9165603518486023,0.9030062556266785,0.8612917096774193,0.3137986042119171,0.2556043973465156,0.2920188812897707,0.5304878048780488,0.1770833333333333,0.4199265811805441,0.4923981360524773,0.5191171317591299,0.4390243902439024,0.2291666666666666,0.5602304116206077,0.553147537078889,0.5701419955824037,0.6280487804878049,0.4895833333333333
237878,apache/airflow,apache_airflow/airflow/models/crypto.py,airflow.models.crypto.NullFernet,"class NullFernet:
    """"""
    A ""Null"" encryptor class that doesn't encrypt or decrypt but that presents a similar interface to Fernet.

    The purpose of this is to make the rest of the code not have to know the
    difference, and to only display the message once, not 20 times when
    `airflow db migrate` is run.
    """"""

    is_encrypted = False

    def decrypt(self, b):
        """"""Decrypt with Fernet.""""""
        return b

    def encrypt(self, b):
        """"""Encrypt with Fernet.""""""
        return b","class NullFernet:
    '''
    A ""Null"" encryptor class that doesn't encrypt or decrypt but that presents a similar interface to Fernet.

    The purpose of this is to make the rest of the code not have to know the
    difference, and to only display the message once, not 20 times when
    `airflow db migrate` is run.
    '''

    def decrypt(self, b):
    '''Decrypt with Fernet.'''
        pass

    def encrypt(self, b):
    '''Encrypt with Fernet.'''
        pass

",3,3,snippet_341,1.0,"class NullFernet:
    '''
    A ""Null"" encryptor class that doesn't encrypt or decrypt but that presents a similar interface to Fernet.

    The purpose of this is to make the rest of the code not have to know the
    difference, and to only display the message once, not 20 times when
    `airflow db migrate` is run.
    '''

    def decrypt(self, b):
        '''Decrypt with Fernet.'''
        return b

    def encrypt(self, b):
        '''Encrypt with Fernet.'''
        return b","class NullFernet:
    '''
    A ""Null"" encryptor class that doesn't encrypt or decrypt but that presents a similar interface to Fernet.

    The purpose of this is to make the rest of the code not have to know the
    difference, and to only display the message once, not 20 times when
    `airflow db migrate` is run.
    '''

    def decrypt(self, b):
        '''Decrypt with Fernet.'''
        return b

    def encrypt(self, b):
        '''Encrypt with Fernet.'''
        return b","class NullFernet:
    '''
    A ""Null"" encryptor class that doesn't encrypt or decrypt but that presents a similar interface to Fernet.

    The purpose of this is to make the rest of the code not have to know the
    difference, and to only display the message once, not 20 times when
    `airflow db migrate` is run.
    '''

    def decrypt(self, b):
        '''Decrypt with Fernet.'''
        return b

    def encrypt(self, b):
        '''Encrypt with Fernet.'''
        return b",full_docstr,0.9795918367346939,0.9655172413793103,0.9510489510489512,0.9795918367346939,0.7109853375115478,0.9368421052631579,0.8723404255319149,0.8064516129032258,0.9969534277915955,0.9854587316513062,0.9911727905273438,0.9865962266921997,0.9658123076923076,0.9795918367346939,0.9655172413793103,0.9510489510489512,0.9795918367346939,0.7109853375115478,0.9368421052631579,0.8723404255319149,0.8064516129032258,0.9969534277915955,0.9854587316513062,0.9911727905273438,0.9865962266921997,0.9658123076923076,0.9795918367346939,0.9655172413793103,0.9510489510489512,0.9795918367346939,0.7109853375115478,0.9368421052631579,0.8723404255319149,0.8064516129032258,0.9969534277915955,0.9854587316513062,0.9911727905273438,0.9865962266921997,0.9658123076923076,0.5742188316674143,0.7755641697569221,0.7809265415281195,0.6153846153846154,0.125,0.5742188316674143,0.7755641697569221,0.7809265415281195,0.6153846153846154,0.125,0.5742188316674143,0.7755641697569221,0.7809265415281195,0.6153846153846154,0.125
125565,GoogleCloudPlatform/compute-image-packages,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/GoogleCloudPlatform_compute-image-packages/packages/python-google-compute-engine/google_compute_engine/metadata_scripts/script_executor.py,google_compute_engine.metadata_scripts.script_executor.ScriptExecutor,"class ScriptExecutor(object):
    """"""A class for executing user provided metadata scripts.""""""

    def __init__(self, logger, script_type, default_shell=None):
        """"""Constructor.

        Args:
          logger: logger object, used to write to SysLog and serial port.
          script_type: string, the type of the script we are running.
          default_shell: string, the default shell to execute the script.
        """"""
        self.logger = logger
        self.script_type = script_type
        self.default_shell = default_shell or '/bin/bash'

    def _MakeExecutable(self, metadata_script):
        """"""Add executable permissions to a file.

        Args:
          metadata_script: string, the path to the executable file.
        """"""
        mode = os.stat(metadata_script).st_mode
        os.chmod(metadata_script, mode | stat.S_IEXEC)

    def _RunScript(self, metadata_key, metadata_script):
        """"""Run a script and log the streamed script output.

        Args:
          metadata_key: string, the key specifing the metadata script.
          metadata_script: string, the file location of an executable script.
        """"""
        process = subprocess.Popen(
            metadata_script, shell=True,
            executable=self.default_shell,
            stderr=subprocess.STDOUT, stdout=subprocess.PIPE)
        while True:
            for line in iter(process.stdout.readline, b''):
                message = line.decode('utf-8', 'replace').rstrip('\n')
                if message:
                    self.logger.info('%s: %s', metadata_key, message)
            if process.poll() is not None:
                break
        self.logger.info('%s: Return code %s.',
                         metadata_key, process.returncode)

    def RunScripts(self, script_dict):
        """"""Run the metadata scripts; execute a URL script first if one is provided.

        Args:
          script_dict: a dictionary mapping metadata keys to script files.
        """"""
        metadata_types = ['%s-script-url', '%s-script']
        metadata_keys = [key % self.script_type for key in metadata_types]
        metadata_keys = [key for key in metadata_keys if script_dict.get(key)]
        if not metadata_keys:
            self.logger.info(
                'No %s scripts found in metadata.', self.script_type)
        for metadata_key in metadata_keys:
            metadata_script = script_dict.get(metadata_key)
            self._MakeExecutable(metadata_script)
            self._RunScript(metadata_key, metadata_script)","class ScriptExecutor(object):
    '''A class for executing user provided metadata scripts.'''


    def __init__(self, logger, script_type, default_shell=None):
    '''Constructor.

        Args:
          logger: logger object, used to write to SysLog and serial port.
          script_type: string, the type of the script we are running.
          default_shell: string, the default shell to execute the script.
        '''
                    pass


    def _MakeExecutable(self, metadata_script):
    '''Add executable permissions to a file.

        Args:
          metadata_script: string, the path to the executable file.
        '''
        pass


    def _RunScript(self, metadata_key, metadata_script):
    '''Run a script and log the streamed script output.

        Args:
          metadata_key: string, the key specifing the metadata script.
          metadata_script: string, the file location of an executable script.
        '''
        pass


    def RunScripts(self, script_dict):
    '''Run the metadata scripts; execute a URL script first if one is provided.

        Args:
          script_dict: a dictionary mapping metadata keys to script files.
        '''
        pass

",5,5,snippet_137,0.4761904761904761,"class ScriptExecutor(object):
    '''A class for executing user provided metadata scripts.'''

    def __init__(self, logger, script_type, default_shell=None):
        '''Constructor.

        Args:
          logger: logger object, used to write to SysLog and serial port.
          script_type: string, the type of the script we are running.
          default_shell: string, the default shell to execute the script.
        '''
        self.logger = logger
        self.script_type = script_type
        self.default_shell = default_shell

    def _MakeExecutable(self, metadata_script):
        '''Add executable permissions to a file.

        Args:
          metadata_script: string, the path to the executable file.
        '''
        try:
            st = os.stat(metadata_script)
            os.chmod(metadata_script, st.st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)
            self.logger.info(
                'ScriptExecutor(%s): Made %s executable',
                self.script_type, metadata_script)
        except Exception as e:
            self.logger.error(
                'ScriptExecutor(%s): Failed to make %s executable: %s',
                self.script_type, metadata_script, e)

    def _RunScript(self, metadata_key, metadata_script):
        '''Run a script and log the streamed script output.

        Args:
          metadata_key: string, the key specifying the metadata script.
          metadata_script: string, the file location of an executable script.
        '''
        cmd = [metadata_script]
        if self.default_shell:
            cmd = [self.default_shell, metadata_script]
        self.logger.info(
            'ScriptExecutor(%s): Running script %s (%s)',
            self.script_type, metadata_key, metadata_script)
        try:
            proc = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                bufsize=1,
                universal_newlines=True)
            for line in proc.stdout:
                self.logger.info(
                    'ScriptExecutor(%s)[%s]: %s',
                    self.script_type, metadata_key, line.rstrip('\n'))
            proc.wait()
            if proc.returncode != 0:
                self.logger.error(
                    'ScriptExecutor(%s): Script %s exited with code %d',
                    self.script_type, metadata_key, proc.returncode)
            else:
                self.logger.info(
                    'ScriptExecutor(%s): Script %s completed successfully',
                    self.script_type, metadata_key)
        except Exception as e:
            self.logger.error(
                'ScriptExecutor(%s): Error running script %s: %s',
                self.script_type, metadata_key, e)

    def RunScripts(self, script_dict):
        '''Run the metadata scripts; execute a URL script first if one is provided.

        Args:
          script_dict: a dictionary mapping metadata keys to script files.
        '''
        # Identify URL scripts first
        url_keys = [k for k in script_dict if k.lower().endswith('-url')]
        other_keys = [k for k in script_dict if k not in url_keys]
        # Run URL scripts first
        for key in url_keys + other_keys:
            script_path = script_dict.get(key)
            if not script_path:
                continue
            if not os.path.exists(script_path):
                self.logger.error(
                    'ScriptExecutor(%s): Script file for %s not found: %s',
                    self.script_type, key, script_path)
                continue
            self._MakeExecutable(script_path)
            self._RunScript(key, script_path)","class ScriptExecutor(object):
    '''A class for executing user provided metadata scripts.'''

    def __init__(self, logger, script_type, default_shell=None):
        '''Constructor.

        Args:
          logger: logger object, used to write to SysLog and serial port.
          script_type: string, the type of the script we are running.
          default_shell: string, the default shell to execute the script.
        '''
        self.logger = logger
        self.script_type = script_type
        self.default_shell = default_shell or '/bin/bash'

    def _MakeExecutable(self, metadata_script):
        '''Add executable permissions to a file.

        Args:
          metadata_script: string, the path to the executable file.
        '''
        current_permissions = os.stat(metadata_script).st_mode
        os.chmod(metadata_script, current_permissions | stat.S_IEXEC)

    def _RunScript(self, metadata_key, metadata_script):
        '''Run a script and log the streamed script output.

        Args:
          metadata_key: string, the key specifing the metadata script.
          metadata_script: string, the file location of an executable script.
        '''
        self._MakeExecutable(metadata_script)
        
        try:
            process = subprocess.Popen(
                [self.default_shell, metadata_script],
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True
            )
            
            # Stream output line by line
            for line in process.stdout:
                line = line.rstrip('\n')
                self.logger.info(f'{self.script_type} {metadata_key}: {line}')
            
            process.wait()
            
            if process.returncode != 0:
                self.logger.error(
                    f'{self.script_type} {metadata_key} failed with return code {process.returncode}'
                )
            else:
                self.logger.info(f'{self.script_type} {metadata_key} succeeded')
                
        except Exception as e:
            self.logger.error(f'Error running {self.script_type} {metadata_key}: {str(e)}')

    def RunScripts(self, script_dict):
        '''Run the metadata scripts; execute a URL script first if one is provided.

        Args:
          script_dict: a dictionary mapping metadata keys to script files.
        '''
        if not script_dict:
            return

        # Check if any script is a URL (starts with http)
        url_scripts = {}
        file_scripts = {}
        
        for key, script in script_dict.items():
            if script.startswith(('http://', 'https://')):
                url_scripts[key] = script
            else:
                file_scripts[key] = script

        # Execute URL scripts first
        for key, url in url_scripts.items():
            try:
                # Download the script to a temporary file
                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.sh') as temp_file:
                    temp_filename = temp_file.name
                    with urllib.request.urlopen(url) as response:
                        script_content = response.read().decode('utf-8')
                        temp_file.write(script_content)
                
                # Run the downloaded script
                self._RunScript(key, temp_filename)
                
                # Clean up the temporary file
                os.unlink(temp_filename)
                
            except Exception as e:
                self.logger.error(f'Error downloading/executing URL script {key}: {str(e)}')

        # Execute file scripts
        for key, script_file in file_scripts.items():
            if os.path.exists(script_file):
                self._RunScript(key, script_file)
            else:
                self.logger.error(f'Script file {script_file} does not exist for key {key}')","class ScriptExecutor(object):
    '''A class for executing user provided metadata scripts.'''

    def __init__(self, logger, script_type, default_shell=None):
        '''Constructor.

        Args:
          logger: logger object, used to write to SysLog and serial port.
          script_type: string, the type of the script we are running.
          default_shell: string, the default shell to execute the script.
        '''
        self.logger = logger
        self.script_type = script_type
        self.default_shell = default_shell

    def _MakeExecutable(self, metadata_script):
        '''Add executable permissions to a file.

        Args:
          metadata_script: string, the path to the executable file.
        '''
        current_permissions = os.stat(metadata_script).st_mode
        os.chmod(metadata_script, current_permissions | stat.S_IEXEC)

    def _RunScript(self, metadata_key, metadata_script):
        '''Run a script and log the streamed script output.

        Args:
          metadata_key: string, the key specifing the metadata script.
          metadata_script: string, the file location of an executable script.
        '''
        self.logger.info('Running %s script found in metadata.', self.script_type)
        
        try:
            self._MakeExecutable(metadata_script)
            
            if self.default_shell:
                cmd = [self.default_shell, metadata_script]
            else:
                cmd = [metadata_script]
            
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True
            )
            
            for line in iter(process.stdout.readline, ''):
                self.logger.info(line.rstrip())
            
            process.wait()
            
            if process.returncode != 0:
                self.logger.warning('%s script %s failed with return code %d',
                                  self.script_type, metadata_key, process.returncode)
            else:
                self.logger.info('%s script %s completed successfully',
                               self.script_type, metadata_key)
                
        except Exception as e:
            self.logger.error('Error running %s script %s: %s',
                            self.script_type, metadata_key, str(e))

    def RunScripts(self, script_dict):
        '''Run the metadata scripts; execute a URL script first if one is provided.

        Args:
          script_dict: a dictionary mapping metadata keys to script files.
        '''
        if not script_dict:
            return
        
        # Execute URL script first if present
        if 'startup-script-url' in script_dict:
            self._RunScript('startup-script-url', script_dict['startup-script-url'])
            
        # Execute other scripts
        for metadata_key, script_file in script_dict.items():
            if metadata_key != 'startup-script-url':
                self._RunScript(metadata_key, script_file)",full_docstr,0.7282758620689656,0.5615491009681881,0.4604715672676838,0.6262068965517241,0.5078228327517093,0.6205533596837944,0.503957783641161,0.4187582562747688,0.8947180509567261,0.9135023951530457,0.9040126800537109,0.9115885496139526,0.816948273381295,0.6991869918699186,0.5625,0.47411444141689374,0.6016260162601627,0.4805767026199366,0.5941101152368758,0.46794871794871795,0.3992297817715019,0.8720489740371704,0.9311816096305847,0.9006457924842834,0.9249098896980286,0.8093352400000003,0.80625,0.677115987460815,0.5754716981132075,0.7,0.677525219149676,0.8017391304347826,0.6655052264808362,0.5828970331588132,0.9240566492080688,0.9304341673851013,0.9272344708442688,0.9297923445701599,0.8093800917431194,0.514334032728327,0.3738926483889914,0.524503967469694,0.5107913669064749,0.6481481481481481,0.5598502021270273,0.3899108031579429,0.5651175033517649,0.5899280575539568,0.6944444444444444,0.551085938899071,0.5040780623302826,0.5506520508466036,0.5755395683453237,0.5740740740740741
7894,AustralianSynchrotron/lightflow,AustralianSynchrotron_lightflow/lightflow/models/signal.py,lightflow.models.signal.Client,"class Client:
    """""" The client for the signal system, sending requests to the server.

    This implementation sends requests to a list stored in redis. Each request
    is implemented using the Request class and stored as a pickled object. The response
    from the server is stored under the unique response id.
    """"""
    def __init__(self, connection, request_key):
        """""" Initialises the signal client.

        Args:
            connection: Reference to a signal connection object.
            request_key (str): The key under which the list of requests is stored.
        """"""
        self._connection = connection
        self._request_key = '{}:{}'.format(SIGNAL_REDIS_PREFIX, request_key)

    def send(self, request):
        """""" Send a request to the server and wait for its response.

        Args:
            request (Request): Reference to a request object that is sent to the server.

        Returns:
            Response: The response from the server to the request.
        """"""
        self._connection.connection.rpush(self._request_key, pickle.dumps(request))
        resp_key = '{}:{}'.format(SIGNAL_REDIS_PREFIX, request.uid)

        while True:
            if self._connection.polling_time > 0.0:
                sleep(self._connection.polling_time)

            response_data = self._connection.connection.get(resp_key)
            if response_data is not None:
                self._connection.connection.delete(resp_key)
                break

        return pickle.loads(response_data)","class Client:
    ''' The client for the signal system, sending requests to the server.

    This implementation sends requests to a list stored in redis. Each request
    is implemented using the Request class and stored as a pickled object. The response
    from the server is stored under the unique response id.
    '''

    def __init__(self, connection, request_key):
    ''' Initialises the signal client.

        Args:
            connection: Reference to a signal connection object.
            request_key (str): The key under which the list of requests is stored.
        '''
        pass

    def send(self, request):
    ''' Send a request to the server and wait for its response.

        Args:
            request (Request): Reference to a request object that is sent to the server.

        Returns:
            Response: The response from the server to the request.
        '''
        pass

",3,3,snippet_27,0.4285714285714285,"class Client:
    ''' The client for the signal system, sending requests to the server.

    This implementation sends requests to a list stored in redis. Each request
    is implemented using the Request class and stored as a pickled object. The response
    from the server is stored under the unique response id.
    '''

    def __init__(self, connection, request_key):
        ''' Initialises the signal client.

        Args:
            connection: Reference to a signal connection object.
            request_key (str): The key under which the list of requests is stored.
        '''
        self.connection = connection
        self.request_key = request_key

    def send(self, request):
        ''' Send a request to the server and wait for its response.

        Args:
            request (Request): Reference to a request object that is sent to the server.

        Returns:
            Response: The response from the server to the request.
        '''
        # Serialize and enqueue the request
        payload = pickle.dumps(request)
        self.connection.rpush(self.request_key, payload)

        # Wait for the server to write the response under request.response_id
        response_key = request.response_id
        while not self.connection.exists(response_key):
            time.sleep(0.01)

        # Retrieve, deserialize, and clean up
        raw = self.connection.get(response_key)
        self.connection.delete(response_key)
        return pickle.loads(raw)","class Client:
    ''' The client for the signal system, sending requests to the server.

    This implementation sends requests to a list stored in redis. Each request
    is implemented using the Request class and stored as a pickled object. The response
    from the server is stored under the unique response id.
    '''

    def __init__(self, connection, request_key):
        ''' Initialises the signal client.

        Args:
            connection: Reference to a signal connection object.
            request_key (str): The key under which the list of requests is stored.
        '''
        self.connection = connection
        self.request_key = request_key

    def send(self, request):
        ''' Send a request to the server and wait for its response.

        Args:
            request (Request): Reference to a request object that is sent to the server.

        Returns:
            Response: The response from the server to the request.
        '''
        # Generate a unique response ID
        response_id = str(uuid.uuid4())
        request.response_id = response_id
        
        # Pickle the request object
        pickled_request = pickle.dumps(request)
        
        # Push the request to the Redis list
        self.connection.lpush(self.request_key, pickled_request)
        
        # Wait for the response
        response_key = f""response:{response_id}""
        pickled_response = self.connection.brpoplpush(response_key, response_key, timeout=30)
        
        # Unpickle and return the response
        response = pickle.loads(pickled_response)
        
        # Clean up the response key
        self.connection.delete(response_key)
        
        return response","class Client:
    ''' The client for the signal system, sending requests to the server.

    This implementation sends requests to a list stored in redis. Each request
    is implemented using the Request class and stored as a pickled object. The response
    from the server is stored under the unique response id.
    '''

    def __init__(self, connection, request_key):
        ''' Initialises the signal client.

        Args:
            connection: Reference to a signal connection object.
            request_key (str): The key under which the list of requests is stored.
        '''
        self.connection = connection
        self.request_key = request_key

    def send(self, request):
        ''' Send a request to the server and wait for its response.

        Args:
            request (Request): Reference to a request object that is sent to the server.

        Returns:
            Response: The response from the server to the request.
        '''
        pickled_request = pickle.dumps(request)
        self.connection.lpush(self.request_key, pickled_request)
        
        while True:
            response_data = self.connection.get(request.response_id)
            if response_data is not None:
                response = pickle.loads(response_data)
                self.connection.delete(request.response_id)
                return response
            time.sleep(0.01)",full_docstr,0.8368421052631579,0.7407407407407407,0.6861702127659575,0.7999999999999999,0.6252226089263163,0.8531468531468531,0.7263157894736842,0.6267605633802817,0.9376049041748047,0.9269390106201172,0.9322414398193359,0.9279946684837341,0.866668,0.7587939698492463,0.6767676767676768,0.6345177664974619,0.7336683417085428,0.6151324396722326,0.7617554858934169,0.6320754716981132,0.5362776025236593,0.9178846478462219,0.912516713142395,0.9151927828788757,0.9130507111549377,0.8229902758620689,0.8839779005524862,0.8111111111111111,0.7486033519553074,0.8342541436464088,0.6226788694833323,0.9233716475095786,0.8115384615384615,0.7142857142857143,0.9682153463363647,0.935045599937439,0.9513413906097412,0.938260018825531,0.8482773793103449,0.5666607314236616,0.6492856850177635,0.7154145949784556,0.391304347826087,0.5106382978723404,0.5374273697149002,0.5772837156754046,0.7062524668536381,0.3768115942028985,0.4893617021276595,0.6138170653180077,0.7421442822712054,0.7473515460683556,0.391304347826087,0.574468085106383
249742,astrorafael/twisted-mqtt,src/mqtt/client/interval.py,mqtt.client.interval.Interval,"class Interval(object):
    '''
    This class build automatically incrementing interval objects, 
    to be used in requests timeouts
    
    Use like:
    C{interval = Interval()}
    C{t = interval()}
    C{t = interval()}

    @ivar initial:  Initial interval value, in seconds.
    @ivar maxDelay: maximun interval value produced, in seconds.
    @ivar factor:   multiplier for the next interval.
    '''
   
    
    def __init__(self, initial=2, maxDelay=1024, factor=2):
        '''Initialize interval object'''
        self.initial  = initial
        self.factor   = factor
        self.maxDelay = max(initial, maxDelay)
        self._value   = self.initial


    def __call__(self):
        '''Call the interval to produce a new delay time'''
        self._value *= self.factor
        self._value = min(self._value, self.maxDelay)
        return self._value + random.random()","class Interval(object):
    '''
    This class build automatically incrementing interval objects, 
    to be used in requests timeouts
    
    Use like:
    C{interval = Interval()}
    C{t = interval()}
    C{t = interval()}

    @ivar initial:  Initial interval value, in seconds.
    @ivar maxDelay: maximun interval value produced, in seconds.
    @ivar factor:   multiplier for the next interval.
    '''

    def __init__(self, initial=2, maxDelay=1024, factor=2):
    '''Initialize interval object'''
        pass

    def __call__(self):
    '''Call the interval to produce a new delay time'''
        pass

",3,3,snippet_351,1.0,"class Interval(object):
    '''
    This class build automatically incrementing interval objects, 
    to be used in requests timeouts
    
    Use like:
    C{interval = Interval()}
    C{t = interval()}
    C{t = interval()}

    @ivar initial:  Initial interval value, in seconds.
    @ivar maxDelay: maximun interval value produced, in seconds.
    @ivar factor:   multiplier for the next interval.
    '''

    def __init__(self, initial=2, maxDelay=1024, factor=2):
        '''Initialize interval object'''
        self.initial = initial
        self.maxDelay = maxDelay
        self.factor = factor
        self._current = initial

    def __call__(self):
        '''Call the interval to produce a new delay time'''
        delay = self._current
        self._current = min(self._current * self.factor, self.maxDelay)
        return delay","class Interval(object):
    '''
    This class build automatically incrementing interval objects, 
    to be used in requests timeouts
    
    Use like:
    C{interval = Interval()}
    C{t = interval()}
    C{t = interval()}

    @ivar initial:  Initial interval value, in seconds.
    @ivar maxDelay: maximun interval value produced, in seconds.
    @ivar factor:   multiplier for the next interval.
    '''

    def __init__(self, initial=2, maxDelay=1024, factor=2):
        '''Initialize interval object'''
        self.initial = initial
        self.maxDelay = maxDelay
        self.factor = factor
        self.current = initial

    def __call__(self):
        '''Call the interval to produce a new delay time'''
        delay = self.current
        self.current = min(self.current * self.factor, self.maxDelay)
        return delay","class Interval(object):
    '''
    This class build automatically incrementing interval objects, 
    to be used in requests timeouts
    
    Use like:
    C{interval = Interval()}
    C{t = interval()}
    C{t = interval()}

    @ivar initial:  Initial interval value, in seconds.
    @ivar maxDelay: maximun interval value produced, in seconds.
    @ivar factor:   multiplier for the next interval.
    '''

    def __init__(self, initial=2, maxDelay=1024, factor=2):
        '''Initialize interval object'''
        self.initial = initial
        self.maxDelay = maxDelay
        self.factor = factor
        self.current = initial

    def __call__(self):
        '''Call the interval to produce a new delay time'''
        result = self.current
        self.current = min(self.current * self.factor, self.maxDelay)
        return result",full_docstr,0.9162561576354681,0.8557213930348259,0.793969849246231,0.8768472906403941,0.8382027887630571,0.9659090909090909,0.9085714285714286,0.867816091954023,0.9756357073783875,0.9660164713859558,0.9708022475242615,0.9669697880744934,0.9346411764705882,0.9162561576354681,0.8557213930348259,0.793969849246231,0.8768472906403941,0.8153416069877614,0.9651162790697675,0.9064327485380117,0.8647058823529412,0.9746870398521423,0.9652048945426941,0.9699227809906006,0.9661446809768677,0.9346411764705882,0.9162561576354681,0.8557213930348259,0.793969849246231,0.8768472906403941,0.8153416069877614,0.9651162790697675,0.9064327485380117,0.8647058823529412,0.9733123183250427,0.9648672938346863,0.9690713882446289,0.965705156326294,0.9346411764705882,0.6746726848662052,0.7901170163726191,0.7980632125816917,0.4888888888888889,0.6216216216216216,0.6746726848662052,0.7901170163726191,0.7980632125816917,0.4888888888888889,0.6216216216216216,0.6746726848662052,0.7901170163726191,0.7980632125816917,0.4888888888888889,0.6216216216216216
400392,giancosta86/Iris,src/info/gianlucacosta/iris/maven.py,iris.maven.MavenRepository,"class MavenRepository:
    """"""
    A Maven repository
    """"""

    def __init__(self, rootPath):
        """"""
        Initializes the repository.

        --rootPath: the path of the repository itself
        """"""

        self._rootPath = rootPath

    def getRootPath(self):
        """"""
        Returns the root path of the repository
        """"""
        return self._rootPath

    def getArtifactPath(self, artifact, suffix=None, extension=""jar""):
        """"""
        Joins the root path of the repository with the relative path returned
        by the artifact's getPath() method
        """"""
        return os.path.join(self._rootPath, artifact.getPath(suffix, extension, os.sep))

    def getLatestArtifactVersion(self, groupId, artifactId):
        """"""
        Returns the latest version of the given artifact,
        given its groupId and its artifactId.

        Returns None if no version is available for that artifact.
        """"""
        artifact = MavenArtifact(groupId, artifactId)

        artifactPath = self.getArtifactPath(artifact)

        artifactVersionDirectory = VersionDirectory(artifactPath)

        return artifactVersionDirectory.getLatestVersion()","class MavenRepository:
    '''
    A Maven repository
    '''

    def __init__(self, rootPath):
    '''
        Initializes the repository.

        --rootPath: the path of the repository itself
        '''
        pass

    def getRootPath(self):
    '''
        Returns the root path of the repository
        '''
        pass

    def getArtifactPath(self, artifact, suffix=None, extension=""jar""):
    '''
        Joins the root path of the repository with the relative path returned
        by the artifact's getPath() method
        '''
        pass

    def getLatestArtifactVersion(self, groupId, artifactId):
    '''
        Returns the latest version of the given artifact,
        given its groupId and its artifactId.

        Returns None if no version is available for that artifact.
        '''
        pass

",5,5,snippet_717,1.0,"class MavenRepository:
    '''
    A Maven repository
    '''

    def __init__(self, rootPath):
        '''
        Initializes the repository.

        --rootPath: the path of the repository itself
        '''
        self._rootPath = rootPath

    def getRootPath(self):
        '''
        Returns the root path of the repository
        '''
        return self._rootPath

    def getArtifactPath(self, artifact, suffix=None, extension=""jar""):
        '''
        Joins the root path of the repository with the relative path returned
        by the artifact's getPath() method
        '''
        base_path = os.path.join(self._rootPath, artifact.getPath())
        if suffix:
            base_path = f""{base_path}-{suffix}""
        return f""{base_path}.{extension}""

    def getLatestArtifactVersion(self, groupId, artifactId):
        '''
        Returns the latest version of the given artifact,
        given its groupId and its artifactId.

        Returns None if no version is available for that artifact.
        '''
        group_path = os.path.join(self._rootPath, *groupId.split('.'))
        artifact_path = os.path.join(group_path, artifactId)
        if not os.path.isdir(artifact_path):
            return None
        versions = [
            name for name in os.listdir(artifact_path)
            if os.path.isdir(os.path.join(artifact_path, name))
        ]
        if not versions:
            return None

        def version_key(ver):
            parts = ver.split('.')
            nums = []
            for part in parts:
                m = re.match(r'(\d+)', part)
                nums.append(int(m.group(1)) if m else 0)
            return tuple(nums)

        return max(versions, key=version_key)","class MavenRepository:
    '''
    A Maven repository
    '''

    def __init__(self, rootPath):
        '''
        Initializes the repository.

        --rootPath: the path of the repository itself
        '''
        self.rootPath = rootPath

    def getRootPath(self):
        '''
        Returns the root path of the repository
        '''
        return self.rootPath

    def getArtifactPath(self, artifact, suffix=None, extension=""jar""):
        '''
        Joins the root path of the repository with the relative path returned
        by the artifact's getPath() method
        '''
        relative_path = artifact.getPath(suffix=suffix, extension=extension)
        return os.path.join(self.rootPath, relative_path)

    def getLatestArtifactVersion(self, groupId, artifactId):
        '''
        Returns the latest version of the given artifact,
        given its groupId and its artifactId.

        Returns None if no version is available for that artifact.
        '''
        # Convert groupId to directory structure
        group_path = groupId.replace('.', '/')
        artifact_dir = os.path.join(self.rootPath, group_path, artifactId)
        
        # Check if artifact directory exists
        if not os.path.exists(artifact_dir):
            return None
            
        # Get all version directories
        try:
            versions = [v for v in os.listdir(artifact_dir) 
                       if os.path.isdir(os.path.join(artifact_dir, v))]
        except OSError:
            return None
            
        if not versions:
            return None
            
        # Return the ""latest"" version (lexicographically largest for simplicity)
        # In a real implementation, you might want to implement proper version comparison
        return sorted(versions)[-1]","class MavenRepository:
    '''
    A Maven repository
    '''

    def __init__(self, rootPath):
        '''
        Initializes the repository.

        --rootPath: the path of the repository itself
        '''
        self.rootPath = rootPath

    def getRootPath(self):
        '''
        Returns the root path of the repository
        '''
        return self.rootPath

    def getArtifactPath(self, artifact, suffix=None, extension=""jar""):
        '''
        Joins the root path of the repository with the relative path returned
        by the artifact's getPath() method
        '''
        artifact_path = artifact.getPath(suffix=suffix, extension=extension)
        return os.path.join(self.rootPath, artifact_path)

    def getLatestArtifactVersion(self, groupId, artifactId):
        '''
        Returns the latest version of the given artifact,
        given its groupId and its artifactId.

        Returns None if no version is available for that artifact.
        '''
        group_path = groupId.replace('.', os.sep)
        artifact_dir = os.path.join(self.rootPath, group_path, artifactId)
        
        if not os.path.exists(artifact_dir) or not os.path.isdir(artifact_dir):
            return None
        
        versions = []
        for item in os.listdir(artifact_dir):
            item_path = os.path.join(artifact_dir, item)
            if os.path.isdir(item_path):
                try:
                    versions.append(version.parse(item))
                except:
                    continue
        
        if not versions:
            return None
        
        return str(max(versions))",full_docstr,0.6793650793650794,0.6006389776357828,0.5852090032154341,0.653968253968254,0.39895581578272776,0.4822888283378747,0.3907103825136612,0.336986301369863,0.8498935699462891,0.9404686093330383,0.8928900361061096,0.9305515289306641,0.8070194736842108,0.685897435897436,0.6193548387096774,0.5909090909090908,0.641025641025641,0.4419119858699546,0.546875,0.43260188087774293,0.36477987421383645,0.8719717264175415,0.9542700052261353,0.9112665057182312,0.9453476667404175,0.843435909090909,0.7372013651877133,0.6735395189003436,0.6366782006920415,0.689419795221843,0.47257157534527516,0.5704918032786885,0.46710526315789475,0.39603960396039606,0.9021737575531006,0.9583561420440674,0.9294166564941406,0.9524250030517578,0.8341030414746544,0.5777151907632045,0.4301083758780039,0.6418634982859254,0.6,0.6388888888888888,0.5755249752757368,0.3760690670077111,0.616030834095236,0.56,0.75,0.5979984783906311,0.4670428922667864,0.6149510212957383,0.56,0.75
121570,Fantomas42/django-blog-zinnia,Fantomas42_django-blog-zinnia/zinnia/views/search.py,zinnia.views.search.BaseEntrySearch,"class BaseEntrySearch(object):
    """"""
    Mixin providing the behavior of the entry search view,
    by returning in the context the pattern searched, the
    error if something wrong has happened and finally the
    the queryset of published entries matching the pattern.
    """"""
    pattern = ''
    error = None

    def get_queryset(self):
        """"""
        Overridde the get_queryset method to
        do some validations and build the search queryset.
        """"""
        entries = Entry.published.none()

        if self.request.GET:
            self.pattern = self.request.GET.get('pattern', '')
            if len(self.pattern) < 3:
                self.error = _('The pattern is too short')
            else:
                entries = Entry.published.search(self.pattern)
        else:
            self.error = _('No pattern to search found')
        return entries

    def get_context_data(self, **kwargs):
        """"""
        Add error and pattern in context.
        """"""
        context = super(BaseEntrySearch, self).get_context_data(**kwargs)
        context.update({'error': self.error, 'pattern': self.pattern})
        return context","class BaseEntrySearch(object):
    '''
    Mixin providing the behavior of the entry search view,
    by returning in the context the pattern searched, the
    error if something wrong has happened and finally the
    the queryset of published entries matching the pattern.
    '''

    def get_queryset(self):
    '''
        Overridde the get_queryset method to
        do some validations and build the search queryset.
        '''
        pass

    def get_context_data(self, **kwargs):
    '''
        Add error and pattern in context.
        '''
        pass

",3,3,snippet_125,0.4285714285714285,"class BaseEntrySearch(object):
    '''
    Mixin providing the behavior of the entry search view,
    by returning in the context the pattern searched, the
    error if something wrong has happened and finally the
    queryset of published entries matching the pattern.
    '''

    MIN_SEARCH_LENGTH = 3

    def get_queryset(self):
        '''
        Override the get_queryset method to
        do some validations and build the search queryset.
        '''
        qs = super(BaseEntrySearch, self).get_queryset()
        self.pattern = self.request.GET.get('pattern', '').strip()
        self.error = None

        if not self.pattern:
            self.error = 'Please enter a search term.'
            return qs.none()

        if len(self.pattern) < self.MIN_SEARCH_LENGTH:
            self.error = (
                f'Search term must be at least {self.MIN_SEARCH_LENGTH} characters.'
            )
            return qs.none()

        return qs.filter(
            published=True
        ).filter(
            Q(title__icontains=self.pattern) |
            Q(content__icontains=self.pattern)
        )

    def get_context_data(self, **kwargs):
        '''
        Add error and pattern in context.
        '''
        context = super(BaseEntrySearch, self).get_context_data(**kwargs)
        context['pattern'] = getattr(self, 'pattern', '')
        context['error'] = getattr(self, 'error', None)
        return context","class BaseEntrySearch(object):
    '''
    Mixin providing the behavior of the entry search view,
    by returning in the context the pattern searched, the
    error if something wrong has happened and finally the
    the queryset of published entries matching the pattern.
    '''

    def get_queryset(self):
        '''
        Override the get_queryset method to
        do some validations and build the search queryset.
        '''
        queryset = super(BaseEntrySearch, self).get_queryset()
        pattern = self.request.GET.get('pattern', '')
        
        if pattern:
            try:
                # Assuming there's a search method or filter logic
                # This is a generic implementation - adjust based on actual model fields
                queryset = queryset.filter(
                    title__icontains=pattern
                ) | queryset.filter(
                    content__icontains=pattern
                )
                queryset = queryset.distinct()
            except Exception:
                # If search fails, return empty queryset
                queryset = queryset.none()
        
        return queryset

    def get_context_data(self, **kwargs):
        '''
        Add error and pattern in context.
        '''
        context = super(BaseEntrySearch, self).get_context_data(**kwargs)
        pattern = self.request.GET.get('pattern', '')
        error = None
        
        context.update({
            'pattern': pattern,
            'error': error
        })
        
        return context","class BaseEntrySearch(object):
    '''
    Mixin providing the behavior of the entry search view,
    by returning in the context the pattern searched, the
    error if something wrong has happened and finally the
    the queryset of published entries matching the pattern.
    '''

    def get_queryset(self):
        '''
        Override the get_queryset method to
        do some validations and build the search queryset.
        '''
        queryset = super(BaseEntrySearch, self).get_queryset()
        self.pattern = ''
        self.error = None
        
        pattern = self.request.GET.get('pattern', '').strip()
        
        if not pattern:
            self.error = 'Please provide a search pattern'
            return queryset.none()
        
        if len(pattern) < 3:
            self.error = 'Search pattern must be at least 3 characters long'
            return queryset.none()
        
        self.pattern = pattern
        
        return queryset.filter(
            status='published'
        ).filter(
            models.Q(title__icontains=pattern) |
            models.Q(content__icontains=pattern) |
            models.Q(excerpt__icontains=pattern)
        ).distinct()

    def get_context_data(self, **kwargs):
        '''
        Add error and pattern in context.
        '''
        context = super(BaseEntrySearch, self).get_context_data(**kwargs)
        context['pattern'] = getattr(self, 'pattern', '')
        context['error'] = getattr(self, 'error', None)
        return context",full_docstr,0.7609427609427609,0.6033898305084745,0.4982935153583617,0.6801346801346801,0.5294890200258545,0.6518771331058021,0.5136986301369864,0.44329896907216493,0.8736234903335571,0.9267799854278564,0.899416983127594,0.921174943447113,0.8117302777777778,0.745644599303136,0.5964912280701755,0.5300353356890459,0.6689895470383275,0.566207120181763,0.7215686274509804,0.5393700787401575,0.466403162055336,0.8727754354476929,0.9066797494888306,0.8894045948982239,0.9031713008880615,0.8227378034682081,0.777027027027027,0.6258503401360545,0.5136986301369864,0.6824324324324323,0.5387136414350864,0.6631944444444444,0.5226480836236934,0.45104895104895104,0.8770197629928589,0.9219176769256592,0.8989084362983704,0.9172220826148987,0.796785657894737,0.6160144545200216,0.4374910996662413,0.5149388114371009,0.5116279069767442,0.0,0.486097384856442,0.4193093255042743,0.5345141761856448,0.5,0.490566037735849,0.6166043305494052,0.4469594826068375,0.5427136535442718,0.4767441860465116,0.0
7653,AtteqCom/zsl,AtteqCom_zsl/src/zsl/utils/command_dispatcher.py,zsl.utils.command_dispatcher.CommandDispatcher,"class CommandDispatcher:
    """"""
    A simple class for command dictionary. A command is a function
    which can take named parameters.
    """"""

    def __init__(self):
        """"""
        Create command dictionary
        """"""

        self.commands = {}

    def command(self, fn):
        """"""
        Add method or function to dispatcher. Can be use as a nice
        decorator.

        :param fn: function or method
        :type fn: function
        :return: the same function
        :rtype: function
        """"""
        self.commands[fn.__name__] = fn

        return fn

    """"""alias for ``CommandDispatcher.command``""""""
    add_function = command

    def execute_command(self, command, args=None):
        """"""
        Execute a command

        :param command: name of the command
        :type command: str
        :param args: optional named arguments for command
        :type args: dict
        :return: the result of command
        :raises KeyError: if command is not found
        """"""

        if args is None:
            args = {}

        command_fn = self.commands[command]

        return command_fn(**args)

    def bound(self, instance):
        """"""
        Return a new dispatcher, which will switch all command functions
        with bounded methods of given instance matched by name. It will
        match only regular methods.

        :param instance: object instance
        :type instance: object
        :return: new Dispatcher
        :rtype: CommandDispatcher
        """"""

        bounded_dispatcher = CommandDispatcher()
        bounded_dispatcher.commands = self.commands.copy()

        for name in self.commands:
            method = getattr(instance, name, None)

            if method and inspect.ismethod(method) and method.__self__ == instance:
                bounded_dispatcher.commands[name] = method

        return bounded_dispatcher","class CommandDispatcher:
    '''
    A simple class for command dictionary. A command is a function
    which can take named parameters.
    '''

    def __init__(self):
    '''
        Create command dictionary
        '''
        pass

    def command(self, fn):
    '''
        Add method or function to dispatcher. Can be use as a nice
        decorator.

        :param fn: function or method
        :type fn: function
        :return: the same function
        :rtype: function
        '''
        pass

    def execute_command(self, command, args=None):
    '''
        Execute a command

        :param command: name of the command
        :type command: str
        :param args: optional named arguments for command
        :type args: dict
        :return: the result of command
        :raises KeyError: if command is not found
        '''
        pass

    def bound(self, instance):
    '''
        Return a new dispatcher, which will switch all command functions
        with bounded methods of given instance matched by name. It will
        match only regular methods.

        :param instance: object instance
        :type instance: object
        :return: new Dispatcher
        :rtype: CommandDispatcher
        '''
        pass

",5,5,snippet_25,0.5,"class CommandDispatcher:
    '''
    A simple class for command dictionary. A command is a function
    which can take named parameters.
    '''

    def __init__(self):
        '''
        Create command dictionary
        '''
        self._commands = {}

    def command(self, fn):
        '''
        Add method or function to dispatcher. Can be use as a nice
        decorator.

        :param fn: function or method
        :type fn: function
        :return: the same function
        :rtype: function
        '''
        self._commands[fn.__name__] = fn
        return fn

    def execute_command(self, command, args=None):
        '''
        Execute a command

        :param command: name of the command
        :type command: str
        :param args: optional named arguments for command
        :type args: dict
        :return: the result of command
        :raises KeyError: if command is not found
        '''
        if command not in self._commands:
            raise KeyError(f""Command '{command}' not found"")
        fn = self._commands[command]
        if args is None:
            args = {}
        return fn(**args)

    def bound(self, instance):
        '''
        Return a new dispatcher, which will switch all command functions
        with bounded methods of given instance matched by name. It will
        match only regular methods.

        :param instance: object instance
        :type instance: object
        :return: new Dispatcher
        :rtype: CommandDispatcher
        '''
        new_disp = CommandDispatcher()
        for name, fn in self._commands.items():
            if hasattr(instance, name):
                attr = getattr(instance, name)
                if callable(attr):
                    new_disp._commands[name] = attr
                    continue
            new_disp._commands[name] = fn
        return new_disp","class CommandDispatcher:
    '''
    A simple class for command dictionary. A command is a function
    which can take named parameters.
    '''

    def __init__(self):
        '''
        Create command dictionary
        '''
        self.commands = {}

    def command(self, fn):
        '''
        Add method or function to dispatcher. Can be use as a nice
        decorator.

        :param fn: function or method
        :type fn: function
        :return: the same function
        :rtype: function
        '''
        self.commands[fn.__name__] = fn
        return fn

    def execute_command(self, command, args=None):
        '''
        Execute a command

        :param command: name of the command
        :type command: str
        :param args: optional named arguments for command
        :type args: dict
        :return: the result of command
        :raises KeyError: if command is not found
        '''
        if command not in self.commands:
            raise KeyError(f""Command '{command}' not found"")
        
        if args is None:
            args = {}
            
        return self.commands[command](**args)

    def bound(self, instance):
        '''
        Return a new dispatcher, which will switch all command functions
        with bounded methods of given instance matched by name. It will
        match only regular methods.

        :param instance: object instance
        :type instance: object
        :return: new Dispatcher
        :rtype: CommandDispatcher
        '''
        new_dispatcher = CommandDispatcher()
        new_dispatcher.commands = self.commands.copy()
        
        for name, func in self.commands.items():
            if hasattr(instance, name):
                method = getattr(instance, name)
                if callable(method):
                    new_dispatcher.commands[name] = method
                    
        return new_dispatcher","class CommandDispatcher:
    '''
    A simple class for command dictionary. A command is a function
    which can take named parameters.
    '''

    def __init__(self):
        '''
        Create command dictionary
        '''
        self.commands = {}

    def command(self, fn):
        '''
        Add method or function to dispatcher. Can be use as a nice
        decorator.

        :param fn: function or method
        :type fn: function
        :return: the same function
        :rtype: function
        '''
        self.commands[fn.__name__] = fn
        return fn

    def execute_command(self, command, args=None):
        '''
        Execute a command

        :param command: name of the command
        :type command: str
        :param args: optional named arguments for command
        :type args: dict
        :return: the result of command
        :raises KeyError: if command is not found
        '''
        if command not in self.commands:
            raise KeyError(f""Command '{command}' not found"")
        
        fn = self.commands[command]
        if args is None:
            args = {}
        
        return fn(**args)

    def bound(self, instance):
        '''
        Return a new dispatcher, which will switch all command functions
        with bounded methods of given instance matched by name. It will
        match only regular methods.

        :param instance: object instance
        :type instance: object
        :return: new Dispatcher
        :rtype: CommandDispatcher
        '''
        new_dispatcher = CommandDispatcher()
        
        for command_name, command_fn in self.commands.items():
            if hasattr(instance, command_name):
                method = getattr(instance, command_name)
                if callable(method) and not command_name.startswith('_'):
                    new_dispatcher.commands[command_name] = method
                else:
                    new_dispatcher.commands[command_name] = command_fn
            else:
                new_dispatcher.commands[command_name] = command_fn
        
        return new_dispatcher",full_docstr,0.8682926829268292,0.7843137254901961,0.7389162561576355,0.8195121951219512,0.6915337726243079,0.8510028653295129,0.7155172413793104,0.6397694524495677,0.9495950937271118,0.9471278190612793,0.9483599066734314,0.9473738670349121,0.8934119186046512,0.9068627450980392,0.8226600985221676,0.7821782178217822,0.8774509803921569,0.7349470930888379,0.873900293255132,0.7911764705882353,0.7286135693215339,0.9581782221794128,0.9532370567321777,0.9557011723518372,0.9537288546562195,0.8888900000000001,0.8697674418604652,0.7710280373831775,0.7042253521126761,0.813953488372093,0.7098774251576102,0.8051948051948052,0.703125,0.6318537859007833,0.9361843466758728,0.9486180543899536,0.9423602223396301,0.9473598599433899,0.8865990721649484,0.6452075590478737,0.6613697002560519,0.6743338302824218,0.6710526315789473,0.5740740740740741,0.6696480340367069,0.693408496210904,0.6976592734641885,0.6578947368421053,0.6296296296296297,0.6803907285178344,0.660573894163515,0.6969539321885249,0.6973684210526315,0.6666666666666666
135517,JdeRobot/base,src/libs/comm_py/comm/ros/listenerBumper.py,comm.ros.listenerBumper.ListenerBumper,"class ListenerBumper:
    '''
        ROS Bumper Subscriber. Bumper Client to Receive Bumper Scans from ROS nodes.
    '''
    def __init__(self, topic):
        '''
        ListenerBumper Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        self.topic = topic
        self.data = BumperData()
        self.time = current_milli_time()
        self.sub = None
        self.lock = threading.Lock()
        self.start()
 
    def __callback (self, event):
        '''
        Callback function to receive and save Bumper Scans. 

        @param event: ROS BumperScan received
        
        @type event: BumperScan

        '''
        bump = bumperEvent2BumperData(event)

        if bump.state == 1:
            self.lock.acquire()
            self.time = current_milli_time()
            self.data = bump
            self.lock.release()
        
    def stop(self):
        '''
        Stops (Unregisters) the client.

        '''
        self.sub.unregister()

    def start (self):
        '''
        Starts (Subscribes) the client.

        '''
        self.sub = rospy.Subscriber(self.topic, BumperEvent, self.__callback)
        
    def getBumperData(self):
        '''
        Returns last BumperData. 

        @return last JdeRobotTypes BumperData saved

        '''
        self.lock.acquire()
        t = current_milli_time()
        if (t - self.time) > 500:
            self.data.state = 0
        bump = self.data
        self.lock.release()
        
        return bump","class ListenerBumper:
    '''
        ROS Bumper Subscriber. Bumper Client to Receive Bumper Scans from ROS nodes.
    '''

    def __init__(self, topic):
    '''
        ListenerBumper Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        pass

    def __callback (self, event):
    '''
        Callback function to receive and save Bumper Scans. 

        @param event: ROS BumperScan received
        
        @type event: BumperScan

        '''
        pass

    def stop(self):
    '''
        Stops (Unregisters) the client.

        '''
        pass

    def start (self):
    '''
        Starts (Subscribes) the client.

        '''
        pass

    def getBumperData(self):
    '''
        Returns last BumperData. 

        @return last JdeRobotTypes BumperData saved

        '''
        pass

",6,6,snippet_156,0.3333333333333333,"class ListenerBumper:
    '''
        ROS Bumper Subscriber. Bumper Client to Receive Bumper Scans from ROS nodes.
    '''

    def __init__(self, topic):
        '''
            ListenerBumper Constructor.

            @param topic: ROS topic to subscribe
            @type topic: String
        '''
        self.topic = topic
        self.subscriber = None
        self._last_data = None

    def __callback(self, event):
        '''
            Callback function to receive and save Bumper Scans. 

            @param event: ROS BumperScan received
            @type event: BumperScan
        '''
        self._last_data = event

    def stop(self):
        '''
            Stops (Unregisters) the client.
        '''
        if self.subscriber is not None:
            self.subscriber.unregister()
            self.subscriber = None

    def start(self):
        '''
            Starts (Subscribes) the client.
        '''
        if self.subscriber is None:
            self.subscriber = rospy.Subscriber(self.topic,
                                               BumperData,
                                               self.__callback)

    def getBumperData(self):
        '''
            Returns last BumperData. 

            @return last JdeRobotTypes BumperData saved
        '''
        return self._last_data","class ListenerBumper:
    '''
        ROS Bumper Subscriber. Bumper Client to Receive Bumper Scans from ROS nodes.
    '''

    def __init__(self, topic):
        '''
        ListenerBumper Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        self.topic = topic
        self.data = BumperData()
        self.sub = None

    def __callback(self, event):
        '''
        Callback function to receive and save Bumper Scans. 

        @param event: ROS BumperScan received
        
        @type event: BumperScan

        '''
        self.data = BumperData()
        self.data.bumper = event.bumper
        self.data.state = event.state

    def stop(self):
        '''
        Stops (Unregisters) the client.

        '''
        if self.sub is not None:
            self.sub.unregister()
            self.sub = None

    def start(self):
        '''
        Starts (Subscribes) the client.

        '''
        if self.sub is None:
            self.sub = rospy.Subscriber(self.topic, BumperEvent, self.__callback)

    def getBumperData(self):
        '''
        Returns last BumperData. 

        @return last JdeRobotTypes BumperData saved

        '''
        return self.data","class ListenerBumper:
    '''
        ROS Bumper Subscriber. Bumper Client to Receive Bumper Scans from ROS nodes.
    '''

    def __init__(self, topic):
        '''
        ListenerBumper Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        self.topic = topic
        self.sub = None
        self.bumperData = None
        self.lock = threading.Lock()

    def __callback(self, event):
        '''
        Callback function to receive and save Bumper Scans. 

        @param event: ROS BumperScan received
        
        @type event: BumperScan

        '''
        with self.lock:
            self.bumperData = event

    def stop(self):
        '''
        Stops (Unregisters) the client.

        '''
        if self.sub is not None:
            self.sub.unregister()
            self.sub = None

    def start(self):
        '''
        Starts (Subscribes) the client.

        '''
        self.sub = rospy.Subscriber(self.topic, BumperEvent, self.__callback)

    def getBumperData(self):
        '''
        Returns last BumperData. 

        @return last JdeRobotTypes BumperData saved

        '''
        with self.lock:
            return self.bumperData",full_docstr,0.758364312267658,0.599250936329588,0.5433962264150943,0.6914498141263942,0.5506129380251072,0.9241706161137441,0.7952380952380952,0.722488038277512,0.9363044500350952,0.8793002963066101,0.9069075584411621,0.8846865296363831,0.8228245945945948,0.8043478260869565,0.6861313868613139,0.6102941176470588,0.7318840579710146,0.6342339675242775,0.9375,0.852017937219731,0.7972972972972973,0.9410063028335571,0.8822556734085083,0.9106844067573547,0.8877984881401062,0.8228245945945946,0.8044280442804428,0.6988847583643122,0.6367041198501872,0.7527675276752768,0.6077450771881259,0.9392523364485982,0.8685446009389671,0.8254716981132075,0.9411420822143555,0.8915839195251465,0.9156929850578308,0.896303653717041,0.8408424324324323,0.5122683147621825,0.5440837590557933,0.5721816921851288,0.5855855855855856,0.3472222222222222,0.5871918955593607,0.6114581833582408,0.6310781676479709,0.6756756756756757,0.4305555555555556,0.5602356687305683,0.6074703539358061,0.6278416903558365,0.6306306306306306,0.375
102297,BerkeleyAutomation/autolab_core,BerkeleyAutomation_autolab_core/autolab_core/points.py,autolab_core.points.Plane3D,"class Plane3D(object):
    """"""A plane in three dimensions.""""""

    def __init__(self, n, x0):
        """"""Initialize a plane with a normal vector and a point.

        Parameters
        ----------
        n : :obj:`Direction`
            A 3D normal vector to the plane.

        x0 : :obj:`Point`
            A 3D point in the plane.

        Raises
        ------
        ValueError
            If the parameters are of the wrong type or are not of dimension 3.
        """"""
        if not isinstance(n, Direction) or n.dim != 3:
            raise ValueError(""Plane normal must be a 3D direction"")
        if not isinstance(x0, Point) or x0.dim != 3:
            raise ValueError(""Plane offset must be a 3D point"")
        self._n = n
        self._x0 = x0

    def split_points(self, point_cloud):
        """"""Split a point cloud into two along this plane.

        Parameters
        ----------
        point_cloud : :obj:`PointCloud`
            The PointCloud to divide in two.

        Returns
        -------
        :obj:`tuple` of :obj:`PointCloud`
            Two new PointCloud objects. The first contains points above the
            plane, and the second contains points below the plane.

        Raises
        ------
        ValueError
            If the input is not a PointCloud.
        """"""
        if not isinstance(point_cloud, PointCloud):
            raise ValueError(""Can only split point clouds"")
        # compute indices above and below
        above_plane = (
            point_cloud._data
            - np.tile(self._x0.data, [1, point_cloud.num_points]).T.dot(
                self._n
            )
            > 0
        )
        above_plane = point_cloud.z_coords > 0 & above_plane
        below_plane = (
            point_cloud._data
            - np.tile(self._x0.data, [1, point_cloud.num_points]).T.dot(
                self._n
            )
            <= 0
        )
        below_plane = point_cloud.z_coords > 0 & below_plane

        # split data
        above_data = point_cloud.data[:, above_plane]
        below_data = point_cloud.data[:, below_plane]
        return PointCloud(above_data, point_cloud.frame), PointCloud(
            below_data, point_cloud.frame
        )","class Plane3D(object):
    '''A plane in three dimensions.'''

    def __init__(self, n, x0):
    '''Initialize a plane with a normal vector and a point.

        Parameters
        ----------
        n : :obj:`Direction`
            A 3D normal vector to the plane.

        x0 : :obj:`Point`
            A 3D point in the plane.

        Raises
        ------
        ValueError
            If the parameters are of the wrong type or are not of dimension 3.
        '''
        pass

    def split_points(self, point_cloud):
    '''Split a point cloud into two along this plane.

        Parameters
        ----------
        point_cloud : :obj:`PointCloud`
            The PointCloud to divide in two.

        Returns
        -------
        :obj:`tuple` of :obj:`PointCloud`
            Two new PointCloud objects. The first contains points above the
            plane, and the second contains points below the plane.

        Raises
        ------
        ValueError
            If the input is not a PointCloud.
        '''
        pass

",3,3,snippet_41,0.1666666666666666,"class Plane3D(object):
    '''A plane in three dimensions.'''

    def __init__(self, n, x0):
        '''Initialize a plane with a normal vector and a point.

        Parameters
        ----------
        n : :obj:`Direction`
            A 3D normal vector to the plane.

        x0 : :obj:`Point`
            A 3D point in the plane.

        Raises
        ------
        ValueError
            If the parameters are of the wrong type or are not of dimension 3.
        '''
        # Type checks
        from collections.abc import Sequence

        if not isinstance(n, Direction):
            raise ValueError(""n must be a Direction"")
        if not isinstance(x0, Point):
            raise ValueError(""x0 must be a Point"")

        # Dimension checks
        try:
            ln = len(n)
        except Exception:
            raise ValueError(""n must be a sequence of length 3"")
        try:
            lx0 = len(x0)
        except Exception:
            raise ValueError(""x0 must be a sequence of length 3"")

        if ln != 3 or lx0 != 3:
            raise ValueError(""n and x0 must both be 3-dimensional"")

        self.n = n
        self.x0 = x0

    def split_points(self, point_cloud):
        '''Split a point cloud into two along this plane.

        Parameters
        ----------
        point_cloud : :obj:`PointCloud`
            The PointCloud to divide in two.

        Returns
        -------
        :obj:`tuple` of :obj:`PointCloud`
            Two new PointCloud objects. The first contains points above the
            plane, and the second contains points below the plane.

        Raises
        ------
        ValueError
            If the input is not a PointCloud.
        '''
        # Validate input
        if not isinstance(point_cloud, PointCloud):
            raise ValueError(""point_cloud must be a PointCloud"")

        above_pts = []
        below_pts = []

        # Helper for dot product
        def dot(u, v):
            return sum(ui * vi for ui, vi in zip(u, v))

        # For each point, compute signed distance by dot(n, p - x0)
        for p in point_cloud:
            if not isinstance(p, Point):
                raise ValueError(""All elements of point_cloud must be Point instances"")
            # Compute p - x0
            diff = [pi - xi for pi, xi in zip(p, self.x0)]
            val = dot(self.n, diff)
            if val >= 0:
                above_pts.append(p)
            else:
                below_pts.append(p)

        # Build new PointClouds
        top_cloud = PointCloud(above_pts)
        bottom_cloud = PointCloud(below_pts)
        return top_cloud, bottom_cloud","class Plane3D(object):
    '''A plane in three dimensions.'''

    def __init__(self, n, x0):
        '''Initialize a plane with a normal vector and a point.

        Parameters
        ----------
        n : :obj:`Direction`
            A 3D normal vector to the plane.

        x0 : :obj:`Point`
            A 3D point in the plane.

        Raises
        ------
        ValueError
            If the parameters are of the wrong type or are not of dimension 3.
        '''
        if not hasattr(n, 'dimension') or n.dimension != 3:
            raise ValueError(""Normal vector must be 3-dimensional"")
        if not hasattr(x0, 'dimension') or x0.dimension != 3:
            raise ValueError(""Point must be 3-dimensional"")
        
        self.n = n
        self.x0 = x0

    def split_points(self, point_cloud):
        '''Split a point cloud into two along this plane.

        Parameters
        ----------
        point_cloud : :obj:`PointCloud`
            The PointCloud to divide in two.

        Returns
        -------
        :obj:`tuple` of :obj:`PointCloud`
            Two new PointCloud objects. The first contains points above the
            plane, and the second contains points below the plane.

        Raises
        ------
        ValueError
            If the input is not a PointCloud.
        '''
        if not hasattr(point_cloud, 'points'):
            raise ValueError(""Input must be a PointCloud"")
        
        above_points = []
        below_points = []
        
        for point in point_cloud.points:
            # Calculate the dot product of (point - x0) with the normal vector
            # This gives us the signed distance from the point to the plane
            diff = [point[i] - self.x0[i] for i in range(3)]
            dot_product = sum(diff[i] * self.n[i] for i in range(3))
            
            if dot_product > 0:
                above_points.append(point)
            else:
                below_points.append(point)
        
        # Create new PointCloud objects (assuming PointCloud constructor takes a list of points)
        above_cloud = type(point_cloud)(above_points)
        below_cloud = type(point_cloud)(below_points)
        
        return (above_cloud, below_cloud)","class Plane3D(object):
    '''A plane in three dimensions.'''

    def __init__(self, n, x0):
        '''Initialize a plane with a normal vector and a point.

        Parameters
        ----------
        n : :obj:`Direction`
            A 3D normal vector to the plane.

        x0 : :obj:`Point`
            A 3D point in the plane.

        Raises
        ------
        ValueError
            If the parameters are of the wrong type or are not of dimension 3.
        '''
        if not hasattr(n, '__class__') or n.__class__.__name__ != 'Direction':
            raise ValueError(""n must be a Direction object"")
        if not hasattr(x0, '__class__') or x0.__class__.__name__ != 'Point':
            raise ValueError(""x0 must be a Point object"")
        if len(n) != 3:
            raise ValueError(""Normal vector must be 3D"")
        if len(x0) != 3:
            raise ValueError(""Point must be 3D"")
        
        self.n = n
        self.x0 = x0

    def split_points(self, point_cloud):
        '''Split a point cloud into two along this plane.

        Parameters
        ----------
        point_cloud : :obj:`PointCloud`
            The PointCloud to divide in two.

        Returns
        -------
        :obj:`tuple` of :obj:`PointCloud`
            Two new PointCloud objects. The first contains points above the
            plane, and the second contains points below the plane.

        Raises
        ------
        ValueError
            If the input is not a PointCloud.
        '''
        if not hasattr(point_cloud, '__class__') or point_cloud.__class__.__name__ != 'PointCloud':
            raise ValueError(""Input must be a PointCloud object"")
        
        above_points = []
        below_points = []
        
        for point in point_cloud:
            diff = point - self.x0
            dot_product = self.n.dot(diff)
            
            if dot_product > 0:
                above_points.append(point)
            else:
                below_points.append(point)
        
        PointCloud = point_cloud.__class__
        return (PointCloud(above_points), PointCloud(below_points))",full_docstr,0.6520270270270271,0.5288135593220339,0.46938775510204084,0.6114864864864865,0.5133384224753651,0.6597353497164461,0.48674242424242425,0.42125237191650855,0.8708832263946533,0.9053810834884644,0.8877971172332764,0.9018087387084961,0.7852927758007119,0.728624535315985,0.544776119402985,0.4794007490636704,0.6802973977695168,0.5445655775114594,0.773542600896861,0.5752808988764045,0.4752252252252252,0.9094565510749817,0.916149377822876,0.9127907156944275,0.9154756665229797,0.8347842608695653,0.7514677103718199,0.593320235756385,0.5167652859960552,0.6927592954990215,0.5614412683068105,0.7872807017543859,0.5758241758241758,0.47577092511013214,0.9237580299377441,0.9039282202720642,0.9137355089187622,0.9058728218078613,0.779663220338983,0.479142486376671,0.392292292335659,0.5408975538833066,0.495575221238938,0.4878048780487805,0.4679142570758999,0.4796385798108318,0.5270281614217555,0.3893805309734513,0.4756097560975609,0.4684840000855591,0.5065654012785474,0.5267705558951159,0.3893805309734513,0.4512195121951219
121862,Fizzadar/pydocs,Fizzadar_pydocs/fake_module/class_example.py,fake_module.class_example.ExampleClass,"class ExampleClass(object):
    '''This ExampleClass does something magical.'''
    def __init__(self, test, *args, **kargs):
        '''
        # *args: list of arguments
        '''
        pass

    def some_function(self):
        '''Example function inside a class.'''
        pass","class ExampleClass(object):
    '''This ExampleClass does something magical.'''

    def __init__(self, test, *args, **kargs):
    '''
        # *args: list of arguments
        '''
        pass

    def some_function(self):
    '''Example function inside a class.'''
        pass

",3,3,snippet_128,1.0,"class ExampleClass(object):
    '''This ExampleClass does something magical.'''

    def __init__(self, test, *args, **kargs):
        '''
        # *args: list of functions to apply in sequence
        # **kargs: dict of named functions to apply after args
        '''
        self.test = test
        self.args = list(args)
        self.kargs = kargs

    def some_function(self):
        '''Example function inside a class.'''
        result = self.test
        for fn in self.args:
            if callable(fn):
                result = fn(result)
        for fn in self.kargs.values():
            if callable(fn):
                result = fn(result)
        return result

    def __repr__(self):
        return ""ExampleClass(test={!r}, args={!r}, kargs={!r})"".format(
            self.test, self.args, self.kargs
        )","class ExampleClass(object):
    '''This ExampleClass does something magical.'''

    def __init__(self, test, *args, **kargs):
        '''
        # *args: list of arguments
        '''
        self.test = test
        self.args = args
        self.kargs = kargs

    def some_function(self):
        '''Example function inside a class.'''
        return ""This is an example function""","class ExampleClass(object):
    '''This ExampleClass does something magical.'''

    def __init__(self, test, *args, **kwargs):
        '''
        # *args: list of arguments
        '''
        self.test = test
        self.args = args
        self.kwargs = kwargs

    def some_function(self):
        '''Example function inside a class.'''
        return f""Test: {self.test}, Args: {self.args}, Kwargs: {self.kwargs}""",full_docstr,0.41600000000000004,0.3902439024390244,0.3636363636363637,0.41600000000000004,0.2790285390916299,0.2916666666666667,0.2774869109947644,0.26842105263157895,0.7566377520561218,0.9129522442817688,0.8274775743484497,0.8944732546806335,0.7589767692307692,0.7605633802816901,0.7246376811594203,0.6865671641791045,0.7605633802816901,0.6959327020795867,0.7125,0.6962025316455697,0.6794871794871795,0.9367757439613342,0.9619649648666382,0.9492032527923584,0.9593852758407593,0.8700577966101695,0.6842105263157894,0.6216216216216216,0.5555555555555555,0.6842105263157894,0.5402568707977367,0.5656565656565656,0.5408163265306123,0.5154639175257731,0.8921387791633606,0.9513046741485596,0.9207723140716553,0.9450372457504272,0.8310519178082192,0.5967984446247432,0.2620669837183236,0.7679839376377922,0.3571428571428571,1.0,0.691914937583638,0.5797440546932842,0.8307728384984108,0.3571428571428571,1.0,0.6482057701157001,0.4994817583403018,0.7361984649796415,0.3571428571428571,1.0
215028,adamreeve/npTDMS,adamreeve_npTDMS/nptdms/channel_data.py,nptdms.channel_data.DaqmxDataReceiver,"class DaqmxDataReceiver(object):
    """"""Receives raw scaler data for a DAQmx object and stores it in numpy
    arrays

    :ivar scaler_data: Dictionary mapping from scaler id to data for a scaler
    """"""

    def __init__(self, obj, num_values, memmap_dir=None):
        """"""Initialise data receiver for DAQmx backed by a numpy array

        :param obj: Object to store data for
        :param memmap_dir: Optional directory to store memory mmap files in.
        """"""

        self.path = obj.path
        self.data = None
        self.scaler_data = {}
        self._scaler_insert_positions = {}
        for scaler_id, scaler_type in obj.scaler_data_types.items():
            self.scaler_data[scaler_id] = _new_numpy_array(
                scaler_type.nptype, num_values, memmap_dir)
            self._scaler_insert_positions[scaler_id] = 0

    def append_scaler_data(self, scale_id, new_data):
        """"""Append new DAQmx scaler data read from a segment
        """"""

        log.debug(""Adding %d data points for object %s, scaler %d"",
                  len(new_data), self.path, scale_id)
        data_array = self.scaler_data[scale_id]
        start_pos = self._scaler_insert_positions[scale_id]
        end_pos = start_pos + len(new_data)
        data_array[start_pos:end_pos] = new_data
        self._scaler_insert_positions[scale_id] += len(new_data)","class DaqmxDataReceiver(object):
    '''Receives raw scaler data for a DAQmx object and stores it in numpy
    arrays

    :ivar scaler_data: Dictionary mapping from scaler id to data for a scaler
    '''

    def __init__(self, obj, num_values, memmap_dir=None):
    '''Initialise data receiver for DAQmx backed by a numpy array

        :param obj: Object to store data for
        :param memmap_dir: Optional directory to store memory mmap files in.
        '''
        pass

    def append_scaler_data(self, scale_id, new_data):
    '''Append new DAQmx scaler data read from a segment
        '''
        pass

",3,3,snippet_297,0.4,"class DaqmxDataReceiver(object):
    '''Receives raw scaler data for a DAQmx object and stores it in numpy
    arrays

    :ivar scaler_data: Dictionary mapping from scaler id to data for a scaler
    '''

    def __init__(self, obj, num_values, memmap_dir=None):
        '''Initialise data receiver for DAQmx backed by a numpy array

        :param obj: Object to store data for
        :param memmap_dir: Optional directory to store memory mmap files in.
        '''
        self.obj = obj
        self.num_values = num_values
        self.memmap_dir = memmap_dir
        self.scaler_data = {}
        self._counts = {}
        if self.memmap_dir is not None:
            os.makedirs(self.memmap_dir, exist_ok=True)

    def append_scaler_data(self, scale_id, new_data):
        '''Append new DAQmx scaler data read from a segment'''
        data = np.atleast_1d(new_data).astype(np.int64)
        n = data.shape[0]
        if scale_id not in self.scaler_data:
            if self.memmap_dir:
                fname = os.path.join(
                    self.memmap_dir,
                    f""daqmx_obj_{id(self.obj)}_scaler_{scale_id}.dat""
                )
                arr = np.memmap(fname, dtype=np.int64,
                                mode=""w+"", shape=(self.num_values,))
            else:
                arr = np.zeros(self.num_values, dtype=np.int64)
            self.scaler_data[scale_id] = arr
            self._counts[scale_id] = 0
        start = self._counts[scale_id]
        end = start + n
        if end > self.num_values:
            raise ValueError(
                f""Appending {n} values exceeds capacity of {self.num_values}""
            )
        self.scaler_data[scale_id][start:end] = data
        self._counts[scale_id] = end","class DaqmxDataReceiver(object):
    '''Receives raw scaler data for a DAQmx object and stores it in numpy
    arrays

    :ivar scaler_data: Dictionary mapping from scaler id to data for a scaler
    '''

    def __init__(self, obj, num_values, memmap_dir=None):
        '''Initialise data receiver for DAQmx backed by a numpy array

        :param obj: Object to store data for
        :param memmap_dir: Optional directory to store memory mmap files in.
        '''
        self.obj = obj
        self.num_values = num_values
        self.memmap_dir = memmap_dir
        self.scaler_data = {}
        
    def append_scaler_data(self, scale_id, new_data):
        '''Append new DAQmx scaler data read from a segment
        '''
        if scale_id not in self.scaler_data:
            if self.memmap_dir is not None:
                # Create memory mapped array
                mmap_file = os.path.join(self.memmap_dir, f'scaler_{scale_id}.npy')
                self.scaler_data[scale_id] = np.memmap(mmap_file, dtype=new_data.dtype, mode='w+', shape=(self.num_values,))
                self.scaler_data[scale_id][:len(new_data)] = new_data
            else:
                # Create regular numpy array
                self.scaler_data[scale_id] = np.zeros(self.num_values, dtype=new_data.dtype)
                self.scaler_data[scale_id][:len(new_data)] = new_data
        else:
            # Append to existing data
            existing_data = self.scaler_data[scale_id]
            current_length = np.count_nonzero(existing_data) if existing_data.dtype != object else len([x for x in existing_data if x != 0])
            end_index = min(current_length + len(new_data), self.num_values)
            self.scaler_data[scale_id][current_length:end_index] = new_data[:end_index-current_length]","class DaqmxDataReceiver(object):
    '''Receives raw scaler data for a DAQmx object and stores it in numpy
    arrays

    :ivar scaler_data: Dictionary mapping from scaler id to data for a scaler
    '''

    def __init__(self, obj, num_values, memmap_dir=None):
        '''Initialise data receiver for DAQmx backed by a numpy array

        :param obj: Object to store data for
        :param memmap_dir: Optional directory to store memory mmap files in.
        '''
        self.obj = obj
        self.num_values = num_values
        self.memmap_dir = memmap_dir if memmap_dir is not None else tempfile.gettempdir()
        self.scaler_data = {}
        self._data_arrays = {}
        self._current_indices = {}

    def append_scaler_data(self, scale_id, new_data):
        '''Append new DAQmx scaler data read from a segment
        '''
        if scale_id not in self.scaler_data:
            # Initialize memory-mapped array for this scaler
            filename = os.path.join(self.memmap_dir, f""scaler_{scale_id}_{id(self.obj)}.dat"")
            self._data_arrays[scale_id] = np.memmap(filename, dtype=np.float64, mode='w+', shape=(self.num_values,))
            self._current_indices[scale_id] = 0
            self.scaler_data[scale_id] = self._data_arrays[scale_id]
        
        new_data = np.asarray(new_data)
        current_idx = self._current_indices[scale_id]
        end_idx = min(current_idx + len(new_data), self.num_values)
        
        if current_idx < self.num_values:
            self._data_arrays[scale_id][current_idx:end_idx] = new_data[:end_idx-current_idx]
            self._current_indices[scale_id] = end_idx",full_docstr,0.6413301662707838,0.5107398568019093,0.4412470023980815,0.5748218527315915,0.4728274260366286,0.6421800947867299,0.4489311163895487,0.36666666666666664,0.8579789996147156,0.8991392254829407,0.8780770301818848,0.8948464393615723,0.8027485393258432,0.6893424036281178,0.5239179954441913,0.44393592677345534,0.5714285714285715,0.4705859907602272,0.6481069042316259,0.44642857142857145,0.36017897091722595,0.8742647767066956,0.9019805192947388,0.8879063725471497,0.89913010597229,0.8104857661290328,0.6714285714285714,0.5167464114832536,0.4375,0.5761904761904761,0.5029703273818561,0.6627358490566038,0.48226950354609927,0.3981042654028436,0.8742691278457642,0.9079203605651855,0.890777051448822,0.9044390916824341,0.822605493562232,0.4616246835015423,0.4059815811346107,0.5078855739241899,0.5466666666666666,0.3859649122807017,0.4586590854499285,0.4070303000672616,0.5209393750657861,0.5733333333333334,0.3333333333333333,0.5014017393284871,0.4448638415259808,0.5263571508756867,0.6133333333333333,0.4210526315789473
252199,aws/sagemaker-python-sdk,aws_sagemaker-python-sdk/src/sagemaker/model_monitor/monitoring_files.py,sagemaker.model_monitor.monitoring_files.ModelMonitoringFile,"class ModelMonitoringFile(object):
    """"""Represents a file with a body and an S3 uri.""""""

    def __init__(self, body_dict, file_s3_uri, kms_key, sagemaker_session):
        """"""Initializes a file with a body and an S3 uri.

        Args:
            body_dict (str): The body of the JSON file.
            file_s3_uri (str): The uri of the JSON file.
            kms_key (str): The kms key to be used to decrypt the file in S3.
            sagemaker_session (sagemaker.session.Session): A SageMaker Session
                object, used for SageMaker interactions (default: None). If not
                specified, one is created using the default AWS configuration
                chain.

        """"""
        self.body_dict = body_dict
        self.file_s3_uri = file_s3_uri
        self.kms_key = kms_key
        self.session = sagemaker_session

    def save(self, new_save_location_s3_uri=None):
        """"""Save the current instance's body to s3 using the instance's s3 path.

        The S3 path can be overridden by providing one. This also overrides the
        default save location for this object.

        Args:
            new_save_location_s3_uri (str): Optional. The S3 path to save the file to. If not
                provided, the file is saved in place in S3. If provided, the file's S3 path is
                permanently updated.

        Returns:
            str: The s3 location to which the file was saved.

        """"""
        if new_save_location_s3_uri is not None:
            self.file_s3_uri = new_save_location_s3_uri

        return s3.S3Uploader.upload_string_as_file_body(
            body=json.dumps(self.body_dict),
            desired_s3_uri=self.file_s3_uri,
            kms_key=self.kms_key,
            sagemaker_session=self.session,
        )","class ModelMonitoringFile(object):
    '''Represents a file with a body and an S3 uri.'''

    def __init__(self, body_dict, file_s3_uri, kms_key, sagemaker_session):
    '''Initializes a file with a body and an S3 uri.

        Args:
            body_dict (str): The body of the JSON file.
            file_s3_uri (str): The uri of the JSON file.
            kms_key (str): The kms key to be used to decrypt the file in S3.
            sagemaker_session (sagemaker.session.Session): A SageMaker Session
                object, used for SageMaker interactions (default: None). If not
                specified, one is created using the default AWS configuration
                chain.

        '''
        pass

    def save(self, new_save_location_s3_uri=None):
    '''Save the current instance's body to s3 using the instance's s3 path.

        The S3 path can be overridden by providing one. This also overrides the
        default save location for this object.

        Args:
            new_save_location_s3_uri (str): Optional. The S3 path to save the file to. If not
                provided, the file is saved in place in S3. If provided, the file's S3 path is
                permanently updated.

        Returns:
            str: The s3 location to which the file was saved.

        '''
                pass

",3,3,snippet_372,1.0,"class ModelMonitoringFile(object):
    '''Represents a file with a body and an S3 uri.'''

    def __init__(self, body_dict, file_s3_uri, kms_key, sagemaker_session=None):
        '''Initializes a file with a body and an S3 uri.

        Args:
            body_dict (dict): The body of the JSON file.
            file_s3_uri (str): The uri of the JSON file.
            kms_key (str): The kms key to be used to decrypt the file in S3.
            sagemaker_session (sagemaker.session.Session): A SageMaker Session
                object, used for SageMaker interactions (default: None). If not
                specified, one is created using the default AWS configuration
                chain.
        '''
        self.body_dict = body_dict
        self.file_s3_uri = file_s3_uri
        self.kms_key = kms_key
        self.sagemaker_session = sagemaker_session or _SageMakerSession()

    def save(self, new_save_location_s3_uri=None):
        '''Save the current instance's body to s3 using the instance's s3 path.

        The S3 path can be overridden by providing one. This also overrides the
        default save location for this object.

        Args:
            new_save_location_s3_uri (str): Optional. The S3 path to save the file to. If not
                provided, the file is saved in place in S3. If provided, the file's S3 path is
                permanently updated.

        Returns:
            str: The s3 location to which the file was saved.
        '''
        if new_save_location_s3_uri:
            self.file_s3_uri = new_save_location_s3_uri

        parsed = urlparse(self.file_s3_uri)
        if parsed.scheme != ""s3"" or not parsed.netloc or not parsed.path:
            raise ValueError(f""Invalid S3 URI: {self.file_s3_uri}"")

        bucket = parsed.netloc
        key = parsed.path.lstrip(""/"")

        json_body = json.dumps(self.body_dict).encode(""utf-8"")
        s3_client = self.sagemaker_session.boto_session.client(""s3"")

        put_args = {
            ""Bucket"": bucket,
            ""Key"": key,
            ""Body"": json_body,
        }
        if self.kms_key:
            put_args[""ServerSideEncryption""] = ""aws:kms""
            put_args[""SSEKMSKeyId""] = self.kms_key

        s3_client.put_object(**put_args)
        return self.file_s3_uri","class ModelMonitoringFile(object):
    '''Represents a file with a body and an S3 uri.'''

    def __init__(self, body_dict, file_s3_uri, kms_key, sagemaker_session):
        '''Initializes a file with a body and an S3 uri.

        Args:
            body_dict (str): The body of the JSON file.
            file_s3_uri (str): The uri of the JSON file.
            kms_key (str): The kms key to be used to decrypt the file in S3.
            sagemaker_session (sagemaker.session.Session): A SageMaker Session
                object, used for SageMaker interactions (default: None). If not
                specified, one is created using the default AWS configuration
                chain.

        '''
        self.body_dict = body_dict
        self.file_s3_uri = file_s3_uri
        self.kms_key = kms_key
        self.sagemaker_session = sagemaker_session or Session()

    def save(self, new_save_location_s3_uri=None):
        '''Save the current instance's body to s3 using the instance's s3 path.

        The S3 path can be overridden by providing one. This also overrides the
        default save location for this object.

        Args:
            new_save_location_s3_uri (str): Optional. The S3 path to save the file to. If not
                provided, the file is saved in place in S3. If provided, the file's S3 path is
                permanently updated.

        Returns:
            str: The s3 location to which the file was saved.

        '''
        if new_save_location_s3_uri:
            self.file_s3_uri = new_save_location_s3_uri
        
        # Convert body_dict to JSON string
        body_json = json.dumps(self.body_dict)
        
        # Upload to S3
        self.sagemaker_session.upload_data(
            path=body_json,
            key_prefix=self._get_key_prefix(),
            bucket=self._get_bucket(),
            kms_key=self.kms_key
        )
        
        return self.file_s3_uri
    
    def _get_bucket(self):
        '''Extract bucket name from S3 URI'''
        return self.file_s3_uri.split('/')[2]
    
    def _get_key_prefix(self):
        '''Extract key prefix from S3 URI'''
        return '/'.join(self.file_s3_uri.split('/')[3:])","class ModelMonitoringFile(object):
    '''Represents a file with a body and an S3 uri.'''

    def __init__(self, body_dict, file_s3_uri, kms_key, sagemaker_session):
        '''Initializes a file with a body and an S3 uri.

        Args:
            body_dict (str): The body of the JSON file.
            file_s3_uri (str): The uri of the JSON file.
            kms_key (str): The kms key to be used to decrypt the file in S3.
            sagemaker_session (sagemaker.session.Session): A SageMaker Session
                object, used for SageMaker interactions (default: None). If not
                specified, one is created using the default AWS configuration
                chain.

        '''
        self.body_dict = body_dict
        self.file_s3_uri = file_s3_uri
        self.kms_key = kms_key
        self.sagemaker_session = sagemaker_session

    def save(self, new_save_location_s3_uri=None):
        '''Save the current instance's body to s3 using the instance's s3 path.

        The S3 path can be overridden by providing one. This also overrides the
        default save location for this object.

        Args:
            new_save_location_s3_uri (str): Optional. The S3 path to save the file to. If not
                provided, the file is saved in place in S3. If provided, the file's S3 path is
                permanently updated.

        Returns:
            str: The s3 location to which the file was saved.

        '''
        if new_save_location_s3_uri:
            self.file_s3_uri = new_save_location_s3_uri
        
        body_json = json.dumps(self.body_dict)
        
        if self.kms_key:
            self.sagemaker_session.upload_string_as_file_body(
                body=body_json,
                desired_s3_uri=self.file_s3_uri,
                kms_key=self.kms_key
            )
        else:
            self.sagemaker_session.upload_string_as_file_body(
                body=body_json,
                desired_s3_uri=self.file_s3_uri
            )
        
        return self.file_s3_uri",full_docstr,0.8706293706293706,0.8070175438596492,0.7711267605633803,0.8356643356643356,0.671092514815117,0.75,0.6560747663551402,0.6142322097378277,0.9142767190933228,0.9710633754730225,0.9418148398399353,0.9650691747665405,0.7957467234042559,0.8896797153024911,0.842857142857143,0.8136200716845877,0.8540925266903915,0.7148682524355449,0.7649402390438247,0.7085828343313373,0.674,0.939725399017334,0.978142261505127,0.9585490226745605,0.974159836769104,0.8286795530726258,0.9368029739776951,0.9067164179104477,0.8838951310861423,0.9107806691449813,0.8253758411416112,0.8619153674832962,0.8214285714285714,0.7941834451901566,0.9751197099685669,0.9819429516792297,0.9785193800926208,0.9812563061714172,0.8948728461538461,0.6874019586367582,0.6673365569511475,0.8236854190100269,0.6222222222222222,0.6363636363636364,0.8007845673575791,0.7138679453755203,0.8387652735497455,0.7111111111111111,0.9393939393939394,0.7942140968438698,0.8171713825721184,0.8465536916720475,0.7555555555555555,0.7575757575757576
319437,cronofy/pycronofy,pycronofy/auth.py,pycronofy.auth.Auth,"class Auth(object):
    """"""
    Hold OAuth/Access Data, convenience methods.

    https://www.cronofy.com/developers/api/#authentication
    """"""

    def __init__(self, client_id=None, client_secret=None, access_token=None, refresh_token=None, token_expiration=None):
        """"""
        :param string client_id: OAuth Client ID. (Optional, default None)
        :param string client_secret: OAuth Client Secret. (Optional, default None)
        :param string access_token: Access Token for User's Account. (Optional, default None)
        :param string refresh_token: Existing Refresh Token for User's Account. (Optional, default None)
        :param datetime.datetime token_expiration: Datetime token expires. (Optional, default None)
        :param bool settings.DEBUG: Instantiate in debug mode. (Optional, default False).
        """"""
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = access_token
        self.refresh_token = refresh_token
        self.token_expiration = token_expiration
        self.redirect_uri = ''

    def get_authorization(self):
        """"""Get the authorization header with the currently active token

        :return: 'Authorization' header
        :rtype: ``string``
        """"""
        return 'Bearer %s' % self.access_token

    def get_api_key(self):
        """"""Get the authorization header with the api key token

        :return: 'Authorization' header
        :rtype: ``string``
        """"""
        return 'Bearer %s' % self.client_secret

    def update(self, **kwargs):
        """"""Update fields

        :param KeywordArguments kwargs: Fields and values to update.
        """"""
        for kw in kwargs:
            setattr(self, kw, kwargs[kw])","class Auth(object):
    '''
    Hold OAuth/Access Data, convenience methods.

    https://www.cronofy.com/developers/api/#authentication
    '''

    def __init__(self, client_id=None, client_secret=None, access_token=None, refresh_token=None, token_expiration=None):
    '''
        :param string client_id: OAuth Client ID. (Optional, default None)
        :param string client_secret: OAuth Client Secret. (Optional, default None)
        :param string access_token: Access Token for User's Account. (Optional, default None)
        :param string refresh_token: Existing Refresh Token for User's Account. (Optional, default None)
        :param datetime.datetime token_expiration: Datetime token expires. (Optional, default None)
        :param bool settings.DEBUG: Instantiate in debug mode. (Optional, default False).
        '''
        pass

    def get_authorization(self):
    '''Get the authorization header with the currently active token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        pass

    def get_api_key(self):
    '''Get the authorization header with the api key token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        pass

    def update(self, **kwargs):
    '''Update fields

        :param KeywordArguments kwargs: Fields and values to update.
        '''
        pass

",5,5,snippet_561,1.0,"class Auth(object):
    '''
    Hold OAuth/Access Data, convenience methods.

    https://www.cronofy.com/developers/api/#authentication
    '''

    def __init__(self, client_id=None, client_secret=None,
                 access_token=None, refresh_token=None,
                 token_expiration=None):
        '''
        :param string client_id: OAuth Client ID. (Optional, default None)
        :param string client_secret: OAuth Client Secret. (Optional, default None)
        :param string access_token: Access Token for User's Account. (Optional, default None)
        :param string refresh_token: Existing Refresh Token for User's Account. (Optional, default None)
        :param datetime.datetime token_expiration: Datetime token expires. (Optional, default None)
        '''
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = access_token
        self.refresh_token = refresh_token
        if token_expiration and not isinstance(token_expiration, datetime):
            raise TypeError(""token_expiration must be a datetime object"")
        self.token_expiration = token_expiration

    def get_authorization(self):
        '''Get the authorization header with the currently active token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        if not self.access_token:
            raise RuntimeError(""No access token available"")
        return ""Bearer {}"".format(self.access_token)

    def get_api_key(self):
        '''Get the authorization header with the api key token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        if not self.client_secret:
            raise RuntimeError(""No API key (client_secret) available"")
        return ""Bearer {}"".format(self.client_secret)

    def update(self, **kwargs):
        '''Update fields

        :param KeywordArguments kwargs: Fields and values to update.
        '''
        for key, value in kwargs.items():
            if not hasattr(self, key):
                raise AttributeError(""Unknown field '{}'"".format(key))
            setattr(self, key, value)","class Auth(object):
    '''
    Hold OAuth/Access Data, convenience methods.

    https://www.cronofy.com/developers/api/#authentication
    '''

    def __init__(self, client_id=None, client_secret=None, access_token=None, refresh_token=None, token_expiration=None):
        '''
        :param string client_id: OAuth Client ID. (Optional, default None)
        :param string client_secret: OAuth Client Secret. (Optional, default None)
        :param string access_token: Access Token for User's Account. (Optional, default None)
        :param string refresh_token: Existing Refresh Token for User's Account. (Optional, default None)
        :param datetime.datetime token_expiration: Datetime token expires. (Optional, default None)
        :param bool settings.DEBUG: Instantiate in debug mode. (Optional, default False).
        '''
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = access_token
        self.refresh_token = refresh_token
        self.token_expiration = token_expiration

    def get_authorization(self):
        '''Get the authorization header with the currently active token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        if self.access_token:
            return 'Bearer %s' % self.access_token
        return None

    def get_api_key(self):
        '''Get the authorization header with the api key token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        if self.client_secret:
            return 'Bearer %s' % self.client_secret
        return None

    def update(self, **kwargs):
        '''Update fields

        :param KeywordArguments kwargs: Fields and values to update.
        '''
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)","class Auth(object):
    '''
    Hold OAuth/Access Data, convenience methods.

    https://www.cronofy.com/developers/api/#authentication
    '''

    def __init__(self, client_id=None, client_secret=None, access_token=None, refresh_token=None, token_expiration=None):
        '''
        :param string client_id: OAuth Client ID. (Optional, default None)
        :param string client_secret: OAuth Client Secret. (Optional, default None)
        :param string access_token: Access Token for User's Account. (Optional, default None)
        :param string refresh_token: Existing Refresh Token for User's Account. (Optional, default None)
        :param datetime.datetime token_expiration: Datetime token expires. (Optional, default None)
        :param bool settings.DEBUG: Instantiate in debug mode. (Optional, default False).
        '''
        self.client_id = client_id
        self.client_secret = client_secret
        self.access_token = access_token
        self.refresh_token = refresh_token
        self.token_expiration = token_expiration

    def get_authorization(self):
        '''Get the authorization header with the currently active token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        if self.access_token:
            return f""Bearer {self.access_token}""
        return None

    def get_api_key(self):
        '''Get the authorization header with the api key token

        :return: 'Authorization' header
        :rtype: ``string``
        '''
        if self.client_secret:
            return f""Bearer {self.client_secret}""
        return None

    def update(self, **kwargs):
        '''Update fields

        :param KeywordArguments kwargs: Fields and values to update.
        '''
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)",full_docstr,0.8251121076233184,0.7792792792792791,0.7375565610859728,0.8206278026905831,0.6747671279095305,0.7533632286995515,0.6584269662921348,0.6193693693693694,0.9109553098678589,0.9432968497276306,0.92684406042099,0.9399597644805908,0.8656971359223301,0.9380952380952381,0.8995215311004785,0.8653846153846154,0.9333333333333333,0.8415574870650818,0.8909090909090909,0.8411458333333334,0.8015665796344648,0.9672979116439819,0.9750428199768066,0.9711549282073975,0.9742628931999207,0.9199142207792207,0.9285714285714286,0.8708133971291866,0.8365384615384616,0.9238095238095239,0.8158145934419195,0.87146529562982,0.8118556701030928,0.7674418604651163,0.9635490775108337,0.9720637798309326,0.9677876830101013,0.971205472946167,0.8982694155844155,0.6714873558831553,0.5757028815385863,0.6628892481251134,0.5636363636363636,0.8837209302325582,0.764078649288561,0.7265577459694182,0.7733086482249942,0.6727272727272727,0.8837209302325582,0.7132696993460432,0.7056455559170821,0.7364395839618054,0.5272727272727272,0.8837209302325582
135512,JdeRobot/base,src/libs/comm_py/comm/ice/laserIceClient.py,comm.ice.laserIceClient.LaserIceClient,"class LaserIceClient:
    '''
        Laser Ice Client. Recives LaserData from Ice interface running Laser update method in a thread.
    '''
    def __init__(self,ic,prefix, start = False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.laser = Laser(ic,prefix)

        self.kill_event = threading.Event()
        self.thread = ThreadSensor(self.laser, self.kill_event)
        self.thread.daemon = True

        if start:
            self.start()

    
    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.clear()
        self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.kill_event.set()

    def getLaserData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        return self.laser.getLaserData()

    def hasproxy (self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.laser.hasproxy()","class LaserIceClient:
    '''
        Laser Ice Client. Recives LaserData from Ice interface running Laser update method in a thread.
    '''

    def __init__(self,ic,prefix, start = False):
    '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        pass

    def start(self):
    '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def stop(self):
    '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        pass

    def getLaserData(self):
    '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        pass

    def hasproxy (self):
    '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        pass

",6,6,snippet_154,0.25,"class LaserIceClient:
    '''
        Laser Ice Client. Recives LaserData from Ice interface running Laser update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
            LaserIceClient Constructor.

            @param ic: Ice Communicator
            @param prefix: prefix name of client in config file
            @param start: indicates if start automatically the client

            @type ic: Ice Communicator
            @type prefix: String
            @type start: Boolean
        '''
        self.ic = ic
        self.props = ic.getProperties()
        try:
            proxy_str = self.props.getProperty(prefix + "".Proxy"")
        except Ice.PropertyException:
            proxy_str = """"
        self._proxy = None
        if proxy_str:
            self._proxy = Ice.stringToProxy(proxy_str)
            # If you have a specific Slice-generated proxy class, use checkedCast here:
            # from Laser import LaserPrx
            # self._proxy = LaserPrx.checkedCast(self._proxy)
        self._thread = None
        self._running = False
        self._lock = threading.Lock()
        self._laserData = None
        if start:
            self.start()

    def start(self):
        '''
            Starts the client. If client is stopped you can not start again, Threading.Thread raised error
        '''
        if not self._proxy:
            raise RuntimeError(""Proxy has not been created"")
        if self._running:
            raise RuntimeError(""Client already started"")
        self._running = True
        self._thread = threading.Thread(target=self._run)
        self._thread.daemon = True
        self._thread.start()

    def _run(self):
        while self._running:
            try:
                # Assuming the proxy has a method getLaserData()
                data = self._proxy.getLaserData()
                with self._lock:
                    self._laserData = data
            except Exception:
                pass
            time.sleep(0.01)

    def stop(self):
        '''
            Stops the client. If client is stopped you can not start again, Threading.Thread raised error
        '''
        if not self._running:
            raise RuntimeError(""Client is not running"")
        self._running = False
        if self._thread:
            self._thread.join()
            self._thread = None

    def getLaserData(self):
        '''
            Returns last LaserData.

            @return last JdeRobotTypes LaserData saved
        '''
        with self._lock:
            return self._laserData

    def hasproxy(self):
        '''
            Returns if proxy has been created or not.

            @return if proxy has been created or not (Boolean)
        '''
        return self._proxy is not None","class LaserIceClient:
    '''
        Laser Ice Client. Recives LaserData from Ice interface running Laser update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.laser_proxy = None
        self.laser_data = None
        self.running = False
        self.thread = None
        self.lock = threading.Lock()
        
        # Try to create proxy
        try:
            proxy_name = prefix + "".Proxy""
            self.laser_proxy = self.ic.propertyToProxy(proxy_name)
            if self.laser_proxy:
                # Assuming JdeRobotTypes.LaserPrx.checkedCast or similar
                # This would depend on the actual Ice interface
                self.laser_proxy = self.laser_proxy  # Placeholder
        except Exception:
            self.laser_proxy = None
            
        if start:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if self.thread is not None and self.thread.is_alive():
            return
            
        if self.laser_proxy is None:
            raise Exception(""No proxy available to start client"")
            
        self.running = True
        self.thread = threading.Thread(target=self._run)
        self.thread.daemon = True
        self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.running = False
        if self.thread and self.thread.is_alive():
            self.thread.join()

    def getLaserData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        with self.lock:
            return self.laser_data

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.laser_proxy is not None

    def _run(self):
        '''
        Internal method to run in thread
        '''
        while self.running:
            try:
                if self.laser_proxy:
                    # Assuming getLaserData() method exists on proxy
                    # This would depend on the actual Ice interface
                    new_data = self.laser_proxy.getLaserData()
                    with self.lock:
                        self.laser_data = new_data
                time.sleep(0.05)  # 20 Hz update rate
            except Exception:
                # Handle connection errors or other exceptions
                time.sleep(0.1)","class LaserIceClient:
    '''
        Laser Ice Client. Recives LaserData from Ice interface running Laser update method in a thread.
    '''

    def __init__(self, ic, prefix, start=False):
        '''
        LaserIceClient Contructor.

        @param ic: Ice Communicator
        @param prefix: prefix name of client in config file
        @param start: indicates if start automatically the client

        @type ic: Ice Communicator
        @type prefix: String
        @type start: Boolean
        '''
        self.ic = ic
        self.prefix = prefix
        self.proxy = None
        self.laserData = None
        self.lock = threading.Lock()
        self.running = False
        self.thread = None
        
        try:
            proxyString = self.ic.getProperties().getProperty(self.prefix + "".Proxy"")
            if proxyString:
                self.proxy = self.ic.stringToProxy(proxyString)
        except:
            self.proxy = None
            
        if start:
            self.start()

    def start(self):
        '''
        Starts the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        if not self.running and self.proxy:
            self.running = True
            self.thread = threading.Thread(target=self._update_thread)
            self.thread.daemon = True
            self.thread.start()

    def stop(self):
        '''
        Stops the client. If client is stopped you can not start again, Threading.Thread raised error

        '''
        self.running = False
        if self.thread:
            self.thread.join()

    def _update_thread(self):
        while self.running:
            try:
                if self.proxy:
                    data = self.proxy.getLaserData()
                    with self.lock:
                        self.laserData = data
            except:
                pass
            time.sleep(0.1)

    def getLaserData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        with self.lock:
            return self.laserData

    def hasproxy(self):
        '''
        Returns if proxy has ben created or not. 

        @return if proxy has ben created or not (Boolean)

        '''
        return self.proxy is not None",full_docstr,0.6439232409381663,0.556745182012848,0.50752688172043,0.6183368869936035,0.443728912408314,0.5057915057915058,0.43907156673114117,0.39341085271317827,0.8558735847473145,0.922608494758606,0.8879889845848083,0.9154702425003052,0.79166875,0.6208251473477406,0.5601577909270217,0.5188118811881188,0.593320235756385,0.4449396819750124,0.49080882352941174,0.44014732965009207,0.4077490774907749,0.8595755696296692,0.9370867013931274,0.8966590762138367,0.9287120699882507,0.7934698847262247,0.7338129496402876,0.6650602409638555,0.6246973365617433,0.7146282973621103,0.5826845004817902,0.6414634146341464,0.5745721271393643,0.5367647058823529,0.8928769826889038,0.9334732294082642,0.912723958492279,0.9292483329772949,0.8088908,0.5716575768739497,0.4267793956091186,0.7537634414375073,0.6805555555555556,0.425531914893617,0.5836753324334001,0.4200692942910308,0.8159322718491893,0.6944444444444444,0.4042553191489361,0.6105725707039038,0.5710921009893897,0.8150516097222066,0.6944444444444444,0.3617021276595745
212220,abilian/abilian-core,abilian_abilian-core/src/abilian/services/tagging/service.py,abilian.services.tagging.service.TagService,"class TagService:
    """"""The tag service.""""""

    def tag(self, obj, term, user=None):
        """"""Apply a tag on a taggable object.

        If user is None, uses the current logged in user.
        """"""

    def untag(self, obj, term, user=None):
        """"""Remove the given tag from the given object.

        See tag().
        """"""

    def get_objects_tagged_with(self, term):
        """"""Returns a list of objects tagged with a given term.""""""

    def get_tags_applied_on(self, obj):
        """"""Returns a list of tags applied on a given document.""""""","class TagService:
    '''The tag service.'''

    def tag(self, obj, term, user=None):
    '''Apply a tag on a taggable object.

        If user is None, uses the current logged in user.
        '''
        pass

    def untag(self, obj, term, user=None):
    '''Remove the given tag from the given object.

        See tag().
        '''
        pass

    def get_objects_tagged_with(self, term):
    '''Returns a list of objects tagged with a given term.'''
        pass

    def get_tags_applied_on(self, obj):
    '''Returns a list of tags applied on a given document.'''
        pass

",5,5,snippet_287,1.0,"class TagService:
    '''The tag service.'''

    def __init__(self):
        # Map each object to a set of tag terms
        self._tags_by_obj = {}
        # Map each tag term to a set of objects
        self._objs_by_tag = {}

    def tag(self, obj, term, user=None):
        '''Apply a tag on a taggable object.

        If user is None, uses the current logged in user.
        '''
        # Add the term to the object's tag set
        self._tags_by_obj.setdefault(obj, set()).add(term)
        # Add the object to the term's object set
        self._objs_by_tag.setdefault(term, set()).add(obj)

    def untag(self, obj, term, user=None):
        '''Remove the given tag from the given object.

        See tag().
        '''
        # Remove the term from the object's tag set
        tags = self._tags_by_obj.get(obj)
        if tags and term in tags:
            tags.remove(term)
            if not tags:
                del self._tags_by_obj[obj]
        # Remove the object from the term's object set
        objs = self._objs_by_tag.get(term)
        if objs and obj in objs:
            objs.remove(obj)
            if not objs:
                del self._objs_by_tag[term]

    def get_objects_tagged_with(self, term):
        '''Returns a list of objects tagged with a given term.'''
        return list(self._objs_by_tag.get(term, []))

    def get_tags_applied_on(self, obj):
        '''Returns a list of tags applied on a given document.'''
        return list(self._tags_by_obj.get(obj, []))","class TagService:
    '''The tag service.'''

    def __init__(self):
        self.tags = {}  # obj_id -> {term: user}
        self.objects_by_tag = {}  # term -> set of obj_ids

    def _get_user(self, user):
        '''Helper to get current user if none provided.'''
        if user is not None:
            return user
        # In a real implementation, this would get the current logged in user
        # For now, we'll return a default user identifier
        return ""current_user""

    def _get_obj_id(self, obj):
        '''Helper to get a consistent identifier for an object.'''
        return id(obj)

    def tag(self, obj, term, user=None):
        '''Apply a tag on a taggable object.

        If user is None, uses the current logged in user.
        '''
        user = self._get_user(user)
        obj_id = self._get_obj_id(obj)
        
        if obj_id not in self.tags:
            self.tags[obj_id] = {}
        
        # Store the tag with the user who applied it
        self.tags[obj_id][term] = user
        
        # Update the reverse index
        if term not in self.objects_by_tag:
            self.objects_by_tag[term] = set()
        self.objects_by_tag[term].add(obj_id)

    def untag(self, obj, term, user=None):
        '''Remove the given tag from the given object.

        See tag().
        '''
        user = self._get_user(user)
        obj_id = self._get_obj_id(obj)
        
        if obj_id in self.tags and term in self.tags[obj_id]:
            # In a real implementation, you might want to check if the user
            # has permission to remove this tag
            del self.tags[obj_id][term]
            
            # Clean up empty dictionaries
            if not self.tags[obj_id]:
                del self.tags[obj_id]
            
            # Update the reverse index
            if term in self.objects_by_tag:
                self.objects_by_tag[term].discard(obj_id)
                
                # Clean up empty sets
                if not self.objects_by_tag[term]:
                    del self.objects_by_tag[term]

    def get_objects_tagged_with(self, term):
        '''Returns a list of objects tagged with a given term.'''
        if term not in self.objects_by_tag:
            return []
        
        # In a real implementation, you would return the actual objects
        # For now, we'll return the object IDs
        return list(self.objects_by_tag[term])

    def get_tags_applied_on(self, obj):
        '''Returns a list of tags applied on a given document.'''
        obj_id = self._get_obj_id(obj)
        
        if obj_id not in self.tags:
            return []
        
        return list(self.tags[obj_id].keys())","class TagService:
    '''The tag service.'''
    
    def __init__(self):
        self._tags = {}  # {term: set of objects}
        self._object_tags = {}  # {object_id: set of (term, user) tuples}
        self._current_user = None
    
    def set_current_user(self, user):
        self._current_user = user

    def tag(self, obj, term, user=None):
        '''Apply a tag on a taggable object.

        If user is None, uses the current logged in user.
        '''
        if user is None:
            user = self._current_user
        
        obj_id = id(obj)
        
        if term not in self._tags:
            self._tags[term] = set()
        self._tags[term].add(obj)
        
        if obj_id not in self._object_tags:
            self._object_tags[obj_id] = set()
        self._object_tags[obj_id].add((term, user))

    def untag(self, obj, term, user=None):
        '''Remove the given tag from the given object.

        See tag().
        '''
        if user is None:
            user = self._current_user
        
        obj_id = id(obj)
        
        if term in self._tags:
            self._tags[term].discard(obj)
            if not self._tags[term]:
                del self._tags[term]
        
        if obj_id in self._object_tags:
            self._object_tags[obj_id].discard((term, user))
            if not self._object_tags[obj_id]:
                del self._object_tags[obj_id]

    def get_objects_tagged_with(self, term):
        '''Returns a list of objects tagged with a given term.'''
        return list(self._tags.get(term, set()))

    def get_tags_applied_on(self, obj):
        '''Returns a list of tags applied on a given document.'''
        obj_id = id(obj)
        tags = self._object_tags.get(obj_id, set())
        return [term for term, user in tags]",full_docstr,0.517799352750809,0.50814332247557,0.4721311475409836,0.517799352750809,0.2742619612397333,0.3012987012987013,0.2760416666666667,0.24804177545691905,0.7699922323226929,0.8883651494979858,0.8249540328979492,0.8749148845672607,0.7616846261682245,0.34782608695652173,0.3406113537117904,0.31578947368421056,0.34782608695652173,0.16606636759038426,0.1836734693877551,0.16666666666666666,0.14960629921259844,0.7589190006256104,0.8881311416625977,0.8184566497802734,0.8732631206512451,0.7270056973293761,0.48929663608562696,0.47384615384615386,0.4458204334365326,0.48929663608562696,0.22131444178069776,0.24261603375527427,0.2219873150105708,0.20127118644067796,0.7751448154449463,0.8906702995300293,0.8289016485214233,0.8775909543037415,0.7339982450331122,0.4894022064429157,0.260210481093599,0.6644313117110309,0.4615384615384615,0.5714285714285714,0.4629775531263528,0.1545118678273477,0.6644313117110309,0.4615384615384615,0.5714285714285714,0.4529423011712266,0.2572280028639855,0.6644313117110309,0.4615384615384615,0.4285714285714285
121687,Faylixe/pygame_vkeyboard,Faylixe_pygame_vkeyboard/pygame_vkeyboard/vkeyboard.py,pygame_vkeyboard.vkeyboard.VKeyRow,"class VKeyRow(object):
    """"""A VKeyRow defines a keyboard row which is composed of a list of
    VKey.

    This class aims to be created internally after parsing a keyboard
    layout model. It is used to optimize collision detection, by first
    checking row collision, then internal row key detection.
    """"""

    def __init__(self):
        """"""Default row constructor. """"""
        self.keys = []
        self.height = 0
        self.position = (0, 0)
        self.space = None

    def add_key(self, key, first=False):
        """"""Adds the given key to this row.

        Parameters
        ----------
        key:
            Key to be added to this row.
        first:
            Flag that indicates if key is added at the beginning or at the end.
        """"""
        if first:
            self.keys = [key] + self.keys
        else:
            self.keys.append(key)
        if isinstance(key, vkeys.VSpaceKey):
            self.space = key

    def set_size(self, position, size, padding):
        """"""Row size setter. The size correspond to the row height, since the
        row width is constraint to the surface width the associated keyboard
        belongs. Once size is settled, the size for each child keys is
        associated.

        Parameters
        ----------
        position:
            Position of this row.
        size:
            Size of the row (height)
        padding:
            Padding between key.
        """"""
        self.height = size
        self.position = position
        x = position[0]
        for key in self.keys:
            key.set_size(size, size)
            key.set_position(x, position[1])
            x += padding + key.rect.width

    def __len__(self):
        """"""len() operator overload.

        Returns
        -------
        len:
            Number of keys thi row contains.
        """"""
        return len(self.keys)","class VKeyRow(object):
    '''A VKeyRow defines a keyboard row which is composed of a list of
    VKey.

    This class aims to be created internally after parsing a keyboard
    layout model. It is used to optimize collision detection, by first
    checking row collision, then internal row key detection.
    '''

    def __init__(self):
    '''Default row constructor. '''
        pass

    def add_key(self, key, first=False):
    '''Adds the given key to this row.

        Parameters
        ----------
        key:
            Key to be added to this row.
        first:
            Flag that indicates if key is added at the beginning or at the end.
        '''
        pass

    def set_size(self, position, size, padding):
    '''Row size setter. The size correspond to the row height, since the
        row width is constraint to the surface width the associated keyboard
        belongs. Once size is settled, the size for each child keys is
        associated.

        Parameters
        ----------
        position:
            Position of this row.
        size:
            Size of the row (height)
        padding:
            Padding between key.
        '''
        pass

    def __len__(self):
    '''len() operator overload.

        Returns
        -------
        len:
            Number of keys thi row contains.
        '''
        pass

",5,5,snippet_127,0.7,"class VKeyRow(object):
    '''A VKeyRow defines a keyboard row which is composed of a list of
    VKey.

    This class aims to be created internally after parsing a keyboard
    layout model. It is used to optimize collision detection, by first
    checking row collision, then internal row key detection.
    '''

    def __init__(self):
        '''Default row constructor.'''
        self._keys = []
        self.position = (0, 0)
        self.height = 0
        self.padding = 0

    def add_key(self, key, first=False):
        '''Adds the given key to this row.

        Parameters
        ----------
        key:
            Key to be added to this row.
        first:
            Flag that indicates if key is added at the beginning or at the end.
        '''
        if first:
            self._keys.insert(0, key)
        else:
            self._keys.append(key)

    def set_size(self, position, size, padding):
        '''Row size setter. The size correspond to the row height, since the
        row width is constraint to the surface width the associated keyboard
        belongs. Once size is settled, the size for each child keys is
        associated.

        Parameters
        ----------
        position:
            Position of this row as a tuple (x, y).
        size:
            Size of the row (height).
        padding:
            Padding between keys.
        '''
        self.position = position
        self.height = size
        self.padding = padding

        x_cursor, y_cursor = position
        for key in self._keys:
            # assume each key has attributes `width`, `x`, `y`, and `height`
            key.x = x_cursor
            key.y = y_cursor
            key.height = size
            x_cursor += key.width + padding

    def __len__(self):
        '''len() operator overload.

        Returns
        -------
        len:
            Number of keys this row contains.
        '''
        return len(self._keys)","class VKeyRow(object):
    '''A VKeyRow defines a keyboard row which is composed of a list of
    VKey.

    This class aims to be created internally after parsing a keyboard
    layout model. It is used to optimize collision detection, by first
    checking row collision, then internal row key detection.
    '''

    def __init__(self):
        '''Default row constructor. '''
        self.keys = []
        self.position = None
        self.size = None
        self.padding = None

    def add_key(self, key, first=False):
        '''Adds the given key to this row.

        Parameters
        ----------
        key:
            Key to be added to this row.
        first:
            Flag that indicates if key is added at the beginning or at the end.
        '''
        if first:
            self.keys.insert(0, key)
        else:
            self.keys.append(key)

    def set_size(self, position, size, padding):
        '''Row size setter. The size correspond to the row height, since the
        row width is constraint to the surface width the associated keyboard
        belongs. Once size is settled, the size for each child keys is
        associated.

        Parameters
        ----------
        position:
            Position of this row.
        size:
            Size of the row (height)
        padding:
            Padding between key.
        '''
        self.position = position
        self.size = size
        self.padding = padding

    def __len__(self):
        '''len() operator overload.

        Returns
        -------
        len:
            Number of keys this row contains.
        '''
        return len(self.keys)","class VKeyRow(object):
    '''A VKeyRow defines a keyboard row which is composed of a list of
    VKey.

    This class aims to be created internally after parsing a keyboard
    layout model. It is used to optimize collision detection, by first
    checking row collision, then internal row key detection.
    '''

    def __init__(self):
        '''Default row constructor. '''
        self.keys = []

    def add_key(self, key, first=False):
        '''Adds the given key to this row.

        Parameters
        ----------
        key:
            Key to be added to this row.
        first:
            Flag that indicates if key is added at the beginning or at the end.
        '''
        if first:
            self.keys.insert(0, key)
        else:
            self.keys.append(key)

    def set_size(self, position, size, padding):
        '''Row size setter. The size correspond to the row height, since the
        row width is constraint to the surface width the associated keyboard
        belongs. Once size is settled, the size for each child keys is
        associated.

        Parameters
        ----------
        position:
            Position of this row.
        size:
            Size of the row (height)
        padding:
            Padding between key.
        '''
        self.position = position
        self.size = size
        self.padding = padding
        
        if self.keys:
            total_width = sum(getattr(key, 'width', 1) for key in self.keys)
            available_width = size[0] - (len(self.keys) - 1) * padding
            
            current_x = position[0]
            for key in self.keys:
                key_width = (getattr(key, 'width', 1) / total_width) * available_width
                key.set_size((current_x, position[1]), (key_width, size[1]))
                current_x += key_width + padding

    def __len__(self):
        '''len() operator overload.

        Returns
        -------
        len:
            Number of keys thi row contains.
        '''
        return len(self.keys)",full_docstr,0.8983050847457628,0.8,0.7521367521367521,0.8474576271186441,0.7130384545341294,0.8381201044386423,0.7068062827225131,0.6167979002624672,0.9446096420288086,0.95497727394104,0.949765145778656,0.9539303183555603,0.9071047540983607,0.9023255813953489,0.8457943925233645,0.8028169014084506,0.8837209302325583,0.6432011673353203,0.9463087248322147,0.8552188552188552,0.7837837837837838,0.9712594747543335,0.9376345276832581,0.9541508555412292,0.9408919215202332,0.8925329508196721,0.8999999999999999,0.807531380753138,0.7605042016806722,0.8333333333333333,0.7111105505772068,0.8148148148148148,0.7029702970297029,0.6277915632754343,0.9220010042190552,0.9380227327346802,0.9299429059028625,0.936395525932312,0.8325298550724637,0.5622782665016064,0.6183930386982586,0.6658488329287756,0.5714285714285714,0.3934426229508196,0.5604932222667296,0.677528962296469,0.6844673459741962,0.5357142857142857,0.3442622950819672,0.5828372900459726,0.6659802681283586,0.7124024595809025,0.5595238095238095,0.3934426229508196
280328,cackharot/suds-py3,cackharot_suds-py3/suds/xsd/sxbase.py,suds.xsd.sxbase.NodeFinder,"class NodeFinder:
    """"""
    Find nodes based on flexable criteria.  The I{matcher} is
    may be any object that implements a match(n) method.
    @ivar matcher: An object used as criteria for match.
    @type matcher: I{any}.match(n)
    @ivar limit: Limit the number of matches.  0=unlimited.
    @type limit: int
    """"""
    def __init__(self, matcher, limit=0):
        """"""
        @param matcher: An object used as criteria for match.
        @type matcher: I{any}.match(n)
        @param limit: Limit the number of matches.  0=unlimited.
        @type limit: int
        """"""
        self.matcher = matcher
        self.limit = limit

    def find(self, node, list):
        """"""
        Traverse the tree looking for matches.
        @param node: A node to match on.
        @type node: L{SchemaObject}
        @param list: A list to fill.
        @type list: list
        """"""
        if self.matcher.match(node):
            list.append(node)
            self.limit -= 1
            if self.limit == 0:
                return
        for c in node.rawchildren:
            self.find(c, list)
        return self","class NodeFinder:
    '''
    Find nodes based on flexable criteria.  The I{matcher} is
    may be any object that implements a match(n) method.
    @ivar matcher: An object used as criteria for match.
    @type matcher: I{any}.match(n)
    @ivar limit: Limit the number of matches.  0=unlimited.
    @type limit: int
    '''

    def __init__(self, matcher, limit=0):
    '''
        @param matcher: An object used as criteria for match.
        @type matcher: I{any}.match(n)
        @param limit: Limit the number of matches.  0=unlimited.
        @type limit: int
        '''
        pass

    def find(self, node, list):
    '''
        Traverse the tree looking for matches.
        @param node: A node to match on.
        @type node: L{SchemaObject}
        @param list: A list to fill.
        @type list: list
        '''
        pass

",3,3,snippet_463,0.3333333333333333,"class NodeFinder:
    '''
    Find nodes based on flexable criteria.  The I{matcher} is
    may be any object that implements a match(n) method.
    @ivar matcher: An object used as criteria for match.
    @type matcher: I{any}.match(n)
    @ivar limit: Limit the number of matches.  0=unlimited.
    @type limit: int
    '''

    def __init__(self, matcher, limit=0):
        '''
        @param matcher: An object used as criteria for match.
        @type matcher: I{any}.match(n)
        @param limit: Limit the number of matches.  0=unlimited.
        @type limit: int
        '''
        self.matcher = matcher
        self.limit = int(limit)

    def find(self, node, list):
        '''
        Traverse the tree looking for matches.
        @param node: A node to match on.
        @type node: L{SchemaObject}
        @param list: A list to fill.
        @type list: list
        '''
        if self.limit and len(list) >= self.limit:
            return
        # check this node
        if hasattr(self.matcher, 'match') and self.matcher.match(node):
            list.append(node)
            if self.limit and len(list) >= self.limit:
                return
        # traverse children if present
        children = getattr(node, 'children', None)
        if children:
            for child in children:
                self.find(child, list)
                if self.limit and len(list) >= self.limit:
                    return","class NodeFinder:
    '''
    Find nodes based on flexable criteria.  The I{matcher} is
    may be any object that implements a match(n) method.
    @ivar matcher: An object used as criteria for match.
    @type matcher: I{any}.match(n)
    @ivar limit: Limit the number of matches.  0=unlimited.
    @type limit: int
    '''

    def __init__(self, matcher, limit=0):
        '''
        @param matcher: An object used as criteria for match.
        @type matcher: I{any}.match(n)
        @param limit: Limit the number of matches.  0=unlimited.
        @type limit: int
        '''
        self.matcher = matcher
        self.limit = limit

    def find(self, node, list):
        '''
        Traverse the tree looking for matches.
        @param node: A node to match on.
        @type node: L{SchemaObject}
        @param list: A list to fill.
        @type list: list
        '''
        if self.limit > 0 and len(list) >= self.limit:
            return
            
        if self.matcher.match(node):
            list.append(node)
            
        if self.limit > 0 and len(list) >= self.limit:
            return
            
        for child in node.children:
            self.find(child, list)","class NodeFinder:
    '''
    Find nodes based on flexable criteria.  The I{matcher} is
    may be any object that implements a match(n) method.
    @ivar matcher: An object used as criteria for match.
    @type matcher: I{any}.match(n)
    @ivar limit: Limit the number of matches.  0=unlimited.
    @type limit: int
    '''

    def __init__(self, matcher, limit=0):
        '''
        @param matcher: An object used as criteria for match.
        @type matcher: I{any}.match(n)
        @param limit: Limit the number of matches.  0=unlimited.
        @type limit: int
        '''
        self.matcher = matcher
        self.limit = limit

    def find(self, node, list):
        '''
        Traverse the tree looking for matches.
        @param node: A node to match on.
        @type node: L{SchemaObject}
        @param list: A list to fill.
        @type list: list
        '''
        if self.limit > 0 and len(list) >= self.limit:
            return
        
        if self.matcher.match(node):
            list.append(node)
            if self.limit > 0 and len(list) >= self.limit:
                return
        
        if hasattr(node, 'children'):
            for child in node.children:
                self.find(child, list)
                if self.limit > 0 and len(list) >= self.limit:
                    return",full_docstr,0.8597560975609756,0.7914110429447853,0.7592592592592592,0.8414634146341463,0.695230212028443,0.7580645161290323,0.686084142394822,0.6461038961038961,0.9324204921722412,0.9659868478775024,0.9489068984985352,0.9625218510627747,0.8377209210526315,0.9403973509933774,0.8866666666666667,0.8523489932885906,0.9139072847682119,0.8237753178265848,0.8834586466165414,0.8188679245283019,0.7727272727272727,0.9690872430801392,0.970700740814209,0.9698932766914368,0.9705390930175781,0.9017866964285713,0.8987341772151899,0.8407643312101911,0.814102564102564,0.8797468354430379,0.7488519836969082,0.8082191780821918,0.7422680412371134,0.7,0.9521619081497192,0.9695109128952026,0.9607580900192261,0.9677476286888123,0.8657087769784172,0.6734914662926759,0.6077084092900626,0.7575324174781828,0.6190476190476191,0.7096774193548387,0.7969077292663314,0.7304800379156766,0.7835717700866685,0.7380952380952381,0.935483870967742,0.7693587885066956,0.6698121594992217,0.7816629330836282,0.6904761904761905,0.935483870967742
360535,edx/edx-oauth2-provider,edx_edx-oauth2-provider/edx_oauth2_provider/oidc/handlers.py,edx_oauth2_provider.oidc.handlers.BasicUserInfoHandler,"class BasicUserInfoHandler(object):
    """"""
    Basic OpenID Connect User Info claims.

    For reference see:
    http://openid.net/specs/openid-connect-basic-1_0.html#UserInfo

    """"""

    def scope_openid(self, data):
        """"""Returns claims for the `openid` profile""""""
        return ['sub']

    def claim_sub(self, data):
        """""" Required subject identifier. """"""
        # Use the primary key as the identifier
        return str(data['user'].pk)","class BasicUserInfoHandler(object):
    '''
    Basic OpenID Connect User Info claims.

    For reference see:
    http://openid.net/specs/openid-connect-basic-1_0.html#UserInfo

    '''

    def scope_openid(self, data):
    '''Returns claims for the `openid` profile'''
        pass

    def claim_sub(self, data):
    ''' Required subject identifier. '''
        pass

",3,3,snippet_618,1.0,"class BasicUserInfoHandler(object):
    '''
    Basic OpenID Connect User Info claims.

    For reference see:
    http://openid.net/specs/openid-connect-basic-1_0.html#UserInfo

    '''

    def scope_openid(self, data):
        '''Returns claims for the `openid` profile'''
        return {'sub': self.claim_sub(data)}

    def claim_sub(self, data):
        ''' Required subject identifier. '''
        if 'sub' not in data:
            raise ValueError('Missing required claim ""sub""')
        return data['sub']","class BasicUserInfoHandler(object):
    '''
    Basic OpenID Connect User Info claims.

    For reference see:
    http://openid.net/specs/openid-connect-basic-1_0.html#UserInfo

    '''

    def scope_openid(self, data):
        '''Returns claims for the `openid` profile'''
        return {
            'sub': self.claim_sub(data)
        }

    def claim_sub(self, data):
        ''' Required subject identifier. '''
        return data.get('sub', None)","class BasicUserInfoHandler(object):
    '''
    Basic OpenID Connect User Info claims.

    For reference see:
    http://openid.net/specs/openid-connect-basic-1_0.html#UserInfo

    '''

    def scope_openid(self, data):
        '''Returns claims for the `openid` profile'''
        return {
            'sub': self.claim_sub(data)
        }

    def claim_sub(self, data):
        ''' Required subject identifier. '''
        if hasattr(data, 'id'):
            return str(data.id)
        elif hasattr(data, 'pk'):
            return str(data.pk)
        elif isinstance(data, dict) and 'id' in data:
            return str(data['id'])
        elif isinstance(data, dict) and 'sub' in data:
            return str(data['sub'])
        else:
            return str(data)",full_docstr,0.7796610169491526,0.7241379310344828,0.7017543859649122,0.7796610169491526,0.6009942654056664,0.7169811320754716,0.6,0.5192307692307693,0.9431920051574707,0.9472250938415527,0.9452042579650879,0.9468202590942383,0.864735652173913,0.8440366972477065,0.8037383177570092,0.7619047619047618,0.8440366972477065,0.5711202056612044,0.7741935483870968,0.6521739130434783,0.5824175824175825,0.9695554971694946,0.9476804733276367,0.958493173122406,0.9498233795166016,0.9122815789473685,0.6486486486486486,0.6027397260273972,0.5694444444444444,0.6486486486486486,0.4198409589419453,0.484472049689441,0.41875,0.36477987421383645,0.8564522862434387,0.9511335492134094,0.9013132452964783,0.9407336115837097,0.7802491111111111,0.5090765405317234,0.3416369269669462,0.3788797614757368,0.3157894736842105,1.0,0.501993710785088,0.3659371869277735,0.3788797614757368,0.2631578947368421,1.0,0.4816835606205653,0.2320650073223136,0.3788797614757368,0.3157894736842105,1.0
292414,cisco-sas/kitty,cisco-sas_kitty/kitty/data/data_manager.py,kitty.data.data_manager.DataManagerTask,"class DataManagerTask(object):
    '''
    Task to be performed in the :class:`~kitty.data.data_manager.DataManager`
    context
    '''

    def __init__(self, task, *args):
        '''
        :type task: function(:class:`~kitty.data.data_manager.DataManager`) -> object
        :param task: task to be performed
        '''
        self._event = Event()
        self._result = None
        self._task = task
        self._args = args
        self._exception = None

    def execute(self, dataman):
        '''
        run the task

        :type dataman: :class:`~kitty.data.data_manager.DataManager`
        :param dataman: the executing data manager
        '''
        self._event.clear()
        try:
            self._result = self._task(dataman, *self._args)
        #
        # We are going to re-throw this exception from get_results,
        # so we are doing such a general eception handling at the point.
        # however, we do want to print it here as well
        #
        except Exception as ex:  # pylint: disable=W0703
            self._exception = ex
            KittyObject.get_logger().error(traceback.format_exc())
        self._event.set()

    def get_results(self):
        '''
        :return: result from running the task
        '''
        self._event.wait()
        if self._exception is not None:
            #
            # Well... rethrownig the exception caught in execute
            # but on the caller thread
            #
            raise self._exception  # pylint: disable=E0702
        return self._result","class DataManagerTask(object):
    '''
    Task to be performed in the :class:`~kitty.data.data_manager.DataManager`
    context
    '''

    def __init__(self, task, *args):
    '''
        :type task: function(:class:`~kitty.data.data_manager.DataManager`) -> object
        :param task: task to be performed
        '''
        pass

    def execute(self, dataman):
    '''
        run the task

        :type dataman: :class:`~kitty.data.data_manager.DataManager`
        :param dataman: the executing data manager
        '''
        pass

    def get_results(self):
    '''
        :return: result from running the task
        '''
        pass

",4,4,snippet_498,0.4285714285714285,"class DataManagerTask(object):
    '''
    Task to be performed in the :class:`~kitty.data.data_manager.DataManager`
    context
    '''

    def __init__(self, task, *args):
        '''
        :type task: function(:class:`~kitty.data.data_manager.DataManager`, *args) -> object
        :param task: task to be performed
        '''
        self._task = task
        self._args = args
        self._result = None

    def execute(self, dataman):
        '''
        run the task

        :type dataman: :class:`~kitty.data.data_manager.DataManager`
        :param dataman: the executing data manager
        '''
        self._result = self._task(dataman, *self._args)
        return self._result

    def get_results(self):
        '''
        :return: result from running the task
        '''
        return self._result","class DataManagerTask(object):
    '''
    Task to be performed in the :class:`~kitty.data.data_manager.DataManager`
    context
    '''

    def __init__(self, task, *args):
        '''
        :type task: function(:class:`~kitty.data.data_manager.DataManager`) -> object
        :param task: task to be performed
        '''
        self.task = task
        self.args = args
        self.results = None

    def execute(self, dataman):
        '''
        run the task

        :type dataman: :class:`~kitty.data.data_manager.DataManager`
        :param dataman: the executing data manager
        '''
        self.results = self.task(dataman, *self.args)

    def get_results(self):
        '''
        :return: result from running the task
        '''
        return self.results","class DataManagerTask(object):
    '''
    Task to be performed in the :class:`~kitty.data.data_manager.DataManager`
    context
    '''

    def __init__(self, task, *args):
        '''
        :type task: function(:class:`~kitty.data.data_manager.DataManager`) -> object
        :param task: task to be performed
        '''
        self._task = task
        self._args = args
        self._results = None

    def execute(self, dataman):
        '''
        run the task

        :type dataman: :class:`~kitty.data.data_manager.DataManager`
        :param dataman: the executing data manager
        '''
        self._results = self._task(dataman, *self._args)

    def get_results(self):
        '''
        :return: result from running the task
        '''
        return self._results",full_docstr,0.6567164179104479,0.6240601503759399,0.5681818181818182,0.6492537313432836,0.4343700868030223,0.9787234042553191,0.9518716577540107,0.9301075268817204,0.9669073224067688,0.7997466325759888,0.8754185438156128,0.8138160705566406,0.832360350877193,0.6439393939393939,0.6030534351145038,0.5615384615384615,0.6363636363636365,0.3668589868872487,0.9884393063583815,0.9418604651162791,0.8947368421052632,0.9666703939437866,0.7941820621490479,0.8719779849052429,0.8086106181144714,0.8265124561403508,0.6439393939393939,0.6030534351145038,0.5615384615384615,0.6363636363636365,0.4072357944525734,0.9888888888888889,0.9720670391061452,0.9438202247191011,0.9682860374450684,0.7957040667533875,0.8735526204109192,0.8101435899734497,0.8265124561403508,0.3467575995968152,0.2760017081425385,0.3860789342872143,0.4691358024691358,0.2558139534883721,0.3079841102058787,0.2468531077440016,0.3640669678771013,0.4814814814814814,0.1395348837209302,0.3482980677537276,0.2658090334035081,0.3900878026415488,0.4814814814814814,0.2558139534883721
181934,Rockhopper-Technologies/enlighten,Rockhopper-Technologies_enlighten/benchmarks/benchmarks.py,benchmarks.benchmarks.TimeFormat,"class TimeFormat:
    """"""
    Time-based benchmarks for format operations
    These are emphasized because they will have the greatest impact on end users
    """"""
    def setup(self):
        """"""
        General setup functions
        """"""

        # pylint: disable=attribute-defined-outside-init
        manager = get_manager(disable=True)
        self.pbar = manager.counter(total=1000)
        self.counter = manager.counter()
        self.sbar = manager.status_bar(status_format='Current Count: {num}', num=0)

    def time_format_bar(self):
        """"""
        Time Counter.format() for progress bar
        Count does not exceed total
        """"""

        pbar = self.pbar

        for _ in range(1000):
            pbar.update()
            pbar.format()

    def time_format_counter(self):
        """"""
        Time Counter.format() for counter
        Count exceeds total
        """"""

        pbar = self.pbar

        for _ in range(1000):
            pbar.update()
            pbar.format()

    def time_format_status_bar(self):
        """"""
        Time Counter.format() for status bar
        Uses dynamic variable
        """"""

        sbar = self.sbar

        for num in range(1000):
            sbar.update(num=num)
            sbar.format()","class TimeFormat:
    '''
    Time-based benchmarks for format operations
    These are emphasized because they will have the greatest impact on end users
    '''

    def setup(self):
    '''
        General setup functions
        '''
        pass

    def time_format_bar(self):
    '''
        Time Counter.format() for progress bar
        Count does not exceed total
        '''
        pass

    def time_format_counter(self):
    '''
        Time Counter.format() for counter
        Count exceeds total
        '''
        pass

    def time_format_status_bar(self):
    '''
        Time Counter.format() for status bar
        Uses dynamic variable
        '''
        pass

",5,5,snippet_243,0.3333333333333333,"class TimeFormat:
    '''
    Time-based benchmarks for format operations
    These are emphasized because they will have the greatest impact on end users
    '''

    def setup(self):
        '''
            General setup functions
        '''
        class Counter:
            def __init__(self, total):
                self.count = 0
                self.total = total
            def format(self):
                return ""[{count:>7}/{total}]"".format(count=self.count, total=self.total)
        self.Counter = Counter
        self.total = 1000
        self.bar = Counter(self.total)
        self.counter = Counter(self.total)

    def time_format_bar(self):
        '''
            Time Counter.format() for progress bar
            Count does not exceed total
        '''
        for i in range(self.total):
            self.bar.count = i
            self.bar.format()

    def time_format_counter(self):
        '''
            Time Counter.format() for counter
            Count exceeds total
        '''
        for i in range(self.total):
            self.counter.count = self.total + i
            self.counter.format()

    def time_format_status_bar(self):
        '''
            Time Counter.format() for status bar
            Uses dynamic variable
        '''
        for i in range(self.total):
            width = (i % 10) + 1
            ""[{count:>{w}}/{total}]"".format(count=i, w=width, total=self.total)","class TimeFormat:
    '''
    Time-based benchmarks for format operations
    These are emphasized because they will have the greatest impact on end users
    '''

    def setup(self):
        '''
        General setup functions
        '''
        from collections import Counter
        self.counter = Counter()
        self.counter.count = 50
        self.counter.total = 100
        
        # For counter test where count exceeds total
        self.overflow_counter = Counter()
        self.overflow_counter.count = 150
        self.overflow_counter.total = 100
        
        # For status bar with dynamic variable
        self.status_counter = Counter()
        self.status_counter.count = 75
        self.status_counter.total = 100
        self.status_counter.desc = ""Processing""

    def time_format_bar(self):
        '''
        Time Counter.format() for progress bar
        Count does not exceed total
        '''
        self.counter.format()

    def time_format_counter(self):
        '''
        Time Counter.format() for counter
        Count exceeds total
        '''
        self.overflow_counter.format()

    def time_format_status_bar(self):
        '''
        Time Counter.format() for status bar
        Uses dynamic variable
        '''
        self.status_counter.format()","class TimeFormat:
    '''
    Time-based benchmarks for format operations
    These are emphasized because they will have the greatest impact on end users
    '''

    def setup(self):
        '''
        General setup functions
        '''
        self.counter_bar = tqdm(total=1000, desc=""Progress"", leave=False)
        self.counter_bar.n = 500
        
        self.counter_exceed = tqdm(total=100, desc=""Counter"", leave=False)
        self.counter_exceed.n = 150
        
        self.status_bar = tqdm(total=None, desc=""Status"", leave=False)
        self.status_bar.n = 42
        self.dynamic_var = ""Processing files""

    def time_format_bar(self):
        '''
        Time Counter.format() for progress bar
        Count does not exceed total
        '''
        return self.counter_bar.format_meter(
            n=self.counter_bar.n,
            total=self.counter_bar.total,
            elapsed=time.time() - self.counter_bar.start_t if hasattr(self.counter_bar, 'start_t') else 10.5,
            ncols=80,
            prefix=self.counter_bar.desc
        )

    def time_format_counter(self):
        '''
        Time Counter.format() for counter
        Count exceeds total
        '''
        return self.counter_exceed.format_meter(
            n=self.counter_exceed.n,
            total=self.counter_exceed.total,
            elapsed=time.time() - self.counter_exceed.start_t if hasattr(self.counter_exceed, 'start_t') else 15.2,
            ncols=80,
            prefix=self.counter_exceed.desc
        )

    def time_format_status_bar(self):
        '''
        Time Counter.format() for status bar
        Uses dynamic variable
        '''
        return self.status_bar.format_meter(
            n=self.status_bar.n,
            total=self.status_bar.total,
            elapsed=time.time() - self.status_bar.start_t if hasattr(self.status_bar, 'start_t') else 8.7,
            ncols=80,
            prefix=f""{self.status_bar.desc}: {self.dynamic_var}""
        )",full_docstr,0.6556291390728477,0.5066666666666666,0.4429530201342282,0.6092715231788078,0.44692948526410226,0.6360655737704918,0.42105263157894735,0.3333333333333333,0.8737747669219971,0.8542121648788452,0.8638827204704285,0.8561289310455322,0.8090928181818181,0.6360424028268551,0.5195729537366548,0.4659498207885304,0.6219081272084805,0.4671920966468606,0.6708333333333333,0.5104602510460251,0.40756302521008403,0.885233461856842,0.8291316628456116,0.8562646508216858,0.8344197869300842,0.7821250837988829,0.4536082474226804,0.36269430051813467,0.32812499999999994,0.4536082474226804,0.2804496341197433,0.40869565217391307,0.2657952069716776,0.20305676855895197,0.7837502360343933,0.835640013217926,0.8088637590408325,0.830143928527832,0.7857164285714284,0.3177677892296798,0.3516115919292113,0.4196589270309753,0.3068181818181818,0.1929824561403508,0.5147881189919632,0.3688611599488413,0.3948367705644658,0.2954545454545454,0.0,0.5236907904988934,0.3061998838071327,0.3908360054611685,0.3977272727272727,0.0
312363,cohorte/cohorte-herald,python/herald/remote/herald_jsonrpc.py,herald.remote.herald_jsonrpc._JsonRpcMethod,"class _JsonRpcMethod(object):
    """"""
    Represents a method in a call proxy
    """"""
    def __init__(self, method_name, peer, subject, send_method):
        """"""
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        """"""
        self.__name = method_name
        self.__peer = peer
        self.__subject = subject
        self.__send = send_method

    def __call__(self, *args):
        """"""
        Method is being called
        """"""
        # Forge the request
        request = jsonrpclib.dumps(args, self.__name, encoding='utf-8')

        # Send it
        reply_message = self.__send(self.__peer, self.__subject, request)

        # Parse the reply and check for errors
        result = jsonrpclib.loads(reply_message.content)
        jsonrpclib.jsonrpc.check_for_errors(result)
        return result['result']","class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
    '''
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        pass

    def __call__(self, *args):
    '''
        Method is being called
        '''
        pass

",3,3,snippet_538,1.0,"class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
        '''
            Sets up the method

            :param method_name: Full method name
            :param peer: UID of the peer to contact
            :param subject: Subject to use for RPC
            :param send_method: Method to use to send a request
        '''
        self.method_name = method_name
        self.peer = peer
        self.subject = subject
        self.send_method = send_method

    def __call__(self, *args):
        '''
            Method is being called
        '''
        request = {
            ""jsonrpc"": ""2.0"",
            ""method"": self.method_name,
            ""params"": args,
            ""id"": uuid.uuid4().hex
        }
        message = json.dumps(request)
        return self.send_method(self.peer, self.subject, message)","class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
        '''
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self.method_name = method_name
        self.peer = peer
        self.subject = subject
        self.send_method = send_method

    def __call__(self, *args):
        '''
        Method is being called
        '''
        return self.send_method(self.method_name, self.peer, self.subject, args)","class _JsonRpcMethod(object):
    '''
    Represents a method in a call proxy
    '''

    def __init__(self, method_name, peer, subject, send_method):
        '''
        Sets up the method

        :param method_name: Full method name
        :param peer: UID of the peer to contact
        :param subject: Subject to use for RPC
        :param send_method: Method to use to send a request
        '''
        self.method_name = method_name
        self.peer = peer
        self.subject = subject
        self.send_method = send_method

    def __call__(self, *args):
        '''
        Method is being called
        '''
        return self.send_method(self.peer, self.subject, self.method_name, args)",full_docstr,0.8141592920353982,0.6875000000000001,0.6486486486486487,0.7699115044247787,0.5653129216710692,0.8730964467005076,0.6683673469387755,0.5538461538461539,0.928833544254303,0.87749183177948,0.9024330377578735,0.8823692202568054,0.8494638709677419,0.8151658767772512,0.736842105263158,0.6956521739130435,0.7867298578199053,0.4846077280730926,0.9358974358974359,0.8,0.7012987012987013,0.9745163321495056,0.8484233617782593,0.9071089625358582,0.8595449924468994,0.8602164516129032,0.8151658767772512,0.736842105263158,0.6956521739130435,0.7772511848341233,0.4846077280730926,0.9358974358974359,0.8,0.7012987012987013,0.9745657444000244,0.8489944934844971,0.907456636428833,0.8600764274597168,0.8602164516129032,0.546307624644826,0.4922264636654025,0.5016120935219597,0.5961538461538461,0.5952380952380952,0.4777380295627805,0.4678231259648827,0.4953267944840412,0.5192307692307693,0.4285714285714285,0.4777380295627805,0.4678231259648827,0.4953267944840412,0.5192307692307693,0.4285714285714285
394916,gem/oq-engine,gem_oq-engine/openquake/hmtk/strain/geodetic_strain.py,openquake.hmtk.strain.geodetic_strain.GeodeticStrain,"class GeodeticStrain(object):
    """"""
    :class:`openquake.hmtk.strain.geodetic_strain.GeodeticStrain` describes
    the geodetic strain model

    :param dict data:
        Strain data in the form of a dictionary where is vector of attributes
        is stored under the correponding dictionary key (i.e.
        - longitude - Longitude of point
        - latitude - Latitiude of point
        - exx - xx-component of strain tensor
        - eyy - yy-component of strain tensor
        - exy - xy-component of strain tensor
    :param numpy.ndarray seismicity_rate:
        Seismicity rate at each point associated with the strain model
    :param numpy.ndarray target_magnitudes:
        Magnitudes for the corresponding activity rates
    :param list data_variables:
        List of strain data attributes in the current class
    """"""

    def __init__(self):
        """"""Instantiates""""""
        self.data = None
        self.regions = None
        self.seismicity_rate = None
        self.regionalisation = None
        self.target_magnitudes = None
        self.data_variables = []

    def get_secondary_strain_data(self, strain_data=None):
        """"""
        Calculate the following and add to data dictionary:
        1) 2nd invarient of strain
        2) Dilatation rate
        3) e1h and e2h
        4) err

        :param dict strain_data:
            Strain data dictionary (as described) - will overwrite current
            data if input

        """"""
        if strain_data:
            self.data = strain_data

        if not isinstance(self.data, dict):
            raise ValueError(""Strain data not input or incorrectly formatted"")

        # Check to ensure essential attributes are in data dictionary
        for essential_key in DATA_VARIABLES:
            if essential_key not in self.data:
                print(self.data)
                raise ValueError(
                    ""Essential strain information %s missing!"" % essential_key
                )
        self.data_variables = deepcopy(DATA_VARIABLES)

        # Second Invarient
        self.data[""2nd_inv""] = np.sqrt(
            (self.data[""exx""] ** 2.0)
            + (self.data[""eyy""] ** 2.0)
            + 2.0 * (self.data[""exy""] ** 2.0)
        )
        # Dilatation
        self.data[""dilatation""] = self.data[""exx""] + self.data[""eyy""]
        # err
        self.data[""err""] = -1.0 * self.data[""dilatation""]
        center_normal_rate = (self.data[""exx""] + self.data[""eyy""]) / 2.0
        radius_rate = np.sqrt(
            (self.data[""exx""] - center_normal_rate) ** 2.0
            + (self.data[""exy""] ** 2.0)
        )
        # e1h and e2h
        self.data[""e1h""] = center_normal_rate - radius_rate
        self.data[""e2h""] = center_normal_rate + radius_rate
        self.data[""area""] = np.zeros(self.get_number_observations())
        self.data_variables.extend(
            [""2nd_inv"", ""dilatation"", ""err"", ""e1h"", ""e2h""]
        )

    def get_number_observations(self):
        """"""
        Returns the number of observations in the data file
        """"""
        if isinstance(self.data, dict) and (""exx"" in self.data.keys()):
            return len(self.data[""exx""])
        else:
            return 0","class GeodeticStrain(object):
    '''
    :class:`openquake.hmtk.strain.geodetic_strain.GeodeticStrain` describes
    the geodetic strain model

    :param dict data:
        Strain data in the form of a dictionary where is vector of attributes
        is stored under the correponding dictionary key (i.e.
        - longitude - Longitude of point
        - latitude - Latitiude of point
        - exx - xx-component of strain tensor
        - eyy - yy-component of strain tensor
        - exy - xy-component of strain tensor
    :param numpy.ndarray seismicity_rate:
        Seismicity rate at each point associated with the strain model
    :param numpy.ndarray target_magnitudes:
        Magnitudes for the corresponding activity rates
    :param list data_variables:
        List of strain data attributes in the current class
    '''

    def __init__(self):
    '''Instantiates'''
        pass

    def get_secondary_strain_data(self, strain_data=None):
    '''
        Calculate the following and add to data dictionary:
        1) 2nd invarient of strain
        2) Dilatation rate
        3) e1h and e2h
        4) err

        :param dict strain_data:
            Strain data dictionary (as described) - will overwrite current
            data if input

        '''
        pass

    def get_number_observations(self):
    '''
        Returns the number of observations in the data file
        '''
        pass

",4,4,snippet_697,0.5333333333333333,"class GeodeticStrain(object):
    '''
    :class:`openquake.hmtk.strain.geodetic_strain.GeodeticStrain` describes
    the geodetic strain model

    :param dict data:
        Strain data in the form of a dictionary where is vector of attributes
        is stored under the correponding dictionary key (i.e.
        - longitude - Longitude of point
        - latitude - Latitiude of point
        - exx - xx-component of strain tensor
        - eyy - yy-component of strain tensor
        - exy - xy-component of strain tensor
    :param numpy.ndarray seismicity_rate:
        Seismicity rate at each point associated with the strain model
    :param numpy.ndarray target_magnitudes:
        Magnitudes for the corresponding activity rates
    :param list data_variables:
        List of strain data attributes in the current class
    '''

    def __init__(self, data, seismicity_rate, target_magnitudes, data_variables):
        self.data = data
        self.seismicity_rate = np.asarray(seismicity_rate)
        self.target_magnitudes = np.asarray(target_magnitudes)
        self.data_variables = list(data_variables)

    def get_secondary_strain_data(self, strain_data=None):
        '''
        Calculate the following and add to data dictionary:
        1) 2nd invarient of strain
        2) Dilatation rate
        3) e1h and e2h
        4) err

        :param dict strain_data:
            Strain data dictionary (as described) - will overwrite current
            data if input
        '''
        dd = strain_data if strain_data is not None else self.data

        exx = np.asarray(dd['exx'])
        eyy = np.asarray(dd['eyy'])
        exy = np.asarray(dd['exy'])

        # Dilatation rate
        dilatation = exx + eyy

        # Principal strains
        mean = 0.5 * (exx + eyy)
        diff = 0.5 * (exx - eyy)
        root = np.sqrt(diff**2 + exy**2)
        e1h = mean + root
        e2h = mean - root

        # Second invariant of deviatoric strain (J2)
        # here taken as the magnitude of the deviatoric part: root
        invariant_2nd = root

        # Principal axis orientation
        err = 0.5 * np.arctan2(2 * exy, exx - eyy)

        # Store
        dd['dilatation'] = dilatation
        dd['e1h'] = e1h
        dd['e2h'] = e2h
        dd['invariant_2nd'] = invariant_2nd
        dd['err'] = err

        for key in ['dilatation', 'e1h', 'e2h', 'invariant_2nd', 'err']:
            if key not in self.data_variables:
                self.data_variables.append(key)

        if strain_data is None:
            self.data = dd

        return dd

    def get_number_observations(self):
        '''
        Returns the number of observations in the data file
        '''
        # assume all variables are same length
        first_key = next(iter(self.data))
        return len(self.data[first_key])","class GeodeticStrain(object):
    '''
    :class:`openquake.hmtk.strain.geodetic_strain.GeodeticStrain` describes
    the geodetic strain model

    :param dict data:
        Strain data in the form of a dictionary where is vector of attributes
        is stored under the correponding dictionary key (i.e.
        - longitude - Longitude of point
        - latitude - Latitiude of point
        - exx - xx-component of strain tensor
        - eyy - yy-component of strain tensor
        - exy - xy-component of strain tensor
    :param numpy.ndarray seismicity_rate:
        Seismicity rate at each point associated with the strain model
    :param numpy.ndarray target_magnitudes:
        Magnitudes for the corresponding activity rates
    :param list data_variables:
        List of strain data attributes in the current class
    '''

    def __init__(self):
        '''Instantiates'''
        self.data = None
        self.seismicity_rate = None
        self.target_magnitudes = None
        self.data_variables = None

    def get_secondary_strain_data(self, strain_data=None):
        '''
        Calculate the following and add to data dictionary:
        1) 2nd invariant of strain
        2) Dilatation rate
        3) e1h and e2h
        4) err

        :param dict strain_data:
            Strain data dictionary (as described) - will overwrite current
            data if input

        '''
        if strain_data is not None:
            self.data = strain_data
        
        if self.data is None:
            raise ValueError(""No strain data available"")
        
        # Extract strain components
        exx = self.data['exx']
        eyy = self.data['eyy']
        exy = self.data['exy']
        
        # 1) Second invariant of strain: sqrt(exx^2 + eyy^2 + 2*exy^2)
        second_invariant = np.sqrt(exx**2 + eyy**2 + 2.0 * exy**2)
        self.data['second_invariant'] = second_invariant
        
        # 2) Dilatation rate: exx + eyy
        dilatation = exx + eyy
        self.data['dilatation'] = dilatation
        
        # 3) Principal strains e1h and e2h
        # e1h = (exx + eyy)/2 + sqrt(((exx - eyy)/2)^2 + exy^2)
        # e2h = (exx + eyy)/2 - sqrt(((exx - eyy)/2)^2 + exy^2)
        mean_strain = (exx + eyy) / 2.0
        strain_diff = (exx - eyy) / 2.0
        shear_magnitude = np.sqrt(strain_diff**2 + exy**2)
        
        e1h = mean_strain + shear_magnitude
        e2h = mean_strain - shear_magnitude
        
        self.data['e1h'] = e1h
        self.data['e2h'] = e2h
        
        # 4) Maximum shear strain: err = (e1h - e2h) / 2
        err = (e1h - e2h) / 2.0
        self.data['err'] = err

    def get_number_observations(self):
        '''
        Returns the number of observations in the data file
        '''
        if self.data is None:
            return 0
        # Assuming all data arrays have the same length
        for key in self.data:
            return len(self.data[key])
        return 0","class GeodeticStrain(object):
    '''
    :class:`openquake.hmtk.strain.geodetic_strain.GeodeticStrain` describes
    the geodetic strain model

    :param dict data:
        Strain data in the form of a dictionary where is vector of attributes
        is stored under the correponding dictionary key (i.e.
        - longitude - Longitude of point
        - latitude - Latitiude of point
        - exx - xx-component of strain tensor
        - eyy - yy-component of strain tensor
        - exy - xy-component of strain tensor
    :param numpy.ndarray seismicity_rate:
        Seismicity rate at each point associated with the strain model
    :param numpy.ndarray target_magnitudes:
        Magnitudes for the corresponding activity rates
    :param list data_variables:
        List of strain data attributes in the current class
    '''

    def __init__(self):
        '''Instantiates'''
        self.data = {}
        self.seismicity_rate = None
        self.target_magnitudes = None
        self.data_variables = ['longitude', 'latitude', 'exx', 'eyy', 'exy']

    def get_secondary_strain_data(self, strain_data=None):
        '''
        Calculate the following and add to data dictionary:
        1) 2nd invarient of strain
        2) Dilatation rate
        3) e1h and e2h
        4) err

        :param dict strain_data:
            Strain data dictionary (as described) - will overwrite current
            data if input

        '''
        if strain_data is not None:
            self.data = strain_data
        
        exx = np.array(self.data['exx'])
        eyy = np.array(self.data['eyy'])
        exy = np.array(self.data['exy'])
        
        # 2nd invariant of strain
        self.data['e2nd'] = np.sqrt(((exx - eyy) ** 2 + 4 * exy ** 2) / 2)
        
        # Dilatation rate
        self.data['dilatation'] = exx + eyy
        
        # Principal strain rates e1h and e2h
        mean_strain = (exx + eyy) / 2
        diff_strain = np.sqrt(((exx - eyy) / 2) ** 2 + exy ** 2)
        
        self.data['e1h'] = mean_strain + diff_strain
        self.data['e2h'] = mean_strain - diff_strain
        
        # err (radial strain component)
        self.data['err'] = (exx + eyy) / 2
        
        # Update data_variables list
        secondary_vars = ['e2nd', 'dilatation', 'e1h', 'e2h', 'err']
        for var in secondary_vars:
            if var not in self.data_variables:
                self.data_variables.append(var)

    def get_number_observations(self):
        '''
        Returns the number of observations in the data file
        '''
        if not self.data:
            return 0
        
        # Get the length of any data array (they should all be the same length)
        for key, value in self.data.items():
            if isinstance(value, (list, np.ndarray)):
                return len(value)
        
        return 0",full_docstr,0.7203274215552524,0.5554035567715457,0.4883401920438957,0.6002728512960437,0.4635888384471018,0.7912280701754386,0.5588752196836555,0.4788732394366197,0.9108697772026062,0.9069539308547974,0.9089076519012451,0.9073439836502075,0.7700898090692128,0.7320954907161804,0.6117021276595745,0.5280000000000001,0.6710875331564987,0.5059034505648193,0.7564102564102564,0.5521669341894061,0.4758842443729904,0.924803614616394,0.9205746650695801,0.9226843118667603,0.9209958910942078,0.8178220286396183,0.7599451303155007,0.624484181568088,0.5351724137931035,0.6666666666666667,0.5134542017774805,0.8113207547169812,0.6151202749140894,0.5301204819277109,0.9341469407081604,0.9172125458717346,0.9256022572517395,0.9188783168792725,0.8066845107398569,0.3882453362598084,0.488924481912275,0.4948260938961896,0.4,0.1692307692307692,0.4628834091258136,0.4699218340238693,0.5231502640178467,0.52,0.3384615384615385,0.4663682085983463,0.5074267070949094,0.5238153580677067,0.565,0.2692307692307692
354206,dvdme/forecastiopy,dvdme_forecastiopy/forecastiopy/FIOCurrently.py,forecastiopy.FIOCurrently.FIOCurrently,"class FIOCurrently(object):
    """"""
    This class recieves an ForecastIO object and holds the currently weather
    conditions.
    """"""

    currently = None

    def __init__(self, forecast_io):
        """"""
        Construct a new 'FIOCurrently' object.
        Recieves an ForecastIO object and gets the currently weather conditions
        if they are available in the object.

        Args:
            forecast_io (ForecastIO): The ForecastIO object
        """"""
        if forecast_io.has_currently():
            self.currently = forecast_io.get_currently()
            for item in self.currently.keys():
                setattr(self, item, self.currently[item])

    def get(self):
        """"""
        Returns a dictionary with current weather conditions.
        Returns None is none are available.

        Returns:
            Dictionary with current weather conditions.
            None is none are available.
        """"""
        return self.currently","class FIOCurrently(object):
    '''
    This class recieves an ForecastIO object and holds the currently weather
    conditions.
    '''

    def __init__(self, forecast_io):
    '''
        Construct a new 'FIOCurrently' object.
        Recieves an ForecastIO object and gets the currently weather conditions
        if they are available in the object.

        Args:
            forecast_io (ForecastIO): The ForecastIO object
        '''
        pass

    def get(self):
    '''
        Returns a dictionary with current weather conditions.
        Returns None is none are available.

        Returns:
            Dictionary with current weather conditions.
            None is none are available.
        '''
        pass

",3,3,snippet_604,0.2857142857142857,"class FIOCurrently(object):
    '''
    This class recieves an ForecastIO object and holds the currently weather
    conditions.
    '''

    def __init__(self, forecast_io):
        '''
        Construct a new 'FIOCurrently' object.
        Recieves an ForecastIO object and gets the currently weather conditions
        if they are available in the object.

        Args:
            forecast_io (ForecastIO): The ForecastIO object
        '''
        self._currently = None
        try:
            data = getattr(forecast_io, 'json', None)
            if isinstance(data, dict):
                self._currently = data.get('currently')
        except Exception:
            self._currently = None

    def get(self):
        '''
        Returns a dictionary with current weather conditions.
        Returns None is none are available.

        Returns:
            Dictionary with current weather conditions.
            None is none are available.
        '''
        return self._currently","class FIOCurrently(object):
    '''
    This class recieves an ForecastIO object and holds the currently weather
    conditions.
    '''

    def __init__(self, forecast_io):
        '''
        Construct a new 'FIOCurrently' object.
        Recieves an ForecastIO object and gets the currently weather conditions
        if they are available in the object.

        Args:
            forecast_io (ForecastIO): The ForecastIO object
        '''
        self.currently = None
        if hasattr(forecast_io, 'currently'):
            self.currently = forecast_io.currently

    def get(self):
        '''
        Returns a dictionary with current weather conditions.
        Returns None is none are available.

        Returns:
            Dictionary with current weather conditions.
            None is none are available.
        '''
        return self.currently","class FIOCurrently(object):
    '''
    This class recieves an ForecastIO object and holds the currently weather
    conditions.
    '''

    def __init__(self, forecast_io):
        '''
        Construct a new 'FIOCurrently' object.
        Recieves an ForecastIO object and gets the currently weather conditions
        if they are available in the object.

        Args:
            forecast_io (ForecastIO): The ForecastIO object
        '''
        self.forecast_io = forecast_io
        self.currently = None
        if hasattr(forecast_io, 'json') and forecast_io.json:
            self.currently = forecast_io.json.get('currently')

    def get(self):
        '''
        Returns a dictionary with current weather conditions.
        Returns None is none are available.

        Returns:
            Dictionary with current weather conditions.
            None is none are available.
        '''
        return self.currently",full_docstr,0.8792270531400966,0.8097560975609757,0.729064039408867,0.8405797101449275,0.6576631394936593,0.8536585365853658,0.7055214723926381,0.6111111111111112,0.9505919814109802,0.9555339813232422,0.9530565142631531,0.9550374746322632,0.8333349999999999,0.9285714285714286,0.8556701030927835,0.7916666666666666,0.8979591836734695,0.6439905696206343,0.9424460431654677,0.855072463768116,0.7737226277372263,0.9795534610748291,0.9564687013626099,0.9678734540939331,0.9587280750274658,0.8675226923076923,0.8888888888888888,0.8097560975609757,0.7389162561576355,0.8502415458937198,0.6807432874734521,0.8742138364779874,0.759493670886076,0.6815286624203821,0.9705994129180908,0.9600591063499451,0.965300440788269,0.9611028432846069,0.841881923076923,0.5135006684626044,0.6567113530450444,0.7003216238356765,0.3333333333333333,0.3636363636363636,0.4896508964330933,0.695606675776192,0.7023908493501209,0.3333333333333333,0.2272727272727272,0.5308995301367203,0.6964597964492857,0.7023908493501209,0.3611111111111111,0.3636363636363636
349468,doraemonext/wechat-python-sdk,doraemonext_wechat-python-sdk/wechat_sdk/lib/request.py,wechat_sdk.lib.request.WechatRequest,"class WechatRequest(object):
    """""" WechatRequest 

    
    """"""

    def __init__(self, conf=None):
        """"""
        :param conf: WechatConf 
        """"""
        self.__conf = conf

    def request(self, method, url, access_token=None, **kwargs):
        """"""
        
        :param method: 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        """"""
        access_token = self.__conf.access_token if self.__conf is not None else access_token
        if ""params"" not in kwargs:
            kwargs[""params""] = {
                ""access_token"": access_token
            }
        else:
            kwargs[""params""][""access_token""] = access_token

        if isinstance(kwargs.get(""data"", """"), dict):
            body = json.dumps(kwargs[""data""], ensure_ascii=False)
            if isinstance(body, six.text_type):
                body = body.encode('utf8')
            kwargs[""data""] = body

        r = requests.request(
            method=method,
            url=url,
            **kwargs
        )
        r.raise_for_status()
        try:
            response_json = r.json()
        except ValueError:  #  JSON 
            return r

        headimgurl = response_json.get('headimgurl')
        if headimgurl:
            response_json['headimgurl'] = headimgurl.replace('\\', '')
        self._check_official_error(response_json)
        return response_json

    def get(self, url, access_token=None, **kwargs):
        """"""
         GET 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        """"""
        return self.request(
            method=""get"",
            url=url,
            access_token=access_token,
            **kwargs
        )

    def post(self, url, access_token=None, **kwargs):
        """"""
         POST 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        """"""
        return self.request(
            method=""post"",
            url=url,
            access_token=access_token,
            **kwargs
        )

    def _check_official_error(self, json_data):
        """"""
        
        :raises OfficialAPIError:  True
        """"""
        if 'errcode' in json_data and json_data['errcode'] != 0:
            raise OfficialAPIError(errcode=json_data.get('errcode'), errmsg=json_data.get('errmsg', ''))","class WechatRequest(object):
    ''' WechatRequest 

    
    '''

    def __init__(self, conf=None):
    '''
        :param conf: WechatConf 
        '''
        pass

    def request(self, method, url, access_token=None, **kwargs):
    '''
        
        :param method: 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        pass

    def get(self, url, access_token=None, **kwargs):
    '''
         GET 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        pass

    def post(self, url, access_token=None, **kwargs):
    '''
         POST 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        pass

    def _check_official_error(self, json_data):
    '''
        
        :raises OfficialAPIError:  True
        '''
        pass

",6,6,snippet_595,0.4285714285714285,"class WechatRequest(object):
    ''' WechatRequest 

    
    '''

    def __init__(self, conf=None):
        '''
        :param conf: WechatConf 
        '''
        self.conf = conf

    def request(self, method, url, access_token=None, **kwargs):
        '''
        
        :param method: 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        token = access_token or (self.conf.get_access_token() if self.conf else None)
        if not token:
            raise ValueError(""Access token is required"")
        method = method.upper()
        params = {""access_token"": token}
        if method == ""GET"":
            params.update(kwargs)
            resp = requests.get(url, params=params)
        else:
            resp = requests.request(method, url, params=params, json=kwargs)
        resp.raise_for_status()
        data = resp.json()
        self._check_official_error(data)
        return data

    def get(self, url, access_token=None, **kwargs):
        '''
         GET 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        return self.request(""GET"", url, access_token=access_token, **kwargs)

    def post(self, url, access_token=None, **kwargs):
        '''
         POST 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        return self.request(""POST"", url, access_token=access_token, **kwargs)

    def _check_official_error(self, json_data):
        '''
        
        :raises OfficialAPIError:  True
        '''
        errcode = json_data.get(""errcode"")
        if errcode and errcode != 0:
            errmsg = json_data.get(""errmsg"", """")
            raise OfficialAPIError(errcode, errmsg)
        return True","class WechatRequest(object):
    ''' WechatRequest 

    
    '''

    def __init__(self, conf=None):
        '''
        :param conf: WechatConf 
        '''
        self.conf = conf

    def request(self, method, url, access_token=None, **kwargs):
        '''
        
        :param method: 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        if access_token is None and self.conf is not None:
            access_token = self.conf.access_token
            
        if access_token:
            if '?' in url:
                url = '{}&access_token={}'.format(url, access_token)
            else:
                url = '{}?access_token={}'.format(url, access_token)
        
        response = requests.request(method, url, **kwargs)
        response.raise_for_status()
        
        json_data = response.json()
        self._check_official_error(json_data)
        
        return json_data

    def get(self, url, access_token=None, **kwargs):
        '''
         GET 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        return self.request('GET', url, access_token, **kwargs)

    def post(self, url, access_token=None, **kwargs):
        '''
         POST 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        return self.request('POST', url, access_token, **kwargs)

    def _check_official_error(self, json_data):
        '''
        
        :raises OfficialAPIError:  True
        '''
        if 'errcode' in json_data and json_data['errcode'] != 0:
            errcode = json_data['errcode']
            errmsg = json_data.get('errmsg', '')
            raise OfficialAPIError('API: errcode={}, errmsg={}'.format(errcode, errmsg))
        return True","class WechatRequest(object):
    ''' WechatRequest 

    
    '''

    def __init__(self, conf=None):
        '''
        :param conf: WechatConf 
        '''
        self._conf = conf

    def request(self, method, url, access_token=None, **kwargs):
        '''
        
        :param method: 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        if access_token is None and self._conf:
            access_token = self._conf.access_token
        
        if access_token:
            if '?' in url:
                url += '&access_token=' + access_token
            else:
                url += '?access_token=' + access_token
        
        response = requests.request(method, url, **kwargs)
        json_data = response.json()
        self._check_official_error(json_data)
        return json_data

    def get(self, url, access_token=None, **kwargs):
        '''
         GET 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        return self.request('GET', url, access_token, **kwargs)

    def post(self, url, access_token=None, **kwargs):
        '''
         POST 
        :param url: 
        :param access_token: access token ,  conf , 
        :param kwargs: 
        :return:  JSON 
        '''
        return self.request('POST', url, access_token, **kwargs)

    def _check_official_error(self, json_data):
        '''
        
        :raises OfficialAPIError:  True
        '''
        if 'errcode' in json_data and json_data['errcode'] != 0:
            raise OfficialAPIError(json_data.get('errmsg', 'Unknown error'), json_data['errcode'])
        return True",full_docstr,0.8256880733944953,0.6451612903225806,0.5370370370370371,0.7201834862385321,0.5589803512540064,0.9203539823008849,0.7361419068736141,0.6244444444444445,0.9555395841598511,0.937150239944458,0.9462555646896362,0.9389572739601135,0.8430350793650794,0.8367816091954022,0.6882217090069284,0.5846867749419953,0.7540229885057471,0.5664425691938206,0.8973799126637555,0.7330415754923414,0.6359649122807017,0.950133204460144,0.9372909665107727,0.9436683654785156,0.9385595321655273,0.8412714285714288,0.8373205741626794,0.6923076923076923,0.6038647342995169,0.7655502392344498,0.5231108091378506,0.9296116504854369,0.7858880778588808,0.6926829268292682,0.9554449915885925,0.9338191747665405,0.9445083737373352,0.9359376430511475,0.8465623809523811,0.4654040812010334,0.4212627034070972,0.4317856899404884,0.5348837209302325,0.4736842105263157,0.4540138810695083,0.4453969978287292,0.4610298034790878,0.4534883720930232,0.4561403508771929,0.4653704810619105,0.4418791399373265,0.4601984595449134,0.4418604651162791,0.5175438596491229
235165,annoviko/pyclustering,annoviko_pyclustering/pyclustering/container/kdtree.py,pyclustering.container.kdtree.node,"class node:
    """"""!
    @brief Represents a node in a KD-Tree.
    @details The KD-Tree node contains point's coordinates, discriminator, payload and pointers to parent and children.

    @see kdtree_balanced
    @see kdtree

    """"""

    def __init__(self, data=None, payload=None, left=None, right=None, disc=None, parent=None):
        """"""!
        @brief Creates KD-tree node.

        @param[in] data (list): Data point that is presented as list of coordinates.
        @param[in] payload (any): Payload of node (pointer to essence that is attached to this node).
        @param[in] left (node): Node of KD-Tree that represents left successor.
        @param[in] right (node): Node of KD-Tree that represents right successor.
        @param[in] disc (uint): Index of dimension of that node.
        @param[in] parent (node): Node of KD-Tree that represents parent.

        """"""

        ## Data point that is presented as list of coordinates.
        self.data = data

        ## Payload of node that can be used by user for storing specific information in the node.
        self.payload = payload

        ## Left node successor of the node.
        self.left = left

        ## Right node successor of the node.
        self.right = right

        ## Index of dimension.
        self.disc = disc

        ## Parent node of the node.
        self.parent = parent

    def __repr__(self):
        """"""!
        @return (string) Default representation of the node.

        """"""
        left = None
        right = None

        if self.left is not None:
            left = self.left.data

        if self.right is not None:
            right = self.right.data

        return ""(%s: [L:'%s', R:'%s'])"" % (self.data, left, right)

    def __str__(self):
        """"""!
        @return (string) String representation of the node.

        """"""
        return self.__repr__()

    def get_children(self):
        """"""!
        @brief Returns list of not `None` children of the node.

        @return (list) list of not `None` children of the node; if the node does not have children
                        then `None` is returned.

        """"""

        if self.left is not None:
            yield self.left
        if self.right is not None:
            yield self.right","class node:
    '''!
    @brief Represents a node in a KD-Tree.
    @details The KD-Tree node contains point's coordinates, discriminator, payload and pointers to parent and children.

    @see kdtree_balanced
    @see kdtree

    '''

    def __init__(self, data=None, payload=None, left=None, right=None, disc=None, parent=None):
    '''!
        @brief Creates KD-tree node.

        @param[in] data (list): Data point that is presented as list of coordinates.
        @param[in] payload (any): Payload of node (pointer to essence that is attached to this node).
        @param[in] left (node): Node of KD-Tree that represents left successor.
        @param[in] right (node): Node of KD-Tree that represents right successor.
        @param[in] disc (uint): Index of dimension of that node.
        @param[in] parent (node): Node of KD-Tree that represents parent.

        '''
        pass

    def __repr__(self):
    '''!
        @return (string) Default representation of the node.

        '''
        pass

    def __str__(self):
    '''!
        @return (string) String representation of the node.

        '''
        pass

    def get_children(self):
    '''!
        @brief Returns list of not `None` children of the node.

        @return (list) list of not `None` children of the node; if the node does not have children
                        then `None` is returned.

        '''
        pass

",5,5,snippet_331,0.9166666666666666,"class node:
    '''!
    @brief Represents a node in a KD-Tree.
    @details The KD-Tree node contains point's coordinates, discriminator, payload and pointers to parent and children.

    @see kdtree_balanced
    @see kdtree

    '''

    def __init__(self, data=None, payload=None, left=None, right=None, disc=None, parent=None):
        '''!
            @brief Creates KD-tree node.

            @param[in] data (list): Data point that is presented as list of coordinates.
            @param[in] payload (any): Payload of node (pointer to essence that is attached to this node).
            @param[in] left (node): Node of KD-Tree that represents left successor.
            @param[in] right (node): Node of KD-Tree that represents right successor.
            @param[in] disc (uint): Index of dimension of that node.
            @param[in] parent (node): Node of KD-Tree that represents parent.

        '''
        self.data = data
        self.payload = payload
        self.left = left
        self.right = right
        self.disc = disc
        self.parent = parent

    def __repr__(self):
        '''!
            @return (string) Default representation of the node.
        '''
        return f""node(data={self.data!r}, payload={self.payload!r}, disc={self.disc!r})""

    def __str__(self):
        '''!
            @return (string) String representation of the node.
        '''
        return f""KDNode at dim {self.disc} with data {self.data}""

    def get_children(self):
        '''!
            @brief Returns list of not `None` children of the node.

            @return (list) list of not `None` children of the node; if the node does not have children
                            then `None` is returned.

        '''
        children = [child for child in (self.left, self.right) if child is not None]
        return children if children else None","class node:
    '''!
    @brief Represents a node in a KD-Tree.
    @details The KD-Tree node contains point's coordinates, discriminator, payload and pointers to parent and children.

    @see kdtree_balanced
    @see kdtree

    '''

    def __init__(self, data=None, payload=None, left=None, right=None, disc=None, parent=None):
        '''!
        @brief Creates KD-tree node.

        @param[in] data (list): Data point that is presented as list of coordinates.
        @param[in] payload (any): Payload of node (pointer to essence that is attached to this node).
        @param[in] left (node): Node of KD-Tree that represents left successor.
        @param[in] right (node): Node of KD-Tree that represents right successor.
        @param[in] disc (uint): Index of dimension of that node.
        @param[in] parent (node): Node of KD-Tree that represents parent.

        '''
        self.data = data
        self.payload = payload
        self.left = left
        self.right = right
        self.disc = disc
        self.parent = parent

    def __repr__(self):
        '''!
        @return (string) Default representation of the node.

        '''
        return f""node(data={self.data}, payload={self.payload}, disc={self.disc})""

    def __str__(self):
        '''!
        @return (string) String representation of the node.

        '''
        return f""node({self.data})""

    def get_children(self):
        '''!
        @brief Returns list of not `None` children of the node.

        @return (list) list of not `None` children of the node; if the node does not have children
                        then `None` is returned.

        '''
        children = []
        if self.left is not None:
            children.append(self.left)
        if self.right is not None:
            children.append(self.right)
        
        return children if children else None","class node:
    '''!
    @brief Represents a node in a KD-Tree.
    @details The KD-Tree node contains point's coordinates, discriminator, payload and pointers to parent and children.

    @see kdtree_balanced
    @see kdtree

    '''

    def __init__(self, data=None, payload=None, left=None, right=None, disc=None, parent=None):
        '''!
        @brief Creates KD-tree node.

        @param[in] data (list): Data point that is presented as list of coordinates.
        @param[in] payload (any): Payload of node (pointer to essence that is attached to this node).
        @param[in] left (node): Node of KD-Tree that represents left successor.
        @param[in] right (node): Node of KD-Tree that represents right successor.
        @param[in] disc (uint): Index of dimension of that node.
        @param[in] parent (node): Node of KD-Tree that represents parent.

        '''
        self.data = data
        self.payload = payload
        self.left = left
        self.right = right
        self.disc = disc
        self.parent = parent

    def __repr__(self):
        '''!
        @return (string) Default representation of the node.

        '''
        return f""node(data={self.data}, payload={self.payload}, disc={self.disc})""

    def __str__(self):
        '''!
        @return (string) String representation of the node.

        '''
        return f""node(data={self.data}, payload={self.payload}, disc={self.disc})""

    def get_children(self):
        '''!
        @brief Returns list of not `None` children of the node.

        @return (list) list of not `None` children of the node; if the node does not have children
                        then `None` is returned.

        '''
        children = []
        if self.left is not None:
            children.append(self.left)
        if self.right is not None:
            children.append(self.right)
        
        return children if children else None",full_docstr,0.8272058823529412,0.7306273062730628,0.6777777777777777,0.7830882352941175,0.6249042175468286,0.8896882494004796,0.7860576923076923,0.7228915662650602,0.9438496828079224,0.9330885410308838,0.9384382963180542,0.93415367603302,0.8606715873015872,0.8450184501845018,0.7740740740740741,0.7137546468401487,0.8154981549815498,0.6460217021519181,0.916267942583732,0.8081534772182254,0.7475961538461539,0.9575231671333313,0.9371757507324219,0.9472402334213257,0.9391714930534363,0.8730171428571428,0.8451730418943534,0.7605118829981717,0.7045871559633028,0.8051001821493623,0.6560069491278271,0.8899082568807339,0.7793103448275862,0.716589861751152,0.9559285640716553,0.9389100074768066,0.9473428726196289,0.9405845999717712,0.855380634920635,0.5444186203175317,0.5299785916751806,0.5505160115461658,0.4878048780487805,0.609375,0.5773298377787277,0.5456894152415243,0.5707945700197278,0.5365853658536586,0.65625,0.5777401573602406,0.5473306935675764,0.5707945700197278,0.5365853658536586,0.65625
147553,LudovicRousseau/pyscard,LudovicRousseau_pyscard/src/smartcard/Session.py,smartcard.Session.Session,"class Session:
    """"""The Session object enables programmers to transmit APDU to smartcards.

    This is an example of use of the Session object:

    >>> import smartcard
    >>> reader=smartcard.listReaders()
    >>> s = smartcard.Session(reader[0])
    >>> SELECT = [0xA0, 0xA4, 0x00, 0x00, 0x02]
    >>> DF_TELECOM = [0x7F, 0x10]
    >>> data, sw1, sw2 = s.sendCommandAPDU(SELECT+DF_TELECOM)
    >>> print(data, sw1, sw2)
    >>> s.close()
    >>> print(`s`)
    """"""

    def __init__(self, readerName=None, cardServiceClass=None):
        """"""Session constructor. Initializes a smart card session and
        connect to the card.

        @param readerName: reader to connect to; default is first PCSC reader
        @param cardServiceClass: card service to bind the session to; default
                            is None
        """"""

        # if reader name not given, select first reader
        if readerName is None:
            if len(readers()) > 0:
                self.reader = readers()[0]
                self.readerName = repr(self.reader)
            else:
                raise NoReadersException()

        # otherwise select reader from name
        else:
            self.readerName = readerName
            for reader in readers():
                if readerName == str(reader):
                    self.reader = reader
                    self.readerName = repr(self.reader)

        try:
            self.reader
        except AttributeError:
            raise InvalidReaderException(self.readerName)

        # open card connection and bind PassThruCardService
        cc = self.reader.createConnection()
        self.cs = PassThruCardService(cc)
        self.cs.connection.connect()

    def close(self):
        """"""Close the smartcard session.

        Closing a session will disconnect from the card.""""""
        self.cs.connection.disconnect()

    def sendCommandAPDU(self, command):
        """"""Send an APDU command to the connected smartcard.

        @param command: list of APDU bytes, e.g. [0xA0, 0xA4, 0x00, 0x00, 0x02]

        @return: a tuple (response, sw1, sw2) where
                response is the APDU response
                sw1, sw2 are the two status words
        """"""

        response, sw1, sw2 = self.cs.connection.transmit(command)

        if len(response) > 2:
            response.append(sw1)
            response.append(sw2)
        return response, sw1, sw2

    def getATR(self):
        """"""Returns the ATR of the connected card.""""""
        return self.cs.connection.getATR()

    def __repr__(self):
        """"""Returns a string representation of the session.""""""
        return ""<Session instance: readerName=%s>"" % self.readerName","class Session:
    '''The Session object enables programmers to transmit APDU to smartcards.

    This is an example of use of the Session object:

    >>> import smartcard
    >>> reader=smartcard.listReaders()
    >>> s = smartcard.Session(reader[0])
    >>> SELECT = [0xA0, 0xA4, 0x00, 0x00, 0x02]
    >>> DF_TELECOM = [0x7F, 0x10]
    >>> data, sw1, sw2 = s.sendCommandAPDU(SELECT+DF_TELECOM)
    >>> print(data, sw1, sw2)
    >>> s.close()
    >>> print(`s`)
    '''

    def __init__(self, readerName=None, cardServiceClass=None):
    '''Session constructor. Initializes a smart card session and
        connect to the card.

        @param readerName: reader to connect to; default is first PCSC reader
        @param cardServiceClass: card service to bind the session to; default
                            is None
        '''
        pass

    def close(self):
    '''Close the smartcard session.

        Closing a session will disconnect from the card.'''
        pass

    def sendCommandAPDU(self, command):
    '''Send an APDU command to the connected smartcard.

        @param command: list of APDU bytes, e.g. [0xA0, 0xA4, 0x00, 0x00, 0x02]

        @return: a tuple (response, sw1, sw2) where
                response is the APDU response
                sw1, sw2 are the two status words
        '''
        pass

    def getATR(self):
    '''Returns the ATR of the connected card.'''
        pass

    def __repr__(self):
    '''Returns a string representation of the session.'''
        pass

",6,6,snippet_182,0.2352941176470588,"class Session:
    '''The Session object enables programmers to transmit APDU to smartcards.

    This is an example of use of the Session object:

    >>> import smartcard
    >>> reader=smartcard.listReaders()
    >>> s = smartcard.Session(reader[0])
    >>> SELECT = [0xA0, 0xA4, 0x00, 0x00, 0x02]
    >>> DF_TELECOM = [0x7F, 0x10]
    >>> data, sw1, sw2 = s.sendCommandAPDU(SELECT+DF_TELECOM)
    >>> print(data, sw1, sw2)
    >>> s.close()
    >>> print(`s`)
    '''

    def __init__(self, readerName=None, cardServiceClass=None):
        '''Session constructor. Initializes a smart card session and
           connect to the card.

           @param readerName: reader to connect to; default is first PCSC reader
           @param cardServiceClass: card service to bind the session to; default
                                    is None
        '''
        rdrs = readers()
        if not rdrs:
            raise NoReadersException(""No PC/SC readers found"")
        # select reader
        if readerName is None:
            self.reader = rdrs[0]
        else:
            # if user passed a Reader instance
            if readerName in rdrs:
                self.reader = readerName
            else:
                # try matching by name
                match = [r for r in rdrs if str(r) == str(readerName)]
                if match:
                    self.reader = match[0]
                else:
                    raise ValueError(""Reader %r not found"" % readerName)
        # create connection
        self.connection = self.reader.createConnection()
        try:
            self.connection.connect()
        except CardConnectionException as e:
            raise CardConnectionException(""Failed to connect to card: %s"" % e)
        # store ATR
        try:
            self._atr = self.connection.getATR()
        except Exception:
            self._atr = None
        self._connected = True

    def close(self):
        '''Close the smartcard session.

           Closing a session will disconnect from the card.'''
        if self._connected:
            try:
                self.connection.disconnect()
            except Exception:
                pass
            self._connected = False

    def sendCommandAPDU(self, command):
        '''Send an APDU command to the connected smartcard.

           @param command: list of APDU bytes, e.g. [0xA0, 0xA4, 0x00, 0x00, 0x02]

           @return: a tuple (response, sw1, sw2) where
                   response is the APDU response
                   sw1, sw2 are the two status words
        '''
        if not self._connected:
            raise CardConnectionException(""Session is closed"")
        resp = self.connection.transmit(command)
        # pyscard may return (data, sw1, sw2) or a flat list
        if isinstance(resp, tuple) and len(resp) == 3:
            return resp
        # flat list
        if isinstance(resp, list) and len(resp) >= 2:
            sw1, sw2 = resp[-2], resp[-1]
            data = resp[:-2]
            return data, sw1, sw2
        raise RuntimeError(""Unexpected response format: %r"" % resp)

    def getATR(self):
        '''Returns the ATR of the connected card.'''
        return self._atr

    def __repr__(self):
        '''Returns a string representation of the session.'''
        status = ""connected"" if self._connected else ""closed""
        reader_name = str(self.reader)
        atr = self._atr or []
        return ""<Session reader=%r ATR=%s status=%s>"" % (reader_name, atr, status)","class Session:
    '''The Session object enables programmers to transmit APDU to smartcards.

    This is an example of use of the Session object:

    >>> import smartcard
    >>> reader=smartcard.listReaders()
    >>> s = smartcard.Session(reader[0])
    >>> SELECT = [0xA0, 0xA4, 0x00, 0x00, 0x02]
    >>> DF_TELECOM = [0x7F, 0x10]
    >>> data, sw1, sw2 = s.sendCommandAPDU(SELECT+DF_TELECOM)
    >>> print(data, sw1, sw2)
    >>> s.close()
    >>> print(`s`)
    '''

    def __init__(self, readerName=None, cardServiceClass=None):
        '''Session constructor. Initializes a smart card session and
        connect to the card.

        @param readerName: reader to connect to; default is first PCSC reader
        @param cardServiceClass: card service to bind the session to; default
                            is None
        '''
        import smartcard.System
        import smartcard.CardService
        
        if readerName is None:
            readers = smartcard.System.readers()
            if readers:
                readerName = readers[0]
            else:
                raise Exception(""No smart card readers found"")
        
        self.reader = readerName
        self.connection = None
        
        # Establish connection
        self.connection = self.reader.createConnection()
        self.connection.connect()
        
    def close(self):
        '''Close the smartcard session.

        Closing a session will disconnect from the card.'''
        if self.connection:
            self.connection.disconnect()
            self.connection = None

    def sendCommandAPDU(self, command):
        '''Send an APDU command to the connected smartcard.

        @param command: list of APDU bytes, e.g. [0xA0, 0xA4, 0x00, 0x00, 0x02]

        @return: a tuple (response, sw1, sw2) where
                response is the APDU response
                sw1, sw2 are the two status words
        '''
        if not self.connection:
            raise Exception(""Session is not connected"")
            
        # Send the command and get response
        response, sw1, sw2 = self.connection.transmit(command)
        return response, sw1, sw2

    def getATR(self):
        '''Returns the ATR of the connected card.'''
        if not self.connection:
            raise Exception(""Session is not connected"")
            
        return self.connection.getATR()

    def __repr__(self):
        '''Returns a string representation of the session.'''
        if self.connection:
            return f""<Session connected to {self.reader}>""
        else:
            return f""<Session closed>""","class Session:
    '''The Session object enables programmers to transmit APDU to smartcards.

    This is an example of use of the Session object:

    >>> import smartcard
    >>> reader=smartcard.listReaders()
    >>> s = smartcard.Session(reader[0])
    >>> SELECT = [0xA0, 0xA4, 0x00, 0x00, 0x02]
    >>> DF_TELECOM = [0x7F, 0x10]
    >>> data, sw1, sw2 = s.sendCommandAPDU(SELECT+DF_TELECOM)
    >>> print(data, sw1, sw2)
    >>> s.close()
    >>> print(`s`)
    '''

    def __init__(self, readerName=None, cardServiceClass=None):
        '''Session constructor. Initializes a smart card session and
        connect to the card.

        @param readerName: reader to connect to; default is first PCSC reader
        @param cardServiceClass: card service to bind the session to; default
                            is None
        '''
        from smartcard.System import readers
        from smartcard.CardService import CardService
        from smartcard.CardConnection import CardConnection
        
        if readerName is None:
            reader_list = readers()
            if not reader_list:
                raise Exception(""No smart card readers available"")
            self.reader = reader_list[0]
        else:
            self.reader = readerName
            
        self.cardServiceClass = cardServiceClass
        self.connection = self.reader.createConnection()
        self.connection.connect()
        self.closed = False

    def close(self):
        '''Close the smartcard session.

        Closing a session will disconnect from the card.'''
        if not self.closed:
            self.connection.disconnect()
            self.closed = True

    def sendCommandAPDU(self, command):
        '''Send an APDU command to the connected smartcard.

        @param command: list of APDU bytes, e.g. [0xA0, 0xA4, 0x00, 0x00, 0x02]

        @return: a tuple (response, sw1, sw2) where
                response is the APDU response
                sw1, sw2 are the two status words
        '''
        if self.closed:
            raise Exception(""Session is closed"")
        
        response, sw1, sw2 = self.connection.transmit(command)
        return response, sw1, sw2

    def getATR(self):
        '''Returns the ATR of the connected card.'''
        if self.closed:
            raise Exception(""Session is closed"")
        
        return self.connection.getATR()

    def __repr__(self):
        '''Returns a string representation of the session.'''
        if self.closed:
            return f""<Session: closed>""
        else:
            return f""<Session: {self.reader.name}>""",full_docstr,0.7681159420289856,0.5843023255813953,0.5131195335276967,0.6753623188405797,0.5782462064819471,0.7056338028169014,0.5655853314527504,0.4844632768361582,0.8988217115402222,0.9416652917861938,0.9197448492050171,0.9371979236602783,0.7914550769230769,0.8184931506849316,0.6907216494845361,0.6379310344827587,0.7636986301369861,0.6728672291840496,0.878968253968254,0.7495029821073559,0.6693227091633466,0.9433375597000122,0.9268292784690857,0.9350106120109558,0.9284541010856628,0.7840221348314607,0.8313458262350938,0.6871794871794872,0.6277873070325899,0.7597955706984669,0.6808925725639431,0.8771929824561403,0.7421875,0.6614481409001957,0.9377568960189819,0.9260256290435791,0.9318543672561646,0.927185595035553,0.7877674157303369,0.5278132225388373,0.4337246462800583,0.6117104533444444,0.4926470588235294,0.573170731707317,0.4497504207242431,0.5982173999795343,0.6060927477667929,0.4117647058823529,0.1829268292682926,0.4832463559983696,0.596530361026618,0.6051064259510784,0.4264705882352941,0.3048780487804878
216175,aewallin/allantools,allantools/plot.py,allantools.plot.Plot,"class Plot(object):
    """""" A class for plotting data once computed by Allantools

    :Example:
        ::

            import allantools
            import numpy as np
            a = allantools.Dataset(data=np.random.rand(1000))
            a.compute(""mdev"")
            b = allantools.Plot()
            b.plot(a)
            b.show()

    Uses matplotlib. self.fig and self.ax stores the return values of
    matplotlib.pyplot.subplots(). plot() sets various defaults, but you
    can change them by using standard matplotlib method on self.fig and self.ax
    """"""
    def __init__(self, no_display=False):
        """""" set ``no_display`` to ``True`` when we don't have an X-window
        (e.g. for tests)
        """"""
        try:
            import matplotlib
            if no_display:
                matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            self.plt = plt
        except ImportError:
            raise RuntimeError(""Matplotlib is required for plotting"")
        self.fig, self.ax = plt.subplots()
        self.ax.set_xscale(""log"")
        self.ax.set_yscale(""log"")

    def plot(self, atDataset,
             errorbars=False,
             grid=False,
             **kwargs):
        """""" Use matplotlib methods for plotting

        Additional keywords arguments are passed to
        :py:func:`matplotlib.pyplot.plot`.

        Parameters
        ----------
        atDataset : allantools.Dataset()
            a dataset with computed data
        errorbars : boolean
            Plot errorbars. Defaults to False
        grid : boolean
            Plot grid. Defaults to False

        """"""
        if errorbars:
            self.ax.errorbar(atDataset.out[""taus""],
                             atDataset.out[""stat""],
                             yerr=atDataset.out[""stat_err""],
                             **kwargs)
        else:
            self.ax.plot(atDataset.out[""taus""],
                         atDataset.out[""stat""],
                         **kwargs)
        self.ax.set_xlabel(""Tau"")
        self.ax.set_ylabel(atDataset.out[""stat_id""])

        if grid:
            self.ax.grid(True, which=""minor"", ls=""-"", color='0.65')
            self.ax.grid(True, which=""major"", ls=""-"", color='0.25')
        else:
            self.ax.grid(False)

    def show(self):
        """"""Calls matplotlib.pyplot.show()

        Keeping this separated from ``plot()`` allows to tweak display before
        rendering
        """"""
        self.plt.show()

    def save(self, f):
        """"""Save figure to file
        """"""
        self.plt.savefig(f)","class Plot(object):
    ''' A class for plotting data once computed by Allantools

    :Example:
        ::

            import allantools
            import numpy as np
            a = allantools.Dataset(data=np.random.rand(1000))
            a.compute(""mdev"")
            b = allantools.Plot()
            b.plot(a)
            b.show()

    Uses matplotlib. self.fig and self.ax stores the return values of
    matplotlib.pyplot.subplots(). plot() sets various defaults, but you
    can change them by using standard matplotlib method on self.fig and self.ax
    '''

    def __init__(self, no_display=False):
    ''' set ``no_display`` to ``True`` when we don't have an X-window
        (e.g. for tests)
        '''
        pass

    def plot(self, atDataset,
             errorbars=False,
             grid=False,
             **kwargs):
    ''' Use matplotlib methods for plotting

        Additional keywords arguments are passed to
        :py:func:`matplotlib.pyplot.plot`.

        Parameters
        ----------
        atDataset : allantools.Dataset()
            a dataset with computed data
        errorbars : boolean
            Plot errorbars. Defaults to False
        grid : boolean
            Plot grid. Defaults to False

        '''
        pass

    def show(self):
    '''Calls matplotlib.pyplot.show()

        Keeping this separated from ``plot()`` allows to tweak display before
        rendering
        '''
        pass

    def save(self, f):
    '''Save figure to file
        '''
        pass

",5,5,snippet_304,0.25,"class Plot(object):
    ''' A class for plotting data once computed by Allantools

    :Example:
        ::

            import allantools
            import numpy as np
            a = allantools.Dataset(data=np.random.rand(1000))
            a.compute(""mdev"")
            b = allantools.Plot()
            b.plot(a)
            b.show()

    Uses matplotlib. self.fig and self.ax stores the return values of
    matplotlib.pyplot.subplots(). plot() sets various defaults, but you
    can change them by using standard matplotlib method on self.fig and self.ax
    '''
    def __init__(self, no_display=False):
        ''' set ``no_display`` to ``True`` when we don't have an X-window
            (e.g. for tests)
        '''
        if no_display:
            matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        self.plt = plt
        self.fig, self.ax = plt.subplots()
        self.no_display = no_display

    def plot(self, atDataset,
             errorbars=False,
             grid=False,
             **kwargs):
        ''' Use matplotlib methods for plotting

            Additional keywords arguments are passed to
            :py:func:`matplotlib.pyplot.plot`.

            Parameters
            ----------
            atDataset : allantools.Dataset()
                a dataset with computed data
            errorbars : boolean
                Plot errorbars. Defaults to False
            grid : boolean
                Plot grid. Defaults to False

        '''
        # Expecting atDataset._results to be a dict mapping method names
        # to tuples/lists (taus, values, [errors])
        if not hasattr(atDataset, '_results'):
            raise AttributeError(""Dataset has no '_results' attribute; run compute() first"")
        for name, data in atDataset._results.items():
            # data: (taus, values) or (taus, values, errors)
            taus = data[0]
            vals = data[1]
            errs = data[2] if (errorbars and len(data) > 2) else None

            if errorbars and errs is not None:
                self.ax.errorbar(taus, vals, yerr=errs, label=name, **kwargs)
            else:
                self.ax.plot(taus, vals, label=name, **kwargs)

        # log-log by default for Allan-type plots
        self.ax.set_xscale('log')
        self.ax.set_yscale('log')

        # Labels
        self.ax.set_xlabel('Tau')
        self.ax.set_ylabel('Allan deviation')

        if grid:
            self.ax.grid(True)

        self.ax.legend()

    def show(self):
        '''Calls matplotlib.pyplot.show()

            Keeping this separated from ``plot()`` allows to tweak display before
            rendering
        '''
        self.plt.show()

    def save(self, f):
        '''Save figure to file'''
        self.fig.savefig(f)","class Plot(object):
    ''' A class for plotting data once computed by Allantools

    :Example:
        ::

            import allantools
            import numpy as np
            a = allantools.Dataset(data=np.random.rand(1000))
            a.compute(""mdev"")
            b = allantools.Plot()
            b.plot(a)
            b.show()

    Uses matplotlib. self.fig and self.ax stores the return values of
    matplotlib.pyplot.subplots(). plot() sets various defaults, but you
    can change them by using standard matplotlib method on self.fig and self.ax
    '''

    def __init__(self, no_display=False):
        ''' set ``no_display`` to ``True`` when we don't have an X-window
        (e.g. for tests)
        '''
        self.no_display = no_display
        if no_display:
            import matplotlib
            matplotlib.use('Agg')
        self.fig = None
        self.ax = None

    def plot(self, atDataset,
             errorbars=False,
             grid=False,
             **kwargs):
        ''' Use matplotlib methods for plotting

        Additional keywords arguments are passed to
        :py:func:`matplotlib.pyplot.plot`.

        Parameters
        ----------
        atDataset : allantools.Dataset()
            a dataset with computed data
        errorbars : boolean
            Plot errorbars. Defaults to False
        grid : boolean
            Plot grid. Defaults to False

        '''
        self.fig, self.ax = plt.subplots()
        
        if errorbars and hasattr(atDataset, 'dev_err') and atDataset.dev_err is not None:
            self.ax.errorbar(atDataset.tau, atDataset.dev, yerr=atDataset.dev_err, 
                           **kwargs)
        else:
            self.ax.plot(atDataset.tau, atDataset.dev, **kwargs)
            
        self.ax.set_xscale('log')
        self.ax.set_yscale('log')
        
        if grid:
            self.ax.grid(True)
            
        self.ax.set_xlabel('Tau')
        self.ax.set_ylabel('Deviation')

    def show(self):
        '''Calls matplotlib.pyplot.show()

        Keeping this separated from ``plot()`` allows to tweak display before
        rendering
        '''
        if self.fig is not None:
            plt.show()

    def save(self, f):
        '''Save figure to file
        '''
        if self.fig is not None:
            self.fig.savefig(f)","class Plot(object):
    ''' A class for plotting data once computed by Allantools

    :Example:
        ::

            import allantools
            import numpy as np
            a = allantools.Dataset(data=np.random.rand(1000))
            a.compute(""mdev"")
            b = allantools.Plot()
            b.plot(a)
            b.show()

    Uses matplotlib. self.fig and self.ax stores the return values of
    matplotlib.pyplot.subplots(). plot() sets various defaults, but you
    can change them by using standard matplotlib method on self.fig and self.ax
    '''

    def __init__(self, no_display=False):
        ''' set ``no_display`` to ``True`` when we don't have an X-window
            (e.g. for tests)
        '''
        if no_display:
            import matplotlib
            matplotlib.use('Agg')
        
        import matplotlib.pyplot as plt
        self.plt = plt
        self.fig, self.ax = plt.subplots()

    def plot(self, atDataset,
             errorbars=False,
             grid=False,
             **kwargs):
        ''' Use matplotlib methods for plotting

            Additional keywords arguments are passed to
            :py:func:`matplotlib.pyplot.plot`.

            Parameters
            ----------
            atDataset : allantools.Dataset()
                a dataset with computed data
            errorbars : boolean
                Plot errorbars. Defaults to False
            grid : boolean
                Plot grid. Defaults to False

        '''
        if errorbars and hasattr(atDataset, 'errors') and atDataset.errors is not None:
            self.ax.errorbar(atDataset.taus, atDataset.out, yerr=atDataset.errors, **kwargs)
        else:
            self.ax.plot(atDataset.taus, atDataset.out, **kwargs)
        
        self.ax.set_xscale('log')
        self.ax.set_yscale('log')
        self.ax.set_xlabel('Tau')
        self.ax.set_ylabel('Allan Deviation')
        
        if grid:
            self.ax.grid(True)

    def show(self):
        '''Calls matplotlib.pyplot.show()

            Keeping this separated from ``plot()`` allows to tweak display before
            rendering
        '''
        self.plt.show()

    def save(self, f):
        '''Save figure to file
        '''
        self.fig.savefig(f)",full_docstr,0.7987012987012988,0.7198697068403909,0.6797385620915034,0.7402597402597402,0.690265382318588,0.7838765008576329,0.6752577319587629,0.621342512908778,0.905693531036377,0.9373049736022949,0.9212281703948975,0.9340448975563049,0.8183712693498455,0.8520499108734402,0.7656529516994633,0.7073608617594255,0.7843137254901962,0.6778492025359133,0.893970893970894,0.8125,0.7432150313152401,0.9415580034255981,0.9245188236236572,0.9329606294631958,0.926194965839386,0.8317870278637777,0.9027522935779817,0.8397790055248618,0.7837338262476894,0.8513761467889909,0.681459507486066,0.9449339207048458,0.8785871964679912,0.8163716814159292,0.9518529176712036,0.9336675405502319,0.9426725506782532,0.9354547262191772,0.8730662848297214,0.6526363784322088,0.5266026814829935,0.6931736014766108,0.66,0.7307692307692307,0.5524157600695483,0.6394162463951047,0.6502467938830885,0.5866666666666667,0.3333333333333333,0.6977071835116498,0.6806438039434274,0.6881336480518898,0.64,0.782051282051282
339570,digidotcom/python-devicecloud,digidotcom_python-devicecloud/devicecloud/monitor_tcp.py,devicecloud.monitor_tcp.CallbackWorkerPool,"class CallbackWorkerPool(object):
    """"""
    A Worker Pool implementation that creates a number of predefined threads
    used for invoking Session callbacks.
    """"""

    def __init__(self, write_queue=None, size=1):
        """"""
        Creates a Callback Worker Pool for use in invoking Session Callbacks
        when data is received by a push client.

        :param write_queue: Queue used for queueing up socket write events
            for when a payload message is received and processed.
        :param size: The number of worker threads to invoke callbacks.
        """"""
        # Used to queue up PublishMessageReceived events to be sent back to
        # the iDigi server.
        self._write_queue = write_queue
        # Used to queue up sessions and data to callback with.
        self._queue = Queue(size)
        # Number of workers to create.
        self.size = size
        self.log = logging.getLogger('{}.callback_worker_pool'.format(__name__))

        for _ in range(size):
            worker = Thread(target=self._consume_queue)
            worker.daemon = True
            worker.start()

    def _consume_queue(self):
        """"""
        Continually blocks until data is on the internal queue, then calls
        the session's registered callback and sends a PublishMessageReceived
        if callback returned True.
        """"""
        while True:
            session, block_id, raw_data = self._queue.get()
            data = json.loads(raw_data.decode('utf-8'))  # decode as JSON
            try:
                result = session.callback(data)
                if result is None:
                    self.log.warn(""Callback %r returned None, expected boolean.  Messages ""
                                  ""are not marked as received unless True is returned"", session.callback)
                elif result:
                    # Send a Successful PublishMessageReceived with the
                    # block id sent in request
                    if self._write_queue is not None:
                        response_message = struct.pack('!HHH',
                                                       PUBLISH_MESSAGE_RECEIVED,
                                                       block_id, 200)
                        self._write_queue.put((session.socket, response_message))
            except Exception as exception:
                self.log.exception(exception)

            self._queue.task_done()

    def queue_callback(self, session, block_id, data):
        """"""
        Queues up a callback event to occur for a session with the given
        payload data.  Will block if the queue is full.

        :param session: the session with a defined callback function to call.
        :param block_id: the block_id of the message received.
        :param data: the data payload of the message received.
        """"""
        self._queue.put((session, block_id, data))","class CallbackWorkerPool(object):
    '''
    A Worker Pool implementation that creates a number of predefined threads
    used for invoking Session callbacks.
    '''

    def __init__(self, write_queue=None, size=1):
    '''
        Creates a Callback Worker Pool for use in invoking Session Callbacks
        when data is received by a push client.

        :param write_queue: Queue used for queueing up socket write events
            for when a payload message is received and processed.
        :param size: The number of worker threads to invoke callbacks.
        '''
        pass

    def _consume_queue(self):
    '''
        Continually blocks until data is on the internal queue, then calls
        the session's registered callback and sends a PublishMessageReceived
        if callback returned True.
        '''
        pass

    def queue_callback(self, session, block_id, data):
    '''
        Queues up a callback event to occur for a session with the given
        payload data.  Will block if the queue is full.

        :param session: the session with a defined callback function to call.
        :param block_id: the block_id of the message received.
        :param data: the data payload of the message received.
        '''
        pass

",4,4,snippet_585,0.1538461538461538,"class CallbackWorkerPool(object):
    '''
    A Worker Pool implementation that creates a number of predefined threads
    used for invoking Session callbacks.
    '''

    def __init__(self, write_queue=None, size=1):
        '''
        Creates a Callback Worker Pool for use in invoking Session Callbacks
        when data is received by a push client.

        :param write_queue: Queue used for queueing up socket write events
            for when a payload message is received and processed.
        :param size: The number of worker threads to invoke callbacks.
        '''
        self._write_queue = write_queue
        self._queue = queue.Queue()
        self._threads = []
        for _ in range(size):
            t = threading.Thread(target=self._consume_queue)
            t.daemon = True
            t.start()
            self._threads.append(t)

    def _consume_queue(self):
        '''
        Continually blocks until data is on the internal queue, then calls
        the session's registered callback and sends a PublishMessageReceived
        if callback returned True.
        '''
        while True:
            session, block_id, data = self._queue.get()
            try:
                cb = getattr(session, 'callback', None)
                result = False
                if callable(cb):
                    result = cb(block_id, data)
                if result and self._write_queue:
                    # queue a write event for a PublishMessageReceived
                    self._write_queue.put((session, block_id))
            except Exception:
                pass
            finally:
                self._queue.task_done()

    def queue_callback(self, session, block_id, data):
        '''
        Queues up a callback event to occur for a session with the given
        payload data.  Will block if the queue is full.

        :param session: the session with a defined callback function to call.
        :param block_id: the block_id of the message received.
        :param data: the data payload of the message received.
        '''
        self._queue.put((session, block_id, data))","class CallbackWorkerPool(object):
    '''
    A Worker Pool implementation that creates a number of predefined threads
    used for invoking Session callbacks.
    '''

    def __init__(self, write_queue=None, size=1):
        '''
        Creates a Callback Worker Pool for use in invoking Session Callbacks
        when data is received by a push client.

        :param write_queue: Queue used for queueing up socket write events
            for when a payload message is received and processed.
        :param size: The number of worker threads to invoke callbacks.
        '''
        self.write_queue = write_queue
        self.size = size
        self.queue = queue.Queue()
        self.threads = []
        self._stop_event = threading.Event()
        
        for _ in range(self.size):
            thread = threading.Thread(target=self._consume_queue)
            thread.daemon = True
            thread.start()
            self.threads.append(thread)

    def _consume_queue(self):
        '''
        Continually blocks until data is on the internal queue, then calls
        the session's registered callback and sends a PublishMessageReceived
        if callback returned True.
        '''
        while not self._stop_event.is_set():
            try:
                item = self.queue.get(timeout=1)
                if item is None:
                    break
                    
                session, block_id, data = item
                
                # Call the session's callback
                callback_result = session.callback(block_id, data)
                
                # If callback returned True and we have a write_queue, send PublishMessageReceived
                if callback_result and self.write_queue is not None:
                    # Assuming PublishMessageReceived is some message type to be sent
                    # This would depend on the specific implementation details
                    publish_message = {
                        'type': 'PublishMessageReceived',
                        'block_id': block_id,
                        'session_id': getattr(session, 'id', None)
                    }
                    self.write_queue.put(publish_message)
                    
                self.queue.task_done()
            except queue.Empty:
                continue
            except Exception:
                # Handle any exceptions that might occur during callback execution
                if not self.queue.empty():
                    self.queue.task_done()
                continue

    def queue_callback(self, session, block_id, data):
        '''
        Queues up a callback event to occur for a session with the given
        payload data.  Will block if the queue is full.

        :param session: the session with a defined callback function to call.
        :param block_id: the block_id of the message received.
        :param data: the data payload of the message received.
        '''
        self.queue.put((session, block_id, data))","class CallbackWorkerPool(object):
    '''
    A Worker Pool implementation that creates a number of predefined threads
    used for invoking Session callbacks.
    '''

    def __init__(self, write_queue=None, size=1):
        '''
        Creates a Callback Worker Pool for use in invoking Session Callbacks
        when data is received by a push client.

        :param write_queue: Queue used for queueing up socket write events
            for when a payload message is received and processed.
        :param size: The number of worker threads to invoke callbacks.
        '''
        self.write_queue = write_queue
        self.size = size
        self.callback_queue = queue.Queue()
        self.workers = []
        self.running = True
        
        for _ in range(size):
            worker = threading.Thread(target=self._consume_queue)
            worker.daemon = True
            worker.start()
            self.workers.append(worker)

    def _consume_queue(self):
        '''
        Continually blocks until data is on the internal queue, then calls
        the session's registered callback and sends a PublishMessageReceived
        if callback returned True.
        '''
        while self.running:
            try:
                session, block_id, data = self.callback_queue.get(timeout=1)
                if session.callback:
                    result = session.callback(block_id, data)
                    if result and self.write_queue:
                        self.write_queue.put(('PublishMessageReceived', session, block_id))
                self.callback_queue.task_done()
            except queue.Empty:
                continue
            except:
                break

    def queue_callback(self, session, block_id, data):
        '''
        Queues up a callback event to occur for a session with the given
        payload data.  Will block if the queue is full.

        :param session: the session with a defined callback function to call.
        :param block_id: the block_id of the message received.
        :param data: the data payload of the message received.
        '''
        self.callback_queue.put((session, block_id, data))",full_docstr,0.7925801011804384,0.6971235194585449,0.6451612903225806,0.7521079258010117,0.565156218220452,0.9245742092457421,0.7878048780487805,0.7212713936430318,0.9310146570205688,0.8848017454147339,0.9073200821876526,0.8892154693603516,0.8587374721189591,0.7786032689450222,0.6289120715350223,0.5620328849028402,0.6894502228826151,0.6095151843910709,0.8228571428571428,0.6240458015267175,0.5296367112810707,0.9125431776046753,0.8956781625747681,0.9040320515632629,0.8973365426063538,0.8327460777385159,0.8221476510067114,0.696969696969697,0.6317567567567567,0.7516778523489933,0.5661487141810846,0.9390243902439024,0.8019559902200489,0.7083333333333334,0.9417426586151123,0.8850508332252502,0.9125171303749084,0.8904110193252563,0.8426285873605946,0.4998838226227898,0.5101672116247042,0.5333790816171429,0.5581395348837209,0.3978494623655914,0.532535917663479,0.5305420093875601,0.5408369700935625,0.5426356589147286,0.5161290322580645,0.512740736571063,0.5016571593665585,0.5335518484330725,0.5426356589147286,0.4731182795698925
388376,fossasia/AYABInterface,fossasia_AYABInterface/AYABInterface/carriages.py,AYABInterface.carriages.Carriage,"class Carriage(object):

    """"""A base class for carriages.""""""

    def __eq__(self, other):
        """"""Equivalent to ``self == other``.""""""
        return other == (self.__class__,)

    def __hash__(self):
        """"""Make this object hashable.""""""
        return hash((self.__class__,))

    def __repr__(self):
        """"""This object as string.""""""
        return self.__class__.__name__","class Carriage(object):
    '''A base class for carriages.'''

    def __eq__(self, other):
    '''Equivalent to ``self == other``.'''
        pass

    def __hash__(self):
    '''Make this object hashable.'''
        pass

    def __repr__(self):
    '''This object as string.'''
        pass

",4,4,snippet_657,1.0,"class Carriage(object):
    '''A base class for carriages.'''

    def __eq__(self, other):
        '''Equivalent to ``self == other``.'''
        if self is other:
            return True
        if not isinstance(other, self.__class__):
            return NotImplemented
        return self.__dict__ == other.__dict__

    def __hash__(self):
        '''Make this object hashable.'''
        return hash((self.__class__, frozenset(self.__dict__.items())))

    def __repr__(self):
        '''This object as string.'''
        attrs = ', '.join(f""{k}={v!r}"" for k, v in sorted(self.__dict__.items()))
        return f""{self.__class__.__name__}({attrs})""","class Carriage(object):
    '''A base class for carriages.'''

    def __eq__(self, other):
        '''Equivalent to ``self == other``.'''
        return isinstance(other, self.__class__)

    def __hash__(self):
        '''Make this object hashable.'''
        return hash(self.__class__)

    def __repr__(self):
        '''This object as string.'''
        return f""{self.__class__.__name__}()""","class Carriage(object):
    '''A base class for carriages.'''

    def __eq__(self, other):
        '''Equivalent to ``self == other``.'''
        if not isinstance(other, Carriage):
            return False
        return self.__dict__ == other.__dict__

    def __hash__(self):
        '''Make this object hashable.'''
        return hash(tuple(sorted(self.__dict__.items())))

    def __repr__(self):
        '''This object as string.'''
        return f""{self.__class__.__name__}()""",full_docstr,0.7058823529411764,0.6324786324786326,0.5217391304347827,0.7058823529411764,0.4441798485766822,0.5320197044334976,0.43564356435643564,0.3781094527363184,0.8035411834716797,0.9366019368171692,0.8649843335151672,0.9213451743125916,0.8172857777777778,0.9767441860465117,0.9285714285714286,0.8780487804878048,0.9767441860465117,0.6398344671559048,0.8956521739130435,0.7280701754385965,0.6283185840707964,0.9626582860946655,0.9823957681655884,0.9724268913269043,0.9803856611251831,0.955882794117647,0.8333333333333334,0.7021276595744681,0.608695652173913,0.8125000000000001,0.5896777651828059,0.7357142857142858,0.5827338129496403,0.4782608695652174,0.8882903456687927,0.9518980979919434,0.9189948439598083,0.9451302886009216,0.8939404545454545,0.3440053452737587,0.0531931379694141,0.0937373340347115,0.32,0.9090909090909092,0.3297022128223637,0.0872639074765505,0.0933631256310861,0.32,0.8181818181818182,0.2812138714734825,0.0747545154955823,0.0937373340347115,0.32,0.6363636363636364
315768,contentful-labs/contentful.py,contentful-labs_contentful.py/contentful/cda/client.py,contentful.cda.client.Dispatcher,"class Dispatcher(object):
    """"""Responsible for invoking :class:`.Request` instances and delegating result processing.

    **Attributes**:

    - config (:class:`.Config`): Configuration settings.
    - resource_factory (:class:`.ResourceFactory`): Factory to use for generating resources out of JSON responses.
    - httpclient (module): HTTP client module.
    - base_url (str): Base URL of the remote endpoint.
    - user_agent (str): ``User-Agent`` header to pass with requests.
    """"""
    def __init__(self, config, httpclient):
        """"""Dispatcher constructor.

        :param config: Configuration container.
        :param httpclient: HTTP client.
        :return: :class:`.Dispatcher` instance.
        """"""
        super(Dispatcher, self).__init__()
        self.config = config
        self.resource_factory = ResourceFactory(config.custom_entries)
        self.httpclient = httpclient
        self.user_agent = 'contentful.py/{0}'.format(__version__)

        scheme = 'https' if config.secure else 'http'
        self.base_url = '{0}://{1}/spaces/{2}'.format(scheme, config.endpoint, config.space_id)

    def invoke(self, request):
        """"""Invoke the given :class:`.Request` instance using the associated :class:`.Dispatcher`.

        :param request: :class:`.Request` instance to invoke.
        :return: :class:`.Resource` subclass.
        """"""
        url = '{0}/{1}'.format(self.base_url, request.remote_path)
        r = self.httpclient.get(url, params=request.params, headers=self.get_headers())
        if 200 <= r.status_code < 300:
            return self.resource_factory.from_json(r.json())
        else:
            if r.status_code in ErrorMapping.mapping:
                raise ErrorMapping.mapping[r.status_code](r)
            else:
                raise ApiError(r)

    def get_headers(self):
        """"""Create and return a base set of headers to be carried with all requests.

        :return: dict containing header values.
        """"""
        return {'Authorization': 'Bearer {0}'.format(self.config.access_token), 'User-Agent': self.user_agent}","class Dispatcher(object):
    '''Responsible for invoking :class:`.Request` instances and delegating result processing.

    **Attributes**:

    - config (:class:`.Config`): Configuration settings.
    - resource_factory (:class:`.ResourceFactory`): Factory to use for generating resources out of JSON responses.
    - httpclient (module): HTTP client module.
    - base_url (str): Base URL of the remote endpoint.
    - user_agent (str): ``User-Agent`` header to pass with requests.
    '''

    def __init__(self, config, httpclient):
    '''Dispatcher constructor.

        :param config: Configuration container.
        :param httpclient: HTTP client.
        :return: :class:`.Dispatcher` instance.
        '''
        pass

    def invoke(self, request):
    '''Invoke the given :class:`.Request` instance using the associated :class:`.Dispatcher`.

        :param request: :class:`.Request` instance to invoke.
        :return: :class:`.Resource` subclass.
        '''
        pass

    def get_headers(self):
    '''Create and return a base set of headers to be carried with all requests.

        :return: dict containing header values.
        '''
        pass

",4,4,snippet_548,0.1818181818181818,"class Dispatcher(object):
    '''Responsible for invoking :class:`.Request` instances and delegating result processing.

    **Attributes**:

    - config (:class:`.Config`): Configuration settings.
    - resource_factory (:class:`.ResourceFactory`): Factory to use for generating resources out of JSON responses.
    - httpclient (module): HTTP client module.
    - base_url (str): Base URL of the remote endpoint.
    - user_agent (str): ``User-Agent`` header to pass with requests.
    '''

    def __init__(self, config, httpclient):
        '''Dispatcher constructor.

        :param config: Configuration container.
        :param httpclient: HTTP client.
        :return: :class:`.Dispatcher` instance.
        '''
        self.config = config
        self.httpclient = httpclient
        self.resource_factory = getattr(config, 'resource_factory', None)
        self.base_url = getattr(config, 'base_url', '').rstrip('/')
        self.user_agent = getattr(config, 'user_agent', 'python-dispatcher/1.0')

    def invoke(self, request):
        '''Invoke the given :class:`.Request` instance using the associated :class:`.Dispatcher`.

        :param request: :class:`.Request` instance to invoke.
        :return: :class:`.Resource` subclass.
        '''
        # Build URL
        path = request.path.lstrip('/')
        url = urljoin(self.base_url + '/', path)

        # Build headers
        headers = self.get_headers()
        if hasattr(request, 'headers') and request.headers:
            headers.update(request.headers)

        # Prepare request arguments
        method = request.method.upper()
        params = getattr(request, 'params', None)
        data = getattr(request, 'data', None)
        json_body = getattr(request, 'json', None)

        # Dispatch HTTP request
        response = self.httpclient.request(
            method,
            url,
            headers=headers,
            params=params,
            data=data,
            json=json_body,
            timeout=getattr(self.config, 'timeout', None)
        )
        # Raise for HTTP errors
        try:
            response.raise_for_status()
        except AttributeError:
            # Fallback if httpclient.request returns a tuple or custom response
            if not (200 <= response.status_code < 300):
                raise

        # Process empty responses
        content = getattr(response, 'content', None)
        if content is None or (isinstance(content, (bytes, str)) and len(content) == 0):
            return None

        # Parse JSON
        try:
            payload = response.json()
        except (ValueError, AttributeError):
            payload = None

        # Delegate to resource factory
        if self.resource_factory and hasattr(request, 'resource_class'):
            return self.resource_factory.create(request.resource_class, payload)
        return payload

    def get_headers(self):
        '''Create and return a base set of headers to be carried with all requests.

        :return: dict containing header values.
        '''
        headers = {
            'User-Agent': self.user_agent,
            'Accept': 'application/json'
        }
        # Allow additional default headers from config
        extra = getattr(self.config, 'default_headers', {})
        if isinstance(extra, dict):
            headers.update(extra)
        return headers","class Dispatcher(object):
    '''Responsible for invoking :class:`.Request` instances and delegating result processing.

    **Attributes**:

    - config (:class:`.Config`): Configuration settings.
    - resource_factory (:class:`.ResourceFactory`): Factory to use for generating resources out of JSON responses.
    - httpclient (module): HTTP client module.
    - base_url (str): Base URL of the remote endpoint.
    - user_agent (str): ``User-Agent`` header to pass with requests.
    '''

    def __init__(self, config, httpclient):
        '''Dispatcher constructor.

        :param config: Configuration container.
        :param httpclient: HTTP client.
        :return: :class:`.Dispatcher` instance.
        '''
        self.config = config
        self.resource_factory = config.resource_factory
        self.httpclient = httpclient
        self.base_url = config.base_url
        self.user_agent = config.user_agent

    def invoke(self, request):
        '''Invoke the given :class:`.Request` instance using the associated :class:`.Dispatcher`.

        :param request: :class:`.Request` instance to invoke.
        :return: :class:`.Resource` subclass.
        '''
        url = self.base_url + request.path
        headers = self.get_headers()
        headers.update(request.headers or {})
        
        if request.method == 'GET':
            response = self.httpclient.get(url, headers=headers, params=request.params)
        elif request.method == 'POST':
            response = self.httpclient.post(url, headers=headers, data=request.data, json=request.json)
        elif request.method == 'PUT':
            response = self.httpclient.put(url, headers=headers, data=request.data, json=request.json)
        elif request.method == 'DELETE':
            response = self.httpclient.delete(url, headers=headers)
        else:
            raise ValueError(f""Unsupported HTTP method: {request.method}"")
        
        return self.resource_factory.create(response.json())

    def get_headers(self):
        '''Create and return a base set of headers to be carried with all requests.

        :return: dict containing header values.
        '''
        return {
            'User-Agent': self.user_agent,
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        }","class Dispatcher(object):
    '''Responsible for invoking :class:`.Request` instances and delegating result processing.

    **Attributes**:

    - config (:class:`.Config`): Configuration settings.
    - resource_factory (:class:`.ResourceFactory`): Factory to use for generating resources out of JSON responses.
    - httpclient (module): HTTP client module.
    - base_url (str): Base URL of the remote endpoint.
    - user_agent (str): ``User-Agent`` header to pass with requests.
    '''

    def __init__(self, config, httpclient):
        '''Dispatcher constructor.

        :param config: Configuration container.
        :param httpclient: HTTP client.
        :return: :class:`.Dispatcher` instance.
        '''
        self.config = config
        self.resource_factory = config.resource_factory
        self.httpclient = httpclient
        self.base_url = config.base_url
        self.user_agent = config.user_agent

    def invoke(self, request):
        '''Invoke the given :class:`.Request` instance using the associated :class:`.Dispatcher`.

        :param request: :class:`.Request` instance to invoke.
        :return: :class:`.Resource` subclass.
        '''
        headers = self.get_headers()
        headers.update(request.headers or {})
        
        url = self.base_url + request.path
        
        response = self.httpclient.request(
            method=request.method,
            url=url,
            headers=headers,
            data=request.data,
            params=request.params
        )
        
        return self.resource_factory.create(response.json(), response.status_code, response.headers)

    def get_headers(self):
        '''Create and return a base set of headers to be carried with all requests.

        :return: dict containing header values.
        '''
        return {
            'User-Agent': self.user_agent,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }",full_docstr,0.6497461928934011,0.5161290322580645,0.46337308347529815,0.5549915397631133,0.4991839837729347,0.6183431952662722,0.4740740740740741,0.42433234421364985,0.8442131876945496,0.890310525894165,0.8666492700576782,0.8854755163192749,0.7708853460620527,0.7235772357723577,0.6326530612244897,0.5778688524590163,0.6788617886178862,0.6246670401848949,0.7797979797979798,0.631578947368421,0.5760649087221096,0.9090505838394165,0.8806214928627014,0.8946102261543274,0.8833840489387512,0.8058498947368424,0.7757847533632286,0.6846846846846846,0.6244343891402716,0.7399103139013453,0.5813601437829873,0.8883374689826302,0.7611940298507462,0.6957605985037406,0.9357936978340149,0.8776466846466064,0.9057879447937012,0.8831341862678528,0.8169417213114756,0.4979512489643756,0.3453725283750973,0.606711821476294,0.4827586206896552,0.5569620253164557,0.4987028487684268,0.5436867686563857,0.609898087787902,0.4741379310344827,0.3670886075949367,0.487629133525927,0.6008008392649872,0.597642364415325,0.4482758620689655,0.3037974683544304
280413,cackharot/suds-py3,cackharot_suds-py3/suds/sax/enc.py,suds.sax.enc.Encoder,"class Encoder:
    """"""
    An XML special character encoder/decoder.
    @cvar encodings: A mapping of special characters encoding.
    @type encodings: [(str,str)]
    @cvar decodings: A mapping of special characters decoding.
    @type decodings: [(str,str)]
    @cvar special: A list of special characters
    @type special: [char]
    """"""

    encodings = (
        ('&', '&amp;'),
        ('<', '&lt;'),
        ('>', '&gt;'),
        ('""', '&quot;'),
        (""'"", '&apos;')
    )
    decodings = (
        ('&lt;', '<'),
        ('&gt;', '>'),
        ('&quot;', '""'),
        ('&apos;', ""'""),
        ('&amp;', '&')
    )
    special = ('&', '<', '>', '""', ""'"")

    def needsEncoding(self, s):
        """"""
        Get whether string I{s} contains special characters.
        @param s: A string to check.
        @type s: str
        @return: True if needs encoding.
        @rtype: boolean
        """"""
        if isinstance(s, str):
            for c in self.special:
                if c in s:
                    return True
        return False

    def encode(self, s):
        """"""
        Encode special characters found in string I{s}.
        @param s: A string to encode.
        @type s: str
        @return: The encoded string.
        @rtype: str
        """"""
        if isinstance(s, str) and self.needsEncoding(s):
            for x in self.encodings:
                s = re.sub(x[0], x[1], s)
        return s

    def decode(self, s):
        """"""
        Decode special characters encodings found in string I{s}.
        @param s: A string to decode.
        @type s: str
        @return: The decoded string.
        @rtype: str
        """"""
        if isinstance(s, str) and '&' in s:
            for x in self.decodings:
                s = s.replace(x[0], x[1])
        return s","class Encoder:
    '''
    An XML special character encoder/decoder.
    @cvar encodings: A mapping of special characters encoding.
    @type encodings: [(str,str)]
    @cvar decodings: A mapping of special characters decoding.
    @type decodings: [(str,str)]
    @cvar special: A list of special characters
    @type special: [char]
    '''

    def needsEncoding(self, s):
    '''
        Get whether string I{s} contains special characters.
        @param s: A string to check.
        @type s: str
        @return: True if needs encoding.
        @rtype: boolean
        '''
        pass

    def encode(self, s):
    '''
        Encode special characters found in string I{s}.
        @param s: A string to encode.
        @type s: str
        @return: The encoded string.
        @rtype: str
        '''
        pass

    def decode(self, s):
    '''
        Decode special characters encodings found in string I{s}.
        @param s: A string to decode.
        @type s: str
        @return: The decoded string.
        @rtype: str
        '''
        pass

",4,4,snippet_470,0.95,"class Encoder:
    '''
    An XML special character encoder/decoder.
    @cvar encodings: A mapping of special characters encoding.
    @type encodings: [(str,str)]
    @cvar decodings: A mapping of special characters decoding.
    @type decodings: [(str,str)]
    @cvar special: A list of special characters
    @type special: [char]
    '''
    encodings = [
        (""&"", ""&amp;""),
        (""<"", ""&lt;""),
        ("">"", ""&gt;""),
        ('""', ""&quot;""),
        (""'"", ""&apos;"")
    ]
    decodings = [(ent, ch) for ch, ent in encodings]
    special = [ch for ch, _ in encodings]

    def needsEncoding(self, s):
        '''
            Get whether string I{s} contains special characters.
            @param s: A string to check.
            @type s: str
            @return: True if needs encoding.
            @rtype: boolean
        '''
        return any(c in s for c in self.special)

    def encode(self, s):
        '''
            Encode special characters found in string I{s}.
            @param s: A string to encode.
            @type s: str
            @return: The encoded string.
            @rtype: str
        '''
        result = s
        # encode '&' first to avoid double-encoding
        for ch, ent in self.encodings:
            result = result.replace(ch, ent)
        return result

    def decode(self, s):
        '''
            Decode special characters encodings found in string I{s}.
            @param s: A string to decode.
            @type s: str
            @return: The decoded string.
            @rtype: str
        '''
        result = s
        # decode longer entities first to avoid partial replacements
        for ent, ch in sorted(self.decodings, key=lambda x: -len(x[0])):
            result = result.replace(ent, ch)
        return result","class Encoder:
    '''
    An XML special character encoder/decoder.
    @cvar encodings: A mapping of special characters encoding.
    @type encodings: [(str,str)]
    @cvar decodings: A mapping of special characters decoding.
    @type decodings: [(str,str)]
    @cvar special: A list of special characters
    @type special: [char]
    '''

    encodings = [
        ('&', '&amp;'),
        ('<', '&lt;'),
        ('>', '&gt;'),
        ('""', '&quot;'),
        (""'"", '&apos;')
    ]
    
    decodings = [
        ('&amp;', '&'),
        ('&lt;', '<'),
        ('&gt;', '>'),
        ('&quot;', '""'),
        ('&apos;', ""'"")
    ]
    
    special = ['&', '<', '>', '""', ""'""]

    def needsEncoding(self, s):
        '''
        Get whether string I{s} contains special characters.
        @param s: A string to check.
        @type s: str
        @return: True if needs encoding.
        @rtype: boolean
        '''
        for char in self.special:
            if char in s:
                return True
        return False

    def encode(self, s):
        '''
        Encode special characters found in string I{s}.
        @param s: A string to encode.
        @type s: str
        @return: The encoded string.
        @rtype: str
        '''
        result = s
        for char, encoding in self.encodings:
            result = result.replace(char, encoding)
        return result

    def decode(self, s):
        '''
        Decode special characters encodings found in string I{s}.
        @param s: A string to decode.
        @type s: str
        @return: The decoded string.
        @rtype: str
        '''
        result = s
        for encoding, char in self.decodings:
            result = result.replace(encoding, char)
        return result","class Encoder:
    '''
    An XML special character encoder/decoder.
    @cvar encodings: A mapping of special characters encoding.
    @type encodings: [(str,str)]
    @cvar decodings: A mapping of special characters decoding.
    @type decodings: [(str,str)]
    @cvar special: A list of special characters
    @type special: [char]
    '''
    
    encodings = [
        ('&', '&amp;'),
        ('<', '&lt;'),
        ('>', '&gt;'),
        ('""', '&quot;'),
        (""'"", '&apos;')
    ]
    
    decodings = [
        ('&amp;', '&'),
        ('&lt;', '<'),
        ('&gt;', '>'),
        ('&quot;', '""'),
        ('&apos;', ""'"")
    ]
    
    special = ['&', '<', '>', '""', ""'""]

    def needsEncoding(self, s):
        '''
        Get whether string I{s} contains special characters.
        @param s: A string to check.
        @type s: str
        @return: True if needs encoding.
        @rtype: boolean
        '''
        for char in self.special:
            if char in s:
                return True
        return False

    def encode(self, s):
        '''
        Encode special characters found in string I{s}.
        @param s: A string to encode.
        @type s: str
        @return: The encoded string.
        @rtype: str
        '''
        result = s
        for char, encoding in self.encodings:
            result = result.replace(char, encoding)
        return result

    def decode(self, s):
        '''
        Decode special characters encodings found in string I{s}.
        @param s: A string to decode.
        @type s: str
        @return: The decoded string.
        @rtype: str
        '''
        result = s
        for encoding, char in self.decodings:
            result = result.replace(encoding, char)
        return result",full_docstr,0.7851851851851852,0.6947890818858561,0.6483790523690773,0.7555555555555555,0.5550365102903367,0.8461538461538461,0.6503856041131105,0.5670103092783505,0.9093141555786133,0.9248108267784119,0.9169970154762268,0.9232375025749207,0.8262565637065638,0.8526315789473685,0.7777777777777778,0.7287234042553191,0.8473684210526315,0.73960306909066,0.9294403892944039,0.8390243902439024,0.7872860635696821,0.966240644454956,0.9458233714103699,0.9559229612350464,0.9478262066841125,0.9407985328185329,0.8526315789473685,0.7777777777777778,0.7287234042553191,0.8473684210526315,0.73960306909066,0.9294403892944039,0.8390243902439024,0.7872860635696821,0.9637107253074646,0.9445720911026001,0.9540454149246216,0.9464516639709473,0.9407985328185329,0.4948498729943575,0.5335332468834878,0.5404777739159975,0.5238095238095238,0.3815789473684211,0.608183277070015,0.6427204105213874,0.6418923970067929,0.5428571428571428,0.6052631578947368,0.608183277070015,0.6427204105213874,0.6418923970067929,0.5428571428571428,0.6052631578947368
3955,Alignak-monitoring/alignak,Alignak-monitoring_alignak/alignak/http/daemon.py,alignak.http.daemon.HTTPDaemon,"class HTTPDaemon(object):
    """"""HTTP Server class. Mostly based on Cherrypy
    It uses CherryPyWSGIServer and daemon http_interface as Application
    """"""
    # pylint: disable=too-many-arguments, unused-argument
    def __init__(self, host, port, http_interface, use_ssl, ca_cert,
                 ssl_key, ssl_cert, server_dh, thread_pool_size, log_file=None, icon_file=None):
        """"""
        Initialize HTTP daemon

        :param host: host address
        :param port: listening port
        :param http_interface:
        :param use_ssl:
        :param ca_cert:
        :param ssl_key:
        :param ssl_cert:
        :param thread_pool_size:
        :param log_file: if set, the log file for Cherrypy log
        :param icon_file: if set, the favicon file to use
        """"""
        self.port = port
        self.host = host
        self.use_ssl = use_ssl
        self.uri = '%s://%s:%s' % ('https' if self.use_ssl else 'http', self.host, self.port)
        logger.debug(""Configured HTTP server on %s, %d threads"", self.uri, thread_pool_size)

        # This application config overrides the default processors
        # so we put them back in case we need them
        config = {
            '/': {
                'request.body.processors': {'application/x-www-form-urlencoded': process_urlencoded,
                                            'multipart/form-data': process_multipart_form_data,
                                            'multipart': process_multipart,
                                            'application/zlib': zlib_processor},
                'tools.gzip.on': True,
                'tools.gzip.mime_types': ['text/*', 'application/json'],

                'tools.response_headers.on': True,
                'tools.response_headers.headers': [('Access-Control-Allow-Origin', '*')],

                'tools.staticfile.on': True if icon_file else False,
                'tools.staticfile.filename': icon_file
            }
        }

        # For embedding into a WSGI server
        # cherrypy.config.update({'environment': 'embedded'})

        # Configure HTTP server
        # Available parameters (see https://github.com/cherrypy/cherrypy/
        # blob/master/cherrypy/_cpserver.py) for more information if needed.
        # - socket_queue_size
        cherrypy.config.update({'engine.autoreload.on': False,
                                'server.thread_pool': thread_pool_size,
                                'server.socket_host': str(self.host),
                                'server.socket_port': self.port})

        # Default is to disable CherryPy logging
        cherrypy.config.update({'log.screen': False,
                                'log.access_file': '',
                                'log.error_file': ''})
        if log_file:
            # Log into the provided log file
            cherrypy.config.update({'log.screen': True,
                                    'log.access_file': str(log_file),
                                    'log.error_file': str(log_file)})
            cherrypy.log.access_log.setLevel(logging.DEBUG)
            cherrypy.log.error_log.setLevel(logging.DEBUG)
            cherrypy.log(""CherryPy logging: %s"" % (log_file))

        if use_ssl:
            # Configure SSL server certificate and private key
            # Parameters:
            # ssl_context = None
            #   When using PyOpenSSL, an instance of SSL.Context.
            # ssl_certificate = None
            #   The filename of the SSL certificate to use.
            # ssl_certificate_chain = None
            #   When using PyOpenSSL, the certificate chain to pass to
            # Context.load_verify_locations.
            # ssl_private_key = None
            #   The filename of the private key to use with SSL.
            # ssl_ciphers = None
            # The ciphers list of SSL.
            cherrypy.config.update({'server.ssl_certificate': ssl_cert,
                                    'server.ssl_private_key': ssl_key})
            cherrypy.log(""Using PyOpenSSL: %s"" % (PYOPENSSL))
            if not PYOPENSSL:
                # Use CherryPy built-in module if PyOpenSSL is not installed
                cherrypy.config.update({'server.ssl_module': 'builtin'})
            cherrypy.log(""Using SSL certificate: %s"" % (ssl_cert))
            cherrypy.log(""Using SSL private key: %s"" % (ssl_key))
            if ca_cert:
                cherrypy.config.update({'server.ssl_certificate_chain': ca_cert})
                cherrypy.log(""Using SSL CA certificate: %s"" % ca_cert)

        # Mount the main application (an Alignak daemon interface)
        cherrypy.tree.mount(http_interface, '/', config)

    def run(self):
        """"""Wrapper to start the CherryPy server

        This function throws a PortNotFree exception if any socket error is raised.

        :return: None
        """"""
        def _started_callback():
            """"""Callback function when Cherrypy Engine is started""""""
            cherrypy.log(""CherryPy engine started and listening..."")

        self.cherrypy_thread = None
        try:
            cherrypy.log(""Starting CherryPy engine on %s"" % (self.uri))
            self.cherrypy_thread = cherrypy.engine.start_with_callback(_started_callback)
            cherrypy.engine.block()
            cherrypy.log(""Exited from the engine block"")
        except socket.error as exp:
            raise PortNotFree(""Error: Sorry, the HTTP server did not started correctly: error: %s""
                              % (str(exp)))

    def stop(self):  # pylint: disable=no-self-use
        """"""Wrapper to stop the CherryPy server

        :return: None
        """"""
        cherrypy.log(""Stopping CherryPy engine (current state: %s)..."" % cherrypy.engine.state)
        try:
            cherrypy.engine.exit()
        except RuntimeWarning:
            pass
        except SystemExit:
            cherrypy.log('SystemExit raised: shutting down bus')
        cherrypy.log(""Stopped"")","class HTTPDaemon(object):
    '''HTTP Server class. Mostly based on Cherrypy
    It uses CherryPyWSGIServer and daemon http_interface as Application
    '''

    def __init__(self, host, port, http_interface, use_ssl, ca_cert,
                 ssl_key, ssl_cert, server_dh, thread_pool_size, log_file=None, icon_file=None):
    '''
        Initialize HTTP daemon

        :param host: host address
        :param port: listening port
        :param http_interface:
        :param use_ssl:
        :param ca_cert:
        :param ssl_key:
        :param ssl_cert:
        :param thread_pool_size:
        :param log_file: if set, the log file for Cherrypy log
        :param icon_file: if set, the favicon file to use
        '''
        pass

    def run(self):
    '''Wrapper to start the CherryPy server

        This function throws a PortNotFree exception if any socket error is raised.

        :return: None
        '''
        pass

        def _started_callback():
    '''Callback function when Cherrypy Engine is started'''
                pass

    def stop(self):
    '''Wrapper to stop the CherryPy server

        :return: None
        '''
        pass

",5,5,snippet_21,0.1904761904761904,"class HTTPDaemon(object):
    '''HTTP Server class. Mostly based on Cherrypy
    It uses CherryPyWSGIServer and daemon http_interface as Application
    '''

    def __init__(self, host, port, http_interface, use_ssl, ca_cert,
                 ssl_key, ssl_cert, server_dh, thread_pool_size, log_file=None, icon_file=None):
        '''
            Initialize HTTP daemon

            :param host: host address
            :param port: listening port
            :param http_interface:
            :param use_ssl:
            :param ca_cert:
            :param ssl_key:
            :param ssl_cert:
            :param thread_pool_size:
            :param log_file: if set, the log file for Cherrypy log
            :param icon_file: if set, the favicon file to use
        '''
        self.host = host
        self.port = port
        self.use_ssl = use_ssl
        self.ca_cert = ca_cert
        self.ssl_key = ssl_key
        self.ssl_cert = ssl_cert
        self.server_dh = server_dh
        self.thread_pool_size = thread_pool_size
        self.log_file = log_file
        self.icon_file = icon_file
        if icon_file:
            def wrapped_app(environ, start_response):
                if environ.get('PATH_INFO','') == '/favicon.ico':
                    try:
                        with open(self.icon_file, 'rb') as f:
                            data = f.read()
                        ctype = mimetypes.guess_type(self.icon_file)[0] or 'application/octet-stream'
                        headers = [('Content-Type', ctype), ('Content-Length', str(len(data)))]
                        start_response('200 OK', headers)
                        return [data]
                    except IOError:
                        start_response('404 Not Found', [('Content-Type', 'text/plain')])
                        return [b'Not Found']
                return http_interface(environ, start_response)
            self.wsgi_app = wrapped_app
        else:
            self.wsgi_app = http_interface
        self.server = None

    def run(self):
        '''Wrapper to start the CherryPy server

        This function throws a PortNotFree exception if any socket error is raised.

        :return: None
        '''
        def _started_callback():
            '''Callback function when Cherrypy Engine is started'''
            pass

        try:
            self.server = CherryPyWSGIServer((self.host, self.port), self.wsgi_app)
            self.server.thread_pool = self.thread_pool_size
            if self.use_ssl:
                self.server.ssl_certificate = self.ssl_cert
                self.server.ssl_private_key = self.ssl_key
                if self.ca_cert:
                    self.server.ssl_certificate_chain = self.ca_cert
                if hasattr(self.server, 'ssl_server_dh'):
                    self.server.ssl_server_dh = self.server_dh
            if self.log_file:
                try:
                    self.server.log_file = self.log_file
                except Exception:
                    pass
            self.server.start()
        except socket.error as e:
            raise PortNotFree(str(e))

    def stop(self):
        '''Wrapper to stop the CherryPy server

        :return: None
        '''
        if self.server:
            try:
                self.server.stop()
            except:
                pass","class HTTPDaemon(object):
    '''HTTP Server class. Mostly based on Cherrypy
    It uses CherryPyWSGIServer and daemon http_interface as Application
    '''

    def __init__(self, host, port, http_interface, use_ssl, ca_cert,
                 ssl_key, ssl_cert, server_dh, thread_pool_size, log_file=None, icon_file=None):
        '''
        Initialize HTTP daemon

        :param host: host address
        :param port: listening port
        :param http_interface:
        :param use_ssl:
        :param ca_cert:
        :param ssl_key:
        :param ssl_cert:
        :param thread_pool_size:
        :param log_file: if set, the log file for Cherrypy log
        :param icon_file: if set, the favicon file to use
        '''
        self.host = host
        self.port = port
        self.http_interface = http_interface
        self.use_ssl = use_ssl
        self.ca_cert = ca_cert
        self.ssl_key = ssl_key
        self.ssl_cert = ssl_cert
        self.server_dh = server_dh
        self.thread_pool_size = thread_pool_size
        self.log_file = log_file
        self.icon_file = icon_file
        self.server = None

    def run(self):
        '''Wrapper to start the CherryPy server

        This function throws a PortNotFree exception if any socket error is raised.

        :return: None
        '''
        try:
            self.server = CherryPyWSGIServer(
                (self.host, self.port),
                self.http_interface,
                numthreads=self.thread_pool_size,
                server_name=""HTTPDaemon""
            )
            
            if self.use_ssl:
                self.server.ssl_certificate = self.ssl_cert
                self.server.ssl_private_key = self.ssl_key
                if self.ca_cert:
                    self.server.ssl_certificate_chain = self.ca_cert
            
            # Set up logging if specified
            if self.log_file:
                cherrypy.log.access_log.setLevel(cherrypy.log.logging.INFO)
                cherrypy.log.error_log.setLevel(cherrypy.log.logging.INFO)
                cherrypy.log.access_file = self.log_file
                cherrypy.log.error_file = self.log_file
            
            self.server.start()
            
        except socket.error as e:
            raise PortNotFree(f""Port {self.port} is not free: {e}"")
        except Exception as e:
            raise e

    def _started_callback(self):
        '''Callback function when Cherrypy Engine is started'''
        pass

    def stop(self):
        '''Wrapper to stop the CherryPy server

        :return: None
        '''
        if self.server:
            self.server.stop()","class HTTPDaemon(object):
    '''HTTP Server class. Mostly based on Cherrypy
    It uses CherryPyWSGIServer and daemon http_interface as Application
    '''

    def __init__(self, host, port, http_interface, use_ssl, ca_cert,
                 ssl_key, ssl_cert, server_dh, thread_pool_size, log_file=None, icon_file=None):
        '''
        Initialize HTTP daemon

        :param host: host address
        :param port: listening port
        :param http_interface:
        :param use_ssl:
        :param ca_cert:
        :param ssl_key:
        :param ssl_cert:
        :param thread_pool_size:
        :param log_file: if set, the log file for Cherrypy log
        :param icon_file: if set, the favicon file to use
        '''
        self.host = host
        self.port = port
        self.http_interface = http_interface
        self.use_ssl = use_ssl
        self.ca_cert = ca_cert
        self.ssl_key = ssl_key
        self.ssl_cert = ssl_cert
        self.server_dh = server_dh
        self.thread_pool_size = thread_pool_size
        self.log_file = log_file
        self.icon_file = icon_file
        self.server = None
        
        # Configure CherryPy
        cherrypy.config.update({
            'server.socket_host': self.host,
            'server.socket_port': self.port,
            'server.thread_pool': self.thread_pool_size,
            'engine.autoreload.on': False,
            'log.screen': False
        })
        
        if self.log_file:
            cherrypy.config.update({
                'log.access_file': self.log_file,
                'log.error_file': self.log_file
            })
        
        if self.use_ssl:
            cherrypy.config.update({
                'server.ssl_module': 'builtin',
                'server.ssl_certificate': self.ssl_cert,
                'server.ssl_private_key': self.ssl_key
            })
            if self.ca_cert:
                cherrypy.config.update({
                    'server.ssl_certificate_chain': self.ca_cert
                })

    def run(self):
        '''Wrapper to start the CherryPy server

        This function throws a PortNotFree exception if any socket error is raised.

        :return: None
        '''
        try:
            cherrypy.engine.subscribe('start', self._started_callback)
            
            # Mount the application
            cherrypy.tree.mount(self.http_interface, '/')
            
            # Start the engine
            cherrypy.engine.start()
            cherrypy.engine.wait(cherrypy.engine.states.STARTED)
            
        except socket.error as e:
            raise PortNotFree(f""Port {self.port} is not available: {e}"")
        except Exception as e:
            raise PortNotFree(f""Failed to start server: {e}"")

    def _started_callback(self):
        '''Callback function when Cherrypy Engine is started'''
        protocol = ""https"" if self.use_ssl else ""http""
        print(f""HTTP daemon started on {protocol}://{self.host}:{self.port}"")

    def stop(self):
        '''Wrapper to stop the CherryPy server

        :return: None
        '''
        if cherrypy.engine.state == cherrypy.engine.states.STARTED:
            cherrypy.engine.exit()",full_docstr,0.528046421663443,0.37596899224806196,0.3048543689320388,0.3752417794970986,0.24849254275602747,0.7812041116005873,0.5176470588235295,0.4182621502209131,0.889991283416748,0.8032621145248413,0.8444055318832397,0.8111668825149536,0.7631999547511319,0.5679012345679013,0.43298969072164945,0.33884297520661155,0.38271604938271603,0.20575209379983508,0.8689407540394973,0.6726618705035972,0.5477477477477477,0.9332372546195984,0.8109962344169617,0.8678332567214966,0.8217601180076599,0.7526419909502265,0.6314760508308895,0.4916748285994124,0.380765456329735,0.4848484848484849,0.32143524993782546,0.9042709867452136,0.7050147492625368,0.5834564254062038,0.9342584609985352,0.8309537172317505,0.8795832395553589,0.8402446508407593,0.7802938009049777,0.3001437935360801,0.1699991883720846,0.2319602139601551,0.4798657718120805,0.31875,0.2664665754878095,0.1408884127376093,0.2286691643814139,0.4463087248322148,0.25,0.2843318370806981,0.1731140953221375,0.2390874140744803,0.4563758389261745,0.26875
307962,cltl/KafNafParserPy,cltl_KafNafParserPy/KafNafParserPy/features_data.py,KafNafParserPy.features_data.Cproperties,"class Cproperties:
    """"""
    This class encapsulates the property layer in KAF/NAF
    """"""
    def __init__(self,node=None,type='NAF'):
        """"""
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        """"""
        self.type=type
        if node is None:
            self.node = etree.Element('properties')
        else:
            self.node = node
            
    def get_node(self):
        """"""
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        """"""
        return self.node
            
    def __iter__(self):
        """"""
        Iterator that returns all the properties
        @rtype: L{Cproperty}
        @return: list of properties (iterator)
        """"""
        for prop_node in self.node.findall('property'):
            yield Cproperty(prop_node,self.type)
            
    def add_property(self,pid, label,term_span):
        """"""
        Adds a new property to the property layer
        @type pid: string
        @param pid: property identifier
        @type label: string
        @param label: the label of the property
        @type term_span: list
        @param term_span: list of term identifiers
        """"""
        new_property = Cproperty(type=self.type)
        self.node.append(new_property.get_node())
        ##Set the id
        if pid is None:
            ##Generate a new pid
            existing_pids = [property.get_id() for property in self]
            n = 0
            new_pid = ''
            while True:
                new_pid = 'p'+str(n)
                if new_pid not in existing_pids: break
                n += 1
            pid = new_pid
        new_property.set_id(pid)
        
        new_property.set_type(label)
        
        new_ref = Creferences()
        new_ref.add_span(term_span)
        new_property.set_reference(new_ref)","class Cproperties:
    '''
    This class encapsulates the property layer in KAF/NAF
    '''

    def __init__(self,node=None,type='NAF'):
    '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        pass

    def get_node(self):
    '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        pass

    def __iter__(self):
    '''
        Iterator that returns all the properties
        @rtype: L{Cproperty}
        @return: list of properties (iterator)
        '''
        pass

    def add_property(self,pid, label,term_span):
    '''
        Adds a new property to the property layer
        @type pid: string
        @param pid: property identifier
        @type label: string
        @param label: the label of the property
        @type term_span: list
        @param term_span: list of term identifiers
        '''
        pass

",5,5,snippet_519,0.3846153846153846,"class Cproperties:
    '''
    This class encapsulates the property layer in KAF/NAF
    '''

    def __init__(self, node=None, type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        self.type = type
        if node is None:
            self.node = Element('properties')
        else:
            self.node = node

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def __iter__(self):
        '''
        Iterator that returns all the properties
        @rtype: L{Cproperty}
        @return: list of properties (iterator)
        '''
        for prop in self.node.findall('property'):
            yield Cproperty(prop, self.type)

    def add_property(self, pid, label, term_span):
        '''
        Adds a new property to the property layer
        @type pid: string
        @param pid: property identifier
        @type label: string
        @param label: the label of the property
        @type term_span: list
        @param term_span: list of term identifiers
        '''
        prop_el = SubElement(self.node, 'property', {'pid': pid, 'label': label})
        span_el = SubElement(prop_el, 'span')
        for tid in term_span:
            SubElement(span_el, 'target', {'id': tid})
        return Cproperty(prop_el, self.type)","class Cproperties:
    '''
    This class encapsulates the property layer in KAF/NAF
    '''

    def __init__(self,node=None,type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        if node is None:
            self.node = etree.Element('properties')
            self.type = type
        else:
            self.node = node
            self.type = type

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def __iter__(self):
        '''
        Iterator that returns all the properties
        @rtype: L{Cproperty}
        @return: list of properties (iterator)
        '''
        for property_node in self.node.findall('property'):
            yield Cproperty(property_node)

    def add_property(self,pid, label,term_span):
        '''
        Adds a new property to the property layer
        @type pid: string
        @param pid: property identifier
        @type label: string
        @param label: the label of the property
        @type term_span: list
        @param term_span: list of term identifiers
        '''
        property_node = etree.Element('property')
        property_node.set('id', pid)
        property_node.set('label', label)
        
        for term_id in term_span:
            reference_node = etree.Element('ref')
            reference_node.set('id', term_id)
            property_node.append(reference_node)
            
        self.node.append(property_node)","class Cproperties:
    '''
    This class encapsulates the property layer in KAF/NAF
    '''

    def __init__(self,node=None,type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        from lxml import etree
        
        self.type = type
        if node is None:
            self.node = etree.Element('properties')
        else:
            self.node = node

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def __iter__(self):
        '''
        Iterator that returns all the properties
        @rtype: L{Cproperty}
        @return: list of properties (iterator)
        '''
        for property_node in self.node.findall('property'):
            yield Cproperty(property_node, self.type)

    def add_property(self,pid, label,term_span):
        '''
        Adds a new property to the property layer
        @type pid: string
        @param pid: property identifier
        @type label: string
        @param label: the label of the property
        @type term_span: list
        @param term_span: list of term identifiers
        '''
        from lxml import etree
        
        property_node = etree.SubElement(self.node, 'property')
        property_node.set('id', pid)
        property_node.set('label', label)
        
        span_node = etree.SubElement(property_node, 'span')
        for term_id in term_span:
            target_node = etree.SubElement(span_node, 'target')
            target_node.set('id', term_id)",full_docstr,0.8119658119658119,0.7467811158798282,0.7198275862068965,0.7863247863247863,0.5668387139849405,0.8746355685131195,0.7777777777777778,0.7214076246334311,0.9529838562011719,0.9067131280899048,0.9292728900909424,0.911137044429779,0.8481027848101267,0.8399168399168399,0.7390396659707724,0.6792452830188678,0.7733887733887734,0.5990050846668273,0.9095890410958904,0.7472527472527473,0.6694214876033058,0.9661703109741211,0.9218456745147705,0.9434877038002014,0.9260942935943604,0.8509156962025316,0.8139059304703478,0.7310061601642711,0.6969072164948453,0.7811860940695298,0.6059730915210411,0.8716577540106952,0.7345844504021448,0.6720430107526881,0.9517413377761841,0.9220418930053711,0.9366562366485596,0.9249281287193298,0.8593544303797468,0.5392371294764163,0.5939161102467126,0.6026988757947478,0.4260869565217391,0.5342465753424658,0.5225598630557702,0.5980663660659937,0.6079562904453537,0.4869565217391304,0.3972602739726027,0.5366381828355841,0.616258597629361,0.6223727519381095,0.4695652173913043,0.4383561643835616
388425,fossasia/knittingpattern,fossasia_knittingpattern/knittingpattern/Dumper/FileWrapper.py,knittingpattern.Dumper.FileWrapper.TextWrapper,"class TextWrapper(object):
    """"""Use this class if you have a binary-file but you want to
    write strings to it.
    """"""

    def __init__(self, binary_file, encoding):
        """"""Create a wrapper around :paramref:`binary_file` that encodes
        strings to bytes using :paramref:`encoding` and writes them
        to :paramref:`binary_file`.

        :param str encoding: The encoding to use to transfer the written string
          to bytes so they can be written to :paramref:`binary_file`
        :param binary_file: a file-like object open in binary mode
        """"""
        self._file = binary_file
        self._encoding = encoding

    def write(self, string):
        """"""Write a string to the file.""""""
        bytes_ = string.encode(self._encoding)
        self._file.write(bytes_)","class TextWrapper(object):
    '''Use this class if you have a binary-file but you want to
    write strings to it.
    '''

    def __init__(self, binary_file, encoding):
    '''Create a wrapper around :paramref:`binary_file` that encodes
        strings to bytes using :paramref:`encoding` and writes them
        to :paramref:`binary_file`.

        :param str encoding: The encoding to use to transfer the written string
          to bytes so they can be written to :paramref:`binary_file`
        :param binary_file: a file-like object open in binary mode
        '''
        pass

    def write(self, string):
    '''Write a string to the file.'''
        pass

",3,3,snippet_661,1.0,"class TextWrapper(object):
    '''Use this class if you have a binary-file but you want to
    write strings to it.
    '''

    def __init__(self, binary_file, encoding):
        '''Create a wrapper around :paramref:`binary_file` that encodes
        strings to bytes using :paramref:`encoding` and writes them
        to :paramref:`binary_file`.

        :param str encoding: The encoding to use to transfer the written string
          to bytes so they can be written to :paramref:`binary_file`
        :param binary_file: a file-like object open in binary mode
        '''
        self._binary_file = binary_file
        self._encoding = encoding

    def write(self, string):
        '''Write a string to the file.'''
        if not isinstance(string, str):
            raise TypeError(""TextWrapper.write() argument must be a string"")
        data = string.encode(self._encoding)
        return self._binary_file.write(data)","class TextWrapper(object):
    '''Use this class if you have a binary-file but you want to
    write strings to it.
    '''

    def __init__(self, binary_file, encoding):
        '''Create a wrapper around :paramref:`binary_file` that encodes
        strings to bytes using :paramref:`encoding` and writes them
        to :paramref:`binary_file`.

        :param str encoding: The encoding to use to transfer the written string
          to bytes so they can be written to :paramref:`binary_file`
        :param binary_file: a file-like object open in binary mode
        '''
        self.binary_file = binary_file
        self.encoding = encoding

    def write(self, string):
        '''Write a string to the file.'''
        encoded_bytes = string.encode(self.encoding)
        self.binary_file.write(encoded_bytes)","class TextWrapper(object):
    '''Use this class if you have a binary-file but you want to
    write strings to it.
    '''

    def __init__(self, binary_file, encoding):
        '''Create a wrapper around :paramref:`binary_file` that encodes
        strings to bytes using :paramref:`encoding` and writes them
        to :paramref:`binary_file`.

        :param str encoding: The encoding to use to transfer the written string
          to bytes so they can be written to :paramref:`binary_file`
        :param binary_file: a file-like object open in binary mode
        '''
        self.binary_file = binary_file
        self.encoding = encoding

    def write(self, string):
        '''Write a string to the file.'''
        encoded_bytes = string.encode(self.encoding)
        self.binary_file.write(encoded_bytes)",full_docstr,0.9098712446351932,0.8744588744588745,0.8471615720524018,0.9098712446351932,0.7747183685529815,0.8316831683168316,0.7711442786069652,0.725,0.9505283832550049,0.987273633480072,0.9685525894165039,0.9834717512130737,0.9308949999999999,0.9818181818181818,0.944954128440367,0.9166666666666666,0.9818181818181818,0.8024959544696808,0.9431818181818182,0.8571428571428571,0.7988505747126436,0.9866951704025269,0.9930387139320374,0.9898567795753479,0.9924007058143616,1.0,0.9818181818181818,0.944954128440367,0.9166666666666666,0.9818181818181818,0.8024959544696808,0.9431818181818182,0.8571428571428571,0.7988505747126436,0.9866951704025269,0.9930387139320374,0.9898567795753479,0.9924007058143616,1.0,0.8210390116690823,0.702921169077557,0.8034570998209947,0.7777777777777778,1.0,0.7973655019973355,0.7666034090243597,0.7728585989649822,1.0,0.65,0.7973655019973355,0.7666034090243597,0.7728585989649822,1.0,0.65
259723,behave/behave-django,behave_django/environment.py,behave_django.environment.BehaveHooksMixin,"class BehaveHooksMixin:
    """"""
    Provides methods that run during test execution.

    These methods are attached to behave via monkey patching.
    """"""

    testcase_class = None

    def patch_context(self, context):
        """"""
        Patches the context to add utility functions

        Sets up the base_url, and the get_url() utility function.
        """"""
        context.__class__ = PatchedContext
        # Simply setting __class__ directly doesn't work
        # because behave.runner.Context.__setattr__ is implemented wrongly.
        object.__setattr__(context, '__class__', PatchedContext)

    def setup_testclass(self, context):
        """"""
        Adds the test instance to context
        """"""
        context.test = self.testcase_class()

    def setup_fixtures(self, context):
        """"""
        Sets up fixtures
        """"""
        if getattr(context, 'fixtures', None):
            context.test.fixtures = copy(context.fixtures)

        if getattr(context, 'reset_sequences', None):
            context.test.reset_sequences = context.reset_sequences

        if getattr(context, 'databases', None):
            context.test.__class__.databases = context.databases

        if hasattr(context, 'scenario'):
            load_registered_fixtures(context)

    def setup_test(self, context):
        """"""
        Sets up the Django test

        This method runs the code necessary to create the test database, start
        the live server, etc.
        """"""
        context.test._pre_setup(run=True)
        context.test.setUpClass()
        context.test()

    def teardown_test(self, context):
        """"""
        Tears down the Django test
        """"""
        context.test.tearDownClass()
        context.test._post_teardown(run=True)
        del context.test","class BehaveHooksMixin:
    '''
    Provides methods that run during test execution.

    These methods are attached to behave via monkey patching.
    '''

    def patch_context(self, context):
    '''
        Patches the context to add utility functions

        Sets up the base_url, and the get_url() utility function.
        '''
        pass

    def setup_testclass(self, context):
    '''
        Adds the test instance to context
        '''
        pass

    def setup_fixtures(self, context):
    '''
        Sets up fixtures
        '''
        pass

    def setup_testclass(self, context):
    '''
        Sets up the Django test

        This method runs the code necessary to create the test database, start
        the live server, etc.
        '''
        pass

    def teardown_test(self, context):
    '''
        Tears down the Django test
        '''
        pass

",6,6,snippet_431,0.7142857142857143,"class BehaveHooksMixin:
    '''
    Provides methods that run during test execution.

    These methods are attached to behave via monkey patching.
    '''

    def patch_context(self, context):
        '''
        Patches the context to add utility functions

        Sets up the base_url, and the get_url() utility function.
        '''
        host = context.config.userdata.get('host', 'localhost')
        port = context.config.userdata.get('port', 8000)
        context.base_url = f'http://{host}:{port}'

        def get_url(path):
            return urljoin(context.base_url, path)

        context.get_url = get_url

    def setup_testclass(self, context):
        '''
        Adds the test instance to context
        '''
        class BehaveTest(LiveServerTestCase):
            pass

        context.test = BehaveTest('runTest')

    def setup_fixtures(self, context):
        '''
        Sets up fixtures
        '''
        fixtures = context.config.userdata.get('fixtures', None)
        if fixtures:
            context.test.fixtures = fixtures
            context.test._fixture_setup()

    def setup_testclass(self, context):
        '''
        Sets up the Django test

        This method runs the code necessary to create the test database, start
        the live server, etc.
        '''
        cls = context.test.__class__
        cls.setUpClass()
        context.test.setUp()

    def teardown_test(self, context):
        '''
        Tears down the Django test
        '''
        context.test.tearDown()
        context.test.__class__.tearDownClass()","class BehaveHooksMixin:
    '''
    Provides methods that run during test execution.

    These methods are attached to behave via monkey patching.
    '''

    def patch_context(self, context):
        '''
        Patches the context to add utility functions

        Sets up the base_url, and the get_url() utility function.
        '''
        from django.conf import settings
        from django.urls import reverse
        
        context.base_url = getattr(settings, 'LIVE_SERVER_URL', 'http://localhost:8081')
        
        def get_url(url_name, *args, **kwargs):
            if url_name.startswith('/'):
                return context.base_url + url_name
            return context.base_url + reverse(url_name, args=args, kwargs=kwargs)
        
        context.get_url = get_url

    def setup_testclass(self, context):
        '''
        Adds the test instance to context
        '''
        from django.test import TestCase
        
        if not hasattr(self, '_test_instance'):
            self._test_instance = TestCase()
        context.test = self._test_instance

    def setup_fixtures(self, context):
        '''
        Sets up fixtures
        '''
        from django.core.management import call_command
        from django.db import connections
        from django.test.utils import setup_test_environment, teardown_test_environment
        
        setup_test_environment()
        
        # Create test database
        for connection in connections.all():
            connection.creation.create_test_db(autoclobber=True)
        
        # Load fixtures if specified
        if hasattr(self, 'fixtures'):
            call_command('loaddata', *self.fixtures, verbosity=0)

    def setup_testclass(self, context):
        '''
        Sets up the Django test

        This method runs the code necessary to create the test database, start
        the live server, etc.
        '''
        from django.test import LiveServerTestCase
        from django.test.utils import setup_test_environment
        
        setup_test_environment()
        
        if not hasattr(self, '_test_instance'):
            self._test_instance = LiveServerTestCase()
            self._test_instance._pre_setup()
        
        context.test = self._test_instance
        context.base_url = self._test_instance.live_server_url

    def teardown_test(self, context):
        '''
        Tears down the Django test
        '''
        from django.test.utils import teardown_test_environment
        from django.db import connections
        
        if hasattr(self, '_test_instance'):
            self._test_instance._post_teardown()
            delattr(self, '_test_instance')
        
        # Destroy test databases
        for connection in connections.all():
            connection.creation.destroy_test_db(connection.settings_dict['NAME'])
        
        teardown_test_environment()","class BehaveHooksMixin:
    '''
    Provides methods that run during test execution.

    These methods are attached to behave via monkey patching.
    '''

    def patch_context(self, context):
        '''
        Patches the context to add utility functions

        Sets up the base_url, and the get_url() utility function.
        '''
        if hasattr(context, 'test') and hasattr(context.test, 'live_server_url'):
            context.base_url = context.test.live_server_url
        else:
            context.base_url = 'http://localhost:8000'
        
        def get_url(url_path=''):
            if url_path.startswith('/'):
                return context.base_url + url_path
            elif url_path:
                return context.base_url + '/' + url_path
            else:
                return context.base_url
        
        context.get_url = get_url

    def setup_testclass(self, context):
        '''
        Adds the test instance to context
        '''
        if not hasattr(context, 'test'):
            from django.test import TestCase
            context.test = TestCase()
            context.test._pre_setup()

    def setup_fixtures(self, context):
        '''
        Sets up fixtures
        '''
        if hasattr(context, 'test') and hasattr(context.test, '_fixture_setup'):
            context.test._fixture_setup()

    def teardown_test(self, context):
        '''
        Tears down the Django test
        '''
        if hasattr(context, 'test'):
            if hasattr(context.test, '_fixture_teardown'):
                context.test._fixture_teardown()
            if hasattr(context.test, '_post_teardown'):
                context.test._post_teardown()",full_docstr,0.6994535519125683,0.5604395604395604,0.4751381215469613,0.6502732240437159,0.499753054573192,0.7948717948717948,0.6012861736334405,0.5032258064516129,0.8924118280410767,0.8804407119750977,0.8863858580589294,0.8816232681274414,0.7976730567685594,0.5166340508806262,0.381139489194499,0.3234714003944773,0.4657534246575342,0.3322844427023519,0.49559082892416223,0.31448763250883394,0.23539823008849559,0.819236159324646,0.8719516396522522,0.8447722792625427,0.8663768172264099,0.78900920212766,0.6296296296296295,0.44680851063829785,0.3529411764705882,0.4920634920634921,0.45447168722099884,0.7028571428571428,0.4699140401146132,0.367816091954023,0.8787350058555603,0.8575102686882019,0.8679929375648499,0.8595864176750183,0.7670550965250973,0.3890710106920949,0.4347284866260745,0.4351971556157294,0.4660194174757281,0.2203389830508474,0.3759331344802946,0.3015791728076424,0.4478337995384168,0.5339805825242718,0.2203389830508474,0.5146892100992015,0.3032486517779796,0.3186149847353314,0.4368932038834951,0.0
292936,citronneur/rdpy,citronneur_rdpy/rdpy/core/rss.py,rdpy.core.rss.FileReader,"class FileReader(object):
    """"""
    @summary: RSR File reader
    """"""
    def __init__(self, f):
        """"""
        @param f: {file} file pointer use to read
        """"""
        self._s = Stream(f.read())
        
    def nextEvent(self):
        """"""
        @summary: read next event and return it
        """"""
        if self._s.dataLen() == 0:
            return None
        e = Event()
        self._s.readType(e)
        return e","class FileReader(object):
    '''
    @summary: RSR File reader
    '''

    def __init__(self, f):
    '''
        @param f: {file} file pointer use to read
        '''
        pass

    def nextEvent(self):
    '''
        @summary: read next event and return it
        '''
        pass

",3,3,snippet_505,0.6,"class FileReader(object):
    '''
    @summary: RSR File reader
    '''

    def __init__(self, f):
        '''
        @param f: {file} file pointer use to read
        '''
        if not hasattr(f, 'read'):
            raise ValueError(""f must be a file-like object with a read method"")
        self.f = f
        self._buffer = []

    def nextEvent(self):
        '''
        @summary: read next event and return it
        '''
        event = []
        # use any leftover lines first
        while self._buffer:
            line = self._buffer.pop(0)
            if line.strip() == '':
                if event:
                    return event
                else:
                    continue
            event.append(line.rstrip('\n'))

        for raw in self.f:
            if raw.strip() == '':
                if event:
                    return event
                else:
                    continue
            event.append(raw.rstrip('\n'))

        # end of file
        if event:
            return event
        return None","class FileReader(object):
    '''
    @summary: RSR File reader
    '''

    def __init__(self, f):
        '''
        @param f: {file} file pointer use to read
        '''
        self.file = f
        self.finished = False

    def nextEvent(self):
        '''
        @summary: read next event and return it
        '''
        if self.finished:
            return None
            
        try:
            line = self.file.readline()
            if not line:
                self.finished = True
                return None
            return line.strip()
        except Exception:
            self.finished = True
            return None","class FileReader(object):
    '''
    @summary: RSR File reader
    '''

    def __init__(self, f):
        '''
        @param f: {file} file pointer use to read
        '''
        self.file = f
        self.current_position = 0

    def nextEvent(self):
        '''
        @summary: read next event and return it
        '''
        if self.file.closed:
            return None
        
        line = self.file.readline()
        if not line:
            return None
        
        self.current_position = self.file.tell()
        return line.strip()",full_docstr,0.5095541401273886,0.37419354838709673,0.326797385620915,0.47133757961783446,0.31212673690543274,0.43564356435643564,0.3034825870646766,0.23,0.7615697383880615,0.8860668540000916,0.8191146850585938,0.8718148469924927,0.7777799999999999,0.6607142857142858,0.5636363636363636,0.5185185185185185,0.6607142857142858,0.4903249509809304,0.6637168141592921,0.48214285714285715,0.3783783783783784,0.8755893111228943,0.9095754027366638,0.8922588229179382,0.9060585498809814,0.8405813043478261,0.6972477064220183,0.5794392523364487,0.5333333333333333,0.6788990825688074,0.5100983672313592,0.7079646017699115,0.5089285714285714,0.3783783783783784,0.8967305421829224,0.918703556060791,0.9075840711593628,0.9164578914642334,0.8812272413793103,0.3724348436136137,0.1738904074164261,0.4047378559269174,0.4444444444444444,0.4666666666666667,0.3900764839711002,0.2848203370892151,0.4032633765729634,0.4722222222222222,0.4,0.3840616569219833,0.3274276955594145,0.4032633765729634,0.4722222222222222,0.3333333333333333
391403,futurecolors/suds,futurecolors_suds/suds/umx/attrlist.py,suds.umx.attrlist.AttrList,"class AttrList:
    """"""
    A filtered attribute list.
    Items are included during iteration if they are in either the (xs) or
    (xml) namespaces.
    @ivar raw: The I{raw} attribute list.
    @type raw: list
    """"""
    def __init__(self, attributes):
        """"""
        @param attributes: A list of attributes
        @type attributes: list
        """"""
        self.raw = attributes
        
    def real(self):
        """"""
        Get list of I{real} attributes which exclude xs and xml attributes.
        @return: A list of I{real} attributes.
        @rtype: I{generator}
        """"""
        for a in self.raw:
            if self.skip(a): continue
            yield a
            
    def rlen(self):
        """"""
        Get the number of I{real} attributes which exclude xs and xml attributes.
        @return: A count of I{real} attributes. 
        @rtype: L{int}
        """"""
        n = 0
        for a in self.real():
            n += 1
        return n
            
    def lang(self):
        """"""
        Get list of I{filtered} attributes which exclude xs.
        @return: A list of I{filtered} attributes.
        @rtype: I{generator}
        """"""
        for a in self.raw:
            if a.qname() == 'xml:lang':
                return a.value
            return None

    def skip(self, attr):
        """"""
        Get whether to skip (filter-out) the specified attribute.
        @param attr: An attribute.
        @type attr: I{Attribute}
        @return: True if should be skipped.
        @rtype: bool
        """"""
        ns = attr.namespace()
        skip = (
            Namespace.xmlns[1],
            'http://schemas.xmlsoap.org/soap/encoding/',
            'http://schemas.xmlsoap.org/soap/envelope/',
            'http://www.w3.org/2003/05/soap-envelope',
        )
        return ( Namespace.xs(ns) or ns[1] in skip )","class AttrList:
    '''
    A filtered attribute list.
    Items are included during iteration if they are in either the (xs) or
    (xml) namespaces.
    @ivar raw: The I{raw} attribute list.
    @type raw: list
    '''

    def __init__(self, attributes):
    '''
        @param attributes: A list of attributes
        @type attributes: list
        '''
        pass

    def real(self):
    '''
        Get list of I{real} attributes which exclude xs and xml attributes.
        @return: A list of I{real} attributes.
        @rtype: I{generator}
        '''
        pass

    def rlen(self):
    '''
        Get the number of I{real} attributes which exclude xs and xml attributes.
        @return: A count of I{real} attributes. 
        @rtype: L{int}
        '''
        pass

    def lang(self):
    '''
        Get list of I{filtered} attributes which exclude xs.
        @return: A list of I{filtered} attributes.
        @rtype: I{generator}
        '''
        pass

    def skip(self, attr):
    '''
        Get whether to skip (filter-out) the specified attribute.
        @param attr: An attribute.
        @type attr: I{Attribute}
        @return: True if should be skipped.
        @rtype: bool
        '''
        pass

",6,6,snippet_688,0.5333333333333333,"class AttrList:
    """"""
    A filtered attribute list.
    Items are included during iteration if they are in either the (xs) or
    (xml) namespaces.
    @ivar raw: The raw attribute list.
    @type raw: list
    """"""

    # XML and XML-Schema-instance namespace URIs
    XS_NS = ""http://www.w3.org/2001/XMLSchema-instance""
    XML_NS = ""http://www.w3.org/XML/1998/namespace""

    def __init__(self, attributes):
        """"""
        @param attributes: A list of attributes
        @type attributes: list
        """"""
        self.raw = list(attributes)

    def real(self):
        """"""
        Get list of real attributes which exclude xs and xml attributes.
        @return: A list of real attributes.
        @rtype: generator
        """"""
        return (attr for attr in self.raw if not self.skip(attr))

    def rlen(self):
        """"""
        Get the number of real attributes which exclude xs and xml attributes.
        @return: A count of real attributes.
        @rtype: int
        """"""
        return sum(1 for _ in self.real())

    def lang(self):
        """"""
        Get list of filtered attributes which exclude xs.
        @return: A list of filtered attributes.
        @rtype: generator
        """"""
        return (
            attr
            for attr in self.raw
            if getattr(attr, ""namespace"", None) != self.XS_NS
        )

    def skip(self, attr):
        """"""
        Get whether to skip (filter-out) the specified attribute.
        @param attr: An attribute.
        @type attr: Attribute
        @return: True if should be skipped.
        @rtype: bool
        """"""
        ns = getattr(attr, ""namespace"", None)
        return ns == self.XS_NS or ns == self.XML_NS","class AttrList:
    '''
    A filtered attribute list.
    Items are included during iteration if they are in either the (xs) or
    (xml) namespaces.
    @ivar raw: The I{raw} attribute list.
    @type raw: list
    '''

    def __init__(self, attributes):
        '''
        @param attributes: A list of attributes
        @type attributes: list
        '''
        self.raw = attributes

    def real(self):
        '''
        Get list of I{real} attributes which exclude xs and xml attributes.
        @return: A list of I{real} attributes.
        @rtype: I{generator}
        '''
        for attr in self.raw:
            if not self.skip(attr):
                yield attr

    def rlen(self):
        '''
        Get the number of I{real} attributes which exclude xs and xml attributes.
        @return: A count of I{real} attributes. 
        @rtype: L{int}
        '''
        count = 0
        for attr in self.raw:
            if not self.skip(attr):
                count += 1
        return count

    def lang(self):
        '''
        Get list of I{filtered} attributes which exclude xs.
        @return: A list of I{filtered} attributes.
        @rtype: I{generator}
        '''
        for attr in self.raw:
            if not attr.name.startswith('xs:'):
                yield attr

    def skip(self, attr):
        '''
        Get whether to skip (filter-out) the specified attribute.
        @param attr: An attribute.
        @type attr: I{Attribute}
        @return: True if should be skipped.
        @rtype: bool
        '''
        return attr.name.startswith('xs:') or attr.name.startswith('xml:')","class AttrList:
    '''
    A filtered attribute list.
    Items are included during iteration if they are in either the (xs) or
    (xml) namespaces.
    @ivar raw: The I{raw} attribute list.
    @type raw: list
    '''

    def __init__(self, attributes):
        '''
        @param attributes: A list of attributes
        @type attributes: list
        '''
        self.raw = attributes

    def real(self):
        '''
        Get list of I{real} attributes which exclude xs and xml attributes.
        @return: A list of I{real} attributes.
        @rtype: I{generator}
        '''
        for attr in self.raw:
            if not self.skip(attr):
                yield attr

    def rlen(self):
        '''
        Get the number of I{real} attributes which exclude xs and xml attributes.
        @return: A count of I{real} attributes. 
        @rtype: L{int}
        '''
        return len(list(self.real()))

    def lang(self):
        '''
        Get list of I{filtered} attributes which exclude xs.
        @return: A list of I{filtered} attributes.
        @rtype: I{generator}
        '''
        for attr in self.raw:
            if hasattr(attr, 'namespace') and attr.namespace != 'xs':
                yield attr
            elif not hasattr(attr, 'namespace'):
                yield attr

    def skip(self, attr):
        '''
        Get whether to skip (filter-out) the specified attribute.
        @param attr: An attribute.
        @type attr: I{Attribute}
        @return: True if should be skipped.
        @rtype: bool
        '''
        if hasattr(attr, 'namespace'):
            return attr.namespace in ('xs', 'xml')
        return False",full_docstr,0.8073394495412843,0.6359447004608295,0.5416666666666666,0.7477064220183487,0.6175478858164981,0.8429319371727748,0.6509186351706037,0.5789473684210527,0.9015260934829712,0.8664963245391846,0.8836641907691956,0.8698763251304626,0.8333349999999999,0.8226950354609929,0.7458432304038005,0.701670644391408,0.8085106382978724,0.6060412313582624,0.8823529411764706,0.7492625368731564,0.6834319526627219,0.9488427639007568,0.8759665489196777,0.9109494686126709,0.8827464580535889,0.8862756470588234,0.8226950354609929,0.7458432304038005,0.701670644391408,0.7990543735224587,0.598858280876817,0.8668639053254438,0.7477744807121661,0.6875,0.9479998350143433,0.8705006837844849,0.9075989127159119,0.8776757121086121,0.8372565294117646,0.4528668381210632,0.5810749279598387,0.5934943282198232,0.3815789473684211,0.2553191489361702,0.5276089124316599,0.6194287058633814,0.6262253089248485,0.4605263157894737,0.4042553191489361,0.5531355831888984,0.6072620197736939,0.6128391035754052,0.4605263157894737,0.5319148936170213
250235,atztogo/phonopy,atztogo_phonopy/phonopy/interface/vasp.py,vasp.VasprunWrapper,"class VasprunWrapper:
    """"""VasprunWrapper class.

    This is used to fix broken vasprun.xml of VASP 5.2.8 at PRECFOCK.

    """"""

    def __init__(self, fileptr):
        """"""Init method.""""""
        self._fileptr = fileptr

    def read(self, size=None):
        """"""Replace broken PRECFOCK.""""""
        element = self._fileptr.next()
        if element.find(""PRECFOCK"") == -1:
            return element
        else:
            return '<i type=""string"" name=""PRECFOCK""></i>'","class VasprunWrapper:
    '''VasprunWrapper class.

    This is used to fix broken vasprun.xml of VASP 5.2.8 at PRECFOCK.

    '''

    def __init__(self, fileptr):
    '''Init method.'''
        pass

    def read(self, size=None):
    '''Replace broken PRECFOCK.'''
        pass

",3,3,snippet_354,0.6,"class VasprunWrapper:
    '''VasprunWrapper class.

    This is used to fix broken vasprun.xml of VASP 5.2.8 at PRECFOCK.

    '''

    def __init__(self, fileptr):
        '''Init method.'''
        raw = fileptr.read()
        # Remove the broken PRECFOCK section (misspelled closing tag </PRECFCOK>)
        self._data = re.sub(r""<PRECFOCK>.*?</PRECFCOK>"", """", raw, flags=re.DOTALL)
        self._pos = 0

    def read(self, size=None):
        '''Replace broken PRECFOCK.'''
        if size is None:
            result = self._data[self._pos:]
            self._pos = len(self._data)
            return result
        else:
            end = self._pos + size
            result = self._data[self._pos:end]
            self._pos = min(end, len(self._data))
            return result","class VasprunWrapper:
    '''VasprunWrapper class.

    This is used to fix broken vasprun.xml of VASP 5.2.8 at PRECFOCK.

    '''

    def __init__(self, fileptr):
        '''Init method.'''
        self.fileptr = fileptr
        self.buffer = """"
        self.eof = False

    def read(self, size=None):
        '''Replace broken PRECFOCK.'''
        if self.eof:
            return """"
        
        # Read data until we have enough or reach EOF
        while size is None or len(self.buffer) < size:
            chunk = self.fileptr.read(8192)
            if not chunk:
                self.eof = True
                break
            self.buffer += chunk
        
        if size is None:
            result = self.buffer
            self.buffer = """"
        else:
            result = self.buffer[:size]
            self.buffer = self.buffer[size:]
        
        # Fix broken PRECFOCK tags
        result = result.replace('<PRECFOCK>', '<PRECFOCK>\n')
        result = result.replace('</PRECFOCK>', '\n</PRECFOCK>')
        
        return result","class VasprunWrapper:
    '''VasprunWrapper class.

    This is used to fix broken vasprun.xml of VASP 5.2.8 at PRECFOCK.

    '''

    def __init__(self, fileptr):
        '''Init method.'''
        self.fileptr = fileptr

    def read(self, size=None):
        '''Replace broken PRECFOCK.'''
        if size is None:
            content = self.fileptr.read()
        else:
            content = self.fileptr.read(size)
        
        if isinstance(content, str):
            content = content.replace('PRECFOCK', 'PRECFOCK_FIXED')
        elif isinstance(content, bytes):
            content = content.replace(b'PRECFOCK', b'PRECFOCK_FIXED')
        
        return content",full_docstr,0.5599999999999999,0.4189189189189189,0.3972602739726027,0.5066666666666667,0.29362317476098004,0.4397905759162304,0.2789473684210526,0.20634920634920634,0.820517897605896,0.9105759263038635,0.863204300403595,0.9006901383399963,0.781776762589928,0.5176470588235295,0.41666666666666663,0.38554216867469876,0.48235294117647054,0.2795899514757178,0.411214953271028,0.28169014084507044,0.18867924528301888,0.7974961996078491,0.8962596654891968,0.8439984917640686,0.8852959871292114,0.772315573770492,0.6666666666666666,0.5669291338582677,0.5439999999999999,0.6356589147286822,0.423416039256868,0.5748031496062992,0.4126984126984127,0.32,0.8968217372894287,0.9251513481140137,0.9107663035392761,0.9222381114959717,0.8463783478260869,0.3412864413028922,0.2089239610282241,0.3821833426448829,0.3125,0.4615384615384615,0.3458535695954771,0.1574727589395485,0.3894030579038982,0.375,0.4615384615384615,0.4769338740374527,0.3114100633815249,0.4184408173836706,0.5625,0.6153846153846154
312341,cohorte/cohorte-herald,python/snippets/herald_mqtt/core.py,herald_mqtt.core.Herald,"class Herald(object):
    """"""
    Herald's service
    """"""
    def __init__(self):
        """"""
        """"""
        # Peers directory
        self._directory = herald.directory.Directory()

        # Routers
        self._routers = []


    def _get_link(self, peer):
        """"""
        Returns a link to the given peer

        :return: A Link object
        :raise ValueError: Unknown peer
        """"""
        assert isinstance(peer, beans.Peer)

        # Look for a link to the peer, using routers
        for router in self._routers:
            link = router.get_link(peer)
            if link:
                return link

        # Not found
        raise ValueError(""No link to peer {0}"".format(peer))


    def send(self, peer_id, message):
        """"""
        Synchronously sends a message

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        """"""
        assert isinstance(message, beans.RawMessage)

        # Get peer description (raises KeyError)
        peer = self._directory.get_peer(peer_id)

        # Get a link to the peer (raises ValueError)
        link = self._get_link(peer)
        assert isinstance(link, beans.AbstractLink)

        # Call the link, and return its result
        return link.send(message)


    def post(self, peer_id, message):
        """"""
        Sends a message and returns a Future object to get its result later

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :return: A Future object to grab the response(s) to the message
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        """"""
        assert isinstance(message, beans.RawMessage)

        # Get peer description (raises KeyError)
        peer = self._directory.get_peer(peer_id)

        # Get a link to the peer (raises ValueError)
        link = self._get_link(peer)
        assert isinstance(link, beans.AbstractLink)

        # Call the link, and return its result (a Future bean)
        return link.post(message)","class Herald(object):
    '''
    Herald's service
    '''

    def __init__(self):
    '''
        '''
        pass

    def _get_link(self, peer):
    '''
        Returns a link to the given peer

        :return: A Link object
        :raise ValueError: Unknown peer
        '''
        pass

    def send(self, peer_id, message):
    '''
        Synchronously sends a message

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        pass

    def post(self, peer_id, message):
    '''
        Sends a message and returns a Future object to get its result later

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :return: A Future object to grab the response(s) to the message
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        pass

",5,5,snippet_536,0.1764705882352941,"class Herald(object):
    '''
    Herald's service
    '''

    def __init__(self):
        self._links = {}
        self._executor = ThreadPoolExecutor()

    def _get_link(self, peer):
        '''
        Returns a link to the given peer

        :return: A Link object
        :raise ValueError: Unknown peer
        '''
        if peer not in self._links:
            raise ValueError(f""Unknown peer: {peer}"")
        return self._links[peer]

    def send(self, peer_id, message):
        '''
        Synchronously sends a message

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        if peer_id not in self._links:
            raise KeyError(f""Unknown peer: {peer_id}"")
        link = self._get_link(peer_id)
        if link is None:
            raise ValueError(f""No link to the peer: {peer_id}"")
        return link.send(message)

    def post(self, peer_id, message):
        '''
        Sends a message and returns a Future object to get its result later

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :return: A Future object to grab the response(s) to the message
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        if peer_id not in self._links:
            raise KeyError(f""Unknown peer: {peer_id}"")
        link = self._get_link(peer_id)
        if link is None:
            raise ValueError(f""No link to the peer: {peer_id}"")
        return self._executor.submit(link.send, message)","class Herald(object):
    '''
    Herald's service
    '''

    def __init__(self):
        '''
        '''
        self._peers = {}  # type: Dict[uuid.UUID, Any]
        self._links = {}  # type: Dict[uuid.UUID, Link]

    def _get_link(self, peer):
        '''
        Returns a link to the given peer

        :return: A Link object
        :raise ValueError: Unknown peer
        '''
        if peer not in self._links:
            raise ValueError(""Unknown peer"")
        return self._links[peer]

    def send(self, peer_id, message):
        '''
        Synchronously sends a message

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        if peer_id not in self._peers:
            raise KeyError(""Unknown peer"")
        
        link = self._get_link(peer_id)
        return link.send_sync(message)

    def post(self, peer_id, message):
        '''
        Sends a message and returns a Future object to get its result later

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :return: A Future object to grab the response(s) to the message
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        if peer_id not in self._peers:
            raise KeyError(""Unknown peer"")
        
        link = self._get_link(peer_id)
        return link.send_async(message)","class Herald(object):
    '''
    Herald's service
    '''

    def __init__(self):
        '''
        '''
        self._peers = {}
        self._links = {}

    def _get_link(self, peer):
        '''
        Returns a link to the given peer

        :return: A Link object
        :raise ValueError: Unknown peer
        '''
        if peer not in self._peers:
            raise ValueError(f""Unknown peer: {peer}"")
        
        if peer not in self._links:
            raise ValueError(f""No link to peer: {peer}"")
        
        return self._links[peer]

    def send(self, peer_id, message):
        '''
        Synchronously sends a message

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        if peer_id not in self._peers:
            raise KeyError(f""Unknown peer: {peer_id}"")
        
        link = self._get_link(peer_id)
        return link.send_sync(message)

    def post(self, peer_id, message):
        '''
        Sends a message and returns a Future object to get its result later

        :param peer_id: UUID of a peer
        :param message: Message to send to the peer
        :return: A Future object to grab the response(s) to the message
        :raise KeyError: Unknown peer
        :raise ValueError: No link to the peer
        '''
        if peer_id not in self._peers:
            raise KeyError(f""Unknown peer: {peer_id}"")
        
        link = self._get_link(peer_id)
        return link.send_async(message)",full_docstr,0.7336065573770492,0.6008230452674896,0.5454545454545454,0.6639344262295083,0.5183511494162111,0.7994652406417112,0.6193029490616622,0.5483870967741935,0.9101114869117737,0.8725360035896301,0.8909277319908142,0.8761533498764038,0.8104284360189573,0.7086956521739131,0.5982532751091703,0.5394736842105263,0.6695652173913045,0.47463297356685147,0.8328267477203647,0.676829268292683,0.6116207951070336,0.9121619462966919,0.8716578483581543,0.891450047492981,0.8755456209182739,0.8420236966824645,0.7288135593220338,0.6042553191489362,0.5427350427350428,0.6949152542372881,0.49171499701965177,0.8085714285714286,0.6418338108882522,0.5747126436781609,0.9213962554931641,0.8755272030830383,0.8978763222694397,0.8799075484275818,0.8325451184834122,0.4136179814426242,0.4234281976557166,0.4369740468694132,0.4842105263157895,0.3098591549295774,0.3584927549896947,0.3926776844100035,0.4196476720943646,0.4526315789473684,0.1690140845070422,0.3721087028590108,0.3997083081014696,0.4212691275006227,0.4421052631578947,0.2253521126760563
248414,arviz-devs/arviz,arviz-devs_arviz/arviz/utils.py,arviz.utils.interactive_backend,"class interactive_backend:  # pylint: disable=invalid-name
    """"""Context manager to change backend temporarily in ipython sesson.

    It uses ipython magic to change temporarily from the ipython inline backend to
    an interactive backend of choice. It cannot be used outside ipython sessions nor
    to change backends different than inline -> interactive.

    Notes
    -----
    The first time ``interactive_backend`` context manager is called, any of the available
    interactive backends can be chosen. The following times, this same backend must be used
    unless the kernel is restarted.

    Parameters
    ----------
    backend : str, optional
        Interactive backend to use. It will be passed to ``%matplotlib`` magic, refer to
        its docs to see available options.

    Examples
    --------
    Inside an ipython session (i.e. a jupyter notebook) with the inline backend set:

    .. code::

        >>> import arviz as az
        >>> idata = az.load_arviz_data(""centered_eight"")
        >>> az.plot_posterior(idata) # inline
        >>> with az.interactive_backend():
        ...     az.plot_density(idata) # interactive
        >>> az.plot_trace(idata) # inline

    """"""

    # based on matplotlib.rc_context
    def __init__(self, backend=""""):
        """"""Initialize context manager.""""""
        try:
            from IPython import get_ipython
        except ImportError as err:
            raise ImportError(
                ""The exception below was risen while importing Ipython, this ""
                f""context manager can only be used inside ipython sessions:\n{err}""
            ) from err
        self.ipython = get_ipython()
        if self.ipython is None:
            raise EnvironmentError(""This context manager can only be used inside ipython sessions"")
        self.ipython.magic(f""matplotlib {backend}"")

    def __enter__(self):
        """"""Enter context manager.""""""
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        """"""Exit context manager.""""""
        plt.show(block=True)
        self.ipython.magic(""matplotlib inline"")","class interactive_backend:
    '''Context manager to change backend temporarily in ipython sesson.

    It uses ipython magic to change temporarily from the ipython inline backend to
    an interactive backend of choice. It cannot be used outside ipython sessions nor
    to change backends different than inline -> interactive.

    Notes
    -----
    The first time ``interactive_backend`` context manager is called, any of the available
    interactive backends can be chosen. The following times, this same backend must be used
    unless the kernel is restarted.

    Parameters
    ----------
    backend : str, optional
        Interactive backend to use. It will be passed to ``%matplotlib`` magic, refer to
        its docs to see available options.

    Examples
    --------
    Inside an ipython session (i.e. a jupyter notebook) with the inline backend set:

    .. code::

        >>> import arviz as az
        >>> idata = az.load_arviz_data(""centered_eight"")
        >>> az.plot_posterior(idata) # inline
        >>> with az.interactive_backend():
        ...     az.plot_density(idata) # interactive
        >>> az.plot_trace(idata) # inline

    '''

    def __init__(self, backend=""""):
    '''Initialize context manager.'''
        pass

    def __enter__(self):
    '''Enter context manager.'''
        pass

    def __exit__(self, exc_type, exc_value, exc_tb):
    '''Exit context manager.'''
        pass

",4,4,snippet_347,0.375,"class interactive_backend:
    '''Context manager to change backend temporarily in ipython sesson.

    It uses ipython magic to change temporarily from the ipython inline backend to
    an interactive backend of choice. It cannot be used outside ipython sessions nor
    to change backends different than inline -> interactive.

    Notes
    -----
    The first time ``interactive_backend`` context manager is called, any of the available
    interactive backends can be chosen. The following times, this same backend must be used
    unless the kernel is restarted.

    Parameters
    ----------
    backend : str, optional
        Interactive backend to use. It will be passed to ``%matplotlib`` magic, refer to
        its docs to see available options.

    Examples
    --------
    Inside an ipython session (i.e. a jupyter notebook) with the inline backend set:

    .. code::

        >>> import arviz as az
        >>> idata = az.load_arviz_data(""centered_eight"")
        >>> az.plot_posterior(idata) # inline
        >>> with az.interactive_backend():
        ...     az.plot_density(idata) # interactive
        >>> az.plot_trace(idata) # inline

    '''
    _used_backend = None

    def __init__(self, backend=""""):
        '''Initialize context manager.'''
        self.backend = backend

    def __enter__(self):
        '''Enter context manager.'''
        self.ip = get_ipython()
        if self.ip is None:
            raise RuntimeError(""interactive_backend can only be used in IPython environments"")
        prev = matplotlib.get_backend()
        self._was_inline = ""inline"" in prev.lower()
        if not self._was_inline:
            raise RuntimeError(""interactive_backend only supports inline -> interactive transitions"")
        if interactive_backend._used_backend is None:
            # first use
            if self.backend:
                to_use = self.backend
                self.ip.run_line_magic(""matplotlib"", to_use)
                interactive_backend._used_backend = to_use
            else:
                # let IPython pick default interactive
                self.ip.run_line_magic(""matplotlib"", """")
                # detect actual and map to magic alias
                be = matplotlib.get_backend().lower()
                if ""qt5"" in be:
                    alias = ""qt5""
                elif ""qt4"" in be:
                    alias = ""qt4""
                elif ""tk"" in be:
                    alias = ""tk""
                elif ""wx"" in be:
                    alias = ""wx""
                elif ""osx"" in be:
                    alias = ""osx""
                elif ""gtk3"" in be:
                    alias = ""gtk3""
                else:
                    alias = be
                interactive_backend._used_backend = alias
        else:
            # subsequent use
            if self.backend and self.backend != interactive_backend._used_backend:
                raise ValueError(
                    f""Backend '{interactive_backend._used_backend}' was already chosen; ""
                    f""cannot switch to '{self.backend}'""
                )
            self.ip.run_line_magic(""matplotlib"", interactive_backend._used_backend)
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        '''Exit context manager.'''
        if self._was_inline:
            self.ip.run_line_magic(""matplotlib"", ""inline"")","class interactive_backend:
    '''Context manager to change backend temporarily in ipython sesson.

    It uses ipython magic to change temporarily from the ipython inline backend to
    an interactive backend of choice. It cannot be used outside ipython sessions nor
    to change backends different than inline -> interactive.

    Notes
    -----
    The first time ``interactive_backend`` context manager is called, any of the available
    interactive backends can be chosen. The following times, this same backend must be used
    unless the kernel is restarted.

    Parameters
    ----------
    backend : str, optional
        Interactive backend to use. It will be passed to ``%matplotlib`` magic, refer to
        its docs to see available options.

    Examples
    --------
    Inside an ipython session (i.e. a jupyter notebook) with the inline backend set:

    .. code::

        >>> import arviz as az
        >>> idata = az.load_arviz_data(""centered_eight"")
        >>> az.plot_posterior(idata) # inline
        >>> with az.interactive_backend():
        ...     az.plot_density(idata) # interactive
        >>> az.plot_trace(idata) # inline

    '''

    def __init__(self, backend=""""):
        '''Initialize context manager.'''
        self.backend = backend
        self.ipyshell = None
        self.original_backend = None

    def __enter__(self):
        '''Enter context manager.'''
        try:
            from IPython import get_ipython
        except ImportError:
            raise RuntimeError(""interactive_backend can only be used within IPython sessions"")
        
        self.ipyshell = get_ipython()
        if self.ipyshell is None:
            raise RuntimeError(""interactive_backend can only be used within IPython sessions"")
        
        # Get current backend
        try:
            current_backend = self.ipyshell.magic(""matplotlib inline --list"") or ""inline""
        except:
            current_backend = ""inline""
        
        self.original_backend = current_backend
        
        # Set the interactive backend
        if self.backend:
            self.ipyshell.magic(f""matplotlib {self.backend}"")
        else:
            self.ipyshell.magic(""matplotlib"")
        
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        '''Exit context manager.'''
        if self.ipyshell is not None and self.original_backend is not None:
            if self.original_backend == ""inline"":
                self.ipyshell.magic(""matplotlib inline"")
            else:
                self.ipyshell.magic(f""matplotlib {self.original_backend}"")","class interactive_backend:
    '''Context manager to change backend temporarily in ipython sesson.

    It uses ipython magic to change temporarily from the ipython inline backend to
    an interactive backend of choice. It cannot be used outside ipython sessions nor
    to change backends different than inline -> interactive.

    Notes
    -----
    The first time ``interactive_backend`` context manager is called, any of the available
    interactive backends can be chosen. The following times, this same backend must be used
    unless the kernel is restarted.

    Parameters
    ----------
    backend : str, optional
        Interactive backend to use. It will be passed to ``%matplotlib`` magic, refer to
        its docs to see available options.

    Examples
    --------
    Inside an ipython session (i.e. a jupyter notebook) with the inline backend set:

    .. code::

        >>> import arviz as az
        >>> idata = az.load_arviz_data(""centered_eight"")
        >>> az.plot_posterior(idata) # inline
        >>> with az.interactive_backend():
        ...     az.plot_density(idata) # interactive
        >>> az.plot_trace(idata) # inline

    '''

    def __init__(self, backend=""""):
        '''Initialize context manager.'''
        self.backend = backend if backend else ""widget""
        self.original_backend = None
        
    def __enter__(self):
        '''Enter context manager.'''
        try:
            from IPython import get_ipython
            ipython = get_ipython()
            if ipython is None:
                raise RuntimeError(""interactive_backend can only be used in IPython sessions"")
            
            import matplotlib
            self.original_backend = matplotlib.get_backend()
            
            ipython.run_line_magic('matplotlib', self.backend)
            
        except ImportError:
            raise RuntimeError(""interactive_backend requires IPython"")
        
        return self
        
    def __exit__(self, exc_type, exc_value, exc_tb):
        '''Exit context manager.'''
        try:
            from IPython import get_ipython
            ipython = get_ipython()
            if ipython is not None:
                ipython.run_line_magic('matplotlib', 'inline')
        except ImportError:
            pass",full_docstr,0.6528662420382164,0.5750798722044729,0.5480769230769231,0.6146496815286623,0.48385746508776295,0.5672937771345875,0.46956521739130436,0.42525399129172714,0.8710631728172302,0.9227932095527649,0.8961822986602783,0.9173453450202942,0.7442947945205476,0.780399274047187,0.7103825136612022,0.6654478976234004,0.7513611615245008,0.6667173008502475,0.7461240310077519,0.654368932038835,0.6070038910505836,0.9199645519256592,0.9338623881340027,0.9268613457679749,0.9324537515640259,0.8034207692307698,0.8408644400785855,0.7416173570019723,0.700990099009901,0.7740667976424361,0.7269560164193526,0.8425925925925926,0.740139211136891,0.6790697674418604,0.9436783194541931,0.9323844909667969,0.9379973411560059,0.933501660823822,0.7971907831325302,0.5306545007370841,0.4867135250267378,0.6835235255406459,0.4285714285714285,0.5238095238095238,0.5881823881200398,0.6363739900887087,0.7163555623914503,0.5238095238095238,0.4761904761904761,0.5414561538314182,0.6978384720738561,0.7060813813470547,0.3809523809523809,0.3809523809523809
120959,FPGAwars/apio,apio/managers/downloader.py,apio.managers.downloader.FileDownloader,"class FileDownloader:
    """"""Class for downloading files""""""

    CHUNK_SIZE = 1024

    def __init__(self, url: str, dest_dir=None):
        """"""Initialize a FileDownloader object
        * INPUTs:
          * url: File to download (full url)
                 (Ex. 'https://github.com/FPGAwars/apio-examples/
                       releases/download/0.0.35/apio-examples-0.0.35.zip')
          * dest_dir: Destination folder (where to download the file)
        """"""

        # -- Store the url
        self._url = url

        # -- Get the file from the url
        # -- Ex: 'apio-examples-0.0.35.zip'
        self.fname = url.split(""/"")[-1]

        # -- Build the destination path
        self.destination = self.fname
        if dest_dir:

            # -- Add the path
            self.destination = dest_dir / self.fname

        # -- Request the file
        self._request = requests.get(url, stream=True, timeout=TIMEOUT_SECS)

        # -- Raise an exception in case of download error...
        if self._request.status_code != 200:
            cout(
                ""Got an unexpected HTTP status code: ""
                f""{self._request.status_code}"",
                f""When downloading {url}"",
                style=ERROR,
            )
            raise util.ApioException()

    def get_size(self) -> int:
        """"""Return the size (in bytes) of the latest bytes block received""""""

        return int(self._request.headers[""content-length""])

    def start(self):
        """"""Start the downloading of the file""""""

        # -- Download iterator
        itercontent = self._request.iter_content(chunk_size=self.CHUNK_SIZE)

        # -- Open destination file, for writing bytes
        with open(self.destination, ""wb"") as file:

            # -- Get the file length in Kbytes
            num_chunks = int(ceil(self.get_size() / float(self.CHUNK_SIZE)))

            # -- Download and write the chunks, while displaying the progress.
            for _ in track(
                range(num_chunks),
                description=""Downloading"",
                console=console(),
            ):

                file.write(next(itercontent))

            # -- Check that the iterator reached its end. When the end is
            # -- reached, next() returns the default value None.
            assert next(itercontent, None) is None

        # -- Download done!
        self._request.close()

    def __del__(self):
        """"""Close any pending request""""""

        if self._request:
            self._request.close()","class FileDownloader:
    '''Class for downloading files'''

    def __init__(self, url: str, dest_dir=None):
    '''Initialize a FileDownloader object
        * INPUTs:
          * url: File to download (full url)
                 (Ex. 'https://github.com/FPGAwars/apio-examples/
                       releases/download/0.0.35/apio-examples-0.0.35.zip')
          * dest_dir: Destination folder (where to download the file)
        '''
        pass

    def get_size(self) -> int:
    '''Return the size (in bytes) of the latest bytes block received'''
        pass

    def start(self):
    '''Start the downloading of the file'''
        pass

    def __del__(self):
    '''Close any pending request'''
        pass

",5,5,snippet_119,0.2666666666666666,"class FileDownloader:
    '''Class for downloading files'''

    def __init__(self, url: str, dest_dir=None):
        '''Initialize a FileDownloader object
            * INPUTs:
              * url: File to download (full url)
              * dest_dir: Destination folder
        '''
        self.url = url
        self.dest_dir = dest_dir or os.getcwd()
        if not os.path.isdir(self.dest_dir):
            os.makedirs(self.dest_dir, exist_ok=True)
        self.filename = os.path.basename(self.url)
        self.filepath = os.path.join(self.dest_dir, self.filename)
        self._last_block_size = 0
        self._response = None

    def get_size(self) -> int:
        '''Return the size (in bytes) of the latest bytes block received'''
        return self._last_block_size

    def start(self):
        '''Start the downloading of the file'''
        try:
            self._response = urlopen(self.url)
            with open(self.filepath, 'wb') as f:
                while True:
                    chunk = self._response.read(8192)
                    if not chunk:
                        break
                    f.write(chunk)
                    self._last_block_size = len(chunk)
        except (HTTPError, URLError) as e:
            raise RuntimeError(f""Download failed: {e}"")
        finally:
            if self._response:
                try:
                    self._response.close()
                except:
                    pass
                self._response = None

    def __del__(self):
        '''Close any pending request'''
        if self._response:
            try:
                self._response.close()
            except:
                pass
            self._response = None","class FileDownloader:
    '''Class for downloading files'''

    def __init__(self, url: str, dest_dir=None):
        '''Initialize a FileDownloader object
        * INPUTs:
          * url: File to download (full url)
                 (Ex. 'https://github.com/FPGAwars/apio-examples/
                       releases/download/0.0.35/apio-examples-0.0.35.zip')
          * dest_dir: Destination folder (where to download the file)
        '''
        self.url = url
        self.dest_dir = dest_dir
        self.response = None
        self.size = 0
        
        if self.dest_dir is None:
            self.dest_dir = os.getcwd()
        else:
            os.makedirs(self.dest_dir, exist_ok=True)
            
        # Extract filename from URL
        parsed_url = urlparse(url)
        self.filename = os.path.basename(parsed_url.path)
        if not self.filename:
            self.filename = 'downloaded_file'
        self.filepath = os.path.join(self.dest_dir, self.filename)

    def get_size(self) -> int:
        '''Return the size (in bytes) of the latest bytes block received'''
        return self.size

    def start(self):
        '''Start the downloading of the file'''
        self.response = requests.get(self.url, stream=True)
        self.response.raise_for_status()
        
        with open(self.filepath, 'wb') as f:
            for chunk in self.response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    self.size = len(chunk)

    def __del__(self):
        '''Close any pending request'''
        if hasattr(self, 'response') and self.response is not None:
            self.response.close()","class FileDownloader:
    '''Class for downloading files'''

    def __init__(self, url: str, dest_dir=None):
        '''Initialize a FileDownloader object
        * INPUTs:
          * url: File to download (full url)
                 (Ex. 'https://github.com/FPGAwars/apio-examples/
                       releases/download/0.0.35/apio-examples-0.0.35.zip')
          * dest_dir: Destination folder (where to download the file)
        '''
        self.url = url
        self.dest_dir = dest_dir if dest_dir else os.getcwd()
        self.response = None
        self.latest_chunk_size = 0
        
        # Extract filename from URL
        parsed_url = urlparse(url)
        self.filename = os.path.basename(parsed_url.path)
        if not self.filename:
            self.filename = 'downloaded_file'
        
        self.dest_path = os.path.join(self.dest_dir, self.filename)

    def get_size(self) -> int:
        '''Return the size (in bytes) of the latest bytes block received'''
        return self.latest_chunk_size

    def start(self):
        '''Start the downloading of the file'''
        try:
            self.response = requests.get(self.url, stream=True)
            self.response.raise_for_status()
            
            # Create destination directory if it doesn't exist
            os.makedirs(self.dest_dir, exist_ok=True)
            
            with open(self.dest_path, 'wb') as file:
                for chunk in self.response.iter_content(chunk_size=8192):
                    if chunk:
                        file.write(chunk)
                        self.latest_chunk_size = len(chunk)
                        
        except Exception as e:
            if self.response:
                self.response.close()
                self.response = None
            raise e

    def __del__(self):
        '''Close any pending request'''
        if hasattr(self, 'response') and self.response:
            self.response.close()",full_docstr,0.49471458773784355,0.28874734607218683,0.23454157782515989,0.40591966173361527,0.253994517485338,0.7342857142857143,0.42120343839541546,0.29310344827586204,0.8381924629211426,0.7610598206520081,0.7977660894393921,0.7681282758712769,0.7995662745098039,0.6288032454361056,0.40325865580448067,0.3394683026584867,0.4949290060851927,0.31697238846714165,0.8022284122562674,0.5083798882681564,0.38375350140056025,0.8781369924545288,0.8211126923561096,0.8486679792404175,0.8264796733856201,0.7962983333333332,0.6046511627906976,0.40856031128404674,0.33203125,0.47674418604651164,0.343816299038687,0.7563451776649747,0.48091603053435117,0.3647959183673469,0.8735778331756592,0.8284332752227783,0.85040682554245,0.8327367305755615,0.7919410784313725,0.2417392098874132,0.1155821686938159,0.1517485802866638,0.4827586206896552,0.216867469879518,0.4557870284150075,0.1574151682251416,0.2036639799176471,0.4620689655172413,0.0,0.4588580116513669,0.1693058601895191,0.2040572208987071,0.4620689655172413,0.0
127025,HazyResearch/fonduer,HazyResearch_fonduer/src/fonduer/utils/logging/tensorboard_writer.py,fonduer.utils.logging.tensorboard_writer.TensorBoardLogger,"class TensorBoardLogger(object):
    """"""A class for logging to Tensorboard during training process.""""""

    def __init__(self, log_dir: str):
        """"""Create a summary writer logging to log_dir.""""""
        self.writer = SummaryWriter(log_dir)

    def add_scalar(self, name: str, value: float, step: int) -> None:
        """"""Log a scalar variable.""""""
        self.writer.add_scalar(name, value, step)

    def close(self) -> None:
        """"""Close the tensorboard logger.""""""
        self.writer.close()","class TensorBoardLogger(object):
    '''A class for logging to Tensorboard during training process.'''

    def __init__(self, log_dir: str):
    '''Create a summary writer logging to log_dir.'''
        pass

    def add_scalar(self, name: str, value: float, step: int) -> None:
    '''Log a scalar variable.'''
        pass

    def close(self) -> None:
    '''Close the tensorboard logger.'''
        pass

",4,4,snippet_143,0.6,"class TensorBoardLogger(object):
    '''A class for logging to Tensorboard during training process.'''

    def __init__(self, log_dir: str):
        '''Create a summary writer logging to log_dir.'''
        self.writer = SummaryWriter(log_dir)

    def add_scalar(self, name: str, value: float, step: int) -> None:
        '''Log a scalar variable.'''
        self.writer.add_scalar(name, value, step)

    def close(self) -> None:
        '''Close the tensorboard logger.'''
        self.writer.close()","class TensorBoardLogger(object):
    '''A class for logging to Tensorboard during training process.'''

    def __init__(self, log_dir: str):
        '''Create a summary writer logging to log_dir.'''
        self.writer = SummaryWriter(log_dir=log_dir)

    def add_scalar(self, name: str, value: float, step: int) -> None:
        '''Log a scalar variable.'''
        self.writer.add_scalar(name, value, step)

    def close(self) -> None:
        '''Close the tensorboard logger.'''
        self.writer.close()","class TensorBoardLogger(object):
    '''A class for logging to Tensorboard during training process.'''

    def __init__(self, log_dir: str):
        '''Create a summary writer logging to log_dir.'''
        self.writer = SummaryWriter(log_dir=log_dir)

    def add_scalar(self, name: str, value: float, step: int) -> None:
        '''Log a scalar variable.'''
        self.writer.add_scalar(name, value, step)

    def close(self) -> None:
        '''Close the tensorboard logger.'''
        self.writer.close()",full_docstr,1.0,1.0,1.0,1.0,0.7297940073211887,0.9333333333333333,0.865546218487395,0.7966101694915254,0.997870683670044,0.997870683670044,0.997870683670044,0.997870683670044,1.0,0.9846153846153847,0.9843749999999999,0.9841269841269841,0.9846153846153847,0.733396050328874,0.9032258064516129,0.8373983739837398,0.7704918032786885,0.9948418736457825,0.9958014488220215,0.9953214526176453,0.9957053065299988,0.992674065934066,0.9846153846153847,0.9843749999999999,0.9841269841269841,0.9846153846153847,0.733396050328874,0.9032258064516129,0.8373983739837398,0.7704918032786885,0.9948418736457825,0.9958014488220215,0.9953214526176453,0.9957053065299988,0.992674065934066,0.8042015258360444,0.6040051329758228,0.612800970368355,1.0,1.0,0.7038829607490993,0.551893816255108,0.5611208642698935,0.7894736842105263,0.9130434782608696,0.7038829607490993,0.551893816255108,0.5611208642698935,0.7894736842105263,0.9130434782608696
321419,cuducos/getgist,getgist/__main__.py,getgist.__main__.GetGist,"class GetGist(object):
    """"""
    Main GetGist objects linking inputs from the CLI to the helpers from
    GitHubTools (to deal with the API) and LocalTools (to deal with the local
    file system.
    """"""

    def __init__(self, **kwargs):
        """"""
        Instantiate GitHubTools & LocalTools (if needed), and set the variables required
        to get, create or update gists (filename and public/private flag)
        :param user: (str) GitHub username
        :param filename: (str) name of file from any Gist or local file system
        :param allow_none: (bool) flag to use GitHubTools.select_gist
        differently with `getgist` and `putgist` commands (if no gist/filename
        is found it raises an error for `getgist`, or sets `putgist` to create
        a new gist).
        :param create_private: (bool) create a new gist as private
        :param assume_yes: (bool) assume yes (or first option) for all prompts
        :return: (None)
        """"""
        user = kwargs.get(""user"")
        allow_none = kwargs.get(""allow_none"", False)
        assume_yes = kwargs.get(""assume_yes"", False)
        filename = kwargs.get(""filename"")
        self.public = not kwargs.get(""create_private"", False)

        if not user:
            message = """"""
            No default user set yet. To avoid this prompt set an
            environmental variable called  `GETGIST_USER`.'
            """"""
            GetGistCommons().oops(message)
            exit(1)

        self.github = GitHubTools(user, filename, assume_yes)
        self.local = LocalTools(filename, assume_yes) if filename else None
        self.gist = self.github.select_gist(allow_none) if filename else None

    def get(self):
        """"""Reads the remote file from Gist and save it locally""""""
        if self.gist:
            content = self.github.read_gist_file(self.gist)
            self.local.save(content)

    def put(self):
        """""" Reads local file & update the remote gist (or create a new one)""""""
        content = self.local.read()
        if self.gist:
            self.github.update(self.gist, content)
        else:
            self.github.create(content, public=self.public)

    def ls(self):
        """""" Lists all gists from a github user """"""
        self.github.list_gists()","class GetGist(object):
    '''
    Main GetGist objects linking inputs from the CLI to the helpers from
    GitHubTools (to deal with the API) and LocalTools (to deal with the local
    file system.
    '''

    def __init__(self, **kwargs):
    '''
        Instantiate GitHubTools & LocalTools (if needed), and set the variables required
        to get, create or update gists (filename and public/private flag)
        :param user: (str) GitHub username
        :param filename: (str) name of file from any Gist or local file system
        :param allow_none: (bool) flag to use GitHubTools.select_gist
        differently with `getgist` and `putgist` commands (if no gist/filename
        is found it raises an error for `getgist`, or sets `putgist` to create
        a new gist).
        :param create_private: (bool) create a new gist as private
        :param assume_yes: (bool) assume yes (or first option) for all prompts
        :return: (None)
        '''
        pass

    def get(self):
    '''Reads the remote file from Gist and save it locally'''
        pass

    def put(self):
    ''' Reads local file & update the remote gist (or create a new one)'''
        pass

    def ls(self):
    ''' Lists all gists from a github user '''
        pass

",5,5,snippet_567,0.2307692307692307,"class GetGist(object):
    '''
    Main GetGist objects linking inputs from the CLI to the helpers from
    GitHubTools (to deal with the API) and LocalTools (to deal with the local
    file system.
    '''

    def __init__(self, **kwargs):
        '''
        Instantiate GitHubTools & LocalTools (if needed), and set the variables required
        to get, create or update gists (filename and public/private flag)
        :param user: (str) GitHub username
        :param filename: (str) name of file from any Gist or local file system
        :param allow_none: (bool) flag to use GitHubTools.select_gist
        differently with `getgist` and `putgist` commands (if no gist/filename
        is found it raises an error for `getgist`, or sets `putgist` to create
        a new gist).
        :param create_private: (bool) create a new gist as private
        :param assume_yes: (bool) assume yes (or first option) for all prompts
        :return: (None)
        '''
        self.user = kwargs.get('user')
        self.filename = kwargs.get('filename')
        self.allow_none = kwargs.get('allow_none', False)
        self.create_private = kwargs.get('create_private', False)
        self.assume_yes = kwargs.get('assume_yes', False)

        self.github = GitHubTools()
        self.local = LocalTools()

    def get(self):
        '''Reads the remote file from Gist and save it locally'''
        gist = self.github.select_gist(
            user=self.user,
            filename=self.filename,
            allow_none=self.allow_none,
            assume_yes=self.assume_yes
        )
        content = self.github.download_file(gist_id=gist['id'], filename=self.filename)
        self.local.save_file(self.filename, content)

    def put(self):
        ''' Reads local file & update the remote gist (or create a new one)'''
        content = self.local.read_file(self.filename)
        gist = self.github.select_gist(
            user=self.user,
            filename=self.filename,
            allow_none=self.allow_none,
            assume_yes=self.assume_yes
        )
        files = {self.filename: content}
        if gist:
            self.github.update_gist(gist_id=gist['id'], files=files)
        else:
            public_flag = not self.create_private
            self.github.create_gist(files=files, public=public_flag)

    def ls(self):
        ''' Lists all gists from a github user '''
        return self.github.list_gists(user=self.user)","class GetGist(object):
    '''
    Main GetGist objects linking inputs from the CLI to the helpers from
    GitHubTools (to deal with the API) and LocalTools (to deal with the local
    file system.
    '''

    def __init__(self, **kwargs):
        '''
        Instantiate GitHubTools & LocalTools (if needed), and set the variables required
        to get, create or update gists (filename and public/private flag)
        :param user: (str) GitHub username
        :param filename: (str) name of file from any Gist or local file system
        :param allow_none: (bool) flag to use GitHubTools.select_gist
        differently with `getgist` and `putgist` commands (if no gist/filename
        is found it raises an error for `getgist`, or sets `putgist` to create
        a new gist).
        :param create_private: (bool) create a new gist as private
        :param assume_yes: (bool) assume yes (or first option) for all prompts
        :return: (None)
        '''
        self.user = kwargs.get('user')
        self.filename = kwargs.get('filename')
        self.allow_none = kwargs.get('allow_none', False)
        self.create_private = kwargs.get('create_private', False)
        self.assume_yes = kwargs.get('assume_yes', False)
        
        # Instantiate GitHubTools and LocalTools
        from getgist.github import GitHubTools
        from getgist.local import LocalTools
        
        self.github = GitHubTools(self.user, self.filename)
        self.local = LocalTools(self.filename)

    def get(self):
        '''Reads the remote file from Gist and save it locally'''
        # Select the appropriate gist
        gist = self.github.select_gist(allow_none=self.allow_none)
        if not gist:
            return False
            
        # Get the content from the selected gist
        content = self.github.get_gist_content(gist)
        if content is None:
            return False
            
        # Save the content locally
        return self.local.save_content(content)

    def put(self):
        ''' Reads local file & update the remote gist (or create a new one)'''
        # Read local content
        content = self.local.read_content()
        if content is None:
            return False
            
        # Select or create gist
        gist = self.github.select_gist(allow_none=self.allow_none)
        
        if gist:
            # Update existing gist
            return self.github.update_gist(gist, content)
        else:
            # Create new gist
            is_public = not self.create_private
            return self.github.create_gist(content, is_public)

    def ls(self):
        ''' Lists all gists from a github user '''
        gists = self.github.list_gists()
        if gists:
            for gist in gists:
                print(gist)
            return True
        return False","class GetGist(object):
    '''
    Main GetGist objects linking inputs from the CLI to the helpers from
    GitHubTools (to deal with the API) and LocalTools (to deal with the local
    file system.
    '''

    def __init__(self, **kwargs):
        '''
        Instantiate GitHubTools & LocalTools (if needed), and set the variables required
        to get, create or update gists (filename and public/private flag)
        :param user: (str) GitHub username
        :param filename: (str) name of file from any Gist or local file system
        :param allow_none: (bool) flag to use GitHubTools.select_gist
        differently with `getgist` and `putgist` commands (if no gist/filename
        is found it raises an error for `getgist`, or sets `putgist` to create
        a new gist).
        :param create_private: (bool) create a new gist as private
        :param assume_yes: (bool) assume yes (or first option) for all prompts
        :return: (None)
        '''
        self.user = kwargs.get('user')
        self.filename = kwargs.get('filename')
        self.allow_none = kwargs.get('allow_none', False)
        self.create_private = kwargs.get('create_private', False)
        self.assume_yes = kwargs.get('assume_yes', False)
        
        from .github_tools import GitHubTools
        from .local_tools import LocalTools
        
        self.github = GitHubTools(user=self.user, assume_yes=self.assume_yes)
        self.local = LocalTools()

    def get(self):
        '''Reads the remote file from Gist and save it locally'''
        gist = self.github.select_gist(filename=self.filename, allow_none=self.allow_none)
        if not gist:
            raise ValueError(""No gist found"")
        
        content = self.github.get_gist_content(gist, self.filename)
        self.local.save_file(self.filename, content)

    def put(self):
        ''' Reads local file & update the remote gist (or create a new one)'''
        content = self.local.read_file(self.filename)
        gist = self.github.select_gist(filename=self.filename, allow_none=self.allow_none)
        
        if gist:
            self.github.update_gist(gist, self.filename, content)
        else:
            self.github.create_gist(self.filename, content, private=self.create_private)

    def ls(self):
        ''' Lists all gists from a github user '''
        gists = self.github.list_gists()
        for gist in gists:
            print(f""{gist['id']}: {', '.join(gist['files'].keys())}"")",full_docstr,0.8664495114006514,0.7320261437908496,0.6524590163934426,0.736156351791531,0.6782207414823013,0.7885304659498208,0.6768402154398564,0.5845323741007195,0.9453572034835815,0.9378169775009155,0.9415720105171204,0.9385656714439392,0.8412213564668771,0.8092307692307693,0.6975308641975309,0.628482972136223,0.7169230769230769,0.6590675011336788,0.7635726795096323,0.6543859649122807,0.5729349736379613,0.9269092679023743,0.9383891224861145,0.9326138496398926,0.9372283816337585,0.8414255339805826,0.8516129032258065,0.7411003236245955,0.6623376623376623,0.7451612903225807,0.6715013033499434,0.7797202797202797,0.670753064798599,0.5789473684210527,0.9417256712913513,0.9435825347900391,0.9426531195640564,0.9433965086936951,0.843138823529412,0.5180911796908086,0.6063213653601958,0.6089942345428964,0.5118110236220472,0.3452380952380952,0.5263093169664991,0.5088508587779594,0.6243204173370055,0.5196850393700787,0.4523809523809524,0.526862455846348,0.6097960021906841,0.6131393854991698,0.5511811023622047,0.3333333333333333
235027,annoviko/pyclustering,annoviko_pyclustering/pyclustering/cluster/clique.py,pyclustering.cluster.clique.coordinate_iterator,"class coordinate_iterator:
    """"""!
    @brief Coordinate iterator is used to generate logical location description for each CLIQUE block.
    @details This class is used by CLIQUE algorithm for clustering process.

    """"""

    def __init__(self, dimension, intervals):
        """"""!
        @brief Initializes coordinate iterator for CLIQUE algorithm.

        @param[in] dimension (uint): Amount of dimensions in input data space.
        @param[in] intervals (uint): Amount of intervals in each dimension.

        """"""
        self.__intervals = intervals
        self.__dimension = dimension
        self.__coordiate = [0] * dimension


    def get_coordinate(self):
        """"""!
        @brief Returns current block coordinate.

        """"""
        return self.__coordiate


    def increment(self):
        """"""!
        @brief Forms logical location for next block.

        """"""
        for index_dimension in range(self.__dimension):
            if self.__coordiate[index_dimension] + 1 < self.__intervals:
                self.__coordiate[index_dimension] += 1
                return
            else:
                self.__coordiate[index_dimension] = 0

        self.__coordiate = None","class coordinate_iterator:
    '''!
    @brief Coordinate iterator is used to generate logical location description for each CLIQUE block.
    @details This class is used by CLIQUE algorithm for clustering process.

    '''

    def __init__(self, dimension, intervals):
    '''!
        @brief Initializes coordinate iterator for CLIQUE algorithm.

        @param[in] dimension (uint): Amount of dimensions in input data space.
        @param[in] intervals (uint): Amount of intervals in each dimension.

        '''
        pass

    def get_coordinate(self):
    '''!
        @brief Returns current block coordinate.

        '''
        pass

    def increment(self):
    '''!
        @brief Forms logical location for next block.

        '''
        pass

",4,4,snippet_325,1.0,"class coordinate_iterator:
    '''!
    @brief Coordinate iterator is used to generate logical location description for each CLIQUE block.
    @details This class is used by CLIQUE algorithm for clustering process.
    '''

    def __init__(self, dimension, intervals):
        '''!
        @brief Initializes coordinate iterator for CLIQUE algorithm.

        @param[in] dimension (uint): Amount of dimensions in input data space.
        @param[in] intervals (uint): Amount of intervals in each dimension.
        '''
        self.dimension = dimension
        self.intervals = intervals
        self._coord = [0] * dimension
        self._done = False

    def get_coordinate(self):
        '''!
        @brief Returns current block coordinate.
        '''
        return tuple(self._coord)

    def increment(self):
        '''!
        @brief Forms logical location for next block.
        '''
        if self._done:
            return False
        # if already at last coordinate, mark done
        if all(x == self.intervals - 1 for x in self._coord):
            self._done = True
            return False
        # otherwise carry increment
        for i in reversed(range(self.dimension)):
            if self._coord[i] < self.intervals - 1:
                self._coord[i] += 1
                return True
            self._coord[i] = 0
        return True","class coordinate_iterator:
    '''!
    @brief Coordinate iterator is used to generate logical location description for each CLIQUE block.
    @details This class is used by CLIQUE algorithm for clustering process.

    '''

    def __init__(self, dimension, intervals):
        '''!
        @brief Initializes coordinate iterator for CLIQUE algorithm.

        @param[in] dimension (uint): Amount of dimensions in input data space.
        @param[in] intervals (uint): Amount of intervals in each dimension.

        '''
        self.dimension = dimension
        self.intervals = intervals
        self.current_coordinate = [0] * dimension

    def get_coordinate(self):
        '''!
        @brief Returns current block coordinate.

        '''
        return self.current_coordinate.copy()

    def increment(self):
        '''!
        @brief Forms logical location for next block.

        '''
        for i in range(self.dimension - 1, -1, -1):
            self.current_coordinate[i] += 1
            if self.current_coordinate[i] < self.intervals:
                break
            else:
                self.current_coordinate[i] = 0","class coordinate_iterator:
    '''!
    @brief Coordinate iterator is used to generate logical location description for each CLIQUE block.
    @details This class is used by CLIQUE algorithm for clustering process.

    '''

    def __init__(self, dimension, intervals):
        '''!
        @brief Initializes coordinate iterator for CLIQUE algorithm.

        @param[in] dimension (uint): Amount of dimensions in input data space.
        @param[in] intervals (uint): Amount of intervals in each dimension.

        '''
        self.__dimension = dimension
        self.__intervals = intervals
        self.__coordinate = [0] * dimension

    def get_coordinate(self):
        '''!
        @brief Returns current block coordinate.

        '''
        return self.__coordinate[:]

    def increment(self):
        '''!
        @brief Forms logical location for next block.

        '''
        index = self.__dimension - 1
        
        while index >= 0:
            self.__coordinate[index] += 1
            if self.__coordinate[index] < self.__intervals:
                return True
            else:
                self.__coordinate[index] = 0
                index -= 1
        
        return False",full_docstr,0.7725631768953068,0.6763636363636363,0.6153846153846154,0.7364620938628158,0.6179065840112421,0.724907063197026,0.6119402985074627,0.5318352059925093,0.9052863121032715,0.9433225393295288,0.9239131212234497,0.9393756985664368,0.8679666883116882,0.8582995951417003,0.7918367346938776,0.7160493827160493,0.8097165991902834,0.6281405338797665,0.8590909090909091,0.7123287671232876,0.6192660550458715,0.9506893157958984,0.9591041207313538,0.9548782110214233,0.9582558870315552,0.913044347826087,0.8852459016393442,0.7851239669421487,0.7000000000000001,0.8278688524590164,0.711191104567766,0.8744588744588745,0.7739130434782608,0.6899563318777293,0.956210732460022,0.954678475856781,0.9554440379142761,0.9548313617706299,0.8983061016949152,0.5549203097655762,0.4653002170543863,0.6105901723347154,0.5882352941176471,0.5555555555555556,0.6003921111213999,0.6054433584293774,0.61311855010851,0.6274509803921569,0.5555555555555556,0.6257120593465348,0.5937867414449616,0.6263817573790866,0.5882352941176471,0.6944444444444444
135534,JdeRobot/base,src/libs/comm_py/comm/ros/listenerLaser.py,comm.ros.listenerLaser.ListenerLaser,"class ListenerLaser:
    '''
        ROS Laser Subscriber. Laser Client to Receive Laser Scans from ROS nodes.
    '''
    def __init__(self, topic):
        '''
        ListenerLaser Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        self.topic = topic
        self.data = LaserData()
        self.sub = None
        self.lock = threading.Lock()
        self.start()
 
    def __callback (self, scan):
        '''
        Callback function to receive and save Laser Scans. 

        @param scan: ROS LaserScan received
        
        @type scan: LaserScan

        '''
        laser = laserScan2LaserData(scan)

        self.lock.acquire()
        self.data = laser
        self.lock.release()
        
    def stop(self):
        '''
        Stops (Unregisters) the client.

        '''
        self.sub.unregister()

    def start (self):
        '''
        Starts (Subscribes) the client.

        '''
        self.sub = rospy.Subscriber(self.topic, LaserScan, self.__callback)
        
    def getLaserData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        self.lock.acquire()
        laser = self.data
        self.lock.release()
        
        return laser","class ListenerLaser:
    '''
        ROS Laser Subscriber. Laser Client to Receive Laser Scans from ROS nodes.
    '''

    def __init__(self, topic):
    '''
        ListenerLaser Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        pass

    def __callback (self, scan):
    '''
        Callback function to receive and save Laser Scans. 

        @param scan: ROS LaserScan received
        
        @type scan: LaserScan

        '''
        pass

    def stop(self):
    '''
        Stops (Unregisters) the client.

        '''
        pass

    def start (self):
    '''
        Starts (Subscribes) the client.

        '''
        pass

    def getLaserData(self):
    '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        pass

",6,6,snippet_162,0.4285714285714285,"class ListenerLaser:
    '''
        ROS Laser Subscriber. Laser Client to Receive Laser Scans from ROS nodes.
    '''

    def __init__(self, topic):
        '''
        ListenerLaser Constructor.

        @param topic: ROS topic to subscribe

        @type topic: String
        '''
        self.topic = topic
        self.subscriber = None
        self.laserData = None

    def __callback(self, scan):
        '''
        Callback function to receive and save Laser Scans.

        @param scan: ROS LaserScan received

        @type scan: LaserScan
        '''
        data = LaserData()
        data.distances = list(scan.ranges)
        data.angle0 = scan.angle_min
        data.aperture = scan.angle_max - scan.angle_min
        data.resolution = scan.angle_increment
        data.count = len(scan.ranges)
        self.laserData = data

    def stop(self):
        '''
        Stops (Unregisters) the client.
        '''
        if self.subscriber is not None:
            self.subscriber.unregister()
            self.subscriber = None

    def start(self):
        '''
        Starts (Subscribes) the client.
        '''
        if self.subscriber is None:
            self.subscriber = rospy.Subscriber(self.topic, LaserScan, self.__callback)

    def getLaserData(self):
        '''
        Returns last LaserData.

        @return last JdeRobotTypes LaserData saved
        '''
        return self.laserData","class ListenerLaser:
    '''
        ROS Laser Subscriber. Laser Client to Receive Laser Scans from ROS nodes.
    '''

    def __init__(self, topic):
        '''
        ListenerLaser Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        self.topic = topic
        self.data = LaserData()
        self.sub = None
        self.start()

    def __callback(self, scan):
        '''
        Callback function to receive and save Laser Scans. 

        @param scan: ROS LaserScan received
        
        @type scan: LaserScan

        '''
        self.data.values = list(scan.ranges)
        self.data.minAngle = scan.angle_min
        self.data.maxAngle = scan.angle_max
        self.data.minRange = scan.range_min
        self.data.maxRange = scan.range_max
        self.data.angleIncrement = scan.angle_increment

    def stop(self):
        '''
        Stops (Unregisters) the client.

        '''
        if self.sub is not None:
            self.sub.unregister()
            self.sub = None

    def start(self):
        '''
        Starts (Subscribes) the client.

        '''
        if self.sub is None:
            self.sub = rospy.Subscriber(self.topic, LaserScan, self.__callback)

    def getLaserData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        return self.data","class ListenerLaser:
    '''
        ROS Laser Subscriber. Laser Client to Receive Laser Scans from ROS nodes.
    '''

    def __init__(self, topic):
        '''
        ListenerLaser Constructor.

        @param topic: ROS topic to subscribe
        
        @type topic: String

        '''
        self.topic = topic
        self.sub = None
        self.laser_data = None
        self.lock = threading.Lock()

    def __callback(self, scan):
        '''
        Callback function to receive and save Laser Scans. 

        @param scan: ROS LaserScan received
        
        @type scan: LaserScan

        '''
        with self.lock:
            self.laser_data = scan

    def stop(self):
        '''
        Stops (Unregisters) the client.

        '''
        if self.sub is not None:
            self.sub.unregister()
            self.sub = None

    def start(self):
        '''
        Starts (Subscribes) the client.

        '''
        if self.sub is None:
            self.sub = rospy.Subscriber(self.topic, LaserScan, self.__callback)

    def getLaserData(self):
        '''
        Returns last LaserData. 

        @return last JdeRobotTypes LaserData saved

        '''
        with self.lock:
            return self.laser_data",full_docstr,0.7509293680297399,0.6142322097378277,0.5660377358490566,0.6988847583643123,0.6741342467457787,0.7769230769230769,0.6563706563706564,0.6007751937984496,0.8931189775466919,0.9235256910324097,0.9080678820610046,0.9203921556472778,0.8263175263157895,0.7883211678832117,0.6911764705882352,0.637037037037037,0.7591240875912408,0.7056301940277482,0.7712177121771218,0.6962962962962963,0.654275092936803,0.9094657897949219,0.9318059086799622,0.9205003380775452,0.9295226335525513,0.8509227638190955,0.9047619047619047,0.744,0.6693548387096775,0.8253968253968254,0.7977487987538268,0.9074889867841409,0.8185840707964602,0.76,0.9602611064910889,0.9591813087463379,0.9597209095954895,0.9592891931533813,0.866668,0.6299881786524754,0.6020912331350686,0.6954002078087398,0.6867469879518072,0.5357142857142857,0.7031064400921281,0.6726533708199728,0.749927294884168,0.7469879518072289,0.6428571428571429,0.6625315402853353,0.7001677903738404,0.7270668045024408,0.7228915662650602,0.5
171252,PyCQA/pylint,tests/regrtest_data/classdoc_usage.py,classdoc_usage.SomeClass,"class SomeClass:
    """"""cds""""""
    doc = __doc__

    def __init__(self):
        """"""only to make pylint happier""""""

    def please(self):
        """"""public method 1/2""""""

    def besilent(self):
        """"""public method 2/2""""""","class SomeClass:
    '''cds'''

    def __init__(self):
    '''only to make pylint happier'''
        pass

    def please(self):
    '''public method 1/2'''
        pass

    def besilent(self):
    '''public method 2/2'''
        pass

",4,4,snippet_222,1.0,"class SomeClass:
    '''cds'''

    def __init__(self):
        '''only to make pylint happier'''
        self._silent = False

    def please(self):
        '''public method 1/2'''
        if not self._silent:
            print('Please?')

    def besilent(self):
        '''public method 2/2'''
        self._silent = True","class SomeClass:
    '''cds'''

    def __init__(self):
        '''only to make pylint happier'''
        pass

    def please(self):
        '''public method 1/2'''
        return ""please""

    def besilent(self):
        '''public method 2/2'''
        return ""be silent""","class SomeClass:
    '''cds'''

    def __init__(self):
        '''only to make pylint happier'''
        self._silent = False

    def please(self):
        '''public method 1/2'''
        self._silent = False
        return self

    def besilent(self):
        '''public method 2/2'''
        self._silent = True
        return self",full_docstr,0.7812500000000001,0.6774193548387097,0.5666666666666667,0.7812500000000001,0.3930869531817753,0.582089552238806,0.42424242424242425,0.3230769230769231,0.8653349280357361,0.9294215440750122,0.8962340354919434,0.9225888848304749,0.8512835384615385,0.8620689655172414,0.75,0.6296296296296295,0.8620689655172414,0.3792743280690936,0.75,0.5686274509803921,0.44,0.9108922481536865,0.9344522953033447,0.9225218892097473,0.9320416450500488,0.900001,0.7692307692307692,0.6666666666666666,0.5573770491803278,0.7692307692307692,0.3909619611542736,0.609375,0.4444444444444444,0.3387096774193548,0.8762698173522949,0.9360133409500122,0.9051568508148193,0.9296748638153076,0.8579249180327868,0.2541441018057678,0.0597805022516482,0.0840686322441503,0.2727272727272727,0.6,0.1560922697668137,0.0682826774606969,0.0833591288792855,0.2727272727272727,0.2,0.2027188648534727,0.0540795544424678,0.0840686322441503,0.2727272727272727,0.4
144080,KrzyHonk/bpmn-python,KrzyHonk_bpmn-python/bpmn_python/graph/classes/base_element_type.py,KrzyHonk_bpmn-python.bpmn_python.graph.classes.base_element_type.BaseElement,"class BaseElement(object):
    """"""
    Class used for representing tBaseElement of BPMN 2.0 graph.
    Fields:
    - id: an ID of element. Must be either None (ID is optional according to BPMN 2.0 XML Schema) or String.
    """"""

    def __init__(self):
        """"""
        Default constructor, initializes object fields with new instances.
        """"""
        self.__id = None

    def get_id(self):
        """"""
        Getter for 'id' field.
        :return: value of 'id' field.
        """"""
        return self.__id

    def set_id(self, value):
        """"""
        Setter for 'id' field.
        :param value - a new value of 'id' field. Must be either None (ID is optional according to BPMN 2.0 XML Schema)
        or String type.
        """"""
        if value is None:
            self.__id = value
        if not isinstance(value, str):
            raise TypeError(""ID must be set to a String"")
        else:
            self.__id = value","class BaseElement(object):
    '''
    Class used for representing tBaseElement of BPMN 2.0 graph.
    Fields:
    - id: an ID of element. Must be either None (ID is optional according to BPMN 2.0 XML Schema) or String.
    '''

    def __init__(self):
    '''
        Default constructor, initializes object fields with new instances.
        '''
        pass

    def get_id(self):
    '''
        Getter for 'id' field.
        :return: value of 'id' field.
        '''
        pass

    def set_id(self, value):
    '''
        Setter for 'id' field.
        :param value - a new value of 'id' field. Must be either None (ID is optional according to BPMN 2.0 XML Schema)
        or String type.
        '''
        pass

",4,4,snippet_171,1.0,"class BaseElement(object):
    '''
    Class used for representing tBaseElement of BPMN 2.0 graph.
    Fields:
    - id: an ID of element. Must be either None (ID is optional according to BPMN 2.0 XML Schema) or String.
    '''

    def __init__(self):
        '''
        Default constructor, initializes object fields with new instances.
        '''
        self._id = None

    def get_id(self):
        '''
        Getter for 'id' field.
        :return: value of 'id' field.
        '''
        return self._id

    def set_id(self, value):
        '''
        Setter for 'id' field.
        :param value: a new value of 'id' field. Must be either None (ID is optional according to BPMN 2.0 XML Schema)
                      or String type.
        '''
        if value is not None and not isinstance(value, str):
            raise TypeError(""id must be a string or None"")
        self._id = value

    id = property(get_id, set_id)","class BaseElement(object):
    '''
    Class used for representing tBaseElement of BPMN 2.0 graph.
    Fields:
    - id: an ID of element. Must be either None (ID is optional according to BPMN 2.0 XML Schema) or String.
    '''

    def __init__(self):
        '''
        Default constructor, initializes object fields with new instances.
        '''
        self._id = None

    def get_id(self):
        '''
        Getter for 'id' field.
        :return: value of 'id' field.
        '''
        return self._id

    def set_id(self, value):
        '''
        Setter for 'id' field.
        :param value - a new value of 'id' field. Must be either None (ID is optional according to BPMN 2.0 XML Schema)
        or String type.
        '''
        if value is not None and not isinstance(value, str):
            raise TypeError(""ID must be either None or String"")
        self._id = value","class BaseElement(object):
    '''
    Class used for representing tBaseElement of BPMN 2.0 graph.
    Fields:
    - id: an ID of element. Must be either None (ID is optional according to BPMN 2.0 XML Schema) or String.
    '''

    def __init__(self):
        '''
        Default constructor, initializes object fields with new instances.
        '''
        self.id = None

    def get_id(self):
        '''
        Getter for 'id' field.
        :return: value of 'id' field.
        '''
        return self.id

    def set_id(self, value):
        '''
        Setter for 'id' field.
        :param value - a new value of 'id' field. Must be either None (ID is optional according to BPMN 2.0 XML Schema)
        or String type.
        '''
        self.id = value",full_docstr,0.9482071713147411,0.9076305220883534,0.8825910931174089,0.9322709163346614,0.7286493707210207,0.8923076923076924,0.7938144329896907,0.6994818652849741,0.9744387865066528,0.9767543077468872,0.9755951762199402,0.9765222668647766,0.9195410344827586,0.946938775510204,0.9135802469135802,0.8962655601659751,0.946938775510204,0.7345095038504978,0.9289617486338798,0.8626373626373627,0.7845303867403315,0.983966588973999,0.9803979992866516,0.9821791052818298,0.9807537198066711,0.9501920689655172,0.9026548672566371,0.8928571428571429,0.882882882882883,0.9026548672566371,0.5958176778843961,0.9477124183006536,0.875,0.8013245033112583,0.9916657209396362,0.9497379660606384,0.9702491164207458,0.9537705779075623,0.88889,0.6510239096442938,0.6471634461481872,0.6575900871658302,0.7368421052631579,0.5625,0.7379290862268156,0.6963521165715303,0.7060221230725745,0.7368421052631579,0.8125,0.6273015315609879,0.6292246748269301,0.639849872469653,0.5526315789473685,0.6875
111134,CygnusNetworks/pypureomapi,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/CygnusNetworks_pypureomapi/pypureomapi.py,pypureomapi.OmapiStartupMessage,"class OmapiStartupMessage(object):  # pylint:disable=useless-object-inheritance
    """"""Class describing the protocol negotiation messages.

    >>> s = OmapiStartupMessage().as_string()
    >>> s == b""\\0\\0\\0\\x64\\0\\0\\0\\x18""
    True
    >>> next(InBuffer(s).parse_startup_message()).validate()
    >>> OmapiStartupMessage(42).validate()
    Traceback (most recent call last):
    ...
    OmapiError: protocol mismatch
    """"""
    implemented_protocol_version = 100
    implemented_header_size = 4 * 6

    def __init__(self, protocol_version=None, header_size=None):
        """"""
        @type protocol_version: int or None
        @type header_size: int or None
        """"""
        if protocol_version is None:
            protocol_version = self.implemented_protocol_version
        if header_size is None:
            header_size = self.implemented_header_size
        self.protocol_version = protocol_version
        self.header_size = header_size

    def validate(self):
        """"""Checks whether this OmapiStartupMessage matches the implementation.
        @raises OmapiError:
        """"""
        if self.implemented_protocol_version != self.protocol_version:
            raise OmapiError(""protocol mismatch"")
        if self.implemented_header_size != self.header_size:
            raise OmapiError(""header size mismatch"")

    def as_string(self):
        """"""
        @rtype: bytes
        """"""
        ret = OutBuffer()
        self.serialize(ret)
        return ret.getvalue()

    def serialize(self, outbuffer):
        """"""Serialize this OmapiStartupMessage to the given outbuffer.
        @type outbuffer: OutBuffer
        """"""
        outbuffer.add_net32int(self.protocol_version)
        outbuffer.add_net32int(self.header_size)

    def dump_oneline(self):
        """"""
        @rtype: str
        @returns: a human readable representation in one line
        """"""
        return ""protocol_version=%d header_size=%d"" % (self.protocol_version, self.header_size)","class OmapiStartupMessage(object):
    '''Class describing the protocol negotiation messages.

    >>> s = OmapiStartupMessage().as_string()
    >>> s == b""\0\0\0\x64\0\0\0\x18""
    True
    >>> next(InBuffer(s).parse_startup_message()).validate()
    >>> OmapiStartupMessage(42).validate()
    Traceback (most recent call last):
    ...
    OmapiError: protocol mismatch
    '''


    def __init__(self, protocol_version=None, header_size=None):
    '''
        @type protocol_version: int or None
        @type header_size: int or None
        '''
        pass


    def validate(self):
    '''Checks whether this OmapiStartupMessage matches the implementation.
        @raises OmapiError:
        '''
        pass


    def as_string(self):
    '''
        @rtype: bytes
        '''
        pass


    def serialize(self, outbuffer):
    '''Serialize this OmapiStartupMessage to the given outbuffer.
        @type outbuffer: OutBuffer
        '''
        pass


    def dump_oneline(self):
    '''
        @rtype: str
        @returns: a human readable representation in one line
        '''
        pass

",6,6,snippet_81,1.0,"class OmapiStartupMessage(object):
    '''Class describing the protocol negotiation messages.

    >>> s = OmapiStartupMessage().as_string()
    >>> s == b""\0\0\0\x64\0\0\0\x18""
    True
    >>> next(InBuffer(s).parse_startup_message()).validate()
    >>> OmapiStartupMessage(42).validate()
    Traceback (most recent call last):
    ...
    OmapiError: protocol mismatch
    '''

    DEFAULT_PROTOCOL_VERSION = 100
    DEFAULT_HEADER_SIZE = 24

    def __init__(self, protocol_version=None, header_size=None):
        '''
            @type protocol_version: int or None
            @type header_size: int or None
        '''
        if protocol_version is None:
            protocol_version = self.DEFAULT_PROTOCOL_VERSION
        if header_size is None:
            header_size = self.DEFAULT_HEADER_SIZE
        self.protocol_version = protocol_version
        self.header_size = header_size

    def validate(self):
        '''Checks whether this OmapiStartupMessage matches the implementation.
            @raises OmapiError:
        '''
        if (self.protocol_version != self.DEFAULT_PROTOCOL_VERSION or
            self.header_size != self.DEFAULT_HEADER_SIZE):
            raise OmapiError(""protocol mismatch"")

    def as_string(self):
        '''
            @rtype: bytes
        '''
        return struct.pack("">II"",
                           self.protocol_version,
                           self.header_size)

    def serialize(self, outbuffer):
        '''Serialize this OmapiStartupMessage to the given outbuffer.
            @type outbuffer: OutBuffer
        '''
        outbuffer.write(self.as_string())

    def dump_oneline(self):
        '''
            @rtype: str
            @returns: a human readable representation in one line
        '''
        return (""OmapiStartupMessage(protocol_version=%d, ""
                ""header_size=%d)"") % (
                    self.protocol_version,
                    self.header_size)","class OmapiStartupMessage(object):
    '''Class describing the protocol negotiation messages.

    >>> s = OmapiStartupMessage().as_string()
    >>> s == b""\0\0\0\x64\0\0\0\x18""
    True
    >>> next(InBuffer(s).parse_startup_message()).validate()
    >>> OmapiStartupMessage(42).validate()
    Traceback (most recent call last):
    ...
    OmapiError: protocol mismatch
    '''

    def __init__(self, protocol_version=None, header_size=None):
        '''
        @type protocol_version: int or None
        @type header_size: int or None
        '''
        if protocol_version is None:
            protocol_version = 100
        if header_size is None:
            header_size = 24
        self.protocol_version = protocol_version
        self.header_size = header_size

    def validate(self):
        '''Checks whether this OmapiStartupMessage matches the implementation.
        @raises OmapiError:
        '''
        if self.protocol_version != 100 or self.header_size != 24:
            raise OmapiError(""protocol mismatch"")

    def as_string(self):
        '''
        @rtype: bytes
        '''
        outbuffer = OutBuffer()
        self.serialize(outbuffer)
        return outbuffer.getvalue()

    def serialize(self, outbuffer):
        '''Serialize this OmapiStartupMessage to the given outbuffer.
        @type outbuffer: OutBuffer
        '''
        outbuffer.add_net32int(self.protocol_version)
        outbuffer.add_net32int(self.header_size)

    def dump_oneline(self):
        '''
        @rtype: str
        @returns: a human readable representation in one line
        '''
        return f""OmapiStartupMessage(protocol_version={self.protocol_version}, header_size={self.header_size})""","class OmapiStartupMessage(object):
    '''Class describing the protocol negotiation messages.

    >>> s = OmapiStartupMessage().as_string()
    >>> s == b""\0\0\0\x64\0\0\0\x18""
    True
    >>> next(InBuffer(s).parse_startup_message()).validate()
    >>> OmapiStartupMessage(42).validate()
    Traceback (most recent call last):
    ...
    OmapiError: protocol mismatch
    '''

    def __init__(self, protocol_version=None, header_size=None):
        '''
        @type protocol_version: int or None
        @type header_size: int or None
        '''
        self.protocol_version = protocol_version if protocol_version is not None else 100
        self.header_size = header_size if header_size is not None else 24

    def validate(self):
        '''Checks whether this OmapiStartupMessage matches the implementation.
        @raises OmapiError:
        '''
        if self.protocol_version != 100 or self.header_size != 24:
            raise OmapiError(""protocol mismatch"")

    def as_string(self):
        '''
        @rtype: bytes
        '''
        return struct.pack(""!II"", self.protocol_version, self.header_size)

    def serialize(self, outbuffer):
        '''Serialize this OmapiStartupMessage to the given outbuffer.
        @type outbuffer: OutBuffer
        '''
        outbuffer.write(self.as_string())

    def dump_oneline(self):
        '''
        @rtype: str
        @returns: a human readable representation in one line
        '''
        return f""OmapiStartupMessage(protocol_version={self.protocol_version}, header_size={self.header_size})""",full_docstr,0.8905109489051095,0.8166259168704156,0.737100737100737,0.856447688564477,0.6876169654437632,0.8935643564356436,0.771712158808933,0.6840796019900498,0.943780779838562,0.9285435676574707,0.93610018491745,0.9300451278686523,0.9056919999999999,0.8759493670886076,0.8193384223918575,0.7570332480818415,0.8556962025316457,0.6652327546476465,0.9313186813186813,0.8567493112947658,0.7762430939226519,0.957290530204773,0.9212644696235657,0.9389320611953735,0.9247445464134216,0.917074,0.8256410256410256,0.7422680412371134,0.6580310880829014,0.7487179487179487,0.5935585178478325,0.9002849002849003,0.8,0.7020057306590258,0.9342082738876343,0.8992348313331604,0.9163879752159119,0.9026139378547668,0.832522,0.5043778446719736,0.5228506834966441,0.5348905802487213,0.6666666666666666,0.293103448275862,0.5389319930280405,0.5307946355500199,0.545622991734556,0.7,0.3793103448275862,0.3783213775511278,0.4508210617875003,0.4689778583786967,0.4555555555555555,0.1379310344827586
316075,coopernurse/barrister,coopernurse_barrister/barrister/runtime.py,barrister.runtime.Interface,"class Interface(object):
    """"""
    Represents a Barrister IDL 'interface' entity.
    """"""

    def __init__(self, iface, contract):
        """"""
        Creates an Interface. Creates a 'functions' list of Function objects for
        each function defined on the interface.

        :Parameters:
          iface
            Dict representing the interface (from parsed IDL)
          contract
            Contract instance to associate the interface instance with
        """"""
        self.name = iface[""name""]
        self.functions = { }
        for f in iface[""functions""]:
            self.functions[f[""name""]] = Function(self.name, f, contract)

    def function(self, func_name):
        """"""
        Returns the Function instance associated with the given func_name, or raises a
        RpcException if no function matches.
        """"""
        if func_name in self.functions:
            return self.functions[func_name]
        else:
            raise RpcException(ERR_METHOD_NOT_FOUND, 
                               ""%s: Unknown function: '%s'"", self.name, func_name)","class Interface(object):
    '''
    Represents a Barrister IDL 'interface' entity.
    '''

    def __init__(self, iface, contract):
    '''
        Creates an Interface. Creates a 'functions' list of Function objects for
        each function defined on the interface.

        :Parameters:
          iface
            Dict representing the interface (from parsed IDL)
          contract
            Contract instance to associate the interface instance with
        '''
        pass

    def function(self, func_name):
    '''
        Returns the Function instance associated with the given func_name, or raises a
        RpcException if no function matches.
        '''
        pass

",3,3,snippet_556,0.3333333333333333,"class Interface(object):
    '''
    Represents a Barrister IDL 'interface' entity.
    '''

    def __init__(self, iface, contract):
        '''
        Creates an Interface. Creates a 'functions' list of Function objects for
        each function defined on the interface.

        :Parameters:
          iface
            Dict representing the interface (from parsed IDL)
          contract
            Contract instance to associate the interface instance with
        '''
        self.iface = iface
        self.contract = contract
        self.name = iface.get('name')
        self.functions = []
        self._func_map = {}
        for f in iface.get('functions', []):
            fn = Function(f, self)
            self.functions.append(fn)
            self._func_map[fn.name] = fn

    def function(self, func_name):
        '''
        Returns the Function instance associated with the given func_name, or raises a
        RpcException if no function matches.
        '''
        if func_name in self._func_map:
            return self._func_map[func_name]
        raise RpcException(""Unknown function '%s' in interface '%s'"" %
                           (func_name, self.name))","class Interface(object):
    '''
    Represents a Barrister IDL 'interface' entity.
    '''

    def __init__(self, iface, contract):
        '''
        Creates an Interface. Creates a 'functions' list of Function objects for
        each function defined on the interface.

        :Parameters:
          iface
            Dict representing the interface (from parsed IDL)
          contract
            Contract instance to associate the interface instance with
        '''
        self.iface = iface
        self.contract = contract
        self.functions = []
        
        # Create Function objects for each function in the interface
        for func_dict in iface.get('functions', []):
            from barrister import Function  # Assuming Function class is in barrister module
            func = Function(func_dict, self)
            self.functions.append(func)

    def function(self, func_name):
        '''
        Returns the Function instance associated with the given func_name, or raises a
        RpcException if no function matches.
        '''
        for func in self.functions:
            if func.func.get('name') == func_name:
                return func
        
        # If we get here, no function was found
        from barrister import RpcException  # Assuming RpcException is in barrister module
        raise RpcException(""Function '%s' not found"" % func_name)","class Interface(object):
    '''
    Represents a Barrister IDL 'interface' entity.
    '''

    def __init__(self, iface, contract):
        '''
        Creates an Interface. Creates a 'functions' list of Function objects for
        each function defined on the interface.

        :Parameters:
          iface
            Dict representing the interface (from parsed IDL)
          contract
            Contract instance to associate the interface instance with
        '''
        self.name = iface['name']
        self.contract = contract
        self.functions = []
        
        for func_dict in iface.get('functions', []):
            function_obj = Function(func_dict, self)
            self.functions.append(function_obj)

    def function(self, func_name):
        '''
        Returns the Function instance associated with the given func_name, or raises a
        RpcException if no function matches.
        '''
        for func in self.functions:
            if func.name == func_name:
                return func
        raise RpcException(""Function '%s' not found on interface '%s'"" % (func_name, self.name))",full_docstr,0.8685258964143426,0.7389558232931727,0.6396761133603238,0.8207171314741036,0.6154674467768618,0.7467811158798283,0.6163793103448276,0.5064935064935064,0.9390150308609009,0.9479321241378784,0.9434525370597839,0.9470327496528625,0.8561165467625899,0.7518248175182481,0.6102941176470589,0.525925925925926,0.6861313868613139,0.531955428560993,0.6722689075630253,0.5232067510548524,0.4279661016949153,0.8970967531204224,0.9389839172363281,0.9175625443458557,0.9346200227737427,0.8268751162790697,0.8925619834710744,0.7499999999999999,0.6470588235294118,0.8099173553719008,0.6204101443309211,0.8076923076923077,0.642512077294686,0.5242718446601942,0.9497894048690796,0.9529297351837158,0.9513570070266724,0.9526148438453674,0.8764380172413793,0.4808016394744226,0.5413034271682357,0.6253813915990202,0.4565217391304347,0.3,0.4551099752878518,0.4068609755631348,0.6092310995013158,0.3043478260869565,0.5,0.5514243934478918,0.5476863375399089,0.6116344246574554,0.4130434782608695,0.6333333333333333
228888,amatellanes/fixerio,amatellanes_fixerio/fixerio/client.py,fixerio.client.Fixerio,"class Fixerio(object):
    """""" A client for Fixer.io. """"""

    def __init__(self, access_key, symbols=None):
        """"""
        :param access_key: your API Key.
        :type access_key: str or unicode
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        """"""
        self.access_key = access_key
        self.symbols = symbols

    def _create_payload(self, symbols):
        """""" Creates a payload with no none values.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: a payload.
        :rtype: dict
        """"""
        payload = {'access_key': self.access_key}
        if symbols is not None:
            payload['symbols'] = ','.join(symbols)

        return payload

    def latest(self, symbols=None):
        """""" Get the latest foreign exchange reference rates.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the latest foreign exchange reference rates.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        """"""
        try:
            symbols = symbols or self.symbols
            payload = self._create_payload(symbols)

            url = BASE_URL + LATEST_PATH

            response = requests.get(url, params=payload)

            response.raise_for_status()

            return response.json()
        except requests.exceptions.RequestException as ex:
            raise FixerioException(str(ex))

    def historical_rates(self, date, symbols=None):
        """"""
        Get historical rates for any day since `date`.

        :param date: a date
        :type date: date or str
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the historical rates for any day since `date`.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        """"""
        try:
            if isinstance(date, datetime.date):
                # Convert date to ISO 8601 format.
                date = date.isoformat()

            symbols = symbols or self.symbols
            payload = self._create_payload(symbols)

            url = BASE_URL + date

            response = requests.get(url, params=payload)

            response.raise_for_status()

            return response.json()
        except requests.exceptions.RequestException as ex:
            raise FixerioException(str(ex))","class Fixerio(object):
    ''' A client for Fixer.io. '''

    def __init__(self, access_key, symbols=None):
    '''
        :param access_key: your API Key.
        :type access_key: str or unicode
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        '''
        pass

    def _create_payload(self, symbols):
    ''' Creates a payload with no none values.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: a payload.
        :rtype: dict
        '''
        pass

    def latest(self, symbols=None):
    ''' Get the latest foreign exchange reference rates.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the latest foreign exchange reference rates.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        pass

    def historical_rates(self, date, symbols=None):
    '''
        Get historical rates for any day since `date`.

        :param date: a date
        :type date: date or str
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the historical rates for any day since `date`.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        pass

",5,5,snippet_312,0.4666666666666667,"class Fixerio(object):
    ''' A client for Fixer.io. '''
    BASE_URL = 'http://data.fixer.io/api'

    def __init__(self, access_key, symbols=None):
        '''
        :param access_key: your API Key.
        :type access_key: str or unicode
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        '''
        self.access_key = access_key
        if symbols is not None and not isinstance(symbols, (list, tuple)):
            raise ValueError(""symbols must be a list or tuple"")
        self.symbols = symbols

    def _create_payload(self, symbols):
        ''' Creates a payload with no none values.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: a payload.
        :rtype: dict
        '''
        payload = {'access_key': self.access_key}
        syms = symbols if symbols is not None else self.symbols
        if syms is not None:
            if not isinstance(syms, (list, tuple)):
                raise ValueError(""symbols must be a list or tuple"")
            payload['symbols'] = ','.join(syms)
        return payload

    def latest(self, symbols=None):
        ''' Get the latest foreign exchange reference rates.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the latest foreign exchange reference rates.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        url = f""{self.BASE_URL}/latest""
        payload = self._create_payload(symbols)
        resp = requests.get(url, params=payload)
        try:
            data = resp.json()
        except ValueError:
            raise FixerioException(""Invalid JSON response"")
        if not data.get('success', False):
            err = data.get('error', {})
            msg = err.get('info', 'Unknown error')
            raise FixerioException(msg)
        return data

    def historical_rates(self, date, symbols=None):
        '''
        Get historical rates for any day since `date`.

        :param date: a date
        :type date: date or str
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the historical rates for any day since `date`.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        if isinstance(date, datetime.date):
            date_str = date.isoformat()
        elif isinstance(date, str):
            date_str = date
        else:
            raise ValueError(""date must be a datetime.date or str"")
        url = f""{self.BASE_URL}/{date_str}""
        payload = self._create_payload(symbols)
        resp = requests.get(url, params=payload)
        try:
            data = resp.json()
        except ValueError:
            raise FixerioException(""Invalid JSON response"")
        if not data.get('success', False):
            err = data.get('error', {})
            msg = err.get('info', 'Unknown error')
            raise FixerioException(msg)
        return data","class Fixerio(object):
    ''' A client for Fixer.io. '''

    def __init__(self, access_key, symbols=None):
        '''
        :param access_key: your API Key.
        :type access_key: str or unicode
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        '''
        self.access_key = access_key
        self.symbols = symbols
        self.base_url = 'http://data.fixer.io/api'

    def _create_payload(self, symbols):
        ''' Creates a payload with no none values.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: a payload.
        :rtype: dict
        '''
        payload = {'access_key': self.access_key}
        if symbols:
            payload['symbols'] = ','.join(symbols)
        elif self.symbols:
            payload['symbols'] = ','.join(self.symbols)
        return payload

    def latest(self, symbols=None):
        ''' Get the latest foreign exchange reference rates.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the latest foreign exchange reference rates.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        url = f'{self.base_url}/latest'
        payload = self._create_payload(symbols)
        
        try:
            response = requests.get(url, params=payload)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            raise FixerioException(f""Error making request: {e}"")
        except ValueError as e:
            raise FixerioException(f""Error parsing JSON response: {e}"")

    def historical_rates(self, date, symbols=None):
        '''
        Get historical rates for any day since `date`.

        :param date: a date
        :type date: date or str
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the historical rates for any day since `date`.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        if isinstance(date, date):
            date_str = date.strftime('%Y-%m-%d')
        else:
            date_str = str(date)
            
        url = f'{self.base_url}/{date_str}'
        payload = self._create_payload(symbols)
        
        try:
            response = requests.get(url, params=payload)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            raise FixerioException(f""Error making request: {e}"")
        except ValueError as e:
            raise FixerioException(f""Error parsing JSON response: {e}"")","class Fixerio(object):
    ''' A client for Fixer.io. '''

    def __init__(self, access_key, symbols=None):
        '''
        :param access_key: your API Key.
        :type access_key: str or unicode
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        '''
        self.access_key = access_key
        self.symbols = symbols
        self.base_url = 'http://data.fixer.io/api'

    def _create_payload(self, symbols):
        ''' Creates a payload with no none values.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: a payload.
        :rtype: dict
        '''
        payload = {'access_key': self.access_key}
        
        symbols_to_use = symbols or self.symbols
        if symbols_to_use:
            if isinstance(symbols_to_use, (list, tuple)):
                payload['symbols'] = ','.join(symbols_to_use)
            else:
                payload['symbols'] = symbols_to_use
                
        return payload

    def latest(self, symbols=None):
        ''' Get the latest foreign exchange reference rates.

        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the latest foreign exchange reference rates.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        url = f""{self.base_url}/latest""
        payload = self._create_payload(symbols)
        
        try:
            response = requests.get(url, params=payload)
            response.raise_for_status()
            data = response.json()
            
            if not data.get('success', True):
                raise FixerioException(data.get('error', {}).get('info', 'Unknown error'))
                
            return data
        except requests.RequestException as e:
            raise FixerioException(str(e))

    def historical_rates(self, date, symbols=None):
        '''
        Get historical rates for any day since `date`.

        :param date: a date
        :type date: date or str
        :param symbols: currency symbols to request specific exchange rates.
        :type symbols: list or tuple
        :return: the historical rates for any day since `date`.
        :rtype: dict
        :raises FixerioException: if any error making a request.
        '''
        if isinstance(date, date):
            date_str = date.strftime('%Y-%m-%d')
        else:
            date_str = str(date)
            
        url = f""{self.base_url}/{date_str}""
        payload = self._create_payload(symbols)
        
        try:
            response = requests.get(url, params=payload)
            response.raise_for_status()
            data = response.json()
            
            if not data.get('success', True):
                raise FixerioException(data.get('error', {}).get('info', 'Unknown error'))
                
            return data
        except requests.RequestException as e:
            raise FixerioException(str(e))",full_docstr,0.7873303167420814,0.6686838124054463,0.6100151745068285,0.7088989441930619,0.6069773577263449,0.7077625570776256,0.5929878048780488,0.5328244274809161,0.8939645290374756,0.9274108409881592,0.9103806018829346,0.9239540696144104,0.8264746973365618,0.8715447154471545,0.799347471451876,0.7430441898527006,0.8227642276422765,0.7111030432840437,0.787052810902896,0.6996587030716723,0.652991452991453,0.9234102368354797,0.9450436234474182,0.9341017007827759,0.9428347945213318,0.8829376785714286,0.8593996840442338,0.7448494453248811,0.6709062003179651,0.7930489731437599,0.6539062442038058,0.7321711568938193,0.6492063492063492,0.5882352941176471,0.9178885817527771,0.9504984617233276,0.9339089393615723,0.9471336007118225,0.8531966321243523,0.5360280462927641,0.5162016731689519,0.6689305606557407,0.6183206106870229,0.3406593406593406,0.7552227117124639,0.6625260829840448,0.70187621424749,0.6564885496183206,0.0,0.757096108891428,0.6200921257758978,0.675467882308898,0.732824427480916,0.0
267008,bjoernricks/python-quilt,bjoernricks_python-quilt/quilt/cli/parser.py,quilt.cli.parser.ArgumentGroup,"class ArgumentGroup(object):

    """"""
    A class to declare argument groups at a class

    Usage:
        class MyParser(Parser):
            cmd1 = OptionalArgument()
            cmd2 = OptionalArgument()

            group = ArgumentGroup(title=""group of possible commands"",
                                  argument_names=[""cmd1"", ""cmd2""])
    """"""

    creation_counter = 0

    def __init__(self, title=None, description=None, argument_names=None):
        """"""
        Constructs a ArgumentGroup instance

        @param title The title of the group displayed as headline
        @param description A detailed description of the argument group
        @param argument_names A list of strings containing the Arguments to be
                              grouped
        """"""
        self.title = title
        self.description = description
        self.argument_names = argument_names or []
        self.arguments = []
        self.creation_counter = ArgumentGroup.creation_counter
        ArgumentGroup.creation_counter += 1

    def add_to_parser(self, parser):
        """"""
        Adds the group and its arguments to a argparse.ArgumentParser instance

        @param parser A argparse.ArgumentParser instance
        """"""
        self.group = parser.add_argument_group(self.title, self.description)
        for arg in self.arguments:
            arg.add_to_parser(self.group)

    def set_name(self, name):
        """"""
        Sets the name of this group. Normally this method should not be called
        directly. It is used by the ArgumentsCollectorMetaClass.

        @param name A string for a name
        """"""
        self.name = name

    def add_argument(self, arg):
        """"""
        Adds a Argument to this group.
        Normally this method should not be called directly.
        It is used by the ArgumentsCollectorMetaClass.

        @parma arg An Argument instance to be added to this group.
        """"""
        self.arguments.append(arg)","class ArgumentGroup(object):
    '''
    A class to declare argument groups at a class

    Usage:
        class MyParser(Parser):
            cmd1 = OptionalArgument()
            cmd2 = OptionalArgument()

            group = ArgumentGroup(title=""group of possible commands"",
                                  argument_names=[""cmd1"", ""cmd2""])
    '''

    def __init__(self, title=None, description=None, argument_names=None):
    '''
        Constructs a ArgumentGroup instance

        @param title The title of the group displayed as headline
        @param description A detailed description of the argument group
        @param argument_names A list of strings containing the Arguments to be
                              grouped
        '''
        pass

    def add_to_parser(self, parser):
    '''
        Adds the group and its arguments to a argparse.ArgumentParser instance

        @param parser A argparse.ArgumentParser instance
        '''
        pass

    def set_name(self, name):
    '''
        Sets the name of this group. Normally this method should not be called
        directly. It is used by the ArgumentsCollectorMetaClass.

        @param name A string for a name
        '''
        pass

    def add_argument(self, arg):
    '''
        Adds a Argument to this group.
        Normally this method should not be called directly.
        It is used by the ArgumentsCollectorMetaClass.

        @parma arg An Argument instance to be added to this group.
        '''
        pass

",5,5,snippet_445,0.75,"class ArgumentGroup(object):
    '''
    A class to declare argument groups at a class

    Usage:
        class MyParser(Parser):
            cmd1 = OptionalArgument()
            cmd2 = OptionalArgument()

            group = ArgumentGroup(title=""group of possible commands"",
                                  argument_names=[""cmd1"", ""cmd2""])
    '''

    def __init__(self, title=None, description=None, argument_names=None):
        '''
        Constructs a ArgumentGroup instance

        @param title The title of the group displayed as headline
        @param description A detailed description of the argument group
        @param argument_names A list of strings containing the Arguments to be
                              grouped
        '''
        self.title = title
        self.description = description
        self.argument_names = list(argument_names) if argument_names is not None else []
        self.name = None
        self._arguments = []

    def add_to_parser(self, parser):
        '''
        Adds the group and its arguments to a argparse.ArgumentParser instance

        @param parser A argparse.ArgumentParser instance
        '''
        arg_group = parser.add_argument_group(self.title, self.description)
        # Add by name
        for arg_name in self.argument_names:
            if hasattr(parser, arg_name):
                arg = getattr(parser, arg_name)
                arg.add_to_parser(arg_group)
        # Add by direct argument instances
        for arg in self._arguments:
            arg.add_to_parser(arg_group)

    def set_name(self, name):
        '''
        Sets the name of this group. Normally this method should not be called
        directly. It is used by the ArgumentsCollectorMetaClass.

        @param name A string for a name
        '''
        self.name = name

    def add_argument(self, arg):
        '''
        Adds a Argument to this group.
        Normally this method should not be called directly.
        It is used by the ArgumentsCollectorMetaClass.

        @param arg An Argument instance to be added to this group.
        '''
        self._arguments.append(arg)","class ArgumentGroup(object):
    '''
    A class to declare argument groups at a class

    Usage:
        class MyParser(Parser):
            cmd1 = OptionalArgument()
            cmd2 = OptionalArgument()

            group = ArgumentGroup(title=""group of possible commands"",
                                  argument_names=[""cmd1"", ""cmd2""])
    '''

    def __init__(self, title=None, description=None, argument_names=None):
        '''
        Constructs a ArgumentGroup instance

        @param title The title of the group displayed as headline
        @param description A detailed description of the argument group
        @param argument_names A list of strings containing the Arguments to be
                              grouped
        '''
        self.title = title
        self.description = description
        self.argument_names = argument_names or []
        self.name = None
        self.arguments = []

    def add_to_parser(self, parser):
        '''
        Adds the group and its arguments to a argparse.ArgumentParser instance

        @param parser A argparse.ArgumentParser instance
        '''
        if self.argument_names:
            group = parser.add_argument_group(title=self.title, description=self.description)
            for arg in self.arguments:
                arg.add_to_parser(group)

    def set_name(self, name):
        '''
        Sets the name of this group. Normally this method should not be called
        directly. It is used by the ArgumentsCollectorMetaClass.

        @param name A string for a name
        '''
        self.name = name

    def add_argument(self, arg):
        '''
        Adds a Argument to this group.
        Normally this method should not be called directly.
        It is used by the ArgumentsCollectorMetaClass.

        @parma arg An Argument instance to be added to this group.
        '''
        self.arguments.append(arg)","class ArgumentGroup(object):
    '''
    A class to declare argument groups at a class

    Usage:
        class MyParser(Parser):
            cmd1 = OptionalArgument()
            cmd2 = OptionalArgument()

            group = ArgumentGroup(title=""group of possible commands"",
                                  argument_names=[""cmd1"", ""cmd2""])
    '''

    def __init__(self, title=None, description=None, argument_names=None):
        '''
        Constructs a ArgumentGroup instance

        @param title The title of the group displayed as headline
        @param description A detailed description of the argument group
        @param argument_names A list of strings containing the Arguments to be
                              grouped
        '''
        self.title = title
        self.description = description
        self.argument_names = argument_names or []
        self.name = None
        self.arguments = []

    def add_to_parser(self, parser):
        '''
        Adds the group and its arguments to a argparse.ArgumentParser instance

        @param parser A argparse.ArgumentParser instance
        '''
        group = parser.add_argument_group(title=self.title, description=self.description)
        for arg in self.arguments:
            arg.add_to_parser(group)

    def set_name(self, name):
        '''
        Sets the name of this group. Normally this method should not be called
        directly. It is used by the ArgumentsCollectorMetaClass.

        @param name A string for a name
        '''
        self.name = name

    def add_argument(self, arg):
        '''
        Adds a Argument to this group.
        Normally this method should not be called directly.
        It is used by the ArgumentsCollectorMetaClass.

        @parma arg An Argument instance to be added to this group.
        '''
        self.arguments.append(arg)",full_docstr,0.8776371308016877,0.8347457627118644,0.8,0.8691983122362869,0.7465751061835085,0.8123456790123457,0.7425742574257426,0.6898263027295285,0.9535309076309204,0.9609651565551758,0.9572335481643677,0.9602164030075073,0.8959547976878612,0.9545454545454546,0.9223744292237445,0.8853211009174312,0.9500000000000001,0.8135229456044945,0.9479768786127167,0.8898550724637682,0.8430232558139535,0.9878593683242798,0.9747276306152344,0.9812495708465576,0.9760249853134155,0.9411770588235294,0.9587155963302753,0.9308755760368664,0.8935185185185185,0.9541284403669725,0.8084278386093527,0.9587020648967551,0.9053254437869822,0.8605341246290801,0.9851169586181641,0.9699265360832214,0.9774627089500427,0.971424400806427,0.9520701960784314,0.597560975442124,0.6773463809477233,0.754294310457495,0.6567164179104478,0.3018867924528302,0.6256628735081526,0.7801375689228579,0.7867211906687501,0.6716417910447762,0.2641509433962264,0.6256256140038678,0.7799885309057187,0.7867211906687501,0.6716417910447762,0.2641509433962264
121590,Fantomas42/django-blog-zinnia,Fantomas42_django-blog-zinnia/zinnia/views/channels.py,zinnia.views.channels.BaseEntryChannel,"class BaseEntryChannel(object):
    """"""
    Mixin for displaying a custom selection of entries
    based on a search query, useful to build SEO/SMO pages
    aggregating entries on a thematic or for building a
    custom homepage.
    """"""
    query = ''

    def get_queryset(self):
        """"""
        Override the get_queryset method to build
        the queryset with entry matching query.
        """"""
        return Entry.published.search(self.query)

    def get_context_data(self, **kwargs):
        """"""
        Add query in context.
        """"""
        context = super(BaseEntryChannel, self).get_context_data(**kwargs)
        context.update({'query': self.query})
        return context","class BaseEntryChannel(object):
    '''
    Mixin for displaying a custom selection of entries
    based on a search query, useful to build SEO/SMO pages
    aggregating entries on a thematic or for building a
    custom homepage.
    '''

    def get_queryset(self):
    '''
        Override the get_queryset method to build
        the queryset with entry matching query.
        '''
        pass

    def get_context_data(self, **kwargs):
    '''
        Add query in context.
        '''
        pass

",3,3,snippet_126,1.0,"class BaseEntryChannel(object):
    '''
    Mixin for displaying a custom selection of entries
    based on a search query, useful to build SEO/SMO pages
    aggregating entries on a thematic or for building a
    custom homepage.
    '''

    def get_queryset(self):
        '''
        Override the get_queryset method to build
        the queryset with entry matching query.
        '''
        queryset = super().get_queryset()
        query = self.request.GET.get('q', '').strip()
        if query:
            queryset = queryset.filter(
                Q(title__icontains=query) |
                Q(content__icontains=query) |
                Q(body__icontains=query)
            )
        return queryset

    def get_context_data(self, **kwargs):
        '''
        Add query in context.
        '''
        context = super().get_context_data(**kwargs)
        context['query'] = self.request.GET.get('q', '').strip()
        return context","class BaseEntryChannel(object):
    '''
    Mixin for displaying a custom selection of entries
    based on a search query, useful to build SEO/SMO pages
    aggregating entries on a thematic or for building a
    custom homepage.
    '''

    def get_queryset(self):
        '''
        Override the get_queryset method to build
        the queryset with entry matching query.
        '''
        queryset = super(BaseEntryChannel, self).get_queryset()
        query = getattr(self, 'query', None)
        if query:
            queryset = queryset.filter(query)
        return queryset

    def get_context_data(self, **kwargs):
        '''
        Add query in context.
        '''
        context = super(BaseEntryChannel, self).get_context_data(**kwargs)
        context['query'] = getattr(self, 'query', None)
        return context","class BaseEntryChannel(object):
    '''
    Mixin for displaying a custom selection of entries
    based on a search query, useful to build SEO/SMO pages
    aggregating entries on a thematic or for building a
    custom homepage.
    '''

    def get_queryset(self):
        '''
        Override the get_queryset method to build
        the queryset with entry matching query.
        '''
        queryset = super(BaseEntryChannel, self).get_queryset()
        query = getattr(self, 'query', None)
        if query:
            queryset = queryset.filter(query)
        return queryset

    def get_context_data(self, **kwargs):
        '''
        Add query in context.
        '''
        context = super(BaseEntryChannel, self).get_context_data(**kwargs)
        context['query'] = getattr(self, 'query', None)
        return context",full_docstr,0.8085106382978724,0.7096774193548386,0.641304347826087,0.7765957446808511,0.5078005425923527,0.6142131979695431,0.49489795918367346,0.4307692307692308,0.8742415308952332,0.9405801892280579,0.9061983823776245,0.9334966540336609,0.8014204255319148,0.8813559322033899,0.8,0.7283236994219653,0.8587570621468926,0.6451504949354209,0.7484276729559748,0.6329113924050633,0.5668789808917197,0.9433724880218506,0.9641051292419434,0.9536261558532715,0.9619909524917603,0.8301299038461537,0.8813559322033899,0.8,0.7283236994219653,0.8587570621468926,0.6451504949354209,0.7484276729559748,0.6329113924050633,0.5668789808917197,0.9433724880218506,0.9641051292419434,0.9536261558532715,0.9619909524917603,0.8301299038461537,0.5368226503921457,0.528352378732826,0.6616124760363257,0.3783783783783784,0.5789473684210527,0.5778945739435739,0.5616169637370089,0.6845274771297475,0.4864864864864865,0.5789473684210527,0.5778945739435739,0.5616169637370089,0.6845274771297475,0.4864864864864865,0.5789473684210527
284950,cemsbr/yala,cemsbr_yala/yala/base.py,yala.base.LinterOutput,"class LinterOutput:
    """"""A one-line linter result. It can be sorted and printed as string.""""""

    # We only override magic methods.

    def __init__(self, linter_name, path, msg, line_nr=None, col=None):
        """"""Optionally set all attributes.

        Args:
            path (str): Relative file path.
            line (int): Line number.
            msg (str): Explanation of what is wrong.
            col (int): Column where the problem begins.

        """"""
        # Set all attributes in the constructor for convenience.
        # pylint: disable=too-many-arguments
        if line_nr:
            line_nr = int(line_nr)
        if col:
            col = int(col)
        self._linter_name = linter_name
        self.path = path
        self.line_nr = line_nr
        self.msg = msg
        self.col = col

    def __str__(self):
        """"""Output shown to the user.""""""
        return (
            f""{self.path}|{self.line_nr}:{self.col}|{self.msg} ""
            f""[{self._linter_name}]""
        )

    def _cmp_key(self, obj=None):
        """"""Comparison key for sorting results from all linters.

        The sort should group files and lines from different linters to make it
        easier for refactoring.
        """"""
        if not obj:
            obj = self
        line_nr = int(obj.line_nr) if obj.line_nr else 0
        col = int(obj.col) if obj.col else 0
        return (obj.path, line_nr, col, obj.msg)

    def __lt__(self, other):
        """"""Use ``_cmp_key`` to compare two lines.""""""
        if isinstance(other, type(self)):
            return self._cmp_key() < self._cmp_key(other)
        return super().__lt__(other)","class LinterOutput:
    '''A one-line linter result. It can be sorted and printed as string.'''

    def __init__(self, linter_name, path, msg, line_nr=None, col=None):
    '''Optionally set all attributes.

        Args:
            path (str): Relative file path.
            line (int): Line number.
            msg (str): Explanation of what is wrong.
            col (int): Column where the problem begins.

        '''
        pass

    def __str__(self):
    '''Output shown to the user.'''
        pass

    def _cmp_key(self, obj=None):
    '''Comparison key for sorting results from all linters.

        The sort should group files and lines from different linters to make it
        easier for refactoring.
        '''
        pass

    def __lt__(self, other):
    '''Use ``_cmp_key`` to compare two lines.'''
        pass

",5,5,snippet_483,1.0,"class LinterOutput:
    '''A one-line linter result. It can be sorted and printed as string.'''

    def __init__(self, linter_name, path, msg, line_nr=None, col=None):
        '''Optionally set all attributes.

        Args:
            path (str): Relative file path.
            line (int): Line number.
            msg (str): Explanation of what is wrong.
            col (int): Column where the problem begins.
        '''
        self.linter_name = linter_name
        self.path = path
        self.msg = msg
        self.line_nr = line_nr
        self.col = col

    def __str__(self):
        '''Output shown to the user.'''
        parts = [self.path]
        if self.line_nr is not None:
            parts.append(str(self.line_nr))
            if self.col is not None:
                parts.append(str(self.col))
        location = "":"".join(parts)
        return f""{location}: [{self.linter_name}] {self.msg}""

    def _cmp_key(self, obj=None):
        '''Comparison key for sorting results from all linters.

        The sort should group files and lines from different linters to make it
        easier for refactoring.
        '''
        if obj is not None:
            return obj._cmp_key()
        return (
            self.path,
            self.line_nr if self.line_nr is not None else -1,
            self.col if self.col is not None else -1,
            self.linter_name,
            self.msg,
        )

    def __lt__(self, other):
        '''Use ``_cmp_key`` to compare two lines.'''
        return self._cmp_key() < other._cmp_key()","class LinterOutput:
    '''A one-line linter result. It can be sorted and printed as string.'''

    def __init__(self, linter_name, path, msg, line_nr=None, col=None):
        '''Optionally set all attributes.

        Args:
            path (str): Relative file path.
            line (int): Line number.
            msg (str): Explanation of what is wrong.
            col (int): Column where the problem begins.

        '''
        self.linter_name = linter_name
        self.path = path
        self.msg = msg
        self.line_nr = line_nr
        self.col = col

    def __str__(self):
        '''Output shown to the user.'''
        parts = [self.path]
        if self.line_nr is not None:
            parts.append(str(self.line_nr))
            if self.col is not None:
                parts.append(str(self.col))
        parts.append(self.msg)
        return ':'.join(parts)

    def _cmp_key(self, obj=None):
        '''Comparison key for sorting results from all linters.

        The sort should group files and lines from different linters to make it
        easier for refactoring.
        '''
        if obj is None:
            return (self.path or '', self.line_nr or 0, self.col or 0, self.linter_name or '')
        else:
            return (
                (self.path or '', self.line_nr or 0, self.col or 0, self.linter_name or ''),
                (obj.path or '', obj.line_nr or 0, obj.col or 0, obj.linter_name or '')
            )

    def __lt__(self, other):
        '''Use ``_cmp_key`` to compare two lines.'''
        self_key, other_key = self._cmp_key(other)
        return self_key < other_key","class LinterOutput:
    '''A one-line linter result. It can be sorted and printed as string.'''

    def __init__(self, linter_name, path, msg, line_nr=None, col=None):
        '''Optionally set all attributes.

        Args:
            path (str): Relative file path.
            line (int): Line number.
            msg (str): Explanation of what is wrong.
            col (int): Column where the problem begins.

        '''
        self.linter_name = linter_name
        self.path = path
        self.msg = msg
        self.line_nr = line_nr
        self.col = col

    def __str__(self):
        '''Output shown to the user.'''
        result = f""{self.linter_name}: {self.path}""
        if self.line_nr is not None:
            result += f"":{self.line_nr}""
            if self.col is not None:
                result += f"":{self.col}""
        result += f"": {self.msg}""
        return result

    def _cmp_key(self, obj=None):
        '''Comparison key for sorting results from all linters.

        The sort should group files and lines from different linters to make it
        easier for refactoring.
        '''
        return (self.path, self.line_nr or 0, self.col or 0, self.linter_name)

    def __lt__(self, other):
        '''Use ``_cmp_key`` to compare two lines.'''
        return self._cmp_key() < other._cmp_key()",full_docstr,0.7962529274004685,0.6729411764705882,0.5815602836879432,0.7166276346604215,0.6010009772686556,0.8548387096774194,0.6873315363881402,0.581081081081081,0.928520679473877,0.9163097143173218,0.9223747849464417,0.9175164103507996,0.811405394736842,0.7820224719101124,0.6410835214446953,0.5487528344671202,0.6876404494382022,0.5948495790446351,0.7930174563591023,0.6175,0.5263157894736842,0.9204740524291992,0.909615695476532,0.9150126576423645,0.9106899499893188,0.78646046875,0.805,0.693467336683417,0.6161616161616161,0.715,0.574240925420347,0.9033232628398792,0.7606060606060606,0.6656534954407295,0.933265209197998,0.9001719951629639,0.9164199233055115,0.9033752679824829,0.8289490789473684,0.5067251781631905,0.4671900952539763,0.4834276770381757,0.5048543689320388,0.5714285714285714,0.4906399884172493,0.4555503279701302,0.4701164218153718,0.4368932038834951,0.6,0.4352017739111057,0.4484056385721806,0.4606400146311879,0.4174757281553398,0.4142857142857143
206171,Unidata/MetPy,Unidata_MetPy/src/metpy/io/_tools.py,metpy.io._tools.Array,"class Array:
    """"""Use a Struct as a callable to unpack a bunch of bytes as a list.""""""

    def __init__(self, fmt):
        """"""Initialize the Struct unpacker.""""""
        self._struct = Struct(fmt)

    def __call__(self, buf):
        """"""Perform the actual unpacking.""""""
        return list(self._struct.unpack(buf))","class Array:
    '''Use a Struct as a callable to unpack a bunch of bytes as a list.'''

    def __init__(self, fmt):
    '''Initialize the Struct unpacker.'''
        pass

    def __call__(self, buf):
    '''Perform the actual unpacking.'''
        pass

",3,3,snippet_274,0.75,"class Array:
    """"""Use a Struct as a callable to unpack a bunch of bytes as a list.""""""

    def __init__(self, fmt):
        """"""Initialize the Struct unpacker.""""""
        self.struct = struct.Struct(fmt)
        self.size = self.struct.size

    def __call__(self, buf):
        """"""Perform the actual unpacking.""""""
        length = len(buf)
        if length % self.size:
            raise ValueError(""Buffer length must be a multiple of struct size"")
        count = length // self.size
        return [self.struct.unpack_from(buf, i * self.size) for i in range(count)]","class Array:
    '''Use a Struct as a callable to unpack a bunch of bytes as a list.'''

    def __init__(self, fmt):
        '''Initialize the Struct unpacker.'''
        self.fmt = fmt
        self.struct = struct.Struct(fmt)

    def __call__(self, buf):
        '''Perform the actual unpacking.'''
        return list(self.struct.unpack(buf))","class Array:
    '''Use a Struct as a callable to unpack a bunch of bytes as a list.'''

    def __init__(self, fmt):
        '''Initialize the Struct unpacker.'''
        self.struct = struct.Struct(fmt)

    def __call__(self, buf):
        '''Perform the actual unpacking.'''
        return list(self.struct.unpack(buf))",full_docstr,0.6885245901639344,0.6166666666666666,0.576271186440678,0.6885245901639344,0.5395075582184503,0.6013071895424836,0.5328947368421053,0.4900662251655629,0.8456548452377319,0.9654203653335571,0.9015775918960571,0.9519386291503906,0.8187720388349514,0.9555555555555556,0.9545454545454545,0.9302325581395349,0.9555555555555556,0.645660780286522,0.8452380952380952,0.7349397590361446,0.6219512195121951,0.9816700220108032,0.9882194995880127,0.9849339127540588,0.9875606298446655,0.955556,0.9885057471264368,0.988235294117647,0.9879518072289156,0.9885057471264368,0.6394360894097872,0.8987341772151899,0.782051282051282,0.6623376623376623,0.9896118640899658,0.9928267598152161,0.9912167191505432,0.9925042986869812,0.9876544444444444,0.5592191302916267,0.4263769079055106,0.8295472323086156,0.3809523809523809,0.6,0.5071563676737357,0.428723285492463,0.4808545661548608,0.6190476190476191,0.5,0.5414858508616467,0.466041218244107,0.4808545661548608,0.6190476190476191,0.6
175475,Qiskit/qiskit-terra,Qiskit_qiskit-terra/qiskit/transpiler/passes/optimization/template_matching/backward_match.py,qiskit.transpiler.passes.optimization.template_matching.backward_match.MatchingScenariosList,"class MatchingScenariosList:
    """"""
    Object to define a list of MatchingScenarios, with method to append
    and pop elements.
    """"""

    def __init__(self):
        """"""
        Create an empty MatchingScenariosList.
        """"""
        self.matching_scenarios_list = []

    def append_scenario(self, matching):
        """"""
        Append a scenario to the list.
        Args:
            matching (MatchingScenarios): a scenario of match.
        """"""
        self.matching_scenarios_list.append(matching)

    def pop_scenario(self):
        """"""
        Pop the first scenario of the list.
        Returns:
            MatchingScenarios: a scenario of match.
        """"""
        # Pop the first MatchingScenario and returns it
        first = self.matching_scenarios_list[0]
        self.matching_scenarios_list.pop(0)
        return first","class MatchingScenariosList:
    '''
    Object to define a list of MatchingScenarios, with method to append
    and pop elements.
    '''

    def __init__(self):
    '''
        Create an empty MatchingScenariosList.
        '''
        pass

    def append_scenario(self, matching):
    '''
        Append a scenario to the list.
        Args:
            matching (MatchingScenarios): a scenario of match.
        '''
        pass

    def pop_scenario(self):
    '''
        Pop the first scenario of the list.
        Returns:
            MatchingScenarios: a scenario of match.
        '''
        pass

",4,4,snippet_235,1.0,"class MatchingScenariosList:
    '''
    Object to define a list of MatchingScenarios, with method to append
    and pop elements.
    '''

    def __init__(self):
        '''
        Create an empty MatchingScenariosList.
        '''
        self._scenarios = []

    def append_scenario(self, matching):
        '''
        Append a scenario to the list.
        Args:
            matching (MatchingScenarios): a scenario of match.
        '''
        self._scenarios.append(matching)

    def pop_scenario(self):
        '''
        Pop the first scenario of the list.
        Returns:
            MatchingScenarios: a scenario of match.
        '''
        return self._scenarios.pop(0)","class MatchingScenariosList:
    '''
    Object to define a list of MatchingScenarios, with method to append
    and pop elements.
    '''

    def __init__(self):
        '''
        Create an empty MatchingScenariosList.
        '''
        self.scenarios = []

    def append_scenario(self, matching):
        '''
        Append a scenario to the list.
        Args:
            matching (MatchingScenarios): a scenario of match.
        '''
        self.scenarios.append(matching)

    def pop_scenario(self):
        '''
        Pop the first scenario of the list.
        Returns:
            MatchingScenarios: a scenario of match.
        '''
        if self.scenarios:
            return self.scenarios.pop(0)
        else:
            raise IndexError(""pop from empty MatchingScenariosList"")","class MatchingScenariosList:
    '''
    Object to define a list of MatchingScenarios, with method to append
    and pop elements.
    '''

    def __init__(self):
        '''
        Create an empty MatchingScenariosList.
        '''
        self.scenarios = []

    def append_scenario(self, matching):
        '''
        Append a scenario to the list.
        Args:
            matching (MatchingScenarios): a scenario of match.
        '''
        self.scenarios.append(matching)

    def pop_scenario(self):
        '''
        Pop the first scenario of the list.
        Returns:
            MatchingScenarios: a scenario of match.
        '''
        return self.scenarios.pop(0)",full_docstr,0.8734177215189874,0.7692307692307693,0.7272727272727273,0.8607594936708861,0.5539071328902907,0.9349593495934959,0.8114754098360656,0.6942148760330579,0.9864839315414429,0.9581769704818726,0.972124457359314,0.9609344005584717,0.9466671999999999,0.8571428571428571,0.7228915662650602,0.6829268292682927,0.8333333333333333,0.5719537903694467,0.8540145985401459,0.7132352941176471,0.6222222222222222,0.9599632024765015,0.9596664905548096,0.9598147869110107,0.9596962332725525,0.9240513924050634,0.8734177215189874,0.7692307692307693,0.7272727272727273,0.8607594936708861,0.5381363177847072,0.9333333333333333,0.8067226890756303,0.711864406779661,0.9863107800483704,0.9581239223480225,0.9720131158828735,0.9608698487281799,0.9466671999999999,0.6156990384880995,0.5517536930753559,0.5669564393716661,0.6774193548387096,0.6666666666666666,0.6504891756165037,0.557580908255639,0.5669564393716661,0.6774193548387096,0.8,0.6156990384880995,0.5517536930753559,0.5669564393716661,0.6774193548387096,0.6666666666666666
214987,adamnovak/tsv,adamnovak_tsv/tsv.py,tsv.TsvReader,"class TsvReader(object):
    """"""
    Represents a reader for tab-separated value files. Skips over comments 
    starting with #. Can be iterated over.
    
    Field values consisting of only whitespace are not allowed.
    """"""
    
    def __init__(self, stream):
        """"""
        Make a new TsvReader to read from the given stream.
        """"""
        
        self.stream = stream
        
    def __iter__(self):
        """"""
        Yields lists of all fields on each line, as strings, until all lines are
        exhausted. Strips whitespace around field contents. 
        """"""
        
        for line in self.stream:
            line = line.strip()
            if line == """" or line[0] == ""#"":
                # Skip comments and empty lines
                continue
            
            yield map(str.strip, line.split(""\t""))
            
    def close(self):
        """"""
        Close the underlying stream.
        """"""
        
        self.stream.close()","class TsvReader(object):
    '''
    Represents a reader for tab-separated value files. Skips over comments 
    starting with #. Can be iterated over.
    
    Field values consisting of only whitespace are not allowed.
    '''

    def __init__(self, stream):
    '''
        Make a new TsvReader to read from the given stream.
        '''
        pass

    def __iter__(self):
    '''
        Yields lists of all fields on each line, as strings, until all lines are
        exhausted. Strips whitespace around field contents. 
        '''
        pass

    def close(self):
    '''
        Close the underlying stream.
        '''
        pass

",4,4,snippet_295,1.0,"class TsvReader(object):
    '''
    Represents a reader for tab-separated value files. Skips over comments 
    starting with #. Can be iterated over.

    Field values consisting of only whitespace are not allowed.
    '''

    def __init__(self, stream):
        '''
            Make a new TsvReader to read from the given stream.
        '''
        self.stream = stream

    def __iter__(self):
        '''
            Yields lists of all fields on each line, as strings, until all lines are
            exhausted. Strips whitespace around field contents. 
        '''
        for line in self.stream:
            if line.startswith('#'):
                continue
            line = line.rstrip('\n')
            fields = line.split('\t')
            stripped_fields = []
            for f in fields:
                s = f.strip()
                if s == '':
                    raise ValueError(""Field value consists only of whitespace or is empty"")
                stripped_fields.append(s)
            yield stripped_fields

    def close(self):
        '''
            Close the underlying stream.
        '''
        self.stream.close()","class TsvReader(object):
    '''
    Represents a reader for tab-separated value files. Skips over comments 
    starting with #. Can be iterated over.
    
    Field values consisting of only whitespace are not allowed.
    '''

    def __init__(self, stream):
        '''
        Make a new TsvReader to read from the given stream.
        '''
        self.stream = stream

    def __iter__(self):
        '''
        Yields lists of all fields on each line, as strings, until all lines are
        exhausted. Strips whitespace around field contents. 
        '''
        for line in self.stream:
            # Skip comments and empty lines
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            # Split by tab and strip whitespace from each field
            fields = [field.strip() for field in line.split('\t')]
            
            # Check if any field consists of only whitespace
            if any(field == '' for field in fields):
                raise ValueError(""Field values consisting of only whitespace are not allowed"")
            
            yield fields

    def close(self):
        '''
        Close the underlying stream.
        '''
        self.stream.close()","class TsvReader(object):
    '''
    Represents a reader for tab-separated value files. Skips over comments 
    starting with #. Can be iterated over.
    
    Field values consisting of only whitespace are not allowed.
    '''

    def __init__(self, stream):
        '''
        Make a new TsvReader to read from the given stream.
        '''
        self.stream = stream

    def __iter__(self):
        '''
        Yields lists of all fields on each line, as strings, until all lines are
        exhausted. Strips whitespace around field contents. 
        '''
        for line in self.stream:
            line = line.rstrip('\n\r')
            if line.startswith('#') or not line.strip():
                continue
            fields = []
            for field in line.split('\t'):
                stripped_field = field.strip()
                if not stripped_field:
                    raise ValueError(""Field values consisting of only whitespace are not allowed"")
                fields.append(stripped_field)
            yield fields

    def close(self):
        '''
        Close the underlying stream.
        '''
        self.stream.close()",full_docstr,0.8347826086956521,0.7631578947368421,0.7168141592920354,0.7913043478260869,0.6121287388621786,0.7289719626168224,0.6009389671361502,0.5235849056603774,0.9181594848632812,0.9579211473464966,0.9376189708709717,0.9537907242774963,0.8510653191489361,0.8160000000000001,0.7500000000000001,0.7073170731707318,0.768,0.6025436313385805,0.7105263157894737,0.5947136563876652,0.5176991150442478,0.9115435481071472,0.9671861529350281,0.9385408163070679,0.9613181352615356,0.8922316541353383,0.8290598290598291,0.7672413793103448,0.7217391304347827,0.8034188034188035,0.6082513619920804,0.7110091743119266,0.5944700460829493,0.5324074074074074,0.9201046228408813,0.9581415057182312,0.9387379288673401,0.9541968107223511,0.8615037323943662,0.6467573446292101,0.5365345529170357,0.6238643908171961,0.6875,0.7391304347826086,0.702777265786855,0.4858398026012979,0.6812475214156875,0.6875,0.9565217391304348,0.6649223096914713,0.5513019855873053,0.6364669633235072,0.6458333333333334,0.8260869565217391
384359,fermiPy/fermipy,fermiPy_fermipy/fermipy/diffuse/model_component.py,fermipy.diffuse.model_component.GalpropMergedRingInfo,"class GalpropMergedRingInfo(object):
    """"""Information about a set of Merged Galprop Rings

    Parameters
    ----------

    source_name : str
        The name given to the merged component, e.g., merged_CO or merged_HI
    ring : int
        The index of the merged ring
    sourcekey : str
        Key that identifies this component, e.g., merged_CO_1, or merged_HI_3
    galkey : str
        Key that identifies how to merge the galprop rings, e.g., 'ref'
    galprop_run : str
        Key that idenfifies the galprop run used to make the input rings
    files : str
        List of files of the input gasmap files
    merged_gasmap : str
        Filename for the merged gasmap
    """"""

    def __init__(self, **kwargs):
        """"""C'tor: copies keyword arguments to data members
        """"""
        self.source_name = kwargs.get('source_name')
        self.ring = kwargs.get('ring')
        self.sourcekey = kwargs.get(
            'sourcekey', ""%s_%i"" % (self.source_name, self.ring))
        self.galkey = kwargs.get('galkey', None)
        self.galprop_run = kwargs.get('galprop_run', None)
        self.files = kwargs.get('files', [])
        self.merged_gasmap = kwargs.get('merged_gasmap', None)

    def update(self, **kwargs):
        """"""Update data members from keyword arguments
        """"""
        self.__dict__.update(**kwargs)","class GalpropMergedRingInfo(object):
    '''Information about a set of Merged Galprop Rings

    Parameters
    ----------

    source_name : str
        The name given to the merged component, e.g., merged_CO or merged_HI
    ring : int
        The index of the merged ring
    sourcekey : str
        Key that identifies this component, e.g., merged_CO_1, or merged_HI_3
    galkey : str
        Key that identifies how to merge the galprop rings, e.g., 'ref'
    galprop_run : str
        Key that idenfifies the galprop run used to make the input rings
    files : str
        List of files of the input gasmap files
    merged_gasmap : str
        Filename for the merged gasmap
    '''

    def __init__(self, **kwargs):
    '''C'tor: copies keyword arguments to data members
        '''
        pass

    def update(self, **kwargs):
    '''Update data members from keyword arguments
        '''
        pass

",3,3,snippet_645,0.75,"class GalpropMergedRingInfo(object):
    '''Information about a set of Merged Galprop Rings

    Parameters
    ----------

    source_name : str
        The name given to the merged component, e.g., merged_CO or merged_HI
    ring : int
        The index of the merged ring
    sourcekey : str
        Key that identifies this component, e.g., merged_CO_1, or merged_HI_3
    galkey : str
        Key that identifies how to merge the galprop rings, e.g., 'ref'
    galprop_run : str
        Key that idenfifies the galprop run used to make the input rings
    files : str
        List of files of the input gasmap files
    merged_gasmap : str
        Filename for the merged gasmap
    '''

    def __init__(self, **kwargs):
        '''C'tor: copies keyword arguments to data members'''
        self.update(**kwargs)

    def update(self, **kwargs):
        '''Update data members from keyword arguments'''
        for key, value in kwargs.items():
            setattr(self, key, value)","class GalpropMergedRingInfo(object):
    '''Information about a set of Merged Galprop Rings

    Parameters
    ----------

    source_name : str
        The name given to the merged component, e.g., merged_CO or merged_HI
    ring : int
        The index of the merged ring
    sourcekey : str
        Key that identifies this component, e.g., merged_CO_1, or merged_HI_3
    galkey : str
        Key that identifies how to merge the galprop rings, e.g., 'ref'
    galprop_run : str
        Key that idenfifies the galprop run used to make the input rings
    files : str
        List of files of the input gasmap files
    merged_gasmap : str
        Filename for the merged gasmap
    '''

    def __init__(self, **kwargs):
        '''C'tor: copies keyword arguments to data members
        '''
        self.source_name = kwargs.get('source_name')
        self.ring = kwargs.get('ring')
        self.sourcekey = kwargs.get('sourcekey')
        self.galkey = kwargs.get('galkey')
        self.galprop_run = kwargs.get('galprop_run')
        self.files = kwargs.get('files')
        self.merged_gasmap = kwargs.get('merged_gasmap')

    def update(self, **kwargs):
        '''Update data members from keyword arguments
        '''
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)","class GalpropMergedRingInfo(object):
    '''Information about a set of Merged Galprop Rings

    Parameters
    ----------

    source_name : str
        The name given to the merged component, e.g., merged_CO or merged_HI
    ring : int
        The index of the merged ring
    sourcekey : str
        Key that identifies this component, e.g., merged_CO_1, or merged_HI_3
    galkey : str
        Key that identifies how to merge the galprop rings, e.g., 'ref'
    galprop_run : str
        Key that idenfifies the galprop run used to make the input rings
    files : str
        List of files of the input gasmap files
    merged_gasmap : str
        Filename for the merged gasmap
    '''

    def __init__(self, **kwargs):
        '''C'tor: copies keyword arguments to data members
        '''
        for key, value in kwargs.items():
            setattr(self, key, value)

    def update(self, **kwargs):
        '''Update data members from keyword arguments
        '''
        for key, value in kwargs.items():
            setattr(self, key, value)",full_docstr,0.8141025641025641,0.7870967741935485,0.7727272727272727,0.8012820512820513,0.4851108104256319,0.925,0.8592964824120602,0.8131313131313131,0.9592759013175964,0.9206092357635498,0.9395449161529541,0.9243350625038147,0.7589122641509437,0.9378531073446328,0.8977272727272727,0.8742857142857143,0.9265536723163841,0.7725238616017984,0.926056338028169,0.8515901060070671,0.8120567375886525,0.9687275290489197,0.9753285646438599,0.9720168709754944,0.9746643304824829,0.9224326415094339,0.7899686520376176,0.7570977917981072,0.7492063492063492,0.7836990595611286,0.4981110109442173,0.8873239436619719,0.7877358490566038,0.7488151658767772,0.948889970779419,0.9239695072174072,0.936263918876648,0.9264024496078491,0.7693943396226417,0.4835616638674508,0.6730244242300396,0.6924551079520924,0.3287671232876712,0.24,0.6747652321427987,0.7542095154793722,0.7643034678863431,0.5205479452054794,0.66,0.480088739513459,0.6933111677655632,0.7056739272745745,0.3013698630136986,0.22
292810,citronneur/rdpy,citronneur_rdpy/rdpy/protocol/rdp/tpkt.py,rdpy.protocol.rdp.tpkt.IFastPathSender,"class IFastPathSender(object):
    """"""
    @summary: Fast path send capability
    """"""
    def sendFastPath(self, secFlag, fastPathS):
        """"""
        @summary: Send fastPathS Type as fast path packet
        @param secFlag: {integer} Security flag for fastpath packet
        @param fastPathS: {Type | Tuple} type transform to stream and send as fastpath
        """"""
        raise CallPureVirtualFuntion(""%s:%s defined by interface %s""%(self.__class__, ""sendFastPath"", ""IFastPathSender""))
    
    def initFastPath(self, fastPathListener):
        """"""
        @summary: initialize stack
        @param fastPathListener: {IFastPathListener}
        """"""
        self.setFastPathListener(fastPathListener)
        fastPathListener.setFastPathSender(self)
        
    def setFastPathListener(self, fastPathListener):
        """"""
        @param fastPathListener: {IFastPathListener}
        """"""
        raise CallPureVirtualFuntion(""%s:%s defined by interface %s""%(self.__class__, ""setFastPathListener"", ""IFastPathSender""))","class IFastPathSender(object):
    '''
    @summary: Fast path send capability
    '''

    def sendFastPath(self, secFlag, fastPathS):
    '''
        @summary: Send fastPathS Type as fast path packet
        @param secFlag: {integer} Security flag for fastpath packet
        @param fastPathS: {Type | Tuple} type transform to stream and send as fastpath
        '''
        pass

    def initFastPath(self, fastPathListener):
    '''
        @summary: initialize stack
        @param fastPathListener: {IFastPathListener}
        '''
        pass

    def setFastPathListener(self, fastPathListener):
    '''
        @param fastPathListener: {IFastPathListener}
        '''
        pass

",4,4,snippet_503,1.0,"class IFastPathSender(object):
    '''
    @summary: Fast path send capability
    '''

    def __init__(self):
        self._fastPathListener = None
        self._initialized = False

    def initFastPath(self, fastPathListener):
        '''
        @summary: initialize stack
        @param fastPathListener: {IFastPathListener}
        '''
        self.setFastPathListener(fastPathListener)
        self._initialized = True

    def setFastPathListener(self, fastPathListener):
        '''
        @param fastPathListener: {IFastPathListener}
        '''
        if not hasattr(fastPathListener, 'onFastPathData'):
            raise ValueError(""Listener must implement onFastPathData(secFlag, data_bytes)"")
        self._fastPathListener = fastPathListener

    def sendFastPath(self, secFlag, fastPathS):
        '''
        @summary: Send fastPathS Type as fast path packet
        @param secFlag: {integer} Security flag for fastpath packet
        @param fastPathS: {Type | Tuple} type transform to stream and send as fastpath
        '''
        if not self._initialized or self._fastPathListener is None:
            raise RuntimeError(""FastPathSender not initialized with a listener"")

        # convert fastPathS to bytes
        if isinstance(fastPathS, bytes):
            payload = fastPathS
        elif isinstance(fastPathS, str):
            payload = fastPathS.encode('utf-8')
        elif isinstance(fastPathS, tuple):
            parts = []
            for item in fastPathS:
                if isinstance(item, bytes):
                    parts.append(item)
                elif isinstance(item, str):
                    parts.append(item.encode('utf-8'))
                else:
                    parts.append(str(item).encode('utf-8'))
            payload = b''.join(parts)
        else:
            payload = str(fastPathS).encode('utf-8')

        # build header: 1 byte secFlag, 2 bytes payload length
        header = struct.pack('!BH', secFlag & 0xFF, len(payload))
        packet = header + payload

        # send packet to listener
        self._fastPathListener.onFastPathData(secFlag, packet)","class IFastPathSender(object):
    '''
    @summary: Fast path send capability
    '''

    def sendFastPath(self, secFlag, fastPathS):
        '''
        @summary: Send fastPathS Type as fast path packet
        @param secFlag: {integer} Security flag for fastpath packet
        @param fastPathS: {Type | Tuple} type transform to stream and send as fastpath
        '''
        pass

    def initFastPath(self, fastPathListener):
        '''
        @summary: initialize stack
        @param fastPathListener: {IFastPathListener}
        '''
        pass

    def setFastPathListener(self, fastPathListener):
        '''
        @param fastPathListener: {IFastPathListener}
        '''
        pass","class IFastPathSender(object):
    '''
    @summary: Fast path send capability
    '''

    def __init__(self):
        self._fastPathListener = None

    def sendFastPath(self, secFlag, fastPathS):
        '''
        @summary: Send fastPathS Type as fast path packet
        @param secFlag: {integer} Security flag for fastpath packet
        @param fastPathS: {Type | Tuple} type transform to stream and send as fastpath
        '''
        raise NotImplementedError(""sendFastPath method must be implemented"")

    def initFastPath(self, fastPathListener):
        '''
        @summary: initialize stack
        @param fastPathListener: {IFastPathListener}
        '''
        self._fastPathListener = fastPathListener

    def setFastPathListener(self, fastPathListener):
        '''
        @param fastPathListener: {IFastPathListener}
        '''
        self._fastPathListener = fastPathListener",full_docstr,0.4652777777777778,0.41258741258741255,0.38028169014084506,0.3194444444444445,0.3025662749431045,0.3821138211382114,0.29891304347826086,0.24250681198910082,0.7748193740844727,0.8712241053581238,0.8201985955238342,0.8605173230171204,0.7444857142857149,0.7785234899328859,0.7482993197278912,0.7172413793103448,0.7785234899328859,0.3513233362578481,0.8990825688073395,0.8333333333333334,0.7663551401869159,0.9679453372955322,0.891801118850708,0.9283144474029541,0.8988721370697021,0.8151833663366336,0.7999999999999999,0.7116564417177914,0.6583850931677019,0.7757575757575759,0.4810052901036795,0.8482758620689655,0.7152777777777778,0.6013986013986014,0.9395164847373962,0.9009479284286499,0.9198281168937683,0.9046616554260254,0.8349851485148515,0.4031719725352325,0.2475395787007459,0.5582101515608481,0.5128205128205128,0.2941176470588235,0.3785099200447646,0.5235655200978606,0.5425103591762206,0.1538461538461538,0.2941176470588235,0.4621621342131699,0.5356373281150956,0.5498136220105853,0.4102564102564102,0.3529411764705882
399400,getsentry/raven-python,getsentry_raven-python/raven/contrib/zerorpc/__init__.py,raven.contrib.zerorpc.SentryMiddleware,"class SentryMiddleware(object):
    """"""Sentry/Raven middleware for ZeroRPC.

    >>> import zerorpc
    >>> from raven.contrib.zerorpc import SentryMiddleware
    >>> sentry = SentryMiddleware(dsn='udp://..../')
    >>> zerorpc.Context.get_instance().register_middleware(sentry)

    Exceptions detected server-side in ZeroRPC will be submitted to Sentry (and
    propagated to the client as well).
    """"""

    def __init__(self, hide_zerorpc_frames=True, client=None, **kwargs):
        """"""
        Create a middleware object that can be injected in a ZeroRPC server.

        - hide_zerorpc_frames: modify the exception stacktrace to remove the
                               internal zerorpc frames (True by default to make
                               the stacktrace as readable as possible);
        - client: use an existing raven.Client object, otherwise one will be
                  instantiated from the keyword arguments.
        """"""
        self._sentry_client = client or Client(**kwargs)
        self._hide_zerorpc_frames = hide_zerorpc_frames

    def server_inspect_exception(self, req_event, rep_event, task_ctx, exc_info):
        """"""
        Called when an exception has been raised in the code run by ZeroRPC
        """"""
        # Hide the zerorpc internal frames for readability, for a REQ/REP or
        # REQ/STREAM server the frames to hide are:
        # - core.ServerBase._async_task
        # - core.Pattern*.process_call
        # - core.DecoratorBase.__call__
        #
        # For a PUSH/PULL or PUB/SUB server the frame to hide is:
        # - core.Puller._receiver
        if self._hide_zerorpc_frames:
            traceback = exc_info[2]
            while traceback:
                zerorpc_frame = traceback.tb_frame
                zerorpc_frame.f_locals['__traceback_hide__'] = True
                frame_info = inspect.getframeinfo(zerorpc_frame)
                # Is there a better way than this (or looking up the filenames
                # or hardcoding the number of frames to skip) to know when we
                # are out of zerorpc?
                if frame_info.function == '__call__' \
                        or frame_info.function == '_receiver':
                    break
                traceback = traceback.tb_next

        self._sentry_client.captureException(
            exc_info,
            extra=task_ctx
        )","class SentryMiddleware(object):
    '''Sentry/Raven middleware for ZeroRPC.

    >>> import zerorpc
    >>> from raven.contrib.zerorpc import SentryMiddleware
    >>> sentry = SentryMiddleware(dsn='udp://..../')
    >>> zerorpc.Context.get_instance().register_middleware(sentry)

    Exceptions detected server-side in ZeroRPC will be submitted to Sentry (and
    propagated to the client as well).
    '''

    def __init__(self, hide_zerorpc_frames=True, client=None, **kwargs):
    '''
        Create a middleware object that can be injected in a ZeroRPC server.

        - hide_zerorpc_frames: modify the exception stacktrace to remove the
                               internal zerorpc frames (True by default to make
                               the stacktrace as readable as possible);
        - client: use an existing raven.Client object, otherwise one will be
                  instantiated from the keyword arguments.
        '''
        pass

    def server_inspect_exception(self, req_event, rep_event, task_ctx, exc_info):
    '''
        Called when an exception has been raised in the code run by ZeroRPC
        '''
        pass

",3,3,snippet_713,0.5714285714285714,"class SentryMiddleware(object):
    '''Sentry/Raven middleware for ZeroRPC.

    >>> import zerorpc
    >>> from raven.contrib.zerorpc import SentryMiddleware
    >>> sentry = SentryMiddleware(dsn='udp://..../')
    >>> zerorpc.Context.get_instance().register_middleware(sentry)

    Exceptions detected server-side in ZeroRPC will be submitted to Sentry (and
    propagated to the client as well).
    '''

    def __init__(self, hide_zerorpc_frames=True, client=None, **kwargs):
        '''
        Create a middleware object that can be injected in a ZeroRPC server.

        - hide_zerorpc_frames: modify the exception stacktrace to remove the
                               internal zerorpc frames (True by default to make
                               the stacktrace as readable as possible);
        - client: use an existing raven.Client object, otherwise one will be
                  instantiated from the keyword arguments.
        '''
        if client is not None:
            self.client = client
        else:
            self.client = Client(**kwargs)
        self.hide_zerorpc_frames = hide_zerorpc_frames

    def server_inspect_exception(self, req_event, rep_event, task_ctx, exc_info):
        '''
        Called when an exception has been raised in the code run by ZeroRPC
        '''
        etype, evalue, tb = exc_info
        if self.hide_zerorpc_frames:
            try:
                frames = []
                current = tb
                while current:
                    modname = current.tb_frame.f_globals.get('__name__', '')
                    if not modname.startswith('zerorpc'):
                        frames.append((current.tb_frame, current.tb_frame.f_lasti, current.tb_lineno))
                    current = current.tb_next
                new_tb = None
                for frame, lasti, lineno in reversed(frames):
                    new_tb = types.TracebackType(new_tb, frame, lasti, lineno)
                tb = new_tb
                exc_info = (etype, evalue, tb)
            except Exception:
                pass
        self.client.captureException(exc_info=exc_info)
        return None","class SentryMiddleware(object):
    '''Sentry/Raven middleware for ZeroRPC.

    >>> import zerorpc
    >>> from raven.contrib.zerorpc import SentryMiddleware
    >>> sentry = SentryMiddleware(dsn='udp://..../')
    >>> zerorpc.Context.get_instance().register_middleware(sentry)

    Exceptions detected server-side in ZeroRPC will be submitted to Sentry (and
    propagated to the client as well).
    '''

    def __init__(self, hide_zerorpc_frames=True, client=None, **kwargs):
        '''
        Create a middleware object that can be injected in a ZeroRPC server.

        - hide_zerorpc_frames: modify the exception stacktrace to remove the
                               internal zerorpc frames (True by default to make
                               the stacktrace as readable as possible);
        - client: use an existing raven.Client object, otherwise one will be
                  instantiated from the keyword arguments.
        '''
        self.hide_zerorpc_frames = hide_zerorpc_frames
        
        if client is not None:
            self.client = client
        else:
            from raven import Client
            self.client = Client(**kwargs)

    def server_inspect_exception(self, req_event, rep_event, task_ctx, exc_info):
        '''
        Called when an exception has been raised in the code run by ZeroRPC
        '''
        exc_type, exc_value, exc_traceback = exc_info
        
        if self.hide_zerorpc_frames:
            # Filter out zerorpc frames from the traceback
            import traceback
            tb_list = traceback.extract_tb(exc_traceback)
            filtered_tb_list = [frame for frame in tb_list if 'zerorpc' not in frame.filename]
            
            if filtered_tb_list:
                # Create a new traceback with filtered frames
                import sys
                exc_traceback = None
                for frame in reversed(filtered_tb_list):
                    exc_traceback = traceback.FrameSummary(
                        frame.filename, frame.lineno, frame.name, frame.line
                    )
        
        # Capture the exception with Raven client
        self.client.captureException(exc_info=(exc_type, exc_value, exc_traceback))","class SentryMiddleware(object):
    '''Sentry/Raven middleware for ZeroRPC.

    >>> import zerorpc
    >>> from raven.contrib.zerorpc import SentryMiddleware
    >>> sentry = SentryMiddleware(dsn='udp://..../')
    >>> zerorpc.Context.get_instance().register_middleware(sentry)

    Exceptions detected server-side in ZeroRPC will be submitted to Sentry (and
    propagated to the client as well).
    '''

    def __init__(self, hide_zerorpc_frames=True, client=None, **kwargs):
        '''
        Create a middleware object that can be injected in a ZeroRPC server.

        - hide_zerorpc_frames: modify the exception stacktrace to remove the
                               internal zerorpc frames (True by default to make
                               the stacktrace as readable as possible);
        - client: use an existing raven.Client object, otherwise one will be
                  instantiated from the keyword arguments.
        '''
        self.hide_zerorpc_frames = hide_zerorpc_frames
        if client is None:
            from raven import Client
            self.client = Client(**kwargs)
        else:
            self.client = client

    def server_inspect_exception(self, req_event, rep_event, task_ctx, exc_info):
        '''
        Called when an exception has been raised in the code run by ZeroRPC
        '''
        if self.hide_zerorpc_frames:
            import traceback
            tb = exc_info[2]
            frames = []
            while tb is not None:
                frame = tb.tb_frame
                filename = frame.f_code.co_filename
                if not ('zerorpc' in filename and 'site-packages' in filename):
                    frames.append(tb)
                tb = tb.tb_next
            
            if frames:
                exc_info = (exc_info[0], exc_info[1], frames[-1])
        
        self.client.captureException(exc_info=exc_info, extra={
            'zerorpc_event': req_event.name if req_event else None,
            'zerorpc_args': req_event.args if req_event else None
        })",full_docstr,0.6861598440545809,0.5949119373776909,0.5618860510805501,0.6510721247563354,0.5553299280209583,0.7808857808857809,0.6261682242990654,0.5761124121779859,0.901171088218689,0.8789653778076172,0.8899297118186951,0.8811365962028503,0.8187720388349514,0.7007575757575758,0.5741444866920151,0.5381679389312978,0.6174242424242425,0.5451652533418188,0.8014184397163121,0.6208530805687204,0.5629453681710214,0.9103677272796631,0.8771680593490601,0.8934595584869385,0.8803787231445312,0.7965136627906977,0.7067961165048544,0.6042884990253412,0.5557729941291586,0.6446601941747572,0.5485661185563409,0.7961165048543689,0.656934306569343,0.6,0.9232474565505981,0.8793289065361023,0.9007531404495239,0.8835318088531494,0.8104925888324872,0.5068836340786813,0.4510446674392678,0.4707900131756017,0.492063492063492,0.6136363636363636,0.5022500309771284,0.462696023609345,0.4723502763453446,0.4603174603174603,0.6136363636363636,0.5036326576565273,0.4487189747063184,0.4648015549096895,0.5555555555555556,0.5454545454545454
253828,awslabs/aws-sam-cli,awslabs_aws-sam-cli/samcli/commands/local/lib/local_lambda_service.py,samcli.commands.local.lib.local_lambda_service.LocalLambdaService,"class LocalLambdaService:
    """"""
    Implementation of Local Lambda Invoke Service that is capable of serving the invoke path to your Lambda Functions
    that are defined in a SAM file.
    """"""

    def __init__(self, lambda_invoke_context, port, host, ssl_context=None):
        """"""
        Initialize the Local Lambda Invoke service.

        :param samcli.commands.local.cli_common.invoke_context.InvokeContext lambda_invoke_context: Context object
            that can help with Lambda invocation
        :param int port: Port to listen on
        :param string host: Local hostname or IP address to bind to
        :param tuple(string, string) ssl_context: Optional, path to ssl certificate and key files to start service
            in https
        """"""

        self.port = port
        self.host = host
        self.ssl_context = ssl_context
        self.lambda_runner = lambda_invoke_context.local_lambda_runner
        self.stderr_stream = lambda_invoke_context.stderr

    def start(self):
        """"""
        Creates and starts the Local Lambda Invoke service. This method will block until the service is stopped
        manually using an interrupt. After the service is started, callers can make HTTP requests to the endpoint
        to invoke the Lambda function and receive a response.

        NOTE: This is a blocking call that will not return until the thread is interrupted with SIGINT/SIGTERM
        """"""

        # We care about passing only stderr to the Service and not stdout because stdout from Docker container
        # contains the response to the API which is sent out as HTTP response. Only stderr needs to be printed
        # to the console or a log file. stderr from Docker container contains runtime logs and output of print
        # statements from the Lambda function
        service = LocalLambdaInvokeService(
            lambda_runner=self.lambda_runner,
            port=self.port,
            host=self.host,
            ssl_context=self.ssl_context,
            stderr=self.stderr_stream,
        )

        service.create()

        LOG.info(
            ""Starting the Local Lambda Service. You can now invoke your Lambda Functions defined in your template""
            "" through the endpoint.""
        )

        service.run()","class LocalLambdaService:
    '''
    Implementation of Local Lambda Invoke Service that is capable of serving the invoke path to your Lambda Functions
    that are defined in a SAM file.
    '''

    def __init__(self, lambda_invoke_context, port, host, ssl_context=None):
    '''
        Initialize the Local Lambda Invoke service.

        :param samcli.commands.local.cli_common.invoke_context.InvokeContext lambda_invoke_context: Context object
            that can help with Lambda invocation
        :param int port: Port to listen on
        :param string host: Local hostname or IP address to bind to
        :param tuple(string, string) ssl_context: Optional, path to ssl certificate and key files to start service
            in https
        '''
        pass

    def start(self):
    '''
        Creates and starts the Local Lambda Invoke service. This method will block until the service is stopped
        manually using an interrupt. After the service is started, callers can make HTTP requests to the endpoint
        to invoke the Lambda function and receive a response.

        NOTE: This is a blocking call that will not return until the thread is interrupted with SIGINT/SIGTERM
        '''
        pass

",3,3,snippet_406,0.75,"class LocalLambdaService:
    '''
    Implementation of Local Lambda Invoke Service that is capable of serving the invoke path to your Lambda Functions
    that are defined in a SAM file.
    '''

    def __init__(self, lambda_invoke_context, port, host, ssl_context=None):
        '''
        Initialize the Local Lambda Invoke service.

        :param samcli.commands.local.cli_common.invoke_context.InvokeContext lambda_invoke_context: Context object
            that can help with Lambda invocation
        :param int port: Port to listen on
        :param string host: Local hostname or IP address to bind to
        :param tuple(string, string) ssl_context: Optional, path to ssl certificate and key files to start service
            in https
        '''
        self.lambda_invoke_context = lambda_invoke_context
        self.port = port
        self.host = host
        self.ssl_context = ssl_context
        self._server = None

    def start(self):
        '''
        Creates and starts the Local Lambda Invoke service. This method will block until the service is stopped
        manually using an interrupt. After the service is started, callers can make HTTP requests to the endpoint
        to invoke the Lambda function and receive a response.

        NOTE: This is a blocking call that will not return until the thread is interrupted with SIGINT/SIGTERM
        '''
        invoke_ctx = self.lambda_invoke_context

        class _Handler(BaseHTTPRequestHandler):
            def do_POST(self):
                prefix = '/2015-03-31/functions/'
                suffix = '/invocations'
                path = self.path
                if not path.startswith(prefix) or not path.endswith(suffix):
                    self.send_error(404, 'Not Found')
                    return
                func_name = path[len(prefix):-len(suffix)]
                length = int(self.headers.get('Content-Length', 0))
                body = self.rfile.read(length) if length > 0 else b''
                try:
                    event = json.loads(body.decode('utf-8')) if body else {}
                except Exception:
                    self.send_error(400, 'Invalid JSON')
                    return

                # Invoke the lambda locally
                result = invoke_ctx.invoke(func_name, event)
                # result may be tuple(status_code, headers_dict, body)
                if isinstance(result, tuple) and len(result) == 3:
                    status_code, headers, resp_body = result
                else:
                    # assume raw body return
                    status_code, headers, resp_body = 200, {}, result

                if not isinstance(resp_body, (bytes, bytearray)):
                    resp_body = json.dumps(resp_body).encode('utf-8')

                self.send_response(status_code)
                has_ct = False
                for k, v in headers.items():
                    self.send_header(k, v)
                    if k.lower() == 'content-type':
                        has_ct = True
                if not has_ct:
                    self.send_header('Content-Type', 'application/json')
                self.send_header('Content-Length', str(len(resp_body)))
                self.end_headers()
                self.wfile.write(resp_body)

            def log_message(self, format, *args):
                return  # suppress default logging

        server = ThreadingHTTPServer((self.host, self.port), _Handler)
        if self.ssl_context:
            cert, key = self.ssl_context
            server.socket = ssl.wrap_socket(
                server.socket,
                certfile=cert,
                keyfile=key,
                server_side=True
            )
        self._server = server
        try:
            server.serve_forever()
        except (KeyboardInterrupt, SystemExit):
            pass
        finally:
            server.server_close()","class LocalLambdaService:
    '''
    Implementation of Local Lambda Invoke Service that is capable of serving the invoke path to your Lambda Functions
    that are defined in a SAM file.
    '''

    def __init__(self, lambda_invoke_context, port, host, ssl_context=None):
        '''
        Initialize the Local Lambda Invoke service.

        :param samcli.commands.local.cli_common.invoke_context.InvokeContext lambda_invoke_context: Context object
            that can help with Lambda invocation
        :param int port: Port to listen on
        :param string host: Local hostname or IP address to bind to
        :param tuple(string, string) ssl_context: Optional, path to ssl certificate and key files to start service
            in https
        '''
        self.lambda_invoke_context = lambda_invoke_context
        self.port = port
        self.host = host
        self.ssl_context = ssl_context
        self.server = None
        self.thread = None

    def start(self):
        '''
        Creates and starts the Local Lambda Invoke service. This method will block until the service is stopped
        manually using an interrupt. After the service is started, callers can make HTTP requests to the endpoint
        to invoke the Lambda function and receive a response.

        NOTE: This is a blocking call that will not return until the thread is interrupted with SIGINT/SIGTERM
        '''
        class LambdaInvokeHandler(BaseHTTPRequestHandler):
            def do_POST(self):
                try:
                    content_length = int(self.headers.get('Content-Length', 0))
                    post_data = self.rfile.read(content_length)
                    
                    # Parse the request data
                    try:
                        request_data = json.loads(post_data) if post_data else {}
                    except json.JSONDecodeError:
                        request_data = {}
                    
                    # Get the function name from the request path or default context
                    function_name = self.get_function_name()
                    
                    # Invoke the Lambda function
                    response = self.server.lambda_service.invoke_function(function_name, request_data)
                    
                    # Send response
                    self.send_response(200)
                    self.send_header('Content-Type', 'application/json')
                    self.end_headers()
                    self.wfile.write(json.dumps(response).encode())
                    
                except Exception as e:
                    logger.error(f""Error invoking Lambda function: {str(e)}"")
                    self.send_response(500)
                    self.send_header('Content-Type', 'application/json')
                    self.end_headers()
                    error_response = {""error"": str(e)}
                    self.wfile.write(json.dumps(error_response).encode())
            
            def get_function_name(self):
                # Extract function name from path or use default
                return ""default-function""
            
            def log_message(self, format, *args):
                logger.info(format % args)

        # Create HTTP server
        self.server = HTTPServer((self.host, self.port), LambdaInvokeHandler)
        self.server.lambda_service = self
        
        # Configure SSL if provided
        if self.ssl_context:
            cert_file, key_file = self.ssl_context
            self.server.socket = ssl.wrap_socket(self.server.socket, 
                                               certfile=cert_file, 
                                               keyfile=key_file, 
                                               server_side=True)
        
        logger.info(f""Starting Local Lambda Service on {self.host}:{self.port}"")
        
        try:
            self.server.serve_forever()
        except KeyboardInterrupt:
            logger.info(""Shutting down Local Lambda Service"")
            self.server.shutdown()
    
    def invoke_function(self, function_name, event_data):
        '''
        Invoke the Lambda function with the given name and event data.
        
        :param string function_name: Name of the Lambda function to invoke
        :param dict event_data: Event data to pass to the Lambda function
        :return: Response from the Lambda function
        '''
        # Use the invoke context to invoke the function
        if self.lambda_invoke_context:
            # This is a simplified implementation - in practice, you would
            # use the invoke context to properly invoke the Lambda function
            local_lambda_runner = self.lambda_invoke_context.local_lambda_runner
            function = self.lambda_invoke_context.function_provider.get(function_name)
            
            if function:
                # Invoke the function and return the result
                response = local_lambda_runner.invoke(function, event_data)
                return response
        
        # Fallback response
        return {""statusCode"": 200, ""body"": ""Function invoked successfully""}","class LocalLambdaService:
    '''
    Implementation of Local Lambda Invoke Service that is capable of serving the invoke path to your Lambda Functions
    that are defined in a SAM file.
    '''

    def __init__(self, lambda_invoke_context, port, host, ssl_context=None):
        '''
        Initialize the Local Lambda Invoke service.

        :param samcli.commands.local.cli_common.invoke_context.InvokeContext lambda_invoke_context: Context object
            that can help with Lambda invocation
        :param int port: Port to listen on
        :param string host: Local hostname or IP address to bind to
        :param tuple(string, string) ssl_context: Optional, path to ssl certificate and key files to start service
            in https
        '''
        self.lambda_invoke_context = lambda_invoke_context
        self.port = port
        self.host = host
        self.ssl_context = ssl_context
        self.app = Flask(__name__)
        self.server = None
        self._setup_routes()

    def _setup_routes(self):
        @self.app.route('/2015-03-31/functions/<function_name>/invocations', methods=['POST'])
        def invoke_function(function_name):
            try:
                payload = request.get_data()
                if not payload:
                    payload = b'{}'
                
                stdout, stderr = self.lambda_invoke_context.local_lambda_runner.invoke(
                    function_name,
                    payload,
                    stdout=None,
                    stderr=None
                )
                
                return stdout
            except Exception as e:
                return jsonify({'errorMessage': str(e), 'errorType': type(e).__name__}), 500

    def start(self):
        '''
        Creates and starts the Local Lambda Invoke service. This method will block until the service is stopped
        manually using an interrupt. After the service is started, callers can make HTTP requests to the endpoint
        to invoke the Lambda function and receive a response.

        NOTE: This is a blocking call that will not return until the thread is interrupted with SIGINT/SIGTERM
        '''
        self.server = make_server(
            self.host,
            self.port,
            self.app,
            ssl_context=self.ssl_context,
            threaded=True
        )
        
        try:
            self.server.serve_forever()
        except KeyboardInterrupt:
            self.server.shutdown()",full_docstr,0.5587044534412956,0.5115020297699595,0.474898236092266,0.5182186234817814,0.3643933917950735,0.4234354194407457,0.34933333333333333,0.32710280373831774,0.8020909428596497,0.8992413282394409,0.8478922843933105,0.8884798884391785,0.7392556025369981,0.5734265734265734,0.46728971962616817,0.4309133489461358,0.4801864801864802,0.3314607202474212,0.4043478260869565,0.31556039173014144,0.28540305010893247,0.8375533819198608,0.9136872887611389,0.8739653825759888,0.9054566621780396,0.7362518091451298,0.7147766323024054,0.6655172413793103,0.6228373702422145,0.6701030927835051,0.5928157776923144,0.6673728813559322,0.5753715498938429,0.5425531914893617,0.8741138577461243,0.903384804725647,0.8885082602500916,0.9003697633743286,0.7863269230769234,0.5759622970253728,0.4414582436904606,0.5766766586967452,0.5714285714285714,0.7142857142857143,0.571533593959681,0.3685862297258753,0.6080243365890391,0.5714285714285714,0.7380952380952381,0.6431610980150597,0.5563649400165198,0.5698508806151479,0.6607142857142857,0.7857142857142857
329450,datadotworld/data.world-py,datadotworld_data.world-py/datadotworld/datadotworld.py,datadotworld.datadotworld.UriParam,"class UriParam:
    """"""Represents a URI value as a parameter to a SPARQL query""""""
    def __init__(self, uri):
        """"""
        Initialize the UriParam value
        :param uri: the uri value to wrap
        """"""
        self._uri = uri

    def __repr__(self):
        """"""
        The official string representation for the URI
        :return: the string representation for the URI
        """"""
        return self._uri","class UriParam:
    '''Represents a URI value as a parameter to a SPARQL query'''

    def __init__(self, uri):
    '''
        Initialize the UriParam value
        :param uri: the uri value to wrap
        '''
        pass

    def __repr__(self):
    '''
        The official string representation for the URI
        :return: the string representation for the URI
        '''
        pass

",3,3,snippet_572,1.0,"class UriParam:
    '''Represents a URI value as a parameter to a SPARQL query'''

    def __init__(self, uri):
        '''
        Initialize the UriParam value
        :param uri: the uri value to wrap
        '''
        if not isinstance(uri, str):
            raise TypeError(f""URI must be a string, got {type(uri).__name__}"")
        if not uri:
            raise ValueError(""URI cannot be an empty string"")
        self.uri = uri

    def __repr__(self):
        '''
        The official string representation for the URI
        :return: the string representation for the URI
        '''
        return f""<{self.uri}>""","class UriParam:
    '''Represents a URI value as a parameter to a SPARQL query'''

    def __init__(self, uri):
        '''
        Initialize the UriParam value
        :param uri: the uri value to wrap
        '''
        self.uri = uri

    def __repr__(self):
        '''
        The official string representation for the URI
        :return: the string representation for the URI
        '''
        return f'<{self.uri}>'","class UriParam:
    '''Represents a URI value as a parameter to a SPARQL query'''

    def __init__(self, uri):
        '''
        Initialize the UriParam value
        :param uri: the uri value to wrap
        '''
        self.uri = uri

    def __repr__(self):
        '''
        The official string representation for the URI
        :return: the string representation for the URI
        '''
        return f""<{self.uri}>""",full_docstr,0.7786259541984732,0.7441860465116279,0.7086614173228346,0.7786259541984732,0.48396224141568817,0.5912408759124088,0.47058823529411764,0.4074074074074074,0.8754787445068359,0.9664826393127441,0.9187326431274414,0.9565397500991821,0.8312774074074073,0.9902912621359222,0.9702970297029702,0.9494949494949495,0.9902912621359222,0.6684181092693475,0.8588235294117647,0.75,0.6626506024096386,0.9847285151481628,0.9907586574554443,0.9877343773841858,0.9901522994041443,0.9565221739130435,0.9902912621359222,0.9702970297029702,0.9494949494949495,0.9902912621359222,0.6753649088930471,0.872093023255814,0.7411764705882353,0.6547619047619048,0.9849030375480652,0.9909709095954895,0.9879276752471924,0.9903607964515686,0.9565221739130435,0.536918095016381,0.4668861644032407,0.680786215662283,0.4285714285714285,0.5714285714285714,0.623502524926992,0.6703667411885421,0.680786215662283,0.5714285714285714,0.5714285714285714,0.623502524926992,0.6703667411885421,0.680786215662283,0.5714285714285714,0.5714285714285714
133307,JanHendrikDolling/configvalidator,JanHendrikDolling_configvalidator/configvalidator/tools/configValidator.py,configvalidator.tools.configValidator.ConfigValidator,"class ConfigValidator(object):
    """"""ConfigValidator

    Attributes:
        cp: An class which fulfill the configparser interface
        cp_init_args: This item will be passed as kwargs to new cp instances
        data: local data store

    """"""

    def __init__(self, cp, cp_init_args=None):
        """"""Inits ConfigValidator.""""""
        self.cp = cp
        assert isinstance(cp, object)
        self.cp_init_args = cp_init_args
        assert isinstance(self.cp_init_args, dict) or self.cp_init_args is None
        self.data = {}
        for method_name in [""has_option"", ""read"", ""get"", ""options""]:
            if method_name not in dir(cp):
                raise InitException(""No such method \""{method_name}\"". Need to implement the ConfigParser interface"".format(method_name=method_name))

    def add_data(self, key, value):
        """"""
	TODO
        """"""
        self.data[key] = value

    def remove_data(self, key):
        """"""
	TODO
        """"""
        assert isinstance(key, object)
        del self.data[key]

    def parse(self, config_dict, feature_key=""__feature__""):
        """"""

        :param config_dict:
        :param feature_key:
        :return:
        """"""
        parse_obj = ParseObj(self.cp, cp_init_args=self.cp_init_args, context_data=dict(self.data))
        # copy config dict so that changes wont affect the original dict.
        tmp_config_dict = json.loads(json.dumps(config_dict))
        for section, section_config_dict in tmp_config_dict.items():
            try:
                parse_obj.current_section = section
                section_class_name = ""default""
                if feature_key in section_config_dict:
                    section_class_name = section_config_dict[feature_key]
                    del section_config_dict[feature_key]
                section_class = load_section_feature(section_class_name)
                section_instance = section_class(parse_obj, **section_config_dict)
                section_instance.parse_section(parse_obj, section_config_dict)
            except Exception as e:
                parse_obj.add_error(error_msg=""Error parsing section {section}: {raise_msg}"".format(section=section, raise_msg=e), exception=e)
        parse_obj.current_section = None
        parse_obj.current_option = None
        return parse_obj.result()","class ConfigValidator(object):
    '''ConfigValidator

    Attributes:
        cp: An class which fulfill the configparser interface
        cp_init_args: This item will be passed as kwargs to new cp instances
        data: local data store

    '''

    def __init__(self, cp, cp_init_args=None):
    '''Inits ConfigValidator.'''
        pass

    def add_data(self, key, value):
    '''
    TODO
        '''
        pass

    def remove_data(self, key):
    '''
    TODO
        '''
        pass

    def parse(self, config_dict, feature_key=""__feature__""):
    '''

        :param config_dict:
        :param feature_key:
        :return:
        '''
        pass

",5,5,snippet_151,0.4285714285714285,"class ConfigValidator(object):
    '''ConfigValidator

    Attributes:
        cp: A class which fulfills the configparser interface
        cp_init_args: This item will be passed as kwargs to new cp instances
        data: local data store
    '''

    def __init__(self, cp, cp_init_args=None):
        '''Inits ConfigValidator.'''
        self.cp = cp
        self.cp_init_args = cp_init_args.copy() if cp_init_args else {}
        self.data = {}

    def add_data(self, key, value):
        '''Add a data item to the local store.'''
        self.data[key] = value

    def remove_data(self, key):
        '''Remove a data item from the local store.'''
        del self.data[key]

    def parse(self, config_dict, feature_key=""__feature__""):
        '''
        Build and return a configparser instance filled with the provided
        config_dict plus any locally stored data under the feature_key section.
        '''
        cfg = self.cp(**self.cp_init_args)
        # build a copy of the input dict
        merged = {}
        for section, opts in config_dict.items():
            merged[section] = opts.copy() if isinstance(opts, dict) else opts
        # inject feature data if available
        if self.data:
            merged[feature_key] = self.data.copy()
        cfg.read_dict(merged)
        return cfg","class ConfigValidator(object):
    '''ConfigValidator

    Attributes:
        cp: An class which fulfill the configparser interface
        cp_init_args: This item will be passed as kwargs to new cp instances
        data: local data store

    '''

    def __init__(self, cp, cp_init_args=None):
        '''Inits ConfigValidator.'''
        self.cp = cp
        self.cp_init_args = cp_init_args or {}
        self.data = {}

    def add_data(self, key, value):
        '''
        Add data to the local data store
        '''
        self.data[key] = value

    def remove_data(self, key):
        '''
        Remove data from the local data store
        '''
        if key in self.data:
            del self.data[key]

    def parse(self, config_dict, feature_key=""__feature__""):
        '''

        :param config_dict:
        :param feature_key:
        :return:
        '''
        # Create a new instance of the configparser class
        config_parser = self.cp(**self.cp_init_args)
        
        # Process the config_dict to handle feature-specific configurations
        processed_config = {}
        
        for section, options in config_dict.items():
            if isinstance(options, dict):
                # Handle regular sections
                processed_config[section] = {}
                for option, value in options.items():
                    if option == feature_key and isinstance(value, list):
                        # Handle feature-specific configurations
                        for feature_config in value:
                            if isinstance(feature_config, dict):
                                for feat_section, feat_options in feature_config.items():
                                    if feat_section not in processed_config:
                                        processed_config[feat_section] = {}
                                    processed_config[feat_section].update(feat_options)
                    else:
                        processed_config[section][option] = value
            else:
                # Handle top-level options
                processed_config[section] = options
        
        # Return the processed configuration
        return processed_config","class ConfigValidator(object):
    '''ConfigValidator

    Attributes:
        cp: An class which fulfill the configparser interface
        cp_init_args: This item will be passed as kwargs to new cp instances
        data: local data store

    '''

    def __init__(self, cp, cp_init_args=None):
        '''Inits ConfigValidator.'''
        self.cp = cp
        self.cp_init_args = cp_init_args if cp_init_args is not None else {}
        self.data = {}

    def add_data(self, key, value):
        '''
        TODO
        '''
        self.data[key] = value

    def remove_data(self, key):
        '''
        TODO
        '''
        if key in self.data:
            del self.data[key]

    def parse(self, config_dict, feature_key=""__feature__""):
        '''

        :param config_dict:
        :param feature_key:
        :return:
        '''
        parser = self.cp(**self.cp_init_args)
        
        for section_name, section_data in config_dict.items():
            if isinstance(section_data, dict):
                parser.add_section(section_name)
                for key, value in section_data.items():
                    if key != feature_key:
                        parser.set(section_name, key, str(value))
        
        return parser",full_docstr,0.5269978401727862,0.3687635574837311,0.2962962962962963,0.46652267818574517,0.24376203521746626,0.7861842105263158,0.570957095709571,0.4768211920529801,0.8624917268753052,0.8125219345092773,0.836761474609375,0.8172568082809448,0.8144672641509434,0.5786407766990291,0.37816764132553604,0.30919765166340507,0.47766990291262135,0.34610617407905114,0.742014742014742,0.5024630541871922,0.38765432098765434,0.8743544816970825,0.8284756541252136,0.8507970571517944,0.8328456878662109,0.7997923584905661,0.6114942528735633,0.46651270207852197,0.38979118329466356,0.5563218390804598,0.2566857186194307,0.9078014184397163,0.7295373665480427,0.5892857142857143,0.9306764602661133,0.8368081450462341,0.8812496662139893,0.8453341722488403,0.8186600943396226,0.272401128479489,0.2185233569317098,0.2253584431219393,0.4333333333333333,0.2123893805309734,0.3195198825518311,0.2707946446892186,0.2907657114768078,0.4333333333333333,0.2831858407079646,0.292079725677944,0.2351049034832968,0.2808246186975059,0.44,0.2123893805309734
267304,blackecho/Deep-Learning-TensorFlow,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/blackecho_Deep-Learning-TensorFlow/yadlt/core/config.py,yadlt.core.config.Config.__Singleton,"class __Singleton(object):
    """"""Singleton design pattern.""""""

    def __init__(self, models_dir='models/', data_dir='data/',
                 logs_dir='logs/'):
        """"""Constructor.

        Parameters
        ----------
        models_dir : string, optional (default='models/')
            directory path to store trained models.
            Path is relative to ~/.yadlt
        data_dir : string, optional (default='data/')
            directory path to store model generated data.
            Path is relative to ~/.yadlt
        logs_dir : string, optional (default='logs/')
            directory path to store yadlt and tensorflow logs.
            Path is relative to ~/.yadlt
        """"""
        self.home_dir = os.path.join(os.path.expanduser(""~""), '.yadlt')
        self.models_dir = os.path.join(self.home_dir, models_dir)
        self.data_dir = os.path.join(self.home_dir, data_dir)
        self.logs_dir = os.path.join(self.home_dir, logs_dir)
        self.mkdir_p(self.home_dir)
        self.mkdir_p(self.models_dir)
        self.mkdir_p(self.data_dir)
        self.mkdir_p(self.logs_dir)

    def mkdir_p(self, path):
        """"""Recursively create directories.""""""
        try:
            os.makedirs(path)
        except OSError as exc:  # Python >2.5
            if exc.errno == errno.EEXIST and os.path.isdir(path):
                pass
            else:
                raise
","class __Singleton(object):
    '''Singleton design pattern.'''


    def __init__(self, models_dir='models/', data_dir='data/',
                 logs_dir='logs/'):
    '''Constructor.

        Parameters
        ----------
        models_dir : string, optional (default='models/')
            directory path to store trained models.
            Path is relative to ~/.yadlt
        data_dir : string, optional (default='data/')
            directory path to store model generated data.
            Path is relative to ~/.yadlt
        logs_dir : string, optional (default='logs/')
            directory path to store yadlt and tensorflow logs.
            Path is relative to ~/.yadlt
        '''
        pass


    def mkdir_p(self, path):
    '''Recursively create directories.'''
        pass

",3,3,snippet_449,0.3333333333333333,"class __Singleton(object):
    '''Singleton design pattern.'''
    _instance = None

    def __new__(cls, models_dir='models/', data_dir='data/', logs_dir='logs/'):
        if cls._instance is None:
            cls._instance = super(__Singleton, cls).__new__(cls)
        return cls._instance

    def __init__(self, models_dir='models/', data_dir='data/',
                 logs_dir='logs/'):
        '''Constructor.

        Parameters
        ----------
        models_dir : string, optional (default='models/')
            directory path to store trained models.
            Path is relative to ~/.yadlt
        data_dir : string, optional (default='data/')
            directory path to store model generated data.
            Path is relative to ~/.yadlt
        logs_dir : string, optional (default='logs/')
            directory path to store yadlt and tensorflow logs.
            Path is relative to ~/.yadlt
        '''
        if getattr(self, '_initialized', False):
            return

        config_root = os.path.join(os.path.expanduser('~'), '.yadlt')
        self.mkdir_p(config_root)

        self.models_dir = os.path.join(config_root, models_dir)
        self.data_dir   = os.path.join(config_root, data_dir)
        self.logs_dir   = os.path.join(config_root, logs_dir)

        self.mkdir_p(self.models_dir)
        self.mkdir_p(self.data_dir)
        self.mkdir_p(self.logs_dir)

        self._initialized = True

    def mkdir_p(self, path):
        '''Recursively create directories.'''
        try:
            os.makedirs(path)
        except OSError as e:
            if e.errno != errno.EEXIST:
                raise","class __Singleton(object):
    '''Singleton design pattern.'''


    def __init__(self, models_dir='models/', data_dir='data/',
                 logs_dir='logs/'):
        '''Constructor.

        Parameters
        ----------
        models_dir : string, optional (default='models/')
            directory path to store trained models.
            Path is relative to ~/.yadlt
        data_dir : string, optional (default='data/')
            directory path to store model generated data.
            Path is relative to ~/.yadlt
        logs_dir : string, optional (default='logs/')
            directory path to store yadlt and tensorflow logs.
            Path is relative to ~/.yadlt
        '''
        self.models_dir = models_dir
        self.data_dir = data_dir
        self.logs_dir = logs_dir


    def mkdir_p(self, path):
        '''Recursively create directories.'''
        try:
            os.makedirs(path)
        except OSError as exc:
            if exc.errno == errno.EEXIST and os.path.isdir(path):
                pass
            else:
                raise","class __Singleton(object):
    '''Singleton design pattern.'''
    
    _instance = None
    _initialized = False
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super(__Singleton, cls).__new__(cls)
        return cls._instance

    def __init__(self, models_dir='models/', data_dir='data/',
                 logs_dir='logs/'):
        '''Constructor.

        Parameters
        ----------
        models_dir : string, optional (default='models/')
            directory path to store trained models.
            Path is relative to ~/.yadlt
        data_dir : string, optional (default='data/')
            directory path to store model generated data.
            Path is relative to ~/.yadlt
        logs_dir : string, optional (default='logs/')
            directory path to store yadlt and tensorflow logs.
            Path is relative to ~/.yadlt
        '''
        if not self._initialized:
            self.home_dir = os.path.expanduser('~/.yadlt/')
            self.models_dir = os.path.join(self.home_dir, models_dir)
            self.data_dir = os.path.join(self.home_dir, data_dir)
            self.logs_dir = os.path.join(self.home_dir, logs_dir)
            
            self.mkdir_p(self.home_dir)
            self.mkdir_p(self.models_dir)
            self.mkdir_p(self.data_dir)
            self.mkdir_p(self.logs_dir)
            
            self._initialized = True

    def mkdir_p(self, path):
        '''Recursively create directories.'''
        try:
            os.makedirs(path)
        except OSError as exc:
            if exc.errno == errno.EEXIST and os.path.isdir(path):
                pass
            else:
                raise",full_docstr,0.8184281842818428,0.7574931880108992,0.6849315068493151,0.7804878048780489,0.6825567829549153,0.7555555555555555,0.6757425742574258,0.6228287841191067,0.8386322259902954,0.926139235496521,0.8802161812782288,0.9165752530097961,0.8663980971659919,0.8109965635738832,0.8027681660899654,0.7735191637630662,0.8109965635738832,0.4983352365043137,0.9728506787330317,0.9136363636363637,0.8538812785388128,0.9669915437698364,0.9257956743240356,0.9459453225135803,0.9297566413879395,0.8425476381909548,0.9002695417789757,0.878048780487805,0.8555858310626703,0.9002695417789757,0.7694195233692677,0.8079800498753117,0.7625,0.7393483709273183,0.9017460942268372,0.9430767297744751,0.9219484329223633,0.9387738704681396,0.9118466115702479,0.5746339996621066,0.527541292857076,0.624390703365638,0.6907216494845361,0.4558823529411764,0.5601936587743694,0.6589106399957997,0.677982855016778,0.6391752577319587,0.2647058823529412,0.6692252455202904,0.652760748384289,0.7933943270868056,0.9072164948453608,0.3235294117647059
387772,flowersteam/explauto,flowersteam_explauto/explauto/sensorimotor_model/inverse/cma.py,explauto.sensorimotor_model.inverse.cma.ConstRandnShift,"class ConstRandnShift(object):
    """"""``ConstRandnShift()(x)`` adds a fixed realization of
    ``stddev * randn(len(x))`` to the vector x.

    By default, the realized shift is the same for each instance of
    ``ConstRandnShift``, see ``seed`` argument. This class is used in
    class ``FFWrapper.ShiftedFitness`` as default transformation.

    See: class ``FFWrapper.ShiftedFitness``

    """"""
    def __init__(self, stddev=3, seed=1):
        """"""with ``seed=None`` each instance realizes a different shift""""""
        self.seed = seed
        self.stddev = stddev
        self._xopt = {}
    def __call__(self, x):
        """"""return ""shifted"" ``x - shift``

        """"""
        try:
            x_opt = self._xopt[len(x)]
        except KeyError:
            if self.seed is None:
                shift = np.random.randn(len(x))
            else:
                rstate = np.random.get_state()
                np.random.seed(self.seed)
                shift = np.random.randn(len(x))
                np.random.set_state(rstate)
            x_opt = self._xopt.setdefault(len(x), self.stddev * shift)
        return array(x, copy=False) - x_opt
    def get(self, dimension):
        """"""return shift applied to ``zeros(dimension)``

            >>> import numpy as np, cma
            >>> s = cma.ConstRandnShift()
            >>> assert all(s(-s.get(3)) == np.zeros(3))
            >>> assert all(s.get(3) == s(np.zeros(3)))

        """"""
        return self.__call__(np.zeros(dimension))","class ConstRandnShift(object):
    '''``ConstRandnShift()(x)`` adds a fixed realization of
    ``stddev * randn(len(x))`` to the vector x.

    By default, the realized shift is the same for each instance of
    ``ConstRandnShift``, see ``seed`` argument. This class is used in
    class ``FFWrapper.ShiftedFitness`` as default transformation.

    See: class ``FFWrapper.ShiftedFitness``

    '''

    def __init__(self, stddev=3, seed=1):
    '''with ``seed=None`` each instance realizes a different shift'''
        pass

    def __call__(self, x):
    '''return ""shifted"" ``x - shift``

        '''
        pass

    def get(self, dimension):
    '''return shift applied to ``zeros(dimension)``

            >>> import numpy as np, cma
            >>> s = cma.ConstRandnShift()
            >>> assert all(s(-s.get(3)) == np.zeros(3))
            >>> assert all(s.get(3) == s(np.zeros(3)))

        '''
        pass

",4,4,snippet_654,1.0,"class ConstRandnShift(object):
    '''``ConstRandnShift()(x)`` adds a fixed realization of
    ``stddev * randn(len(x))`` to the vector x.

    By default, the realized shift is the same for each instance of
    ``ConstRandnShift``, see ``seed`` argument. This class is used in
    class ``FFWrapper.ShiftedFitness`` as default transformation.

    See: class ``FFWrapper.ShiftedFitness``
    '''

    def __init__(self, stddev=3, seed=1):
        '''with ``seed=None`` each instance realizes a different shift'''
        self.stddev = stddev
        if seed is None:
            self.rng = np.random.RandomState()
        else:
            self.rng = np.random.RandomState(seed)
        self._shifts = {}

    def __call__(self, x):
        '''return ""shifted"" ``x + shift``'''
        x = np.asanyarray(x)
        d = x.shape[0]
        if d not in self._shifts:
            self._shifts[d] = self.stddev * self.rng.randn(d)
        return x + self._shifts[d]

    def get(self, dimension):
        '''return shift applied to ``zeros(dimension)``

                >>> import numpy as np, cma
                >>> s = cma.ConstRandnShift()
                >>> assert all(s(-s.get(3)) == np.zeros(3))
                >>> assert all(s.get(3) == s(np.zeros(3)))

        '''
        if dimension not in self._shifts:
            self._shifts[dimension] = self.stddev * self.rng.randn(dimension)
        return self._shifts[dimension]","class ConstRandnShift(object):
    '''``ConstRandnShift()(x)`` adds a fixed realization of
    ``stddev * randn(len(x))`` to the vector x.

    By default, the realized shift is the same for each instance of
    ``ConstRandnShift``, see ``seed`` argument. This class is used in
    class ``FFWrapper.ShiftedFitness`` as default transformation.

    See: class ``FFWrapper.ShiftedFitness``

    '''

    def __init__(self, stddev=3, seed=1):
        '''with ``seed=None`` each instance realizes a different shift'''
        self.stddev = stddev
        self.seed = seed
        self.shift = None

    def __call__(self, x):
        '''return ""shifted"" ``x - shift``

        '''
        x = np.array(x)
        if self.shift is None or len(self.shift) != len(x):
            if self.seed is not None:
                np.random.seed(self.seed)
            self.shift = self.stddev * np.random.randn(len(x))
        return x - self.shift

    def get(self, dimension):
        '''return shift applied to ``zeros(dimension)``

            >>> import numpy as np, cma
            >>> s = cma.ConstRandnShift()
            >>> assert all(s(-s.get(3)) == np.zeros(3))
            >>> assert all(s.get(3) == s(np.zeros(3)))

        '''
        if self.shift is None or len(self.shift) != dimension:
            if self.seed is not None:
                np.random.seed(self.seed)
            self.shift = self.stddev * np.random.randn(dimension)
        return self.shift","class ConstRandnShift(object):
    '''``ConstRandnShift()(x)`` adds a fixed realization of
    ``stddev * randn(len(x))`` to the vector x.

    By default, the realized shift is the same for each instance of
    ``ConstRandnShift``, see ``seed`` argument. This class is used in
    class ``FFWrapper.ShiftedFitness`` as default transformation.

    See: class ``FFWrapper.ShiftedFitness``

    '''

    def __init__(self, stddev=3, seed=1):
        '''with ``seed=None`` each instance realizes a different shift'''
        self.stddev = stddev
        self.seed = seed
        self._shifts = {}
        
    def __call__(self, x):
        '''return ""shifted"" ``x - shift``

        '''
        x = np.asarray(x)
        dimension = len(x)
        
        if dimension not in self._shifts:
            if self.seed is not None:
                np.random.seed(self.seed + dimension)
            self._shifts[dimension] = self.stddev * np.random.randn(dimension)
            
        return x + self._shifts[dimension]

    def get(self, dimension):
        '''return shift applied to ``zeros(dimension)``

            >>> import numpy as np, cma
            >>> s = cma.ConstRandnShift()
            >>> assert all(s(-s.get(3)) == np.zeros(3))
            >>> assert all(s.get(3) == s(np.zeros(3)))

        '''
        if dimension not in self._shifts:
            if self.seed is not None:
                np.random.seed(self.seed + dimension)
            self._shifts[dimension] = self.stddev * np.random.randn(dimension)
            
        return self._shifts[dimension].copy()",full_docstr,0.7855153203342619,0.6666666666666667,0.5971830985915493,0.7075208913649026,0.665508896705325,0.8502673796791443,0.7292225201072386,0.6505376344086021,0.9143571257591248,0.9210031032562256,0.9176681041717529,0.9203341007232666,0.7835972774869114,0.8409703504043127,0.7262872628726287,0.6376021798365122,0.7493261455525607,0.7152267284667877,0.8740157480314961,0.7736842105263158,0.6965699208443272,0.9428244829177856,0.926097571849823,0.9343862533569336,0.9277434945106506,0.8247440206185567,0.8054054054054054,0.7065217391304348,0.6284153005464481,0.7243243243243244,0.710301804802644,0.8439897698209718,0.7410256410256411,0.6786632390745502,0.9285429120063782,0.9253889322280884,0.926963210105896,0.9257033467292786,0.8082920725388603,0.5354813668528906,0.5647879582011887,0.5949946520675166,0.4583333333333333,0.5238095238095238,0.5867973440672021,0.5447590170422534,0.6045136925598883,0.53125,0.6666666666666666,0.5951518382854859,0.5508476217562833,0.6159700488459778,0.53125,0.6825396825396826
236883,aouyar/PyMunin,aouyar_PyMunin/pysysinfo/redisdb.py,pysysinfo.redisdb.RedisInfo,"class RedisInfo:
    """"""Class that establishes connection to Memcached Instance
    to retrieve statistics on operation.

    """"""

    def __init__(self, host=None, port=None, db=None, password=None, 
                 socket_timeout=None, unix_socket_path=None):
        """"""Initialize connection to Redis.
        
        @param host:             Redis Host.  (Default: localhost)
        @param port:             Redis Port.  (Default: Default Redis Port)
        @param db:               Redis DB ID. (Default: 0)
        @param password:         Redis Password (Optional)
        @param socket_timeout:   Redis Socket Timeout (Default: OS Default.)
        @param unix_socket_path: Socket File Path for UNIX Socket connections.
                                 (Not required unless connection to Redis is 
                                 through named socket.)
        
        """"""
        params = locals()
        self._conn = None
        self._connParams = dict((k, params[k]) 
                                for k in ('host', 'port', 'db', 'password', 
                                          'socket_timeout', 'unix_socket_path')
                                if params[k] is not None)
        self._conn = redis.Redis(**self._connParams)
        
    def ping(self):
        """"""Ping Redis Server and return Round-Trip-Time in seconds.
        
        @return: Round-trip-time in seconds as float.
        
        """"""
        start = time.time()
        self._conn.ping()
        return (time.time() - start)
        
    def getStats(self):
        """"""Query Redis and return stats.
        
        @return: Dictionary of stats.
        
        """"""
        try:
            return self._conn.info('all')
        except TypeError:
            return self._conn.info()","class RedisInfo:
    '''Class that establishes connection to Memcached Instance
    to retrieve statistics on operation.

    '''

    def __init__(self, host=None, port=None, db=None, password=None, 
                 socket_timeout=None, unix_socket_path=None):
    '''Initialize connection to Redis.
        
        @param host:             Redis Host.  (Default: localhost)
        @param port:             Redis Port.  (Default: Default Redis Port)
        @param db:               Redis DB ID. (Default: 0)
        @param password:         Redis Password (Optional)
        @param socket_timeout:   Redis Socket Timeout (Default: OS Default.)
        @param unix_socket_path: Socket File Path for UNIX Socket connections.
                                 (Not required unless connection to Redis is 
                                 through named socket.)
        
        '''
        pass

    def ping(self):
    '''Ping Redis Server and return Round-Trip-Time in seconds.
        
        @return: Round-trip-time in seconds as float.
        
        '''
        pass

    def getStats(self):
    '''Query Redis and return stats.
        
        @return: Dictionary of stats.
        
        '''
        pass

",4,4,snippet_339,0.7,"class RedisInfo:
    '''Class that establishes connection to Redis instance
    to retrieve statistics on operation.
    '''

    def __init__(self, host=None, port=None, db=None, password=None,
                 socket_timeout=None, unix_socket_path=None):
        '''Initialize connection to Redis.
        
        @param host:             Redis Host.  (Default: localhost)
        @param port:             Redis Port.  (Default: 6379)
        @param db:               Redis DB ID. (Default: 0)
        @param password:         Redis Password (Optional)
        @param socket_timeout:   Redis Socket Timeout (Default: OS Default.)
        @param unix_socket_path: Socket File Path for UNIX Socket connections.
                                 (Not required unless connection to Redis is 
                                 through named socket.)
        '''
        self.host = host or 'localhost'
        self.port = port or 6379
        self.db = db or 0
        self.password = password
        self.socket_timeout = socket_timeout
        self.unix_socket_path = unix_socket_path

        if self.unix_socket_path:
            self.client = redis.Redis(
                unix_socket_path=self.unix_socket_path,
                db=self.db,
                password=self.password,
                socket_timeout=self.socket_timeout
            )
        else:
            self.client = redis.Redis(
                host=self.host,
                port=self.port,
                db=self.db,
                password=self.password,
                socket_timeout=self.socket_timeout
            )

    def ping(self):
        '''Ping Redis Server and return Round-Trip-Time in seconds.
        
        @return: Round-trip-time in seconds as float.
        '''
        start = time.perf_counter()
        self.client.ping()
        end = time.perf_counter()
        return end - start

    def getStats(self):
        '''Query Redis and return stats.
        
        @return: Dictionary of stats.
        '''
        return self.client.info()","class RedisInfo:
    '''Class that establishes connection to Memcached Instance
    to retrieve statistics on operation.

    '''

    def __init__(self, host=None, port=None, db=None, password=None, 
                 socket_timeout=None, unix_socket_path=None):
        '''Initialize connection to Redis.
        
        @param host:             Redis Host.  (Default: localhost)
        @param port:             Redis Port.  (Default: Default Redis Port)
        @param db:               Redis DB ID. (Default: 0)
        @param password:         Redis Password (Optional)
        @param socket_timeout:   Redis Socket Timeout (Default: OS Default.)
        @param unix_socket_path: Socket File Path for UNIX Socket connections.
                                 (Not required unless connection to Redis is 
                                 through named socket.)
        
        '''
        self.host = host or 'localhost'
        self.port = port or 6379
        self.db = db or 0
        self.password = password
        self.socket_timeout = socket_timeout
        self.unix_socket_path = unix_socket_path
        
        if unix_socket_path:
            self.redis_client = redis.Redis(
                unix_socket_path=unix_socket_path,
                db=db,
                password=password,
                socket_timeout=socket_timeout
            )
        else:
            self.redis_client = redis.Redis(
                host=self.host,
                port=self.port,
                db=db,
                password=password,
                socket_timeout=socket_timeout
            )

    def ping(self):
        '''Ping Redis Server and return Round-Trip-Time in seconds.
        
        @return: Round-trip-time in seconds as float.
        
        '''
        start_time = time.time()
        self.redis_client.ping()
        end_time = time.time()
        return end_time - start_time

    def getStats(self):
        '''Query Redis and return stats.
        
        @return: Dictionary of stats.
        
        '''
        return self.redis_client.info()","class RedisInfo:
    '''Class that establishes connection to Memcached Instance
    to retrieve statistics on operation.

    '''

    def __init__(self, host=None, port=None, db=None, password=None, 
                 socket_timeout=None, unix_socket_path=None):
        '''Initialize connection to Redis.
        
        @param host:             Redis Host.  (Default: localhost)
        @param port:             Redis Port.  (Default: Default Redis Port)
        @param db:               Redis DB ID. (Default: 0)
        @param password:         Redis Password (Optional)
        @param socket_timeout:   Redis Socket Timeout (Default: OS Default.)
        @param unix_socket_path: Socket File Path for UNIX Socket connections.
                                 (Not required unless connection to Redis is 
                                 through named socket.)
        
        '''
        self.host = host or 'localhost'
        self.port = port or 6379
        self.db = db or 0
        self.password = password
        self.socket_timeout = socket_timeout
        self.unix_socket_path = unix_socket_path
        
        if unix_socket_path:
            self.redis_client = redis.Redis(
                unix_socket_path=unix_socket_path,
                db=self.db,
                password=self.password,
                socket_timeout=self.socket_timeout
            )
        else:
            self.redis_client = redis.Redis(
                host=self.host,
                port=self.port,
                db=self.db,
                password=self.password,
                socket_timeout=self.socket_timeout
            )

    def ping(self):
        '''Ping Redis Server and return Round-Trip-Time in seconds.
        
        @return: Round-trip-time in seconds as float.
        
        '''
        start_time = time.time()
        self.redis_client.ping()
        end_time = time.time()
        return end_time - start_time

    def getStats(self):
        '''Query Redis and return stats.
        
        @return: Dictionary of stats.
        
        '''
        return self.redis_client.info()",full_docstr,0.7462686567164177,0.645,0.5879396984924623,0.7213930348258706,0.563988990920309,0.675392670157068,0.5485564304461942,0.4842105263157895,0.9222830533981323,0.9070107340812683,0.914583146572113,0.9085151553153992,0.8079384285714285,0.7661691542288558,0.6900000000000001,0.6331658291457285,0.7512437810945274,0.5946565522191458,0.6947368421052632,0.5778364116094987,0.5238095238095238,0.9312901496887207,0.9161680936813354,0.9236672520637512,0.917658269405365,0.8144348453608248,0.7549019607843137,0.6798029556650246,0.6237623762376238,0.7401960784313726,0.5764061424063084,0.673469387755102,0.5601023017902813,0.5076923076923077,0.9304198026657104,0.9154753684997559,0.9228870868682861,0.9169481992721558,0.8090633980582523,0.4685144248440934,0.5174473836776531,0.5610336311183155,0.524390243902439,0.2711864406779661,0.4881345472866575,0.5606517559059178,0.61325890120268,0.524390243902439,0.2542372881355932,0.4881345472866575,0.5606517559059178,0.61325890120268,0.524390243902439,0.2542372881355932
188553,SoftwareDefinedBuildings/XBOS,apps/data_analysis/XBOS_data_analytics/Plot_Data.py,XBOS_data_analytics.Plot_Data.Plot_Data,"class Plot_Data:

    """""" This class contains functions for displaying various plots.
   
    Attributes
    ----------
    count    : int
        Keeps track of the number of figures.

    """"""

    # Static variable to keep count of number of figures
    count = 1

    def __init__(self, figsize=(18,5)):
        """""" Constructor.

        Parameters
        ----------
        figsize : tuple
            Size of figure.

        """"""
        self.figsize = figsize


    def correlation_plot(self, data):
        """""" Create heatmap of Pearson's correlation coefficient.

        Parameters
        ----------
        data    : pd.DataFrame()
            Data to display.

        Returns
        -------
        matplotlib.figure
            Heatmap.

        """"""

        # CHECK: Add saved filename in result.json
        fig = plt.figure(Plot_Data.count)
        corr = data.corr()
        ax = sns.heatmap(corr)

        Plot_Data.count += 1
        return fig


    def baseline_projection_plot(self, y_true, y_pred, 
                                baseline_period, projection_period,
                                model_name, adj_r2,
                                data, input_col, output_col, model,
                                site):
        """""" Create baseline and projection plots.

        Parameters
        ----------
        y_true              : pd.Series()
            Actual y values.
        y_pred              : np.ndarray
            Predicted y values.
        baseline_period     : list(str)
            Baseline period.
        projection_period   : list(str)
            Projection periods.
        model_name          : str
            Optimal model's name.
        adj_r2              : float
            Adjusted R2 score of optimal model.
        data                : pd.Dataframe()
            Data containing real values.
        input_col           : list(str)
            Predictor column(s).
        output_col          : str
            Target column.
        model               : func
            Optimal model.

        Returns
        -------
        matplotlib.figure
            Baseline plot

        """"""

        # Baseline and projection plots
        fig = plt.figure(Plot_Data.count)
        
        # Number of plots to display
        if projection_period:
            nrows = len(baseline_period) + len(projection_period) / 2
        else:
            nrows = len(baseline_period) / 2
        
        # Plot 1 - Baseline
        base_df = pd.DataFrame()
        base_df['y_true'] = y_true
        base_df['y_pred'] = y_pred
        ax1 = fig.add_subplot(nrows, 1, 1)
        base_df.plot(ax=ax1, figsize=self.figsize,
            title='Baseline Period ({}-{}). \nBest Model: {}. \nBaseline Adj R2: {}. \nSite: {}.'.format(baseline_period[0], baseline_period[1], 
                                                                                                            model_name, adj_r2, site))

        if projection_period:
            # Display projection plots
            num_plot = 2
            for i in range(0, len(projection_period), 2):
                ax = fig.add_subplot(nrows, 1, num_plot)
                period = (slice(projection_period[i], projection_period[i+1]))
                project_df = pd.DataFrame()
                
                try:    
                    project_df['y_true'] = data.loc[period, output_col]
                    project_df['y_pred'] = model.predict(data.loc[period, input_col])

                    # Set all negative values to zero since energy > 0
                    project_df['y_pred'][project_df['y_pred'] < 0] = 0

                    project_df.plot(ax=ax, figsize=self.figsize, title='Projection Period ({}-{})'.format(projection_period[i], 
                                                                                                        projection_period[i+1]))
                    num_plot += 1
                    fig.tight_layout()

                    Plot_Data.count += 1
                    return fig, project_df['y_true'], project_df['y_pred']
                except:
                    raise SystemError(""If projecting into the future, please specify project_ind_col that has data available \
                                        in the future time period requested."")
           
        return fig, None, None","class Plot_Data:
    ''' This class contains functions for displaying various plots.
   
    Attributes
    ----------
    count    : int
        Keeps track of the number of figures.

    '''

    def __init__(self, figsize=(18,5)):
    ''' Constructor.

        Parameters
        ----------
        figsize : tuple
            Size of figure.

        '''
        pass

    def correlation_plot(self, data):
    ''' Create heatmap of Pearson's correlation coefficient.

        Parameters
        ----------
        data    : pd.DataFrame()
            Data to display.

        Returns
        -------
        matplotlib.figure
            Heatmap.

        '''
        pass

    def baseline_projection_plot(self, y_true, y_pred, 
                                baseline_period, projection_period,
                                model_name, adj_r2,
                                data, input_col, output_col, model,
                                site):
    ''' Create baseline and projection plots.

        Parameters
        ----------
        y_true              : pd.Series()
            Actual y values.
        y_pred              : np.ndarray
            Predicted y values.
        baseline_period     : list(str)
            Baseline period.
        projection_period   : list(str)
            Projection periods.
        model_name          : str
            Optimal model's name.
        adj_r2              : float
            Adjusted R2 score of optimal model.
        data                : pd.Dataframe()
            Data containing real values.
        input_col           : list(str)
            Predictor column(s).
        output_col          : str
            Target column.
        model               : func
            Optimal model.

        Returns
        -------
        matplotlib.figure
            Baseline plot

        '''
        pass

",4,4,snippet_255,0.4,"class Plot_Data:
    ''' This class contains functions for displaying various plots.
   
    Attributes
    ----------
    count    : int
        Keeps track of the number of figures.
    '''

    def __init__(self, figsize=(18,5)):
        ''' Constructor.

        Parameters
        ----------
        figsize : tuple
            Size of figure.
        '''
        self.figsize = figsize
        self.count = 0

    def correlation_plot(self, data):
        ''' Create heatmap of Pearson's correlation coefficient.

        Parameters
        ----------
        data    : pd.DataFrame()
            Data to display.

        Returns
        -------
        matplotlib.figure
            Heatmap.
        '''
        corr = data.corr()
        fig, ax = plt.subplots(figsize=self.figsize)
        sns.heatmap(corr, annot=True, fmt="".2f"", cmap=""coolwarm"", ax=ax,
                    cbar_kws={""shrink"": .8})
        ax.set_title(""Correlation Heatmap"")
        self.count += 1
        return fig

    def baseline_projection_plot(self, y_true, y_pred, 
                                baseline_period, projection_period,
                                model_name, adj_r2,
                                data, input_col, output_col, model,
                                site):
        ''' Create baseline and projection plots.

        Parameters
        ----------
        y_true              : pd.Series()
            Actual y values.
        y_pred              : np.ndarray
            Predicted y values.
        baseline_period     : list(str)
            Baseline period [start, end].
        projection_period   : list(str)
            Projection period [start, end].
        model_name          : str
            Optimal model's name.
        adj_r2              : float
            Adjusted R2 score of optimal model.
        data                : pd.Dataframe()
            Data containing real values.
        input_col           : list(str)
            Predictor column(s).
        output_col          : str
            Target column.
        model               : func
            Optimal model.
        site                : str
            Site identifier.

        Returns
        -------
        matplotlib.figure
            Baseline plot
        '''
        # align predictions to true index
        y_pred_series = pd.Series(y_pred, index=y_true.index)
        # slice baseline and projection
        start_b, end_b = baseline_period
        start_p, end_p = projection_period
        y_true_b = y_true.loc[start_b:end_b]
        y_pred_b = y_pred_series.loc[start_b:end_b]
        y_true_p = y_true.loc[start_p:end_p]
        y_pred_p = y_pred_series.loc[start_p:end_p]

        fig, ax = plt.subplots(figsize=self.figsize)
        # plot baseline
        ax.plot(y_true_b.index, y_true_b.values, label='Actual (Baseline)', color='blue')
        ax.plot(y_pred_b.index, y_pred_b.values, label='Predicted (Baseline)', color='orange')
        # plot projection
        ax.plot(y_pred_p.index, y_pred_p.values, label='Predicted (Projection)', color='red', linestyle='--')
        # if actual for projection exists
        if not y_true_p.empty:
            ax.plot(y_true_p.index, y_true_p.values, label='Actual (Projection)', color='green', linestyle='--')
        # boundary line
        boundary = pd.to_datetime(end_b)
        ax.axvline(boundary, color='gray', linestyle='--', label='Projection Start')
        # labels and title
        ax.set_xlabel(""Date"")
        ax.set_ylabel(output_col)
        title = f""{model_name} | Adjusted R = {adj_r2:.3f}""
        ax.set_title(title)
        # footer text
        txt = (
            f""Site: {site}\n""
            f""Model: {model}\n""
            f""Inputs: {', '.join(input_col)}""
        )
        fig.text(0.02, 0.02, txt, fontsize=9, va='bottom')
        ax.legend(loc='upper left')
        self.count += 1
        return fig","class Plot_Data:
    ''' This class contains functions for displaying various plots.
   
    Attributes
    ----------
    count    : int
        Keeps track of the number of figures.

    '''

    def __init__(self, figsize=(18,5)):
        ''' Constructor.

        Parameters
        ----------
        figsize : tuple
            Size of figure.

        '''
        self.figsize = figsize
        self.count = 0

    def correlation_plot(self, data):
        ''' Create heatmap of Pearson's correlation coefficient.

        Parameters
        ----------
        data    : pd.DataFrame()
            Data to display.

        Returns
        -------
        matplotlib.figure
            Heatmap.

        '''
        self.count += 1
        fig, ax = plt.subplots(figsize=self.figsize)
        
        # Calculate correlation matrix
        corr_matrix = data.corr()
        
        # Create heatmap
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                    square=True, linewidths=0.5, ax=ax)
        ax.set_title('Pearson Correlation Heatmap')
        
        return fig

    def baseline_projection_plot(self, y_true, y_pred, 
                                baseline_period, projection_period,
                                model_name, adj_r2,
                                data, input_col, output_col, model,
                                site):
        ''' Create baseline and projection plots.

        Parameters
        ----------
        y_true              : pd.Series()
            Actual y values.
        y_pred              : np.ndarray
            Predicted y values.
        baseline_period     : list(str)
            Baseline period.
        projection_period   : list(str)
            Projection periods.
        model_name          : str
            Optimal model's name.
        adj_r2              : float
            Adjusted R2 score of optimal model.
        data                : pd.Dataframe()
            Data containing real values.
        input_col           : list(str)
            Predictor column(s).
        output_col          : str
            Target column.
        model               : func
            Optimal model.

        Returns
        -------
        matplotlib.figure
            Baseline plot

        '''
        self.count += 1
        fig, ax = plt.subplots(figsize=self.figsize)
        
        # Convert y_pred to series if it's numpy array
        if isinstance(y_pred, np.ndarray):
            y_pred = pd.Series(y_pred, index=y_true.index)
        
        # Plot actual values
        ax.plot(y_true.index, y_true.values, label='Actual', marker='o', linewidth=2)
        
        # Plot predicted values
        ax.plot(y_pred.index, y_pred.values, label='Predicted', marker='s', linewidth=2)
        
        # Add labels and title
        ax.set_xlabel('Time')
        ax.set_ylabel(output_col)
        ax.set_title(f'{site} - {model_name} Model (Adj R = {adj_r2:.3f})')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Add vertical line to separate baseline and projection periods if both exist
        if baseline_period and projection_period:
            # Find the end of baseline period
            baseline_end = baseline_period[-1] if isinstance(baseline_period, list) else baseline_period
            if baseline_end in y_true.index:
                ax.axvline(x=baseline_end, color='red', linestyle='--', alpha=0.7, 
                          label='Baseline/Projection Boundary')
        
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        return fig","class Plot_Data:
    ''' This class contains functions for displaying various plots.
   
    Attributes
    ----------
    count    : int
        Keeps track of the number of figures.

    '''

    def __init__(self, figsize=(18,5)):
        ''' Constructor.

        Parameters
        ----------
        figsize : tuple
            Size of figure.

        '''
        self.figsize = figsize
        self.count = 0

    def correlation_plot(self, data):
        ''' Create heatmap of Pearson's correlation coefficient.

        Parameters
        ----------
        data    : pd.DataFrame()
            Data to display.

        Returns
        -------
        matplotlib.figure
            Heatmap.

        '''
        self.count += 1
        fig, ax = plt.subplots(figsize=self.figsize)
        correlation_matrix = data.corr()
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)
        plt.title('Correlation Heatmap')
        plt.tight_layout()
        return fig

    def baseline_projection_plot(self, y_true, y_pred, 
                                baseline_period, projection_period,
                                model_name, adj_r2,
                                data, input_col, output_col, model,
                                site):
        ''' Create baseline and projection plots.

        Parameters
        ----------
        y_true              : pd.Series()
            Actual y values.
        y_pred              : np.ndarray
            Predicted y values.
        baseline_period     : list(str)
            Baseline period.
        projection_period   : list(str)
            Projection periods.
        model_name          : str
            Optimal model's name.
        adj_r2              : float
            Adjusted R2 score of optimal model.
        data                : pd.Dataframe()
            Data containing real values.
        input_col           : list(str)
            Predictor column(s).
        output_col          : str
            Target column.
        model               : func
            Optimal model.

        Returns
        -------
        matplotlib.figure
            Baseline plot

        '''
        self.count += 1
        fig, ax = plt.subplots(figsize=self.figsize)
        
        # Plot actual values
        ax.plot(y_true.index, y_true.values, label='Actual', color='blue', linewidth=2)
        
        # Plot predicted values
        ax.plot(y_true.index, y_pred, label='Predicted', color='red', linestyle='--', linewidth=2)
        
        # Add vertical lines for baseline and projection periods
        if baseline_period:
            ax.axvline(pd.to_datetime(baseline_period[0]), color='green', linestyle=':', alpha=0.7, label='Baseline Start')
            ax.axvline(pd.to_datetime(baseline_period[1]), color='green', linestyle=':', alpha=0.7, label='Baseline End')
        
        if projection_period:
            ax.axvline(pd.to_datetime(projection_period[0]), color='orange', linestyle=':', alpha=0.7, label='Projection Start')
            ax.axvline(pd.to_datetime(projection_period[1]), color='orange', linestyle=':', alpha=0.7, label='Projection End')
        
        ax.set_xlabel('Date')
        ax.set_ylabel(output_col)
        ax.set_title(f'{model_name} - {site} (Adj R: {adj_r2:.3f})')
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        
        return fig",full_docstr,0.5963302752293579,0.43218390804597695,0.359447004608295,0.4908256880733945,0.4570995540406521,0.6838407494145199,0.41031652989449,0.3403755868544601,0.8546993136405945,0.8672093152999878,0.8609088659286499,0.8659419417381287,0.7696001226993868,0.6608910891089109,0.4813895781637717,0.39552238805970147,0.5123762376237624,0.45144999879173037,0.7732732732732732,0.5323308270676692,0.45180722891566266,0.8726671934127808,0.8704537153244019,0.8715590238571167,0.8706745505332947,0.7676542118226602,0.6404066073697585,0.4815286624203822,0.4086845466155811,0.5260482846251588,0.47074551588304836,0.7822222222222223,0.5534124629080118,0.4635958395245171,0.8764562606811523,0.8769525289535522,0.8767043352127075,0.8769028782844543,0.7600024000000004,0.3863745909012019,0.3963841800734452,0.4029877609343516,0.374331550802139,0.3717948717948718,0.3706403174675046,0.4056725358173679,0.4173179127171232,0.3582887700534759,0.3012820512820512,0.3726785717256806,0.3833086008457516,0.4114986519146425,0.3689839572192513,0.3269230769230769
1749,ANTsX/ANTsPy,ants/contrib/sampling/affine2d.py,ants.contrib.sampling.affine2d.Translate2D,"class Translate2D(object):
    """"""
    Create an ANTs Affine Transform with a specified translation.
    """"""

    def __init__(self, translation, reference=None, lazy=False):
        """"""
        Initialize a Translate2D object

        Arguments
        ---------
        translation : list or tuple
            translation values for each axis, in degrees.
            Negative values can be used for translation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        """"""
        if (not isinstance(translation, (list, tuple))) or (len(translation) != 2):
            raise ValueError(""translation argument must be list/tuple with two values!"")

        self.translation = translation
        self.lazy = lazy
        self.reference = reference

        self.tx = tio.ANTsTransform(
            precision=""float"", dimension=2, transform_type=""AffineTransform""
        )
        if self.reference is not None:
            self.tx.set_fixed_parameters(self.reference.get_center_of_mass())

    def transform(self, X=None, y=None):
        """"""
        Transform an image using an Affine transform with the given
        translation parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Translate2D(translation=(10,0))
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(-10,0)) # other direction
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(0,10))
        >>> img2_z = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(10,10))
        >>> img2 = tx.transform(img)
        """"""
        # convert to radians and unpack
        translation_x, translation_y = self.translation

        translation_matrix = np.array([[1, 0, translation_x], [0, 1, translation_y]])
        self.tx.set_parameters(translation_matrix)
        if self.lazy or X is None:
            return self.tx
        else:
            if y is None:
                return self.tx.apply_to_image(X, reference=self.reference)
            else:
                return (
                    self.tx.apply_to_image(X, reference=self.reference),
                    self.tx.apply_to_image(y, reference=self.reference),
                )","class Translate2D(object):
    '''
    Create an ANTs Affine Transform with a specified translation.
    '''

    def __init__(self, translation, reference=None, lazy=False):
    '''
        Initialize a Translate2D object

        Arguments
        ---------
        translation : list or tuple
            translation values for each axis, in degrees.
            Negative values can be used for translation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        pass

    def transform(self, X=None, y=None):
    '''
        Transform an image using an Affine transform with the given
        translation parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Translate2D(translation=(10,0))
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(-10,0)) # other direction
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(0,10))
        >>> img2_z = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(10,10))
        >>> img2 = tx.transform(img)
        '''
        pass

",3,3,snippet_9,0.4285714285714285,"class Translate2D(object):
    '''
    Create an ANTs Affine Transform with a specified translation.
    '''

    def __init__(self, translation, reference=None, lazy=False):
        '''
            Initialize a Translate2D object

            Arguments
            ---------
            translation : list or tuple
                translation values for each axis, in degrees.
                Negative values can be used for translation in the
                other direction

            reference : ANTsImage (optional but recommended)
                image providing the reference space for the transform.
                this will also set the transform fixed parameters.

            lazy : boolean (default = False)
                if True, calling the `transform` method only returns
                the randomly generated transform and does not actually
                transform the image
        '''
        self.translation = tuple(translation)
        if len(self.translation) != 2:
            raise ValueError(""Translate2D requires a 2-element translation."")
        self.reference = reference
        self.lazy = lazy

        # build affine transform parameters for 2D: [rot, tx, ty, sx, sy, skew]
        params = [0.0,
                  float(self.translation[0]),
                  float(self.translation[1]),
                  1.0, 1.0,
                  0.0]

        # fixed parameters: center of reference image
        if self.reference is not None:
            origin = np.array(self.reference.origin)
            spacing = np.array(self.reference.spacing)
            shape = np.array(self.reference.shape)
            center_index = (shape - 1) / 2.0
            phys_center = origin + spacing * center_index
            fixed_params = list(phys_center)
        else:
            fixed_params = None

        # create the ANTs affine transform
        self._transform = ants.create_ants_transform(
            transformtype='AffineTransform',
            dimension=2,
            parameters=params,
            fixed_parameters=fixed_params
        )

    def transform(self, X=None, y=None):
        '''
            Transform an image using an Affine transform with the given
            translation parameters.  Return the transform if X=None.

            Arguments
            ---------
            X : ANTsImage
                Image to transform

            y : ANTsImage (optional)
                Another image to transform

            Returns
            -------
            ANTsImage if y is None, else a tuple of ANTsImage types
        '''
        if X is None or self.lazy:
            return self._transform

        if self.reference is None:
            raise ValueError(""A reference image must be provided to apply the transform."")

        out_x = ants.apply_ants_transform_to_image(self._transform, X, self.reference)
        if y is None:
            return out_x
        out_y = ants.apply_ants_transform_to_image(self._transform, y, self.reference)
        return out_x, out_y","class Translate2D(object):
    '''
    Create an ANTs Affine Transform with a specified translation.
    '''

    def __init__(self, translation, reference=None, lazy=False):
        '''
        Initialize a Translate2D object

        Arguments
        ---------
        translation : list or tuple
            translation values for each axis, in degrees.
            Negative values can be used for translation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        self.translation = translation
        self.reference = reference
        self.lazy = lazy
        
        # Create the affine transform
        self.transform_obj = ants.create_ants_transform(
            transform_type='AffineTransform',
            precision='float',
            dimension=2
        )
        
        # Set the translation parameters
        # For affine transform, parameters are [cos, -sin, sin, cos, tx, ty]
        # For pure translation: [1, 0, 0, 1, tx, ty]
        tx, ty = translation
        parameters = [1, 0, 0, 1, tx, ty]
        self.transform_obj.set_parameters(parameters)
        
        # Set fixed parameters if reference is provided
        if reference is not None:
            self.transform_obj.set_fixed_parameters(reference.get_origin())

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        translation parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Translate2D(translation=(10,0))
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(-10,0)) # other direction
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(0,10))
        >>> img2_z = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(10,10))
        >>> img2 = tx.transform(img)
        '''
        if X is None:
            return self.transform_obj
            
        if self.lazy:
            return self.transform_obj
            
        # Apply transform to X
        X_transformed = ants.apply_ants_transform_to_image(
            self.transform_obj, X, reference=X
        )
        
        if y is None:
            return X_transformed
        else:
            # Apply transform to y
            y_transformed = ants.apply_ants_transform_to_image(
                self.transform_obj, y, reference=y
            )
            return (X_transformed, y_transformed)","class Translate2D(object):
    '''
    Create an ANTs Affine Transform with a specified translation.
    '''

    def __init__(self, translation, reference=None, lazy=False):
        '''
        Initialize a Translate2D object

        Arguments
        ---------
        translation : list or tuple
            translation values for each axis, in degrees.
            Negative values can be used for translation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        import ants
        
        self.translation = translation
        self.reference = reference
        self.lazy = lazy
        
        # Create the affine transform
        self.tx = ants.new_ants_transform(precision='float', dimension=2, transform_type='AffineTransform')
        
        # Set translation parameters (identity matrix with translation)
        # For 2D affine: [m11, m12, m21, m22, tx, ty]
        params = [1.0, 0.0, 0.0, 1.0, float(translation[0]), float(translation[1])]
        self.tx.set_parameters(params)
        
        # Set fixed parameters if reference is provided
        if reference is not None:
            # Fixed parameters are the center of rotation (origin)
            center = [0.0, 0.0]
            self.tx.set_fixed_parameters(center)

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        translation parameters.  Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Translate2D(translation=(10,0))
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(-10,0)) # other direction
        >>> img2_x = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(0,10))
        >>> img2_z = tx.transform(img)
        >>> tx = ants.contrib.Translate2D(translation=(10,10))
        >>> img2 = tx.transform(img)
        '''
        import ants
        
        if X is None:
            return self.tx
            
        if self.lazy:
            return self.tx
            
        reference_image = self.reference if self.reference is not None else X
        
        X_transformed = ants.apply_ants_transform_to_image(self.tx, X, reference_image)
        
        if y is not None:
            y_transformed = ants.apply_ants_transform_to_image(self.tx, y, reference_image)
            return (X_transformed, y_transformed)
        
        return X_transformed",full_docstr,0.7601809954751132,0.5446293494704991,0.45523520485584223,0.5671191553544495,0.5187295942999363,0.8116760828625236,0.5811320754716981,0.4706994328922495,0.8975266814231873,0.8825805187225342,0.8899908661842346,0.8840526938438416,0.7702403928571436,0.8192419825072886,0.6929824561403509,0.6334310850439883,0.7172011661807579,0.7200487371049601,0.8265139116202946,0.7032786885245902,0.6486042692939245,0.9293110370635986,0.926527202129364,0.9279170036315918,0.9268048405647278,0.798583574468085,0.837410071942446,0.7157287157287157,0.6454413892908829,0.7280575539568345,0.7340567019032664,0.8524590163934426,0.7175697865353038,0.65625,0.9261572360992432,0.9311691522598267,0.9286564588546753,0.9306654930114746,0.7886545957446808,0.5243248770538431,0.5285847508737384,0.5627708938303518,0.4869565217391304,0.5189873417721519,0.6128007072434313,0.620867820102059,0.7065045190532844,0.4782608695652174,0.6455696202531646,0.5866107126914762,0.6258446510290926,0.7099212597258052,0.5043478260869565,0.5063291139240507
181804,Robpol86/libnl,Robpol86_libnl/libnl/netlink_private/cache_api.py,libnl.netlink_private.cache_api.nl_msgtype,"class nl_msgtype(object):
    """"""Message type to cache action association.

    https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/cache-api.h#L117

    Positional arguments:
    mt_id -- Netlink message type (c_int).
    mt_act -- cache action to take (c_int).
    mt_name -- name of operation for human-readable printing (string).
    """"""

    def __init__(self, mt_id, mt_act, mt_name):
        """"""Constructor.""""""
        self.mt_id = mt_id
        self.mt_act = mt_act
        self.mt_name = mt_name

    def __repr__(self):
        """"""repr() handler.""""""
        answer = ""<{0}.{1} mt_id={2} mt_act={3} mt_name='{4}'>"".format(
            self.__class__.__module__,
            self.__class__.__name__,
            self.mt_id, self.mt_act, self.mt_name,
        )
        return answer","class nl_msgtype(object):
    '''Message type to cache action association.

    https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/cache-api.h#L117

    Positional arguments:
    mt_id -- Netlink message type (c_int).
    mt_act -- cache action to take (c_int).
    mt_name -- name of operation for human-readable printing (string).
    '''

    def __init__(self, mt_id, mt_act, mt_name):
    '''Constructor.'''
        pass

    def __repr__(self):
    '''repr() handler.'''
        pass

",3,3,snippet_242,1.0,"class nl_msgtype(object):
    '''Message type to cache action association.

    https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/cache-api.h#L117

    Positional arguments:
    mt_id -- Netlink message type (c_int).
    mt_act -- cache action to take (c_int).
    mt_name -- name of operation for human-readable printing (string).
    '''

    def __init__(self, mt_id, mt_act, mt_name):
        '''Constructor.'''
        self.mt_id = mt_id
        self.mt_act = mt_act
        self.mt_name = mt_name

    def __repr__(self):
        '''repr() handler.'''
        return (
            f""{self.__class__.__name__}(""
            f""mt_id={self.mt_id!r}, ""
            f""mt_act={self.mt_act!r}, ""
            f""mt_name={self.mt_name!r})""
        )","class nl_msgtype(object):
    '''Message type to cache action association.

    https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/cache-api.h#L117

    Positional arguments:
    mt_id -- Netlink message type (c_int).
    mt_act -- cache action to take (c_int).
    mt_name -- name of operation for human-readable printing (string).
    '''

    def __init__(self, mt_id, mt_act, mt_name):
        '''Constructor.'''
        self.mt_id = mt_id
        self.mt_act = mt_act
        self.mt_name = mt_name

    def __repr__(self):
        '''repr() handler.'''
        return f""nl_msgtype(mt_id={self.mt_id}, mt_act={self.mt_act}, mt_name='{self.mt_name}')""","class nl_msgtype(object):
    '''Message type to cache action association.

    https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/cache-api.h#L117

    Positional arguments:
    mt_id -- Netlink message type (c_int).
    mt_act -- cache action to take (c_int).
    mt_name -- name of operation for human-readable printing (string).
    '''

    def __init__(self, mt_id, mt_act, mt_name):
        '''Constructor.'''
        self.mt_id = mt_id
        self.mt_act = mt_act
        self.mt_name = mt_name

    def __repr__(self):
        '''repr() handler.'''
        return f""nl_msgtype(mt_id={self.mt_id}, mt_act={self.mt_act}, mt_name='{self.mt_name}')""",full_docstr,0.918918918918919,0.8727272727272727,0.8256880733944955,0.8558558558558558,0.7127590744679081,0.922077922077922,0.7869565217391304,0.7379912663755459,0.968205988407135,0.9633089303970337,0.9657512307167053,0.9637963771820068,0.8701767368421052,0.9209302325581395,0.8826291079812207,0.8436018957345972,0.8744186046511628,0.6513139789136528,0.9558823529411765,0.8472906403940886,0.7920792079207921,0.9812359809875488,0.952883780002594,0.9668521285057068,0.9556450843811035,0.9087310714285715,0.9209302325581395,0.8826291079812207,0.8436018957345972,0.8744186046511628,0.6513139789136528,0.9558823529411765,0.8472906403940886,0.7920792079207921,0.9812359809875488,0.952883780002594,0.9668521285057068,0.9556450843811035,0.9087310714285715,0.5991934262931333,0.6478376050031437,0.6642966017367874,0.6363636363636364,0.4482758620689655,0.5813270400951429,0.6391175901529066,0.6621571324011238,0.5757575757575758,0.4482758620689655,0.5813270400951429,0.6391175901529066,0.6621571324011238,0.5757575757575758,0.4482758620689655
109253,Clinical-Genomics/scout,Clinical-Genomics_scout/scout/adapter/mongo/case_group.py,scout.adapter.mongo.case_group.CaseGroupHandler,"class CaseGroupHandler(object):
    """"""Part of the pymongo adapter that handles case groups.
    Case groups are sets of cases with a common group id, for which user assessments are shared.
    """"""

    def init_case_group(self, owner):
        """"""Initialize a case group, creating entry and marking paired case as belonging to group.

        Args:
          owner(str): institute id
        """"""

        result = self.case_group_collection.insert_one({""owner"": owner, ""label"": ""Group""})

        return result.inserted_id

    def remove_case_group(self, case_group_id):
        """"""Remove a case group.

        Args:
            case_group_id
        """"""
        result = self.case_group_collection.find_one_and_delete({""_id"": case_group_id})

        return result

    def case_group_label(self, case_group_id):
        """"""Return case group label for case_group.

        Args:
            case_group_id(ObjectId)
        """"""
        result = self.case_group_collection.find_one({""_id"": case_group_id}, {""label"": 1})
        label = result.get(""label"", ""unlabeled"")

        return label

    def case_group_update_label(self, case_group_id, case_group_label):
        """"""Change case group label.

        Args:
            case_group_id(ObjectId)
            case_group_label(str)
        """"""
        result = self.case_group_collection.find_one_and_update(
            {""_id"": case_group_id},
            {""$set"": {""label"": case_group_label}},
        )
        return result","class CaseGroupHandler(object):
    '''Part of the pymongo adapter that handles case groups.
    Case groups are sets of cases with a common group id, for which user assessments are shared.
    '''

    def init_case_group(self, owner):
    '''Initialize a case group, creating entry and marking paired case as belonging to group.

        Args:
          owner(str): institute id
        '''
        pass

    def remove_case_group(self, case_group_id):
    '''Remove a case group.

        Args:
            case_group_id
        '''
        pass

    def case_group_label(self, case_group_id):
    '''Return case group label for case_group.

        Args:
            case_group_id(ObjectId)
        '''
        pass

    def case_group_update_label(self, case_group_id, case_group_label):
    '''Change case group label.

        Args:
            case_group_id(ObjectId)
            case_group_label(str)
        '''
        pass

",5,5,snippet_67,1.0,"class CaseGroupHandler(object):
    '''Part of the pymongo adapter that handles case groups.
    Case groups are sets of cases with a common group id, for which user assessments are shared.
    '''

    def __init__(self, db):
        self.db = db
        self.case_groups = db.case_groups
        self.cases = db.cases

    def init_case_group(self, owner):
        '''Initialize a case group, creating entry and marking paired case as belonging to group.

        Args:
          owner(str): institute id
        '''
        now = datetime.utcnow()
        entry = {
            'owner': owner,
            'label': '',
            'created_at': now,
            'updated_at': now
        }
        result = self.case_groups.insert_one(entry)
        group_id = result.inserted_id
        # mark paired cases as belonging to this new group
        self.cases.update_many(
            {'owner': owner, 'paired_case': True},
            {'$set': {'case_group_id': group_id, 'updated_at': now}}
        )
        return group_id

    def remove_case_group(self, case_group_id):
        '''Remove a case group.

        Args:
            case_group_id
        '''
        if not isinstance(case_group_id, ObjectId):
            case_group_id = ObjectId(case_group_id)
        # delete group
        self.case_groups.delete_one({'_id': case_group_id})
        # unset group from cases
        self.cases.update_many(
            {'case_group_id': case_group_id},
            {'$unset': {'case_group_id': ''}, '$set': {'updated_at': datetime.utcnow()}}
        )

    def case_group_label(self, case_group_id):
        '''Return case group label for case_group.

        Args:
            case_group_id(ObjectId)
        '''
        if not isinstance(case_group_id, ObjectId):
            case_group_id = ObjectId(case_group_id)
        doc = self.case_groups.find_one({'_id': case_group_id}, {'label': 1})
        return doc.get('label') if doc else None

    def case_group_update_label(self, case_group_id, case_group_label):
        '''Change case group label.

        Args:
            case_group_id(ObjectId)
            case_group_label(str)
        '''
        if not isinstance(case_group_id, ObjectId):
            case_group_id = ObjectId(case_group_id)
        self.case_groups.update_one(
            {'_id': case_group_id},
            {'$set': {'label': case_group_label, 'updated_at': datetime.utcnow()}}
        )","class CaseGroupHandler(object):
    '''Part of the pymongo adapter that handles case groups.
    Case groups are sets of cases with a common group id, for which user assessments are shared.
    '''

    def __init__(self, database):
        '''Initialize the handler with a database connection.
        
        Args:
            database: pymongo database instance
        '''
        self.db = database
        self.case_groups = self.db.case_groups
        self.cases = self.db.cases

    def init_case_group(self, owner):
        '''Initialize a case group, creating entry and marking paired case as belonging to group.

        Args:
          owner(str): institute id
        '''
        from bson import ObjectId
        
        # Create a new case group
        case_group_doc = {
            'owner': owner,
            'label': 'Unnamed Group',
            'created_at': datetime.utcnow(),
            'cases': []
        }
        
        result = self.case_groups.insert_one(case_group_doc)
        return result.inserted_id

    def remove_case_group(self, case_group_id):
        '''Remove a case group.

        Args:
            case_group_id
        '''
        from bson import ObjectId
        
        if isinstance(case_group_id, str):
            case_group_id = ObjectId(case_group_id)
            
        # Remove the case group
        result = self.case_groups.delete_one({'_id': case_group_id})
        
        # Also remove references to this group from cases
        self.cases.update_many(
            {'case_group': case_group_id},
            {'$unset': {'case_group': ''}}
        )
        
        return result.deleted_count

    def case_group_label(self, case_group_id):
        '''Return case group label for case_group.

        Args:
            case_group_id(ObjectId)
        '''
        from bson import ObjectId
        
        if isinstance(case_group_id, str):
            case_group_id = ObjectId(case_group_id)
            
        case_group = self.case_groups.find_one({'_id': case_group_id})
        if case_group:
            return case_group.get('label', 'Unnamed Group')
        return None

    def case_group_update_label(self, case_group_id, case_group_label):
        '''Change case group label.

        Args:
            case_group_id(ObjectId)
            case_group_label(str)
        '''
        from bson import ObjectId
        
        if isinstance(case_group_id, str):
            case_group_id = ObjectId(case_group_id)
            
        result = self.case_groups.update_one(
            {'_id': case_group_id},
            {'$set': {'label': case_group_label}}
        )
        return result.modified_count","class CaseGroupHandler(object):
    '''Part of the pymongo adapter that handles case groups.
    Case groups are sets of cases with a common group id, for which user assessments are shared.
    '''

    def __init__(self):
        self.case_groups = {}
        self.next_id = 1

    def init_case_group(self, owner):
        '''Initialize a case group, creating entry and marking paired case as belonging to group.

        Args:
          owner(str): institute id
        '''
        case_group_id = self.next_id
        self.next_id += 1
        
        self.case_groups[case_group_id] = {
            'owner': owner,
            'label': f'Case Group {case_group_id}',
            'cases': []
        }
        
        return case_group_id

    def remove_case_group(self, case_group_id):
        '''Remove a case group.

        Args:
            case_group_id
        '''
        if case_group_id in self.case_groups:
            del self.case_groups[case_group_id]

    def case_group_label(self, case_group_id):
        '''Return case group label for case_group.

        Args:
            case_group_id(ObjectId)
        '''
        if case_group_id in self.case_groups:
            return self.case_groups[case_group_id]['label']
        return None

    def case_group_update_label(self, case_group_id, case_group_label):
        '''Change case group label.

        Args:
            case_group_id(ObjectId)
            case_group_label(str)
        '''
        if case_group_id in self.case_groups:
            self.case_groups[case_group_id]['label'] = case_group_label",full_docstr,0.6831275720164609,0.6033057851239669,0.5269709543568465,0.6419753086419752,0.43916831390821803,0.5170068027210885,0.434412265758092,0.3771331058020478,0.8755435943603516,0.9379252791404724,0.9056614637374878,0.9312899112701416,0.7945226027397256,0.6841046277665996,0.61010101010101,0.5395537525354969,0.6478873239436621,0.4669268985027472,0.544973544973545,0.4628975265017668,0.40353982300884955,0.8827540278434753,0.94375079870224,0.9122339487075806,0.9372744560241699,0.8186441641337392,0.782608695652174,0.6889460154241646,0.5994832041343668,0.7570332480818416,0.5778807347660101,0.7452054794520548,0.5851648351648352,0.5261707988980716,0.9237596988677979,0.9063562154769897,0.9149752259254456,0.908066987991333,0.7839872625698328,0.4762608131758535,0.3101637888501238,0.5296163059585535,0.6052631578947368,0.46,0.4807289415369788,0.301135695320638,0.5570432287220144,0.6447368421052632,0.42,0.3847132694963631,0.4601271655410927,0.5239890703390969,0.3947368421052631,0.16
170929,PyCQA/pylint,tests/functional/t/too/too_few_public_methods.py,functional.t.too.too_few_public_methods.Klass,"class Klass:
    """"""docstring""""""

    def meth1(self):
        """"""first""""""

    def meth2(self):
        """"""second""""""","class Klass:
    '''docstring'''

    def meth1(self):
    '''first'''
        pass

    def meth2(self):
    '''second'''
        pass

",3,3,snippet_221,1.0,"class Klass:
    '''docstring'''

    def meth1(self):
        '''first'''
        return ""first""

    def meth2(self):
        '''second'''
        return ""second""","class Klass:
    '''docstring'''

    def meth1(self):
        '''first'''
        pass

    def meth2(self):
        '''second'''
        pass","class Klass:
    '''docstring'''

    def meth1(self):
        '''first'''
        pass

    def meth2(self):
        '''second'''
        pass",full_docstr,0.846153846153846,0.8333333333333333,0.7272727272727274,0.846153846153846,0.452290500815377,0.8148148148148148,0.6923076923076923,0.52,0.9532778263092041,0.9830461740493774,0.967933177947998,0.9799858331680298,0.9145307692307691,0.9166666666666666,0.8181818181818182,0.7000000000000001,0.9166666666666666,0.2870237905995852,0.7619047619047619,0.65,0.5263157894736842,0.9521157741546631,0.9900038242340088,0.9706902503967285,0.9860799312591553,0.9784948387096775,0.9166666666666666,0.8181818181818182,0.7000000000000001,0.9166666666666666,0.2870237905995852,0.7619047619047619,0.65,0.5263157894736842,0.9521157741546631,0.9900038242340088,0.9706902503967285,0.9860799312591553,0.9784948387096775,0.3590390019555244,0.0569100288012269,0.0935316933065849,0.2857142857142857,1.0,0.3620729274634041,0.0690457308327456,0.0935316933065849,0.2857142857142857,1.0,0.3620729274634041,0.0690457308327456,0.0935316933065849,0.2857142857142857,1.0
369637,estnltk/estnltk,estnltk/estnltk/storage/postgres/queries/query.py,estnltk.storage.postgres.queries.query.Node,"class Node:
    """"""Base class for operations and leaf nodes""""""

    def __and__(self, other):
        """"""And operation with ""&"" operator""""""
        return And(self, other)

    def __or__(self, other):
        """"""Or operation with ""|"" operator""""""
        return Or(self, other)

    def eval(self, collection: 'PgCollection'):
        """"""Operations and leaf nodes should implement it""""""
        raise NotImplemented()","class Node:
    '''Base class for operations and leaf nodes'''

    def __and__(self, other):
    '''And operation with ""&"" operator'''
        pass

    def __or__(self, other):
    '''Or operation with ""|"" operator'''
        pass

    def eval(self, collection: 'PgCollection'):
    '''Operations and leaf nodes should implement it'''
        pass

",4,4,snippet_636,1.0,"class Node(ABC):
    '''Base class for operations and leaf nodes'''

    def __and__(self, other):
        if not isinstance(other, Node):
            return NotImplemented
        return And(self, other)

    def __rand__(self, other):
        if not isinstance(other, Node):
            return NotImplemented
        return And(other, self)

    def __or__(self, other):
        if not isinstance(other, Node):
            return NotImplemented
        return Or(self, other)

    def __ror__(self, other):
        if not isinstance(other, Node):
            return NotImplemented
        return Or(other, self)

    @abstractmethod
    def eval(self, collection: 'PgCollection'):
        '''Operations and leaf nodes should implement it'''
        raise NotImplementedError","class Node:
    '''Base class for operations and leaf nodes'''

    def __and__(self, other):
        '''And operation with ""&"" operator'''
        return AndNode(self, other)

    def __or__(self, other):
        '''Or operation with ""|"" operator'''
        return OrNode(self, other)

    def eval(self, collection: 'PgCollection'):
        '''Operations and leaf nodes should implement it'''
        raise NotImplementedError(""Subclasses must implement eval method"")","class Node:
    '''Base class for operations and leaf nodes'''

    def __and__(self, other):
        '''And operation with ""&"" operator'''
        return AndNode(self, other)

    def __or__(self, other):
        '''Or operation with ""|"" operator'''
        return OrNode(self, other)

    def eval(self, collection: 'PgCollection'):
        '''Operations and leaf nodes should implement it'''
        raise NotImplementedError(""Subclasses must implement eval method"")",full_docstr,0.6212121212121212,0.523076923076923,0.4375,0.5757575757575757,0.36631637253306754,0.43870967741935485,0.35714285714285715,0.3137254901960784,0.8311707973480225,0.8862447738647461,0.8578247427940369,0.8804111480712891,0.8044096694214875,0.8888888888888888,0.845360824742268,0.8,0.8888888888888888,0.5668662239797952,0.8241758241758241,0.6666666666666666,0.5842696629213483,0.9597345590591431,0.9878668785095215,0.973597526550293,0.9849795699119568,0.9803923529411764,0.8888888888888888,0.845360824742268,0.8,0.8888888888888888,0.5668662239797952,0.8241758241758241,0.6666666666666666,0.5842696629213483,0.9597345590591431,0.9878668785095215,0.973597526550293,0.9849795699119568,0.9803923529411764,0.525732322637831,0.222957585408611,0.3799717051427127,0.5,1.0,0.6046747858101051,0.3513284453381449,0.4007040312356089,0.6666666666666666,1.0,0.6046747858101051,0.3513284453381449,0.4007040312356089,0.6666666666666666,1.0
274965,bsmithyman/galoshes,bsmithyman_galoshes/galoshes/meta.py,galoshes.meta.SCFilter,"class SCFilter(object):
    '''
    A SCFilter class is initialized with a list of classes as arguments.
    For any of those classes that are AttributeMapper subclasses, SCFilter
    determines the required fields in their initMap trees, and the optional
    fields. When called, the SCFilter discards any key in the passed dictionary
    that does not match one of those fields, and raises an error if any of the
    required fields are not present.
    '''

    def __init__(self, clslist):
        '''
        SCFilter(clslist)

        Args:
            clslist (list): List of classes from which to build the filter

        Returns:
            new SCFilter instance
        '''

        if not hasattr(clslist, '__contains__'):
            clslist = [clslist]

        self.required = reduce(set.union, (cls.required for cls in clslist if issubclass(cls, AttributeMapper)))
        self.optional = reduce(set.union, (cls.optional for cls in clslist if issubclass(cls, AttributeMapper)))
        self.optional.symmetric_difference_update(self.required)

    def __call__(self, systemConfig):
        '''
        Args:
            systemConfig (dict): A systemConfig dictionary to filter

        Returns:
            dict: Filtered dictionary

        Raises:
            ValueError: If a required key is not in the systemConfig
        '''

        for key in self.required:
            if key not in systemConfig:
                raise ValueError('{0!s} requires parameter \'{1!s}\''.format(cls.__name__, key))

        return {key: systemConfig[key] for key in set.union(self.required, self.optional) if key in systemConfig}","class SCFilter(object):
    '''
    A SCFilter class is initialized with a list of classes as arguments.
    For any of those classes that are AttributeMapper subclasses, SCFilter
    determines the required fields in their initMap trees, and the optional
    fields. When called, the SCFilter discards any key in the passed dictionary
    that does not match one of those fields, and raises an error if any of the
    required fields are not present.
    '''

    def __init__(self, clslist):
    '''
        SCFilter(clslist)

        Args:
            clslist (list): List of classes from which to build the filter

        Returns:
            new SCFilter instance
        '''
        pass

    def __call__(self, systemConfig):
    '''
        Args:
            systemConfig (dict): A systemConfig dictionary to filter

        Returns:
            dict: Filtered dictionary

        Raises:
            ValueError: If a required key is not in the systemConfig
        '''
        pass

",3,3,snippet_457,0.2,"class SCFilter(object):
    '''
    A SCFilter class is initialized with a list of classes as arguments.
    For any of those classes that are AttributeMapper subclasses, SCFilter
    determines the required fields in their initMap trees, and the optional
    fields. When called, the SCFilter discards any key in the passed dictionary
    that does not match one of those fields, and raises an error if any of the
    required fields are not present.
    '''
    def __init__(self, clslist):
        self._required = set()
        self._optional = set()
        # gather fields from all AttributeMapper subclasses
        for cls in clslist:
            try:
                if issubclass(cls, AttributeMapper):
                    init_map = getattr(cls, 'initMap', {})
                    self._parse_map(init_map)
            except Exception:
                continue
        self._all = self._required.union(self._optional)

    def _parse_map(self, mp):
        """"""
        Recursively parse an initMap tree assumed to be a dict
        mapping field names to dicts with optional 'required' bool
        and optional nested dicts.
        """"""
        if not isinstance(mp, dict):
            return
        for key, val in mp.items():
            if isinstance(val, dict):
                req = val.get('required', False)
                if req:
                    self._required.add(key)
                else:
                    self._optional.add(key)
                # if there is a nested map under 'fields' or 'children', recurse
                for child_key in ('fields', 'children', 'map'):
                    if child_key in val:
                        self._parse_map(val[child_key])
            else:
                # leaf without explicit required flag  optional
                self._optional.add(key)

    def __call__(self, systemConfig):
        missing = self._required - set(systemConfig.keys())
        if missing:
            raise ValueError(f""Missing required fields: {sorted(missing)}"")
        # keep only allowed keys
        return {k: v for k, v in systemConfig.items() if k in self._all}","class SCFilter(object):
    '''
    A SCFilter class is initialized with a list of classes as arguments.
    For any of those classes that are AttributeMapper subclasses, SCFilter
    determines the required fields in their initMap trees, and the optional
    fields. When called, the SCFilter discards any key in the passed dictionary
    that does not match one of those fields, and raises an error if any of the
    required fields are not present.
    '''

    def __init__(self, clslist):
        '''
        SCFilter(clslist)

        Args:
            clslist (list): List of classes from which to build the filter

        Returns:
            new SCFilter instance
        '''
        self.required_fields = set()
        self.optional_fields = set()
        
        for cls in clslist:
            if hasattr(cls, 'initMap') and cls.initMap is not None:
                self._extract_fields(cls.initMap)
    
    def _extract_fields(self, init_map):
        """"""Recursively extract required and optional fields from initMap.""""""
        if isinstance(init_map, dict):
            for key, value in init_map.items():
                if isinstance(value, dict):
                    # Check if this is a field specification
                    if 'required' in value:
                        if value['required']:
                            self.required_fields.add(key)
                        else:
                            self.optional_fields.add(key)
                    # Recursively process nested maps
                    self._extract_fields(value)
                elif key == 'required' and isinstance(value, bool):
                    # This is a required flag, already handled above
                    pass
                else:
                    # Recursively process nested structures
                    self._extract_fields(value)
    
    def __call__(self, systemConfig):
        '''
        Args:
            systemConfig (dict): A systemConfig dictionary to filter

        Returns:
            dict: Filtered dictionary

        Raises:
            ValueError: If a required key is not in the systemConfig
        '''
        # Check if all required fields are present
        missing_required = self.required_fields - systemConfig.keys()
        if missing_required:
            raise ValueError(f""Required keys missing from systemConfig: {missing_required}"")
        
        # Filter the dictionary to only include valid fields
        valid_fields = self.required_fields | self.optional_fields
        filtered_config = {key: value for key, value in systemConfig.items() 
                          if key in valid_fields}
        
        return filtered_config","class SCFilter(object):
    '''
    A SCFilter class is initialized with a list of classes as arguments.
    For any of those classes that are AttributeMapper subclasses, SCFilter
    determines the required fields in their initMap trees, and the optional
    fields. When called, the SCFilter discards any key in the passed dictionary
    that does not match one of those fields, and raises an error if any of the
    required fields are not present.
    '''

    def __init__(self, clslist):
        '''
        SCFilter(clslist)

        Args:
            clslist (list): List of classes from which to build the filter

        Returns:
            new SCFilter instance
        '''
        self.required_fields = set()
        self.optional_fields = set()
        self.all_fields = set()
        
        for cls in clslist:
            if hasattr(cls, 'initMap') and hasattr(cls, '__bases__'):
                # Check if it's an AttributeMapper subclass
                is_attribute_mapper = False
                for base in cls.__mro__:
                    if base.__name__ == 'AttributeMapper':
                        is_attribute_mapper = True
                        break
                
                if is_attribute_mapper:
                    self._extract_fields_from_initmap(cls.initMap)
        
        self.all_fields = self.required_fields | self.optional_fields

    def _extract_fields_from_initmap(self, initmap):
        for key, value in initmap.items():
            if isinstance(value, dict):
                if value.get('required', False):
                    self.required_fields.add(key)
                else:
                    self.optional_fields.add(key)
                
                # Recursively process nested mappings
                if 'initMap' in value:
                    self._extract_fields_from_initmap(value['initMap'])
            else:
                # If value is not a dict, treat as optional field
                self.optional_fields.add(key)

    def __call__(self, systemConfig):
        '''
        Args:
            systemConfig (dict): A systemConfig dictionary to filter

        Returns:
            dict: Filtered dictionary

        Raises:
            ValueError: If a required key is not in the systemConfig
        '''
        # Check for missing required fields
        missing_required = self.required_fields - set(systemConfig.keys())
        if missing_required:
            raise ValueError(f""Required fields missing: {missing_required}"")
        
        # Filter the dictionary to only include known fields
        filtered_config = {}
        for key, value in systemConfig.items():
            if key in self.all_fields:
                filtered_config[key] = value
        
        return filtered_config",full_docstr,0.6269315673289184,0.43015521064301554,0.34743875278396436,0.4988962472406182,0.397267096513693,0.6009501187648456,0.36428571428571427,0.2863961813842482,0.8399713039398193,0.8863790035247803,0.8625513911247253,0.8815087676048279,0.7593331660231668,0.6828282828282828,0.5436105476673427,0.4806517311608962,0.6060606060606061,0.4708708908409685,0.6068376068376068,0.44539614561027835,0.38626609442060084,0.8656712770462036,0.9184638261795044,0.8912864923477173,0.9128965735435486,0.7722930864197538,0.6970297029702971,0.5367793240556661,0.47504990019960086,0.5900990099009901,0.4571812930163815,0.5733855185909981,0.4372549019607843,0.381139489194499,0.8629416227340698,0.9162197709083557,0.8887829184532166,0.9105977416038513,0.7593285198555961,0.3999181338342312,0.3664353047344765,0.4851169298505687,0.3552631578947368,0.3928571428571428,0.5212062780122679,0.4815087190989155,0.7170381974614345,0.3684210526315789,0.5178571428571429,0.4737363443769777,0.4921380948199367,0.7214163052443651,0.3421052631578947,0.3392857142857143
252178,aws/sagemaker-python-sdk,aws_sagemaker-python-sdk/src/sagemaker/model_monitor/clarify_model_monitoring.py,sagemaker.model_monitor.clarify_model_monitoring.ExplainabilityAnalysisConfig,"class ExplainabilityAnalysisConfig:
    """"""Analysis configuration for ModelExplainabilityMonitor.""""""

    def __init__(self, explainability_config, model_config, headers=None, label_headers=None):
        """"""Creates an analysis config dictionary.

        Args:
            explainability_config (sagemaker.clarify.ExplainabilityConfig): Config object related
                to explainability configurations.
            model_config (sagemaker.clarify.ModelConfig): Config object related to bias
                configurations.
            headers (list[str]): A list of feature names (without label) of model/endpint input.
            label_headers (list[str]): List of headers, each for a predicted score in model output.
                It is used to beautify the analysis report by replacing placeholders like ""label0"".

        """"""
        predictor_config = model_config.get_predictor_config()
        self.analysis_config = {
            ""methods"": explainability_config.get_explainability_config(),
            ""predictor"": predictor_config,
        }
        if headers is not None:
            self.analysis_config[""headers""] = headers
        if label_headers is not None:
            predictor_config[""label_headers""] = label_headers

    def _to_dict(self):
        """"""Generates a request dictionary using the parameters provided to the class.""""""
        return self.analysis_config","class ExplainabilityAnalysisConfig:
    '''Analysis configuration for ModelExplainabilityMonitor.'''

    def __init__(self, explainability_config, model_config, headers=None, label_headers=None):
    '''Creates an analysis config dictionary.

        Args:
            explainability_config (sagemaker.clarify.ExplainabilityConfig): Config object related
                to explainability configurations.
            model_config (sagemaker.clarify.ModelConfig): Config object related to bias
                configurations.
            headers (list[str]): A list of feature names (without label) of model/endpint input.
            label_headers (list[str]): List of headers, each for a predicted score in model output.
                It is used to beautify the analysis report by replacing placeholders like ""label0"".

        '''
        pass

    def _to_dict(self):
    '''Generates a request dictionary using the parameters provided to the class.'''
        pass

",3,3,snippet_370,0.2857142857142857,"class ExplainabilityAnalysisConfig:
    '''Analysis configuration for ModelExplainabilityMonitor.'''

    def __init__(self, explainability_config, model_config, headers=None, label_headers=None):
        '''Creates an analysis config dictionary.

        Args:
            explainability_config (sagemaker.clarify.ExplainabilityConfig): Config object related
                to explainability configurations.
            model_config (sagemaker.clarify.ModelConfig): Config object related to bias
                configurations.
            headers (list[str]): A list of feature names (without label) of model/endpoint input.
            label_headers (list[str]): List of headers, each for a predicted score in model output.
                It is used to beautify the analysis report by replacing placeholders like ""label0"".
        '''
        self.explainability_config = explainability_config
        self.model_config = model_config
        self.headers = headers
        self.label_headers = label_headers

    def _to_dict(self):
        '''Generates a request dictionary using the parameters provided to the class.'''
        config = {
            'ExplainabilityConfig': self.explainability_config.to_dict(),
            'ModelConfig': self.model_config.to_dict()
        }
        if self.headers is not None:
            config['Headers'] = self.headers
        if self.label_headers is not None:
            config['LabelHeaders'] = self.label_headers
        return config","class ExplainabilityAnalysisConfig:
    '''Analysis configuration for ModelExplainabilityMonitor.'''

    def __init__(self, explainability_config, model_config, headers=None, label_headers=None):
        '''Creates an analysis config dictionary.

        Args:
            explainability_config (sagemaker.clarify.ExplainabilityConfig): Config object related
                to explainability configurations.
            model_config (sagemaker.clarify.ModelConfig): Config object related to bias
                configurations.
            headers (list[str]): A list of feature names (without label) of model/endpint input.
            label_headers (list[str]): List of headers, each for a predicted score in model output.
                It is used to beautify the analysis report by replacing placeholders like ""label0"".

        '''
        self.explainability_config = explainability_config
        self.model_config = model_config
        self.headers = headers
        self.label_headers = label_headers

    def _to_dict(self):
        '''Generates a request dictionary using the parameters provided to the class.'''
        config_dict = {
            ""explainability_config"": self.explainability_config.get_config(),
            ""model_config"": self.model_config.get_config()
        }
        
        if self.headers is not None:
            config_dict[""headers""] = self.headers
            
        if self.label_headers is not None:
            config_dict[""label_headers""] = self.label_headers
            
        return config_dict","class ExplainabilityAnalysisConfig:
    '''Analysis configuration for ModelExplainabilityMonitor.'''

    def __init__(self, explainability_config, model_config, headers=None, label_headers=None):
        '''Creates an analysis config dictionary.

        Args:
            explainability_config (sagemaker.clarify.ExplainabilityConfig): Config object related
                to explainability configurations.
            model_config (sagemaker.clarify.ModelConfig): Config object related to bias
                configurations.
            headers (list[str]): A list of feature names (without label) of model/endpint input.
            label_headers (list[str]): List of headers, each for a predicted score in model output.
                It is used to beautify the analysis report by replacing placeholders like ""label0"".

        '''
        self.explainability_config = explainability_config
        self.model_config = model_config
        self.headers = headers
        self.label_headers = label_headers

    def _to_dict(self):
        '''Generates a request dictionary using the parameters provided to the class.'''
        config_dict = {}
        
        if self.explainability_config:
            config_dict.update(self.explainability_config._to_dict())
        
        if self.model_config:
            config_dict.update(self.model_config._to_dict())
        
        if self.headers:
            config_dict[""headers""] = self.headers
        
        if self.label_headers:
            config_dict[""label_headers""] = self.label_headers
        
        return config_dict",full_docstr,0.8888888888888888,0.7763157894736842,0.7019867549668874,0.7647058823529411,0.7231601462083341,0.8582089552238806,0.7415730337078652,0.6428571428571429,0.9580435752868652,0.94913649559021,0.953569233417511,0.9500197172164917,0.8241487401574803,0.888178913738019,0.7845659163987139,0.7184466019417476,0.7667731629392973,0.7530233950672104,0.8413793103448276,0.7612456747404844,0.6666666666666666,0.9646541476249695,0.9586501717567444,0.9616428017616272,0.9592471122741699,0.8241487401574803,0.8264984227129336,0.7174603174603176,0.6645367412140575,0.7444794952681387,0.6642345244715945,0.7674418604651163,0.66,0.5785953177257525,0.9552944898605347,0.9486484527587891,0.9519598484039307,0.9493088722229004,0.8098784444444443,0.5408404318026256,0.6199851090571374,0.6797402545170016,0.3636363636363636,0.5,0.5522331055269143,0.6420421867572119,0.7032538717140816,0.3636363636363636,0.5,0.5396966707893801,0.6384288026349281,0.6567215168862288,0.3636363636363636,0.5
181656,RobotStudio/bors,RobotStudio_bors/bors/api/base.py,bors.api.base.IApi,"class IApi:
    """"""Interface to an Api implementation""""""
    # Use name to create a name for your api interface, and use the same
    #  name in your config
    name = ""default""
    result_schema = None
    ws_result_schema = None
    request_schema = None
    ENDPOINT_OVERRIDES = None

    def shutdown(self):
        """"""Override to perform any shutdown necessary""""""
        pass

    def call(self, method, data=None, **args):
        """"""
        Generic interface to REST api
        :param method:  query name
        :param data:   dictionary of inputs
        :param args:    keyword arguments added to the payload
        :return:
        """"""
        pass

    def on_ws_connect(self):
        """"""
        Called by the websocket mixin
        """"""
        pass","class IApi:
    '''Interface to an Api implementation'''

    def shutdown(self):
    '''Override to perform any shutdown necessary'''
        pass

    def call(self, method, data=None, **args):
    '''
        Generic interface to REST api
        :param method:  query name
        :param data:   dictionary of inputs
        :param args:    keyword arguments added to the payload
        :return:
        '''
        pass

    def on_ws_connect(self):
    '''
        Called by the websocket mixin
        '''
        pass

",4,4,snippet_238,1.0,"class IApi:
    '''Interface to an Api implementation'''

    def __init__(self, base_url, timeout=30, headers=None):
        """"""
        :param base_url: Base URL for REST API endpoints
        :param timeout:  Request timeout in seconds
        :param headers:  Optional dict of HTTP headers
        """"""
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.session = requests.Session()
        if headers:
            self.session.headers.update(headers)
        self._logger = logging.getLogger(self.__class__.__name__)

    def shutdown(self):
        """"""Override to perform any shutdown necessary""""""
        try:
            self.session.close()
            self._logger.debug(""HTTP session closed"")
        except Exception as e:
            self._logger.warning(f""Error shutting down session: {e}"")

    def call(self, method, data=None, **args):
        """"""
        Generic interface to REST api
        :param method:  query name (appended to base_url)
        :param data:    dictionary of inputs
        :param args:    keyword arguments added to the payload
        :return:        parsed JSON response
        """"""
        url = f""{self.base_url}/{method.lstrip('/')}""
        payload = {}
        if data:
            if not isinstance(data, dict):
                raise ValueError(""data must be a dict"")
            payload.update(data)
        payload.update(args)
        try:
            resp = self.session.post(url, json=payload, timeout=self.timeout)
            resp.raise_for_status()
            return resp.json()
        except requests.RequestException as e:
            self._logger.error(f""API call error {method}: {e}"")
            raise

    def on_ws_connect(self):
        """"""
        Called by the websocket mixin
        """"""
        self._logger.info(""WebSocket connection established"")","class IApi:
    '''Interface to an Api implementation'''

    def shutdown(self):
        '''Override to perform any shutdown necessary'''
        pass

    def call(self, method, data=None, **args):
        '''
        Generic interface to REST api
        :param method:  query name
        :param data:   dictionary of inputs
        :param args:    keyword arguments added to the payload
        :return:
        '''
        pass

    def on_ws_connect(self):
        '''
        Called by the websocket mixin
        '''
        pass","class IApi:
    '''Interface to an Api implementation'''

    def shutdown(self):
        '''Override to perform any shutdown necessary'''
        pass

    def call(self, method, data=None, **args):
        '''
        Generic interface to REST api
        :param method:  query name
        :param data:   dictionary of inputs
        :param args:    keyword arguments added to the payload
        :return:
        '''
        pass

    def on_ws_connect(self):
        '''
        Called by the websocket mixin
        '''
        pass",full_docstr,0.4224422442244225,0.33887043189368765,0.3076923076923077,0.396039603960396,0.24347909262811226,0.29453681710213775,0.23333333333333334,0.2100238663484487,0.7329646348953247,0.8134219646453857,0.7711002230644226,0.8045899868011475,0.7385870890410959,0.7814569536423841,0.7651006711409395,0.7482993197278912,0.7814569536423841,0.3820830664540401,0.9111111111111111,0.8202247191011236,0.7386363636363636,0.9440793991088867,0.8426107168197632,0.8904637694358826,0.8517654538154602,0.8858458904109588,0.7814569536423841,0.7651006711409395,0.7482993197278912,0.7814569536423841,0.3820830664540401,0.9111111111111111,0.8202247191011236,0.7386363636363636,0.9440793991088867,0.8426107168197632,0.8904637694358826,0.8517654538154602,0.8858458904109588,0.2893172879847016,0.2773331935684999,0.4656502440845921,0.2142857142857142,0.2,0.3269411667881789,0.3485121843766263,0.3925858161094226,0.5,0.0666666666666666,0.3269411667881789,0.3485121843766263,0.3925858161094226,0.5,0.0666666666666666
349346,dolph/pasteraw-client,dolph_pasteraw-client/pasteraw.py,pasteraw.Client,"class Client(object):
    """"""A client library for pasteraw.

    To use pasteraw.com:

    >>> c = pasteraw.Client()
    >>> url = c.create_paste('Lorem ipsum.')
    >>> print(url)
    http://cdn.pasteraw.com/9lvwkwgrgji5gbhjygxgaqcfx3hefpb

    If you're using your own pasteraw deployment, pass your own API endpoint to
    the client:

    >>> c = pasteraw.Client('http://pasteraw.example.com/api/v1')

    """"""

    def __init__(self, endpoint=None):
        """"""Initialize a pasteraw client for the given endpoint (optional).""""""
        self.endpoint = endpoint or ENDPOINT

    def create_paste(self, content):
        """"""Create a raw paste of the given content.

        Returns a URL to the paste, or raises a ``pasteraw.Error`` if something
        tragic happens instead.

        """"""
        r = requests.post(
            self.endpoint + '/pastes',
            data={'content': content},
            allow_redirects=False)

        if r.status_code == 302:
            return r.headers['Location']

        if r.status_code == 413:
            raise MaxLengthExceeded('%d bytes' % len(content))

        try:
            error_message = r.json()['error']
        except Exception:
            error_message = r.text

        raise UnexpectedError(error_message)","class Client(object):
    '''A client library for pasteraw.

    To use pasteraw.com:

    >>> c = pasteraw.Client()
    >>> url = c.create_paste('Lorem ipsum.')
    >>> print(url)
    http://cdn.pasteraw.com/9lvwkwgrgji5gbhjygxgaqcfx3hefpb

    If you're using your own pasteraw deployment, pass your own API endpoint to
    the client:

    >>> c = pasteraw.Client('http://pasteraw.example.com/api/v1')

    '''

    def __init__(self, endpoint=None):
    '''Initialize a pasteraw client for the given endpoint (optional).'''
        pass

    def create_paste(self, content):
    '''Create a raw paste of the given content.

        Returns a URL to the paste, or raises a ``pasteraw.Error`` if something
        tragic happens instead.

        '''
        pass

",3,3,snippet_593,0.4,"class Client(object):
    '''A client library for pasteraw.

    To use pasteraw.com:

    >>> c = pasteraw.Client()
    >>> url = c.create_paste('Lorem ipsum.')
    >>> print(url)
    http://cdn.pasteraw.com/9lvwkwgrgji5gbhjygxgaqcfx3hefpb

    If you're using your own pasteraw deployment, pass your own API endpoint to
    the client:

    >>> c = pasteraw.Client('http://pasteraw.example.com/api/v1')

    '''

    def __init__(self, endpoint=None):
        '''Initialize a pasteraw client for the given endpoint (optional).'''
        base = endpoint.rstrip('/') if endpoint else 'https://pasteraw.com/api/v1'
        self.api_url = base + '/raw'
        p = urlparse(base)
        self.cdn_base = f'{p.scheme}://cdn.{p.netloc}'

    def create_paste(self, content):
        '''Create a raw paste of the given content.

        Returns a URL to the paste, or raises a ``pasteraw.Error`` if something
        tragic happens instead.

        '''
        headers = {'Content-Type': 'text/plain'}
        resp = requests.post(self.api_url, data=content.encode('utf-8'), headers=headers)
        if resp.status_code >= 400:
            raise Error(f'HTTP {resp.status_code}: {resp.text}')
        key = resp.text.strip()
        return f'{self.cdn_base}/{key}'","class Client(object):
    '''A client library for pasteraw.

    To use pasteraw.com:

    >>> c = pasteraw.Client()
    >>> url = c.create_paste('Lorem ipsum.')
    >>> print(url)
    http://cdn.pasteraw.com/9lvwkwgrgji5gbhjygxgaqcfx3hefpb

    If you're using your own pasteraw deployment, pass your own API endpoint to
    the client:

    >>> c = pasteraw.Client('http://pasteraw.example.com/api/v1')

    '''

    def __init__(self, endpoint=None):
        '''Initialize a pasteraw client for the given endpoint (optional).'''
        self.endpoint = endpoint or 'https://pasteraw.com/api/v1'

    def create_paste(self, content):
        '''Create a raw paste of the given content.

        Returns a URL to the paste, or raises a ``pasteraw.Error`` if something
        tragic happens instead.

        '''
        try:
            response = requests.post(
                self.endpoint + '/pastes',
                data={'content': content},
                headers={'User-Agent': 'pasteraw.py'}
            )
            response.raise_for_status()
            data = response.json()
            return data['url']
        except requests.exceptions.RequestException as e:
            raise Error(str(e))
        except (KeyError, json.JSONDecodeError) as e:
            raise Error('Invalid response from server: {}'.format(str(e)))","class Client(object):
    '''A client library for pasteraw.

    To use pasteraw.com:

    >>> c = pasteraw.Client()
    >>> url = c.create_paste('Lorem ipsum.')
    >>> print(url)
    http://cdn.pasteraw.com/9lvwkwgrgji5gbhjygxgaqcfx3hefpb

    If you're using your own pasteraw deployment, pass your own API endpoint to
    the client:

    >>> c = pasteraw.Client('http://pasteraw.example.com/api/v1')

    '''

    def __init__(self, endpoint=None):
        '''Initialize a pasteraw client for the given endpoint (optional).'''
        if endpoint is None:
            self.endpoint = 'https://pasteraw.com/api/v1'
        else:
            self.endpoint = endpoint.rstrip('/')

    def create_paste(self, content):
        '''Create a raw paste of the given content.

        Returns a URL to the paste, or raises a ``pasteraw.Error`` if something
        tragic happens instead.

        '''
        try:
            response = requests.post(
                f'{self.endpoint}/paste',
                data={'content': content},
                timeout=30
            )
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    return data.get('url')
                except (json.JSONDecodeError, KeyError):
                    raise Error('Invalid response format from server')
            else:
                raise Error(f'HTTP {response.status_code}: {response.text}')
                
        except requests.exceptions.RequestException as e:
            raise Error(f'Request failed: {str(e)}')",full_docstr,0.7365079365079366,0.6325878594249201,0.5980707395498392,0.6984126984126985,0.59886276440463,0.7191358024691358,0.5758513931888545,0.5186335403726708,0.9025077223777771,0.9133415222167969,0.9078922867774963,0.9122464060783386,0.7875264912280703,0.7763157894736842,0.6953642384105959,0.6799999999999999,0.756578947368421,0.6804405957327387,0.7755102040816326,0.6621160409556314,0.6198630136986302,0.9287469387054443,0.9260221123695374,0.9273825287818909,0.9262939095497131,0.8466681999999999,0.7663551401869161,0.6394984326018808,0.5930599369085174,0.7289719626168224,0.6198535673092248,0.7107692307692308,0.6080246913580247,0.5510835913312694,0.9041934609413147,0.9148959517478943,0.9095131754875183,0.9138143062591553,0.8379904469273743,0.4936917738316856,0.5693905350310585,0.5758311057502294,0.375,0.4545454545454545,0.5953340798672524,0.6276699810999942,0.6348216413993182,0.421875,0.696969696969697,0.6427776278604626,0.5348548545295423,0.5987556569123079,0.4375,0.0
1751,ANTsX/ANTsPy,ants/contrib/sampling/affine2d.py,ants.contrib.sampling.affine2d.Rotate2D,"class Rotate2D(object):
    """"""
    Create an ANTs Affine Transform with a specified level
    of rotation.
    """"""

    def __init__(self, rotation, reference=None, lazy=False):
        """"""
        Initialize a Rotate2D object

        Arguments
        ---------
        rotation : scalar
            rotation value in degrees.
            Negative values can be used for rotation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        """"""
        self.rotation = rotation
        self.lazy = lazy
        self.reference = reference

        self.tx = tio.ANTsTransform(
            precision=""float"", dimension=2, transform_type=""AffineTransform""
        )
        if self.reference is not None:
            self.tx.set_fixed_parameters(self.reference.get_center_of_mass())

    def transform(self, X=None, y=None):
        """"""
        Transform an image using an Affine transform with the given
        rotation parameters.   Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Rotate2D(rotation=(10,-5,12))
        >>> img2 = tx.transform(img)
        """"""
        # unpack zoom range
        rotation = self.rotation

        # Rotation about X axis
        theta = math.pi / 180 * rotation
        rotation_matrix = np.array(
            [[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0]]
        )

        self.tx.set_parameters(rotation_matrix)
        if self.lazy or X is None:
            return self.tx
        else:
            if y is None:
                return self.tx.apply_to_image(X, reference=self.reference)
            else:
                return (
                    self.tx.apply_to_image(X, reference=self.reference),
                    self.tx.apply_to_image(y, reference=self.reference),
                )","class Rotate2D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of rotation.
    '''

    def __init__(self, rotation, reference=None, lazy=False):
    '''
        Initialize a Rotate2D object

        Arguments
        ---------
        rotation : scalar
            rotation value in degrees.
            Negative values can be used for rotation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        pass

    def transform(self, X=None, y=None):
    '''
        Transform an image using an Affine transform with the given
        rotation parameters.   Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Rotate2D(rotation=(10,-5,12))
        >>> img2 = tx.transform(img)
        '''
        pass

",3,3,snippet_10,0.2,"class Rotate2D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of rotation.
    '''

    def __init__(self, rotation, reference=None, lazy=False):
        '''
        Initialize a Rotate2D object

        Arguments
        ---------
        rotation : scalar
            rotation value in degrees.
            Negative values can be used for rotation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        self.rotation_deg = rotation
        self.rotation_rad = math.radians(rotation)
        self.reference = reference
        self.lazy = lazy

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        rotation parameters.   Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types
        '''
        # Determine reference image for transform creation
        ref = self.reference if self.reference is not None else X
        if ref is None:
            raise ValueError(""No reference or input image provided to define the transform space."")

        # Create the 2D Euler transform with the requested rotation (radians)
        tx = ants.create_ants_transform(
            transform_type='Euler2DTransform',
            fixed_image=ref,
            rotation=[self.rotation_rad]
        )

        # If no image to apply to, return the transform object
        if X is None:
            return tx

        # If lazy, return transform without applying
        if self.lazy:
            return tx

        # Apply transform to X (and y if given)
        x_t = ants.apply_ants_transform_to_image(tx, X, ref)
        if y is not None:
            y_t = ants.apply_ants_transform_to_image(tx, y, ref)
            return x_t, y_t
        return x_t","class Rotate2D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of rotation.
    '''

    def __init__(self, rotation, reference=None, lazy=False):
        '''
        Initialize a Rotate2D object

        Arguments
        ---------
        rotation : scalar
            rotation value in degrees.
            Negative values can be used for rotation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        self.rotation = rotation
        self.reference = reference
        self.lazy = lazy
        self.transform_obj = self._create_transform()

    def _create_transform(self):
        '''
        Create the affine transform object with the specified rotation
        '''
        # Create affine transform
        transform = ants.create_ants_transform(transform_type='AffineTransform', precision='float', dimension=2)
        
        # Convert rotation from degrees to radians
        rotation_rad = np.radians(self.rotation)
        
        # Create rotation matrix
        cos_theta = np.cos(rotation_rad)
        sin_theta = np.sin(rotation_rad)
        
        rotation_matrix = np.array([
            [cos_theta, -sin_theta],
            [sin_theta, cos_theta]
        ])
        
        # Set the transform parameters
        transform.set_parameters(rotation_matrix.flatten())
        
        # Set fixed parameters if reference is provided
        if self.reference is not None:
            transform.set_fixed_parameters(self.reference.get_center_of_mass())
            
        return transform

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        rotation parameters.   Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Rotate2D(rotation=(10,-5,12))
        >>> img2 = tx.transform(img)
        '''
        if X is None:
            return self.transform_obj
            
        if self.lazy:
            return self.transform_obj
            
        # Apply transform to X
        X_transformed = ants.apply_ants_transform_to_image(self.transform_obj, X, reference=self.reference)
        
        if y is None:
            return X_transformed
        else:
            # Apply transform to y as well
            y_transformed = ants.apply_ants_transform_to_image(self.transform_obj, y, reference=self.reference)
            return (X_transformed, y_transformed)","class Rotate2D(object):
    '''
    Create an ANTs Affine Transform with a specified level
    of rotation.
    '''

    def __init__(self, rotation, reference=None, lazy=False):
        '''
        Initialize a Rotate2D object

        Arguments
        ---------
        rotation : scalar
            rotation value in degrees.
            Negative values can be used for rotation in the
            other direction

        reference : ANTsImage (optional but recommended)
            image providing the reference space for the transform.
            this will also set the transform fixed parameters.

        lazy : boolean (default = False)
            if True, calling the `transform` method only returns
            the randomly generated transform and does not actually
            transform the image
        '''
        self.rotation = rotation
        self.reference = reference
        self.lazy = lazy

    def transform(self, X=None, y=None):
        '''
        Transform an image using an Affine transform with the given
        rotation parameters.   Return the transform if X=None.

        Arguments
        ---------
        X : ANTsImage
            Image to transform

        y : ANTsImage (optional)
            Another image to transform

        Returns
        -------
        ANTsImage if y is None, else a tuple of ANTsImage types

        Examples
        --------
        >>> import ants
        >>> img = ants.image_read(ants.get_data('r16'))
        >>> tx = ants.contrib.Rotate2D(rotation=(10,-5,12))
        >>> img2 = tx.transform(img)
        '''
        # Convert rotation from degrees to radians
        rotation_rad = math.radians(self.rotation)
        
        # Create rotation matrix parameters
        cos_theta = math.cos(rotation_rad)
        sin_theta = math.sin(rotation_rad)
        
        # Create affine transform
        tx = ants.create_ants_transform(transform_type='AffineTransform', dimension=2)
        
        # Set rotation matrix parameters
        matrix = [cos_theta, -sin_theta, sin_theta, cos_theta]
        tx.set_parameters(matrix + [0.0, 0.0])
        
        # Set fixed parameters if reference image is provided
        if self.reference is not None:
            center = [self.reference.shape[0] / 2.0, self.reference.shape[1] / 2.0]
            tx.set_fixed_parameters(center)
        elif X is not None:
            center = [X.shape[0] / 2.0, X.shape[1] / 2.0]
            tx.set_fixed_parameters(center)
        
        if X is None or self.lazy:
            return tx
        
        # Apply transform to image(s)
        if y is None:
            reference_img = self.reference if self.reference is not None else X
            return ants.apply_ants_transform_to_image(tx, X, reference_img)
        else:
            reference_img = self.reference if self.reference is not None else X
            X_transformed = ants.apply_ants_transform_to_image(tx, X, reference_img)
            y_transformed = ants.apply_ants_transform_to_image(tx, y, reference_img)
            return (X_transformed, y_transformed)",full_docstr,0.7327433628318583,0.5896980461811723,0.5276292335115864,0.6194690265486724,0.5219370232549319,0.7894736842105263,0.6139088729016786,0.5216346153846154,0.9122055768966675,0.8900508880615234,0.9009920358657837,0.8922178149223328,0.7969207983193277,0.8184713375796179,0.7060702875399361,0.6346153846153846,0.6847133757961784,0.6553653252052473,0.759515570934256,0.6429809358752167,0.5763888888888888,0.9167886972427368,0.9370014071464539,0.926784873008728,0.9349400401115417,0.779087176470589,0.7907692307692308,0.6419753086419753,0.541795665634675,0.683076923076923,0.6008433534192645,0.7354409317803661,0.585,0.5041736227045075,0.9046844840049744,0.9282808303833008,0.9163307547569275,0.925865888595581,0.7801694623655923,0.5342338502991012,0.5485525427704149,0.6258683291737622,0.4568965517241379,0.5056179775280899,0.6201165623242891,0.5724912797513214,0.7037905449042232,0.5862068965517241,0.6179775280898876,0.5957285148413972,0.5292062518190206,0.6960169900339763,0.5172413793103449,0.6404494382022472
289480,chimera0/accel-brain-code,Automatic-Summarization/pysummarization/n_gram.py,Automatic-Summarization.pysummarization.n_gram.Ngram,"class Ngram(object):
    '''
    N-gram
    '''

    def generate_ngram_data_set(self, token_list, n=2):
        '''
        Generate the N-gram's pair.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        n_gram_tuple_zip = self.generate_tuple_zip(token_list, n)
        n_gram_tuple_list = [n_gram_tuple for n_gram_tuple in n_gram_tuple_zip]
        n_gram_data_set = self.generate_tuple_zip(n_gram_tuple_list, 2)
        return n_gram_data_set

    def generate_skip_gram_data_set(self, token_list):
        '''
        Generate the Skip-gram's pair.

        Args:
            token_list:     The list of tokens.

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        n_gram_tuple_zip = self.generate_tuple_zip(token_list, 3)
        skip_gram_list = []
        for pre, point, post in n_gram_tuple_zip:
            skip_gram_list.append((point, pre))
            skip_gram_list.append((point, post))
        return zip(skip_gram_list)

    def generate_tuple_zip(self, token_list, n=2):
        '''
        Generate the N-gram.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(N-gram)
        '''
        return zip(*[token_list[i:] for i in range(n)])","class Ngram(object):
    '''
    N-gram
    '''

    def generate_ngram_data_set(self, token_list, n=2):
    '''
        Generate the N-gram's pair.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        pass

    def generate_skip_gram_data_set(self, token_list):
    '''
        Generate the Skip-gram's pair.

        Args:
            token_list:     The list of tokens.

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        pass

    def generate_tuple_zip(self, token_list, n=2):
    '''
        Generate the N-gram.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(N-gram)
        '''
        pass

",4,4,snippet_494,1.0,"class Ngram(object):
    '''
    N-gram
    '''

    def generate_ngram_data_set(self, token_list, n=2):
        '''
        Generate the N-gram's pair.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        tuples = list(self.generate_tuple_zip(token_list, n))
        X = [t[:-1] for t in tuples]
        y = [t[-1] for t in tuples]
        return zip(X, y)

    def generate_skip_gram_data_set(self, token_list):
        '''
        Generate the Skip-gram's pair.

        Args:
            token_list:     The list of tokens.

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        X, y = [], []
        length = len(token_list)
        for i, center in enumerate(token_list):
            for j in (-1, 1):
                ctx_i = i + j
                if 0 <= ctx_i < length:
                    X.append(center)
                    y.append(token_list[ctx_i])
        return zip(X, y)

    def generate_tuple_zip(self, token_list, n=2):
        '''
        Generate the N-gram.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(N-gram)
        '''
        if n <= 0:
            return iter(())
        slices = [token_list[i:] for i in range(n)]
        return zip(*slices)","class Ngram(object):
    '''
    N-gram
    '''

    def generate_ngram_data_set(self, token_list, n=2):
        '''
        Generate the N-gram's pair.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        if len(token_list) < n + 1:
            return zip([], [])
        
        training_data = []
        target_data = []
        
        for i in range(len(token_list) - n):
            training_data.append(tuple(token_list[i:i + n]))
            target_data.append(token_list[i + n])
        
        return zip(training_data, target_data)

    def generate_skip_gram_data_set(self, token_list):
        '''
        Generate the Skip-gram's pair.

        Args:
            token_list:     The list of tokens.

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        training_data = []
        target_data = []
        
        for i, target_word in enumerate(token_list):
            for j, context_word in enumerate(token_list):
                if i != j:  # Skip the target word itself
                    training_data.append((target_word,))
                    target_data.append(context_word)
        
        return zip(training_data, target_data)

    def generate_tuple_zip(self, token_list, n=2):
        '''
        Generate the N-gram.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(N-gram)
        '''
        if len(token_list) < n:
            return zip([])
        
        ngrams = []
        for i in range(len(token_list) - n + 1):
            ngrams.append(tuple(token_list[i:i + n]))
        
        return zip(ngrams)","class Ngram(object):
    '''
    N-gram
    '''

    def generate_ngram_data_set(self, token_list, n=2):
        '''
        Generate the N-gram's pair.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        if len(token_list) < n + 1:
            return zip([], [])
        
        training_data = []
        target_data = []
        
        for i in range(len(token_list) - n):
            training_data.append(tuple(token_list[i:i+n]))
            target_data.append(token_list[i+n])
        
        return zip(training_data, target_data)

    def generate_skip_gram_data_set(self, token_list):
        '''
        Generate the Skip-gram's pair.

        Args:
            token_list:     The list of tokens.

        Returns:
            zip of Tuple(Training N-gram data, Target N-gram data)
        '''
        if len(token_list) < 3:
            return zip([], [])
        
        training_data = []
        target_data = []
        
        for i in range(1, len(token_list) - 1):
            training_data.append(token_list[i])
            target_data.append(token_list[i-1])
            training_data.append(token_list[i])
            target_data.append(token_list[i+1])
        
        return zip(training_data, target_data)

    def generate_tuple_zip(self, token_list, n=2):
        '''
        Generate the N-gram.

        Args:
            token_list:     The list of tokens.
            n               N

        Returns:
            zip of Tuple(N-gram)
        '''
        if len(token_list) < n:
            return zip([])
        
        ngrams = []
        for i in range(len(token_list) - n + 1):
            ngrams.append(tuple(token_list[i:i+n]))
        
        return zip(ngrams)",full_docstr,0.7080103359173125,0.612987012987013,0.5691906005221933,0.6821705426356589,0.6193670836924228,0.7584097859327217,0.6441717791411042,0.5846153846153846,0.8958220481872559,0.9281343817710876,0.9116919636726379,0.9247986078262329,0.8698765240641712,0.7050359712230215,0.544578313253012,0.4939467312348668,0.6330935251798561,0.5370586983347293,0.681704260651629,0.5125628140703518,0.4433249370277078,0.8842071890830994,0.908158540725708,0.8960228562355042,0.9057051539421082,0.8050614732142857,0.6964705882352942,0.5342789598108747,0.48931116389548696,0.6305882352941177,0.5029993975494343,0.6455399061032864,0.4776470588235294,0.41273584905660377,0.8849961757659912,0.9062192440032959,0.8954820036888123,0.9040512442588806,0.8002665476190476,0.5276122707647393,0.5271501279636769,0.6662316474029728,0.359375,0.5576923076923077,0.5368030381253646,0.4887467352914315,0.6728884941331034,0.3125,0.6730769230769231,0.5161853955190048,0.5216607802506082,0.6728884941331034,0.3125,0.5576923076923077
113634,DataDog/integrations-core,tokumx/datadog_checks/tokumx/vendor/pymongo/bulk.py,datadog_checks.tokumx.vendor.pymongo.bulk._Run,"class _Run(object):
    """"""Represents a batch of write operations.
    """"""
    def __init__(self, op_type):
        """"""Initialize a new Run object.
        """"""
        self.op_type = op_type
        self.index_map = []
        self.ops = []

    def index(self, idx):
        """"""Get the original index of an operation in this run.

        :Parameters:
          - `idx`: The Run index that maps to the original index.
        """"""
        return self.index_map[idx]

    def add(self, original_index, operation):
        """"""Add an operation to this Run instance.

        :Parameters:
          - `original_index`: The original index of this operation
            within a larger bulk operation.
          - `operation`: The operation document.
        """"""
        self.index_map.append(original_index)
        self.ops.append(operation)","class _Run(object):
    '''Represents a batch of write operations.
    '''

    def __init__(self, op_type):
    '''Initialize a new Run object.
        '''
        pass

    def index(self, idx):
    '''Get the original index of an operation in this run.

        :Parameters:
          - `idx`: The Run index that maps to the original index.
        '''
        pass

    def add(self, original_index, operation):
    '''Add an operation to this Run instance.

        :Parameters:
          - `original_index`: The original index of this operation
            within a larger bulk operation.
          - `operation`: The operation document.
        '''
        pass

",4,4,snippet_99,1.0,"class _Run(object):
    '''Represents a batch of write operations.
    '''
    def __init__(self, op_type):
        '''Initialize a new Run object.
        '''
        self.op_type = op_type
        self._original_indexes = []
        self._operations = []

    def index(self, idx):
        '''Get the original index of an operation in this run.

        :Parameters:
          - `idx`: The Run index that maps to the original index.
        '''
        return self._original_indexes[idx]

    def add(self, original_index, operation):
        '''Add an operation to this Run instance.

        :Parameters:
          - `original_index`: The original index of this operation
            within a larger bulk operation.
          - `operation`: The operation document.
        '''
        self._original_indexes.append(original_index)
        self._operations.append(operation)","class _Run(object):
    '''Represents a batch of write operations.
    '''

    def __init__(self, op_type):
        '''Initialize a new Run object.
        '''
        self.op_type = op_type
        self.operations = []
        self.original_indexes = []

    def index(self, idx):
        '''Get the original index of an operation in this run.

        :Parameters:
          - `idx`: The Run index that maps to the original index.
        '''
        return self.original_indexes[idx]

    def add(self, original_index, operation):
        '''Add an operation to this Run instance.

        :Parameters:
          - `original_index`: The original index of this operation
            within a larger bulk operation.
          - `operation`: The operation document.
        '''
        self.original_indexes.append(original_index)
        self.operations.append(operation)","class _Run(object):
    '''Represents a batch of write operations.
    '''

    def __init__(self, op_type):
        '''Initialize a new Run object.
        '''
        self.op_type = op_type
        self.ops = []
        self.idx_map = []

    def index(self, idx):
        '''Get the original index of an operation in this run.

        :Parameters:
          - `idx`: The Run index that maps to the original index.
        '''
        return self.idx_map[idx]

    def add(self, original_index, operation):
        '''Add an operation to this Run instance.

        :Parameters:
          - `original_index`: The original index of this operation
            within a larger bulk operation.
          - `operation`: The operation document.
        '''
        self.ops.append(operation)
        self.idx_map.append(original_index)",full_docstr,0.92,0.8686868686868688,0.826530612244898,0.92,0.7373269734316513,0.8858695652173914,0.7978142076502732,0.7252747252747253,0.9756581783294678,0.9799192547798157,0.9777840971946716,0.9794915318489075,1.0,0.92,0.8686868686868688,0.826530612244898,0.92,0.7353468410943852,0.9106145251396648,0.8202247191011236,0.7457627118644068,0.9754780530929565,0.9796270728111267,0.9775482416152954,0.9792106747627258,1.0,0.97,0.9090909090909091,0.8571428571428571,0.91,0.7799092534274137,0.9385474860335196,0.8764044943820225,0.807909604519774,0.9830584526062012,0.9868053197860718,0.98492830991745,0.9864293932914734,1.0,0.8412500482173308,0.6793887979914963,0.6856113948778273,1.0,1.0,0.8303804829999395,0.6793887979914963,0.6856113948778273,1.0,0.9565217391304348,0.8352780363594035,0.6896858650491994,0.6949045412579797,1.0,0.9565217391304348
337126,denisenkom/pytds,denisenkom_pytds/src/pytds/tds_types.py,pytds.tds_types.PlpReader,"class PlpReader(object):
    """"""Partially length prefixed reader

    Spec: http://msdn.microsoft.com/en-us/library/dd340469.aspx
    """"""

    def __init__(self, r):
        """"""
        :param r: An instance of :class:`_TdsReader`
        """"""
        self._rdr = r
        size = r.get_uint8()
        self._size = size

    def is_null(self):
        """"""
        :return: True if stored value is NULL
        """"""
        return self._size == tds_base.PLP_NULL

    def is_unknown_len(self):
        """"""
        :return: True if total size is unknown upfront
        """"""
        return self._size == tds_base.PLP_UNKNOWN

    def size(self):
        """"""
        :return: Total size in bytes if is_uknown_len and is_null are both False
        """"""
        return self._size

    def chunks(self):
        """"""Generates chunks from stream, each chunk is an instace of bytes.""""""
        if self.is_null():
            return
        total = 0
        while True:
            chunk_len = self._rdr.get_uint()
            if chunk_len == 0:
                if not self.is_unknown_len() and total != self._size:
                    msg = (
                        ""PLP actual length (%d) doesn't match reported length (%d)""
                        % (total, self._size)
                    )
                    self._rdr.session.bad_stream(msg)

                return

            total += chunk_len
            left = chunk_len
            while left:
                buf = self._rdr.recv(left)
                yield buf
                left -= len(buf)","class PlpReader(object):
    '''Partially length prefixed reader

    Spec: http://msdn.microsoft.com/en-us/library/dd340469.aspx
    '''

    def __init__(self, r):
    '''
        :param r: An instance of :class:`_TdsReader`
        '''
        pass

    def is_null(self):
    '''
        :return: True if stored value is NULL
        '''
        pass

    def is_unknown_len(self):
    '''
        :return: True if total size is unknown upfront
        '''
        pass

    def size(self):
    '''
        :return: Total size in bytes if is_uknown_len and is_null are both False
        '''
        pass

    def chunks(self):
    '''Generates chunks from stream, each chunk is an instace of bytes.'''
        pass

",6,6,snippet_580,0.1666666666666666,"class PlpReader(object):
    '''Partially length prefixed reader

    Spec: http://msdn.microsoft.com/en-us/library/dd340469.aspx
    '''

    NULL_LEN = 0xFFFFFFFFFFFFFFFE
    UNKNOWN_LEN = 0xFFFFFFFFFFFFFFFF

    def __init__(self, r):
        '''
            :param r: An instance of :class:`_TdsReader`
        '''
        self._r = r
        raw = self._r.read(8)
        if len(raw) < 8:
            raise EOFError(""Unable to read PLP total length"")
        self._total_length = struct.unpack('<Q', raw)[0]

    def is_null(self):
        '''
            :return: True if stored value is NULL
        '''
        return self._total_length == self.NULL_LEN

    def is_unknown_len(self):
        '''
            :return: True if total size is unknown upfront
        '''
        return self._total_length == self.UNKNOWN_LEN

    def size(self):
        '''
            :return: Total size in bytes if is_unknown_len and is_null are both False
        '''
        if self.is_null():
            raise ValueError(""Value is NULL"")
        if self.is_unknown_len():
            raise ValueError(""Total size is unknown"")
        return self._total_length

    def chunks(self):
        '''Generates chunks from stream, each chunk is an instance of bytes.'''
        if self.is_null():
            return
        while True:
            raw = self._r.read(4)
            if len(raw) < 4:
                raise EOFError(""Unable to read PLP chunk length"")
            chunk_len = struct.unpack('<I', raw)[0]
            if chunk_len == 0:
                break
            data = self._r.read(chunk_len)
            if len(data) < chunk_len:
                raise EOFError(""Unable to read full PLP chunk"")
            yield data","class PlpReader(object):
    '''Partially length prefixed reader

    Spec: http://msdn.microsoft.com/en-us/library/dd340469.aspx
    '''

    def __init__(self, r):
        '''
        :param r: An instance of :class:`_TdsReader`
        '''
        self._r = r
        self._is_null = None
        self._is_unknown_len = None
        self._size = None
        self._finished = False

    def is_null(self):
        '''
        :return: True if stored value is NULL
        '''
        if self._is_null is None:
            self._read_header()
        return self._is_null

    def is_unknown_len(self):
        '''
        :return: True if total size is unknown upfront
        '''
        if self._is_unknown_len is None:
            self._read_header()
        return self._is_unknown_len

    def size(self):
        '''
        :return: Total size in bytes if is_uknown_len and is_null are both False
        '''
        if self._size is None:
            self._read_header()
        return self._size

    def chunks(self):
        '''Generates chunks from stream, each chunk is an instace of bytes.'''
        if self.is_null():
            return
        
        if self.is_unknown_len():
            while not self._finished:
                chunk_len = self._r.read_uint32()
                if chunk_len == 0:
                    self._finished = True
                    break
                yield self._r.read(chunk_len)
        else:
            remaining = self._size
            while remaining > 0:
                chunk_len = min(remaining, 0x7FFFFFFF)  # Max chunk size
                yield self._r.read(chunk_len)
                remaining -= chunk_len

    def _read_header(self):
        '''Read the PLP header to determine null status, unknown length, and size'''
        length = self._r.read_uint64()
        if length == 0xFFFFFFFFFFFFFFFF:
            self._is_null = True
            self._is_unknown_len = False
            self._size = 0
        elif length == 0xFFFFFFFFFFFFFFFE:
            self._is_null = False
            self._is_unknown_len = True
            self._size = 0
        else:
            self._is_null = False
            self._is_unknown_len = False
            self._size = length","class PlpReader(object):
    '''Partially length prefixed reader

    Spec: http://msdn.microsoft.com/en-us/library/dd340469.aspx
    '''

    def __init__(self, r):
        '''
        :param r: An instance of :class:`_TdsReader`
        '''
        self._reader = r
        self._size = r.get_uint8()
        
        if self._size == 0xFFFFFFFFFFFFFFFF:
            # NULL value
            self._is_null = True
            self._is_unknown_len = False
            self._total_size = 0
        elif self._size == 0xFFFFFFFFFFFFFFFE:
            # Unknown length
            self._is_null = False
            self._is_unknown_len = True
            self._total_size = 0
        else:
            # Known length
            self._is_null = False
            self._is_unknown_len = False
            self._total_size = self._size

    def is_null(self):
        '''
        :return: True if stored value is NULL
        '''
        return self._is_null

    def is_unknown_len(self):
        '''
        :return: True if total size is unknown upfront
        '''
        return self._is_unknown_len

    def size(self):
        '''
        :return: Total size in bytes if is_uknown_len and is_null are both False
        '''
        if self._is_unknown_len or self._is_null:
            return None
        return self._total_size

    def chunks(self):
        '''Generates chunks from stream, each chunk is an instace of bytes.'''
        if self._is_null:
            return
            
        if self._is_unknown_len:
            while True:
                chunk_len = self._reader.get_uint4()
                if chunk_len == 0:
                    break
                yield self._reader.read(chunk_len)
        else:
            remaining = self._total_size
            while remaining > 0:
                chunk_len = self._reader.get_uint4()
                if chunk_len == 0:
                    break
                chunk_data = self._reader.read(chunk_len)
                remaining -= chunk_len
                yield chunk_data",full_docstr,0.6836734693877551,0.4923076923076923,0.4175257731958763,0.5816326530612244,0.5027642041496504,0.7070707070707071,0.47848101265822784,0.3756345177664975,0.8400421142578125,0.8802226185798645,0.8596631288528442,0.8760324716567993,0.8185346332046333,0.6334841628959276,0.49090909090909085,0.406392694063927,0.5610859728506787,0.43293497452202795,0.5647773279352226,0.4158215010141988,0.34552845528455284,0.8599968552589417,0.897236704826355,0.8782221674919128,0.8933683037757874,0.8071298113207551,0.705596107055961,0.5574572127139364,0.4766584766584766,0.6228710462287106,0.4858647347389984,0.6210045662100456,0.47368421052631576,0.38990825688073394,0.8944913148880005,0.9006524682044983,0.897561252117157,0.9000325202941895,0.8010159315589354,0.3928604764682572,0.2657003443325728,0.3147891805880752,0.61,0.3809523809523809,0.4340861065811764,0.2590537146135555,0.3741161085365471,0.5,0.6031746031746031,0.4641781932873829,0.2990252636620778,0.3727668745668189,0.55,0.6349206349206349
116998,Duke-GCB/DukeDSClient,Duke-GCB_DukeDSClient/ddsc/core/d4s2.py,ddsc.core.d4s2.UploadedFileRelations,"class UploadedFileRelations(object):
    """"""
    Contains run method that will be called via project upload file post-processor.
    """"""
    def __init__(self, activity):
        """"""
        :param activity: CopyActivity: info about the activity associated with the files we are uploading
        """"""
        self.activity = activity

    def run(self, data_service, file_details):
        """"""
        Attach a remote file to activity with was generated by relationship.
        :param data_service: DataServiceApi: service used to attach relationship
        :param file_details: dict: response from DukeDS POST to /files/ containing current_version id
        """"""
        file_version_id = file_details['current_version']['id']
        data_service.create_was_generated_by_relation(self.activity.id, KindType.file_str, file_version_id)
        used_entity_id = self._lookup_used_entity_id(file_details)
        data_service.create_was_derived_from_relation(used_entity_id, KindType.file_str,
                                                      file_version_id, KindType.file_str)

    def _lookup_used_entity_id(self, file_details):
        """"""
        Return the file_version_id associated with the path from file_details.
        The file_version_id is looked up from a dictionary in the activity.
        :param file_details: dict: response from DukeDS POST to /files/
        :return: str: file_version_id uuid
        """"""
        # Since this uses the response from POST to /files/ this will include the ancestors and not be
        # effected by exclude_response_fields that were used when listing the project
        name_parts = [ancestor['name'] for ancestor in file_details['ancestors']
                      if ancestor['kind'] == KindType.folder_str]
        name_parts.append(file_details['name'])
        remote_path = RemotePath.add_leading_slash(os.sep.join(name_parts))
        return self.activity.remote_path_to_file_version_id[remote_path]","class UploadedFileRelations(object):
    '''
    Contains run method that will be called via project upload file post-processor.
    '''

    def __init__(self, activity):
    '''
        :param activity: CopyActivity: info about the activity associated with the files we are uploading
        '''
        pass

    def run(self, data_service, file_details):
    '''
        Attach a remote file to activity with was generated by relationship.
        :param data_service: DataServiceApi: service used to attach relationship
        :param file_details: dict: response from DukeDS POST to /files/ containing current_version id
        '''
        pass

    def _lookup_used_entity_id(self, file_details):
    '''
        Return the file_version_id associated with the path from file_details.
        The file_version_id is looked up from a dictionary in the activity.
        :param file_details: dict: response from DukeDS POST to /files/
        :return: str: file_version_id uuid
        '''
        pass

",4,4,snippet_105,0.4444444444444444,"class UploadedFileRelations(object):
    '''
    Contains run method that will be called via project upload file post-processor.
    '''

    def __init__(self, activity):
        '''
        :param activity: CopyActivity: info about the activity associated with the files we are uploading
        '''
        self.activity = activity

    def run(self, data_service, file_details):
        '''
        Attach a remote file to activity with wasGeneratedBy relationship,
        and, if there is a matching used entity, attach wasDerivedFrom.
        :param data_service: DataServiceApi: service used to attach relationship
        :param file_details: dict: response from DukeDS POST to /files/ containing current_version id
        '''
        current_version = file_details.get('current_version', {})
        file_version_id = current_version.get('id')
        if not file_version_id:
            return

        # wasGeneratedBy: file_version -> activity
        data_service.create_relationship(
            subject_id=file_version_id,
            subject_type='FILE_VERSION',
            predicate='wasGeneratedBy',
            object_id=self.activity.id,
            object_type='ACTIVITY'
        )

        # wasDerivedFrom: file_version -> used input file (if any)
        used_entity_id = self._lookup_used_entity_id(file_details)
        if used_entity_id:
            data_service.create_relationship(
                subject_id=file_version_id,
                subject_type='FILE_VERSION',
                predicate='wasDerivedFrom',
                object_id=used_entity_id,
                object_type='FILE_VERSION'
            )

    def _lookup_used_entity_id(self, file_details):
        '''
        Return the file_version_id associated with the path from file_details.
        The file_version_id is looked up from a dictionary in the activity.
        :param file_details: dict: response from DukeDS POST to /files/
        :return: str or None: file_version_id uuid
        '''
        path = file_details.get('path')
        if not path:
            return None
        used_map = getattr(self.activity, 'used_entities', {})
        return used_map.get(path)","class UploadedFileRelations(object):
    '''
    Contains run method that will be called via project upload file post-processor.
    '''

    def __init__(self, activity):
        '''
        :param activity: CopyActivity: info about the activity associated with the files we are uploading
        '''
        self.activity = activity

    def run(self, data_service, file_details):
        '''
        Attach a remote file to activity with was generated by relationship.
        :param data_service: DataServiceApi: service used to attach relationship
        :param file_details: dict: response from DukeDS POST to /files/ containing current_version id
        '''
        used_entity_id = self._lookup_used_entity_id(file_details)
        if used_entity_id:
            data_service.create_relationship(
                from_entity_id=file_details['current_version']['id'],
                to_entity_id=used_entity_id,
                relationship_type='wasGeneratedBy'
            )

    def _lookup_used_entity_id(self, file_details):
        '''
        Return the file_version_id associated with the path from file_details.
        The file_version_id is looked up from a dictionary in the activity.
        :param file_details: dict: response from DukeDS POST to /files/
        :return: str: file_version_id uuid
        '''
        file_path = file_details.get('path')
        if file_path and hasattr(self.activity, 'used_files') and self.activity.used_files:
            return self.activity.used_files.get(file_path)
        return None","class UploadedFileRelations(object):
    '''
    Contains run method that will be called via project upload file post-processor.
    '''

    def __init__(self, activity):
        '''
        :param activity: CopyActivity: info about the activity associated with the files we are uploading
        '''
        self.activity = activity

    def run(self, data_service, file_details):
        '''
        Attach a remote file to activity with was generated by relationship.
        :param data_service: DataServiceApi: service used to attach relationship
        :param file_details: dict: response from DukeDS POST to /files/ containing current_version id
        '''
        used_entity_id = self._lookup_used_entity_id(file_details)
        if used_entity_id:
            current_version_id = file_details.get('current_version', {}).get('id')
            if current_version_id:
                data_service.create_used_relation(
                    activity_id=self.activity.id,
                    entity_id=used_entity_id,
                    generated_entity_id=current_version_id
                )

    def _lookup_used_entity_id(self, file_details):
        '''
        Return the file_version_id associated with the path from file_details.
        The file_version_id is looked up from a dictionary in the activity.
        :param file_details: dict: response from DukeDS POST to /files/
        :return: str: file_version_id uuid
        '''
        file_path = file_details.get('name')
        if hasattr(self.activity, 'file_version_map') and file_path:
            return self.activity.file_version_map.get(file_path)
        return None",full_docstr,0.708910891089109,0.6043737574552684,0.5349301397205588,0.6534653465346534,0.5893275441264805,0.7289293849658315,0.5707762557077626,0.5125858123569794,0.8842954635620117,0.8789560794830322,0.8816176652908325,0.879487156867981,0.8047157575757575,0.7640449438202247,0.672686230248307,0.6394557823129252,0.701123595505618,0.5375244635088302,0.9009287925696594,0.7732919254658385,0.6947040498442367,0.943771481513977,0.8824536800384521,0.9120831489562988,0.8882245421409607,0.8098058235294118,0.780701754385965,0.6740088105726872,0.6283185840707964,0.7105263157894737,0.5725332474234949,0.882183908045977,0.7435158501440923,0.661849710982659,0.9398940205574036,0.8831544518470764,0.9106412529945374,0.8885181546211243,0.8215704117647058,0.5599652343405148,0.4902028728295627,0.5276978968176117,0.4861111111111111,0.7358490566037735,0.538132966171141,0.543690493240247,0.5676988137923256,0.5694444444444444,0.4716981132075472,0.5234114539306381,0.5484651752115332,0.5685034916640594,0.4861111111111111,0.490566037735849
388805,fracpete/python-weka-wrapper3,fracpete_python-weka-wrapper3/python/weka/associations.py,python.weka.associations.AssociationRulesIterator,"class AssociationRulesIterator(object):
    """"""
    Iterator for weka.associations.AssociationRules class.
    """"""

    def __init__(self, rules):
        """"""
        Initializes with the rules.

        :param rules: the rules to use
        :type rules: AssociationRules
        """"""
        self.rules = rules
        self.index = 0
        self.length = len(rules)

    def __iter__(self):
        """"""
        Returns itself.
        """"""
        return self

    def __next__(self):
        """"""
        Returns the next rule.

        :return: the next rule object
        :rtype: AssociationRule
        """"""
        if self.index < self.length:
            index = self.index
            self.index += 1
            return self.rules[index]
        else:
            raise StopIteration()","class AssociationRulesIterator(object):
    '''
    Iterator for weka.associations.AssociationRules class.
    '''

    def __init__(self, rules):
    '''
        Initializes with the rules.

        :param rules: the rules to use
        :type rules: AssociationRules
        '''
        pass

    def __iter__(self):
    '''
        Returns itself.
        '''
        pass

    def __next__(self):
    '''
        Returns the next rule.

        :return: the next rule object
        :rtype: AssociationRule
        '''
        pass

",4,4,snippet_672,1.0,"class AssociationRulesIterator(object):
    '''
    Iterator for weka.associations.AssociationRules class.
    '''

    def __init__(self, rules):
        '''
        Initializes with the rules.

        :param rules: the rules to use
        :type rules: AssociationRules
        '''
        self._rules = list(rules.rules)
        self._index = 0

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def __next__(self):
        '''
        Returns the next rule.

        :return: the next rule object
        :rtype: AssociationRule
        '''
        if self._index >= len(self._rules):
            raise StopIteration
        rule = self._rules[self._index]
        self._index += 1
        return rule","class AssociationRulesIterator(object):
    '''
    Iterator for weka.associations.AssociationRules class.
    '''

    def __init__(self, rules):
        '''
        Initializes with the rules.

        :param rules: the rules to use
        :type rules: AssociationRules
        '''
        self._rules = rules
        self._index = 0

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def __next__(self):
        '''
        Returns the next rule.

        :return: the next rule object
        :rtype: AssociationRule
        '''
        if self._index >= self._rules.numRules:
            raise StopIteration
        
        rule = self._rules.get(self._index)
        self._index += 1
        return rule","class AssociationRulesIterator(object):
    '''
    Iterator for weka.associations.AssociationRules class.
    '''

    def __init__(self, rules):
        '''
        Initializes with the rules.

        :param rules: the rules to use
        :type rules: AssociationRules
        '''
        self.rules = rules
        self.index = 0

    def __iter__(self):
        '''
        Returns itself.
        '''
        return self

    def __next__(self):
        '''
        Returns the next rule.

        :return: the next rule object
        :rtype: AssociationRule
        '''
        if self.index >= len(self.rules):
            raise StopIteration
        rule = self.rules[self.index]
        self.index += 1
        return rule",full_docstr,0.9324324324324323,0.8356164383561645,0.7638888888888888,0.8513513513513513,0.6329626879688036,0.8666666666666667,0.697986577181208,0.5337837837837838,0.9722568392753601,0.9682737588882446,0.9702612161636353,0.9686706066131592,0.8809535714285714,0.9251700680272109,0.8551724137931033,0.7972027972027972,0.8571428571428572,0.618101990820177,0.8561643835616438,0.6827586206896552,0.5625,0.9700206518173218,0.9666115045547485,0.9683130383491516,0.9669513702392578,0.8843548979591837,0.9452054794520549,0.8472222222222222,0.7887323943661971,0.863013698630137,0.6660923390086319,0.9202898550724637,0.8029197080291971,0.6764705882352942,0.9817185997962952,0.9730597734451294,0.9773699641227722,0.9739188551902771,0.8911575510204082,0.4001281485677357,0.4349088898613326,0.4517989906048965,0.4545454545454545,0.2592592592592592,0.4416511180137404,0.4400713887574587,0.4561627129271327,0.5,0.3703703703703703,0.5483643898943598,0.5062622579078515,0.5205286350029209,0.5,0.6666666666666666
181795,Robpol86/libnl,Robpol86_libnl/libnl/netlink_private/types.py,libnl.netlink_private.types.nl_msg,"class nl_msg(object):
    """"""https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/types.h#L133.

    Client-side only. Never transmitted to the kernel.

    Instance variables:
    nm_protocol -- integer.
    nm_flags -- integer.
    nm_src -- sockaddr_nl class instance.
    nm_dst -- sockaddr_nl class instance.
    nm_creds -- ucred class instance.
    nm_nlh -- nlmsghdr class instance.
    nm_size -- integer.
    nm_refcnt -- integer.
    """"""

    def __init__(self):
        """"""Constructor.""""""
        self.nm_protocol = 0
        self.nm_flags = 0
        self.nm_src = sockaddr_nl()
        self.nm_dst = sockaddr_nl()
        self.nm_creds = None
        self.nm_nlh = None
        self.nm_size = 0
        self.nm_refcnt = 1

    def __repr__(self):
        """"""repr() handler.""""""
        answer_base = (""<{0}.{1} nm_protocol={2} nm_flags={3} nm_src='{4}' nm_dst='{5}' nm_creds='{6}' nm_nlh='{7}' ""
                       ""nm_size='{8}'>"")
        answer = answer_base.format(
            self.__class__.__module__,
            self.__class__.__name__,
            self.nm_protocol, self.nm_flags, self.nm_src, self.nm_dst, self.nm_creds, self.nm_nlh, self.nm_size,
        )
        return answer","class nl_msg(object):
    '''https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/types.h#L133.

    Client-side only. Never transmitted to the kernel.

    Instance variables:
    nm_protocol -- integer.
    nm_flags -- integer.
    nm_src -- sockaddr_nl class instance.
    nm_dst -- sockaddr_nl class instance.
    nm_creds -- ucred class instance.
    nm_nlh -- nlmsghdr class instance.
    nm_size -- integer.
    nm_refcnt -- integer.
    '''

    def __init__(self):
    '''Constructor.'''
        pass

    def __repr__(self):
    '''repr() handler.'''
        pass

",3,3,snippet_241,0.75,"class nl_msg(object):
    '''https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/types.h#L133.

    Client-side only. Never transmitted to the kernel.

    Instance variables:
    nm_protocol -- integer.
    nm_flags -- integer.
    nm_src -- sockaddr_nl class instance.
    nm_dst -- sockaddr_nl class instance.
    nm_creds -- ucred class instance.
    nm_nlh -- nlmsghdr class instance.
    nm_size -- integer.
    nm_refcnt -- integer.
    '''

    def __init__(self):
        '''Constructor.'''
        # protocol family (e.g. NETLINK_ROUTE)
        self.nm_protocol = 0
        # message flags (e.g. NLM_F_REQUEST)
        self.nm_flags = 0
        # source sockaddr_nl
        self.nm_src = sockaddr_nl()
        # destination sockaddr_nl
        self.nm_dst = sockaddr_nl()
        # credentials ucred
        self.nm_creds = ucred()
        # netlink message header
        self.nm_nlh = nlmsghdr()
        # total message size
        self.nm_size = 0
        # reference count
        self.nm_refcnt = 1

    def __repr__(self):
        '''repr() handler.'''
        cls = self.__class__.__name__
        return (
            f""{cls}(nm_protocol={self.nm_protocol!r}, ""
            f""nm_flags={self.nm_flags!r}, ""
            f""nm_src={self.nm_src!r}, ""
            f""nm_dst={self.nm_dst!r}, ""
            f""nm_creds={self.nm_creds!r}, ""
            f""nm_nlh={self.nm_nlh!r}, ""
            f""nm_size={self.nm_size!r}, ""
            f""nm_refcnt={self.nm_refcnt!r})""
        )","class nl_msg(object):
    '''https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/types.h#L133.

    Client-side only. Never transmitted to the kernel.

    Instance variables:
    nm_protocol -- integer.
    nm_flags -- integer.
    nm_src -- sockaddr_nl class instance.
    nm_dst -- sockaddr_nl class instance.
    nm_creds -- ucred class instance.
    nm_nlh -- nlmsghdr class instance.
    nm_size -- integer.
    nm_refcnt -- integer.
    '''

    def __init__(self):
        '''Constructor.'''
        self.nm_protocol = 0
        self.nm_flags = 0
        self.nm_src = None
        self.nm_dst = None
        self.nm_creds = None
        self.nm_nlh = None
        self.nm_size = 0
        self.nm_refcnt = 0

    def __repr__(self):
        '''repr() handler.'''
        return f""<nl_msg protocol={self.nm_protocol} flags={self.nm_flags} size={self.nm_size} refcnt={self.nm_refcnt}>""","class nl_msg(object):
    '''https://github.com/thom311/libnl/blob/libnl3_2_25/include/netlink-private/types.h#L133.

    Client-side only. Never transmitted to the kernel.

    Instance variables:
    nm_protocol -- integer.
    nm_flags -- integer.
    nm_src -- sockaddr_nl class instance.
    nm_dst -- sockaddr_nl class instance.
    nm_creds -- ucred class instance.
    nm_nlh -- nlmsghdr class instance.
    nm_size -- integer.
    nm_refcnt -- integer.
    '''

    def __init__(self):
        '''Constructor.'''
        self.nm_protocol = 0
        self.nm_flags = 0
        self.nm_src = None
        self.nm_dst = None
        self.nm_creds = None
        self.nm_nlh = None
        self.nm_size = 0
        self.nm_refcnt = 0

    def __repr__(self):
        '''repr() handler.'''
        return (f""nl_msg(nm_protocol={self.nm_protocol}, nm_flags={self.nm_flags}, ""
                f""nm_src={self.nm_src}, nm_dst={self.nm_dst}, nm_creds={self.nm_creds}, ""
                f""nm_nlh={self.nm_nlh}, nm_size={self.nm_size}, nm_refcnt={self.nm_refcnt})"")",full_docstr,0.7977839335180056,0.701949860724234,0.6162464985994397,0.7091412742382271,0.6382008598847112,0.7985611510791367,0.6057692307692307,0.5373493975903615,0.8998017907142639,0.9276936650276184,0.9135348796844482,0.924826979637146,0.8404271276595744,0.8194444444444444,0.7412587412587412,0.6901408450704226,0.7777777777777778,0.47975361940973466,0.9504132231404959,0.8340248962655602,0.7666666666666667,0.972027599811554,0.9273996353149414,0.9491893649101257,0.9316772222518921,0.8759136496350365,0.8917197452229298,0.7948717948717949,0.7225806451612903,0.7898089171974522,0.6273898100501171,0.948220064724919,0.7564935064935064,0.6807817589576547,0.96722012758255,0.9389262199401855,0.9528632164001465,0.9416808485984802,0.8637483211678831,0.4950242797352152,0.4232536233610909,0.5328838486693033,0.639344262295082,0.3846153846153846,0.4991800965402291,0.5680103439319563,0.5992648972100447,0.5409836065573771,0.2884615384615384,0.5016420637990507,0.5764884556955716,0.6006346544817158,0.5409836065573771,0.2884615384615384
189146,SpriteLink/NIPAP,nipap/nipap/authlib.py,nipap.authlib.BaseAuth,"class BaseAuth:
    """""" A base authentication class.

        All authentication modules should extend this class.
    """"""

    username = None
    password = None
    authenticated_as = None
    full_name = None
    authoritative_source = None
    auth_backend = None
    trusted = None
    readonly = None

    _logger = None
    _auth_options = None
    _cfg = None

    def __init__(self, username, password, authoritative_source, auth_backend, auth_options=None):
        """""" Constructor.

            Note that the instance variables not are set by the constructor but
            by the :func:`authenticate` method. Therefore, run the
            :func:`authenticate`-method before trying to access those
            variables!

            * `username` [string]
                Username to authenticate as.
            * `password` [string]
                Password to authenticate with.
            * `authoritative_source` [string]
                Authoritative source of the query.
            * `auth_backend` [string]
                Name of authentication backend.
            * `auth_options` [dict]
                A dict which, if authenticated as a trusted user, can override
                `username` and `authoritative_source`.
        """"""

        if auth_options is None:
            auth_options = {}

        self._logger = logging.getLogger(self.__class__.__name__)
        self._cfg = NipapConfig()

        self.username = username
        self.password = password
        self.auth_backend = auth_backend
        self.authoritative_source = authoritative_source

        self._auth_options = auth_options

    def authenticate(self):
        """""" Verify authentication.

            Returns True/False dependant on whether the authentication
            succeeded or not.
        """"""

        return False

    def authorize(self):
        """""" Verify authorization.

            Check if a user is authorized to perform a specific operation.
        """"""
        return False","class BaseAuth:
    ''' A base authentication class.

        All authentication modules should extend this class.
    '''

    def __init__(self, username, password, authoritative_source, auth_backend, auth_options=None):
    ''' Constructor.

            Note that the instance variables not are set by the constructor but
            by the :func:`authenticate` method. Therefore, run the
            :func:`authenticate`-method before trying to access those
            variables!

            * `username` [string]
                Username to authenticate as.
            * `password` [string]
                Password to authenticate with.
            * `authoritative_source` [string]
                Authoritative source of the query.
            * `auth_backend` [string]
                Name of authentication backend.
            * `auth_options` [dict]
                A dict which, if authenticated as a trusted user, can override
                `username` and `authoritative_source`.
        '''
        pass

    def authenticate(self):
    ''' Verify authentication.

            Returns True/False dependant on whether the authentication
            succeeded or not.
        '''
        pass

    def authorize(self):
    ''' Verify authorization.

            Check if a user is authorized to perform a specific operation.
        '''
        pass

",4,4,snippet_256,0.6666666666666666,"class BaseAuth(abc.ABC):
    ''' A base authentication class.

        All authentication modules should extend this class.
    '''

    def __init__(self, username, password, authoritative_source, auth_backend, auth_options=None):
        self._raw_username = username
        self._password = password
        self._raw_authoritative_source = authoritative_source
        self._auth_backend = auth_backend
        self._auth_options = auth_options or {}
        self.authenticated = False
        self.username = None
        self.authoritative_source = None

    @abc.abstractmethod
    def _authenticate_backend(self):
        """"""Return True if credential check against the backend succeeds.""""""
        raise NotImplementedError

    def authenticate(self):
        """"""Verify authentication against the backend and set instance variables.""""""
        ok = self._authenticate_backend()
        if not ok:
            self.authenticated = False
            return False
        self.authenticated = True
        # apply overrides if provided
        self.username = self._auth_options.get('username', self._raw_username)
        self.authoritative_source = self._auth_options.get(
            'authoritative_source',
            self._raw_authoritative_source
        )
        return True

    @abc.abstractmethod
    def authorize(self):
        """"""Return True/False depending on whether the user is authorized.""""""
        raise NotImplementedError","class BaseAuth:
    ''' A base authentication class.

        All authentication modules should extend this class.
    '''

    def __init__(self, username, password, authoritative_source, auth_backend, auth_options=None):
        ''' Constructor.

            Note that the instance variables not are set by the constructor but
            by the :func:`authenticate` method. Therefore, run the
            :func:`authenticate`-method before trying to access those
            variables!

            * `username` [string]
                Username to authenticate as.
            * `password` [string]
                Password to authenticate with.
            * `authoritative_source` [string]
                Authoritative source of the query.
            * `auth_backend` [string]
                Name of authentication backend.
            * `auth_options` [dict]
                A dict which, if authenticated as a trusted user, can override
                `username` and `authoritative_source`.
        '''
        self.username = username
        self.password = password
        self.authoritative_source = authoritative_source
        self.auth_backend = auth_backend
        self.auth_options = auth_options or {}
        
        # Instance variables that will be set by authenticate method
        self.authenticated = False
        self.trusted = False
        self.user = None

    def authenticate(self):
        ''' Verify authentication.

            Returns True/False dependant on whether the authentication
            succeeded or not.
        '''
        # This is a base class implementation that should be overridden
        # by subclasses. For demonstration purposes, we'll return False.
        self.authenticated = False
        return self.authenticated

    def authorize(self):
        ''' Verify authorization.

            Check if a user is authorized to perform a specific operation.
        '''
        # This is a base class implementation that should be overridden
        # by subclasses. For demonstration purposes, we'll return False.
        return False","class BaseAuth:
    ''' A base authentication class.

        All authentication modules should extend this class.
    '''

    def __init__(self, username, password, authoritative_source, auth_backend, auth_options=None):
        ''' Constructor.

            Note that the instance variables not are set by the constructor but
            by the :func:`authenticate` method. Therefore, run the
            :func:`authenticate`-method before trying to access those
            variables!

            * `username` [string]
                Username to authenticate as.
            * `password` [string]
                Password to authenticate with.
            * `authoritative_source` [string]
                Authoritative source of the query.
            * `auth_backend` [string]
                Name of authentication backend.
            * `auth_options` [dict]
                A dict which, if authenticated as a trusted user, can override
                `username` and `authoritative_source`.
        '''
        self.username = username
        self.password = password
        self.authoritative_source = authoritative_source
        self.auth_backend = auth_backend
        self.auth_options = auth_options if auth_options is not None else {}
        self.authenticated = False
        self.authorized = False

    def authenticate(self):
        ''' Verify authentication.

            Returns True/False dependant on whether the authentication
            succeeded or not.
        '''
        raise NotImplementedError(""Subclasses must implement authenticate method"")

    def authorize(self):
        ''' Verify authorization.

            Check if a user is authorized to perform a specific operation.
        '''
        raise NotImplementedError(""Subclasses must implement authorize method"")",full_docstr,0.6022727272727274,0.36,0.2413793103448276,0.375,0.3965671487580413,0.7746478873239436,0.5053003533568905,0.40070921985815605,0.8310355544090271,0.7990684509277344,0.8147385120391846,0.8021539449691772,0.7813641935483875,0.7875894988066826,0.7242206235011989,0.6795180722891566,0.7255369928400955,0.6803603198045597,0.7971014492753623,0.7296511627906976,0.6793002915451894,0.895512580871582,0.911393940448761,0.9033834934234619,0.9097805023193359,0.8247880769230768,0.8556430446194224,0.8021108179419525,0.7586206896551724,0.7769028871391076,0.6722226937546152,0.9172185430463576,0.8338870431893688,0.79,0.9082423448562622,0.9024544954299927,0.9053391814231873,0.9030299782752991,0.814104423076923,0.2006680170797926,0.1136419176266817,0.1394915397162868,0.3943661971830985,0.1551724137931034,0.4426638485499143,0.5754451128370675,0.6175026563018806,0.4225352112676056,0.1551724137931034,0.4483867714444368,0.6213891934686571,0.6131486645286145,0.352112676056338,0.2068965517241379
171841,PyCQA/pylint,tests/functional/c/class_scope.py,functional.c.class_scope.Right,"class Right:
    """"""right""""""
    class Result1:
        """"""result one""""""
        OK = 0
    def work(self) -> Result1:
        """"""good type hint""""""
        return self.Result1.OK","class Right:
    '''right'''

    class Result1:
    '''result one'''

    def work(self) -> Result1:
    '''good type hint'''
        pass

",3,3,snippet_227,1.0,"class Right:
    '''right'''

    class Result1:
        '''result one'''
        def __init__(self, result: int) -> None:
            self.result = result

        def __repr__(self) -> str:
            return f'Result1(result={self.result})'

    def __init__(self, value: int) -> None:
        self.value = value

    def work(self) -> Result1:
        '''good type hint'''
        computed = self.value ** 2
        return self.Result1(computed)","class Right:
    '''right'''

    class Result1:
        '''result one'''
        pass

    def work(self) -> 'Right.Result1':
        '''good type hint'''
        return Right.Result1()","class Right:
    '''right'''

    class Result1:
        '''result one'''
        pass

    def work(self) -> Result1:
        '''good type hint'''
        return self.Result1()",full_docstr,0.4857142857142858,0.4117647058823529,0.33333333333333337,0.4857142857142858,0.15848736889649867,0.22641509433962265,0.1523809523809524,0.11538461538461539,0.7742304801940918,0.8744017481803894,0.8212728500366211,0.8632331490516663,0.7964932631578947,0.8205128205128205,0.6486486486486486,0.5142857142857143,0.8205128205128205,0.22745565476436597,0.6451612903225806,0.4,0.27586206896551724,0.9396502375602722,0.9238108396530151,0.9316632747650146,0.9253706932067871,0.9145307692307691,0.8947368421052632,0.8333333333333333,0.7647058823529411,0.8947368421052632,0.2783918812592351,0.7241379310344828,0.5714285714285714,0.4444444444444444,0.9618512392044067,0.9419896602630615,0.9518167972564697,0.9439387917518616,0.9487184615384615,0.3411225213067199,0.0744736153300685,0.200730755611097,0.2142857142857142,0.875,0.171338322450877,0.0792109290432661,0.088285217903099,0.1428571428571428,0.375,0.2738065283506291,0.1818483989940587,0.1990920001227435,0.2142857142857142,0.5
312284,cohorte/cohorte-herald,python/herald/core.py,herald.core._BundleActivator,"class _BundleActivator(object):
    """"""
    Bundle activator: registers a dummy probe service
    """"""
    def __init__(self):
        """"""
        Sets up members
        """"""
        self._registration = None

    def start(self, context):
        """"""
        Bundle started
        """"""
        # Register the dummy probe service
        self._registration = context.register_service(
            herald.SERVICE_PROBE, herald.probe.DummyProbe(),
            {pelix.constants.SERVICE_RANKING: -100})

    def stop(self, context):
        """"""
        Bundle stopped
        """"""
        self._registration.unregister()
        self._registration = None","class _BundleActivator(object):
    '''
    Bundle activator: registers a dummy probe service
    '''

    def __init__(self):
    '''
        Sets up members
        '''
        pass

    def start(self, context):
    '''
        Bundle started
        '''
        pass

    def stop(self, context):
    '''
        Bundle stopped
        '''
        pass

",4,4,snippet_526,1.0,"class _BundleActivator(object):
    '''
    Bundle activator: registers a dummy probe service
    '''

    class _DummyProbeService(object):
        def probe(self):
            # Dummy implementation
            return ""Probe OK""

    def __init__(self):
        '''
        Sets up members
        '''
        self._service = None
        self._registration = None

    def start(self, context):
        '''
        Bundle started
        '''
        # Instantiate and register the dummy probe service
        self._service = _BundleActivator._DummyProbeService()
        # The interface name can be any agreed-upon string
        interface = 'dummy.probe.service'
        properties = {}
        self._registration = context.register_service(interface,
                                                      self._service,
                                                      properties)

    def stop(self, context):
        '''
        Bundle stopped
        '''
        # Unregister the service if it was registered
        if self._registration:
            try:
                context.unregister_service(self._registration)
            except Exception:
                pass
            finally:
                self._registration = None
                self._service = None","class _BundleActivator(object):
    '''
    Bundle activator: registers a dummy probe service
    '''

    def __init__(self):
        '''
        Sets up members
        '''
        self._registration = None

    def start(self, context):
        '''
        Bundle started
        '''
        # Register a dummy probe service
        class DummyProbeService(object):
            def probe(self):
                return ""dummy""
        
        service = DummyProbeService()
        self._registration = context.register_service(""probe"", service)

    def stop(self, context):
        '''
        Bundle stopped
        '''
        if self._registration is not None:
            self._registration.unregister()
            self._registration = None","class _BundleActivator(object):
    '''
    Bundle activator: registers a dummy probe service
    '''

    def __init__(self):
        '''
        Sets up members
        '''
        self._registration = None
        self._service = None

    def start(self, context):
        '''
        Bundle started
        '''
        self._service = DummyProbeService()
        self._registration = context.register_service(
            ""probe.service"", self._service, {}
        )

    def stop(self, context):
        '''
        Bundle stopped
        '''
        if self._registration:
            self._registration.unregister()
            self._registration = None
        self._service = None",full_docstr,0.6257668711656442,0.4968944099378882,0.4150943396226416,0.5889570552147239,0.4011236091768378,0.5282051282051282,0.3865979381443299,0.3160621761658031,0.8228903412818909,0.8637312650680542,0.8428162932395935,0.8594657182693481,0.8217610416666665,0.8130081300813008,0.6942148760330578,0.6050420168067226,0.7804878048780489,0.5674933912185028,0.7461538461538462,0.5813953488372093,0.484375,0.9263805747032166,0.902207612991333,0.9141342639923096,0.9045679569244385,0.8691601869158879,0.7931034482758621,0.7192982456140351,0.6071428571428571,0.7758620689655173,0.5734051829443901,0.7734375,0.5984251968503937,0.49206349206349204,0.9556667804718018,0.9042757153511047,0.929261326789856,0.9091646671295166,0.8710704716981131,0.3591334466969228,0.1803201574165296,0.3662136293711617,0.45,0.44,0.4257354181291783,0.2966131566020276,0.3713285159146858,0.675,0.36,0.4685645924951115,0.3030569342881791,0.3462014356922668,0.625,0.6
207220,VingtCinq/python-mailchimp,VingtCinq_python-mailchimp/mailchimp3/baseapi.py,mailchimp3.baseapi.BaseApi,"class BaseApi(object):
    """"""
    Simple class to buid path for entities
    """"""

    def __init__(self, mc_client):
        """"""
        Initialize the class with you user_id and secret_key

        :param mc_client: The mailchimp client connection
        :type mc_client: :mod:`mailchimp3.mailchimpclient.MailChimpClient`
        """"""
        super(BaseApi, self).__init__()
        self._mc_client = mc_client
        self.endpoint = ''

    def _build_path(self, *args):
        """"""
        Build path with endpoint and args

        :param args: Tokens in the endpoint URL
        :type args: :py:class:`unicode`
        """"""
        return '/'.join(chain((self.endpoint,), map(str, args)))

    def _iterate(self, url, **queryparams):
        """"""
        Iterate over all pages for the given url. Feed in the result of self._build_path as the url.

        :param url: The url of the endpoint
        :type url: :py:class:`str`
        :param queryparams: The query string parameters
        queryparams['fields'] = []
        queryparams['exclude_fields'] = []
        queryparams['count'] = integer
        queryparams['offset'] = integer
        """"""
        # fields as a query string parameter should be a string with
        # comma-separated substring values to pass along to
        # self._mc_client._get(). It should also contain total_items whenever
        # the parameter is employed, which is forced here.
        if not self._mc_client.enabled:
            return
        if 'fields' in queryparams:
            if 'total_items' not in queryparams['fields'].split(','):
                queryparams['fields'] += ',total_items'
        # Remove offset if provided in queryparams to avoid 'multiple values
        # for keyword argument' TypeError
        queryparams.pop(""offset"", None)

        # Fetch results from mailchimp, up to first count. If count is not
        # provided, return a count of 500. The maximum value supported by the
        # api is 1000, but such a large request can cause 504 errors. See:
        # https://github.com/VingtCinq/python-mailchimp/pull/207
        count = queryparams.pop(""count"", 500)
        result = self._mc_client._get(url=url, offset=0, count=count, **queryparams)
        total = result['total_items']
        # Fetch further results if necessary
        if total > count:
            for offset in range(1, int(total / count) + 1):
                result = merge_results(result, self._mc_client._get(
                    url=url,
                    offset=int(offset * count),
                    count=count,
                    **queryparams
                ))
            return result
        else:  # Further results not necessary
            return result","class BaseApi(object):
    '''
    Simple class to buid path for entities
    '''

    def __init__(self, mc_client):
    '''
        Initialize the class with you user_id and secret_key

        :param mc_client: The mailchimp client connection
        :type mc_client: :mod:`mailchimp3.mailchimpclient.MailChimpClient`
        '''
        pass

    def _build_path(self, *args):
    '''
        Build path with endpoint and args

        :param args: Tokens in the endpoint URL
        :type args: :py:class:`unicode`
        '''
        pass

    def _iterate(self, url, **queryparams):
    '''
        Iterate over all pages for the given url. Feed in the result of self._build_path as the url.

        :param url: The url of the endpoint
        :type url: :py:class:`str`
        :param queryparams: The query string parameters
        queryparams['fields'] = []
        queryparams['exclude_fields'] = []
        queryparams['count'] = integer
        queryparams['offset'] = integer
        '''
        pass

",4,4,snippet_278,0.2142857142857142,"class BaseApi(object):
    '''
    Simple class to build path for entities
    '''

    def __init__(self, mc_client):
        '''
        Initialize the class with your MailChimp client

        :param mc_client: The mailchimp client connection
        :type mc_client: :mod:`mailchimp3.mailchimpclient.MailChimpClient`
        '''
        self.mc_client = mc_client

    def _build_path(self, *args):
        '''
        Build path with endpoint and args

        :param args: Tokens in the endpoint URL
        :type args: :py:class:`unicode`
        '''
        parts = [str(arg).strip('/') for arg in args if arg is not None]
        return '/'.join(parts)

    def _iterate(self, url, **queryparams):
        '''
        Iterate over all pages for the given url. Feed in the result of self._build_path as the url.

        :param url: The url of the endpoint
        :type url: :py:class:`str`
        :param queryparams: The query string parameters
        queryparams['fields'] = []
        queryparams['exclude_fields'] = []
        queryparams['count'] = integer
        queryparams['offset'] = integer
        '''
        params = queryparams.copy()
        offset = params.get('offset', 0)
        count = params.get('count', 1000)
        params['offset'] = offset
        params['count'] = count

        all_items = []
        total_items = None

        while True:
            response = self.mc_client._get(url, **params)
            if total_items is None:
                total_items = response.get('total_items', 0)

            # find the list in the response
            items_key = next((k for k, v in response.items() if isinstance(v, list)), None)
            if not items_key:
                break

            items = response.get(items_key, [])
            all_items.extend(items)

            offset += count
            if offset >= total_items:
                break
            params['offset'] = offset

        return all_items","class BaseApi(object):
    '''
    Simple class to buid path for entities
    '''

    def __init__(self, mc_client):
        '''
        Initialize the class with you user_id and secret_key

        :param mc_client: The mailchimp client connection
        :type mc_client: :mod:`mailchimp3.mailchimpclient.MailChimpClient`
        '''
        self._mc_client = mc_client
        self.endpoint = ''

    def _build_path(self, *args):
        '''
        Build path with endpoint and args

        :param args: Tokens in the endpoint URL
        :type args: :py:class:`unicode`
        '''
        return '/'.join(str(arg) for arg in (self.endpoint,) + args)

    def _iterate(self, url, **queryparams):
        '''
        Iterate over all pages for the given url. Feed in the result of self._build_path as the url.

        :param url: The url of the endpoint
        :type url: :py:class:`str`
        :param queryparams: The query string parameters
        queryparams['fields'] = []
        queryparams['exclude_fields'] = []
        queryparams['count'] = integer
        queryparams['offset'] = integer
        '''
        queryparams['offset'] = 0
        queryparams['count'] = 1000
        
        result = self._mc_client._get(url=url, **queryparams)
        
        for item in result.get(self._get_collection_name(), []):
            yield item
        
        total = result.get('total_items', 0)
        queryparams['offset'] += queryparams['count']
        
        while queryparams['offset'] < total:
            result = self._mc_client._get(url=url, **queryparams)
            for item in result.get(self._get_collection_name(), []):
                yield item
            queryparams['offset'] += queryparams['count']

    def _get_collection_name(self):
        '''
        Get the name of the collection for this endpoint
        '''
        # Default implementation - subclasses should override this
        return 'items'","class BaseApi(object):
    '''
    Simple class to buid path for entities
    '''

    def __init__(self, mc_client):
        '''
        Initialize the class with you user_id and secret_key

        :param mc_client: The mailchimp client connection
        :type mc_client: :mod:`mailchimp3.mailchimpclient.MailChimpClient`
        '''
        self._mc_client = mc_client

    def _build_path(self, *args):
        '''
        Build path with endpoint and args

        :param args: Tokens in the endpoint URL
        :type args: :py:class:`unicode`
        '''
        if hasattr(self, 'endpoint'):
            path_parts = [self.endpoint]
        else:
            path_parts = []
        
        for arg in args:
            if arg is not None:
                path_parts.append(str(arg))
        
        return '/'.join(path_parts)

    def _iterate(self, url, **queryparams):
        '''
        Iterate over all pages for the given url. Feed in the result of self._build_path as the url.

        :param url: The url of the endpoint
        :type url: :py:class:`str`
        :param queryparams: The query string parameters
        queryparams['fields'] = []
        queryparams['exclude_fields'] = []
        queryparams['count'] = integer
        queryparams['offset'] = integer
        '''
        offset = queryparams.get('offset', 0)
        count = queryparams.get('count', 10)
        
        while True:
            current_params = queryparams.copy()
            current_params['offset'] = offset
            current_params['count'] = count
            
            response = self._mc_client._get(url=url, **current_params)
            
            if not response or not isinstance(response, dict):
                break
                
            items_key = None
            for key in response.keys():
                if isinstance(response[key], list) and key != 'links':
                    items_key = key
                    break
            
            if not items_key or not response[items_key]:
                break
                
            for item in response[items_key]:
                yield item
                
            if len(response[items_key]) < count:
                break
                
            offset += count",full_docstr,0.6131386861313869,0.45421245421245415,0.3897058823529412,0.510948905109489,0.3983238064458712,0.8080568720379147,0.5605700712589073,0.46190476190476193,0.9027413129806519,0.839600682258606,0.8700268864631653,0.8455145359039307,0.7588407954545457,0.6728624535315986,0.5149253731343284,0.4831460674157303,0.5836431226765799,0.459434171414185,0.8369304556354916,0.6778846153846154,0.5951807228915663,0.9257560968399048,0.8510646820068359,0.8868405222892761,0.8579869866371155,0.7752547727272732,0.6178571428571428,0.46953405017921146,0.420863309352518,0.5142857142857142,0.42570576627463474,0.7790432801822323,0.5662100456621004,0.4919908466819222,0.8874208331108093,0.8376816511154175,0.8618342280387878,0.8424032926559448,0.7436894318181821,0.3382245949160739,0.2779745819079197,0.3115624532185608,0.4033613445378151,0.36,0.3585727845977776,0.3097209389374336,0.3478755215825284,0.4033613445378151,0.3733333333333333,0.3420273002071871,0.3101160803475832,0.3479651092766832,0.4033613445378151,0.3066666666666666
116572,Dirrot/python-cryptocoincharts-api,Dirrot_python-cryptocoincharts-api/CryptoCoinChartsApi/Models/Coin.py,CryptoCoinChartsApi.Models.Coin.Coin,"class Coin(object):
    '''
    This is a model for a Coin object.
    '''
    
    def __init__(self, id = """", name = """", website = """", price_btc = """", volume_btc = """"):
        '''
        Simple constructor for a Coin.
        '''
        self.id = id
        self.name = name
        self.website = website
        self.price_btc = price_btc
        self.volume_btc = volume_btc
        
    def __repr__(self):
        '''
        The typ representation of a Coin.
        '''
        return ""Coin""
    
    def __str__(self):
        '''
        The string representation of a Coin.
        '''
        return ""Coin: ["" + self.id + '/' + self.name + ""] - "" + self.price_btc","class Coin(object):
    '''
    This is a model for a Coin object.
    '''

    def __init__(self, id = """", name = """", website = """", price_btc = """", volume_btc = """"):
    '''
        Simple constructor for a Coin.
        '''
        pass

    def __repr__(self):
    '''
        The typ representation of a Coin.
        '''
        pass

    def __str__(self):
    '''
        The string representation of a Coin.
        '''
        pass

",4,4,snippet_103,1.0,"class Coin(object):
    '''
    This is a model for a Coin object.
    '''

    def __init__(self, id="""", name="""", website="""", price_btc="""", volume_btc=""""):
        '''
        Simple constructor for a Coin.
        '''
        self.id = id
        self.name = name
        self.website = website
        self.price_btc = price_btc
        self.volume_btc = volume_btc

    def __repr__(self):
        '''
        The typ representation of a Coin.
        '''
        return (
            ""Coin(id={!r}, name={!r}, website={!r}, ""
            ""price_btc={!r}, volume_btc={!r})""
        ).format(
            self.id,
            self.name,
            self.website,
            self.price_btc,
            self.volume_btc
        )

    def __str__(self):
        '''
        The string representation of a Coin.
        '''
        return (
            f""{self.name} ({self.id})\n""
            f""Website: {self.website}\n""
            f""Price (BTC): {self.price_btc}\n""
            f""Volume (BTC): {self.volume_btc}""
        )","class Coin(object):
    '''
    This is a model for a Coin object.
    '''

    def __init__(self, id = """", name = """", website = """", price_btc = """", volume_btc = """"):
        '''
        Simple constructor for a Coin.
        '''
        self.id = id
        self.name = name
        self.website = website
        self.price_btc = price_btc
        self.volume_btc = volume_btc

    def __repr__(self):
        '''
        The typ representation of a Coin.
        '''
        return f""Coin(id='{self.id}', name='{self.name}', website='{self.website}', price_btc='{self.price_btc}', volume_btc='{self.volume_btc}')""

    def __str__(self):
        '''
        The string representation of a Coin.
        '''
        return f""Coin: {self.name} ({self.id}) - Price: {self.price_btc} BTC, Volume: {self.volume_btc} BTC""","class Coin(object):
    '''
    This is a model for a Coin object.
    '''

    def __init__(self, id = """", name = """", website = """", price_btc = """", volume_btc = """"):
        '''
        Simple constructor for a Coin.
        '''
        self.id = id
        self.name = name
        self.website = website
        self.price_btc = price_btc
        self.volume_btc = volume_btc

    def __repr__(self):
        '''
        The typ representation of a Coin.
        '''
        return f""Coin(id='{self.id}', name='{self.name}', website='{self.website}', price_btc='{self.price_btc}', volume_btc='{self.volume_btc}')""

    def __str__(self):
        '''
        The string representation of a Coin.
        '''
        return f""Coin: {self.name} ({self.id})""",full_docstr,0.7724867724867726,0.7486631016042781,0.7135135135135136,0.7619047619047619,0.5358116890107917,0.5709090909090909,0.5291970802919708,0.5091575091575091,0.8914815187454224,0.9410050511360168,0.9155740141868591,0.9358064532279968,0.8849914035087719,0.8409090909090908,0.8045977011494252,0.7325581395348838,0.8181818181818183,0.6240661369498157,0.6625,0.6192468619246861,0.592436974789916,0.9401676654815674,0.949783205986023,0.9449509978294373,0.9488127827644348,0.8962482781456953,0.891566265060241,0.8536585365853658,0.7777777777777777,0.8433734939759038,0.6858923811991209,0.7247706422018348,0.6820276497695853,0.6527777777777778,0.9577099680900574,0.949170708656311,0.9534212350845337,0.9500177502632141,0.9007102127659574,0.7461638083615931,0.6128877422257911,0.6409982604513504,0.7307692307692307,1.0,0.7765672462657122,0.8116591053960838,0.8225819076387928,0.6538461538461539,0.8181818181818182,0.775001765875459,0.8072730954913931,0.8207059959824707,0.6538461538461539,0.8181818181818182
155320,NASA-AMMOS/AIT-Core,ait/core/seq.py,core.seq.SeqPos,"class SeqPos(object):
    """"""SeqPos - Sequence Position

    Each SeqAtom contains a SeqPos to locate the atom within the text
    sequence.
    """"""

    def __init__(self, line=None, lineno=1, start=1, stop=None):
        """"""Creates a new SeqPos from the given line in the sequence and start
        and stop line and character positions within the line.
        """"""
        if line is None:
            line = """"
            start = 0
            stop = 0

        self.line = line
        self.lineno = lineno
        self.col = slice(start, stop or len(self.line))

    def __str__(self):
        """"""Returns this SeqPos as a string.""""""
        return str(self.lineno) + "":"" + str(self.col.start) + "":""","class SeqPos(object):
    '''SeqPos - Sequence Position

    Each SeqAtom contains a SeqPos to locate the atom within the text
    sequence.
    '''

    def __init__(self, line=None, lineno=1, start=1, stop=None):
    '''Creates a new SeqPos from the given line in the sequence and start
        and stop line and character positions within the line.
        '''
        pass

    def __str__(self):
    '''Returns this SeqPos as a string.'''
        pass

",3,3,snippet_196,1.0,"class SeqPos(object):
    '''SeqPos - Sequence Position

    Each SeqAtom contains a SeqPos to locate the atom within the text
    sequence.
    '''

    def __init__(self, line=None, lineno=1, start=1, stop=None):
        '''Creates a new SeqPos from the given line in the sequence and start
        and stop character positions within the line.
        '''
        self.line = line
        self.lineno = lineno
        self.start = start
        self.stop = stop if stop is not None else start

    def __str__(self):
        '''Returns this SeqPos as a string.'''
        if self.start == self.stop:
            return f""{self.lineno}:{self.start}""
        return f""{self.lineno}:{self.start}-{self.stop}""","class SeqPos(object):
    '''SeqPos - Sequence Position

    Each SeqAtom contains a SeqPos to locate the atom within the text
    sequence.
    '''

    def __init__(self, line=None, lineno=1, start=1, stop=None):
        '''Creates a new SeqPos from the given line in the sequence and start
        and stop line and character positions within the line.
        '''
        self.line = line
        self.lineno = lineno
        self.start = start
        self.stop = stop if stop is not None else start

    def __str__(self):
        '''Returns this SeqPos as a string.'''
        if self.start == self.stop:
            return f""{self.lineno}:{self.start}""
        else:
            return f""{self.lineno}:{self.start}-{self.stop}""","class SeqPos(object):
    '''SeqPos - Sequence Position

    Each SeqAtom contains a SeqPos to locate the atom within the text
    sequence.
    '''

    def __init__(self, line=None, lineno=1, start=1, stop=None):
        '''Creates a new SeqPos from the given line in the sequence and start
        and stop line and character positions within the line.
        '''
        self.line = line
        self.lineno = lineno
        self.start = start
        self.stop = stop

    def __str__(self):
        '''Returns this SeqPos as a string.'''
        return f""SeqPos(line={self.line!r}, lineno={self.lineno}, start={self.start}, stop={self.stop})""",full_docstr,0.8315789473684212,0.6702127659574468,0.6236559139784945,0.768421052631579,0.5784134741838269,0.7636363636363637,0.5975609756097561,0.50920245398773,0.9513552784919739,0.9405207633972168,0.9459069967269897,0.9415931105613708,0.826212564102564,0.8393782383419689,0.6910994764397905,0.6560846560846562,0.77720207253886,0.5953354414754559,0.757396449704142,0.5952380952380952,0.5209580838323353,0.9505517482757568,0.9439049959182739,0.9472167491912842,0.9445655345916748,0.8205146153846153,0.8791208791208791,0.7666666666666666,0.7078651685393258,0.8241758241758241,0.5974953904179651,0.8181818181818182,0.6797385620915033,0.5789473684210527,0.9615565538406372,0.9333170056343079,0.947226345539093,0.9360660910606384,0.8547023076923077,0.4462589240460626,0.49788616423798,0.5085632533599919,0.3461538461538461,0.4324324324324324,0.4691204293147138,0.5421126979691879,0.5557827407033891,0.3461538461538461,0.4324324324324324,0.4435556916130017,0.5271880661450871,0.5417332450054643,0.3269230769230769,0.3783783783783784
398727,geopython/OWSLib,geopython_OWSLib/owslib/map/common.py,owslib.map.common.WMSCapabilitiesReader,"class WMSCapabilitiesReader(object):
    """"""Read and parse capabilities document into a lxml.etree infoset
    """"""

    def __init__(self, version='1.1.1', url=None, un=None, pw=None, headers=None, auth=None):
        """"""Initialize""""""
        self.version = version
        self._infoset = None
        self.url = url
        if auth:
            if un:
                auth.username = un
            if pw:
                auth.password = pw
        self.headers = headers
        self.request = None
        self.auth = auth or Authentication(un, pw)

        # if self.username and self.password:
        #     # Provide login information in order to use the WMS server
        #     # Create an OpenerDirector with support for Basic HTTP
        #     # Authentication...
        #     passman = HTTPPasswordMgrWithDefaultRealm()
        #     passman.add_password(None, self.url, self.username, self.password)
        #     auth_handler = HTTPBasicAuthHandler(passman)
        #     opener = build_opener(auth_handler)
        #     self._open = opener.open

    def capabilities_url(self, service_url):
        """"""Return a capabilities url
        """"""
        qs = []
        if service_url.find('?') != -1:
            qs = parse_qsl(service_url.split('?')[1])

        params = [x[0] for x in qs]

        if 'service' not in params:
            qs.append(('service', 'WMS'))
        if 'request' not in params:
            qs.append(('request', 'GetCapabilities'))
        if 'version' not in params:
            qs.append(('version', self.version))

        urlqs = urlencode(tuple(qs))
        return service_url.split('?')[0] + '?' + urlqs

    def read(self, service_url, timeout=30):
        """"""Get and parse a WMS capabilities document, returning an
        elementtree instance

        service_url is the base url, to which is appended the service,
        version, and request parameters
        """"""
        self.request = self.capabilities_url(service_url)

        # now split it up again to use the generic openURL function...
        spliturl = self.request.split('?')
        u = openURL(spliturl[0], spliturl[1], method='Get',
                    timeout=timeout, headers=self.headers, auth=self.auth)
        return getXMLTree(u)

    def readString(self, st):
        """"""Parse a WMS capabilities document, returning an elementtree instance.

        string should be an XML capabilities document
        """"""
        if not isinstance(st, str) and not isinstance(st, bytes):
            raise ValueError(""String must be of type string or bytes, not %s"" % type(st))
        raw_text = strip_bom(st)
        return etree.fromstring(raw_text)","class WMSCapabilitiesReader(object):
    '''Read and parse capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version='1.1.1', url=None, un=None, pw=None, headers=None, auth=None):
    '''Initialize'''
        pass

    def capabilities_url(self, service_url):
    '''Return a capabilities url
        '''
        pass

    def read(self, service_url, timeout=30):
    '''Get and parse a WMS capabilities document, returning an
        elementtree instance

        service_url is the base url, to which is appended the service,
        version, and request parameters
        '''
        pass

    def readString(self, st):
    '''Parse a WMS capabilities document, returning an elementtree instance.

        string should be an XML capabilities document
        '''
        pass

",5,5,snippet_708,0.84,"class WMSCapabilitiesReader(object):
    '''Read and parse capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version='1.1.1', url=None, un=None, pw=None, headers=None, auth=None):
        '''Initialize'''
        self.version = version
        self.url = url
        self.headers = headers
        if auth is not None:
            self.auth = auth
        elif un is not None and pw is not None:
            self.auth = (un, pw)
        else:
            self.auth = None

    def capabilities_url(self, service_url):
        '''Return a capabilities url'''
        parsed = urlparse(service_url)
        qs = dict(parse_qsl(parsed.query))
        qs.update({
            'service': 'WMS',
            'version': self.version,
            'request': 'GetCapabilities'
        })
        new_query = urlencode(qs)
        return urlunparse((
            parsed.scheme,
            parsed.netloc,
            parsed.path,
            parsed.params,
            new_query,
            parsed.fragment
        ))

    def read(self, service_url, timeout=30):
        '''Get and parse a WMS capabilities document, returning an
        elementtree instance

        service_url is the base url, to which is appended the service,
        version, and request parameters
        '''
        url = self.capabilities_url(service_url)
        resp = requests.get(url, headers=self.headers, auth=self.auth, timeout=timeout)
        resp.raise_for_status()
        parser = etree.XMLParser(ns_clean=True, recover=True)
        root = etree.fromstring(resp.content, parser=parser)
        return etree.ElementTree(root)

    def readString(self, st):
        '''Parse a WMS capabilities document, returning an elementtree instance.

        string should be an XML capabilities document
        '''
        data = st.encode('utf-8') if isinstance(st, str) else st
        parser = etree.XMLParser(ns_clean=True, recover=True)
        root = etree.fromstring(data, parser=parser)
        return etree.ElementTree(root)","class WMSCapabilitiesReader(object):
    '''Read and parse capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version='1.1.1', url=None, un=None, pw=None, headers=None, auth=None):
        '''Initialize'''
        self.version = version
        self.url = url
        self.username = un
        self.password = pw
        self.headers = headers or {}
        self.auth = auth

    def capabilities_url(self, service_url):
        '''Return a capabilities url
        '''
        parsed_url = urllib.parse.urlparse(service_url)
        query_params = urllib.parse.parse_qs(parsed_url.query)
        
        # Add or update required parameters
        query_params['service'] = ['WMS']
        query_params['version'] = [self.version]
        query_params['request'] = ['GetCapabilities']
        
        # Reconstruct the query string
        query_string = urllib.parse.urlencode(query_params, doseq=True)
        
        # Reconstruct the URL
        new_parsed = parsed_url._replace(query=query_string)
        return urllib.parse.urlunparse(new_parsed)

    def read(self, service_url, timeout=30):
        '''Get and parse a WMS capabilities document, returning an
        elementtree instance

        service_url is the base url, to which is appended the service,
        version, and request parameters
        '''
        cap_url = self.capabilities_url(service_url)
        
        # Create request with headers
        request = urllib.request.Request(cap_url, headers=self.headers)
        
        # Handle authentication if provided
        if self.username and self.password:
            # Create password manager
            password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
            password_mgr.add_password(None, cap_url, self.username, self.password)
            handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
            opener = urllib.request.build_opener(handler)
            response = opener.open(request, timeout=timeout)
        else:
            response = urllib.request.urlopen(request, timeout=timeout)
        
        # Parse the XML response
        return etree.parse(response)

    def readString(self, st):
        '''Parse a WMS capabilities document, returning an elementtree instance.

        string should be an XML capabilities document
        '''
        return etree.fromstring(st.encode('utf-8') if isinstance(st, str) else st)","class WMSCapabilitiesReader(object):
    '''Read and parse capabilities document into a lxml.etree infoset
    '''

    def __init__(self, version='1.1.1', url=None, un=None, pw=None, headers=None, auth=None):
        '''Initialize'''
        self.version = version
        self.url = url
        self.username = un
        self.password = pw
        self.headers = headers or {}
        self.auth = auth

    def capabilities_url(self, service_url):
        '''Return a capabilities url
        '''
        params = {
            'service': 'WMS',
            'version': self.version,
            'request': 'GetCapabilities'
        }
        
        if '?' in service_url:
            separator = '&'
        else:
            separator = '?'
            
        query_string = urllib.parse.urlencode(params)
        return service_url + separator + query_string

    def read(self, service_url, timeout=30):
        '''Get and parse a WMS capabilities document, returning an
        elementtree instance

        service_url is the base url, to which is appended the service,
        version, and request parameters
        '''
        capabilities_url = self.capabilities_url(service_url)
        
        request = urllib.request.Request(capabilities_url)
        
        for key, value in self.headers.items():
            request.add_header(key, value)
            
        if self.username and self.password:
            import base64
            credentials = base64.b64encode(f""{self.username}:{self.password}"".encode()).decode()
            request.add_header('Authorization', f'Basic {credentials}')
        
        if self.auth:
            request.add_header('Authorization', self.auth)
            
        response = urllib.request.urlopen(request, timeout=timeout)
        content = response.read()
        
        return etree.fromstring(content)

    def readString(self, st):
        '''Parse a WMS capabilities document, returning an elementtree instance.

        string should be an XML capabilities document
        '''
        return etree.fromstring(st.encode() if isinstance(st, str) else st)",full_docstr,0.6156648451730419,0.4680073126142596,0.381651376146789,0.5391621129326047,0.35620205425191515,0.80440097799511,0.5098039215686274,0.4201474201474201,0.8685277700424194,0.8384543657302856,0.8532261252403259,0.8413676619529724,0.8080827272727273,0.6450511945392491,0.4554794520547945,0.3814432989690722,0.48805460750853236,0.4297510712919606,0.7710084033613446,0.52,0.4092827004219409,0.8569204807281494,0.8496859073638916,0.8532878160476685,0.8504038453102112,0.7819887121212122,0.6629422718808193,0.4934579439252337,0.4165103189493434,0.521415270018622,0.37425537333572617,0.8300492610837439,0.5580246913580247,0.44554455445544555,0.8745169639587402,0.8347078561782837,0.854148805141449,0.8385249376296997,0.779463484848485,0.4010245625339571,0.2351817074596205,0.2595806160299171,0.5245901639344263,0.5847457627118644,0.3690845925326155,0.276528685883293,0.2861762675573475,0.4644808743169399,0.4491525423728814,0.3537926809646712,0.2485730818298075,0.2772765343137711,0.4316939890710382,0.4576271186440678
267294,blackecho/Deep-Learning-TensorFlow,blackecho_Deep-Learning-TensorFlow/yadlt/core/trainers.py,yadlt.core.trainers.Loss,"class Loss(object):
    """"""Collection of loss functions.""""""

    def __init__(self, lfunc, summary=True, name=""loss""):
        """"""Constructor.

        Parameters
        ----------

        lfunc : str
            Loss function type. Types supported:
            ""cross_entropy"", ""softmax_cross_entropy"" and ""mse"".

        summary : bool, optional (default = True)
            Whether to attach a tf scalar summary to the op.

        name : str, optional (default = ""loss"")
            Name for the loss op.
        """"""
        assert lfunc in [""cross_entropy"",
                         ""softmax_cross_entropy"",
                         ""mse""]

        self.lfunc = lfunc
        self.summary = summary
        self.name = name

    def compile(self, mod_y, ref_y, regterm=None):
        """"""Compute the loss function tensor.

        Parameters
        ----------

        mode_y : tf.Tensor
            model output tensor

        ref_y : tf.Tensor
            reference input tensor

        regterm : tf.Tensor, optional (default = None)
            Regularization term tensor

        Returns
        -------

        Loss function tensor.
        """"""
        with tf.name_scope(self.name):
            if self.lfunc == 'cross_entropy':
                clip_inf = tf.clip_by_value(mod_y, 1e-10, float('inf'))
                clip_sup = tf.clip_by_value(1 - mod_y, 1e-10, float('inf'))

                cost = - tf.reduce_mean(tf.add(
                        tf.multiply(ref_y, tf.log(clip_inf)),
                        tf.multiply(tf.subtract(1.0, ref_y), tf.log(clip_sup))))

            elif self.lfunc == 'softmax_cross_entropy':
                cost = tf.losses.softmax_cross_entropy(ref_y, mod_y)

            elif self.lfunc == 'mse':
                cost = tf.sqrt(tf.reduce_mean(
                    tf.square(tf.subtract(ref_y, mod_y))))

            else:
                cost = None

        if cost is not None:
            cost = cost + regterm if regterm is not None else cost
            tf.summary.scalar(self.lfunc, cost)
        else:
            cost = None

        return cost","class Loss(object):
    '''Collection of loss functions.'''

    def __init__(self, lfunc, summary=True, name=""loss""):
    '''Constructor.

        Parameters
        ----------

        lfunc : str
            Loss function type. Types supported:
            ""cross_entropy"", ""softmax_cross_entropy"" and ""mse"".

        summary : bool, optional (default = True)
            Whether to attach a tf scalar summary to the op.

        name : str, optional (default = ""loss"")
            Name for the loss op.
        '''
        pass

    def compile(self, mod_y, ref_y, regterm=None):
    '''Compute the loss function tensor.

        Parameters
        ----------

        mode_y : tf.Tensor
            model output tensor

        ref_y : tf.Tensor
            reference input tensor

        regterm : tf.Tensor, optional (default = None)
            Regularization term tensor

        Returns
        -------

        Loss function tensor.
        '''
        pass

",3,3,snippet_448,0.1875,"class Loss(object):
    '''Collection of loss functions.'''

    def __init__(self, lfunc, summary=True, name=""loss""):
        '''Constructor.

        Parameters
        ----------

        lfunc : str
            Loss function type. Types supported:
            ""cross_entropy"", ""softmax_cross_entropy"" and ""mse"".

        summary : bool, optional (default = True)
            Whether to attach a tf scalar summary to the op.

        name : str, optional (default = ""loss"")
            Name for the loss op.
        '''
        funcs = {""cross_entropy"", ""softmax_cross_entropy"", ""mse""}
        if lfunc not in funcs:
            raise ValueError(f""Unsupported loss function '{lfunc}'. Valid options: {funcs}"")
        self.lfunc = lfunc
        self.summary = summary
        self.name = name

    def compile(self, mod_y, ref_y, regterm=None):
        '''Compute the loss function tensor.

        Parameters
        ----------

        mod_y : tf.Tensor
            model output tensor

        ref_y : tf.Tensor
            reference input tensor

        regterm : tf.Tensor, optional (default = None)
            Regularization term tensor

        Returns
        -------

        Loss function tensor.
        '''
        if self.lfunc == ""cross_entropy"":
            per_example = tf.nn.sigmoid_cross_entropy_with_logits(labels=ref_y, logits=mod_y)
            loss = tf.reduce_mean(per_example, name=self.name)
        elif self.lfunc == ""softmax_cross_entropy"":
            per_example = tf.nn.softmax_cross_entropy_with_logits(labels=ref_y, logits=mod_y)
            loss = tf.reduce_mean(per_example, name=self.name)
        elif self.lfunc == ""mse"":
            loss = tf.reduce_mean(tf.square(mod_y - ref_y), name=self.name)
        else:
            # Should not happen due to check in __init__
            raise ValueError(f""Unknown loss function '{self.lfunc}'"")

        if regterm is not None:
            loss = tf.add(loss, regterm, name=self.name + ""_with_reg"")

        if self.summary:
            tf.summary.scalar(self.name, loss)

        return loss","class Loss(object):
    '''Collection of loss functions.'''

    def __init__(self, lfunc, summary=True, name=""loss""):
        '''Constructor.

        Parameters
        ----------

        lfunc : str
            Loss function type. Types supported:
            ""cross_entropy"", ""softmax_cross_entropy"" and ""mse"".

        summary : bool, optional (default = True)
            Whether to attach a tf scalar summary to the op.

        name : str, optional (default = ""loss"")
            Name for the loss op.
        '''
        self.lfunc = lfunc
        self.summary = summary
        self.name = name

    def compile(self, mod_y, ref_y, regterm=None):
        '''Compute the loss function tensor.

        Parameters
        ----------

        mod_y : tf.Tensor
            model output tensor

        ref_y : tf.Tensor
            reference input tensor

        regterm : tf.Tensor, optional (default = None)
            Regularization term tensor

        Returns
        -------

        Loss function tensor.
        '''
        with tf.name_scope(self.name):
            if self.lfunc == ""cross_entropy"":
                loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
                    labels=ref_y, logits=mod_y))
            elif self.lfunc == ""softmax_cross_entropy"":
                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                    labels=ref_y, logits=mod_y))
            elif self.lfunc == ""mse"":
                loss = tf.reduce_mean(tf.square(mod_y - ref_y))
            else:
                raise ValueError(""Unsupported loss function: {}"".format(self.lfunc))
            
            if regterm is not None:
                loss = loss + regterm
            
            if self.summary:
                tf.summary.scalar(self.name, loss)
            
            return loss","class Loss(object):
    '''Collection of loss functions.'''

    def __init__(self, lfunc, summary=True, name=""loss""):
        '''Constructor.

        Parameters
        ----------

        lfunc : str
            Loss function type. Types supported:
            ""cross_entropy"", ""softmax_cross_entropy"" and ""mse"".

        summary : bool, optional (default = True)
            Whether to attach a tf scalar summary to the op.

        name : str, optional (default = ""loss"")
            Name for the loss op.
        '''
        self.lfunc = lfunc
        self.summary = summary
        self.name = name

    def compile(self, mod_y, ref_y, regterm=None):
        '''Compute the loss function tensor.

        Parameters
        ----------

        mode_y : tf.Tensor
            model output tensor

        ref_y : tf.Tensor
            reference input tensor

        regterm : tf.Tensor, optional (default = None)
            Regularization term tensor

        Returns
        -------

        Loss function tensor.
        '''
        with tf.name_scope(self.name):
            if self.lfunc == ""cross_entropy"":
                loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
                    logits=mod_y, labels=ref_y))
            elif self.lfunc == ""softmax_cross_entropy"":
                loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
                    logits=mod_y, labels=ref_y))
            elif self.lfunc == ""mse"":
                loss = tf.reduce_mean(tf.square(mod_y - ref_y))
            else:
                raise ValueError(f""Unsupported loss function: {self.lfunc}"")
            
            if regterm is not None:
                loss = loss + regterm
            
            if self.summary:
                tf.summary.scalar(self.name, loss)
            
            return loss",full_docstr,0.7239263803680982,0.595482546201232,0.5072164948453609,0.6584867075664621,0.6181476597509603,0.7719665271966527,0.5849056603773585,0.523109243697479,0.908362865447998,0.9063929319381714,0.9073768258094788,0.9065894484519958,0.8149484697508899,0.7709750566893424,0.6833712984054671,0.5949656750572082,0.7301587301587301,0.6123934088806223,0.8947368421052632,0.7546174142480211,0.6772486772486772,0.9336397647857666,0.8990556001663208,0.9160213470458984,0.9023982882499695,0.8422317081850534,0.7709750566893424,0.6879271070615034,0.6041189931350114,0.7256235827664399,0.6110333660597336,0.8938992042440318,0.7606382978723404,0.688,0.933404266834259,0.8999247550964355,0.9163588285446167,0.9031641483306885,0.8434179359430605,0.4834987026080977,0.5221041916398892,0.5380670893807371,0.4338235294117647,0.44,0.5194229612735091,0.5399574561494838,0.544499094826905,0.4632352941176471,0.53,0.5241357731949597,0.5544960606143298,0.558811738047862,0.4632352941176471,0.52
109231,Clinical-Genomics/scout,Clinical-Genomics_scout/scout/adapter/mongo/phenomodel.py,scout.adapter.mongo.phenomodel.PhenoModelHandler,"class PhenoModelHandler(object):
    """"""Class handling phenomodels creation and use""""""

    def phenomodels(self, institute_id):
        """"""Return all phenopanels for a given institute
        Args:
            institute_id(str): institute id
        Returns:
            phenotype_models(pymongo.cursor.Cursor)
        """"""
        query = {""institute"": institute_id}
        phenotype_models = self.phenomodel_collection.find(query)
        return phenotype_models

    def create_phenomodel(self, institute_id, name, description):
        """"""Create an empty advanced phenotype model with data provided by a user
        Args:
            institute_id(str): institute id
            name(str) a model name
            description(str) a model description
        Returns:
            phenomodel_obj(dict) a newly created model
        """"""
        phenomodel_obj = dict(
            institute=institute_id,
            name=name,
            description=description,
            subpanels={},
            created=datetime.datetime.now(),
            updated=datetime.datetime.now(),
        )
        phenomodel_obj = self.phenomodel_collection.insert_one(phenomodel_obj)
        return phenomodel_obj

    def update_phenomodel(self, model_id, model_obj):
        """"""Update a phenotype model using its ObjectId
        Args:
            model_id(str): document ObjectId string id
            model_obj(dict): a dictionary of key/values to update a phenomodel with

        Returns:
            updated_model(dict): the phenomodel document after the update
        """"""
        updated_model = self.phenomodel_collection.find_one_and_update(
            {""_id"": ObjectId(model_id)},
            {
                ""$set"": {
                    ""name"": model_obj[""name""],
                    ""description"": model_obj[""description""],
                    ""subpanels"": model_obj.get(""subpanels"", {}),
                    ""updated"": datetime.datetime.now(),
                    ""admins"": model_obj.get(""admins"", []),
                }
            },
            return_document=pymongo.ReturnDocument.AFTER,
        )
        return updated_model

    def phenomodel(self, model_id):
        """"""Retrieve a phenomodel object using its ObjectId
        Args:
            model_id(ObjectId): document ObjectId
        Returns
            model_obj(dict)
        """"""
        query = {""_id"": ObjectId(model_id)}
        model_obj = self.phenomodel_collection.find_one(query)
        return model_obj","class PhenoModelHandler(object):
    '''Class handling phenomodels creation and use'''

    def phenomodels(self, institute_id):
    '''Return all phenopanels for a given institute
        Args:
            institute_id(str): institute id
        Returns:
            phenotype_models(pymongo.cursor.Cursor)
        '''
        pass

    def create_phenomodel(self, institute_id, name, description):
    '''Create an empty advanced phenotype model with data provided by a user
        Args:
            institute_id(str): institute id
            name(str) a model name
            description(str) a model description
        Returns:
            phenomodel_obj(dict) a newly created model
        '''
        pass

    def update_phenomodel(self, model_id, model_obj):
    '''Update a phenotype model using its ObjectId
        Args:
            model_id(str): document ObjectId string id
            model_obj(dict): a dictionary of key/values to update a phenomodel with

        Returns:
            updated_model(dict): the phenomodel document after the update
        '''
        pass

    def phenomodels(self, institute_id):
    '''Retrieve a phenomodel object using its ObjectId
        Args:
            model_id(ObjectId): document ObjectId
        Returns
            model_obj(dict)
        '''
        pass

",5,5,snippet_65,1.0,"class PhenoModelHandler(object):
    '''Class handling phenomodels creation and use'''

    def __init__(self, db):
        """"""
        Args:
            db (pymongo.database.Database): a PyMongo Database instance
        """"""
        self.db = db
        self.collection = self.db.phenomodels

    def phenomodels(self, institute_id):
        '''Return all phenomodels for a given institute
        Args:
            institute_id(str): institute id
        Returns:
            phenotype_models(pymongo.cursor.Cursor)
        '''
        return self.collection.find({'institute_id': institute_id})

    def create_phenomodel(self, institute_id, name, description):
        '''Create an empty advanced phenotype model with data provided by a user
        Args:
            institute_id(str): institute id
            name(str) a model name
            description(str) a model description
        Returns:
            phenomodel_obj(dict) a newly created model
        '''
        now = datetime.datetime.utcnow()
        doc = {
            'institute_id': institute_id,
            'name': name,
            'description': description,
            'created_at': now,
            'modified_at': now
        }
        res = self.collection.insert_one(doc)
        doc['_id'] = res.inserted_id
        return doc

    def update_phenomodel(self, model_id, model_obj):
        '''Update a phenotype model using its ObjectId
        Args:
            model_id(str): document ObjectId string id
            model_obj(dict): a dictionary of key/values to update a phenomodel with
        Returns:
            updated_model(dict): the phenomodel document after the update
        '''
        oid = ObjectId(model_id)
        model_obj['modified_at'] = datetime.datetime.utcnow()
        self.collection.update_one({'_id': oid}, {'$set': model_obj})
        return self.collection.find_one({'_id': oid})

    def get_phenomodel(self, model_id):
        '''Retrieve a phenomodel object using its ObjectId
        Args:
            model_id(str): document ObjectId string id
        Returns:
            model_obj(dict)
        '''
        oid = ObjectId(model_id)
        return self.collection.find_one({'_id': oid})","class PhenoModelHandler(object):
    '''Class handling phenomodels creation and use'''

    def __init__(self, database):
        '''Initialize with a database connection
        Args:
            database: pymongo database object
        '''
        self.db = database

    def phenomodels(self, institute_id):
        '''Return all phenopanels for a given institute
        Args:
            institute_id(str): institute id
        Returns:
            phenotype_models(pymongo.cursor.Cursor)
        '''
        return self.db.phenomodels.find({'institute_id': institute_id})

    def create_phenomodel(self, institute_id, name, description):
        '''Create an empty advanced phenotype model with data provided by a user
        Args:
            institute_id(str): institute id
            name(str) a model name
            description(str) a model description
        Returns:
            phenomodel_obj(dict) a newly created model
        '''
        phenomodel_obj = {
            'institute_id': institute_id,
            'name': name,
            'description': description,
            'subpanels': {},
            'created_at': datetime.datetime.now(),
            'updated_at': datetime.datetime.now()
        }
        result = self.db.phenomodels.insert_one(phenomodel_obj)
        phenomodel_obj['_id'] = result.inserted_id
        return phenomodel_obj

    def update_phenomodel(self, model_id, model_obj):
        '''Update a phenotype model using its ObjectId
        Args:
            model_id(str): document ObjectId string id
            model_obj(dict): a dictionary of key/values to update a phenomodel with

        Returns:
            updated_model(dict): the phenomodel document after the update
        '''
        from bson import ObjectId
        model_obj['updated_at'] = datetime.datetime.now()
        result = self.db.phenomodels.update_one(
            {'_id': ObjectId(model_id)},
            {'$set': model_obj}
        )
        if result.modified_count > 0:
            return self.db.phenomodels.find_one({'_id': ObjectId(model_id)})
        return None

    def phenomodel(self, model_id):
        '''Retrieve a phenomodel object using its ObjectId
        Args:
            model_id(str): document ObjectId string id
        Returns
            model_obj(dict)
        '''
        from bson import ObjectId
        return self.db.phenomodels.find_one({'_id': ObjectId(model_id)})","class PhenoModelHandler(object):
    '''Class handling phenomodels creation and use'''

    def __init__(self, adapter):
        self.adapter = adapter

    def phenomodels(self, institute_id):
        '''Return all phenopanels for a given institute
        Args:
            institute_id(str): institute id
        Returns:
            phenotype_models(pymongo.cursor.Cursor)
        '''
        return self.adapter.phenomodel_collection.find({'institute': institute_id})

    def create_phenomodel(self, institute_id, name, description):
        '''Create an empty advanced phenotype model with data provided by a user
        Args:
            institute_id(str): institute id
            name(str) a model name
            description(str) a model description
        Returns:
            phenomodel_obj(dict) a newly created model
        '''
        phenomodel_obj = {
            '_id': ObjectId(),
            'institute': institute_id,
            'name': name,
            'description': description,
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'features': []
        }
        
        self.adapter.phenomodel_collection.insert_one(phenomodel_obj)
        return phenomodel_obj

    def update_phenomodel(self, model_id, model_obj):
        '''Update a phenotype model using its ObjectId
        Args:
            model_id(str): document ObjectId string id
            model_obj(dict): a dictionary of key/values to update a phenomodel with

        Returns:
            updated_model(dict): the phenomodel document after the update
        '''
        model_obj['updated_at'] = datetime.now()
        
        self.adapter.phenomodel_collection.update_one(
            {'_id': ObjectId(model_id)},
            {'$set': model_obj}
        )
        
        return self.adapter.phenomodel_collection.find_one({'_id': ObjectId(model_id)})

    def phenomodel(self, model_id):
        '''Retrieve a phenomodel object using its ObjectId
        Args:
            model_id(ObjectId): document ObjectId
        Returns
            model_obj(dict)
        '''
        return self.adapter.phenomodel_collection.find_one({'_id': model_id})",full_docstr,0.7887323943661971,0.6383838383838384,0.5598377281947262,0.7162977867203218,0.5519767842845356,0.8233995584988962,0.6017699115044248,0.5121951219512195,0.9140768051147461,0.9182184934616089,0.9161429405212402,0.9178025722503662,0.7721376953125002,0.8062015503875969,0.6770428015564202,0.59765625,0.7364341085271319,0.5990532028833786,0.7995824634655533,0.6255230125523012,0.5387840670859538,0.919558584690094,0.9337241649627686,0.9265872836112976,0.9322879314422607,0.7741170329670333,0.8672199170124482,0.7583333333333333,0.6861924686192469,0.8049792531120333,0.6057921029654061,0.8796296296296297,0.7146171693735499,0.6302325581395349,0.9464074969291687,0.9380061626434326,0.9421880841255188,0.9388394951820374,0.7630232031250002,0.4861594063914544,0.471057226638409,0.5068102125920051,0.5739130434782609,0.3928571428571428,0.4936501768480901,0.4752586153029464,0.5380584481970745,0.5565217391304348,0.4047619047619047,0.5078058412115354,0.5427388339513727,0.5587743859672328,0.5130434782608696,0.4166666666666667
110854,Cue/scales,Cue_scales/src/greplin/scales/aggregation.py,greplin.scales.aggregation.DirectFormat,"class DirectFormat(object):
  """"""The direct format (pointed straight at the field we want)""""""

  def getCount(self, _):
    ""The count""
    return 1


  def getValue(self, data):
    ""The value""
    return data","class DirectFormat(object):
    '''The direct format (pointed straight at the field we want)'''

  def getCount(self, _):
    '''The count'''
    pass

  def getValue(self, data):
    '''The value'''
    pass

",3,3,snippet_79,1.0,"class DirectFormat(object):
    '''The direct format (pointed straight at the field we want)'''

    def getCount(self, _):
        '''The count'''
        return 1

    def getValue(self, data):
        '''The value'''
        return data","class DirectFormat(object):
    '''The direct format (pointed straight at the field we want)'''

    def getCount(self, _):
        '''The count'''
        return 1

    def getValue(self, data):
        '''The value'''
        return data","class DirectFormat(object):
    '''The direct format (pointed straight at the field we want)'''

    def getCount(self, _):
        '''The count'''
        return 1

    def getValue(self, data):
        '''The value'''
        return data",full_docstr,1.0,1.0,1.0,1.0,0.6178212902123498,0.8636363636363636,0.7674418604651163,0.6666666666666666,0.986793577671051,0.986793577671051,0.986793577671051,0.9867935180664062,1.0,1.0,1.0,1.0,1.0,0.6178212902123498,0.8636363636363636,0.7674418604651163,0.6666666666666666,0.986793577671051,0.986793577671051,0.986793577671051,0.9867935180664062,1.0,1.0,1.0,1.0,1.0,0.6178212902123498,0.8636363636363636,0.7674418604651163,0.6666666666666666,0.986793577671051,0.986793577671051,0.986793577671051,0.9867935180664062,1.0,0.7497574241049356,0.4918602374272221,0.5071694589925205,1.0,1.0,0.7497574241049356,0.4918602374272221,0.5071694589925205,1.0,1.0,0.7497574241049356,0.4918602374272221,0.5071694589925205,1.0,1.0
766490,sripathikrishnan/redis-rdb-tools,sripathikrishnan_redis-rdb-tools/rdbtools/memprofiler.py,rdbtools.memprofiler.PrintJustKeys,"class PrintJustKeys(object):
    def __init__(self, out):
        self._out = out
    
    def next_record(self, record):
        self._out.write(codecs.encode(""%s\n"" % record.key, 'latin-1'))","class PrintJustKeys(object):


    def __init__(self, out):
        pass

    def next_record(self, record):
        pass

",3,0,snippet_458,1.0,"class PrintJustKeys(object):
    def __init__(self, out):
        self.out = out

    def next_record(self, record):
        line = ' '.join(str(k) for k in record.keys()) + '\n'
        self.out.write(line)","class PrintJustKeys(object):
    def __init__(self, out):
        self.out = out

    def next_record(self, record):
        if record is not None and len(record) > 0:
            key = record[0]
            self.out.write(str(key) + '\n')","class PrintJustKeys(object):

    def __init__(self, out):
        self.out = out

    def next_record(self, record):
        if isinstance(record, dict):
            for key in record.keys():
                self.out.write(str(key) + '\n')",no_docstr,0.7272727272727274,0.6037735849056605,0.5490196078431373,0.6545454545454545,0.5926496818111048,0.7121212121212122,0.5846153846153846,0.5,0.8861482739448547,0.8670617938041687,0.8765011429786682,0.8689333200454712,0.8306027868852459,0.7118644067796609,0.5614035087719298,0.509090909090909,0.6440677966101696,0.560653089821152,0.6764705882352942,0.5373134328358209,0.48484848484848486,0.8676167130470276,0.8666993975639343,0.8671578168869019,0.8667910099029541,0.8333349999999999,0.75,0.5925925925925927,0.5384615384615384,0.6785714285714285,0.6090068276967145,0.7272727272727273,0.5846153846153846,0.53125,0.8860265016555786,0.8640938997268677,0.8749227523803711,0.8662381768226624,0.8538026315789474,0.5488565293713029,0.3233842870691159,0.5173409757152411,0.5769230769230769,0.7777777777777778,0.526011498321147,0.2704657013300309,0.5173409757152411,0.5384615384615384,0.7777777777777778,0.5434004634806604,0.3400215619680846,0.5173409757152411,0.5384615384615384,0.7777777777777778
529298,kata198/indexedredis,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/kata198_indexedredis/IndexedRedis/__init__.py,IndexedRedis.classproperty,"class classproperty(object):
    def __init__(self, getter):
        self.getter = getter

    def __get__(self, instance, owner):
        return self.getter(owner)
","class classproperty(object):


    def __init__(self, getter):
        pass


    def __get__(self, instance, owner):
        pass

",3,0,snippet_416,1.0,"class classproperty(object):
    def __init__(self, getter):
        self.fget = getter

    def __get__(self, instance, owner):
        return self.fget(owner)","class classproperty(object):
    def __init__(self, getter):
        self.getter = getter

    def __get__(self, instance, owner):
        return self.getter(owner)","class classproperty(object):
    def __init__(self, getter):
        self.getter = getter

    def __get__(self, instance, owner):
        return self.getter(owner)",no_docstr,0.8947368421052632,0.7777777777777778,0.7058823529411765,0.8947368421052632,0.907539441290753,0.9555555555555556,0.9090909090909091,0.8604651162790697,0.965765118598938,0.9818145036697388,0.9737236499786377,0.9801855683326721,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.7703070443403058,0.6997522298221912,0.7148092808723655,1.0,0.6666666666666666,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
102918,BlockHub/blockhubdpostools,BlockHub_blockhubdpostools/dpostools/legacy.py,dpostools.legacy.DbConnection,"class DbConnection:
    def __init__(self):
        try:
            self._conn = psycopg2.connect(
                host=c.CONNECTION['HOST'],
                database=c.CONNECTION['DATABASE'],
                user=c.CONNECTION['USER'],
                password=c.CONNECTION['PASSWORD'])
        except Exception as e:
            logger.exception('failed to connect to ark-node: {}'.format(e))
            raise e

    def connection(self):
        return self._conn","class DbConnection:


    def __init__(self):
        pass

    def connection(self):
        pass

",3,0,snippet_572,0.6,"class DbConnection:
    def __init__(self):
        self._conn = None
        self._db_path = os.getenv(""DB_PATH"", "":memory:"")

    def connection(self):
        if self._conn is None:
            self._conn = sqlite3.connect(self._db_path)
            self._conn.row_factory = sqlite3.Row
        return self._conn","class DbConnection:
    def __init__(self):
        self._connection = None
        self._is_connected = False

    def connection(self):
        if not self._is_connected:
            self._connection = self._create_connection()
            self._is_connected = True
        return self._connection

    def _create_connection(self):
        # Placeholder for actual database connection logic
        # This would typically involve connecting to a specific database
        return ""DatabaseConnectionObject""","class DbConnection:
    def __init__(self):
        self.db_path = "":memory:""
        self._connection = None

    @contextmanager
    def connection(self):
        conn = sqlite3.connect(self.db_path)
        try:
            yield conn
        finally:
            conn.close()",no_docstr,0.31818181818181823,0.20930232558139536,0.11904761904761904,0.2954545454545454,0.33306244885620634,0.5444444444444444,0.3258426966292135,0.2727272727272727,0.8110689520835876,0.7436630725860596,0.7759048342704773,0.7498952746391296,0.7562748387096774,0.3564356435643565,0.14141414141414144,0.08247422680412371,0.27722772277227725,0.2820678813051843,0.4444444444444444,0.24489795918367346,0.20618556701030927,0.7823748588562012,0.7313159108161926,0.7559842467308044,0.7361199259757996,0.7311854838709677,0.39473684210526316,0.18918918918918917,0.1111111111111111,0.3157894736842105,0.2516532845103937,0.6935483870967742,0.4262295081967213,0.31666666666666665,0.8257606625556946,0.726132869720459,0.7727488279342651,0.7350006103515625,0.7491064516129032,0.2248908837444285,0.1250559995712433,0.1334818943808296,0.3333333333333333,0.3076923076923077,0.1784106034760439,0.0685637486751052,0.1194376395880451,0.3333333333333333,0.1923076923076923,0.3823899208254407,0.1041025378622236,0.1129571454395392,0.3125,0.0
260043,benjamin-hodgson/Contexts,benjamin-hodgson_Contexts/src/contexts/core.py,contexts.core.Assertion,"class Assertion(object):
    def __init__(self, func, plugin_composite):
        self.func = func
        self.name = func.__name__
        self.plugin_composite = plugin_composite
        self.exception_handler = ExceptionHandler(self.plugin_composite)

    def run(self, test_data):
        with self.exception_handler.run_assertion(self):
            run_with_test_data(self.func, test_data)","class Assertion(object):


    def __init__(self, func, plugin_composite):
        pass

    def run(self, test_data):
        pass

",3,0,snippet_449,0.6,"class Assertion(object):

    def __init__(self, func, plugin_composite):
        self.func = func
        self.plugin_composite = plugin_composite

    def run(self, test_data):
        # call before hook if present
        before = getattr(self.plugin_composite, 'before_assertion', None)
        if callable(before):
            before(self, test_data)

        try:
            result = self.func(test_data)
            success = True
        except Exception as e:
            result = e
            success = False

        # call after hook if present
        after = getattr(self.plugin_composite, 'after_assertion', None)
        if callable(after):
            after(self, test_data, result, success)

        if not success:
            # re-raise the exception from the assertion
            raise result

        return result","class Assertion(object):
    def __init__(self, func, plugin_composite):
        self.func = func
        self.plugin_composite = plugin_composite

    def run(self, test_data):
        return self.func(test_data, self.plugin_composite)","class Assertion(object):

    def __init__(self, func, plugin_composite):
        self.func = func
        self.plugin_composite = plugin_composite

    def run(self, test_data):
        return self.func(test_data, self.plugin_composite)",no_docstr,0.5211267605633803,0.38571428571428573,0.3188405797101449,0.43661971830985913,0.39464084921045345,0.49390243902439024,0.3803680981595092,0.3271604938271605,0.7635327577590942,0.8953853249549866,0.8242191076278687,0.8801856637001038,0.7680023199999999,0.7435897435897435,0.7105263157894737,0.6216216216216216,0.6666666666666667,0.463339187931421,0.9838709677419355,0.8852459016393442,0.8166666666666667,0.9455176591873169,0.8838424682617188,0.9136403799057007,0.8896455764770508,0.8428587142857142,0.7435897435897435,0.7105263157894737,0.6216216216216216,0.6666666666666667,0.463339187931421,0.9838709677419355,0.8852459016393442,0.8166666666666667,0.944542407989502,0.8826209902763367,0.912532389163971,0.8884454965591431,0.8428587142857142,0.4303576337306094,0.1358616334803604,0.4445162698631298,0.4210526315789473,0.72,0.4557103961671966,0.4088284408961523,0.4329605121936867,0.4210526315789473,0.56,0.4557103961671966,0.4088284408961523,0.4329605121936867,0.4210526315789473,0.56
141063,Kaggle/kaggle-api,Kaggle_kaggle-api/src/kaggle/models/kaggle_models_extended.py,src.kaggle.models.kaggle_models_extended.LeaderboardEntry,"class LeaderboardEntry(object):

  def __init__(self, init_dict):
    parsed_dict = {k: parse(v) for k, v in init_dict.items()}
    self.__dict__.update(parsed_dict)

  def __repr__(self):
    return self.teamId","class LeaderboardEntry(object):


  def __init__(self, init_dict):
    pass

  def __repr__(self):
    pass

",3,0,snippet_327,1.0,"class LeaderboardEntry(object):

    def __init__(self, init_dict):
        if not isinstance(init_dict, dict):
            raise TypeError(""init_dict must be a dict"")
        for key, value in init_dict.items():
            setattr(self, key, value)

    def __repr__(self):
        items = sorted(self.__dict__.items())
        body = "", "".join(f""{k}={v!r}"" for k, v in items)
        return f""{self.__class__.__name__}({body})""","class LeaderboardEntry(object):
    def __init__(self, init_dict):
        self.name = init_dict.get('name', '')
        self.score = init_dict.get('score', 0)
        self.rank = init_dict.get('rank', 0)

    def __repr__(self):
        return f""LeaderboardEntry(name='{self.name}', score={self.score}, rank={self.rank})""","class LeaderboardEntry(object):

    def __init__(self, init_dict):
        for key, value in init_dict.items():
            setattr(self, key, value)

    def __repr__(self):
        attrs = []
        for key, value in self.__dict__.items():
            if isinstance(value, str):
                attrs.append(f""{key}='{value}'"")
            else:
                attrs.append(f""{key}={value}"")
        return f""LeaderboardEntry({', '.join(attrs)})""",no_docstr,0.5842696629213483,0.367816091954023,0.2588235294117647,0.44943820224719105,0.38297067574044713,0.4755244755244755,0.3873239436619718,0.3049645390070922,0.785102367401123,0.8524853587150574,0.817407488822937,0.8452309966087341,0.7712441176470588,0.4864864864864865,0.3055555555555555,0.2285714285714286,0.4864864864864865,0.3895618106772892,0.5238095238095238,0.375,0.30097087378640774,0.8402131795883179,0.8312205076217651,0.8356926441192627,0.8321111798286438,0.8055575,0.49382716049382713,0.3291139240506329,0.2337662337662338,0.4444444444444445,0.3662071601109311,0.45454545454545453,0.3511450381679389,0.3076923076923077,0.7809615135192871,0.8622706532478333,0.8196045160293579,0.8533856868743896,0.7500025,0.3871867757441892,0.1676652429098026,0.3810818600669545,0.4285714285714285,0.5714285714285714,0.3360616584929498,0.2123347058599882,0.2747690709689539,0.2857142857142857,0.5714285714285714,0.3692532622754172,0.1398365671039177,0.2657479105691797,0.4285714285714285,0.6428571428571429
295127,cloud-custodian/cloud-custodian,tools/c7n_policystream/policystream.py,policystream.TempDir,"class TempDir:

    def __init__(self):
        self.path = None

    def open(self):
        self.path = tempfile.mkdtemp()
        return self

    def close(self):
        if not self.path:
            return
        shutil.rmtree(self.path)","class TempDir:


    def __init__(self):
        pass

    def open(self):
        pass

    def close(self):
        pass

",4,0,snippet_167,0.8333333333333334,"class TempDir:
    def __init__(self):
        self.path = None

    def open(self):
        if self.path is not None:
            raise RuntimeError(""TempDir is already open"")
        self.path = tempfile.mkdtemp()
        return self.path

    def close(self):
        if self.path is None:
            return
        shutil.rmtree(self.path, ignore_errors=True)
        self.path = None

    def __enter__(self):
        return self.open()

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()","class TempDir:
    def __init__(self):
        self._temp_dir = None
        self._is_open = False

    def open(self):
        if not self._is_open:
            self._temp_dir = tempfile.mkdtemp()
            self._is_open = True
        return self._temp_dir

    def close(self):
        if self._is_open and self._temp_dir:
            shutil.rmtree(self._temp_dir)
            self._temp_dir = None
            self._is_open = False","class TempDir:
    def __init__(self):
        self.path = None

    def open(self):
        self.path = tempfile.mkdtemp()
        return self.path

    def close(self):
        if self.path and os.path.exists(self.path):
            shutil.rmtree(self.path)
            self.path = None",no_docstr,0.6105263157894737,0.4946236559139785,0.39560439560439564,0.5894736842105264,0.393173981264171,0.4318181818181818,0.3893129770992366,0.36153846153846153,0.8390350341796875,0.9488459825515747,0.8905682563781738,0.9365881681442261,0.8317477142857141,0.5517241379310345,0.3764705882352941,0.24096385542168672,0.5287356321839081,0.3594539079690643,0.43333333333333335,0.36134453781512604,0.2966101694915254,0.8420525193214417,0.9133630394935608,0.8762593269348145,0.9056930541992188,0.8505762068965517,0.8181818181818181,0.7187499999999999,0.6129032258064516,0.8181818181818181,0.6972560213300113,0.7534246575342466,0.6944444444444444,0.647887323943662,0.9468770027160645,0.967008113861084,0.9568367004394531,0.9649565815925598,0.900001,0.5752583306941738,0.2543054133259545,0.5958350523078833,0.59375,0.8571428571428571,0.4371042628453609,0.130098684530849,0.238854081136309,0.59375,0.7857142857142857,0.7167686666096326,0.5784879107039426,0.6635867557345878,0.625,1.0
622245,osrg/ryu,osrg_ryu/ryu/lib/ovs/bridge.py,ryu.lib.ovs.bridge.VifPort,"class VifPort(object):

    def __init__(self, port_name, ofport, vif_id, vif_mac, switch):
        super(VifPort, self).__init__()
        self.port_name = port_name
        self.ofport = ofport
        self.vif_id = vif_id
        self.vif_mac = vif_mac
        self.switch = switch

    def __str__(self):
        return ('iface-id=%s, '
                'vif_mac=%s, '
                'port_name=%s, '
                'ofport=%d, '
                'bridge_name=%s' % (self.vif_id,
                                    self.vif_mac,
                                    self.port_name,
                                    self.ofport,
                                    self.switch.br_name))","class VifPort(object):


    def __init__(self, port_name, ofport, vif_id, vif_mac, switch):
        pass

    def __str__(self):
        pass

",3,0,snippet_146,1.0,"class VifPort(object):
    def __init__(self, port_name, ofport, vif_id, vif_mac, switch):
        self.port_name = port_name
        self.ofport = ofport
        self.vif_id = vif_id
        self.vif_mac = vif_mac
        self.switch = switch

    def __str__(self):
        return (f""VifPort(port_name={self.port_name}, ""
                f""ofport={self.ofport}, ""
                f""vif_id={self.vif_id}, ""
                f""vif_mac={self.vif_mac}, ""
                f""switch={self.switch})"")","class VifPort(object):
    def __init__(self, port_name, ofport, vif_id, vif_mac, switch):
        self.port_name = port_name
        self.ofport = ofport
        self.vif_id = vif_id
        self.vif_mac = vif_mac
        self.switch = switch

    def __str__(self):
        return (""VifPort(port_name=%s, ofport=%s, vif_id=%s, vif_mac=%s, switch=%s)"" % 
                (self.port_name, self.ofport, self.vif_id, self.vif_mac, self.switch))","class VifPort(object):

    def __init__(self, port_name, ofport, vif_id, vif_mac, switch):
        self.port_name = port_name
        self.ofport = ofport
        self.vif_id = vif_id
        self.vif_mac = vif_mac
        self.switch = switch

    def __str__(self):
        return f""VifPort(port_name={self.port_name}, ofport={self.ofport}, vif_id={self.vif_id}, vif_mac={self.vif_mac}, switch={self.switch})""",no_docstr,0.855072463768116,0.75,0.626865671641791,0.7391304347826088,0.635820183050193,0.7960526315789473,0.6622516556291391,0.6066666666666667,0.9215476512908936,0.8987552523612976,0.9100087285041809,0.9009836912155151,0.8478979611650486,0.9130434782608695,0.8382352941176471,0.7313432835820896,0.7971014492753623,0.756334643343362,0.9315068493150684,0.8413793103448276,0.7847222222222222,0.9395536184310913,0.914097011089325,0.9266505241394043,0.9165804386138916,0.9061498058252426,0.8805970149253732,0.7727272727272727,0.6461538461538462,0.7611940298507464,0.6201706607536424,0.8623188405797102,0.7226277372262774,0.6617647058823529,0.9297551512718201,0.883681058883667,0.9061327576637268,0.888081967830658,0.8576066019417475,0.4950748964809351,0.5548965063896154,0.5846900260551144,0.4893617021276595,0.3513513513513513,0.5560179184248031,0.5742358722097124,0.5946316611789767,0.5957446808510638,0.4594594594594595,0.4910560355231134,0.5388210625583286,0.5846900260551144,0.4893617021276595,0.3513513513513513
468843,hotdoc/hotdoc,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/hotdoc_hotdoc/hotdoc/extensions/c/clang/cindex.py,hotdoc.extensions.c.clang.cindex.CompletionChunk.Kind,"class Kind:
    def __init__(self, name):
        self.name = name

    def __str__(self):
        return self.name

    def __repr__(self):
        return ""<ChunkKind: %s>"" % self
","class Kind:


    def __init__(self, name):
        pass


    def __str__(self):
        pass


    def __repr__(self):
        pass

",4,0,snippet_736,1.0,"class Kind:
    def __init__(self, name):
        self.name = name

    def __str__(self):
        return self.name

    def __repr__(self):
        return f""Kind({self.name!r})""","class Kind:
    def __init__(self, name):
        self.name = name

    def __str__(self):
        return self.name

    def __repr__(self):
        return f""Kind('{self.name}')""","class Kind:
    def __init__(self, name):
        self.name = name

    def __str__(self):
        return self.name

    def __repr__(self):
        return f""Kind('{self.name}')""",no_docstr,0.8695652173913043,0.8181818181818182,0.8095238095238095,0.8695652173913043,0.7923227690603861,0.8305084745762712,0.7758620689655172,0.7719298245614035,0.9605575203895569,0.9549516439437866,0.9577463269233704,0.95550936460495,0.93496,0.888888888888889,0.8372093023255814,0.8292682926829269,0.888888888888889,0.7923227690603861,0.8305084745762712,0.7758620689655172,0.7719298245614035,0.9658480882644653,0.9458562135696411,0.9557476043701172,0.9478181004524231,0.9416672500000001,0.888888888888889,0.8372093023255814,0.8292682926829269,0.888888888888889,0.7923227690603861,0.8305084745762712,0.7758620689655172,0.7719298245614035,0.9658480882644653,0.9458562135696411,0.9557476043701172,0.9478181004524231,0.9416672500000001,0.7644815644670315,0.7714985257158095,0.7975388432634276,0.6,0.8888888888888888,0.7644815644670315,0.7714985257158095,0.7975388432634276,0.6,0.8888888888888888,0.7644815644670315,0.7714985257158095,0.7975388432634276,0.6,0.8888888888888888
319624,crossbario/zlmdb,crossbario_zlmdb/zlmdb/_types.py,zlmdb._types._UuidSetValuesMixin,"class _UuidSetValuesMixin(object):
    def _serialize_value(self, value_set):
        assert type(value_set) == set
        return b''.join([value.bytes for value in value_set])

    def _deserialize_value(self, data):
        VLEN = 16
        assert len(data) % VLEN == 0
        cnt = len(data) // VLEN
        return set([uuid.UUID(bytes=data[i:i + VLEN]) for i in range(0, cnt, VLEN)])","class _UuidSetValuesMixin(object):


    def _serialize_value(self, value_set):
        pass

    def _deserialize_value(self, data):
        pass

",3,0,snippet_251,0.2,"class _UuidSetValuesMixin(object):

    def _serialize_value(self, value_set):
        if value_set is None:
            return []
        return [str(u) for u in value_set]

    def _deserialize_value(self, data):
        if not data:
            return set()
        return {uuid.UUID(s) for s in data}","class _UuidSetValuesMixin(object):

    def _serialize_value(self, value_set):
        if value_set is None:
            return None
        return [str(uuid) for uuid in value_set]

    def _deserialize_value(self, data):
        if data is None:
            return None
        import uuid
        return {uuid.UUID(item) for item in data}","class _UuidSetValuesMixin(object):

    def _serialize_value(self, value_set):
        if value_set is None:
            return None
        return [str(uuid_val) for uuid_val in value_set]

    def _deserialize_value(self, data):
        if data is None:
            return None
        return {uuid.UUID(uuid_str) for uuid_str in data}",no_docstr,0.5979381443298969,0.4,0.27956989247311825,0.5773195876288659,0.36441388848496076,0.8026315789473685,0.56,0.47297297297297297,0.9177165031433105,0.8071565628051758,0.8588932156562805,0.8169991374015808,0.8089906741573033,0.5544554455445545,0.3434343434343434,0.2680412371134021,0.5346534653465347,0.3451078533083837,0.7368421052631579,0.5333333333333333,0.4594594594594595,0.8899354934692383,0.8082358837127686,0.8471204042434692,0.8157245516777039,0.8015001123595504,0.5436893203883495,0.33663366336633666,0.2626262626262626,0.5242718446601942,0.3569175397062245,0.6829268292682927,0.49382716049382713,0.425,0.8876827359199524,0.8085306882858276,0.8462598919868469,0.8158050179481506,0.8015001123595504,0.1955794429216942,0.1211234075373761,0.1445276974827343,0.25,0.2666666666666666,0.196270591547757,0.123888002041627,0.1445276974827343,0.25,0.2666666666666666,0.195851852046348,0.1222130440359914,0.1445276974827343,0.25,0.2666666666666666
438136,googleapis/google-cloud-python,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/googleapis_google-cloud-python/packages/google-cloud-gke-hub/google/cloud/gkehub_v1/services/gke_hub/transports/rest_base.py,gkehub_v1.services.gke_hub.transports.rest_base._BaseGkeHubRestTransport._BaseGetFeature,"class _BaseGetFeature:
    def __hash__(self):  # pragma: NO COVER
        return NotImplementedError(""__hash__ must be implemented."")

    @staticmethod
    def _get_http_options():
        http_options: List[Dict[str, str]] = [
            {
                ""method"": ""get"",
                ""uri"": ""/v1/{name=projects/*/locations/*/features/*}"",
            },
        ]
        return http_options

    @staticmethod
    def _get_transcoded_request(http_options, request):
        pb_request = service.GetFeatureRequest.pb(request)
        transcoded_request = path_template.transcode(
            http_options, pb_request)
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = json.loads(
            json_format.MessageToJson(
                transcoded_request[""query_params""],
                use_integers_for_enums=True,
            )
        )

        query_params[""$alt""] = ""json;enum-encoding=int""
        return query_params
","class _BaseGetFeature:


    def __hash__(self):
        pass

    @staticmethod
    def _get_http_options():
        pass

    @staticmethod
    def _get_transcoded_request(http_options, request):
        pass

    @staticmethod
    def _get_query_params_json(transcoded_request):
        pass

",8,0,snippet_283,0.5,"class _BaseGetFeature:

    def __hash__(self):
        return object.__hash__(self)

    @staticmethod
    def _get_http_options():
        return [
            {
                ""method"": ""get"",
                ""uri"": ""/v1/{name=projects/*/locations/*/featurestores/*/entityTypes/*/features/*}"",
            }
        ]

    @staticmethod
    def _get_transcoded_request(http_options, request):
        return transcode(http_options, request)

    @staticmethod
    def _get_query_params_json(transcoded_request):
        params = transcoded_request.get(""query_params"", {})
        # Filter out None values
        filtered = {k: v for k, v in params.items() if v is not None}
        return json.loads(
            json.dumps(
                filtered,
                default=lambda o: o.value if hasattr(o, ""value"") else o,
            )
        )","class _BaseGetFeature:

    def __hash__(self):
        return hash(type(self).__name__)

    @staticmethod
    def _get_http_options():
        return {}

    @staticmethod
    def _get_transcoded_request(http_options, request):
        return request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        return {}","class _BaseGetFeature:

    def __hash__(self):
        return hash(type(self))

    @staticmethod
    def _get_http_options():
        return {
            'method': 'GET',
            'uri': '/v1/{name=projects/*/locations/*/featurestores/*/entityTypes/*/features/*}',
        }

    @staticmethod
    def _get_transcoded_request(http_options, request):
        transcoded_request = {
            'uri': http_options['uri'].format(name=request.name),
            'method': http_options['method'],
            'query_params': {},
        }
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = transcoded_request.get('query_params', {})
        return {key: value for key, value in query_params.items() if value is not None}",no_docstr,0.5792349726775957,0.39779005524861877,0.29050279329608936,0.5245901639344263,0.5379062325681789,0.7598039215686274,0.5812807881773399,0.5099009900990099,0.8366280198097229,0.8194000124931335,0.827924370765686,0.821090817451477,0.7608719565217391,0.5038167938931298,0.37209302325581395,0.2992125984251968,0.4885496183206106,0.13315091784505423,0.9759036144578314,0.7439024390243902,0.6790123456790124,0.8699433207511902,0.6896786093711853,0.769393265247345,0.7042722105979919,0.7608719565217391,0.6741573033707865,0.46590909090909094,0.3333333333333333,0.5955056179775281,0.4620126025052298,0.7591623036649214,0.5263157894736842,0.4497354497354497,0.8788703680038452,0.8154315948486328,0.8459632992744446,0.8213603496551514,0.7801954347826087,0.2864242843219404,0.1776938353302997,0.2088708818661377,0.3424657534246575,0.4166666666666667,0.1143482537849028,0.0592054969182646,0.1363914756033864,0.1506849315068493,0.1111111111111111,0.2955719578706743,0.2058799248658293,0.2317351516701404,0.3835616438356164,0.3611111111111111
114336,DataDog/integrations-core,hazelcast/datadog_checks/hazelcast/utils.py,datadog_checks.hazelcast.utils.ServiceCheckStatus,"class ServiceCheckStatus(object):
    def __init__(self, default_map, user_map):
        self.statuses = {key.lower(): status for key, status in default_map.items()}
        self.statuses.update(
            (key.lower(), getattr(ServiceCheck, status.upper(), ServiceCheck.UNKNOWN))
            for key, status in user_map.items()
        )

    def get(self, key):
        return self.statuses.get(key.lower(), ServiceCheck.UNKNOWN)","class ServiceCheckStatus(object):


    def __init__(self, default_map, user_map):
        pass

    def get(self, key):
        pass

",3,0,snippet_488,1.0,"class ServiceCheckStatus(object):

    def __init__(self, default_map, user_map):
        if default_map is None:
            default_map = {}
        if user_map is None:
            user_map = {}
        self._combined = dict(default_map)
        self._combined.update(user_map)

    def get(self, key):
        return self._combined.get(key)","class ServiceCheckStatus(object):
    def __init__(self, default_map, user_map):
        self.default_map = default_map
        self.user_map = user_map

    def get(self, key):
        if key in self.user_map:
            return self.user_map[key]
        return self.default_map.get(key)","class ServiceCheckStatus(object):

    def __init__(self, default_map, user_map):
        self.default_map = default_map
        self.user_map = user_map

    def get(self, key):
        if key in self.user_map:
            return self.user_map[key]
        elif key in self.default_map:
            return self.default_map[key]
        else:
            return None",no_docstr,0.5263157894736843,0.3870967741935484,0.2857142857142857,0.5263157894736843,0.4083349633096794,0.6703296703296703,0.5333333333333333,0.43820224719101125,0.8856956362724304,0.8284925818443298,0.8561396598815918,0.833878219127655,0.8043497826086956,0.5806451612903226,0.39560439560439564,0.26966292134831465,0.5376344086021505,0.37150482743742513,0.725,0.569620253164557,0.48717948717948717,0.9268759489059448,0.8205472826957703,0.8704766631126404,0.8300696015357971,0.7826108695652173,0.5544554455445544,0.32323232323232326,0.2268041237113402,0.4752475247524753,0.36535377023056126,0.6263736263736264,0.45555555555555555,0.39325842696629215,0.9015287160873413,0.8196684122085571,0.8586519360542297,0.8271793723106384,0.7644951086956522,0.2743990775947358,0.2224708825902278,0.2340997867630746,0.3076923076923077,0.3333333333333333,0.2672516947825163,0.1876296055087014,0.2100485022926925,0.3076923076923077,0.3636363636363636,0.2550124343510592,0.1996732723114984,0.2178123625286357,0.2692307692307692,0.3333333333333333
298413,cloud9ers/gurumate,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/cloud9ers_gurumate/environment/lib/python2.7/site-packages/IPython/zmq/eventloops.py,IPython.zmq.eventloops.loop_tk.Timer,"class Timer(object):
    def __init__(self, func):
        self.app = Tkinter.Tk()
        self.app.withdraw()
        self.func = func

    def on_timer(self):
        self.func()
        self.app.after(poll_interval, self.on_timer)

    def start(self):
        self.on_timer()  # Call it once to get things going.
        self.app.mainloop()
","class Timer(object):


    def __init__(self, func):
        pass


    def on_timer(self):
        pass


    def start(self):
        pass

",4,0,snippet_96,0.6,"class Timer(object):
    def __init__(self, func):
        self.func = func
        self._running = False
        self._thread = None

    def on_timer(self):
        self.func()

    def start(self):
        if self._running:
            return
        self._running = True
        def _run():
            while self._running:
                time.sleep(1)
                self.on_timer()
        self._thread = threading.Thread(target=_run)
        self._thread.daemon = True
        self._thread.start()","class Timer(object):
    def __init__(self, func):
        self.func = func
        self.timer = None
        self.running = False

    def on_timer(self):
        if self.running:
            self.func()
            self.start()

    def start(self):
        if not self.running:
            self.running = True
            self.timer = threading.Timer(1.0, self.on_timer)
            self.timer.start()

    def stop(self):
        self.running = False
        if self.timer:
            self.timer.cancel()","class Timer(object):
    def __init__(self, func):
        self.func = func
        self.timer = None
        self.is_running = False

    def on_timer(self):
        self.is_running = False
        self.func()

    def start(self, interval=1.0):
        if not self.is_running:
            self.timer = threading.Timer(interval, self.on_timer)
            self.timer.start()
            self.is_running = True

    def stop(self):
        if self.timer:
            self.timer.cancel()
            self.is_running = False",no_docstr,0.5242718446601942,0.396039603960396,0.2626262626262626,0.46601941747572817,0.48222012484948906,0.6178861788617886,0.4672131147540984,0.3884297520661157,0.8090426325798035,0.815211832523346,0.8121155500411987,0.8145906329154968,0.8073413761467889,0.5185185185185185,0.3584905660377358,0.23076923076923078,0.46296296296296297,0.49725185241347253,0.6333333333333333,0.48739495798319327,0.3983050847457627,0.8338624238967896,0.8204001784324646,0.8270765542984009,0.8217267990112305,0.8260886956521738,0.5132743362831859,0.3783783783783784,0.2385321100917431,0.46017699115044247,0.47669044492420376,0.5968992248062015,0.4609375,0.3937007874015748,0.8218812942504883,0.830522358417511,0.8261792659759521,0.8296500444412231,0.8112113274336282,0.3616532010325688,0.1661477543252332,0.236986788935477,0.6956521739130435,0.3478260869565217,0.3396501832046334,0.1409758738694868,0.2176248589490471,0.6956521739130435,0.3043478260869565,0.3403012100101453,0.1307042108469498,0.2087614987588489,0.717391304347826,0.3043478260869565
248602,asciimoo/searx,asciimoo_searx/searx/search/models.py,searx.search.models.EngineRef,"class EngineRef:

    __slots__ = 'name', 'category'

    def __init__(self, name: str, category: str):
        self.name = name
        self.category = category

    def __repr__(self):
        return ""EngineRef({!r}, {!r})"".format(self.name, self.category)

    def __eq__(self, other):
        return self.name == other.name and self.category == other.category

    def __hash__(self):
        return hash((self.name, self.category))","class EngineRef:


    def __init__(self, name: str, category: str):
        pass

    def __repr__(self):
        pass

    def __eq__(self, other):
        pass

    def __hash__(self):
        pass

",5,0,snippet_253,1.0,"class EngineRef:
    def __init__(self, name: str, category: str):
        self.name = name
        self.category = category

    def __repr__(self):
        return f""{self.__class__.__name__}(name={self.name!r}, category={self.category!r})""

    def __eq__(self, other):
        if not isinstance(other, EngineRef):
            return NotImplemented
        return (self.name, self.category) == (other.name, other.category)

    def __hash__(self):
        return hash((self.name, self.category))","class EngineRef:
    def __init__(self, name: str, category: str):
        self.name = name
        self.category = category

    def __repr__(self):
        return f""EngineRef(name='{self.name}', category='{self.category}')""

    def __eq__(self, other):
        if not isinstance(other, EngineRef):
            return False
        return self.name == other.name and self.category == other.category

    def __hash__(self):
        return hash((self.name, self.category))","class EngineRef:
    def __init__(self, name: str, category: str):
        self.name = name
        self.category = category

    def __repr__(self):
        return f""EngineRef(name='{self.name}', category='{self.category}')""

    def __eq__(self, other):
        if not isinstance(other, EngineRef):
            return False
        return self.name == other.name and self.category == other.category

    def __hash__(self):
        return hash((self.name, self.category))",no_docstr,0.8849557522123894,0.7027027027027027,0.5504587155963303,0.7610619469026548,0.7074459057654195,0.8322147651006712,0.7027027027027027,0.6054421768707483,0.9075607061386108,0.940753698348999,0.923859179019928,0.9373255968093872,0.8698425714285714,0.8909090909090909,0.7962962962962962,0.679245283018868,0.8545454545454546,0.7801038342175649,0.8787878787878788,0.7633587786259542,0.7076923076923077,0.9457885026931763,0.9470360279083252,0.9464118480682373,0.9469111561775208,0.88889,0.8909090909090909,0.7962962962962962,0.679245283018868,0.8545454545454546,0.7801038342175649,0.8787878787878788,0.7633587786259542,0.7076923076923077,0.9457885026931763,0.9470360279083252,0.9464118480682373,0.9469111561775208,0.88889,0.5007607250992452,0.5029382979553326,0.5179299143846071,0.5882352941176471,0.3939393939393939,0.6149111187336186,0.6821747554847857,0.7168636588436279,0.6666666666666666,0.3939393939393939,0.6149111187336186,0.6821747554847857,0.7168636588436279,0.6666666666666666,0.3939393939393939
134958,Jaymon/captain,captain/io.py,captain.io.Progress,"class Progress(object):
    def __init__(self, output, length, **kwargs):
        self.length = length
        self.output = output

    def get_percentage(self, current):
        fill = float(current) / float(self.length)
        percentage = ""[{:3.2f}%]"".format(fill * 100.0)
        return percentage

    def get_progress(self, current):
        # http://stackoverflow.com/a/5676884/5006
        # http://stackoverflow.com/a/22776/5006
        bar = ""{current: >{justify}}/{length} {percentage: >10}"".format(
        #bar = ""{: >10} {: >10}"".format(
            current=current,
            justify=len(str(self.length)) + 1,
            length=self.length,
            percentage=self.get_percentage(current)
        )
        return bar

    def update(self, current):
        bar = self.get_progress(current)
        #self.output.err(bar + chr(8) * (len(bar) + 1), suffix="""")
        self.output.out(bar + chr(8) * (len(bar) + 1), suffix="""")","class Progress(object):


    def __init__(self, output, length, **kwargs):
        pass

    def get_percentage(self, current):
        pass

    def get_progress(self, current):
        pass

    def update(self, current):
        pass

",5,0,snippet_677,1.0,"class Progress(object):
    def __init__(self, output, length, **kwargs):
        self.output = output
        self.total = length
        self.bar_length = kwargs.get('bar_length', 50)
        self.fill_char = kwargs.get('fill_char', '#')
        self.empty_char = kwargs.get('empty_char', '-')
        self.prefix = kwargs.get('prefix', '')
        self.suffix = kwargs.get('suffix', '')
        self.decimals = kwargs.get('decimals', 1)
        self.end = kwargs.get('end', '\r')

    def get_percentage(self, current):
        if self.total == 0:
            return 100.0
        pct = (current / self.total) * 100
        return round(pct, self.decimals)

    def get_progress(self, current):
        pct = self.get_percentage(current)
        filled_len = int(self.bar_length * current / float(self.total or 1))
        bar = self.fill_char * filled_len + self.empty_char * (self.bar_length - filled_len)
        return f""{self.prefix}[{bar}]{pct}%{self.suffix}""

    def update(self, current):
        line = self.get_progress(current) + self.end
        self.output.write(line)
        self.output.flush()
        if current >= self.total:
            self.output.write('\n')
            self.output.flush()","class Progress(object):
    def __init__(self, output, length, **kwargs):
        self.output = output
        self.length = length
        self.width = kwargs.get('width', 50)
        self.fill_char = kwargs.get('fill_char', '#')
        self.empty_char = kwargs.get('empty_char', '-')
        self.show_percentage = kwargs.get('show_percentage', True)
        
    def get_percentage(self, current):
        if self.length <= 0:
            return 100.0
        return (current / self.length) * 100
        
    def get_progress(self, current):
        if self.length <= 0:
            filled_length = self.width
        else:
            filled_length = int((current / self.length) * self.width)
        
        filled = self.fill_char * min(filled_length, self.width)
        empty = self.empty_char * max(0, self.width - filled_length)
        
        bar = f""[{filled}{empty}]""
        
        if self.show_percentage:
            percentage = self.get_percentage(current)
            bar += f"" {percentage:.1f}%""
            
        return bar
        
    def update(self, current):
        progress_bar = self.get_progress(current)
        self.output.write(f""\r{progress_bar}"")
        self.output.flush()","class Progress(object):
    def __init__(self, output, length, **kwargs):
        self.output = output
        self.length = length
        self.current = 0
        self.last_output = """"
        
    def get_percentage(self, current):
        if self.length == 0:
            return 0
        return min(100, max(0, (current / self.length) * 100))
    
    def get_progress(self, current):
        percentage = self.get_percentage(current)
        return f""Progress: {current}/{self.length} ({percentage:.1f}%)""
    
    def update(self, current):
        self.current = current
        progress_str = self.get_progress(current)
        
        # Clear previous output
        if self.last_output:
            self.output.write('\r' + ' ' * len(self.last_output) + '\r')
        
        # Write new progress
        self.output.write(progress_str)
        self.output.flush()
        
        self.last_output = progress_str",no_docstr,0.5303030303030303,0.29007633587786263,0.1769230769230769,0.37121212121212116,0.3463648757090941,0.572289156626506,0.311178247734139,0.23333333333333334,0.7889949679374695,0.7713523507118225,0.780073881149292,0.7730810642242432,0.7486881072555209,0.528,0.3629032258064516,0.24390243902439024,0.44799999999999995,0.4131288480040372,0.6220735785953178,0.3825503355704698,0.2962962962962963,0.8148736953735352,0.7723684310913086,0.7930519580841064,0.7764183282852173,0.7535145977011501,0.5514018691588786,0.4150943396226415,0.26666666666666666,0.4392523364485981,0.4191511666504118,0.7142857142857143,0.49327354260089684,0.38288288288288286,0.853076696395874,0.7775707244873047,0.8135755658149719,0.7845144867897034,0.7486656149732623,0.295516157451667,0.1188681362349514,0.1703393507145737,0.375,0.5178571428571429,0.3202531228389568,0.1604485087015421,0.215206839797142,0.3875,0.5178571428571429,0.3581560674010179,0.1681372644883006,0.1787727194014853,0.425,0.6607142857142857
591080,nameko/nameko,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/nameko_nameko/docs/examples/auth.py,examples.auth.Auth.Api,"class Api:
    def __init__(self, users, worker_ctx):
        self.users = users
        self.worker_ctx = worker_ctx

    def authenticate(self, username, password):
        user = self.users.get(username)
        if not user:
            raise Unauthenticated(""User does not exist"")
        if not bcrypt.checkpw(password.encode('utf-8'), user['password']):
            raise Unauthenticated(""Incorrect password"")

        payload = {
            'username': username,
            'roles': self.users[username]['roles']
        }
        token = jwt.encode(payload, key=JWT_SECRET, algorithm=""HS256"")
        self.worker_ctx.context_data['auth'] = token
        return token

    def has_role(self, role):
        token = self.worker_ctx.context_data.get('auth')
        if not token:
            raise Unauthenticated()

        try:
            payload = jwt.decode(
                token, key=JWT_SECRET, verify=True, algorithms=[""HS256""]
            )
            if role in payload['roles']:
                return True
        except Exception:
            pass

        return False

    def check_role(self, role):
        if self.has_role(role):
            return
        raise Unauthorized()
","class Api:


    def __init__(self, users, worker_ctx):
        pass


    def authenticate(self, username, password):
        pass


    def has_role(self, role):
        pass


    def check_role(self, role):
        pass

",5,0,snippet_297,0.2666666666666666,"class Api:

    def __init__(self, users, worker_ctx):
        self._users = users
        self._ctx = worker_ctx
        setattr(self._ctx, 'user', None)

    def authenticate(self, username, password):
        user = self._users.get(username)
        if user is None or user.get('password') != password:
            raise ValueError(""Invalid username or password"")
        setattr(self._ctx, 'user', username)

    def has_role(self, role):
        current = getattr(self._ctx, 'user', None)
        if current is None:
            return False
        return role in self._users.get(current, {}).get('roles', [])

    def check_role(self, role):
        if not self.has_role(role):
            raise PermissionError(f""Access denied, missing role: {role}"")","class Api:
    def __init__(self, users, worker_ctx):
        self.users = users
        self.worker_ctx = worker_ctx
        self.current_user = None

    def authenticate(self, username, password):
        if username in self.users and self.users[username] == password:
            self.current_user = username
            return True
        return False

    def has_role(self, role):
        if self.current_user is None:
            return False
        # Assuming users dictionary structure includes roles
        # Example: {'username': {'password': 'pass', 'roles': ['admin', 'user']}}
        user_data = self.users.get(self.current_user, {})
        if isinstance(user_data, dict) and 'roles' in user_data:
            return role in user_data['roles']
        return False

    def check_role(self, role):
        if not self.has_role(role):
            raise PermissionError(f""User does not have required role: {role}"")
        return True","class Api:
    def __init__(self, users, worker_ctx):
        self.users = users
        self.worker_ctx = worker_ctx
        self.current_user = None

    def authenticate(self, username, password):
        if username in self.users and self.users[username]['password'] == password:
            self.current_user = self.users[username]
            self.current_user['username'] = username
            return True
        return False

    def has_role(self, role):
        if self.current_user is None:
            return False
        return role in self.current_user.get('roles', [])

    def check_role(self, role):
        if not self.has_role(role):
            raise PermissionError(f""User does not have required role: {role}"")
        return True",no_docstr,0.5866666666666667,0.35874439461883406,0.26244343891402716,0.4977777777777779,0.38776007507606186,0.8177083333333334,0.4973821989528796,0.3736842105263158,0.8444138765335083,0.7800507545471191,0.8109572529792786,0.7860420942306519,0.7968546781115879,0.6048387096774194,0.3658536585365854,0.27049180327868855,0.4274193548387097,0.4444325453270116,0.7464788732394366,0.5141509433962265,0.4028436018957346,0.8466943502426147,0.7931009531021118,0.8190218806266785,0.7981531023979187,0.7596590557939918,0.6133333333333334,0.4035874439461884,0.2895927601809955,0.4533333333333333,0.3902371918123445,0.8505747126436781,0.5838150289017341,0.47093023255813954,0.8620567917823792,0.7797785997390747,0.8188560605049133,0.7872928380966187,0.775395665236052,0.298142607252138,0.1659719701605755,0.1801797260656073,0.4297520661157025,0.4166666666666667,0.309680378672128,0.2466953930937827,0.2616542207682832,0.3553719008264462,0.375,0.2875025283896184,0.2199444175084615,0.2440004986211785,0.3388429752066115,0.3472222222222222
544662,lensacom/sparkit-learn,lensacom_sparkit-learn/splearn/cluster/dbscan.py,splearn.cluster.dbscan.DbscanModel,"class DbscanModel(object):

    def __init__(self, model):
        self._model = model

    def predict(self, point):
        serialized = _serialize_double_vector(point)
        return self._model.predict(serialized)","class DbscanModel(object):


    def __init__(self, model):
        pass

    def predict(self, point):
        pass

",3,0,snippet_352,1.0,"class DbscanModel(object):
    def __init__(self, model):
        if not hasattr(model, 'labels_') or not hasattr(model, 'components_') or not hasattr(model, 'eps'):
            raise ValueError(""Model must be a fitted sklearn.cluster.DBSCAN instance."")
        self.eps = model.eps
        self.core_samples = model.components_
        self.core_labels = model.labels_[model.core_sample_indices_]

    def predict(self, point):
        pt = np.asarray(point)
        dists = np.linalg.norm(self.core_samples - pt, axis=1)
        idx = np.argmin(dists)
        return int(self.core_labels[idx]) if dists[idx] <= self.eps else -1","class DbscanModel(object):
    def __init__(self, model):
        self.model = model
        self.labels = model.labels_
        self.core_sample_indices = model.core_sample_indices_
        
    def predict(self, point):
        # DBSCAN doesn't have a built-in predict method for new points
        # We need to implement nearest neighbor classification based on fitted clusters
        import numpy as np
        from sklearn.neighbors import NearestNeighbors
        
        # Get the core samples (points that were actually clustered)
        if hasattr(self.model, 'components_'):
            core_points = self.model.components_
        else:
            # Fallback: use the original training data if available
            raise ValueError(""Model must have components_ attribute or training data"")
        
        # If the point belongs to a cluster, find nearest core point
        if len(core_points) == 0:
            return -1  # Noise label
            
        # Fit nearest neighbors on core samples
        nbrs = NearestNeighbors(n_neighbors=1).fit(core_points)
        distances, indices = nbrs.kneighbors([point])
        
        # Return the label of the nearest core point
        nearest_core_idx = indices[0][0]
        # This is a simplified approach - in practice, you'd need to map core point indices to labels
        return 0","class DbscanModel(object):

    def __init__(self, model):
        self.model = model
        self.core_samples_ = model.core_sample_indices_
        self.labels_ = model.labels_
        self.X_ = model.components_
        self.eps = model.eps
        self.min_samples = model.min_samples
        self.nn = NearestNeighbors(radius=self.eps, metric=model.metric)
        self.nn.fit(self.X_)

    def predict(self, point):
        point = np.array(point).reshape(1, -1)
        neighbors = self.nn.radius_neighbors(point, return_distance=False)[0]
        
        if len(neighbors) == 0:
            return -1
        
        neighbor_labels = self.labels_[neighbors]
        neighbor_labels = neighbor_labels[neighbor_labels != -1]
        
        if len(neighbor_labels) == 0:
            return -1
        
        unique_labels, counts = np.unique(neighbor_labels, return_counts=True)
        return unique_labels[np.argmax(counts)]",no_docstr,0.32727272727272727,0.16666666666666666,0.1320754716981132,0.3090909090909091,0.19577485320893734,0.2807017543859649,0.18823529411764706,0.14201183431952663,0.6569011211395264,0.8096096515655518,0.7253045439720154,0.7912164330482483,0.7595262142857142,0.19791666666666666,0.14736842105263157,0.10638297872340424,0.16666666666666666,0.1325092235130053,0.18992248062015504,0.12062256809338522,0.1015625,0.5859346389770508,0.8190946578979492,0.6831685900688171,0.7877479195594788,0.751827299270073,0.26666666666666666,0.19548872180451127,0.15267175572519087,0.2518518518518518,0.15423937298771642,0.20869565217391303,0.14847161572052403,0.11842105263157894,0.6094768047332764,0.8198332786560059,0.6991755962371826,0.7924813032150269,0.7361880213903743,0.3604699192799228,0.0863880453573337,0.3489981252688509,0.3636363636363636,0.6428571428571429,0.3500774702770299,0.034286896295121,0.3660229848129988,0.5,0.5,0.3969573378592503,0.0789492237668599,0.3660229848129988,0.5,0.6428571428571429
707499,rocky/python-uncompyle6,rocky_python-uncompyle6/test/simple_source/def/10_class.py,10_class.B,"class B:
    def __init__(self):
        self.bed = True

    def bar(self):
        self.barred = True","class B:


    def __init__(self):
        pass

    def bar(self):
        pass

",3,0,snippet_286,1.0,"class B:

    def __init__(self):
        pass

    def bar(self):
        return ""bar""","class B:
    def __init__(self):
        self.value = 0

    def bar(self):
        return ""bar method called""","class B:
    def __init__(self):
        pass

    def bar(self):
        pass",no_docstr,0.64,0.5217391304347826,0.380952380952381,0.64,0.6067872526955007,0.8,0.75,0.6956521739130435,0.8981378674507141,0.8420053720474243,0.8691662549972534,0.8473008871078491,0.8461553846153845,0.6206896551724138,0.5185185185185186,0.4,0.6206896551724138,0.6746053744042909,0.7419354838709677,0.6666666666666666,0.6206896551724138,0.8591839671134949,0.8644208908081055,0.8617944717407227,0.8638943433761597,0.9102573076923076,0.6666666666666666,0.5454545454545455,0.4,0.6666666666666666,0.5836305100821954,0.9090909090909091,0.8571428571428571,0.8,0.9107055068016052,0.8480720520019531,0.8782734870910645,0.8539450764656067,0.8461553846153845,0.1975438741041205,0.2543314312919721,0.2596535889340338,0.1333333333333333,0.1428571428571428,0.3350733073496649,0.2390108882452813,0.2631871030581402,0.2666666666666666,0.5714285714285714,0.1963023022533058,0.2493651438887133,0.2596535889340338,0.1333333333333333,0.1428571428571428
352521,driftx/Telephus,driftx_Telephus/telephus/client.py,telephus.client.requirekwargs,"class requirekwargs:
    def __init__(self, *args):
        self.required = args

    def __call__(self, f):
        def wrapper(*args, **kwargs):
            for arg in self.required:
                if arg in kwargs and kwargs[arg] is None:
                    raise TypeError(""'%s' argument must not be None"" % arg)
            return f(*args, **kwargs)
        wrapper.__doc__ = f.__doc__
        return wrapper","class requirekwargs:


    def __init__(self, *args):
        pass

    def __call__(self, f):
        pass

        def wrapper(*args, **kwargs):
                pass

",4,0,snippet_460,0.7,"class requirekwargs:
    def __init__(self, *args):
        self._required = set(args)

    def __call__(self, f):
        @wraps(f)
        def wrapper(*args, **kwargs):
            missing = self._required - set(kwargs)
            if missing:
                name = f.__name__
                missing_list = "", "".join(sorted(missing))
                raise TypeError(f""{name}() missing required keyword arguments: {missing_list}"")
            return f(*args, **kwargs)
        return wrapper","class requirekwargs:
    def __init__(self, *args):
        self.required_kwargs = set(args)

    def __call__(self, f):
        def wrapper(*args, **kwargs):
            missing_kwargs = self.required_kwargs - set(kwargs.keys())
            if missing_kwargs:
                raise TypeError(f""Missing required keyword arguments: {', '.join(missing_kwargs)}"")
            return f(*args, **kwargs)
        return wrapper","class requirekwargs:
    def __init__(self, *args):
        self.required_kwargs = set(args)

    def __call__(self, f):
        def wrapper(*args, **kwargs):
            missing_kwargs = self.required_kwargs - set(kwargs.keys())
            if missing_kwargs:
                raise TypeError(f""Missing required keyword arguments: {', '.join(sorted(missing_kwargs))}"")
            return f(*args, **kwargs)
        return wrapper",no_docstr,0.5940594059405941,0.42424242424242425,0.288659793814433,0.5544554455445545,0.4979124432972288,0.6507936507936508,0.48,0.3951612903225806,0.8570536375045776,0.8696034550666809,0.8632828593254089,0.8683319687843323,0.8178712371134019,0.6458333333333334,0.44680851063829785,0.32608695652173914,0.6041666666666666,0.5717840105413686,0.7431192660550459,0.5277777777777778,0.4766355140186916,0.896729588508606,0.879439115524292,0.8880002498626709,0.881138026714325,0.854168125,0.6391752577319586,0.4421052631578947,0.3225806451612903,0.5979381443298969,0.556329540784227,0.7232142857142857,0.5135135135135135,0.4636363636363636,0.8878292441368103,0.8786916732788086,0.883236825466156,0.8795969486236572,0.8473910843373494,0.3389452188299366,0.1728991555333114,0.1781198150245305,0.4047619047619047,0.6,0.3307411606057297,0.2322344815777706,0.2459682560832436,0.4047619047619047,0.44,0.3307411606057297,0.2322344815777706,0.2459682560832436,0.4047619047619047,0.44
319266,crdoconnor/strictyaml,crdoconnor_strictyaml/hitch/pyenv.py,pyenv.ProjectDependencies,"class ProjectDependencies:
    def __init__(self, pyproject_toml, pyenv_build):
        self._pyproject_toml = pyproject_toml
        self._pyenv_build = pyenv_build

    def load(self):
        project = tomli.loads(self._pyproject_toml)[""project""]
        pyversion = project[""requires-python""]
        dependencies = project[""dependencies""]

        self.dependency_versions = {}

        for dependency in dependencies:
            assert "">="" in dependency

            self.dependency_versions[
                dependency.split("">="")[0]
            ] = package_versions_above(
                dependency.split("">="")[0],
                dependency.split("">="")[1],
            )

        self.python_versions = self._pyenv_build.available_versions_above_and_including(
            pyversion.split("">="")[1]
        )","class ProjectDependencies:


    def __init__(self, pyproject_toml, pyenv_build):
        pass

    def load(self):
        pass

",3,0,snippet_519,0.4285714285714285,"class ProjectDependencies:
    def __init__(self, pyproject_toml, pyenv_build):
        self.pyproject_toml = Path(pyproject_toml)
        self.pyenv_build = pyenv_build

    def load(self):
        content = self.pyproject_toml.read_text(encoding=""utf-8"")
        data = toml.loads(content)
        poetry = data.get(""tool"", {}).get(""poetry"", {})
        main_deps = poetry.get(""dependencies"", {})
        dev_deps = poetry.get(""dev-dependencies"", {})

        built = {
            ""dependencies"": [],
            ""dev-dependencies"": []
        }

        for name, spec in main_deps.items():
            if name.lower() == ""python"":
                continue
            built_dep = self.pyenv_build.build(name, spec, dev=False)
            built[""dependencies""].append(built_dep)

        for name, spec in dev_deps.items():
            built_dep = self.pyenv_build.build(name, spec, dev=True)
            built[""dev-dependencies""].append(built_dep)

        return built","class ProjectDependencies:
    def __init__(self, pyproject_toml, pyenv_build):
        self.pyproject_toml = pyproject_toml
        self.pyenv_build = pyenv_build
        self.dependencies = {}
        self.dev_dependencies = {}
        self.optional_dependencies = {}

    def load(self):
        import toml
        import os
        
        # Load pyproject.toml
        if os.path.exists(self.pyproject_toml):
            with open(self.pyproject_toml, 'r') as f:
                config = toml.load(f)
            
            # Extract dependencies
            project_config = config.get('project', {})
            
            # Main dependencies
            self.dependencies = project_config.get('dependencies', {})
            
            # Development dependencies
            self.dev_dependencies = config.get('tool', {}).get('pytest', {}).get('dev-dependencies', {})
            
            # Optional dependencies
            self.optional_dependencies = project_config.get('optional-dependencies', {})
        
        # Load pyenv build information if available
        if os.path.exists(self.pyenv_build):
            with open(self.pyenv_build, 'r') as f:
                # Parse pyenv build file if needed
                pass","class ProjectDependencies:
    def __init__(self, pyproject_toml, pyenv_build):
        self.pyproject_toml = pyproject_toml
        self.pyenv_build = pyenv_build
        self.dependencies = {}
        self.dev_dependencies = {}
        self.build_dependencies = {}
        self.python_version = None

    def load(self):
        if os.path.exists(self.pyproject_toml):
            with open(self.pyproject_toml, 'r') as f:
                data = toml.load(f)
            
            # Load project dependencies
            if 'project' in data and 'dependencies' in data['project']:
                self.dependencies = {dep.split('==')[0] if '==' in dep else dep.split('>=')[0] if '>=' in dep else dep.split('~=')[0] if '~=' in dep else dep: dep for dep in data['project']['dependencies']}
            
            # Load optional dependencies (dev dependencies)
            if 'project' in data and 'optional-dependencies' in data['project']:
                for group, deps in data['project']['optional-dependencies'].items():
                    self.dev_dependencies[group] = {dep.split('==')[0] if '==' in dep else dep.split('>=')[0] if '>=' in dep else dep.split('~=')[0] if '~=' in dep else dep: dep for dep in deps}
            
            # Load build system dependencies
            if 'build-system' in data and 'requires' in data['build-system']:
                self.build_dependencies = {dep.split('==')[0] if '==' in dep else dep.split('>=')[0] if '>=' in dep else dep.split('~=')[0] if '~=' in dep else dep: dep for dep in data['build-system']['requires']}
            
            # Load Python version requirement
            if 'project' in data and 'requires-python' in data['project']:
                self.python_version = data['project']['requires-python']
        
        if os.path.exists(self.pyenv_build):
            with open(self.pyenv_build, 'r') as f:
                content = f.read().strip()
                if content:
                    self.python_version = content",no_docstr,0.40217391304347827,0.26373626373626374,0.2222222222222222,0.3695652173913043,0.3054642092374258,0.5476190476190477,0.28286852589641437,0.184,0.7991935014724731,0.8493063449859619,0.8234882354736328,0.844014048576355,0.7958553110047849,0.39593908629441626,0.26666666666666666,0.2072538860103627,0.3756345177664974,0.27026972161651314,0.45491803278688525,0.23868312757201646,0.18181818181818182,0.7929372787475586,0.8301617503166199,0.8111225962638855,0.826282799243927,0.7963895566502465,0.31875000000000003,0.19496855345911948,0.13291139240506328,0.2875,0.17100540574181416,0.28714859437751006,0.16297786720321933,0.10685483870967742,0.7847058773040771,0.8825471997261047,0.8307557106018066,0.8716785907745361,0.7472247499999998,0.2446819992232429,0.1149344162923357,0.1875285540420675,0.410958904109589,0.2653061224489796,0.2747371354801118,0.0753352101089574,0.1499762057281798,0.4246575342465753,0.4489795918367347,0.346297163490452,0.0380553042325406,0.1659759552646324,0.6301369863013698,0.5510204081632653
740233,six8/corona-cipr,six8_corona-cipr/src/cipr/commands/cfg.py,cipr.commands.cfg.Package,"class Package(object):    
    def __init__(self, dir, source):
        self._dir = dir
        self._packagesDir = path.dirname(dir)
        self.info = {}
        self.source = source

        self.name = path.basename(self._dir)

        info_file = path.join(self._dir, 'package.json')
        if path.exists(info_file):
            with open(info_file) as file:
                self.info = json.load(file)

    @property
    def path(self):
        return self._dir

    @property
    def deploy_packages(self):
        return [
            Package(path.join(self._packagesDir, name), source)
                for name, source in self.dependencies.items()
        ]

    @property
    def dependencies(self):
        return self.info.get('dependencies', {})","class Package(object):


    def __init__(self, dir, source):
        pass

    @property
    def path(self):
        pass

    @property
    def deploy_packages(self):
        pass

    @property
    def dependencies(self):
        pass

",8,0,snippet_341,0.1818181818181818,"class Package(object):

    def __init__(self, dir, source):
        self.dir = dir
        self.source = source

    @property
    def path(self):
        return os.path.abspath(os.path.join(self.dir, self.source))

    @property
    def deploy_packages(self):
        pkgs = []
        base = self.path
        for root, dirs, files in os.walk(base):
            if '__init__.py' in files:
                rel = os.path.relpath(root, base)
                if rel == '.':
                    name = os.path.basename(base)
                else:
                    name = rel.replace(os.sep, '.')
                pkgs.append(name)
        return sorted(pkgs)

    @property
    def dependencies(self):
        req_file = os.path.join(self.path, 'requirements.txt')
        if not os.path.isfile(req_file):
            return []
        deps = []
        with open(req_file) as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    deps.append(line)
        return deps","class Package(object):
    def __init__(self, dir, source):
        self.dir = dir
        self.source = source

    @property
    def path(self):
        return os.path.join(self.dir, self.source)

    @property
    def deploy_packages(self):
        deploy_dir = os.path.join(self.dir, 'deploy')
        if os.path.exists(deploy_dir):
            return [f for f in os.listdir(deploy_dir) 
                   if os.path.isfile(os.path.join(deploy_dir, f))]
        return []

    @property
    def dependencies(self):
        deps_file = os.path.join(self.dir, 'dependencies.txt')
        if os.path.exists(deps_file):
            with open(deps_file, 'r') as f:
                return [line.strip() for line in f.readlines() if line.strip()]
        return []","class Package(object):

    def __init__(self, dir, source):
        self.dir = dir
        self.source = source
        self._deploy_packages = None
        self._dependencies = None

    @property
    def path(self):
        return os.path.join(self.source, self.dir)

    @property
    def deploy_packages(self):
        if self._deploy_packages is None:
            package_json_path = os.path.join(self.path, 'package.json')
            if os.path.exists(package_json_path):
                with open(package_json_path, 'r') as f:
                    package_data = json.load(f)
                    self._deploy_packages = package_data.get('deployPackages', [])
            else:
                self._deploy_packages = []
        return self._deploy_packages

    @property
    def dependencies(self):
        if self._dependencies is None:
            package_json_path = os.path.join(self.path, 'package.json')
            if os.path.exists(package_json_path):
                with open(package_json_path, 'r') as f:
                    package_data = json.load(f)
                    deps = package_data.get('dependencies', {})
                    dev_deps = package_data.get('devDependencies', {})
                    self._dependencies = list(set(list(deps.keys()) + list(dev_deps.keys())))
            else:
                self._dependencies = []
        return self._dependencies",no_docstr,0.5358851674641149,0.3188405797101449,0.21463414634146344,0.33492822966507174,0.38042390397862275,0.5793650793650794,0.3545816733067729,0.268,0.7584782838821411,0.824999213218689,0.7903414964675903,0.8178265690803528,0.7666690000000009,0.6,0.37234042553191493,0.24731182795698925,0.38947368421052636,0.49393329530993996,0.697560975609756,0.4803921568627451,0.35960591133004927,0.827136218547821,0.8483525514602661,0.837610125541687,0.8461820483207703,0.7753645652173917,0.5102880658436214,0.3319502074688797,0.2092050209205021,0.3868312757201646,0.3547648012730194,0.47865853658536583,0.345565749235474,0.26993865030674846,0.8092358708381653,0.8502293825149536,0.8292263150215149,0.8459440469741821,0.7828660211267611,0.3309610150552141,0.1305624571262528,0.2173950782719085,0.5425531914893617,0.4333333333333333,0.3383443605198145,0.1865080395106896,0.2154509628522563,0.4680851063829787,0.4833333333333333,0.3254415878607856,0.1255895623792029,0.2155384911915989,0.5106382978723404,0.45
424631,googleapis/google-cloud-python,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/googleapis_google-cloud-python/packages/google-cloud-dataform/google/cloud/dataform_v1beta1/services/dataform/transports/rest_base.py,dataform_v1beta1.services.dataform.transports.rest_base._BaseDataformRestTransport._BaseGetIamPolicy,"class _BaseGetIamPolicy:
    def __hash__(self):  # pragma: NO COVER
        return NotImplementedError(""__hash__ must be implemented."")

    @staticmethod
    def _get_http_options():
        http_options: List[Dict[str, str]] = [
            {
                ""method"": ""get"",
                ""uri"": ""/v1beta1/{resource=projects/*/locations/*/repositories/*}:getIamPolicy"",
            },
            {
                ""method"": ""get"",
                ""uri"": ""/v1beta1/{resource=projects/*/locations/*/repositories/*/workspaces/*}:getIamPolicy"",
            },
        ]
        return http_options

    @staticmethod
    def _get_transcoded_request(http_options, request):
        request_kwargs = json_format.MessageToDict(request)
        transcoded_request = path_template.transcode(
            http_options, **request_kwargs)
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = json.loads(json.dumps(
            transcoded_request[""query_params""]))
        return query_params
","class _BaseGetIamPolicy:


    def __hash__(self):
        pass

    @staticmethod
    def _get_http_options():
        pass

    @staticmethod
    def _get_transcoded_request(http_options, request):
        pass

    @staticmethod
    def _get_query_params_json(transcoded_request):
        pass

",8,0,snippet_674,0.5,"class _BaseGetIamPolicy:

    def __hash__(self):
        return hash(tuple(tuple(sorted(option.items())) for option in self._get_http_options()))

    @staticmethod
    def _get_http_options():
        return [
            {
                ""method"": ""post"",
                ""uri"": ""/v1/{resource}:getIamPolicy"",
                ""body"": ""*""
            }
        ]

    @staticmethod
    def _get_transcoded_request(http_options, request):
        return path_template.transcode(http_options, **request)

    @staticmethod
    def _get_query_params_json(transcoded_request):
        return json.loads(MessageToJson(transcoded_request[""query_params""]))","class _BaseGetIamPolicy:

    def __hash__(self):
        return hash(type(self).__name__)

    @staticmethod
    def _get_http_options():
        return [
            {
                ""method"": ""GET"",
                ""uri"": ""/v1/{resource=**}:getIamPolicy"",
            },
        ]

    @staticmethod
    def _get_transcoded_request(http_options, request):
        transcoded_request = http_options[0].copy()
        uri = transcoded_request[""uri""]
        
        # Extract resource from request
        resource = getattr(request, ""resource"", """")
        if resource:
            uri = uri.replace(""{resource=**}"", resource)
        
        transcoded_request[""uri""] = uri
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = {}
        
        # Extract query parameters from URI if present
        uri = transcoded_request.get(""uri"", """")
        if ""?"" in uri:
            query_string = uri.split(""?"", 1)[1]
            for param in query_string.split(""&""):
                if ""="" in param:
                    key, value = param.split(""="", 1)
                    query_params[key] = value
        
        return query_params","class _BaseGetIamPolicy:

    def __hash__(self):
        return hash(type(self))

    @staticmethod
    def _get_http_options():
        return [
            {
                ""method"": ""post"",
                ""uri"": ""/v1/{resource=projects/*/locations/*/datasets/*}:getIamPolicy"",
                ""body"": ""*"",
            },
            {
                ""method"": ""post"", 
                ""uri"": ""/v1/{resource=projects/*/locations/*/datasets/*/dicomStores/*}:getIamPolicy"",
                ""body"": ""*"",
            },
            {
                ""method"": ""post"",
                ""uri"": ""/v1/{resource=projects/*/locations/*/datasets/*/fhirStores/*}:getIamPolicy"", 
                ""body"": ""*"",
            },
            {
                ""method"": ""post"",
                ""uri"": ""/v1/{resource=projects/*/locations/*/datasets/*/hl7V2Stores/*}:getIamPolicy"",
                ""body"": ""*"",
            },
        ]

    @staticmethod
    def _get_transcoded_request(http_options, request):
        pb_request = request
        transcoded_request = {}
        
        if hasattr(pb_request, 'resource'):
            transcoded_request['resource'] = pb_request.resource
        
        body = {}
        if hasattr(pb_request, 'options'):
            body['options'] = pb_request.options
            
        transcoded_request['body'] = body
        transcoded_request['method'] = http_options.get('method', 'post')
        transcoded_request['uri'] = http_options.get('uri', '')
        
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = {}
        body = transcoded_request.get('body', {})
        
        if 'options' in body:
            options = body['options']
            if hasattr(options, 'requested_policy_version'):
                query_params['options.requestedPolicyVersion'] = options.requested_policy_version
                
        return query_params",no_docstr,0.6369426751592357,0.4387096774193548,0.35294117647058826,0.5605095541401274,0.4211903256522616,0.8695652173913043,0.6875,0.6037735849056604,0.8518465757369995,0.7870755791664124,0.8181811571121216,0.7931060194969177,0.8297889361702127,0.5384615384615384,0.3592233009708738,0.2549019607843137,0.4807692307692307,0.45519237476607893,0.6501766784452296,0.42907801418439717,0.33807829181494664,0.8183996677398682,0.7966541647911072,0.8073805570602417,0.7987765669822693,0.7567164928909961,0.5241935483870968,0.3333333333333333,0.22131147540983606,0.4758064516129032,0.37764606999617706,0.49653579676674364,0.3541666666666667,0.3062645011600928,0.8401656150817871,0.8392553329467773,0.8397102355957031,0.8393462896347046,0.7662497169811321,0.2362216426773771,0.12069867705267,0.1540766058984917,0.4054054054054054,0.2647058823529412,0.3416685396403326,0.1558885436138364,0.2648396690015482,0.4459459459459459,0.5,0.3179652246521408,0.1447889780062133,0.2804900446087093,0.4054054054054054,0.4411764705882353
318075,cpenv/cpenv,cpenv_cpenv/cpenv/vendor/yaml/yaml3/events.py,cpenv.vendor.yaml.yaml3.events.Event,"class Event(object):
    def __init__(self, start_mark=None, end_mark=None):
        self.start_mark = start_mark
        self.end_mark = end_mark
    def __repr__(self):
        attributes = [key for key in ['anchor', 'tag', 'implicit', 'value']
                if hasattr(self, key)]
        arguments = ', '.join(['%s=%r' % (key, getattr(self, key))
                for key in attributes])
        return '%s(%s)' % (self.__class__.__name__, arguments)","class Event(object):


    def __init__(self, start_mark=None, end_mark=None):
        pass

    def __repr__(self):
        pass

",3,0,snippet_405,0.8,"class Event(object):
    def __init__(self, start_mark=None, end_mark=None):
        self.start_mark = start_mark
        self.end_mark = end_mark

    def __repr__(self):
        return ""{}(start_mark={!r}, end_mark={!r})"".format(
            self.__class__.__name__, self.start_mark, self.end_mark
        )","class Event(object):
    def __init__(self, start_mark=None, end_mark=None):
        self.start_mark = start_mark
        self.end_mark = end_mark

    def __repr__(self):
        return f""{self.__class__.__name__}(start_mark={self.start_mark!r}, end_mark={self.end_mark!r})""","class Event(object):

    def __init__(self, start_mark=None, end_mark=None):
        self.start_mark = start_mark
        self.end_mark = end_mark

    def __repr__(self):
        attributes = [key for key, value in self.__dict__.items()
                     if not key.endswith('_mark')]
        attributes.sort()
        arguments = ', '.join(['%s=%r' % (key, getattr(self, key))
                              for key in attributes])
        if arguments:
            return '%s(%s)' % (self.__class__.__name__, arguments)
        else:
            return '%s()' % self.__class__.__name__",no_docstr,0.6464646464646465,0.5360824742268041,0.5052631578947367,0.5858585858585859,0.5112305253855414,0.7545454545454545,0.6422018348623854,0.6296296296296297,0.9445990920066833,0.8102429509162903,0.8722776770591736,0.8219338655471802,0.8141044230769231,0.6464646464646465,0.5360824742268041,0.5052631578947367,0.5858585858585859,0.48608986043531616,0.7523809523809524,0.6538461538461539,0.6407766990291263,0.9364590048789978,0.7975810766220093,0.8614587783813477,0.8095873594284058,0.7980789423076923,0.8479999999999999,0.7317073170731707,0.694214876033058,0.816,0.688481408199033,0.7303370786516854,0.6779661016949152,0.6590909090909091,0.9156767725944519,0.9368441700935364,0.9261395335197449,0.9346835613250732,0.8699199999999999,0.3547692988422271,0.2176092867056986,0.3078377293187445,0.4693877551020408,0.4242424242424242,0.2786673853267441,0.1673760296753067,0.3078377293187445,0.3061224489795918,0.3333333333333333,0.7642467038076387,0.6339492131620197,0.7384364888959934,0.7755102040816326,0.9090909090909092
744507,socialwifi/RouterOS-api,socialwifi_RouterOS-api/routeros_api/api_communicator/base.py,routeros_api.api_communicator.base.AsynchronousResponseIterator,"class AsynchronousResponseIterator:
    def __init__(self, response_buffor_manager):
        self.response_buffor_manager = response_buffor_manager
        self.index = 0

    def __iter__(self):
        return self

    def __next__(self):
        response = self.response_buffor_manager.response
        while self.end_of_buffered and not self.response_buffor_manager.done:
            self.response_buffor_manager.step_to_finish_response()
        if self.end_of_buffered and response.error:
            self.response_buffor_manager.clean()
            raise response.error_as_exception
        elif self.end_of_buffered:
            self.response_buffor_manager.clean()
            raise StopIteration
        else:
            current = response[self.index]
            self.index += 1
            return current

    @property
    def end_of_buffered(self):
        return self.index >= len(self.response_buffor_manager.response)","class AsynchronousResponseIterator:


    def __init__(self, response_buffor_manager):
        pass

    def __iter__(self):
        pass

    def __next__(self):
        pass

    @property
    def end_of_buffered(self):
        pass

",6,0,snippet_1,0.2105263157894736,"class AsynchronousResponseIterator:
    def __init__(self, response_buffor_manager):
        self._mgr = response_buffor_manager
        self._finished = False

    def __iter__(self):
        return self

    def __next__(self):
        if self._finished:
            raise StopIteration
        try:
            item = next(self._mgr)
        except StopIteration:
            self._finished = True
            raise
        return item

    @property
    def end_of_buffered(self):
        return self._finished","class AsynchronousResponseIterator:
    def __init__(self, response_buffor_manager):
        self._response_buffer_manager = response_buffor_manager
        self._index = 0
        self._current_buffer = []
        self._buffer_exhausted = False

    def __iter__(self):
        return self

    def __next__(self):
        if self._index >= len(self._current_buffer):
            if self._buffer_exhausted or self.end_of_buffered:
                raise StopIteration
            # Try to get more data from the buffer manager
            try:
                self._current_buffer = self._response_buffer_manager.get_next_chunk()
                self._index = 0
                if len(self._current_buffer) == 0:
                    self._buffer_exhausted = True
                    raise StopIteration
            except Exception:
                self._buffer_exhausted = True
                raise StopIteration
        
        if self._index < len(self._current_buffer):
            result = self._current_buffer[self._index]
            self._index += 1
            return result
        else:
            raise StopIteration

    @property
    def end_of_buffered(self):
        return self._response_buffer_manager.end_of_buffered if hasattr(self._response_buffer_manager, 'end_of_buffered') else True","class AsynchronousResponseIterator:
    def __init__(self, response_buffer_manager):
        self.response_buffer_manager = response_buffer_manager
        self.current_index = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.current_index >= len(self.response_buffer_manager.buffer):
            if self.response_buffer_manager.is_complete:
                raise StopIteration
            else:
                self.response_buffer_manager.wait_for_data()
                if self.current_index >= len(self.response_buffer_manager.buffer):
                    raise StopIteration
        
        item = self.response_buffer_manager.buffer[self.current_index]
        self.current_index += 1
        return item

    @property
    def end_of_buffered(self):
        return self.current_index >= len(self.response_buffer_manager.buffer)",no_docstr,0.46835443037974683,0.34615384615384615,0.27272727272727276,0.4556962025316456,0.2604701781623079,0.8679245283018868,0.6666666666666666,0.5961538461538461,0.8786300420761108,0.8377436399459839,0.8576998710632324,0.8416603207588196,0.81508700729927,0.6072874493927125,0.39999999999999997,0.2880658436213992,0.48582995951417,0.44284367950916725,0.6205673758865248,0.4306049822064057,0.325,0.8385927081108093,0.8699207305908203,0.8539694547653198,0.8666830062866211,0.839852625698324,0.6470588235294117,0.3861386138613861,0.23,0.588235294117647,0.5904481872158501,0.8282828282828283,0.6091370558375635,0.4897959183673469,0.9056887626647949,0.8778653740882874,0.8915600776672363,0.8805704712867737,0.8905120437956203,0.2761513300956177,0.2109432583599993,0.2368153626225807,0.358974358974359,0.2978723404255319,0.3955694454259483,0.149005164498515,0.2606048594311377,0.5769230769230769,0.5957446808510638,0.507384989157707,0.2660166515112462,0.2796171403623533,0.717948717948718,0.7659574468085106
176820,QualiSystems/vCenterShell,QualiSystems_vCenterShell/package/cloudshell/cp/vcenter/commands/vm_details.py,package.cloudshell.cp.vcenter.commands.vm_details.VmDetailsCommand,"class VmDetailsCommand(object):
    def __init__(self, pyvmomi_service, vm_details_provider):
        self.pyvmomi_service = pyvmomi_service
        self.vm_details_provider = vm_details_provider
        self.timeout = 30
        self.delay = 1

    def get_vm_details(self, si, logger, resource_context, requests, cancellation_context):
        results = []

        for request in requests:
            if cancellation_context.is_cancelled:
                break

            app_name = request.deployedAppJson.name

            try:
                vm = self.pyvmomi_service.find_by_uuid(si, request.deployedAppJson.vmdetails.uid)

                wait_for_ip = next((p.value for p in request.deployedAppJson.vmdetails.vmCustomParams if p.name == 'wait_for_ip'), 'False')

                self._wait_for_vm_to_be_ready(vm, request, logger)

                result = self.vm_details_provider.create(
                    vm=vm,
                    name=app_name,
                    reserved_networks=resource_context.attributes.get('Reserved Networks', '').split(';'),
                    ip_regex=next((p.value for p in request.deployedAppJson.vmdetails.vmCustomParams if p.name=='ip_regex'), None),
                    deployment_details_provider=DeploymentDetailsProviderFromAppJson(request.appRequestJson.deploymentService),
                    wait_for_ip=wait_for_ip,
                    logger=logger)

            except Exception as e:
                logger.error(""Error getting vm details for '{0}': {1}"".format(app_name, traceback.format_exc()))
                result = VmDetailsData(errorMessage=e.message)

            result.appName = app_name
            results.append(result)

        return results

    def _wait_for_vm_to_be_ready(self, vm, request, logger):
        start_time = time.time()
        while time.time()-start_time<self.timeout and (self._not_guest_net(vm) or self._no_guest_ip(vm, request)):
            time.sleep(self.delay)
        logger.info('_wait_for_vm_to_be_ready: '+str(time.time()-start_time)+' sec')

    @staticmethod
    def _not_guest_net(vm):
        return not vm.guest.net

    @staticmethod
    def _no_guest_ip(vm, request):
        wait_for_ip = next((p.value for p in request.deployedAppJson.vmdetails.vmCustomParams if p.name == 'wait_for_ip'), False)
        return wait_for_ip and not vm.guest.ipAddress","class VmDetailsCommand(object):


    def __init__(self, pyvmomi_service, vm_details_provider):
        pass

    def get_vm_details(self, si, logger, resource_context, requests, cancellation_context):
        pass

    def _wait_for_vm_to_be_ready(self, vm, request, logger):
        pass

    @staticmethod
    def _not_guest_net(vm):
        pass

    @staticmethod
    def _no_guest_ip(vm, request):
        pass

",8,0,snippet_99,0.1388888888888889,"class VmDetailsCommand(object):

    def __init__(self, pyvmomi_service, vm_details_provider):
        self.pyvmomi_service = pyvmomi_service
        self.vm_details_provider = vm_details_provider

    def get_vm_details(self, si, logger, resource_context, requests, cancellation_context):
        """"""
        Retrieves VM details for each request object in `requests`.
        Returns a list of detail dicts, one per request.
        """"""
        # Locate the VM by its managed object ID (moid)
        vm = self.pyvmomi_service.get_vm_by_moid(si, resource_context.resource_id)
        results = []
        for req in requests:
            # If the request wants to wait for an IP, block until ready
            if getattr(req, ""wait_for_ip"", False):
                self._wait_for_vm_to_be_ready(vm, req, logger)
            # Delegate to provider to fetch the actual details
            detail = self.vm_details_provider.get_vm_details(vm, req)
            results.append(detail)
        return results

    def _wait_for_vm_to_be_ready(self, vm, request, logger):
        """"""
        Polls the VM guest properties until it has network adapters
        and at least one IP of the requested type (if specified).
        """"""
        timeout = getattr(request, ""timeout_seconds"", 300)
        interval = getattr(request, ""poll_interval_seconds"", 5)
        start = time.time()
        while True:
            if cancellation_event := getattr(request, ""cancellation_event"", None):
                if cancellation_event.is_set():
                    raise Exception(""Operation cancelled while waiting for VM network readiness"")
            # Check for presence of guest.net and guest IPs
            if not self._not_guest_net(vm) and not self._no_guest_ip(vm, request):
                return
            elapsed = time.time() - start
            if elapsed >= timeout:
                raise Exception(f""Timeout ({timeout}s) waiting for VM '{vm.name}' network/IP readiness"")
            logger.info(
                f""Waiting for VM '{vm.name}' to report networks and IP (waited {int(elapsed)}s)...""
            )
            time.sleep(interval)

    @staticmethod
    def _not_guest_net(vm):
        """"""
        Returns True if vm.guest.net is empty or missing.
        """"""
        try:
            nets = vm.guest.net
        except AttributeError:
            return True
        return not bool(nets)

    @staticmethod
    def _no_guest_ip(vm, request):
        """"""
        Returns True if the VM has no guest IP matching the request criteria.
        If request.ip_type is set to 'ipv4' or 'ipv6', filters accordingly.
        """"""
        ip_type = getattr(request, ""ip_type"", None)
        try:
            nets = vm.guest.net or []
        except AttributeError:
            return True

        for net in nets:
            addrs = getattr(net, ""ipAddress"", None) or []
            for addr in addrs:
                if not addr:
                    continue
                if ip_type:
                    # crude check: IPv4 contains dots, IPv6 contains colons
                    if ip_type.lower() == ""ipv4"" and ""."" in addr:
                        return False
                    if ip_type.lower() == ""ipv6"" and "":"" in addr:
                        return False
                else:
                    return False
        return True","class VmDetailsCommand(object):
    def __init__(self, pyvmomi_service, vm_details_provider):
        self.pyvmomi_service = pyvmomi_service
        self.vm_details_provider = vm_details_provider

    def get_vm_details(self, si, logger, resource_context, requests, cancellation_context):
        results = []
        
        for request in requests:
            if cancellation_context.is_cancelled:
                break
                
            try:
                vm = self.pyvmomi_service.find_by_uuid(si, request.vm_uuid)
                if not vm:
                    results.append({""error"": f""VM with UUID {request.vm_uuid} not found""})
                    continue
                    
                # Wait for VM to be ready
                if not self._wait_for_vm_to_be_ready(vm, request, logger):
                    results.append({""error"": f""VM {request.vm_uuid} is not ready""})
                    continue
                
                # Get VM details
                vm_details = self.vm_details_provider.get_vm_details(vm, resource_context, request)
                results.append(vm_details)
                
            except Exception as e:
                logger.error(f""Error getting details for VM {request.vm_uuid}: {str(e)}"")
                results.append({""error"": str(e)})
                
        return results

    def _wait_for_vm_to_be_ready(self, vm, request, logger):
        # Check if VM is powered on
        if vm.runtime.powerState != 'poweredOn':
            return False
            
        # Check for guest networking
        if self._not_guest_net(vm):
            return False
            
        # Check for guest IP
        if self._no_guest_ip(vm, request):
            return False
            
        return True

    @staticmethod
    def _not_guest_net(vm):
        return not vm.guest.net

    @staticmethod
    def _no_guest_ip(vm, request):
        if not vm.guest.net:
            return True
            
        # Check if any interface has an IP
        for net in vm.guest.net:
            if net.ipConfig and net.ipConfig.ipAddress:
                return False
                
        return True","class VmDetailsCommand(object):

    def __init__(self, pyvmomi_service, vm_details_provider):
        self.pyvmomi_service = pyvmomi_service
        self.vm_details_provider = vm_details_provider

    def get_vm_details(self, si, logger, resource_context, requests, cancellation_context):
        results = []
        for request in requests:
            try:
                vm = self.pyvmomi_service.find_vm_by_name(si, request.vm_name)
                if vm is None:
                    results.append(None)
                    continue
                
                self._wait_for_vm_to_be_ready(vm, request, logger)
                
                if cancellation_context.is_cancelled:
                    break
                
                vm_details = self.vm_details_provider.get_vm_details(vm, request)
                results.append(vm_details)
                
            except Exception as e:
                logger.error(f""Error getting VM details for {request.vm_name}: {str(e)}"")
                results.append(None)
        
        return results

    def _wait_for_vm_to_be_ready(self, vm, request, logger):
        import time
        timeout = getattr(request, 'timeout', 300)
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if vm.runtime.powerState == 'poweredOn':
                if not self._not_guest_net(vm) and not self._no_guest_ip(vm, request):
                    return
            time.sleep(5)
        
        logger.warning(f""VM {vm.name} did not become ready within timeout period"")

    @staticmethod
    def _not_guest_net(vm):
        try:
            return vm.guest.net is None or len(vm.guest.net) == 0
        except:
            return True

    @staticmethod
    def _no_guest_ip(vm, request):
        try:
            if vm.guest.net:
                for net in vm.guest.net:
                    if net.ipAddress:
                        for ip in net.ipAddress:
                            if ip and not ip.startswith('169.254'):
                                return False
            return True
        except:
            return True",no_docstr,0.5283018867924528,0.31149927219796214,0.23065693430656936,0.386066763425254,0.38591652187576336,0.5710382513661202,0.35841313269493846,0.2808219178082192,0.8044966459274292,0.8222764730453491,0.8132894039154053,0.820463240146637,0.7138317985611508,0.599250936329588,0.45488721804511273,0.3886792452830189,0.5243445692883896,0.4474444372900291,0.7180616740088106,0.5584988962472406,0.497787610619469,0.8919826745986938,0.8122074604034424,0.8502278327941895,0.8195370435714722,0.7867668382352941,0.6628787878787878,0.4600760456273764,0.3740458015267175,0.5568181818181818,0.48073715469570316,0.8147321428571429,0.6174496644295302,0.5179372197309418,0.9000077843666077,0.8314850330352783,0.8643905520439148,0.8378642201423645,0.7769630147058825,0.305950153739378,0.1072184423979961,0.2631461873870039,0.4761904761904761,0.3772455089820359,0.3560420558372142,0.2980457385276829,0.3623642869312395,0.4523809523809524,0.311377245508982,0.3696694092519258,0.3025395128071687,0.3348207589310734,0.5,0.3413173652694611
624932,packethost/packet-python,packethost_packet-python/packet/Email.py,packet.Email.Email,"class Email:
    def __init__(self, data, manager):
        self.manager = manager

        self.id = data.get(""id"")
        self.address = data.get(""address"")
        self.default = data.get(""default"")
        self.verified = data.get(""verified"")

    def update(self):
        params = {""address"": self.address, ""default"": self.default}

        return self.manager.call_api(""emails/%s"" % self.id, type=""PATCH"", params=params)

    def delete(self):
        return self.manager.call_api(""emails/%s"" % self.id, type=""DELETE"")

    def __str__(self):
        return ""%s"" % self.address

    def __repr__(self):
        return ""{}: {}"".format(self.__class__.__name__, self.id)","class Email:


    def __init__(self, data, manager):
        pass

    def update(self):
        pass

    def delete(self):
        pass

    def __str__(self):
        pass

    def __repr__(self):
        pass

",6,0,snippet_296,1.0,"class Email:
    def __init__(self, data, manager):
        if not isinstance(data, dict):
            raise TypeError(""data must be a dict"")
        self._data = data.copy()
        self._manager = manager

    def update(self):
        """"""
        Send current data to the manager for updating.
        The manager.update(...) method is expected to return
        a dict of updated fields (or None).
        """"""
        result = self._manager.update(self._data)
        if isinstance(result, dict):
            self._data.update(result)
        return self

    def delete(self):
        """"""
        Tell the manager to delete this email.
        The manager.delete(...) method may return a status or None.
        """"""
        return self._manager.delete(self._data.get(""id""))

    def __str__(self):
        """"""
        A userfriendly representation, showing key fields.
        """"""
        eid = self._data.get(""id"", ""<no id>"")
        subj = self._data.get(""subject"", ""<no subject>"")
        return f""<Email id={eid} subject={subj!r}>""

    def __repr__(self):
        """"""
        An unambiguous representation, suitable for debugging.
        """"""
        return f""Email(data={self._data!r})""","class Email:
    def __init__(self, data, manager):
        self.data = data
        self.manager = manager
        self.id = data.get('id')
        self.sender = data.get('sender')
        self.recipient = data.get('recipient')
        self.subject = data.get('subject')
        self.body = data.get('body')
        self.timestamp = data.get('timestamp')
        self.is_read = data.get('is_read', False)

    def update(self):
        if self.manager and self.id:
            self.manager.update_email(self.id, self.data)

    def delete(self):
        if self.manager and self.id:
            self.manager.delete_email(self.id)
            self.id = None

    def __str__(self):
        return f""Email from {self.sender} to {self.recipient}: {self.subject}""

    def __repr__(self):
        return f""Email(id={self.id}, sender='{self.sender}', recipient='{self.recipient}', subject='{self.subject}')""","class Email:
    def __init__(self, data, manager):
        self.data = data
        self.manager = manager
        self.id = data.get('id')
        self.subject = data.get('subject', '')
        self.sender = data.get('sender', '')
        self.recipient = data.get('recipient', '')
        self.body = data.get('body', '')
        self.timestamp = data.get('timestamp')
        self.read = data.get('read', False)

    def update(self):
        if self.manager and hasattr(self.manager, 'update_email'):
            self.manager.update_email(self)
        else:
            for key, value in self.__dict__.items():
                if key not in ['manager', 'data']:
                    self.data[key] = value

    def delete(self):
        if self.manager and hasattr(self.manager, 'delete_email'):
            self.manager.delete_email(self)

    def __str__(self):
        return f""From: {self.sender}\nTo: {self.recipient}\nSubject: {self.subject}\n\n{self.body}""

    def __repr__(self):
        return f""Email(id={self.id}, subject='{self.subject}', sender='{self.sender}', recipient='{self.recipient}')""",no_docstr,0.43859649122807015,0.21238938053097342,0.10714285714285714,0.32456140350877194,0.3207156080329016,0.5463258785942492,0.2980769230769231,0.20257234726688103,0.7238894701004028,0.798587441444397,0.7594060301780701,0.7904309630393982,0.7638912500000004,0.5247524752475247,0.33,0.1919191919191919,0.5148514851485149,0.4335509538434707,0.5905511811023622,0.4189723320158103,0.32936507936507936,0.8298288583755493,0.8338736295700073,0.831846296787262,0.833467423915863,0.831207361702128,0.47058823529411764,0.2831050228310502,0.17511520737327188,0.4524886877828054,0.3511072367870076,0.4919093851132686,0.33766233766233766,0.26058631921824105,0.7736028432846069,0.8106986284255981,0.791716456413269,0.8068297505378723,0.8093626369863021,0.2576522057706037,0.0645465943208639,0.1552730179723405,0.4835164835164835,0.3272727272727272,0.4547752404006007,0.1714157382645285,0.2323006079532588,0.6153846153846154,0.8,0.3968863608882962,0.1398602202153106,0.2323006079532588,0.6153846153846154,0.6
599071,nikoladimitroff/Adder,nikoladimitroff_Adder/adder/logic.py,adder.logic.DefiniteClause,"class DefiniteClause:
    ReplacementIndex = 0

    def __init__(self, text):
        self.premises, self.conclusion = self.__parse(text)
        self.is_fact = len(self.premises) == 0

    def __parse(self, text):
        if LogicOperator.Implication in text:
            lhs, rhs = text.split(LogicOperator.Implication)

            premises = [symbol.strip() for symbol in
                        lhs.split(LogicOperator.Conjuction)]
            conclusions = [rhs.strip()]
        else:
            symbols = [symbol.strip() for symbol in
                       text.split(LogicOperator.Disjunction)]

            premises = [symbol[1:] for symbol in symbols
                        if symbol[0] == LogicOperator.Negation]
            conclusions = [symbol for symbol in symbols
                           if symbol[0] != LogicOperator.Negation]
        if len(conclusions) != 1:
            msg = ""A clause must have EXACTLY one positive symbol""
            raise utils.InvalidArgumentError(msg)

        return (premises, conclusions[0])

    def standardize(self, var=""x""):
        replacer = StandartizationReplacer(var)
        for index, premise in enumerate(self.premises):
            self.premises[index] = re.sub(replacer.REGEX, replacer, premise)
        self.conclusion = re.sub(replacer.REGEX, replacer, self.conclusion)

        StandartizationReplacer.GlobalIndex = replacer.index

    def __str__(self):
        return ""{0} => {1}"".format("" & "".join(self.premises), self.conclusion)

    __repr__ = __str__","class DefiniteClause:


    def __init__(self, text):
        pass

    def __parse(self, text):
        pass

    def standardize(self, var=""x""):
        pass

    def __str__(self):
        pass

",5,0,snippet_104,0.1363636363636363,"class DefiniteClause:
    def __init__(self, text):
        self.text = text.strip()
        self.head, self.body = self.__parse(self.text)

    def __parse(self, text):
        t = text.strip()
        if t.endswith('.'):
            t = t[:-1].strip()
        if ':-' in t:
            head_str, body_str = t.split(':-', 1)
            body_preds = [p.strip() for p in body_str.split(',')]
        else:
            head_str = t
            body_preds = []
        def parse_pred(p):
            if '(' in p and p.endswith(')'):
                name = p[:p.index('(')].strip()
                args_str = p[p.index('(')+1:-1]
                args = [arg.strip() for arg in args_str.split(',') if arg.strip()]
            else:
                name = p.strip()
                args = []
            return (name, args)
        head = parse_pred(head_str.strip())
        body = [parse_pred(p) for p in body_preds]
        return head, body

    def standardize(self, var=""x""):
        mapping = {}
        counter = [1]
        def rename_term(arg):
            if arg and arg[0].isupper():
                if arg not in mapping:
                    mapping[arg] = f""{var}{counter[0]}""
                    counter[0] += 1
                return mapping[arg]
            return arg
        new_head = (self.head[0], [rename_term(a) for a in self.head[1]])
        new_body = []
        for name, args in self.body:
            new_body.append((name, [rename_term(a) for a in args]))
        def pred_to_str(pred):
            name, args = pred
            if args:
                return f""{name}({', '.join(args)})""
            return name
        head_str = pred_to_str(new_head)
        if new_body:
            body_strs = [pred_to_str(p) for p in new_body]
            clause_str = f""{head_str} :- {', '.join(body_strs)}.""
        else:
            clause_str = f""{head_str}.""
        return DefiniteClause(clause_str)

    def __str__(self):
        def pred_to_str(pred):
            name, args = pred
            if args:
                return f""{name}({', '.join(args)})""
            return name
        head_str = pred_to_str(self.head)
        if self.body:
            body_strs = [pred_to_str(p) for p in self.body]
            return f""{head_str} :- {', '.join(body_strs)}.""
        return f""{head_str}.""","class DefiniteClause:
    def __init__(self, text):
        self.head, self.body = self.__parse(text)
    
    def __parse(self, text):
        if "":-"" in text:
            head, body_text = text.split("":-"")
            head = head.strip()
            body_literals = [lit.strip() for lit in body_text.strip().rstrip('.').split(',')]
            return head, body_literals
        else:
            head = text.strip().rstrip('.')
            return head, []
    
    def standardize(self, var=""x""):
        # Replace all variables (assumed to be single lowercase letters) with the given variable
        def replace_vars(term):
            result = """"
            i = 0
            while i < len(term):
                if term[i].islower() and (i == 0 or not term[i-1].isalpha()) and (i == len(term)-1 or not term[i+1].isalpha()):
                    result += var
                else:
                    result += term[i]
                i += 1
            return result
        
        new_head = replace_vars(self.head)
        new_body = [replace_vars(literal) for literal in self.body]
        return DefiniteClause(new_head + "" :- "" + "", "".join(new_body) + ""."" if new_body else new_head + ""."")
    
    def __str__(self):
        if self.body:
            return self.head + "" :- "" + "", "".join(self.body) + "".""
        else:
            return self.head + "".""","class DefiniteClause:
    def __init__(self, text):
        self.original_text = text.strip()
        self.head = None
        self.body = []
        self.__parse(text)

    def __parse(self, text):
        text = text.strip()
        if text.endswith('.'):
            text = text[:-1]
        
        if ':-' in text:
            parts = text.split(':-', 1)
            self.head = parts[0].strip()
            body_text = parts[1].strip()
            if body_text:
                self.body = [term.strip() for term in body_text.split(',')]
        else:
            self.head = text
            self.body = []

    def standardize(self, var=""x""):
        var_counter = 0
        var_mapping = {}
        
        def replace_vars(term):
            nonlocal var_counter
            pattern = r'\b[A-Z][a-zA-Z0-9_]*\b'
            
            def replace_match(match):
                nonlocal var_counter
                old_var = match.group(0)
                if old_var not in var_mapping:
                    var_mapping[old_var] = f""{var}{var_counter}""
                    var_counter += 1
                return var_mapping[old_var]
            
            return re.sub(pattern, replace_match, term)
        
        new_head = replace_vars(self.head) if self.head else None
        new_body = [replace_vars(term) for term in self.body]
        
        standardized_clause = DefiniteClause("""")
        standardized_clause.head = new_head
        standardized_clause.body = new_body
        
        return standardized_clause

    def __str__(self):
        if not self.body:
            return f""{self.head}.""
        else:
            body_str = "", "".join(self.body)
            return f""{self.head} :- {body_str}.""",no_docstr,0.3185840707964602,0.08444444444444443,0.04017857142857143,0.21681415929203537,0.1870769340850416,0.3588235294117647,0.17673048600883653,0.10324483775811209,0.7459350824356079,0.7405397295951843,0.7432276606559753,0.7410757541656494,0.7488034712230222,0.3682539682539683,0.134185303514377,0.0707395498392283,0.273015873015873,0.3084985874208851,0.5591397849462365,0.2857142857142857,0.1837837837837838,0.760055661201477,0.7333570122718811,0.7464675903320312,0.7359421253204346,0.7416692500000003,0.36827195467422097,0.13105413105413102,0.05730659025787965,0.2606232294617564,0.2967868402018293,0.5484633569739953,0.27488151658767773,0.17339667458432304,0.7557603120803833,0.738705039024353,0.74713534116745,0.740375816822052,0.7572163582089556,0.3872019058920674,0.0151827466078667,0.0303136186822572,0.5033112582781457,0.0,0.2243903911412856,0.0473930148923839,0.0613858033796096,0.4701986754966887,0.3185840707964602,0.3814655339947788,0.0250160635903728,0.0306473968920536,0.4701986754966887,0.0
135492,JdeRobot/base,src/libs/parallelIce_py/parallelIce/bumperClient.py,parallelIce.bumperClient.BumperClient,"class BumperClient:
    def __init__(self,ic,prefix, start = False):
        self.bumper = Bumper(ic,prefix)

        self.kill_event = threading.Event()
        self.thread = ThreadSensor(self.bumper, self.kill_event)
        self.thread.daemon = True

        if start:
            self.start()

    # if client is stopped you can not start again, Threading.Thread raised error
    def start(self):
        self.kill_event.clear()
        self.thread.start()

    # if client is stopped you can not start again
    def stop(self):
        self.kill_event.set()

    def getBumperData(self):
        return self.bumper.getBumper()","class BumperClient:


    def __init__(self,ic,prefix, start = False):
        pass

    def start(self):
        pass

    def stop(self):
        pass

    def getBumperData(self):
        pass

",5,0,snippet_107,0.2857142857142857,"class BumperClient:
    def __init__(self, ic, prefix, start=False):
        self._ic = ic
        self._topic = f""{prefix}/bumper""
        self._sub = None
        self._lock = threading.Lock()
        self._data = None
        if start:
            self.start()

    def start(self):
        if self._sub is None:
            # ic.subscribe should return a handle with an unsubscribe() method
            self._sub = self._ic.subscribe(self._topic, self._on_message)

    def stop(self):
        if self._sub is not None:
            try:
                self._sub.unsubscribe()
            except AttributeError:
                # fallback if unsubscribe is on the ic itself
                self._ic.unsubscribe(self._sub)
            finally:
                self._sub = None

    def _on_message(self, msg):
        with self._lock:
            self._data = msg

    def getBumperData(self):
        with self._lock:
            return self._data","class BumperClient:
    def __init__(self, ic, prefix, start=False):
        self.ic = ic
        self.prefix = prefix
        self.bumper_data = None
        self.running = False
        
        if start:
            self.start()

    def start(self):
        if not self.running:
            # Simulate starting the bumper client
            self.running = True
            # In a real implementation, this would connect to hardware or simulation
            self.bumper_data = {""left"": False, ""right"": False, ""front"": False}

    def stop(self):
        if self.running:
            self.running = False
            self.bumper_data = None

    def getBumperData(self):
        if self.running and self.bumper_data is not None:
            return self.bumper_data
        else:
            return {""left"": False, ""right"": False, ""front"": False}","class BumperClient:
    def __init__(self, ic, prefix, start=False):
        self.ic = ic
        self.prefix = prefix
        self.proxy = None
        self.bumper_data = None
        self.running = False
        
        if start:
            self.start()

    def start(self):
        if not self.running:
            try:
                proxy_string = self.prefix + "".Proxy""
                base = self.ic.stringToProxy(proxy_string)
                self.proxy = base.checkedCast(Ice.ObjectPrx)
                self.running = True
                self.bumper_data = {""left"": False, ""right"": False, ""front"": False, ""back"": False}
            except Exception as e:
                self.running = False
                raise e

    def stop(self):
        if self.running:
            self.proxy = None
            self.running = False
            self.bumper_data = None

    def getBumperData(self):
        if self.running and self.proxy:
            try:
                # Simulate getting bumper data from the proxy
                return self.bumper_data
            except Exception as e:
                return None
        return None",no_docstr,0.4375,0.2105263157894737,0.13829787234042554,0.3645833333333333,0.32637433898020035,0.4954545454545455,0.3059360730593607,0.22935779816513763,0.7644487619400024,0.8186925649642944,0.7906413674354553,0.8129241466522217,0.8111772254335261,0.5111111111111112,0.25842696629213485,0.17045454545454547,0.37777777777777777,0.35862480655451817,0.5271739130434783,0.33879781420765026,0.25824175824175827,0.8157966136932373,0.8154863119125366,0.815641462802887,0.8155173659324646,0.7770585064935065,0.4236453201970444,0.22885572139303478,0.15075376884422112,0.3448275862068966,0.30864570160789384,0.452914798206278,0.2927927927927928,0.22171945701357465,0.7551953792572021,0.7889679670333862,0.7717123627662659,0.7854553461074829,0.7666689999999999,0.2600687749556652,0.0294851233288737,0.0482899764937872,0.6875,0.275,0.2110327527117525,0.0307060107458529,0.0509250001011573,0.4375,0.325,0.2097509778320766,0.0245088407331856,0.048870070595121,0.515625,0.25
522854,jshiv/turntable,jshiv_turntable/test/lib/python2.7/site-packages/numpy/core/_internal.py,numpy.core._internal._missing_ctypes,"class _missing_ctypes(object):
    def cast(self, num, obj):
        return num

    def c_void_p(self, num):
        return num","class _missing_ctypes(object):


    def cast(self, num, obj):
        pass

    def c_void_p(self, num):
        pass

",3,0,snippet_731,1.0,"class _missing_ctypes(object):

    def cast(self, num, obj):
        raise ImportError(""ctypes.cast is not available because the ctypes module could not be imported"")

    def c_void_p(self, num):
        raise ImportError(""ctypes.c_void_p is not available because the ctypes module could not be imported"")","class _missing_ctypes(object):
    def cast(self, num, obj):
        return num

    def c_void_p(self, num):
        return num","class _missing_ctypes(object):
    def cast(self, num, obj):
        return obj
    
    def c_void_p(self, num):
        return num",no_docstr,0.4545454545454545,0.40625,0.3548387096774193,0.4545454545454545,0.39943019865882023,0.42105263157894735,0.4,0.3783783783783784,0.7766647338867188,0.9165430665016174,0.8408260941505432,0.9003280401229858,0.866668,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9473684210526315,0.8888888888888888,0.8235294117647058,0.9473684210526315,0.9419577102036562,0.9722222222222222,0.9428571428571428,0.9117647058823529,0.9859925508499146,0.9873143434524536,0.9866529703140259,0.987182080745697,1.0,0.3891485677919776,0.1655980552565983,0.4743295492446456,0.25,0.6666666666666666,1.0,1.0,1.0,1.0,1.0,0.8412720778870645,0.7611606003349892,0.7705943778799352,1.0,0.8333333333333334
149599,ManiacalLabs/BiblioPixelAnimations,ManiacalLabs_BiblioPixelAnimations/BiblioPixelAnimations/matrix/spectrum/system_eq.py,BiblioPixelAnimations.matrix.spectrum.system_eq.Recorder,"class Recorder:
    def __init__(self, rate=8000, chunksize=128):
        self.rate = rate
        self.chunksize = chunksize
        self.p = pyaudio.PyAudio()
        self.stream = self.p.open(format=pyaudio.paInt16,
                                  channels=1,
                                  rate=self.rate,
                                  input=True,
                                  frames_per_buffer=self.chunksize,
                                  stream_callback=self.new_frame)
        self.lock = threading.Lock()
        self.stop = False
        self.frames = []

    def new_frame(self, data, frame_count, time_info, status):
        data = np.fromstring(data, 'int16')
        with self.lock:
            self.frames.append(data)
            if self.stop:
                return None, pyaudio.paComplete
        return None, pyaudio.paContinue

    def get_frames(self):
        with self.lock:
            frames = self.frames
            self.frames = []
            return frames

    def start(self):
        self.stream.start_stream()

    def close(self):
        with self.lock:
            self.stop = True
        self.stream.close()
        self.p.terminate()","class Recorder:


    def __init__(self, rate=8000, chunksize=128):
        pass

    def new_frame(self, data, frame_count, time_info, status):
        pass

    def get_frames(self):
        pass

    def start(self):
        pass

    def close(self):
        pass

",6,0,snippet_561,0.25,"class Recorder:
    def __init__(self, rate=8000, chunksize=128):
        self.rate = rate
        self.chunksize = chunksize
        self.frames = []
        self.pa = None
        self.stream = None

    def new_frame(self, data, frame_count, time_info, status):
        # data is bytes
        self.frames.append(data)
        return (None, pyaudio.paContinue)

    def get_frames(self):
        return b''.join(self.frames)

    def start(self):
        if self.stream is not None:
            return
        self.pa = pyaudio.PyAudio()
        self.stream = self.pa.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunksize,
            stream_callback=self.new_frame
        )
        self.stream.start_stream()

    def close(self):
        if self.stream is not None:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
        if self.pa is not None:
            self.pa.terminate()
            self.pa = None","class Recorder:
    def __init__(self, rate=8000, chunksize=128):
        self.rate = rate
        self.chunksize = chunksize
        self.frames = []
        self.p = pyaudio.PyAudio()
        self.stream = None
        self.recording = False
        self.lock = threading.Lock()

    def new_frame(self, data, frame_count, time_info, status):
        with self.lock:
            if self.recording:
                self.frames.append(data)
        return (data, pyaudio.paContinue)

    def get_frames(self):
        with self.lock:
            return self.frames.copy()

    def start(self):
        if not self.recording:
            self.frames = []
            self.stream = self.p.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunksize,
                stream_callback=self.new_frame
            )
            self.recording = True
            self.stream.start_stream()

    def close(self):
        if self.recording and self.stream:
            self.recording = False
            self.stream.stop_stream()
            self.stream.close()
        self.p.terminate()","class Recorder:
    def __init__(self, rate=8000, chunksize=128):
        self.rate = rate
        self.chunksize = chunksize
        self.frames = []
        self.pa = pyaudio.PyAudio()
        self.stream = None
        self.lock = threading.Lock()

    def new_frame(self, data, frame_count, time_info, status):
        with self.lock:
            self.frames.append(data)
        return (data, pyaudio.paContinue)

    def get_frames(self):
        with self.lock:
            return self.frames.copy()

    def start(self):
        self.stream = self.pa.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunksize,
            stream_callback=self.new_frame
        )
        self.stream.start_stream()

    def close(self):
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        self.pa.terminate()",no_docstr,0.7791164658634538,0.6153846153846154,0.5306122448979592,0.5140562248995983,0.7366259217396555,0.8600823045267489,0.7272727272727273,0.6390041493775933,0.8786590099334717,0.8763641119003296,0.8775100111961365,0.8765931129455566,0.780742933333334,0.8605577689243028,0.7228915662650603,0.5991902834008098,0.5976095617529881,0.8033070091530263,0.875968992248062,0.8015564202334631,0.73828125,0.905888020992279,0.9179543852806091,0.9118812680244446,0.9167332649230957,0.7948738461538467,0.8695652173913043,0.719298245614035,0.6194690265486726,0.6173913043478262,0.787271265990887,0.9414414414414415,0.8597285067873304,0.7909090909090909,0.9110788106918335,0.8915811777114868,0.9012245535850525,0.8934933543205261,0.8044464,0.459762297766391,0.3060902476639602,0.329611262865975,0.6504065040650406,0.5529411764705883,0.5225883634606394,0.3896457804455902,0.4160591798532082,0.7317073170731707,0.5529411764705883,0.4911074376984927,0.3611951683596139,0.3746358258585562,0.6991869918699187,0.5294117647058824
560459,marrow/mailer,marrow_mailer/marrow/mailer/manager/dynamic.py,marrow.mailer.manager.dynamic.WorkItem,"class WorkItem(object):
    __slots__ = ('future', 'fn', 'args', 'kwargs')

    def __init__(self, future, fn, args, kwargs):
        self.future = future
        self.fn = fn
        self.args = args
        self.kwargs = kwargs

    def run(self):
        if not self.future.set_running_or_notify_cancel():
            return

        try:
            result = self.fn(*self.args, **self.kwargs)

        except:
            e = sys.exc_info()[1]
            self.future.set_exception(e)

        else:
            self.future.set_result(result)","class WorkItem(object):


    def __init__(self, future, fn, args, kwargs):
        pass

    def run(self):
        pass

",3,0,snippet_249,0.6,"class WorkItem(object):
    def __init__(self, future, fn, args, kwargs):
        self.future = future
        self.fn = fn
        self.args = args
        self.kwargs = kwargs

    def run(self):
        if not self.future.set_running_or_notify_cancel():
            return
        try:
            result = self.fn(*self.args, **self.kwargs)
        except BaseException as exc:
            self.future.set_exception(exc)
        else:
            self.future.set_result(result)","class WorkItem(object):
    def __init__(self, future, fn, args, kwargs):
        self.future = future
        self.fn = fn
        self.args = args
        self.kwargs = kwargs

    def run(self):
        if not self.future.set_running_or_notify_cancel():
            return
        
        try:
            result = self.fn(*self.args, **self.kwargs)
            self.future.set_result(result)
        except Exception as exc:
            self.future.set_exception(exc)","class WorkItem(object):
    def __init__(self, future, fn, args, kwargs):
        self.future = future
        self.fn = fn
        self.args = args
        self.kwargs = kwargs

    def run(self):
        if not self.future.set_running_or_notify_cancel():
            return
        
        try:
            result = self.fn(*self.args, **self.kwargs)
        except BaseException as exc:
            self.future.set_exception(exc)
        else:
            self.future.set_result(result)",no_docstr,0.894308943089431,0.8264462809917354,0.773109243697479,0.894308943089431,0.7593538831829717,0.9741379310344828,0.9304347826086956,0.9035087719298246,0.965395450592041,0.9505976438522339,0.9579393863677979,0.9520570635795593,0.9200008000000001,0.8852459016393444,0.7999999999999999,0.7457627118644068,0.819672131147541,0.7399076021372264,0.9736842105263158,0.9292035398230089,0.8928571428571429,0.9713635444641113,0.9495232701301575,0.9603192806243896,0.951663076877594,0.89600104,0.894308943089431,0.8264462809917354,0.773109243697479,0.894308943089431,0.7593538831829717,0.9741379310344828,0.9304347826086956,0.9035087719298246,0.9674314856529236,0.9529199600219727,0.9601208567619324,0.9543514251708984,0.9200008000000001,0.5664761479147714,0.6758204003915217,0.6987642486563731,0.7205882352941176,0.1707317073170731,0.5535955032515645,0.6626659484331807,0.6898078866677686,0.6911764705882353,0.1707317073170731,0.5664761479147714,0.6758204003915217,0.6987642486563731,0.7205882352941176,0.1707317073170731
735345,sergei-maertens/django-systemjs,sergei-maertens_django-systemjs/systemjs/management/commands/_mixins.py,systemjs.management.commands._mixins.BundleOptionsMixin,"class BundleOptionsMixin(object):

    def add_arguments(self, parser):
        super(BundleOptionsMixin, self).add_arguments(parser)

        parser.add_argument(
            '--sfx',
            action='store_true', dest='sfx',
            help=""Generate self-executing bundles."")

        parser.add_argument('--node-path', help='Path to the project `node_modules` directory')
        parser.add_argument('--minify', action='store_true', help='Let jspm minify the bundle')
        parser.add_argument('--minimal', action='store_true', help='Only (re)bundle if changes detected')
        parser.add_argument('--skip-source-maps', action='store_true', help='Skip source maps generation')

    def get_system_opts(self, options):
        system_options = ['minimal', 'minify', 'sfx', 'skip_source_maps']
        return {opt: options.get(opt) for opt in system_options}","class BundleOptionsMixin(object):


    def add_arguments(self, parser):
        pass

    def get_system_opts(self, options):
        pass

",3,0,snippet_451,1.0,"class BundleOptionsMixin(object):

    def add_arguments(self, parser):
        parser.add_argument(
            '-o', '--output-dir',
            dest='output_dir',
            default=os.getcwd(),
            help='Directory in which to place the bundle'
        )
        parser.add_argument(
            '-f', '--format',
            dest='format',
            choices=['zip', 'tar', 'gztar', 'bztar', 'xztar'],
            default='gztar',
            help='Bundle archive format'
        )
        parser.add_argument(
            '--force',
            action='store_true',
            dest='force',
            help='Overwrite existing bundles'
        )
        parser.add_argument(
            '-v', '--verbose',
            action='store_true',
            dest='verbose',
            help='Enable verbose output'
        )

    def get_system_opts(self, options):
        return {
            'output_dir': options.output_dir,
            'format':     options.format,
            'force':      options.force,
            'verbose':    options.verbose,
        }","class BundleOptionsMixin(object):

    def add_arguments(self, parser):
        parser.add_argument(
            '--system',
            action='store_true',
            help='Include system packages in the bundle'
        )
        parser.add_argument(
            '--no-system',
            action='store_true',
            help='Exclude system packages from the bundle'
        )
        parser.add_argument(
            '--compress',
            action='store_true',
            help='Compress the bundle'
        )
        parser.add_argument(
            '--format',
            choices=['tar', 'zip', 'dir'],
            default='tar',
            help='Bundle format (default: tar)'
        )

    def get_system_opts(self, options):
        if options.system and options.no_system:
            raise ValueError(""Cannot specify both --system and --no-system"")
        return {
            'include_system': options.system,
            'exclude_system': options.no_system,
            'compress': getattr(options, 'compress', False),
            'format': getattr(options, 'format', 'tar')
        }","class BundleOptionsMixin(object):
    def add_arguments(self, parser):
        parser.add_argument(
            '--bundle-dir',
            dest='bundle_dir',
            help='Directory to store bundle files'
        )
        parser.add_argument(
            '--bundle-format',
            dest='bundle_format',
            choices=['tar', 'zip', 'tar.gz', 'tar.bz2'],
            default='tar.gz',
            help='Bundle format (default: tar.gz)'
        )
        parser.add_argument(
            '--bundle-name',
            dest='bundle_name',
            help='Name of the bundle file'
        )
        parser.add_argument(
            '--include-dependencies',
            dest='include_dependencies',
            action='store_true',
            help='Include dependencies in bundle'
        )
        parser.add_argument(
            '--exclude-patterns',
            dest='exclude_patterns',
            nargs='*',
            help='Patterns to exclude from bundle'
        )

    def get_system_opts(self, options):
        system_opts = {}
        
        if hasattr(options, 'bundle_dir') and options.bundle_dir:
            system_opts['bundle_dir'] = options.bundle_dir
            
        if hasattr(options, 'bundle_format') and options.bundle_format:
            system_opts['bundle_format'] = options.bundle_format
            
        if hasattr(options, 'bundle_name') and options.bundle_name:
            system_opts['bundle_name'] = options.bundle_name
            
        if hasattr(options, 'include_dependencies'):
            system_opts['include_dependencies'] = options.include_dependencies
            
        if hasattr(options, 'exclude_patterns') and options.exclude_patterns:
            system_opts['exclude_patterns'] = options.exclude_patterns
            
        return system_opts",no_docstr,0.47761194029850745,0.29145728643216084,0.21319796954314724,0.42786069651741293,0.4388633521953606,0.6428571428571429,0.43646408839779005,0.35555555555555557,0.7684789299964905,0.7946745157241821,0.7813571691513062,0.7919748425483704,0.8416682499999999,0.48341232227488146,0.33492822966507174,0.2222222222222222,0.46445497630331756,0.47622214971318144,0.6735751295336787,0.4375,0.36649214659685864,0.7958277463912964,0.8155274391174316,0.8055571913719177,0.8135136961936951,0.836008770053476,0.36619718309859156,0.20567375886524825,0.14285714285714285,0.323943661971831,0.27110226795380354,0.4108761329305136,0.24545454545454545,0.19756838905775076,0.7796124815940857,0.8195876479148865,0.7991004586219788,0.8154066205024719,0.8162118835616439,0.3251114343305483,0.0842422180432067,0.1044086474841147,0.5733333333333334,0.5384615384615384,0.3568797686326826,0.0758207447045869,0.1086214067492205,0.6533333333333333,0.5897435897435898,0.389959533262454,0.0529108384949264,0.1079529355805304,0.7066666666666667,0.6923076923076923
370967,ethereum/vyper,ethereum_vyper/vyper/codegen/module.py,vyper.codegen.module.IDGenerator,"class IDGenerator:
    def __init__(self):
        self._id = 0

    def ensure_id(self, fn_t):
        if fn_t._function_id is None:
            fn_t._function_id = self._id
            self._id += 1","class IDGenerator:


    def __init__(self):
        pass

    def ensure_id(self, fn_t):
        pass

",3,0,snippet_646,0.6,"class IDGenerator:
    def __init__(self):
        self._ids = {}
        self._next_id = 0

    def ensure_id(self, fn_t):
        if fn_t not in self._ids:
            self._ids[fn_t] = self._next_id
            self._next_id += 1
        return self._ids[fn_t]","class IDGenerator:
    def __init__(self):
        self._id_counter = 0
        self._id_map = {}

    def ensure_id(self, fn_t):
        if fn_t not in self._id_map:
            self._id_map[fn_t] = self._id_counter
            self._id_counter += 1
        return self._id_map[fn_t]","class IDGenerator:
    def __init__(self):
        self._id_counter = 0
        self._function_ids = {}

    def ensure_id(self, fn_t):
        if fn_t not in self._function_ids:
            self._function_ids[fn_t] = self._id_counter
            self._id_counter += 1
        return self._function_ids[fn_t]",no_docstr,0.6857142857142857,0.5294117647058824,0.3939393939393939,0.6857142857142857,0.5764171399756868,0.6666666666666666,0.5813953488372093,0.49411764705882355,0.8957757353782654,0.9159188270568848,0.9057353138923645,0.9138638973236084,0.9047628571428571,0.7027027027027029,0.4722222222222222,0.34285714285714286,0.6756756756756758,0.5043746702437992,0.631578947368421,0.5106382978723404,0.3978494623655914,0.8833421468734741,0.9111554622650146,0.8970332741737366,0.9082955718040466,0.9047628571428571,0.7027027027027029,0.4722222222222222,0.34285714285714286,0.6756756756756758,0.5290827083328193,0.631578947368421,0.5319148936170213,0.44086021505376344,0.9059615135192871,0.9263699650764465,0.9160521030426025,0.9242877960205078,0.9047628571428571,0.3913557528355641,0.2974309561779646,0.4051158009836899,0.4782608695652174,0.3846153846153846,0.4414555420148126,0.2194409743742214,0.2988895548890423,0.4782608695652174,0.7692307692307693,0.4414555420148126,0.2194409743742214,0.2988895548890423,0.4782608695652174,0.7692307692307693
560467,marrow/mailer,marrow_mailer/marrow/mailer/transport/ses.py,marrow.mailer.transport.ses.AmazonTransport,"class AmazonTransport(object):  # pragma: no cover
    __slots__ = ('ephemeral', 'config', 'region', 'connection')

    def __init__(self, config):
        # Give our configuration aliases their proper names.
        config['aws_access_key_id'] = config.pop('id')
        config['aws_secret_access_key'] = config.pop('key')

        self.region = config.pop('region', ""us-east-1"")
        # boto throws an error if we leave this in the next line
        config.pop('use')
        config.pop('debug')
        # All other configuration directives are passed to connect_to_region.
        self.config = config
        self.connection = None

    def startup(self):
        self.connection = boto3.client('ses', region_name=self.region, **self.config)

    def deliver(self, message):
        try:
            destinations = [str(r) for r in message.recipients]
            response = self.connection.send_raw_email(
                RawMessage = {'Data': str(message)},
                Source = str(message.author),
                Destinations = destinations,
            )

            return (
                response.get('MessageId', 'messageId NOT FOUND'),
                response.get('RequestId', {}).get('ResponseMetadata')
            )

        except ClientError as e:
            raise  # TODO: Raise appropriate internal exception.
            # ['status', 'reason', 'body', 'request_id', 'error_code', 'error_message']

    def shutdown(self):
        # if self.connection:
        #     self.connection.close()

        self.connection = None","class AmazonTransport(object):


    def __init__(self, config):
        pass

    def startup(self):
        pass

    def deliver(self, message):
        pass

    def shutdown(self):
        pass

",5,0,snippet_241,0.3333333333333333,"class AmazonTransport(object):
    def __init__(self, config):
        """"""
        config: {
            ""service"": ""sqs"" or ""sns"",
            ""region_name"": ""..."",
            ""aws_access_key_id"": ""..."",
            ""aws_secret_access_key"": ""..."",
            ""aws_session_token"": ""..."",  # optional
            ""queue_url"": ""..."",          # for sqs
            ""topic_arn"": ""...""           # for sns
        }
        """"""
        self.config = config
        self.client = None
        self.service = config.get(""service"", ""sqs"").lower()
        if self.service not in (""sqs"", ""sns""):
            raise ValueError(""Unsupported service: %s"" % self.service)

    def startup(self):
        params = {
            ""region_name"": self.config.get(""region_name""),
            ""aws_access_key_id"": self.config.get(""aws_access_key_id""),
            ""aws_secret_access_key"": self.config.get(""aws_secret_access_key""),
        }
        token = self.config.get(""aws_session_token"")
        if token:
            params[""aws_session_token""] = token
        if self.service == ""sqs"":
            self.client = boto3.client(""sqs"", **params)
            if not self.config.get(""queue_url""):
                raise ValueError(""queue_url is required for SQS"")
        else:
            self.client = boto3.client(""sns"", **params)
            if not self.config.get(""topic_arn""):
                raise ValueError(""topic_arn is required for SNS"")

    def deliver(self, message):
        if not self.client:
            raise RuntimeError(""Client not initialized. Call startup() first."")
        try:
            if self.service == ""sqs"":
                resp = self.client.send_message(
                    QueueUrl=self.config[""queue_url""],
                    MessageBody=message
                )
            else:
                resp = self.client.publish(
                    TopicArn=self.config[""topic_arn""],
                    Message=message
                )
            return resp
        except (BotoCoreError, ClientError) as e:
            raise RuntimeError(""Failed to deliver message: %s"" % e)

    def shutdown(self):
        # boto3 clients do not require explicit shutdown
        self.client = None","class AmazonTransport(object):
    def __init__(self, config):
        self.config = config
        self.is_running = False
        self.connection = None

    def startup(self):
        if not self.is_running:
            # Simulate connection establishment
            self.connection = f""Connected to Amazon transport with config: {self.config}""
            self.is_running = True
            return ""Transport started successfully""
        return ""Transport is already running""

    def deliver(self, message):
        if not self.is_running:
            raise RuntimeError(""Transport is not running. Call startup() first."")
        
        if not message:
            raise ValueError(""Message cannot be empty"")
        
        # Simulate message delivery
        delivery_result = f""Message delivered: {message}""
        return delivery_result

    def shutdown(self):
        if self.is_running:
            # Simulate connection cleanup
            self.connection = None
            self.is_running = False
            return ""Transport shut down successfully""
        return ""Transport is not running""","class AmazonTransport(object):

    def __init__(self, config):
        self.config = config
        self.client = None
        self.queue_url = config.get('queue_url')
        self.topic_arn = config.get('topic_arn')
        self.region = config.get('region', 'us-east-1')
        self.service = config.get('service', 'sqs')  # 'sqs' or 'sns'
        self.aws_access_key_id = config.get('aws_access_key_id')
        self.aws_secret_access_key = config.get('aws_secret_access_key')

    def startup(self):
        try:
            if self.service == 'sqs':
                self.client = boto3.client(
                    'sqs',
                    region_name=self.region,
                    aws_access_key_id=self.aws_access_key_id,
                    aws_secret_access_key=self.aws_secret_access_key
                )
            elif self.service == 'sns':
                self.client = boto3.client(
                    'sns',
                    region_name=self.region,
                    aws_access_key_id=self.aws_access_key_id,
                    aws_secret_access_key=self.aws_secret_access_key
                )
        except (NoCredentialsError, ClientError) as e:
            raise Exception(f""Failed to initialize AWS client: {str(e)}"")

    def deliver(self, message):
        if not self.client:
            raise Exception(""Transport not started. Call startup() first."")
        
        try:
            if isinstance(message, dict):
                message_body = json.dumps(message)
            else:
                message_body = str(message)
            
            if self.service == 'sqs':
                response = self.client.send_message(
                    QueueUrl=self.queue_url,
                    MessageBody=message_body
                )
                return response.get('MessageId')
            elif self.service == 'sns':
                response = self.client.publish(
                    TopicArn=self.topic_arn,
                    Message=message_body
                )
                return response.get('MessageId')
        except ClientError as e:
            raise Exception(f""Failed to deliver message: {str(e)}"")

    def shutdown(self):
        if self.client:
            self.client = None",no_docstr,0.4010152284263959,0.15306122448979595,0.08205128205128205,0.27918781725888325,0.20457774876822166,0.40293040293040294,0.1926605504587156,0.11029411764705882,0.7951570153236389,0.7763795852661133,0.7856561541557312,0.7782173156738281,0.768238698060942,0.34507042253521125,0.1702127659574468,0.10714285714285714,0.2746478873239437,0.1988207597095547,0.5784313725490197,0.3251231527093596,0.24257425742574257,0.7546417713165283,0.7038117051124573,0.7283410429954529,0.7085844874382019,0.7250351750972766,0.4493827160493827,0.22332506203473945,0.1346633416458853,0.3259259259259259,0.2847994959922525,0.46336206896551724,0.2678185745140389,0.18614718614718614,0.817743182182312,0.7963143587112427,0.8068864941596985,0.7984066009521484,0.7917781102362205,0.2277787185290856,0.0259103102819126,0.0366866911230088,0.5241935483870968,0.3243243243243243,0.1659542365464396,0.0684664590232997,0.0787855351136356,0.4354838709677419,0.081081081081081,0.2521925126273248,0.0731978794437749,0.0846567395049315,0.5806451612903226,0.2702702702702703
585806,morpframework/morpfw,morpframework_morpfw/morpfw/crud/storage/elasticsearchstorage.py,morpfw.crud.storage.elasticsearchstorage.Aggregate,"class Aggregate(object):
    def __init__(self):
        self.groups = []
        self.values = []
        self.first_group = None
        self._finalized = False

    def add_group(self, key, field, type=""terms"", opts=None):
        if self._finalized:
            raise ValueError(""Aggregate has been finalized"")
        self.groups.append(AggGroup(key, field, type, opts))

    def add(self, key, function, field):
        if self._finalized:
            raise ValueError(""Aggregate has been finalized"")
        self.values.append(AggValue(key, function, field))

    def finalize(self):
        if self._finalized:
            raise ValueError(""Aggregate has been finalized"")

        if not self.groups:
            self._finalized = True
            return

        prev = None
        first = None
        for g in self.groups:
            if prev is None:
                prev = g
                continue
            if g not in prev.children:
                prev.children.append(g)
                g.parent = prev
            prev = g
        prev.is_leaf = True
        for v in self.values:
            if v not in prev.children:
                prev.children.append(v)
                v.parent = prev

        self._finalized = True

    def json(self):
        if not self._finalized:
            self.finalize()
        if not self.groups:
            return {}
        return self.groups[0].json()

    def parse(self, result):
        if not self._finalized:
            self.finalize()
        return self.groups[0].parse(result)","class Aggregate(object):


    def __init__(self):
        pass

    def add_group(self, key, field, type=""terms"", opts=None):
        pass

    def add_group(self, key, field, type=""terms"", opts=None):
        pass

    def finalize(self):
        pass

    def json(self):
        pass

    def parse(self, result):
        pass

",7,0,snippet_406,0.5555555555555556,"class Aggregate(object):
    def __init__(self):
        self.groups = []
        self._finalized = False
        self._query = None

    def add_group(self, key, field, type=""terms"", opts=None):
        if opts is None:
            opts = {}
        self.groups.append({
            'key': key,
            'field': field,
            'type': type,
            'opts': opts
        })
        return self

    def finalize(self):
        self._finalized = True
        self._query = self.json()
        return self._query

    def json(self):
        def build(idx):
            g = self.groups[idx]
            agg_body = {'field': g['field']}
            agg_body.update(g['opts'])
            node = {g['key']: {g['type']: agg_body}}
            if idx + 1 < len(self.groups):
                node[g['key']]['aggs'] = build(idx + 1)
            return node

        if not self.groups:
            return {}
        return {'aggs': build(0)}

    def parse(self, result):
        aggs = result.get('aggregations', result)
        if not self.groups:
            return []

        rows = []
        keys = [g['key'] for g in self.groups]

        def recurse(level, buckets, path):
            key = keys[level]
            for b in buckets:
                p = path.copy()
                p[key] = b.get('key')
                if level == len(keys) - 1:
                    p['doc_count'] = b.get('doc_count')
                    rows.append(p)
                else:
                    nxt = b.get(keys[level + 1], {})
                    recurse(level + 1, nxt.get('buckets', []), p)

        first = keys[0]
        recurse(0, aggs.get(first, {}).get('buckets', []), {})
        return rows","class Aggregate(object):
    def __init__(self):
        self.groups = {}
        self.aggregations = {}

    def add_group(self, key, field, type=""terms"", opts=None):
        if opts is None:
            opts = {}
        self.groups[key] = {
            ""field"": field,
            ""type"": type,
            ""opts"": opts
        }
        return self

    def finalize(self):
        aggregations = {}
        for key, group in self.groups.items():
            agg = {group[""type""]: {""field"": group[""field""]}}
            if group[""opts""]:
                agg[group[""type""]].update(group[""opts""])
            aggregations[key] = agg
        self.aggregations = aggregations
        return self

    def json(self):
        if not self.aggregations:
            self.finalize()
        return self.aggregations

    def parse(self, result):
        parsed = {}
        if ""aggregations"" in result:
            aggregations = result[""aggregations""]
            for key, group in self.groups.items():
                if key in aggregations:
                    if group[""type""] == ""terms"":
                        parsed[key] = [
                            {
                                ""key"": bucket.get(""key""),
                                ""doc_count"": bucket.get(""doc_count"")
                            }
                            for bucket in aggregations[key].get(""buckets"", [])
                        ]
                    else:
                        parsed[key] = aggregations[key]
        return parsed","class Aggregate(object):
    def __init__(self):
        self.aggregations = {}
        self.finalized = False

    def add_group(self, key, field, type=""terms"", opts=None):
        if opts is None:
            opts = {}
        
        agg_config = {
            type: {
                ""field"": field,
                **opts
            }
        }
        
        self.aggregations[key] = agg_config
        return self

    def finalize(self):
        self.finalized = True
        return self

    def json(self):
        return {
            ""aggs"": self.aggregations
        }

    def parse(self, result):
        if ""aggregations"" not in result:
            return {}
        
        parsed = {}
        for key, agg_result in result[""aggregations""].items():
            if ""buckets"" in agg_result:
                parsed[key] = []
                for bucket in agg_result[""buckets""]:
                    bucket_data = {
                        ""key"": bucket[""key""],
                        ""doc_count"": bucket[""doc_count""]
                    }
                    parsed[key].append(bucket_data)
            else:
                parsed[key] = agg_result
        
        return parsed",no_docstr,0.5013623978201635,0.28493150684931506,0.18732782369146006,0.35422343324250677,0.3553606443527592,0.5518072289156627,0.32608695652173914,0.24939467312348668,0.7870510220527649,0.8466195464134216,0.8157492876052856,0.8402599692344666,0.7540088701923078,0.4551282051282052,0.2709677419354839,0.16883116883116883,0.3461538461538462,0.3421332651151041,0.5700934579439252,0.33125,0.23510971786833856,0.8133856058120728,0.8061721920967102,0.8097628355026245,0.8068877458572388,0.7088918000000003,0.43508771929824563,0.24028268551236748,0.1708185053380783,0.32982456140350874,0.2774301364417586,0.6446280991735537,0.36929460580912865,0.275,0.8170303106307983,0.8108940720558167,0.8139505982398987,0.8115034699440002,0.7380182274247499,0.2761375073964345,0.1653446460123534,0.1991482532723519,0.4878048780487805,0.2522522522522522,0.2373313840937389,0.1313516178555105,0.1386177330656987,0.4451219512195122,0.2342342342342342,0.2035150984815819,0.126441300789296,0.1415852544202662,0.3658536585365853,0.1801801801801801
559141,marionette-tg/marionette,marionette-tg_marionette/marionette_tg/plugins/_tg.py,marionette_tg.plugins._tg.Pop3ContentLengthHandler,"class Pop3ContentLengthHandler(object):

    def capacity(self):
        return 0

    def encode(self, marionette_state, template, to_embed):
        pop3_body_length = str(len('\n'.join(template.split(""\n"")[1:])))
        return pop3_body_length

    def decode(self, marionette_state, ctxt):
        return None","class Pop3ContentLengthHandler(object):


    def capacity(self):
        pass

    def encode(self, marionette_state, template, to_embed):
        pass

    def decode(self, marionette_state, ctxt):
        pass

",4,0,snippet_153,1.0,"class Pop3ContentLengthHandler(object):
    _LITERAL_RE = re.compile(r'\{(\d+)\+?\}$')

    def capacity(self):
        return sys.maxsize

    def encode(self, marionette_state, template, to_embed):
        """"""
        template should contain a '%d' placeholder where the length of to_embed goes.
        Returns a tuple of (command_string, to_embed_bytes).
        """"""
        size = len(to_embed)
        cmd = template % size
        return cmd, to_embed

    def decode(self, marionette_state, ctxt):
        """"""
        Reads a line from ctxt, detects a literal length {n} or {n+}, then reads n bytes
        plus the following CRLF, and returns the data block.
        If no literal marker is found, returns None.
        """"""
        line = ctxt.read_line()
        m = self._LITERAL_RE.search(line)
        if not m:
            return None
        length = int(m.group(1))
        data = ctxt.read(length)
        # consume the trailing CRLF after the data
        ctxt.read(2)
        return data","class Pop3ContentLengthHandler(object):

    def capacity(self):
        return 0

    def encode(self, marionette_state, template, to_embed):
        if not to_embed:
            return template
            
        # Find the content length line in the POP3 response
        lines = template.split('\n')
        new_lines = []
        
        for line in lines:
            if line.startswith('Content-Length:'):
                # Extract current content length
                try:
                    current_length = int(line.split(':')[1].strip())
                    # Add the length of data to embed
                    new_length = current_length + len(to_embed)
                    new_lines.append('Content-Length: ' + str(new_length))
                except (ValueError, IndexError):
                    new_lines.append(line)
            else:
                new_lines.append(line)
        
        # Join the lines back together
        result = '\n'.join(new_lines)
        
        # Append the data to embed at the end
        if not result.endswith('\n'):
            result += '\n'
        result += to_embed
        
        return result

    def decode(self, marionette_state, ctxt):
        # Find the content length line in the context
        lines = ctxt.split('\n')
        content_length = 0
        
        for line in lines:
            if line.startswith('Content-Length:'):
                try:
                    content_length = int(line.split(':')[1].strip())
                    break
                except (ValueError, IndexError):
                    continue
        
        if content_length > 0:
            # Extract the last 'content_length' characters as the embedded data
            # This assumes the embedded data is appended at the end
            embedded_data = ctxt[-content_length:] if len(ctxt) >= content_length else ctxt
            return embedded_data
        
        return ''","class Pop3ContentLengthHandler(object):
    def __init__(self):
        self.max_capacity = 4  # Can encode up to 9999 in 4 digits

    def capacity(self):
        return self.max_capacity

    def encode(self, marionette_state, template, to_embed):
        if len(to_embed) > 9999:
            raise ValueError(""Data too large to embed in POP3 content length"")
        
        # Convert data length to 4-digit string
        length_str = str(len(to_embed)).zfill(4)
        
        # Find content-length header in template and replace
        lines = template.split('\n')
        for i, line in enumerate(lines):
            if line.lower().startswith('content-length:'):
                lines[i] = f'Content-Length: {length_str}'
                break
        else:
            # Add content-length header if not found
            header_end = template.find('\r\n\r\n')
            if header_end == -1:
                header_end = template.find('\n\n')
                if header_end == -1:
                    lines.append(f'Content-Length: {length_str}')
                else:
                    lines.insert(-1, f'Content-Length: {length_str}')
            else:
                lines.insert(-1, f'Content-Length: {length_str}')
        
        return '\n'.join(lines)

    def decode(self, marionette_state, ctxt):
        lines = ctxt.split('\n')
        for line in lines:
            if line.lower().startswith('content-length:'):
                length_str = line.split(':', 1)[1].strip()
                try:
                    length = int(length_str)
                    return str(length).encode()
                except ValueError:
                    continue
        return b''",no_docstr,0.3647058823529412,0.2142857142857143,0.1566265060240964,0.31764705882352945,0.20017461904931455,0.2987551867219917,0.18333333333333332,0.14644351464435146,0.651038408279419,0.8390076160430908,0.7331668734550476,0.8154634237289429,0.7200028000000002,0.28688524590163933,0.2066115702479339,0.15833333333333333,0.24590163934426226,0.16439141076677452,0.20380434782608695,0.16621253405994552,0.13114754098360656,0.6474561095237732,0.8667529821395874,0.7412246465682983,0.8383573293685913,0.7195600000000004,0.28936170212765955,0.19742489270386265,0.12987012987012989,0.2638297872340426,0.16216352868410153,0.2086720867208672,0.16304347826086957,0.12534059945504086,0.6575366854667664,0.8549953699111938,0.7433770895004272,0.8300684094429016,0.7153959800664457,0.3142609131884198,0.0699269164526634,0.3893226186539572,0.2352941176470588,0.5625,0.4442973594191096,0.0727867802241416,0.6088144221581792,0.4705882352941176,0.625,0.3579471188627842,0.0597468218819425,0.394100477098606,0.3529411764705882,0.625
222357,aleju/imgaug,aleju_imgaug/imgaug/augmenters/meta.py,imgaug.augmenters.meta._AssertShapeLineStringsCheck,"class _AssertShapeLineStringsCheck(object):
    def __init__(self, shape):
        self.shape = shape

    def __call__(self, line_strings_on_images, _random_state, _parents,
                 _hooks):
        AssertShape._check_shapes([obj.shape for obj
                                   in line_strings_on_images],
                                  self.shape[0:3])
        return line_strings_on_images","class _AssertShapeLineStringsCheck(object):


    def __init__(self, shape):
        pass

    def __call__(self, line_strings_on_images, _random_state, _parents,
                 _hooks):
        pass

",3,0,snippet_489,0.6666666666666666,"class _AssertShapeLineStringsCheck(object):
    def __init__(self, shape):
        # store expected shape
        self.shape = tuple(shape)

    def __call__(self, line_strings_on_images, _random_state, _parents, _hooks):
        # verify that each LineStringsOnImage has the expected shape
        for ls in line_strings_on_images:
            actual = getattr(ls, ""shape"", None)
            if actual != self.shape:
                raise AssertionError(
                    ""Expected LineStringsOnImage.shape to be {0}, got {1}."".format(
                        self.shape, actual
                    )
                )
        return line_strings_on_images","class _AssertShapeLineStringsCheck(object):

    def __init__(self, shape):
        self.shape = shape

    def __call__(self, line_strings_on_images, _random_state, _parents,
                 _hooks):
        for ls_on_image in line_strings_on_images:
            if ls_on_image.shape != self.shape:
                raise AssertionError(
                    ""Expected line strings to have shape %s, ""
                    ""but got %s."" % (self.shape, ls_on_image.shape)
                )
        return line_strings_on_images","class _AssertShapeLineStringsCheck(object):

    def __init__(self, shape):
        self.shape = shape

    def __call__(self, line_strings_on_images, _random_state, _parents,
                 _hooks):
        for line_strings_on_image in line_strings_on_images:
            assert line_strings_on_image.shape == self.shape, \
                ""Expected shape %s, got %s"" % (self.shape, line_strings_on_image.shape)
        return line_strings_on_images",no_docstr,0.6545454545454545,0.5370370370370371,0.4150943396226416,0.6545454545454545,0.5083070206044925,0.5899280575539568,0.5,0.44525547445255476,0.8252784609794617,0.9192612171173096,0.8697382807731628,0.9089105129241943,0.8264857534246575,0.6862745098039216,0.58,0.5102040816326531,0.6666666666666666,0.5793380224042207,0.6535433070866141,0.5634920634920635,0.528,0.8833961486816406,0.9278784990310669,0.9050911068916321,0.9232297539710999,0.862435238095238,0.7142857142857143,0.6041666666666666,0.5319148936170213,0.6938775510204083,0.6032786786202772,0.680327868852459,0.5867768595041323,0.55,0.9281874895095825,0.9306931495666504,0.9294386506080627,0.9304420351982117,0.8993720754716981,0.3751254817314254,0.1705785400383973,0.4581285150924326,0.3333333333333333,0.5384615384615384,0.6300352791498759,0.342035044064516,0.6781060725349874,0.5,1.0,0.6517764216061296,0.4289996138895309,0.6781060725349874,0.5,1.0
740197,sirrice/pygg,sirrice_pygg/pygg/pygg.py,pygg.pygg.GGData,"class GGData(object):
  def __init__(self, r_commands, fname=None):
      self.r_commands = r_commands
      self.fname = fname


  def __str__(self):
      return self.r_commands","class GGData(object):


  def __init__(self, r_commands, fname=None):
    pass

  def __str__(self):
    pass

",3,0,snippet_368,1.0,"class GGData(object):

    def __init__(self, r_commands, fname=None):
        if not isinstance(r_commands, (list, tuple)):
            raise TypeError(""r_commands must be a list or tuple"")
        self.r_commands = [str(cmd) for cmd in r_commands]
        self.fname = fname
        if self.fname:
            with open(self.fname, ""w"") as f:
                f.write(""\n"".join(self.r_commands))

    def __str__(self):
        return ""\n"".join(self.r_commands)","class GGData(object):
    def __init__(self, r_commands, fname=None):
        self.r_commands = r_commands
        self.fname = fname
    
    def __str__(self):
        if self.fname:
            return f""GGData(r_commands={self.r_commands}, fname={self.fname})""
        else:
            return f""GGData(r_commands={self.r_commands})""","class GGData(object):

    def __init__(self, r_commands, fname=None):
        self.r_commands = r_commands
        self.fname = fname

    def __str__(self):
        if self.fname:
            return f""GGData(r_commands={self.r_commands}, fname='{self.fname}')""
        else:
            return f""GGData(r_commands={self.r_commands}, fname=None)""",no_docstr,0.5494505494505494,0.4494382022471911,0.3448275862068965,0.5494505494505494,0.3532950807759337,0.39568345323741005,0.35507246376811596,0.31386861313868614,0.774113118648529,0.8954466581344604,0.8303710222244263,0.881628155708313,0.7757598181818182,0.7246376811594203,0.6567164179104478,0.6153846153846153,0.7246376811594203,0.5315968894134773,0.55,0.5353535353535354,0.5102040816326531,0.8953264951705933,0.9483491778373718,0.9210754632949829,0.942766010761261,0.854168125,0.704225352112676,0.6376811594202899,0.5970149253731344,0.704225352112676,0.5012180316095669,0.5188679245283019,0.5047619047619047,0.4807692307692308,0.8941792249679565,0.9459586143493652,0.9193404316902161,0.9405123591423035,0.854168125,0.4600861566409315,0.1794432482931897,0.4986206765161503,0.5789473684210527,0.5833333333333334,0.7757596349867297,0.6187934993051338,0.8833678476593292,0.6842105263157895,0.9166666666666666,0.7685443380474558,0.5899323115480382,0.8833678476593292,0.6842105263157895,0.9166666666666666
573777,micropython/micropython,tests/basics/gen_yield_from_ducktype.py,gen_yield_from_ducktype.Incrementer,"class Incrementer:

    def __iter__(self):
        return self

    def __next__(self):
        return self.send(None)

    def send(self, val):
        if val is None:
            return ""Incrementer initialized""
        return val + 1","class Incrementer:


    def __iter__(self):
        pass

    def __next__(self):
        pass

    def send(self, val):
        pass

",4,0,snippet_482,1.0,"class Incrementer:
    def __init__(self):
        self._value = 0
        self._waiting = None
        self._first = True

    def __iter__(self):
        return self

    def __next__(self):
        if self._waiting is not None:
            self._value = self._waiting
            self._waiting = None
        else:
            if not self._first:
                self._value += 1
        self._first = False
        return self._value

    def send(self, val):
        self._waiting = val
        return self.__next__()","class Incrementer:
    def __init__(self, start=0):
        self.value = start
        self.increment = 1

    def __iter__(self):
        return self

    def __next__(self):
        current = self.value
        self.value += self.increment
        return current

    def send(self, val):
        if val is not None:
            self.increment = val
        return self.__next__()","class Incrementer:
    def __init__(self, start=0, step=1):
        self.start = start
        self.step = step
        self.current = start

    def __iter__(self):
        return self

    def __next__(self):
        value = self.current
        self.current += self.step
        return value

    def send(self, val):
        if val is not None:
            self.current = val
        value = self.current
        self.current += self.step
        return value",no_docstr,0.5287356321839081,0.30588235294117644,0.21686746987951808,0.4137931034482759,0.29764375294489853,0.37209302325581395,0.28125,0.25196850393700787,0.7720886468887329,0.8583076000213623,0.8129184246063232,0.8488287925720215,0.7451005882352941,0.6301369863013698,0.4507042253521127,0.3478260869565218,0.5479452054794521,0.42563275339936946,0.5106382978723404,0.40860215053763443,0.3695652173913043,0.8429254293441772,0.8840640783309937,0.8630048036575317,0.8797703981399536,0.8088908,0.5476190476190476,0.36585365853658536,0.3,0.4761904761904762,0.3630344459143667,0.4444444444444444,0.34579439252336447,0.3113207547169811,0.7955700159072876,0.863684356212616,0.8282291293144226,0.8563525080680847,0.7801440425531915,0.2699991753219425,0.1515551103099188,0.3367749243111844,0.2916666666666667,0.3,0.3751314146327618,0.2887308472548599,0.4784614779428538,0.3333333333333333,0.4,0.3332900164029873,0.2235550668505662,0.4762716654280496,0.3333333333333333,0.3
586236,mozilla-b2g/fxos-certsuite,mozilla-b2g_fxos-certsuite/mcts/web-platform-tests/tests/tools/wptserve/wptserve/pipes.py,wptserve.pipes.opt,"class opt(object):
    def __init__(self, f):
        self.f = f

    def __call__(self, arg):
        return self.f(arg)","class opt(object):


    def __init__(self, f):
        pass

    def __call__(self, arg):
        pass

",3,0,snippet_752,1.0,"class opt(object):
    def __init__(self, f):
        if not callable(f):
            raise TypeError(""Expected a callable"")
        self.f = f

    def __call__(self, arg):
        return self.f(arg)","class opt(object):
    def __init__(self, f):
        self.f = f

    def __call__(self, arg):
        return self.f(arg)","class opt(object):
    def __init__(self, f):
        self.f = f
        self.cache = {}

    def __call__(self, arg):
        if arg not in self.cache:
            self.cache[arg] = self.f(arg)
        return self.cache[arg]",no_docstr,0.8,0.744186046511628,0.6829268292682927,0.8,0.7064054146516275,0.7288135593220338,0.7068965517241379,0.6842105263157895,0.8483424186706543,0.9668264389038086,0.9037174582481384,0.9535092711448669,0.8913054347826087,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.000000238418579,1.000000238418579,1.000000238418579,1.000000238418579,1.0,0.72,0.6666666666666666,0.5217391304347827,0.6799999999999999,0.5786616608202216,0.6142857142857143,0.5797101449275363,0.5441176470588235,0.8766690492630005,0.9518259167671204,0.9127028584480286,0.9437352418899536,0.8452396428571428,0.7711709986616132,0.5275855485130294,0.8512160931922469,0.7058823529411765,1.0,1.0,1.0,1.0,1.0,1.0,0.6183013405514034,0.3559739463323481,0.6989307622784944,0.5294117647058824,0.8888888888888888
531044,kervi/kervi-core,kervi_kervi-core/kervi/core/utility/kervi_logging.py,utility.kervi_logging.KerviLog,"class KerviLog(object):
    def __init__(self, name):
        self.logger = logging.getLogger(name)

    def info(self, message, *args):
        self.logger.debug(BraceMessage(message, *args))

    def debug(self, message, *args):
        if args:
            self.logger.debug(BraceMessage(message, *args))
        else:
            self.logger.debug(message)

    def error(self, message, *args):
        self.logger.error(BraceMessage(message, *args))

    def exception(self, message, *args):
        self.logger.exception(BraceMessage(message, *args))

    def fatal(self, message, *args):
        self.logger.fatal(BraceMessage(message, *args))","class KerviLog(object):


    def __init__(self, name):
        pass

    def info(self, message, *args):
        pass

    def debug(self, message, *args):
        pass

    def error(self, message, *args):
        pass

    def exception(self, message, *args):
        pass

    def fatal(self, message, *args):
        pass

",7,0,snippet_673,0.3333333333333333,"class KerviLog(object):

    def __init__(self, name):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            handler.setLevel(logging.DEBUG)
            formatter = logging.Formatter(
                '%(asctime)s [%(name)s] %(levelname)s: %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)

    def info(self, message, *args):
        msg = message % args if args else message
        self.logger.info(msg)

    def debug(self, message, *args):
        msg = message % args if args else message
        self.logger.debug(msg)

    def error(self, message, *args):
        msg = message % args if args else message
        self.logger.error(msg)

    def exception(self, message, *args):
        msg = message % args if args else message
        self.logger.exception(msg)

    def fatal(self, message, *args):
        msg = message % args if args else message
        self.logger.fatal(msg)","class KerviLog(object):
    def __init__(self, name):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        if not self.logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)

    def info(self, message, *args):
        self.logger.info(message, *args)

    def debug(self, message, *args):
        self.logger.debug(message, *args)

    def error(self, message, *args):
        self.logger.error(message, *args)

    def exception(self, message, *args):
        self.logger.exception(message, *args)

    def fatal(self, message, *args):
        self.logger.critical(message, *args)","class KerviLog(object):

    def __init__(self, name):
        self.logger = logging.getLogger(name)
        if not self.logger.handlers:
            handler = logging.StreamHandler(sys.stdout)
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.DEBUG)

    def info(self, message, *args):
        self.logger.info(message, *args)

    def debug(self, message, *args):
        self.logger.debug(message, *args)

    def error(self, message, *args):
        self.logger.error(message, *args)

    def exception(self, message, *args):
        self.logger.exception(message, *args)

    def fatal(self, message, *args):
        self.logger.critical(message, *args)",no_docstr,0.6865671641791046,0.49246231155778897,0.3147208121827411,0.5572139303482588,0.4800049738173625,0.6072874493927125,0.45528455284552843,0.4,0.8122643232345581,0.861438512802124,0.8361290693283081,0.8562547564506531,0.7926288018433182,0.7692307692307693,0.6467065868263473,0.5333333333333333,0.7100591715976332,0.6625583184294473,0.7358490566037735,0.6587677725118484,0.6,0.8584427833557129,0.890070915222168,0.8739708065986633,0.8868035674095154,0.8522742045454546,0.7692307692307693,0.6467065868263473,0.5333333333333333,0.7100591715976332,0.6625583184294473,0.7358490566037735,0.6587677725118484,0.6,0.8584977388381958,0.8922089338302612,0.8750287890434265,0.8887190818786621,0.854168125,0.4049449293900145,0.1891619381864571,0.4615120883166901,0.4024390243902439,0.5666666666666667,0.4576528682790873,0.3280424742305535,0.4615120883166901,0.524390243902439,0.5166666666666667,0.4576528682790873,0.3280424742305535,0.4615120883166901,0.524390243902439,0.5166666666666667
830741,why2pac/dp-tornado,why2pac_dp-tornado/dp_tornado/engine/ini.py,why2pac_dp-tornado.dp_tornado.engine.ini.IniParser,"class IniParser(object):
    def __init__(self, parser):
        self._parser = parser

    def get(self, section, key, default=None):
        try:
            if not self._parser:
                got = False
            else:
                got = self._parser.get(section, key)

            if default is True or default is False:
                return True if got == '1' else False

            elif isinstance(default, str):
                return str(got)

            elif isinstance(default, int):
                return int(got)

            else:
                return got

        except (configparser.NoSectionError, configparser.NoOptionError):
            return default","class IniParser(object):


    def __init__(self, parser):
        pass

    def get(self, section, key, default=None):
        pass

",3,0,snippet_360,0.8235294117647058,"class IniParser(object):
    def __init__(self, parser):
        if isinstance(parser, configparser.ConfigParser):
            self._parser = parser
        else:
            self._parser = configparser.ConfigParser()
            self._parser.read(parser)

    def get(self, section, key, default=None):
        try:
            return self._parser.get(section, key)
        except (configparser.NoSectionError, configparser.NoOptionError):
            return default","class IniParser(object):
    def __init__(self, parser):
        self.parser = parser

    def get(self, section, key, default=None):
        try:
            return self.parser.get(section, key)
        except (KeyError, ValueError, AttributeError):
            return default","class IniParser(object):

    def __init__(self, parser):
        self.parser = parser

    def get(self, section, key, default=None):
        try:
            return self.parser.get(section, key)
        except:
            return default",no_docstr,0.6260869565217391,0.47787610619469023,0.3783783783783784,0.5217391304347826,0.5308280312796253,0.8556701030927835,0.71875,0.6210526315789474,0.8976790308952332,0.825057327747345,0.8598374724388123,0.8317865133285522,0.7619071428571428,0.5399999999999999,0.44897959183673475,0.39583333333333337,0.52,0.2878908671626797,0.9516129032258065,0.8360655737704918,0.7333333333333333,0.8877938985824585,0.7438881397247314,0.8094951510429382,0.7561447620391846,0.8065495535714285,0.5567010309278351,0.46315789473684205,0.4086021505376344,0.5360824742268041,0.23801572990962397,1.0,0.9074074074074074,0.8113207547169812,0.9275020360946655,0.7255872488021851,0.8142133355140686,0.7417346835136414,0.7946449107142856,0.3071423609824212,0.176933234924616,0.2198389739820274,0.4032258064516129,0.4285714285714285,0.2475296266782629,0.1051558279853018,0.1835801902484873,0.3870967741935484,0.3142857142857143,0.2403175709991195,0.0820336780089178,0.1778541175082976,0.3870967741935484,0.3142857142857143
372560,ets-labs/python-dependency-injector,ets-labs_python-dependency-injector/examples/miniapps/movie-lister/movies/entities.py,movies.entities.Movie,"class Movie:

    def __init__(self, title: str, year: int, director: str):
        self.title = str(title)
        self.year = int(year)
        self.director = str(director)

    def __repr__(self):
        return ""{0}(title={1}, year={2}, director={3})"".format(
            self.__class__.__name__,
            repr(self.title),
            repr(self.year),
            repr(self.director),
        )","class Movie:


    def __init__(self, title: str, year: int, director: str):
        pass

    def __repr__(self):
        pass

",3,0,snippet_115,1.0,"class Movie:

    def __init__(self, title: str, year: int, director: str):
        self.title = title
        self.year = year
        self.director = director

    def __repr__(self):
        return f""Movie(title={self.title!r}, year={self.year}, director={self.director!r})""","class Movie:
    def __init__(self, title: str, year: int, director: str):
        self.title = title
        self.year = year
        self.director = director

    def __repr__(self):
        return f""Movie(title='{self.title}', year={self.year}, director='{self.director}')""","class Movie:
    def __init__(self, title: str, year: int, director: str):
        self.title = title
        self.year = year
        self.director = director

    def __repr__(self):
        return f""Movie('{self.title}', {self.year}, '{self.director}')""",no_docstr,0.7857142857142857,0.5609756097560975,0.4,0.7380952380952381,0.4824646369410839,0.9294117647058824,0.7619047619047619,0.6385542168674698,0.9241040945053101,0.8786793947219849,0.9008194208145142,0.8830199241638184,0.8823541176470588,0.8048780487804879,0.5750000000000001,0.41025641025641024,0.7560975609756098,0.46000510224239943,0.9294117647058824,0.7142857142857143,0.5903614457831325,0.9429210424423218,0.8798714876174927,0.9103057980537415,0.8857945203781128,0.8862756470588234,0.759493670886076,0.5974025974025974,0.42666666666666675,0.759493670886076,0.3990786430837127,0.9240506329113924,0.6794871794871795,0.5714285714285714,0.9439474940299988,0.8768138289451599,0.9091430306434631,0.8830943703651428,0.8862756470588234,0.3912359985789324,0.4520491692565753,0.4764630409512084,0.3260869565217391,0.3103448275862069,0.3912359985789324,0.4520491692565753,0.4764630409512084,0.3260869565217391,0.3103448275862069,0.3912359985789324,0.4520491692565753,0.4764630409512084,0.3260869565217391,0.3103448275862069
130805,IdentityPython/pysaml2,src/saml2/s2repoze/plugins/sp.py,saml2.s2repoze.plugins.sp.ECP_response,"class ECP_response:
    code = 200
    title = ""OK""

    def __init__(self, content):
        self.content = content

    # noinspection PyUnusedLocal
    def __call__(self, environ, start_response):
        start_response(f""{self.code} {self.title}"", [(""Content-Type"", ""text/xml"")])
        return [self.content]","class ECP_response:


    def __init__(self, content):
        pass

    def __call__(self, environ, start_response):
        pass

",3,0,snippet_81,1.0,"class ECP_response:
    def __init__(self, content):
        if isinstance(content, (list, tuple)):
            parts = []
            for part in content:
                if isinstance(part, str):
                    part = part.encode('utf-8')
                parts.append(part)
            self._body = b''.join(parts)
        elif isinstance(content, str):
            self._body = content.encode('utf-8')
        elif isinstance(content, bytes):
            self._body = content
        else:
            raise TypeError(""content must be bytes, str, or list/tuple of them"")

    def __call__(self, environ, start_response):
        status = '200 OK'
        headers = [
            ('Content-Type', 'application/xml; charset=utf-8'),
            ('Content-Length', str(len(self._body)))
        ]
        start_response(status, headers)
        return [self._body]","class ECP_response:
    def __init__(self, content):
        self.content = content
        if isinstance(content, str):
            self.content_bytes = content.encode('utf-8')
        else:
            self.content_bytes = content
        self.headers = [('Content-Type', 'text/html; charset=utf-8')]

    def __call__(self, environ, start_response):
        status = '200 OK'
        start_response(status, self.headers)
        return [self.content_bytes]","class ECP_response:
    def __init__(self, content):
        self.content = content

    def __call__(self, environ, start_response):
        if isinstance(self.content, str):
            content_bytes = self.content.encode('utf-8')
        else:
            content_bytes = self.content
        
        status = '200 OK'
        headers = [
            ('Content-Type', 'application/vnd.paos+xml'),
            ('Content-Length', str(len(content_bytes)))
        ]
        
        start_response(status, headers)
        return [content_bytes]",no_docstr,0.43076923076923074,0.203125,0.1111111111111111,0.32307692307692304,0.2528530218726905,0.34554973821989526,0.25263157894736843,0.18518518518518517,0.6741218566894531,0.77857905626297,0.7225949764251709,0.7666987776756287,0.7489737037037042,0.6292134831460674,0.41379310344827586,0.2823529411764706,0.4943820224719102,0.4626534630343973,0.5887850467289719,0.4528301886792453,0.37142857142857144,0.8367277383804321,0.8415732979774475,0.8391435146331787,0.841086208820343,0.7471289655172414,0.6086956521739131,0.35555555555555557,0.22727272727272727,0.5,0.41250841592468995,0.5384615384615384,0.4051724137931034,0.3217391304347826,0.8078769445419312,0.8346071243286133,0.8210245370864868,0.8318548202514648,0.7649146315789473,0.3263073915512799,0.0604580479995205,0.175059979744061,0.53125,0.5384615384615384,0.4105963288637039,0.2253375316053057,0.3160862453879713,0.5625,0.5384615384615384,0.3518750208103475,0.206798453238034,0.3160862453879713,0.5,0.3846153846153846
686342,quantumlib/Cirq,quantumlib_Cirq/benchmarks/transformers/routing.py,benchmarks.transformers.routing.RouteCQC,"class RouteCQC:
    params = [[10, 25, 50, 75, 100], [10, 50, 100, 250, 500, 1000], [0.5], [10]]
    param_names = [""qubits"", ""depth"", ""op_density"", ""grid_device_size""]
    timeout = 300  # Increase timeout to 5 minutes instead of default 60 seconds.

    def setup(self, qubits: int, depth: int, op_density: float, grid_device_size: int):
        gate_domain = {cirq.CNOT: 2, cirq.X: 1}
        self.circuit = cirq.testing.random_circuit(
            qubits, depth, op_density, gate_domain=gate_domain, random_state=12345
        )
        self.device = cirq.testing.construct_grid_device(grid_device_size, grid_device_size)
        self.router = cirq.RouteCQC(self.device.metadata.nx_graph)

    def time_circuit_routing(self, *_):
        self.routed_circuit = self.router(self.circuit)

    def track_routed_circuit_depth_ratio(self, *_) -> float:
        self.routed_circuit = self.router(self.circuit)
        return len(self.routed_circuit) / len(self.circuit)

    def teardown(self, *_):
        self.device.validate_circuit(self.routed_circuit)","class RouteCQC:


    def setup(self, qubits: int, depth: int, op_density: float, grid_device_size: int):
        pass

    def time_circuit_routing(self, *_):
        pass

    def track_routed_circuit_depth_ratio(self, *_) -> float:
        pass

    def teardown(self, *_):
        pass

",5,0,snippet_584,1.0,"class RouteCQC:
    def setup(self, qubits: int, depth: int, op_density: float, grid_device_size: int):
        self.qubits = qubits
        self.depth = depth
        self.op_density = op_density
        self.grid_device_size = grid_device_size
        self.results = []
        self.depth_ratios = []
        # Build grid coupling map
        size = grid_device_size
        edges = []
        for i in range(size):
            for j in range(size):
                idx = i * size + j
                if idx >= qubits:
                    continue
                if i + 1 < size:
                    idx2 = (i + 1) * size + j
                    if idx2 < qubits:
                        edges.append([idx, idx2])
                if j + 1 < size:
                    idx2 = i * size + (j + 1)
                    if idx2 < qubits:
                        edges.append([idx, idx2])
        self.coupling_map = CouplingMap(edges)

    def time_circuit_routing(self, *_):
        circ = random_circuit(self.qubits, self.depth, self.op_density, measure=False)
        orig_depth = circ.depth()
        start = time.perf_counter()
        routed = transpile(circ, coupling_map=self.coupling_map, optimization_level=1, routing_method='sabre')
        end = time.perf_counter()
        routed_depth = routed.depth()
        self.results.append(end - start)
        self.depth_ratios.append(routed_depth / orig_depth if orig_depth > 0 else 0.0)
        return end - start

    def track_routed_circuit_depth_ratio(self, *_) -> float:
        if not self.depth_ratios:
            return 0.0
        return sum(self.depth_ratios) / len(self.depth_ratios)

    def teardown(self, *_):
        for attr in ['qubits', 'depth', 'op_density', 'grid_device_size',
                     'results', 'depth_ratios', 'coupling_map']:
            if hasattr(self, attr):
                delattr(self, attr)","class RouteCQC:
    def __init__(self):
        self.qubits = 0
        self.depth = 0
        self.op_density = 0.0
        self.grid_device_size = 0
        self.circuit = None
        self.routed_circuit = None
        self.original_depth = 0
        self.routed_depth = 0

    def setup(self, qubits: int, depth: int, op_density: float, grid_device_size: int):
        self.qubits = qubits
        self.depth = depth
        self.op_density = op_density
        self.grid_device_size = grid_device_size
        self.circuit = self._generate_random_circuit()
        self.original_depth = depth

    def _generate_random_circuit(self):
        circuit = []
        for _ in range(self.depth):
            layer = []
            for q in range(self.qubits):
                if random.random() < self.op_density:
                    # Generate random single-qubit or two-qubit gate
                    if q < self.qubits - 1 and random.random() < 0.3:
                        # Two-qubit gate
                        layer.append(('CNOT', q, q + 1))
                    else:
                        # Single-qubit gate
                        layer.append(('RX', q, random.random() * 2 * np.pi))
            if layer:
                circuit.append(layer)
        return circuit

    def time_circuit_routing(self, *_):
        if not self.circuit:
            return
            
        # Simulate routing process
        self.routed_circuit = []
        swap_count = 0
        
        # Simple routing simulation - add SWAP gates when needed
        for layer in self.circuit:
            routed_layer = layer.copy()
            # In a real implementation, this would do actual routing
            # For simulation, we just count and add some overhead
            if random.random() < 0.1:  # 10% chance of needing swaps
                swap_count += random.randint(1, 3)
            self.routed_circuit.append(routed_layer)
        
        # Add swap layers
        for _ in range(swap_count):
            if self.routed_circuit:
                self.routed_circuit.append([('SWAP', 0, 1)])  # Simplified
        
        self.routed_depth = len(self.routed_circuit)

    def track_routed_circuit_depth_ratio(self, *_) -> float:
        if self.original_depth == 0:
            return 0.0
        return float(self.routed_depth) / float(self.original_depth)

    def teardown(self, *_):
        self.circuit = None
        self.routed_circuit = None
        self.qubits = 0
        self.depth = 0
        self.op_density = 0.0
        self.grid_device_size = 0
        self.original_depth = 0
        self.routed_depth = 0","class RouteCQC:
    def __init__(self):
        self.original_circuit = None
        self.routed_circuit = None
        self.device_graph = None
        self.original_depth = 0
        self.routed_depth = 0
        self.qubits = 0
        self.depth = 0
        self.op_density = 0.0
        self.grid_size = 0

    def setup(self, qubits: int, depth: int, op_density: float, grid_device_size: int):
        self.qubits = qubits
        self.depth = depth
        self.op_density = op_density
        self.grid_size = grid_device_size
        
        # Create grid device topology
        self.device_graph = nx.grid_2d_graph(grid_device_size, grid_device_size)
        
        # Generate random circuit
        self.original_circuit = self._generate_random_circuit()
        self.original_depth = self._calculate_circuit_depth(self.original_circuit)

    def time_circuit_routing(self, *_):
        # Simple routing algorithm - maps logical qubits to physical qubits
        # and inserts SWAP gates when needed
        self.routed_circuit = self._route_circuit()

    def track_routed_circuit_depth_ratio(self, *_) -> float:
        if self.original_depth == 0:
            return 1.0
        self.routed_depth = self._calculate_circuit_depth(self.routed_circuit)
        return self.routed_depth / self.original_depth

    def teardown(self, *_):
        self.original_circuit = None
        self.routed_circuit = None
        self.device_graph = None
        self.original_depth = 0
        self.routed_depth = 0

    def _generate_random_circuit(self) -> List[List[Tuple]]:
        circuit = [[] for _ in range(self.depth)]
        
        for layer in range(self.depth):
            # Determine number of operations in this layer based on density
            num_ops = int(self.qubits * self.op_density / 2)  # Assuming 2-qubit gates
            
            available_qubits = set(range(self.qubits))
            
            for _ in range(num_ops):
                if len(available_qubits) < 2:
                    break
                
                # Select two random qubits for a 2-qubit gate
                qubit_pair = random.sample(list(available_qubits), 2)
                circuit[layer].append(('CNOT', qubit_pair[0], qubit_pair[1]))
                
                # Remove used qubits from available set
                available_qubits.discard(qubit_pair[0])
                available_qubits.discard(qubit_pair[1])
        
        return circuit

    def _calculate_circuit_depth(self, circuit: List[List[Tuple]]) -> int:
        if not circuit:
            return 0
        return len([layer for layer in circuit if layer])

    def _route_circuit(self) -> List[List[Tuple]]:
        if not self.original_circuit:
            return []
        
        # Simple routing: create initial mapping
        physical_qubits = list(self.device_graph.nodes())[:self.qubits]
        logical_to_physical = {i: physical_qubits[i] for i in range(self.qubits)}
        
        routed_circuit = []
        
        for layer in self.original_circuit:
            routed_layer = []
            
            for gate in layer:
                if len(gate) == 3:  # 2-qubit gate
                    gate_type, q1, q2 = gate
                    phys_q1 = logical_to_physical[q1]
                    phys_q2 = logical_to_physical[q2]
                    
                    # Check if qubits are connected in device topology
                    if self.device_graph.has_edge(phys_q1, phys_q2):
                        routed_layer.append((gate_type, phys_q1, phys_q2))
                    else:
                        # Need to insert SWAP gates - simplified approach
                        # Find shortest path and insert SWAPs
                        try:
                            path = nx.shortest_path(self.device_graph, phys_q1, phys_q2)
                            if len(path) > 2:
                                # Insert SWAP to move qubits closer
                                swap_target = path[1]
                                routed_layer.append(('SWAP', phys_q1, swap_target))
                                # Update mapping
                                for logical, physical in logical_to_physical.items():
                                    if physical == phys_q1:
                                        logical_to_physical[logical] = swap_target
                                    elif physical == swap_target:
                                        logical_to_physical[logical] = phys_q1
                                
                                # Add the original gate with updated mapping
                                routed_layer.append((gate_type, swap_target, phys_q2))
                            else:
                                routed_layer.append((gate_type, phys_q1, phys_q2))
                        except nx.NetworkXNoPath:
                            # If no path exists, just add the gate (shouldn't happen in grid)
                            routed_layer.append((gate_type, phys_q1, phys_q2))
            
            if routed_layer:
                routed_circuit.append(routed_layer)
        
        return routed_circuit",no_docstr,0.40871934604904636,0.2410958904109589,0.17630853994490361,0.31607629427792916,0.3123994012360817,0.5034168564920274,0.2876712328767123,0.21052631578947367,0.7562679052352905,0.801227331161499,0.7780986428260803,0.7964922785758972,0.7337033057851239,0.4043956043956044,0.2693156732891832,0.1729490022172949,0.3076923076923077,0.2781493444399418,0.39824561403508774,0.2601054481546573,0.20774647887323944,0.7826917767524719,0.8262567520141602,0.8038845062255859,0.8216831684112549,0.738595034802784,0.27605633802816903,0.16666666666666666,0.09631728045325778,0.21971830985915497,0.16199180626679477,0.23724007561436672,0.15137180700094607,0.11837121212121213,0.7474018335342407,0.8314824104309082,0.7872033715248108,0.8222325444221497,0.718410776119405,0.2841290787707445,0.0917963840994454,0.1978674411620484,0.5242718446601942,0.3225806451612903,0.2446496372709233,0.0724172392230361,0.2098664544477749,0.5242718446601942,0.1720430107526881,0.3191718102270589,0.0438927049540915,0.2073221484397898,0.5631067961165048,0.4623655913978494
519255,jopohl/urh,jopohl_urh/src/urh/ui/ui_modulation_parameters_dialog.py,urh.ui.ui_modulation_parameters_dialog.Ui_DialogModulationParameters,"class Ui_DialogModulationParameters(object):
    def setupUi(self, DialogModulationParameters):
        DialogModulationParameters.setObjectName(""DialogModulationParameters"")
        DialogModulationParameters.resize(303, 286)
        DialogModulationParameters.setModal(True)
        self.verticalLayout = QtWidgets.QVBoxLayout(DialogModulationParameters)
        self.verticalLayout.setObjectName(""verticalLayout"")
        self.tblSymbolParameters = QtWidgets.QTableWidget(DialogModulationParameters)
        self.tblSymbolParameters.setShowGrid(False)
        self.tblSymbolParameters.setRowCount(2)
        self.tblSymbolParameters.setObjectName(""tblSymbolParameters"")
        self.tblSymbolParameters.setColumnCount(2)
        item = QtWidgets.QTableWidgetItem()
        self.tblSymbolParameters.setHorizontalHeaderItem(0, item)
        item = QtWidgets.QTableWidgetItem()
        self.tblSymbolParameters.setHorizontalHeaderItem(1, item)
        self.tblSymbolParameters.horizontalHeader().setVisible(True)
        self.tblSymbolParameters.verticalHeader().setVisible(False)
        self.verticalLayout.addWidget(self.tblSymbolParameters)
        self.buttonBox = QtWidgets.QDialogButtonBox(DialogModulationParameters)
        self.buttonBox.setStandardButtons(
            QtWidgets.QDialogButtonBox.Cancel | QtWidgets.QDialogButtonBox.Ok
        )
        self.buttonBox.setObjectName(""buttonBox"")
        self.verticalLayout.addWidget(self.buttonBox)

        self.retranslateUi(DialogModulationParameters)

    def retranslateUi(self, DialogModulationParameters):
        _translate = QtCore.QCoreApplication.translate
        DialogModulationParameters.setWindowTitle(
            _translate(""DialogModulationParameters"", ""Modulation Parameters"")
        )
        item = self.tblSymbolParameters.horizontalHeaderItem(0)
        item.setText(_translate(""DialogModulationParameters"", ""Symbol""))
        item = self.tblSymbolParameters.horizontalHeaderItem(1)
        item.setText(_translate(""DialogModulationParameters"", ""Amplitude""))","class Ui_DialogModulationParameters(object):


    def setupUi(self, DialogModulationParameters):
        pass

    def retranslateUi(self, DialogModulationParameters):
        pass

",3,0,snippet_114,1.0,"class Ui_DialogModulationParameters(object):
    def setupUi(self, DialogModulationParameters):
        DialogModulationParameters.setObjectName(""DialogModulationParameters"")
        DialogModulationParameters.resize(320, 150)
        self.gridLayout = QtWidgets.QGridLayout(DialogModulationParameters)
        self.gridLayout.setObjectName(""gridLayout"")

        self.labelType = QtWidgets.QLabel(DialogModulationParameters)
        self.labelType.setObjectName(""labelType"")
        self.gridLayout.addWidget(self.labelType, 0, 0, 1, 1)

        self.comboBoxType = QtWidgets.QComboBox(DialogModulationParameters)
        self.comboBoxType.setObjectName(""comboBoxType"")
        self.comboBoxType.addItem("""")
        self.comboBoxType.addItem("""")
        self.comboBoxType.addItem("""")
        self.gridLayout.addWidget(self.comboBoxType, 0, 1, 1, 1)

        self.labelFrequency = QtWidgets.QLabel(DialogModulationParameters)
        self.labelFrequency.setObjectName(""labelFrequency"")
        self.gridLayout.addWidget(self.labelFrequency, 1, 0, 1, 1)

        self.doubleSpinBoxFrequency = QtWidgets.QDoubleSpinBox(DialogModulationParameters)
        self.doubleSpinBoxFrequency.setObjectName(""doubleSpinBoxFrequency"")
        self.doubleSpinBoxFrequency.setRange(0.0, 1000000.0)
        self.doubleSpinBoxFrequency.setSuffix("" Hz"")
        self.gridLayout.addWidget(self.doubleSpinBoxFrequency, 1, 1, 1, 1)

        self.labelDepth = QtWidgets.QLabel(DialogModulationParameters)
        self.labelDepth.setObjectName(""labelDepth"")
        self.gridLayout.addWidget(self.labelDepth, 2, 0, 1, 1)

        self.doubleSpinBoxDepth = QtWidgets.QDoubleSpinBox(DialogModulationParameters)
        self.doubleSpinBoxDepth.setObjectName(""doubleSpinBoxDepth"")
        self.doubleSpinBoxDepth.setRange(0.0, 100.0)
        self.doubleSpinBoxDepth.setSuffix("" %"")
        self.gridLayout.addWidget(self.doubleSpinBoxDepth, 2, 1, 1, 1)

        self.buttonBox = QtWidgets.QDialogButtonBox(DialogModulationParameters)
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel|QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.gridLayout.addWidget(self.buttonBox, 3, 0, 1, 2)

        self.retranslateUi(DialogModulationParameters)
        self.buttonBox.accepted.connect(DialogModulationParameters.accept)
        self.buttonBox.rejected.connect(DialogModulationParameters.reject)
        QtCore.QMetaObject.connectSlotsByName(DialogModulationParameters)

    def retranslateUi(self, DialogModulationParameters):
        _translate = QtCore.QCoreApplication.translate
        DialogModulationParameters.setWindowTitle(_translate(""DialogModulationParameters"", ""Modulation Parameters""))
        self.labelType.setText(_translate(""DialogModulationParameters"", ""Type:""))
        self.comboBoxType.setItemText(0, _translate(""DialogModulationParameters"", ""AM""))
        self.comboBoxType.setItemText(1, _translate(""DialogModulationParameters"", ""FM""))
        self.comboBoxType.setItemText(2, _translate(""DialogModulationParameters"", ""PM""))
        self.labelFrequency.setText(_translate(""DialogModulationParameters"", ""Frequency:""))
        self.labelDepth.setText(_translate(""DialogModulationParameters"", ""Depth:""))","class Ui_DialogModulationParameters(object):
    def setupUi(self, DialogModulationParameters):
        DialogModulationParameters.setObjectName(""DialogModulationParameters"")
        DialogModulationParameters.resize(400, 300)
        self.buttonBox = QtWidgets.QDialogButtonBox(DialogModulationParameters)
        self.buttonBox.setGeometry(QtCore.QRect(30, 240, 341, 32))
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel|QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.layoutWidget = QtWidgets.QWidget(DialogModulationParameters)
        self.layoutWidget.setGeometry(QtCore.QRect(20, 20, 351, 201))
        self.layoutWidget.setObjectName(""layoutWidget"")
        self.gridLayout = QtWidgets.QGridLayout(self.layoutWidget)
        self.gridLayout.setContentsMargins(0, 0, 0, 0)
        self.gridLayout.setObjectName(""gridLayout"")
        self.labelModulationType = QtWidgets.QLabel(self.layoutWidget)
        self.labelModulationType.setObjectName(""labelModulationType"")
        self.gridLayout.addWidget(self.labelModulationType, 0, 0, 1, 1)
        self.comboBoxModulationType = QtWidgets.QComboBox(self.layoutWidget)
        self.comboBoxModulationType.setObjectName(""comboBoxModulationType"")
        self.comboBoxModulationType.addItem("""")
        self.comboBoxModulationType.addItem("""")
        self.comboBoxModulationType.addItem("""")
        self.gridLayout.addWidget(self.comboBoxModulationType, 0, 1, 1, 1)
        self.labelFrequency = QtWidgets.QLabel(self.layoutWidget)
        self.labelFrequency.setObjectName(""labelFrequency"")
        self.gridLayout.addWidget(self.labelFrequency, 1, 0, 1, 1)
        self.spinBoxFrequency = QtWidgets.QSpinBox(self.layoutWidget)
        self.spinBoxFrequency.setMinimum(1)
        self.spinBoxFrequency.setMaximum(1000000)
        self.spinBoxFrequency.setObjectName(""spinBoxFrequency"")
        self.gridLayout.addWidget(self.spinBoxFrequency, 1, 1, 1, 1)
        self.labelAmplitude = QtWidgets.QLabel(self.layoutWidget)
        self.labelAmplitude.setObjectName(""labelAmplitude"")
        self.gridLayout.addWidget(self.labelAmplitude, 2, 0, 1, 1)
        self.doubleSpinBoxAmplitude = QtWidgets.QDoubleSpinBox(self.layoutWidget)
        self.doubleSpinBoxAmplitude.setMinimum(0.1)
        self.doubleSpinBoxAmplitude.setMaximum(100.0)
        self.doubleSpinBoxAmplitude.setObjectName(""doubleSpinBoxAmplitude"")
        self.gridLayout.addWidget(self.doubleSpinBoxAmplitude, 2, 1, 1, 1)
        self.labelPhase = QtWidgets.QLabel(self.layoutWidget)
        self.labelPhase.setObjectName(""labelPhase"")
        self.gridLayout.addWidget(self.labelPhase, 3, 0, 1, 1)
        self.spinBoxPhase = QtWidgets.QSpinBox(self.layoutWidget)
        self.spinBoxPhase.setMaximum(360)
        self.spinBoxPhase.setObjectName(""spinBoxPhase"")
        self.gridLayout.addWidget(self.spinBoxPhase, 3, 1, 1, 1)

        self.retranslateUi(DialogModulationParameters)
        self.buttonBox.accepted.connect(DialogModulationParameters.accept)
        self.buttonBox.rejected.connect(DialogModulationParameters.reject)
        QtCore.QMetaObject.connectSlotsByName(DialogModulationParameters)

    def retranslateUi(self, DialogModulationParameters):
        _translate = QtCore.QCoreApplication.translate
        DialogModulationParameters.setWindowTitle(_translate(""DialogModulationParameters"", ""Modulation Parameters""))
        self.labelModulationType.setText(_translate(""DialogModulationParameters"", ""Modulation Type:""))
        self.comboBoxModulationType.setItemText(0, _translate(""DialogModulationParameters"", ""Amplitude Modulation""))
        self.comboBoxModulationType.setItemText(1, _translate(""DialogModulationParameters"", ""Frequency Modulation""))
        self.comboBoxModulationType.setItemText(2, _translate(""DialogModulationParameters"", ""Phase Modulation""))
        self.labelFrequency.setText(_translate(""DialogModulationParameters"", ""Carrier Frequency (Hz):""))
        self.labelAmplitude.setText(_translate(""DialogModulationParameters"", ""Amplitude:""))
        self.labelPhase.setText(_translate(""DialogModulationParameters"", ""Phase (degrees):""))","class Ui_DialogModulationParameters(object):
    def setupUi(self, DialogModulationParameters):
        DialogModulationParameters.setObjectName(""DialogModulationParameters"")
        DialogModulationParameters.resize(400, 300)
        DialogModulationParameters.setWindowTitle(""Modulation Parameters"")
        
        self.verticalLayout = QtWidgets.QVBoxLayout(DialogModulationParameters)
        self.verticalLayout.setObjectName(""verticalLayout"")
        
        self.groupBoxModulation = QtWidgets.QGroupBox(DialogModulationParameters)
        self.groupBoxModulation.setObjectName(""groupBoxModulation"")
        self.formLayout = QtWidgets.QFormLayout(self.groupBoxModulation)
        self.formLayout.setObjectName(""formLayout"")
        
        self.labelFrequency = QtWidgets.QLabel(self.groupBoxModulation)
        self.labelFrequency.setObjectName(""labelFrequency"")
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.LabelRole, self.labelFrequency)
        
        self.spinBoxFrequency = QtWidgets.QDoubleSpinBox(self.groupBoxModulation)
        self.spinBoxFrequency.setObjectName(""spinBoxFrequency"")
        self.spinBoxFrequency.setMaximum(999999.99)
        self.spinBoxFrequency.setValue(1000.0)
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.FieldRole, self.spinBoxFrequency)
        
        self.labelAmplitude = QtWidgets.QLabel(self.groupBoxModulation)
        self.labelAmplitude.setObjectName(""labelAmplitude"")
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.LabelRole, self.labelAmplitude)
        
        self.spinBoxAmplitude = QtWidgets.QDoubleSpinBox(self.groupBoxModulation)
        self.spinBoxAmplitude.setObjectName(""spinBoxAmplitude"")
        self.spinBoxAmplitude.setMaximum(100.0)
        self.spinBoxAmplitude.setValue(50.0)
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.FieldRole, self.spinBoxAmplitude)
        
        self.labelPhase = QtWidgets.QLabel(self.groupBoxModulation)
        self.labelPhase.setObjectName(""labelPhase"")
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.LabelRole, self.labelPhase)
        
        self.spinBoxPhase = QtWidgets.QDoubleSpinBox(self.groupBoxModulation)
        self.spinBoxPhase.setObjectName(""spinBoxPhase"")
        self.spinBoxPhase.setMaximum(360.0)
        self.spinBoxPhase.setValue(0.0)
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.FieldRole, self.spinBoxPhase)
        
        self.verticalLayout.addWidget(self.groupBoxModulation)
        
        self.buttonBox = QtWidgets.QDialogButtonBox(DialogModulationParameters)
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel|QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.verticalLayout.addWidget(self.buttonBox)
        
        self.retranslateUi(DialogModulationParameters)
        self.buttonBox.accepted.connect(DialogModulationParameters.accept)
        self.buttonBox.rejected.connect(DialogModulationParameters.reject)
        QtCore.QMetaObject.connectSlotsByName(DialogModulationParameters)

    def retranslateUi(self, DialogModulationParameters):
        _translate = QtCore.QCoreApplication.translate
        DialogModulationParameters.setWindowTitle(_translate(""DialogModulationParameters"", ""Modulation Parameters""))
        self.groupBoxModulation.setTitle(_translate(""DialogModulationParameters"", ""Modulation Settings""))
        self.labelFrequency.setText(_translate(""DialogModulationParameters"", ""Frequency (Hz):""))
        self.labelAmplitude.setText(_translate(""DialogModulationParameters"", ""Amplitude (%):""))
        self.labelPhase.setText(_translate(""DialogModulationParameters"", ""Phase ():""))",no_docstr,0.43842364532019706,0.27722772277227725,0.22388059701492535,0.4236453201970444,0.33264533669268115,0.4304635761589404,0.32172470978441126,0.26578073089701,0.8564221262931824,0.8817083239555359,0.8688812851905823,0.879112720489502,0.8300987864077671,0.36734693877551017,0.22950819672131145,0.18518518518518517,0.3020408163265306,0.25901608809681037,0.3337595907928389,0.25224071702944945,0.2064102564102564,0.8529032468795776,0.8835728764533997,0.8679671287536621,0.8804070949554443,0.792198854961832,0.4539007092198581,0.327790973871734,0.2911694510739857,0.43498817966903075,0.35090125910934117,0.4320388349514563,0.34035656401944897,0.29383116883116883,0.8701810836791992,0.8892802000045776,0.879626989364624,0.8873326182365417,0.824263032659409,0.4300279634159567,0.0985357831228928,0.1878639493288127,0.6761363636363636,0.7575757575757576,0.4359397399649407,0.0754657176016571,0.1878639493288127,0.7329545454545454,0.7474747474747475,0.3746256101458739,0.1405535628141167,0.2348428171633182,0.6988636363636364,0.4242424242424242
838959,yyuu/botornado,yyuu_botornado/boto/s3/user.py,boto.s3.user.User,"class User:
    def __init__(self, parent=None, id='', display_name=''):
        if parent:
            parent.owner = self
        self.type = None
        self.id = id
        self.display_name = display_name

    def startElement(self, name, attrs, connection):
        return None

    def endElement(self, name, value, connection):
        if name == 'DisplayName':
            self.display_name = value
        elif name == 'ID':
            self.id = value
        else:
            setattr(self, name, value)

    def to_xml(self, element_name='Owner'):
        if self.type:
            s = '<%s xsi:type=""%s"">' % (element_name, self.type)
        else:
            s = '<%s>' % element_name
        s += '<ID>%s</ID>' % self.id
        s += '<DisplayName>%s</DisplayName>' % self.display_name
        s += '</%s>' % element_name
        return s","class User:


    def __init__(self, parent=None, id='', display_name=''):
        pass

    def startElement(self, name, attrs, connection):
        pass

    def endElement(self, name, value, connection):
        pass

    def to_xml(self, element_name='Owner'):
        pass

",5,0,snippet_480,0.7272727272727273,"class User:

    def __init__(self, parent=None, id='', display_name=''):
        self.parent = parent
        self.id = id
        self.display_name = display_name
        self._current = None

    def startElement(self, name, attrs, connection):
        if name == 'ID':
            self._current = 'id'
            return self
        if name == 'DisplayName':
            self._current = 'display_name'
            return self
        return None

    def endElement(self, name, value, connection):
        if name == 'ID':
            self.id = value
        elif name == 'DisplayName':
            self.display_name = value
        else:
            if self.parent is not None:
                setattr(self.parent, name, value)
        self._current = None

    def to_xml(self, element_name='Owner'):
        parts = [
            f'<{element_name}>',
            f'<ID>{escape(self.id)}</ID>',
            f'<DisplayName>{escape(self.display_name)}</DisplayName>',
            f'</{element_name}>'
        ]
        return ''.join(parts)","class User:
    def __init__(self, parent=None, id='', display_name=''):
        self.parent = parent
        self.id = id
        self.display_name = display_name

    def startElement(self, name, attrs, connection):
        pass

    def endElement(self, name, value, connection):
        if name == 'ID':
            self.id = value
        elif name == 'DisplayName':
            self.display_name = value

    def to_xml(self, element_name='Owner'):
        xml = f'<{element_name}>'
        if self.id:
            xml += f'<ID>{self.id}</ID>'
        if self.display_name:
            xml += f'<DisplayName>{self.display_name}</DisplayName>'
        xml += f'</{element_name}>'
        return xml","class User:
    def __init__(self, parent=None, id='', display_name=''):
        self.parent = parent
        self.id = id
        self.display_name = display_name

    def startElement(self, name, attrs, connection):
        return None

    def endElement(self, name, value, connection):
        if name == 'ID':
            self.id = value
        elif name == 'DisplayName':
            self.display_name = value

    def to_xml(self, element_name='Owner'):
        xml = f'<{element_name}>'
        if self.id:
            xml += f'<ID>{self.id}</ID>'
        if self.display_name:
            xml += f'<DisplayName>{self.display_name}</DisplayName>'
        xml += f'</{element_name}>'
        return xml",no_docstr,0.7570093457943925,0.5754716981132075,0.4000000000000001,0.616822429906542,0.6062136019289129,0.756198347107438,0.5892116182572614,0.5,0.88643479347229,0.8782947063446045,0.882345974445343,0.8791019320487976,0.8225326388888888,0.7783783783783783,0.644808743169399,0.49723756906077343,0.6702702702702702,0.5769509035901096,0.8913043478260869,0.726775956284153,0.6098901098901099,0.9212855100631714,0.8858479261398315,0.9032192230224609,0.8892685770988464,0.8775906779661017,0.7956989247311828,0.6739130434782609,0.5384615384615384,0.6881720430107526,0.5913010720025312,0.8972972972972973,0.7391304347826086,0.6284153005464481,0.9257022142410278,0.8910151124000549,0.9080275297164917,0.8943663835525513,0.8813571186440677,0.6088328382758099,0.4224225554418326,0.4547692627776863,0.5581395348837209,0.0,0.3914587840792894,0.3849135871791407,0.4195704970892904,0.5232558139534884,0.238095238095238,0.4250651002996625,0.430040449283127,0.4739851789365641,0.5581395348837209,0.238095238095238
632236,pantsbuild/pex,pantsbuild_pex/pex/vendor/_vendored/pip/pip/_internal/req/__init__.py,pex.vendor._vendored.pip.pip._internal.req.InstallationResult,"class InstallationResult(object):
    def __init__(self, name):
        # type: (str) -> None
        self.name = name

    def __repr__(self):
        # type: () -> str
        return ""InstallationResult(name={!r})"".format(self.name)","class InstallationResult(object):


    def __init__(self, name):
        pass

    def __repr__(self):
        pass

",3,0,snippet_227,1.0,"class InstallationResult(object):
    def __init__(self, name):
        self.name = name

    def __repr__(self):
        return f""{self.__class__.__name__}(name={self.name!r})""","class InstallationResult(object):
    def __init__(self, name):
        self.name = name
        self.success = False
        self.message = """"
        self.details = {}

    def __repr__(self):
        return f""InstallationResult(name='{self.name}', success={self.success}, message='{self.message}')""","class InstallationResult(object):

    def __init__(self, name):
        self.name = name

    def __repr__(self):
        return f""InstallationResult(name='{self.name}')""",no_docstr,0.7659574468085107,0.5777777777777778,0.4186046511627907,0.7234042553191491,0.601305757589373,0.765625,0.6507936507936508,0.5806451612903226,0.9292813539505005,0.8619788885116577,0.8943657875061035,0.868267297744751,0.8833344999999999,0.631578947368421,0.43636363636363634,0.26415094339622636,0.631578947368421,0.46582898317993354,0.5647058823529412,0.4642857142857143,0.3855421686746988,0.8960011005401611,0.8535533547401428,0.8742623329162598,0.8576162457466125,0.8042347619047618,0.8181818181818181,0.619047619047619,0.45,0.8181818181818181,0.5380404983178323,0.94,0.7959183673469388,0.7083333333333334,0.9554303884506226,0.8541069030761719,0.901931881904602,0.863261878490448,0.9099108108108108,0.4557069193146986,0.282200188850411,0.3526575635963537,0.4736842105263157,0.7142857142857143,0.3934753708284983,0.2320305803246989,0.2591641360720011,0.3684210526315789,0.7142857142857143,0.4557069193146986,0.282200188850411,0.3526575635963537,0.4736842105263157,0.7142857142857143
383519,fedora-infra/fedmsg_meta_fedora_infrastructure,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/fedora-infra_fedmsg_meta_fedora_infrastructure/fedmsg_meta_fedora_infrastructure/fasshim.py,fedmsg_meta_fedora_infrastructure.fasshim.make_fasjson_cache.Client,"class Client(object):
    def __init__(self, url, principal=None):
        self.url = url.rstrip(""/"") + ""/v1/""
        self.principal = principal

        gssapi_auth = HTTPSPNEGOAuth(
            opportunistic_auth=True, mutual_authentication=""OPTIONAL""
        )
        self.session = requests.Session()
        self.session.auth = gssapi_auth

    def list_all_entities(self, ent_name):
        if not ent_name.endswith(""/""):
            # avoid redirection round trip
            ent_name += ""/""
        endpoint = urljoin(self.url, ent_name)

        # yay, pagination
        next_page_url = endpoint + ""?"" + urlencode({""page_number"": 1})
        while next_page_url:
            res = self.session.get(next_page_url)
            for item in res[""result""]:
                yield item
            next_page_url = res.get(""page"", {}).get(""next_page"")
","class Client(object):


    def __init__(self, url, principal=None):
        pass


    def list_all_entities(self, ent_name):
        pass

",3,0,snippet_4,0.2727272727272727,"class Client(object):
    def __init__(self, url, principal=None):
        self.base_url = url.rstrip('/')
        self.session = requests.Session()
        if isinstance(principal, tuple) and len(principal) == 2:
            self.session.auth = principal
        elif isinstance(principal, str):
            self.session.headers.update({'Authorization': f'Bearer {principal}'})

    def list_all_entities(self, ent_name):
        results = []
        next_url = f""{self.base_url}/{ent_name.lstrip('/')}""
        while next_url:
            resp = self.session.get(next_url)
            resp.raise_for_status()
            data = resp.json()

            # Hydra style
            if isinstance(data, dict) and 'hydra:member' in data:
                members = data['hydra:member']
            # Generic items field
            elif isinstance(data, dict) and 'items' in data:
                members = data['items']
            # Direct list
            elif isinstance(data, list):
                members = data
            else:
                raise ValueError(""Unsupported response format for listing entities"")

            results.extend(members)

            # Check HTTP Link header
            link_next = resp.links.get('next', {}).get('url')
            if link_next:
                next_url = link_next
                continue

            # Check Hydra pagination
            view = data.get('hydra:view', {})
            hydra_next = view.get('hydra:next')
            if hydra_next:
                next_url = hydra_next if hydra_next.startswith('http') else self.base_url + hydra_next
            else:
                next_url = None

        return results","class Client(object):
    def __init__(self, url, principal=None):
        self.url = url
        self.principal = principal
        self.entities = {}

    def list_all_entities(self, ent_name):
        if ent_name in self.entities:
            return self.entities[ent_name]
        else:
            return []","class Client(object):

    def __init__(self, url, principal=None):
        self.url = url.rstrip('/')
        self.principal = principal
        self.session = requests.Session()
        if principal:
            self.session.headers.update({'Authorization': f'Bearer {principal}'})

    def list_all_entities(self, ent_name):
        endpoint = f""{self.url}/entities/{ent_name}""
        try:
            response = self.session.get(endpoint)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            raise Exception(f""Failed to list entities: {str(e)}"")",no_docstr,0.381294964028777,0.2101449275362319,0.145985401459854,0.33093525179856115,0.28571146818403087,0.4376731301939058,0.26944444444444443,0.1977715877437326,0.7517191767692566,0.7963404655456543,0.7733867168426514,0.7916414141654968,0.7685798089171978,0.46616541353383467,0.33587786259541985,0.26356589147286824,0.43609022556390975,0.10166226387513629,0.8947368421052632,0.7066666666666667,0.5945945945945946,0.8895588517189026,0.6715844869613647,0.7653542757034302,0.6884541511535645,0.7551813559322034,0.4761904761904762,0.34939759036144585,0.25609756097560976,0.45238095238095233,0.3330612299994324,0.7243589743589743,0.47096774193548385,0.3961038961038961,0.820671558380127,0.7538528442382812,0.7858443856239319,0.7600411176681519,0.7758967796610173,0.2963171214807414,0.0662592010224894,0.1362506642108209,0.5,0.4827586206896552,0.1464447187643539,0.0829727744358248,0.164875066138832,0.2,0.1379310344827586,0.2666265765790629,0.1379758338531687,0.1626300893213208,0.4555555555555555,0.3103448275862069
486792,hydraplatform/hydra-base,hydraplatform_hydra-base/hydra_base/lib/HydraTypes/Encodings.py,hydra_base.lib.HydraTypes.Encodings.DataframeJSON,"class DataframeJSON(object):
    def __get__(self, instance, owner):
        return ""{}""

    def __set__(self, instance, encstr):
        pass","class DataframeJSON(object):


    def __get__(self, instance, owner):
        pass

    def __set__(self, instance, encstr):
        pass

",3,0,snippet_356,1.0,"class DataframeJSON(object):
    def __set_name__(self, owner, name):
        self.name = name
        self.private_name = '_' + name

    def __get__(self, instance, owner):
        if instance is None:
            return self
        val = instance.__dict__.get(self.private_name, None)
        if isinstance(val, str):
            df = pd.read_json(val)
            instance.__dict__[self.private_name] = df
            return df
        return val

    def __set__(self, instance, encstr):
        if isinstance(encstr, str):
            df = pd.read_json(encstr)
        elif isinstance(encstr, pd.DataFrame):
            df = encstr
        else:
            raise TypeError(""Value must be a JSON string or a pandas DataFrame"")
        instance.__dict__[self.private_name] = df","class DataframeJSON(object):
    
    def __init__(self, name):
        self.name = name

    def __get__(self, instance, owner):
        if instance is None:
            return self
        data = instance.__dict__.get(self.name)
        if data is not None:
            return pd.DataFrame(data)
        return None

    def __set__(self, instance, encstr):
        if encstr is None:
            instance.__dict__[self.name] = None
        else:
            if isinstance(encstr, pd.DataFrame):
                instance.__dict__[self.name] = encstr.to_dict('records')
            elif isinstance(encstr, str):
                instance.__dict__[self.name] = json.loads(encstr)
            else:
                instance.__dict__[self.name] = encstr","class DataframeJSON(object):
    def __init__(self, name=None):
        self.name = name

    def __get__(self, instance, owner):
        if instance is None:
            return self
        return getattr(instance, self.name, None)

    def __set__(self, instance, encstr):
        if isinstance(encstr, str):
            df = pd.read_json(encstr)
        elif isinstance(encstr, pd.DataFrame):
            df = encstr
        else:
            df = pd.DataFrame(encstr)
        setattr(instance, self.name, df)

    def __set_name__(self, owner, name):
        self.name = f'_{name}'",no_docstr,0.25688073394495414,0.20560747663551404,0.1523809523809524,0.25688073394495414,0.17456443463603263,0.19289340101522842,0.17346938775510204,0.15897435897435896,0.6229853630065918,0.8433801531791687,0.7166200876235962,0.8145632147789001,0.7222250000000002,0.2857142857142857,0.22916666666666669,0.1702127659574468,0.2857142857142857,0.18262805344019373,0.1945945945945946,0.18478260869565216,0.16939890710382513,0.6349725723266602,0.8472516536712646,0.7259112000465393,0.8198432326316833,0.7152806250000002,0.33333333333333337,0.2682926829268293,0.19999999999999998,0.33333333333333337,0.23118143915295292,0.2550335570469799,0.22972972972972974,0.2108843537414966,0.6894345283508301,0.8600215315818787,0.7653376460075378,0.8392558097839355,0.7264984615384614,0.4642121656243539,0.0772655986892868,0.4718907561158214,0.3076923076923077,1.0,0.4065002192155066,0.0964178130538972,0.4718907561158214,0.3076923076923077,0.75,0.3276346756147821,0.1078787155740764,0.4718907561158214,0.2307692307692307,0.5
605786,oblalex/isotopic-logging,oblalex_isotopic-logging/isotopic_logging/context.py,isotopic_logging.context.InjectionContext,"class InjectionContext(object):

    _old_enter_time = None

    def __init__(self, injector, inherit=False):
        if _stack.is_empty:
            if callable(injector):
                injector = injector()

            self._push(injector)
        elif inherit:
            if callable(injector):
                injector = injector()

            injector = merge_injectors(_stack.top.injector, injector)
            self._push(injector)

    def _push(self, injector):
        item = StackItem(injector, self)
        _stack.push(item)

    def __enter__(self):
        inj = _stack.top.injector
        self._old_enter_time, inj.enter_time = inj.enter_time, time.time()
        return inj

    def __exit__(self, exc_type, value, traceback):
        item = _stack.top

        inj = item.injector
        inj.enter_time, self._old_enter_time = self._old_enter_time, None

        if item.parent is self:
            _stack.pop()","class InjectionContext(object):


    def __init__(self, injector, inherit=False):
        pass

    def _push(self, injector):
        pass

    def __enter__(self):
        pass

    def __exit__(self, exc_type, value, traceback):
        pass

",5,0,snippet_640,0.1428571428571428,"class InjectionContext(object):
    def __init__(self, injector, inherit=False):
        self.injector = injector
        self.inherit = inherit
        self._previous = None

    def _push(self, injector):
        prev = getattr(_thread_local, 'current_injector', None)
        if self.inherit and prev is not None:
            if hasattr(injector, 'set_parent'):
                injector.set_parent(prev)
            elif hasattr(injector, 'parent'):
                try:
                    setattr(injector, 'parent', prev)
                except Exception:
                    pass
        _thread_local.current_injector = injector
        return prev

    def __enter__(self):
        self._previous = self._push(self.injector)
        return self.injector

    def __exit__(self, exc_type, value, traceback):
        if hasattr(_thread_local, 'current_injector'):
            _thread_local.current_injector = self._previous
        self._previous = None","class InjectionContext(object):
    def __init__(self, injector, inherit=False):
        self.injector = injector
        self.inherit = inherit
        self.previous_context = None

    def _push(self, injector):
        self.previous_context = self.injector.get_current_context()
        self.injector.set_current_context(self)

    def __enter__(self):
        if self.inherit and self.previous_context is not None:
            self._push(self.injector)
        else:
            self._push(self.injector)
        return self

    def __exit__(self, exc_type, value, traceback):
        if self.previous_context is not None:
            self.injector.set_current_context(self.previous_context)
        else:
            self.injector.set_current_context(None)","class InjectionContext(object):
    _stack = []

    def __init__(self, injector, inherit=False):
        self.injector = injector
        self.inherit = inherit
        self.previous_injector = None

    def _push(self, injector):
        if self._stack:
            self._stack.append(injector)
        else:
            self._stack.append(injector)

    def __enter__(self):
        if self._stack and self.inherit:
            self.previous_injector = self._stack[-1]
        else:
            self.previous_injector = None
        
        self._stack.append(self.injector)
        return self

    def __exit__(self, exc_type, value, traceback):
        if self._stack:
            self._stack.pop()",no_docstr,0.5268292682926828,0.25615763546798026,0.13930348258706465,0.3902439024390244,0.4302385213075177,0.7586206896551724,0.47029702970297027,0.3333333333333333,0.8315736055374146,0.8328342437744141,0.8322034478187561,0.8327080011367798,0.7621746629213488,0.4897959183673469,0.24742268041237114,0.14583333333333334,0.3775510204081633,0.3865653955347738,0.7637362637362637,0.46408839779005523,0.3611111111111111,0.8307284712791443,0.804340124130249,0.8173213005065918,0.8069032430648804,0.8127359550561798,0.5714285714285714,0.28888888888888886,0.1797752808988764,0.43956043956043955,0.4160607372364095,0.8323353293413174,0.6024096385542169,0.4484848484848485,0.8681368827819824,0.8179625272750854,0.8423031568527222,0.8227174878120422,0.7958821910112361,0.2360910772840511,0.1433103905287394,0.1560322735858202,0.3571428571428571,0.2878787878787879,0.2406086450101285,0.1259170500108666,0.146041339553457,0.3571428571428571,0.3333333333333333,0.1934201408271084,0.1304055495174053,0.149768520284535,0.3571428571428571,0.1363636363636363
531341,kevinpt/syntrax,kevinpt_syntrax/syntrax.py,syntrax.DrawStyle,"class DrawStyle(object):
  def __init__(self, styles=None, node_styles=[]):
    # Set defaults
    self.line_width = 2
    self.line_color = (0,0,0)
    self.outline_width = 2
    self.padding = 5
    self.max_radius = 9
    self.h_sep = 17
    self.v_sep = 9
    self.arrows = True
    self.title_pos = 'tl'
    self.bullet_fill = (255,255,255)
    self.text_color = (0,0,0)
    self.shadow = True
    self.shadow_fill = (0,0,0, 127)
    self.title_font = ('Sans', 22, 'bold')

    # Load any styles
    if styles is None:
      styles = {}

    for k,v in styles.iteritems():
      if hasattr(self, k):
        # Check for color styles
        if k.endswith('_fill') or k.endswith('_color'):
          v = convert_color(v)

        setattr(self, k, v)

    # Set node style defaults
    if len(node_styles) == 0:
      node_styles = [
        ('bubble', {'shape':'bubble', 'pattern':'^\w', 'font':('Sans', 14, 'bold'), 'fill':(179, 229, 252)}),
        ('box', {'shape':'box', 'pattern':'^/', 'font':('Times', 14, 'italic'),
                'fill':(144, 164, 174), 'text_mod':'lambda txt: txt[1:]'}),
        ('token', {'shape':'bubble', 'pattern':'.', 'font':('Sans', 16, 'bold'), 'fill':(179, 229, 252)}),
      ]

    for _, ns in node_styles:
      if 'text_color' not in ns:
        ns['text_color'] = self.text_color

    # Init node styles
    self.node_styles = [NodeStyle(name, ns) for name,ns in node_styles]

  def __repr__(self):
    keys = ('line_width',
      'outline_width',
      'padding',
      'line_color',
      'max_radius',
      'h_sep',
      'v_sep',
      'arrows',
      'title_pos',
      'bullet_fill',
      'text_color',
      'shadow',
      'shadow_fill',
      'title_font')

    ini_keys = ['{} = {}'.format(k, repr(getattr(self, k))) for k in keys]

    return '[style]\n{}\n'.format('\n'.join(ini_keys))","class DrawStyle(object):


  def __init__(self, styles=None, node_styles=[]):
    pass

  def __repr__(self):
    pass

",3,0,snippet_134,0.1739130434782608,"class DrawStyle(object):
    def __init__(self, styles=None, node_styles=[]):
        # Initialize styles dictionary
        if styles is None:
            self.styles = {}
        elif isinstance(styles, dict):
            self.styles = styles.copy()
        else:
            try:
                self.styles = dict(styles)
            except Exception:
                raise TypeError(""styles must be a dict or iterable of key/value pairs"")

        # Initialize node_styles list of dicts
        self.node_styles = []
        for ns in node_styles:
            if isinstance(ns, dict):
                self.node_styles.append(ns.copy())
            else:
                try:
                    self.node_styles.append(dict(ns))
                except Exception:
                    raise TypeError(""each node_style must be a dict or iterable of key/value pairs"")

    def __repr__(self):
        return ""{}(styles={!r}, node_styles={!r})"".format(
            self.__class__.__name__, self.styles, self.node_styles
        )","class DrawStyle(object):
    def __init__(self, styles=None, node_styles=[]):
        self.styles = styles if styles is not None else {}
        self.node_styles = node_styles.copy() if node_styles else []

    def __repr__(self):
        return f""DrawStyle(styles={self.styles}, node_styles={self.node_styles})""","class DrawStyle(object):

    def __init__(self, styles=None, node_styles=[]):
        self.styles = styles if styles is not None else {}
        self.node_styles = node_styles[:]

    def __repr__(self):
        return f""DrawStyle(styles={self.styles}, node_styles={self.node_styles})""",no_docstr,0.30136986301369867,0.1542699724517906,0.09418282548476455,0.24109589041095894,0.11482284740636214,0.7100840336134454,0.37130801687763715,0.23728813559322035,0.7563647031784058,0.7037582993507385,0.729113757610321,0.7086873650550842,0.7086643307086613,0.25938566552901027,0.1443298969072165,0.09688581314878891,0.20477815699658702,0.007255840351220026,0.9278350515463918,0.6666666666666666,0.49473684210526314,0.8073224425315857,0.6074420809745789,0.69326251745224,0.6228631734848022,0.692916456692913,0.24305555555555555,0.14685314685314685,0.11267605633802817,0.19444444444444445,0.004571377684216539,0.9438202247191011,0.6931818181818182,0.5287356321839081,0.8245963454246521,0.6051545143127441,0.6980351805686951,0.6216991543769836,0.6916041338582674,0.3872219512282501,0.0445604026614185,0.0751036579593442,0.4292237442922374,0.0,0.299714997578294,0.0011137553468802,0.0516275135051088,0.1461187214611872,0.0,0.2968694550758969,0.0004224136274951,0.0500691053062295,0.136986301369863,0.0
817239,vaexio/vaex,vaexio_vaex/benchmarks/groupbyh2o.py,benchmarks.groupbyh2o.GroupBySetup,"class GroupBySetup:
    pretty_name = ""Groupby benchmarks - H2O inspired""
    version = ""1""

    params = ([10**7, 5*10**7, 10**8],)
    param_names = ['N']

    def setup_cache(self):
        # ensure the dataframe is generated
        generate_numerical()

    def setup(self, N):
        df = self.df = vaex.open(generate_numerical())[:N]
        df['id1'] = df['i1_100']
        df['id2'] = df['i1_100']
        df['id3'] = df['i4_1M']
        df['id4'] = df['i1_100']
        df['id5'] = df['i1_100']
        df['id6'] = df['i4_1M']
        df['v1'] = df['i1_10']
        df['v2'] = df['i1_10']
        df['v3'] = df['x4']","class GroupBySetup:


    def setup_cache(self):
        pass

    def setup_cache(self):
        pass

",3,0,snippet_428,1.0,"class GroupBySetup:
    def __init__(self, cache_dir='groupby_cache'):
        self.cache_dir = cache_dir
        self._lock = RLock()
        self._memory = {}
        os.makedirs(self.cache_dir, exist_ok=True)

    def setup_cache(self, key=None, func=None, use_disk=False):
        """"""
        If called with no arguments, clears both in-memory and on-disk cache.
        If called with key and func, computes func(), caches it under key and returns it.
        If use_disk=True, also writes to disk.
        """"""
        with self._lock:
            if key is None and func is None:
                # clear all caches
                self._memory.clear()
                for fname in os.listdir(self.cache_dir):
                    try:
                        os.remove(os.path.join(self.cache_dir, fname))
                    except OSError:
                        pass
                return

            if key in self._memory:
                return self._memory[key]

            path = os.path.join(self.cache_dir, f'{key!r}.pkl')
            if use_disk and os.path.exists(path):
                with open(path, 'rb') as f:
                    result = pickle.load(f)
                self._memory[key] = result
                return result

            # compute, cache in memory, optionally on disk
            result = func()
            self._memory[key] = result
            if use_disk:
                with open(path, 'wb') as f:
                    pickle.dump(result, f)
            return result

    def setup_cache(self):
        """"""
        Alias: clears both in-memory and on-disk cache.
        """"""
        return self.setup_cache(key=None, func=None)","class GroupBySetup:
    def setup_cache(self):
        pass","class GroupBySetup:
    def __init__(self):
        self.cache = {}
        self.data = []
    
    def setup_cache(self):
        self.cache.clear()
        for item in self.data:
            key = self._get_group_key(item)
            if key not in self.cache:
                self.cache[key] = []
            self.cache[key].append(item)
    
    def _get_group_key(self, item):
        return item",no_docstr,0.08843537414965986,0.03424657534246575,0.013793103448275862,0.08163265306122448,0.06952150822764339,0.19946091644204852,0.062162162162162166,0.02710027100271003,0.6312073469161987,0.6403610110282898,0.6357512474060059,0.639433741569519,0.7086448888888892,0.1263157894736842,0.08602150537634408,0.04395604395604395,0.1263157894736842,2.3190469853243255e-07,0.9230769230769231,0.8333333333333334,0.7272727272727273,0.8039305806159973,0.541519045829773,0.6471349000930786,0.5597911477088928,0.681521336633665,0.13138686131386862,0.05925925925925926,0.030075187969924814,0.13138686131386862,0.09130708561512413,0.5,0.1941747572815534,0.10784313725490197,0.7535792589187622,0.6469203233718872,0.6961883306503296,0.6562080383300781,0.7112240099009908,0.1111001287466279,0.0050866299313582,0.0134295019662837,0.2947368421052631,0.1311475409836065,0.2552801049450776,1.2058750201177545e-06,0.0105928981158167,0.0105263157894736,0.0,0.2709099482256554,0.0082983353333544,0.0121835628324249,0.0631578947368421,0.0
470709,huge-success/sanic,huge-success_sanic/sanic/touchup/service.py,sanic.touchup.service.TouchUp,"class TouchUp:
    _registry: set[tuple[type, str]] = set()

    @classmethod
    def run(cls, app):
        for target, method_name in cls._registry:
            method = getattr(target, method_name)

            if app.test_mode:
                placeholder = f""_{method_name}""
                if hasattr(target, placeholder):
                    method = getattr(target, placeholder)
                else:
                    setattr(target, placeholder, method)

            module = getmodule(target)
            module_globals = dict(getmembers(module))
            modified = BaseScheme.build(method, module_globals, app)
            setattr(target, method_name, modified)

            target.__touched__ = True

    @classmethod
    def register(cls, target, method_name):
        cls._registry.add((target, method_name))","class TouchUp:


    @classmethod
    def run(cls, app):
        pass

    @classmethod
    def register(cls, target, method_name):
        pass

",5,0,snippet_429,0.2222222222222222,"class TouchUp:
    _registry = []

    @classmethod
    def register(cls, target, method_name):
        """"""
        Register a callback method by specifying the target (object or class)
        and the name of the method (string) to be called later.
        """"""
        cls._registry.append((target, method_name))

    @classmethod
    def run(cls, app):
        """"""
        Invoke all registered methods, passing the `app` argument to each.
        """"""
        for target, method_name in cls._registry:
            method = getattr(target, method_name, None)
            if callable(method):
                method(app)","class TouchUp:
    _registry = {}

    @classmethod
    def run(cls, app):
        if app in cls._registry:
            for target, method_name in cls._registry[app]:
                method = getattr(target, method_name)
                method()

    @classmethod
    def register(cls, target, method_name):
        app = getattr(target, '__app__', None)
        if app is None:
            raise ValueError(""Target must have an '__app__' attribute"")
        
        if app not in cls._registry:
            cls._registry[app] = []
        
        cls._registry[app].append((target, method_name))","class TouchUp:
    _registered_methods = {}

    @classmethod
    def run(cls, app):
        for target, method_name in cls._registered_methods.items():
            if hasattr(target, method_name):
                method = getattr(target, method_name)
                if callable(method):
                    method(app)

    @classmethod
    def register(cls, target, method_name):
        cls._registered_methods[target] = method_name",no_docstr,0.5359477124183006,0.3443708609271523,0.26845637583892623,0.3529411764705882,0.3898028824952007,0.6888888888888889,0.5,0.42105263157894735,0.8041532039642334,0.7950736284255981,0.7995876669883728,0.7959724068641663,0.7460342857142856,0.5369127516778522,0.36734693877551017,0.24827586206896554,0.44295302013422816,0.4437737156429022,0.7448275862068966,0.5138888888888888,0.42657342657342656,0.8630177974700928,0.799508810043335,0.8300502896308899,0.8054359555244446,0.7573720408163265,0.59375,0.46031746031746035,0.3548387096774194,0.515625,0.3183235908328553,0.9166666666666666,0.7157894736842105,0.5957446808510638,0.8846431374549866,0.7778563499450684,0.8278201222419739,0.7873607277870178,0.793652857142857,0.2447235194684942,0.2101308904247493,0.2437631874492274,0.275,0.25,0.2464758551282737,0.2013067490727424,0.2167395285832097,0.3,0.2678571428571428,0.2697359696944846,0.1981552470803639,0.2700743459832888,0.325,0.2857142857142857
251577,aws/aws-iot-device-sdk-python,aws_aws-iot-device-sdk-python/samples/basicPubSub/basicPubSub_APICallInCallback.py,basicPubSub_APICallInCallback.CallbackContainer,"class CallbackContainer(object):

    def __init__(self, client):
        self._client = client

    def messagePrint(self, client, userdata, message):
        print(""Received a new message: "")
        print(message.payload)
        print(""from topic: "")
        print(message.topic)
        print(""--------------\n\n"")

    def messageForward(self, client, userdata, message):
        topicRepublish = message.topic + ""/republish""
        print(""Forwarding message from: %s to %s"" % (message.topic, topicRepublish))
        print(""--------------\n\n"")
        self._client.publishAsync(topicRepublish, str(message.payload), 1, self.pubackCallback)

    def pubackCallback(self, mid):
        print(""Received PUBACK packet id: "")
        print(mid)
        print(""++++++++++++++\n\n"")

    def subackCallback(self, mid, data):
        print(""Received SUBACK packet id: "")
        print(mid)
        print(""Granted QoS: "")
        print(data)
        print(""++++++++++++++\n\n"")","class CallbackContainer(object):


    def __init__(self, client):
        pass

    def messagePrint(self, client, userdata, message):
        pass

    def messageForward(self, client, userdata, message):
        pass

    def pubackCallback(self, mid):
        pass

    def subackCallback(self, mid, data):
        pass

",6,0,snippet_161,1.0,"class CallbackContainer(object):
    def __init__(self, client):
        self.client = client

    def messagePrint(self, client, userdata, message):
        try:
            text = message.payload.decode('utf-8')
        except Exception:
            text = message.payload
        print(f""Received on topic '{message.topic}': {text}"")

    def messageForward(self, client, userdata, message):
        forward_topic = f""forward/{message.topic}""
        client.publish(forward_topic, message.payload, qos=message.qos)
        print(f""Forwarded message from '{message.topic}' to '{forward_topic}'"")

    def pubackCallback(self, mid):
        print(f""Publish acknowledged, message ID: {mid}"")

    def subackCallback(self, mid, data):
        print(f""Subscribe acknowledged, message ID: {mid}, granted QoS: {data}"")","class CallbackContainer(object):
    def __init__(self, client):
        self.client = client
        self.message_handlers = []

    def messagePrint(self, client, userdata, message):
        print(f""Received message on topic {message.topic}: {message.payload.decode()}"")

    def messageForward(self, client, userdata, message):
        # Forward message to all registered handlers
        for handler in self.message_handlers:
            try:
                handler(client, userdata, message)
            except Exception as e:
                print(f""Error in message handler: {e}"")

    def pubackCallback(self, mid):
        print(f""Publish acknowledged for message ID: {mid}"")

    def subackCallback(self, mid, data):
        print(f""Subscribe acknowledged for message ID: {mid}, QoS levels: {data}"")","class CallbackContainer(object):

    def __init__(self, client):
        self.client = client
        self.callbacks = {}
        self.forward_topic = None
        self.forward_client = None

    def messagePrint(self, client, userdata, message):
        print(f""Topic: {message.topic}"")
        print(f""Payload: {message.payload.decode('utf-8')}"")
        print(f""QoS: {message.qos}"")
        print(f""Retain: {message.retain}"")

    def messageForward(self, client, userdata, message):
        if self.forward_client and self.forward_topic:
            self.forward_client.publish(self.forward_topic, message.payload, message.qos, message.retain)

    def pubackCallback(self, mid):
        if mid in self.callbacks:
            callback = self.callbacks.pop(mid)
            if callback:
                callback(mid)

    def subackCallback(self, mid, data):
        if mid in self.callbacks:
            callback = self.callbacks.pop(mid)
            if callback:
                callback(mid, data)",no_docstr,0.6113989637305699,0.3979057591623037,0.2751322751322752,0.5595854922279794,0.36170691590258297,0.678391959798995,0.4595959595959596,0.36548223350253806,0.877991795539856,0.8511608242988586,0.8643681406974792,0.8537698984146118,0.7933354,0.5833333333333334,0.3263157894736842,0.2553191489361702,0.5208333333333334,0.32087802112977687,0.6961325966850829,0.45,0.3743016759776536,0.8526338338851929,0.8325809240341187,0.8424880504608154,0.8345437049865723,0.77500225,0.5140186915887851,0.3018867924528302,0.21904761904761907,0.4392523364485982,0.38511650374277306,0.5991379310344828,0.4155844155844156,0.3173913043478261,0.8310041427612305,0.8062403798103333,0.81843501329422,0.8086501955986023,0.7651911822660099,0.3085888486744821,0.2237110163367941,0.2447184524352083,0.34,0.4259259259259259,0.2604639883718726,0.198827271391983,0.2171027561695814,0.2,0.4259259259259259,0.3456534840435412,0.1950790825880656,0.2149422609935066,0.38,0.5925925925925926
817555,vaexio/vaex,vaexio_vaex/packages/vaex-core/vaex/encoding.py,vaex.encoding.vaex_evaluate_results_encoding,"class vaex_evaluate_results_encoding:
    @classmethod
    def encode(cls, encoding, result):
        if isinstance(result, (list, tuple)):
            return [cls.encode(encoding, k) for k in result]
        else:
           return encoding.encode('array', result)

    @classmethod
    def decode(cls, encoding, result_encoded):
        if isinstance(result_encoded, (list, tuple)):
            return [cls.decode(encoding, k) for k in result_encoded]
        else:
            return encoding.decode('array', result_encoded)","class vaex_evaluate_results_encoding:


    @classmethod
    def encode(cls, encoding, result):
        pass

    @classmethod
    def decode(cls, encoding, result_encoded):
        pass

",5,0,snippet_108,0.2,"class vaex_evaluate_results_encoding:

    @classmethod
    def encode(cls, encoding, result):
        if encoding in (None, 'none'):
            return result
        if encoding in ('pickle', 'binary'):
            return pickle.dumps(result)
        if encoding == 'json':
            def _encode(obj):
                if isinstance(obj, np.ndarray):
                    data = base64.b64encode(obj.tobytes()).decode('ascii')
                    return {'__ndarray__': True, 'data': data, 'dtype': str(obj.dtype), 'shape': obj.shape}
                if isinstance(obj, (np.integer,)):
                    return int(obj)
                if isinstance(obj, (np.floating,)):
                    return float(obj)
                if isinstance(obj, dict):
                    return {k: _encode(v) for k, v in obj.items()}
                if isinstance(obj, (list, tuple)):
                    return [_encode(v) for v in obj]
                return obj
            return json.dumps(_encode(result))
        raise ValueError(f""Unknown encoding: {encoding}"")

    @classmethod
    def decode(cls, encoding, result_encoded):
        if encoding in (None, 'none'):
            return result_encoded
        if encoding in ('pickle', 'binary'):
            return pickle.loads(result_encoded)
        if encoding == 'json':
            def _decode(obj):
                if isinstance(obj, dict) and obj.get('__ndarray__'):
                    data = base64.b64decode(obj['data'])
                    arr = np.frombuffer(data, dtype=np.dtype(obj['dtype']))
                    return arr.reshape(obj['shape'])
                if isinstance(obj, dict):
                    return {k: _decode(v) for k, v in obj.items()}
                if isinstance(obj, list):
                    return [_decode(v) for v in obj]
                return obj
            return _decode(json.loads(result_encoded))
        raise ValueError(f""Unknown encoding: {encoding}"")","class vaex_evaluate_results_encoding:
    @classmethod
    def encode(cls, encoding, result):
        if encoding == 'json':
            import json
            return json.dumps(result)
        elif encoding == 'pickle':
            import pickle
            return pickle.dumps(result)
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")

    @classmethod
    def decode(cls, encoding, result_encoded):
        if encoding == 'json':
            import json
            return json.loads(result_encoded)
        elif encoding == 'pickle':
            import pickle
            return pickle.loads(result_encoded)
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")","class vaex_evaluate_results_encoding:

    @classmethod
    def encode(cls, encoding, result):
        if encoding == 'pickle':
            return base64.b64encode(pickle.dumps(result)).decode('ascii')
        elif encoding == 'json':
            if isinstance(result, np.ndarray):
                return json.dumps({
                    'type': 'ndarray',
                    'data': result.tolist(),
                    'dtype': str(result.dtype),
                    'shape': result.shape
                })
            elif isinstance(result, (np.integer, np.floating)):
                return json.dumps({
                    'type': 'numpy_scalar',
                    'data': result.item(),
                    'dtype': str(result.dtype)
                })
            else:
                return json.dumps(result)
        elif encoding == 'arrow':
            import pyarrow as pa
            if isinstance(result, np.ndarray):
                array = pa.array(result)
                return base64.b64encode(array.to_pandas().to_numpy().tobytes()).decode('ascii')
            else:
                return base64.b64encode(pickle.dumps(result)).decode('ascii')
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")

    @classmethod
    def decode(cls, encoding, result_encoded):
        if encoding == 'pickle':
            return pickle.loads(base64.b64decode(result_encoded.encode('ascii')))
        elif encoding == 'json':
            data = json.loads(result_encoded)
            if isinstance(data, dict) and 'type' in data:
                if data['type'] == 'ndarray':
                    return np.array(data['data'], dtype=data['dtype']).reshape(data['shape'])
                elif data['type'] == 'numpy_scalar':
                    return np.array(data['data'], dtype=data['dtype']).item()
            return data
        elif encoding == 'arrow':
            try:
                import pyarrow as pa
                decoded_bytes = base64.b64decode(result_encoded.encode('ascii'))
                return np.frombuffer(decoded_bytes)
            except:
                return pickle.loads(base64.b64decode(result_encoded.encode('ascii')))
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")",no_docstr,0.4,0.20149253731343283,0.12781954887218044,0.3111111111111111,0.183681330246019,0.25813953488372093,0.17715617715617715,0.13551401869158877,0.7372760772705078,0.8830586671829224,0.8036092519760132,0.8659364581108093,0.7169207537688451,0.5496183206106869,0.34108527131782945,0.2677165354330709,0.48854961832061067,0.40186267888355404,0.5846153846153846,0.3643410852713178,0.3046875,0.8101359605789185,0.8581165671348572,0.8334363102912903,0.8530642986297607,0.8055575,0.34532374100719426,0.20289855072463767,0.1386861313868613,0.27338129496402874,0.1657615913571433,0.22939866369710468,0.15848214285714285,0.12527964205816555,0.6940640807151794,0.8578939437866211,0.7673317193984985,0.8381108045578003,0.7230368684759925,0.4002342928024697,0.0895118453161587,0.3532620605875978,0.4081632653061224,0.75,0.329797260767834,0.2242665591622094,0.3075075179227318,0.2040816326530612,0.5833333333333334,0.3700471470918701,0.0962056471157493,0.3335294265125022,0.2448979591836734,0.8055555555555556
650017,portfoliome/postpy,portfoliome_postpy/postpy/base.py,postpy.base.Database,"class Database:
    __slots__ = 'name',

    def __init__(self, name):
        self.name = name

    def create_statement(self):
        return 'CREATE DATABASE %s;' % self.name

    def drop_statement(self):
        return 'DROP DATABASE IF EXISTS %s;' % self.name

    def __repr__(self):
        return format_repr(self, self.__slots__)","class Database:


    def __init__(self, name):
        pass

    def create_statement(self):
        pass

    def drop_statement(self):
        pass

    def __repr__(self):
        pass

",5,0,snippet_706,1.0,"class Database:
    def __init__(self, name):
        self.name = name

    def create_statement(self):
        return f""CREATE DATABASE {self.name};""

    def drop_statement(self):
        return f""DROP DATABASE {self.name};""

    def __repr__(self):
        return f""Database({self.name!r})""","class Database:
    def __init__(self, name):
        self.name = name

    def create_statement(self):
        return f""CREATE DATABASE {self.name};""

    def drop_statement(self):
        return f""DROP DATABASE {self.name};""

    def __repr__(self):
        return f""Database('{self.name}')""","class Database:
    def __init__(self, name):
        self.name = name

    def create_statement(self):
        return f""CREATE DATABASE {self.name};""

    def drop_statement(self):
        return f""DROP DATABASE {self.name};""

    def __repr__(self):
        return f""Database('{self.name}')""",no_docstr,0.825,0.6410256410256411,0.5,0.8,0.5601151107202561,0.7529411764705882,0.6071428571428571,0.5301204819277109,0.9479094743728638,0.9016579389572144,0.9242053627967834,0.9060789346694946,0.8564116923076922,0.8354430379746834,0.6493506493506495,0.5066666666666667,0.810126582278481,0.5658899003994822,0.7764705882352941,0.6071428571428571,0.5301204819277109,0.9531909823417664,0.9000487327575684,0.9258579015731812,0.9050948619842529,0.8615398461538462,0.8354430379746834,0.6493506493506495,0.5066666666666667,0.810126582278481,0.5658899003994822,0.7764705882352941,0.6071428571428571,0.5301204819277109,0.9531909823417664,0.9000487327575684,0.9258579015731812,0.9050948619842529,0.8615398461538462,0.3036220320439871,0.3152618217589531,0.3587851299464068,0.3529411764705882,0.1875,0.3036220320439871,0.3152618217589531,0.3587851299464068,0.3529411764705882,0.1875,0.3036220320439871,0.3152618217589531,0.3587851299464068,0.3529411764705882,0.1875
223003,alertot/detectem,alertot_detectem/detectem/matchers.py,detectem.matchers.UrlMatcher,"class UrlMatcher:
    @classmethod
    def get_info(cls, entry, *matchers):
        name = None
        version = None
        presence = False

        for rtype in [""request"", ""response""]:
            try:
                url = entry[rtype][""url""]
            except KeyError:
                # It could not contain response
                continue

            if not name:
                name = extract_name(url, *matchers)

            if not version:
                version = extract_version(url, *matchers)
                if version:
                    if version == ""presence"":
                        presence = True
                        version = None

        return PluginMatch(name=name, version=version, presence=presence)","class UrlMatcher:


    @classmethod
    def get_info(cls, entry, *matchers):
        pass

",3,0,snippet_551,0.1428571428571428,"class UrlMatcher:
    _regex_type = type(re.compile(''))

    @classmethod
    def get_info(cls, entry, *matchers):
        for matcher in matchers:
            if isinstance(matcher, cls._regex_type):
                m = matcher.match(entry)
                if m:
                    gd = m.groupdict()
                    return gd if gd else m.groups()
            elif isinstance(matcher, str):
                m = re.match(matcher, entry)
                if m:
                    gd = m.groupdict()
                    return gd if gd else m.groups()
            elif callable(matcher):
                res = matcher(entry)
                if res:
                    return res
        return None","class UrlMatcher:
    @classmethod
    def get_info(cls, entry, *matchers):
        """"""
        Get information from an entry using the provided matchers.
        
        Args:
            entry: The entry to match against (typically a URL or request object)
            *matchers: Variable number of matcher objects or functions
            
        Returns:
            dict: A dictionary containing matching information
        """"""
        result = {}
        
        # If no matchers provided, return empty dict
        if not matchers:
            return result
            
        # Apply each matcher to the entry
        for i, matcher in enumerate(matchers):
            try:
                # If matcher is callable, call it with the entry
                if callable(matcher):
                    match_result = matcher(entry)
                    if match_result is not None:
                        result[f'matcher_{i}'] = match_result
                # If matcher has a match method, use that
                elif hasattr(matcher, 'match'):
                    match_result = matcher.match(entry)
                    if match_result is not None:
                        result[f'matcher_{i}'] = match_result
                # Otherwise, try direct comparison or containment
                else:
                    if matcher == entry or (hasattr(entry, '__contains__') and matcher in entry):
                        result[f'matcher_{i}'] = True
                    else:
                        result[f'matcher_{i}'] = False
            except Exception:
                # If matcher fails, record the error
                result[f'matcher_{i}'] = None
                
        return result","class UrlMatcher:
    def __init__(self, pattern, **kwargs):
        self.pattern = pattern
        self.regex = re.compile(pattern)
        self.kwargs = kwargs
    
    def match(self, url):
        match = self.regex.search(url)
        if match:
            result = self.kwargs.copy()
            result.update(match.groupdict())
            return result
        return None

    @classmethod
    def get_info(cls, entry, *matchers):
        for matcher in matchers:
            result = matcher.match(entry)
            if result:
                return result
        return None",no_docstr,0.2733812949640288,0.11678832116788321,0.07407407407407407,0.24460431654676257,0.18626869977130428,0.3897058823529412,0.14814814814814814,0.11194029850746269,0.7536859512329102,0.7485209107398987,0.7510945796966553,0.7490342855453491,0.7213569531250001,0.26778242677824265,0.08438818565400844,0.05957446808510638,0.17573221757322177,0.13106438048024574,0.2926829268292683,0.11538461538461539,0.06666666666666667,0.7033824920654297,0.7708835005760193,0.7355876564979553,0.7635559439659119,0.738374709302326,0.3125,0.1111111111111111,0.08064516129032258,0.21875,0.20539975870875654,0.453781512605042,0.17796610169491525,0.1282051282051282,0.7359354496002197,0.7478232383728027,0.7418317794799805,0.7466171979904175,0.6869596521739133,0.1523296578974279,0.0801319375864324,0.0860627551238225,0.0483870967741935,0.3947368421052631,0.1520340999939647,0.0601088554895189,0.1660241489006015,0.1451612903225806,0.2368421052631578,0.1181316025237893,0.0767392005409152,0.0842422180432067,0.0483870967741935,0.2631578947368421
132493,JMSwag/dsdev-utils,JMSwag_dsdev-utils/dsdev_utils/terminal.py,dsdev_utils.terminal.GetCh,"class GetCh:
    def __init__(self):
        if sys.platform == ""win32"":
            self.impl = _GetchWindows()
        else:
            self.impl = _GetchUnix()

    def __call__(self):
        return self.impl()","class GetCh:


    def __init__(self):
        pass

    def __call__(self):
        pass

",3,0,snippet_74,0.4,"class GetCh:
    def __init__(self):
        try:
            import msvcrt
            self.impl = lambda: msvcrt.getch().decode('utf-8', errors='ignore')
        except ImportError:
            import tty
            import termios
            def _unix_getch():
                fd = sys.stdin.fileno()
                old_settings = termios.tcgetattr(fd)
                try:
                    tty.setraw(fd)
                    ch = sys.stdin.read(1)
                finally:
                    termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
                return ch
            self.impl = _unix_getch

    def __call__(self):
        return self.impl()","class GetCh:
    def __init__(self):
        try:
            # Try to import Windows-specific modules
            import msvcrt
            self.impl = self._getch_windows
        except ImportError:
            # Fall back to Unix/Linux implementation
            try:
                import sys, tty, termios
                self.impl = self._getch_unix
            except ImportError:
                # If neither works, fall back to regular input
                self.impl = self._getch_fallback

    def __call__(self):
        return self.impl()

    def _getch_windows(self):
        import msvcrt
        return msvcrt.getch().decode('utf-8')

    def _getch_unix(self):
        import sys, tty, termios
        fd = sys.stdin.fileno()
        old_settings = termios.tcgetattr(fd)
        try:
            tty.setraw(sys.stdin.fileno())
            ch = sys.stdin.read(1)
        finally:
            termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
        return ch

    def _getch_fallback(self):
        return input()[0] if input() else ''","class GetCh:
    def __init__(self):
        self.fd = sys.stdin.fileno()
        self.old_settings = termios.tcgetattr(self.fd)

    def __call__(self):
        try:
            tty.cbreak(self.fd)
            ch = sys.stdin.read(1)
        finally:
            termios.tcsetattr(self.fd, termios.TCSADRAIN, self.old_settings)
        return ch",no_docstr,0.36781609195402304,0.2588235294117647,0.1686746987951807,0.3448275862068966,0.2970130775874632,0.3787878787878788,0.2900763358778626,0.23846153846153847,0.6303902864456177,0.8285729885101318,0.7160212993621826,0.8033181428909302,0.7750699999999999,0.2571428571428571,0.15942028985507248,0.10294117647058824,0.2285714285714286,0.18371219543451514,0.23423423423423423,0.17647058823529413,0.15,0.6275877356529236,0.8501597046852112,0.7221122980117798,0.8210417628288269,0.7337084357541901,0.40625000000000006,0.1935483870967742,0.13333333333333333,0.37499999999999994,0.3427426897772861,0.5054945054945055,0.32222222222222224,0.24719101123595505,0.7144059538841248,0.8203464150428772,0.7637197375297546,0.8083591461181641,0.7666689999999999,0.2810116483863985,0.1239086813556538,0.3112490233010513,0.4666666666666667,0.2222222222222222,0.3412245910295694,0.0628205671111468,0.3243000192293531,0.5333333333333333,0.4444444444444444,0.2094479871343062,0.1356697961014,0.1798999302136025,0.3,0.2222222222222222
286529,chaosim/dao,chaosim_dao/dao/dinpy/dinpy.py,dao.dinpy.dinpy.SymbolForm,"class SymbolForm(object):
  def __init__(self, name=None, grammar=None):
    self.__form_name__ = 'var'
    self.__form_grammar__ = None
    self.__symbols__ = []
  def __getattr__(self, name):
    self.__symbols__.append(_VarSymbol(name))
    return self
  def __len__(self): return len(self.__symbols__)
  def __iter__(self): return iter(self.__symbols__)","class SymbolForm(object):


  def __init__(self, name=None, grammar=None):
    pass

  def __getattr__(self, name):
    pass

  def __len__(self):
    pass

  def __iter__(self):
    pass

",5,0,snippet_362,1.0,"class SymbolForm(object):
    def __init__(self, name=None, grammar=None):
        self.name = name
        # Normalize grammar into a dict: {child_name: child_grammar_or_None}
        if grammar is None:
            self.grammar = {}
        elif isinstance(grammar, dict):
            self.grammar = grammar.copy()
        else:
            try:
                self.grammar = {k: None for k in grammar}
            except TypeError:
                raise TypeError(""grammar must be None, a dict, or an iterable of names"")
        self._children = {}

    def __getattr__(self, name):
        if name in self.grammar:
            if name not in self._children:
                child_grammar = self.grammar[name]
                self._children[name] = SymbolForm(name=name, grammar=child_grammar)
            return self._children[name]
        raise AttributeError(f""'{type(self).__name__}' object has no attribute '{name}'"")

    def __len__(self):
        return len(self.grammar)

    def __iter__(self):
        for child_name in self.grammar:
            yield getattr(self, child_name)","class SymbolForm(object):
    def __init__(self, name=None, grammar=None):
        self.name = name
        self.grammar = grammar
        self._attributes = {}

    def __getattr__(self, name):
        if name in self._attributes:
            return self._attributes[name]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{name}'"")

    def __len__(self):
        return len(self._attributes)

    def __iter__(self):
        return iter(self._attributes)","class SymbolForm(object):
    def __init__(self, name=None, grammar=None):
        self.name = name
        self.grammar = grammar
        self._symbols = []

    def __getattr__(self, name):
        if name.startswith('_'):
            raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{name}'"")
        symbol = SymbolForm(name, self.grammar)
        self._symbols.append(symbol)
        return symbol

    def __len__(self):
        return len(self._symbols)

    def __iter__(self):
        return iter(self._symbols)",no_docstr,0.3885714285714286,0.26589595375722547,0.1871345029239766,0.3885714285714286,0.3188846868417936,0.4037735849056604,0.3106060606060606,0.2585551330798479,0.7026419043540955,0.8112081289291382,0.7530321478843689,0.7988647222518921,0.7934803260869565,0.6930693069306931,0.5050505050505051,0.3917525773195876,0.6732673267326731,0.6192622044843392,0.7410071942446043,0.6014492753623188,0.5328467153284672,0.8586228489875793,0.8752304315567017,0.8668470978736877,0.8735407590866089,0.8854178125,0.7547169811320755,0.5961538461538463,0.5098039215686275,0.7169811320754719,0.6010046453313496,0.7142857142857143,0.6078431372549019,0.5,0.8614822030067444,0.9059590101242065,0.8831609487533569,0.9013057947158813,0.866668,0.4870434767530259,0.0792516594076302,0.2911444698266956,0.5777777777777777,0.0,0.5206455469010217,0.2171467271798786,0.3098799048686526,0.5555555555555556,0.0,0.5790942830951041,0.2568958148132367,0.392814650900513,0.6666666666666666,0.0
188997,SpockBotMC/SpockBot,SpockBotMC_SpockBot/spockbot/plugins/helpers/pathfinding.py,spockbot.plugins.helpers.pathfinding.Path,"class Path(object):
    def __init__(self, start_node, end_node):
        self.end_node = end_node
        self.open_list = [start_node]
        self.closed_list = []
        self.result = None

    def calc_f_val(self, node):
        return node.node_dist + self.end_node.dist(node)","class Path(object):


    def __init__(self, start_node, end_node):
        pass

    def calc_f_val(self, node):
        pass

",3,0,snippet_443,1.0,"class Path(object):
    def __init__(self, start_node, end_node):
        self.start_node = start_node
        self.end_node = end_node

    def calc_f_val(self, node):
        sx, sy = self.start_node.state
        nx, ny = node.state
        ex, ey = self.end_node.state
        g = abs(nx - sx) + abs(ny - sy)
        h = abs(ex - nx) + abs(ey - ny)
        return g + h","class Path(object):
    def __init__(self, start_node, end_node):
        self.start_node = start_node
        self.end_node = end_node
        self.nodes = [start_node]
        self.g_cost = 0
        self.h_cost = 0
        self.f_cost = 0

    def calc_f_val(self, node):
        # Calculate g_cost (distance from start to current node)
        g_cost = self.calculate_g_cost(node)
        
        # Calculate h_cost (heuristic distance from current node to end)
        h_cost = self.calculate_h_cost(node)
        
        # Calculate f_cost (total cost)
        f_cost = g_cost + h_cost
        
        return f_cost
    
    def calculate_g_cost(self, node):
        # Implement actual distance calculation based on your node structure
        # This is a placeholder implementation
        return 0
    
    def calculate_h_cost(self, node):
        # Implement heuristic calculation (e.g., Euclidean distance, Manhattan distance)
        # This is a placeholder implementation
        return 0","class Path(object):
    def __init__(self, start_node, end_node):
        self.start_node = start_node
        self.end_node = end_node
        self.nodes = [start_node]
        self.g_cost = 0
        
    def calc_f_val(self, node):
        g_val = self.g_cost
        h_val = abs(node.x - self.end_node.x) + abs(node.y - self.end_node.y)
        return g_val + h_val",no_docstr,0.64,0.46938775510204084,0.3958333333333333,0.52,0.49710934088942504,0.6186440677966102,0.4700854700854701,0.4224137931034483,0.789255678653717,0.896072506904602,0.839279055595398,0.8841071128845215,0.7929845263157894,0.3793103448275862,0.2558139534883721,0.2235294117647059,0.3563218390804598,0.26668396888480056,0.3347826086956522,0.25327510917030566,0.2236842105263158,0.6973147392272949,0.8821808695793152,0.7789292931556702,0.8593972325325012,0.8158748571428571,0.6534653465346535,0.4848484848484849,0.4123711340206186,0.594059405940594,0.5275135027655696,0.6363636363636364,0.5083333333333333,0.453781512605042,0.8616756200790405,0.9023590087890625,0.8815481662750244,0.8981185555458069,0.873985,0.4049337642534443,0.1525519390505368,0.3144949459202295,0.4193548387096774,0.7333333333333333,0.42051939278978,0.0728989451053333,0.3253076583118514,0.4838709677419355,0.8,0.5135165400603252,0.2126294696713846,0.3253076583118514,0.5161290322580645,1.0
266945,bjodah/pyodesys,bjodah_pyodesys/pyodesys/integrators.py,pyodesys.integrators.Trapezoidal_example_integrator,"class Trapezoidal_example_integrator:

    with_jacobian = True
    integrate_adaptive = None

    @staticmethod
    def integrate_predefined(rhs, jac, y0, xout, **kwargs):
        if kwargs:
            warnings.warn(""Ignoring keyword-argumtents: %s"" % ', '.join(kwargs.keys()))
        x_old = xout[0]
        yout = [y0[:]]
        f = np.empty(len(y0))
        j = np.empty((len(y0), len(y0)))
        I = np.eye(len(y0))
        for i, x in enumerate(xout[1:], 1):
            y = yout[-1]
            h = x - x_old
            jac(x_old, y, j)
            lu_piv = lu_factor(h*j - I)
            rhs(x, y, f)
            euler_fw_dy = f*h
            ynew = y + euler_fw_dy
            norm_delta_ynew = float('inf')
            while norm_delta_ynew > 1e-12:
                rhs(x, ynew, f)
                delta_ynew = lu_solve(lu_piv, ynew - y - f*h)
                ynew += delta_ynew
                norm_delta_ynew = np.sqrt(np.sum(np.square(delta_ynew)))

            yout.append((ynew + y + euler_fw_dy)/2)
            x_old = x
        return np.array(yout), {'nfev': (len(xout)-1)}","class Trapezoidal_example_integrator:


    @staticmethod
    def integrate_predefined(rhs, jac, y0, xout, **kwargs):
        pass

",3,0,snippet_670,0.4,"class Trapezoidal_example_integrator:

    @staticmethod
    def integrate_predefined(rhs, jac, y0, xout, **kwargs):
        tol = kwargs.get('tol', 1e-6)
        maxiter = kwargs.get('maxiter', 10)
        y0 = np.array(y0, dtype=float)
        xout = np.array(xout, dtype=float)
        n_steps = len(xout)
        n_eq = y0.size
        Y = np.zeros((n_steps, n_eq))
        Y[0] = y0

        for i in range(n_steps - 1):
            x_n = xout[i]
            x_np1 = xout[i+1]
            h = x_np1 - x_n
            y_n = Y[i].copy()
            y_np1 = y_n.copy()

            f_n = rhs(x_n, y_n)

            for _ in range(maxiter):
                f_np1 = rhs(x_np1, y_np1)
                g = y_np1 - y_n - 0.5 * h * (f_n + f_np1)
                if np.linalg.norm(g, np.inf) < tol:
                    break
                J_np1 = jac(x_np1, y_np1)
                I = np.eye(n_eq)
                Jg = I - 0.5 * h * J_np1
                delta = np.linalg.solve(Jg, g)
                y_np1 -= delta

            Y[i+1] = y_np1

        return Y","class Trapezoidal_example_integrator:
    @staticmethod
    def integrate_predefined(rhs, jac, y0, xout, **kwargs):
        import numpy as np
        
        # Initialize arrays
        n_steps = len(xout) - 1
        y0 = np.array(y0)
        y = np.zeros((n_steps + 1, len(y0)))
        y[0] = y0
        
        # Get tolerance and max iterations from kwargs
        tol = kwargs.get('tol', 1e-10)
        max_iter = kwargs.get('max_iter', 50)
        
        # Time stepping loop
        for i in range(n_steps):
            h = xout[i+1] - xout[i]
            y_prev = y[i]
            
            # Initial prediction using Euler step
            y_pred = y_prev + h * rhs(xout[i], y_prev)
            y_new = y_pred.copy()
            
            # Newton iteration to solve the implicit trapezoidal rule
            for _ in range(max_iter):
                # Function value: f(y_new) = y_new - y_prev - h/2 * (rhs(x_i, y_prev) + rhs(x_{i+1}, y_new))
                f_val = y_new - y_prev - 0.5 * h * (rhs(xout[i], y_prev) + rhs(xout[i+1], y_new))
                
                # Jacobian: J = I - h/2 * jac(x_{i+1}, y_new)
                J = np.eye(len(y0)) - 0.5 * h * jac(xout[i+1], y_new)
                
                # Solve linear system: J * delta = -f_val
                delta = np.linalg.solve(J, -f_val)
                
                # Update solution
                y_new += delta
                
                # Check convergence
                if np.linalg.norm(delta) < tol:
                    break
            
            y[i+1] = y_new
        
        return y","class Trapezoidal_example_integrator:

    @staticmethod
    def integrate_predefined(rhs, jac, y0, xout, **kwargs):
        rtol = kwargs.get('rtol', 1e-6)
        atol = kwargs.get('atol', 1e-9)
        max_iter = kwargs.get('max_iter', 100)
        
        y0 = np.asarray(y0, dtype=float)
        xout = np.asarray(xout, dtype=float)
        
        n_points = len(xout)
        n_vars = len(y0)
        
        y_result = np.zeros((n_points, n_vars))
        y_result[0] = y0
        
        y_current = y0.copy()
        
        for i in range(1, n_points):
            x_prev = xout[i-1]
            x_curr = xout[i]
            h = x_curr - x_prev
            
            y_prev = y_current.copy()
            
            def residual(y_new):
                f_prev = rhs(x_prev, y_prev)
                f_new = rhs(x_curr, y_new)
                return y_new - y_prev - 0.5 * h * (f_prev + f_new)
            
            def jacobian_residual(y_new):
                J = jac(x_curr, y_new)
                return np.eye(n_vars) - 0.5 * h * J
            
            y_guess = y_prev + h * rhs(x_prev, y_prev)
            
            try:
                y_new = fsolve(residual, y_guess, fprime=jacobian_residual, 
                              xtol=rtol, maxfev=max_iter)[0] if n_vars == 1 else fsolve(residual, y_guess, fprime=jacobian_residual, xtol=rtol, maxfev=max_iter)
                y_current = y_new
                y_result[i] = y_current
            except:
                y_current = y_guess
                y_result[i] = y_current
        
        return xout, y_result",no_docstr,0.48231511254019294,0.16181229773462785,0.0781758957654723,0.30868167202572344,0.2920464376209332,0.6634615384615384,0.2733118971061093,0.14838709677419354,0.8030664324760437,0.7897307276725769,0.7963427305221558,0.7910443544387817,0.7815252808988769,0.4328767123287671,0.14325068870523416,0.0664819944598338,0.26301369863013696,0.2514749018326881,0.5436893203883495,0.22627737226277372,0.12926829268292683,0.8077810406684875,0.8087400197982788,0.8082602024078369,0.8086439371109009,0.7553083146067421,0.39226519337016574,0.11666666666666665,0.05027932960893855,0.2596685082872928,0.22212405117527897,0.5184275184275184,0.19458128078817735,0.10864197530864197,0.786750078201294,0.7976760864257812,0.7921754121780396,0.7965698838233948,0.7694086986301375,0.2309051815828689,0.0762376565503541,0.089452035298363,0.3379310344827586,0.42,0.2249038299533063,0.0545617908550222,0.0940190461995826,0.3310344827586207,0.42,0.2141091606100106,0.0620073323321789,0.0864982756251049,0.3379310344827586,0.37
809738,twisted/axiom,axiom/attributes.py,axiom.attributes.TwoAttributeComparison,"class TwoAttributeComparison:
    def __init__(self, leftAttribute, operationString, rightAttribute):
        self.leftAttribute = leftAttribute
        self.operationString = operationString
        self.rightAttribute = rightAttribute

    def getQuery(self, store):
        sql = ('(%s %s %s)' % (self.leftAttribute.getColumnName(store),
                               self.operationString,
                               self.rightAttribute.getColumnName(store)) )
        return sql

    def getInvolvedTables(self):
        tables = [self.leftAttribute.type]
        if self.leftAttribute.type is not self.rightAttribute.type:
            tables.append(self.rightAttribute.type)
        return tables


    def getArgs(self, store):
        return []


    def __repr__(self):
        return ' '.join((self.leftAttribute.fullyQualifiedName(),
                         self.operationString,
                         self.rightAttribute.fullyQualifiedName()))","class TwoAttributeComparison:


    def __init__(self, leftAttribute, operationString, rightAttribute):
        pass

    def getQuery(self, store):
        pass

    def getInvolvedTables(self):
        pass

    def getArgs(self, store):
        pass

    def __repr__(self):
        pass

",6,0,snippet_37,0.75,"class TwoAttributeComparison:

    def __init__(self, leftAttribute, operationString, rightAttribute):
        self.leftAttribute = leftAttribute
        self.operationString = operationString
        self.rightAttribute = rightAttribute

    def getQuery(self, store):
        left_q = self.leftAttribute.getQuery(store)
        right_q = self.rightAttribute.getQuery(store)
        return f""{left_q} {self.operationString} {right_q}""

    def getInvolvedTables(self):
        return self.leftAttribute.getInvolvedTables().union(
            self.rightAttribute.getInvolvedTables()
        )

    def getArgs(self, store):
        return self.leftAttribute.getArgs(store) + self.rightAttribute.getArgs(store)

    def __repr__(self):
        return (
            f""TwoAttributeComparison({self.leftAttribute!r}, ""
            f""{self.operationString!r}, {self.rightAttribute!r})""
        )","class TwoAttributeComparison:
    def __init__(self, leftAttribute, operationString, rightAttribute):
        self.leftAttribute = leftAttribute
        self.operationString = operationString
        self.rightAttribute = rightAttribute

    def getQuery(self, store):
        left_table = self.leftAttribute.split('.')[0]
        right_table = self.rightAttribute.split('.')[0]
        left_column = self.leftAttribute.split('.')[1]
        right_column = self.rightAttribute.split('.')[1]
        
        return f""{left_table}.{left_column} {self.operationString} {right_table}.{right_column}""

    def getInvolvedTables(self):
        left_table = self.leftAttribute.split('.')[0]
        right_table = self.rightAttribute.split('.')[0]
        return {left_table, right_table}

    def getArgs(self, store):
        return []

    def __repr__(self):
        return f""TwoAttributeComparison({self.leftAttribute}, {self.operationString}, {self.rightAttribute})""","class TwoAttributeComparison:
    def __init__(self, leftAttribute, operationString, rightAttribute):
        self.leftAttribute = leftAttribute
        self.operationString = operationString
        self.rightAttribute = rightAttribute

    def getQuery(self, store):
        left_table = self.leftAttribute.split('.')[0]
        right_table = self.rightAttribute.split('.')[0]
        return f""{left_table}.{self.leftAttribute.split('.')[1]} {self.operationString} {right_table}.{self.rightAttribute.split('.')[1]}""

    def getInvolvedTables(self):
        left_table = self.leftAttribute.split('.')[0]
        right_table = self.rightAttribute.split('.')[0]
        tables = set()
        tables.add(left_table)
        tables.add(right_table)
        return list(tables)

    def getArgs(self, store):
        return []

    def __repr__(self):
        return f""TwoAttributeComparison({self.leftAttribute}, {self.operationString}, {self.rightAttribute})""",no_docstr,0.7169811320754716,0.5222929936305731,0.3225806451612903,0.6289308176100629,0.5649527938719797,0.7252747252747253,0.5524861878453039,0.45,0.9147346019744873,0.885608434677124,0.8999359011650085,0.8884373307228088,0.8061021568627451,0.6395348837209303,0.4823529411764706,0.34523809523809523,0.5813953488372093,0.4338128135944331,0.5822784810126582,0.4067796610169492,0.3446808510638298,0.8973652720451355,0.8865983486175537,0.8919492959976196,0.8876633644104004,0.8041256701030928,0.6744186046511628,0.4941176470588235,0.35714285714285715,0.6046511627906976,0.4443292363093854,0.6108786610878661,0.42016806722689076,0.34177215189873417,0.89780592918396,0.8885278701782227,0.893142819404602,0.889447033405304,0.8132063768115942,0.5198676721659288,0.4173291875092288,0.4326525185009467,0.5443037974683544,0.6851851851851852,0.526568583041215,0.457250060542046,0.4818887817025143,0.5189873417721519,0.6481481481481481,0.526387790970669,0.4737424198187349,0.48811441682531,0.569620253164557,0.5740740740740741
515104,jlesquembre/autopilot,jlesquembre_autopilot/src/autopilot/ui.py,autopilot.ui.Widget,"class Widget(object):

    def handle_key(self, key):
        k = None

        if key == curses.KEY_UP:
            k = '_up'
        elif key == curses.KEY_DOWN:
            k = '_down'
        elif key == ord('\n'):
            k = '_enter'
        elif key == ord(' '):
            k = '_printable' if hasattr(self, '_printable') else '_space'
        elif key in range(32, 256) or key == curses.KEY_BACKSPACE:
            k = '_printable'

        subwidget = self.get_subwidget()

        if k in dir(type(self)) and not getattr(subwidget, 'handle_input', False):
            if k == '_printable':
                return getattr(self, k)(key)
            else:
                return getattr(self, k)()

        elif subwidget:
            return subwidget.handle_key(key)

    def get_subwidget(self):
        if hasattr(self, 'popup'):
            return self.popup
        if hasattr(self, 'widgets'):
            return self.widgets[self.current]
        elif hasattr(self, 'widget'):
            return self.widget

    @property
    def handle_input(self):
        return False

    @property
    def read_only(self):
        return getattr(self, '_read_only', False)

    def get_value(self):
        subwidget = self.get_subwidget()
        if subwidget:
            return getattr(subwidget, 'value', subwidget.get_value())","class Widget(object):


    def handle_key(self, key):
        pass

    def get_subwidget(self):
        pass

    @property
    def handle_input(self):
        pass

    @property
    def read_only(self):
        pass

    def get_value(self):
        pass

",8,0,snippet_322,0.1764705882352941,"class Widget(object):
    def __init__(self, value='', read_only=False, subwidget=None):
        self._value = value
        self._read_only = read_only
        self._subwidget = subwidget

    def handle_key(self, key):
        if self._read_only:
            return False
        if self._subwidget:
            return self._subwidget.handle_key(key)
        if key == '\b':
            self._value = self._value[:-1]
        else:
            self._value += key
        return True

    def get_subwidget(self):
        return self._subwidget

    @property
    def handle_input(self):
        return self.handle_key

    @property
    def read_only(self):
        return self._read_only

    def get_value(self):
        if self._subwidget:
            return self._subwidget.get_value()
        return self._value","class Widget(object):
    def __init__(self):
        self._handle_input = True
        self._read_only = False
        self._value = None
        self._subwidget = None

    def handle_key(self, key):
        # Handle a key press event
        # This is a basic implementation that can be overridden
        if not self.read_only:
            # Process the key input
            pass

    def get_subwidget(self):
        # Return the subwidget if it exists
        return self._subwidget

    @property
    def handle_input(self):
        # Return whether this widget handles input
        return self._handle_input

    @handle_input.setter
    def handle_input(self, value):
        # Set whether this widget handles input
        self._handle_input = bool(value)

    @property
    def read_only(self):
        # Return whether this widget is read-only
        return self._read_only

    @read_only.setter
    def read_only(self, value):
        # Set whether this widget is read-only
        self._read_only = bool(value)

    def get_value(self):
        # Return the current value of the widget
        return self._value

    def set_value(self, value):
        # Set the value of the widget
        if not self.read_only:
            self._value = value","class Widget(object):
    def __init__(self):
        self._handle_input = False
        self._read_only = False
        self._value = None
        self._subwidget = None

    def handle_key(self, key):
        return False

    def get_subwidget(self):
        return self._subwidget

    @property
    def handle_input(self):
        return self._handle_input

    @property
    def read_only(self):
        return self._read_only

    def get_value(self):
        return self._value",no_docstr,0.6080000000000001,0.33064516129032256,0.17886178861788615,0.432,0.30300075586472464,0.7989949748743719,0.5050505050505051,0.37055837563451777,0.8581616282463074,0.7989054918289185,0.8274741172790527,0.8044602870941162,0.7511440410958908,0.43396226415094336,0.2088607594936709,0.1273885350318471,0.3018867924528302,0.2693728815842513,0.5274725274725275,0.29044117647058826,0.1918819188191882,0.7903878092765808,0.7801138162612915,0.78521728515625,0.7811292409896851,0.732879383561644,0.5,0.32380952380952377,0.2019230769230769,0.39622641509433965,0.1245215296967208,0.9145299145299145,0.6379310344827587,0.48695652173913045,0.8365723490715027,0.727393388748169,0.778171956539154,0.7370120286941528,0.739728630136987,0.1397775146496705,0.0599299375703584,0.0853808378742017,0.2193548387096774,0.1944444444444444,0.1725856777578518,0.0263884660406188,0.0314273632703584,0.1741935483870967,0.4583333333333333,0.1118511277063006,0.0264911348095794,0.0736015480586339,0.1806451612903225,0.1666666666666666
667182,pyinvoke/invocations,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/pyinvoke_invocations/tests/packaging/release.py,release.publish_.base_case,"class base_case:
    def does_all_the_things(self, fakepub):
        c, mocks = fakepub
        # Execution
        publish(c)
        # Unhides stdout
        assert c.config.run.hide is False
        # Build
        mocks.build.assert_called_once_with(
            c, sdist=True, wheel=True, directory=""tmpdir""
        )
        # Twine check
        splat = path.join(""tmpdir"", ""dist"", ""*"")
        mocks.twine_check.assert_called_once_with(dists=[splat])
        # Install test
        mocks.test_install.assert_called_once_with(c, directory=""tmpdir"")
        # Upload
        mocks.upload.assert_called_once_with(
            c, directory=""tmpdir"", index=None, sign=False, dry_run=False
        )
        # Tmpdir cleaned up
        mocks.rmtree.assert_called_once_with(""tmpdir"")

    def cleans_up_on_error(self, fakepub):
        c, mocks = fakepub
        mocks.build.side_effect = _Kaboom
        with pytest.raises(_Kaboom):
            publish(MockContext(run=True))
        mocks.rmtree.assert_called_once_with(mocks.mkdtemp.return_value)

    def monkeypatches_readme_renderer(self, fakepub):
        # Happens at module load time but is just a data structure change
        import readme_renderer.rst

        assert (
            readme_renderer.rst.SETTINGS[""halt_level""]
            == Reporter.INFO_LEVEL
        )
        assert (
            readme_renderer.rst.SETTINGS[""report_level""]
            == Reporter.INFO_LEVEL
        )
","class base_case:


    def does_all_the_things(self, fakepub):
        pass


    def cleans_up_on_error(self, fakepub):
        pass


    def monkeypatches_readme_renderer(self, fakepub):
        pass

",4,0,snippet_10,0.2,"class base_case:

    def does_all_the_things(self, fakepub):
        self.monkeypatches_readme_renderer(fakepub)
        try:
            fakepub.setup_project()
            fakepub.build_sdist()
            fakepub.build_wheel()
            fakepub.upload()
        except Exception:
            self.cleans_up_on_error(fakepub)
            raise

    def cleans_up_on_error(self, fakepub):
        # remove temporary build directories if they exist
        for attr in (""sdist_dir"", ""wheel_dir"", ""build_dir""):
            path = getattr(fakepub, attr, None)
            if path and os.path.isdir(path):
                shutil.rmtree(path, ignore_errors=True)

    def monkeypatches_readme_renderer(self, fakepub):
        import readme_renderer.rst
        fakepub.monkeypatch.setattr(
            readme_renderer.rst,
            ""render"",
            lambda text, **kwargs: (""<p>%s</p>"" % text, [])
        )","class base_case:


    def does_all_the_things(self, fakepub):
        # Implementation for doing all the things
        if fakepub is not None:
            fakepub.process()
            fakepub.validate()
            fakepub.publish()
            return True
        return False


    def cleans_up_on_error(self, fakepub):
        # Implementation for cleaning up on error
        try:
            if fakepub is not None:
                fakepub.process()
        except Exception as e:
            if fakepub is not None:
                fakepub.cleanup()
            raise e


    def monkeypatches_readme_renderer(self, fakepub):
        # Implementation for monkeypatching readme renderer
        if fakepub is not None:
            original_render = fakepub.render_readme
            fakepub.render_readme = lambda content: f""PATCHED: {original_render(content)}""
            return fakepub.render_readme
        return None","class base_case:
    def does_all_the_things(self, fakepub):
        return True

    def cleans_up_on_error(self, fakepub):
        try:
            fakepub.process()
        except Exception:
            fakepub.cleanup()
            raise

    def monkeypatches_readme_renderer(self, fakepub):
        import readme_renderer
        original_render = readme_renderer.render
        
        def patched_render(*args, **kwargs):
            return original_render(*args, **kwargs)
        
        readme_renderer.render = patched_render
        fakepub.readme_renderer = readme_renderer",no_docstr,0.33333333333333337,0.19402985074626866,0.15037593984962405,0.2814814814814815,0.21445809147721634,0.676056338028169,0.35377358490566035,0.2559241706161137,0.8155084848403931,0.7259445190429688,0.7681244611740112,0.7340057492256165,0.7661087815126054,0.27306273062730624,0.15613382899628253,0.12734082397003746,0.23616236162361626,0.11750728974818252,0.5568862275449101,0.27710843373493976,0.24848484848484848,0.7917822003364563,0.6886064410209656,0.7365989089012146,0.6976980566978455,0.7352967647058829,0.29565217391304344,0.21052631578947364,0.1592920353982301,0.2782608695652174,0.07728778912704087,0.7166666666666667,0.44537815126050423,0.3898305084745763,0.7899225354194641,0.6602872610092163,0.7193108201026917,0.6713041067123413,0.726893487394959,0.21132071060387,0.0558479629404316,0.0719745620147309,0.4,0.3174603174603174,0.1426521466653973,0.0776271930889959,0.0881504756981975,0.1826086956521739,0.2222222222222222,0.1309039663323132,0.0296612273475722,0.067591629009976,0.1565217391304348,0.2698412698412698
241651,apache/spark,python/pyspark/ml/torch/log_communication.py,pyspark.ml.torch.log_communication.LogStreamingServer,"class LogStreamingServer:
    def __init__(self) -> None:
        self.server = None
        self.serve_thread = None
        self.port = None

    @staticmethod
    def _get_free_port(spark_host_address: str = """") -> int:
        with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as tcp:
            tcp.bind((spark_host_address, 0))
            _, port = tcp.getsockname()
        return port

    def start(self, spark_host_address: str = """") -> None:
        if self.server:
            raise RuntimeError(""Cannot start the server twice."")

        def serve_task(port: int) -> None:
            with socketserver.ThreadingTCPServer((""0.0.0.0"", port), WriteLogToStdout) as server:
                self.server = server
                server.is_active = True
                server.serve_forever(poll_interval=_SERVER_POLL_INTERVAL)

        self.port = LogStreamingServer._get_free_port(spark_host_address)
        self.serve_thread = threading.Thread(target=serve_task, args=(self.port,))
        self.serve_thread.daemon = True
        self.serve_thread.start()

    def shutdown(self) -> None:
        if self.server:
            # Sleep to ensure all log has been received and printed.
            time.sleep(_SERVER_POLL_INTERVAL * 2)
            # Before close we need flush to ensure all stdout buffer were printed.
            sys.stdout.flush()
            self.server.is_active = False
            self.server.shutdown()
            self.serve_thread.join()
            self.server = None
            self.serve_thread = None","class LogStreamingServer:


    def __init__(self) -> None:
        pass

    @staticmethod
    def _get_free_port(spark_host_address: str = """") -> int:
        pass

    def start(self, spark_host_address: str = """") -> None:
        pass

        def serve_task(port: int) -> None:
                pass

    def shutdown(self) -> None:
        pass

",7,0,snippet_484,0.4545454545454545,"class LogStreamingServer:
    def __init__(self) -> None:
        self._server_socket: socket.socket = None  # type: ignore
        self._serve_thread: threading.Thread = None  # type: ignore
        self._client_threads: list[threading.Thread] = []
        self._running = False
        self._port: int = 0

    @staticmethod
    def _get_free_port(spark_host_address: str = """") -> int:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind(('', 0))
            return s.getsockname()[1]

    def start(self, spark_host_address: str = """") -> None:
        host, port = (""localhost"", 4040)
        if spark_host_address:
            if "":"" in spark_host_address:
                h, p = spark_host_address.split("":"", 1)
                host = h or host
                try:
                    port = int(p)
                except ValueError:
                    port = port
            else:
                host = spark_host_address
        self._port = self._get_free_port()
        self._server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self._server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self._server_socket.bind(('', self._port))
        self._server_socket.listen(5)
        self._server_socket.settimeout(1.0)
        self._running = True

        def serve_task(port: int) -> None:
            def forward(src: socket.socket, dst: socket.socket) -> None:
                try:
                    while True:
                        data = src.recv(4096)
                        if not data:
                            break
                        dst.sendall(data)
                except Exception:
                    pass
                finally:
                    try:
                        src.shutdown(socket.SHUT_RD)
                    except Exception:
                        pass
                    try:
                        dst.shutdown(socket.SHUT_WR)
                    except Exception:
                        pass

            while self._running:
                try:
                    client_sock, _ = self._server_socket.accept()
                except socket.timeout:
                    continue
                except OSError:
                    break
                try:
                    remote_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                    remote_sock.connect((host, port))
                except Exception:
                    client_sock.close()
                    continue
                t1 = threading.Thread(target=forward, args=(client_sock, remote_sock))
                t2 = threading.Thread(target=forward, args=(remote_sock, client_sock))
                t1.daemon = True
                t2.daemon = True
                t1.start()
                t2.start()
                self._client_threads.extend([t1, t2])

        self._serve_thread = threading.Thread(target=serve_task, args=(port,))
        self._serve_thread.daemon = True
        self._serve_thread.start()

    def shutdown(self) -> None:
        self._running = False
        try:
            if self._server_socket:
                self._server_socket.close()
        except Exception:
            pass
        if self._serve_thread:
            self._serve_thread.join()
        for t in self._client_threads:
            t.join()","class LogStreamingServer:
    def __init__(self) -> None:
        self.server = None
        self.server_thread = None
        self.is_running = False
        self.log_queue = queue.Queue()
        self.clients = []

    @staticmethod
    def _get_free_port(spark_host_address: str = """") -> int:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind((spark_host_address or 'localhost', 0))
            s.listen(1)
            port = s.getsockname()[1]
        return port

    def start(self, spark_host_address: str = """") -> None:
        if self.is_running:
            return
            
        port = self._get_free_port(spark_host_address)
        self.is_running = True
        
        def serve_task(port: int) -> None:
            class LogHandler(BaseHTTPRequestHandler):
                def do_GET(self):
                    if self.path == '/logs':
                        self.send_response(200)
                        self.send_header('Content-Type', 'text/plain')
                        self.send_header('Cache-Control', 'no-cache')
                        self.send_header('Connection', 'keep-alive')
                        self.end_headers()
                        
                        # Keep connection open and stream logs
                        try:
                            while self.server.server_instance.is_running:
                                try:
                                    log_entry = self.server.server_instance.log_queue.get(timeout=1)
                                    self.wfile.write(f""{log_entry}\n"".encode('utf-8'))
                                    self.wfile.flush()
                                except queue.Empty:
                                    continue
                        except (BrokenPipeError, ConnectionResetError):
                            pass
                    
                    elif self.path == '/health':
                        self.send_response(200)
                        self.send_header('Content-Type', 'application/json')
                        self.end_headers()
                        self.wfile.write(b'{""status"": ""healthy""}')
                    
                    else:
                        self.send_response(404)
                        self.end_headers()
                
                def log_message(self, format, *args):
                    # Suppress default logging
                    pass
            
            try:
                server = HTTPServer((spark_host_address or 'localhost', port), LogHandler)
                server.server_instance = self
                self.server = server
                server.serve_forever()
            except Exception:
                pass
        
        self.server_thread = threading.Thread(target=serve_task, args=(port,), daemon=True)
        self.server_thread.start()
        
        # Wait for server to start
        while self.server is None:
            time.sleep(0.1)
        
        self.port = port

    def shutdown(self) -> None:
        if not self.is_running:
            return
            
        self.is_running = False
        if self.server:
            self.server.shutdown()
        if self.server_thread:
            self.server_thread.join(timeout=5)","class LogStreamingServer:
    def __init__(self) -> None:
        self.server: Optional[socketserver.TCPServer] = None
        self.server_thread: Optional[threading.Thread] = None
        self.port: Optional[int] = None

    @staticmethod
    def _get_free_port(spark_host_address: str = """") -> int:
        host = spark_host_address if spark_host_address else ""localhost""
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind((host, 0))
            s.listen(1)
            port = s.getsockname()[1]
        return port

    def start(self, spark_host_address: str = """") -> None:
        if self.server is not None:
            return
        
        host = spark_host_address if spark_host_address else ""localhost""
        self.port = self._get_free_port(spark_host_address)
        
        class LogHandler(socketserver.StreamRequestHandler):
            def handle(self):
                while True:
                    try:
                        data = self.rfile.readline()
                        if not data:
                            break
                        sys.stdout.write(data.decode('utf-8'))
                        sys.stdout.flush()
                    except Exception:
                        break

        def serve_task(port: int) -> None:
            self.server = socketserver.TCPServer((host, port), LogHandler)
            self.server.serve_forever()

        self.server_thread = threading.Thread(target=serve_task, args=(self.port,))
        self.server_thread.daemon = True
        self.server_thread.start()

    def shutdown(self) -> None:
        if self.server is not None:
            self.server.shutdown()
            self.server.server_close()
            self.server = None
        if self.server_thread is not None:
            self.server_thread.join()
            self.server_thread = None
        self.port = None",no_docstr,0.46833013435700577,0.3314065510597302,0.23597678916827852,0.36084452975047987,0.308595750015976,0.42075736325385693,0.2991573033707865,0.23347398030942335,0.8071251511573792,0.8437728881835938,0.8250423073768616,0.8399591445922852,0.7716917808219178,0.5213849287169042,0.35173824130879344,0.2587268993839836,0.4073319755600815,0.40355477351473656,0.504950495049505,0.3950413223140496,0.3294701986754967,0.790270209312439,0.8538840413093567,0.8208464980125427,0.8470655083656311,0.7814335203094777,0.6513994910941476,0.4757033248081841,0.365038560411311,0.5241730279898219,0.5935535348018033,0.7253012048192771,0.572463768115942,0.5036319612590799,0.86800616979599,0.8624085783958435,0.8651983141899109,0.8629650473594666,0.8496747058823529,0.3336730933927092,0.135940393616526,0.2476797963239877,0.5324675324675324,0.4186046511627907,0.3994171820731442,0.2125719092627773,0.3160844360639281,0.6038961038961039,0.4651162790697674,0.4175969190098251,0.3047691480190689,0.3363222429099928,0.6688311688311688,0.3604651162790697
122483,FortyNorthSecurity/Hasher,FortyNorthSecurity_Hasher/hashes/ops/sha1.py,hashes.ops.sha1.Algorithm,"class Algorithm:

    def __init__(self):
        self.hash_type = ""sha1""
        self.description = ""This module generates sha1 hashes""

    def generate(self, cli_object):
        hash_object = getattr(hashlib, ""sha1"")()
        hash_object.update(cli_object.plaintext)
        return hash_object.hexdigest()","class Algorithm:


    def __init__(self):
        pass

    def generate(self, cli_object):
        pass

",3,0,snippet_343,1.0,"class Algorithm:
    def __init__(self):
        super().__init__()

    def generate(self, cli_object):
        raise NotImplementedError(""Subclasses must implement generate()"")","class Algorithm:
    def __init__(self):
        pass

    def generate(self, cli_object):
        pass","class Algorithm:
    def __init__(self):
        self.name = ""Base Algorithm""
        self.version = ""1.0""
        self.parameters = {}
    
    def generate(self, cli_object):
        if cli_object is None:
            return None
        
        result = {
            'algorithm': self.name,
            'version': self.version,
            'input': str(cli_object),
            'output': self._process(cli_object),
            'parameters': self.parameters.copy()
        }
        
        return result
    
    def _process(self, cli_object):
        return f""Processed: {cli_object}""
    
    def set_parameter(self, key, value):
        self.parameters[key] = value
    
    def get_parameter(self, key, default=None):
        return self.parameters.get(key, default)",no_docstr,0.3703703703703704,0.3076923076923077,0.24,0.3703703703703704,0.29829461956487774,0.8297872340425532,0.5434782608695652,0.4444444444444444,0.7988533973693848,0.752008318901062,0.7747234106063843,0.7564440965652466,0.7978162295081968,0.4166666666666667,0.34782608695652173,0.2727272727272727,0.4166666666666667,0.10969342182192707,0.9230769230769231,0.88,0.8333333333333334,0.8894855976104736,0.7398285865783691,0.8077839016914368,0.7524892687797546,0.748636393442623,0.3050847457627119,0.1724137931034483,0.12280701754385966,0.3050847457627119,0.2249885589761278,0.35502958579881655,0.21428571428571427,0.1497005988023952,0.722148597240448,0.7677716016769409,0.744261622428894,0.7629514932632446,0.7732448979591837,0.373260193720324,0.1200018821337764,0.1609176806263074,0.2121212121212121,0.0,0.3257639186818591,0.0815319334950687,0.1609176806263074,0.0606060606060606,0.0,0.4307212206478341,0.0623426507445906,0.175693746998261,0.4848484848484848,0.0
529386,katerina7479/pypdflite,katerina7479_pypdflite/pypdflite/pdfobjects/pdfgraphformat.py,pypdflite.pdfobjects.pdfgraphformat.PDFGraphBackground,"class PDFGraphBackground(object):
    def __init__(self, background_style=None, border_size=None, background_border_color=None, background_fill_color=None, padding=0.0, stroke=None):
        self.style = background_style
        self.size = border_size
        self.border_color = background_border_color
        self.fill_color = background_fill_color
        self.padding = padding
        self.stroke = stroke

        self.default_color_list = [PDFColor(79, 129, 189), PDFColor(192, 80, 77), PDFColor(55, 187, 89),
                                   PDFColor(128, 100, 162), PDFColor(72, 172, 198), PDFColor(247, 150, 70),
                                   PDFColor(208, 146, 167), PDFColor(162, 200, 22), PDFColor(231, 188, 41),
                                   PDFColor(156, 133, 192), PDFColor(243, 164, 71), PDFColor(128, 158, 194)]


    @property
    def exists(self):
        if self.style is None and self.size is None and self.border_color is None and self.fill_color is None:
            return False
        else:
            return True","class PDFGraphBackground(object):


    def __init__(self, background_style=None, border_size=None, background_border_color=None, background_fill_color=None, padding=0.0, stroke=None):
        pass

    @property
    def exists(self):
        pass

",4,0,snippet_364,0.2727272727272727,"class PDFGraphBackground(object):
    def __init__(self, background_style=None, border_size=None, background_border_color=None,
                 background_fill_color=None, padding=0.0, stroke=None):
        self.background_style = background_style
        self.border_size = border_size
        self.background_border_color = background_border_color
        self.background_fill_color = background_fill_color
        self.padding = padding
        self.stroke = stroke

    @property
    def exists(self):
        return any([
            self.background_style is not None,
            self.border_size is not None and self.border_size != 0,
            self.background_border_color is not None,
            self.background_fill_color is not None,
            self.padding != 0.0,
            self.stroke is not None
        ])","class PDFGraphBackground(object):
    def __init__(self, background_style=None, border_size=None, background_border_color=None, background_fill_color=None, padding=0.0, stroke=None):
        self.background_style = background_style
        self.border_size = border_size
        self.background_border_color = background_border_color
        self.background_fill_color = background_fill_color
        self.padding = padding
        self.stroke = stroke

    @property
    def exists(self):
        return any(attr is not None for attr in [
            self.background_style,
            self.border_size,
            self.background_border_color,
            self.background_fill_color,
            self.padding,
            self.stroke
        ])","class PDFGraphBackground(object):

    def __init__(self, background_style=None, border_size=None, background_border_color=None, background_fill_color=None, padding=0.0, stroke=None):
        self.background_style = background_style
        self.border_size = border_size
        self.background_border_color = background_border_color
        self.background_fill_color = background_fill_color
        self.padding = padding
        self.stroke = stroke

    @property
    def exists(self):
        return (self.background_style is not None or 
                self.border_size is not None or 
                self.background_border_color is not None or 
                self.background_fill_color is not None or 
                self.stroke is not None)",no_docstr,0.6468085106382978,0.5064377682403433,0.4069264069264069,0.6297872340425532,0.44319730191943413,0.8032786885245902,0.6538461538461539,0.580110497237569,0.8881545662879944,0.770969033241272,0.8254233002662659,0.7812774181365967,0.8131886813186813,0.6272727272727273,0.4862385321100917,0.39814814814814814,0.5909090909090909,0.39804821544309427,0.852760736196319,0.6975308641975309,0.6273291925465838,0.90296471118927,0.7605298161506653,0.8256493210792542,0.7727187871932983,0.8040312637362637,0.6550218340611353,0.5022026431718061,0.4,0.6375545851528384,0.40582190586783307,0.8414634146341463,0.7177914110429447,0.6358024691358025,0.886996865272522,0.7656527757644653,0.8218700289726257,0.7762724161148071,0.8351664835164834,0.3093635420138318,0.2016195617821009,0.2307298760748634,0.4567901234567901,0.348314606741573,0.283981694872924,0.1615994187211394,0.2073693915653964,0.4074074074074074,0.3595505617977528,0.3152320301364736,0.1907243229975896,0.2280620303129046,0.4938271604938271,0.348314606741573
363906,eliangcs/http-prompt,eliangcs_http-prompt/http_prompt/cli.py,http_prompt.cli.ExecutionListener,"class ExecutionListener(object):

    def __init__(self, cfg):
        self.cfg = cfg

    def context_changed(self, context):
        # Dump the current context to HTTP Prompt format
        save_context(context)

    def response_returned(self, context, response):
        if not response.cookies:
            return

        cookie_pref = self.cfg.get('set_cookies') or 'auto'
        if cookie_pref == 'auto' or (
                cookie_pref == 'ask' and
                click.confirm('Cookies incoming! Do you want to set them?')):
            existing_cookie = context.headers.get('Cookie')
            new_cookie = update_cookies(existing_cookie, response.cookies)
            context.headers['Cookie'] = new_cookie
            click.secho('Cookies set: %s' % new_cookie)","class ExecutionListener(object):


    def __init__(self, cfg):
        pass

    def context_changed(self, context):
        pass

    def response_returned(self, context, response):
        pass

",4,0,snippet_230,0.2857142857142857,"class ExecutionListener(object):
    def __init__(self, cfg):
        self.cfg = cfg or {}
        self.log_to_console = self.cfg.get('console', True)
        self.log_file_path = self.cfg.get('log_file')
        self._lock = threading.Lock()
        self._file = None
        if self.log_file_path:
            self._file = open(self.log_file_path, 'a', encoding='utf-8')

    def context_changed(self, context):
        timestamp = datetime.datetime.utcnow().isoformat()
        msg = f""{timestamp} - CONTEXT_CHANGED - {context}\n""
        self._emit(msg)

    def response_returned(self, context, response):
        timestamp = datetime.datetime.utcnow().isoformat()
        msg = f""{timestamp} - RESPONSE_RETURNED - context={context} response={response}\n""
        self._emit(msg)

    def _emit(self, message):
        with self._lock:
            if self.log_to_console:
                print(message, end='')
            if self._file:
                self._file.write(message)
                self._file.flush()

    def __del__(self):
        if self._file:
            try:
                self._file.close()
            except Exception:
                pass","class ExecutionListener(object):
    def __init__(self, cfg):
        self.cfg = cfg

    def context_changed(self, context):
        # Handle context change event
        pass

    def response_returned(self, context, response):
        # Handle response returned event
        pass","class ExecutionListener(object):

    def __init__(self, cfg):
        self.cfg = cfg

    def context_changed(self, context):
        pass

    def response_returned(self, context, response):
        pass",no_docstr,0.31999999999999995,0.18834080717488788,0.14479638009049772,0.24000000000000002,0.21815524228914748,0.35451505016722407,0.18120805369127516,0.16161616161616163,0.7039549350738525,0.7214221358299255,0.7125815153121948,0.7196365594863892,0.7417680632411072,0.3770491803278688,0.31666666666666665,0.288135593220339,0.3770491803278688,0.11214454763882864,0.8448275862068966,0.7894736842105263,0.7678571428571429,0.8909441232681274,0.6655392646789551,0.7619204521179199,0.6828141212463379,0.7451005882352942,0.368421052631579,0.3392857142857143,0.3090909090909091,0.368421052631579,0.06979163391677738,0.9583333333333334,0.9361702127659575,0.9130434782608695,0.9268797636032104,0.642452597618103,0.7588912844657898,0.6627914309501648,0.7426496323529411,0.2953946391927602,0.1357517491943202,0.180570246667986,0.4057971014492754,0.4594594594594595,0.1962760332814279,0.1159893801870253,0.2065217251282673,0.2463768115942029,0.2162162162162162,0.1732672628390191,0.040260919593328,0.1902151039523292,0.2463768115942029,0.2162162162162162
352144,draperunner/fjlc,draperunner_fjlc/fjlc/utils/reader/line_reader.py,draperunner_fjlc.fjlc.utils.reader.line_reader.LineReader,"class LineReader:

    def __init__(self, file_name):
        self.total_lines = file_utils.count_lines(file_name)
        self.file = open(file_name)
        self.line_counter = 0

    def has_next(self):
        return self.line_counter < self.total_lines

    def __next__(self):
        if not self.has_next():
            raise StopIteration
        self.line_counter += 1
        return self.file.readline()

    def __iter__(self):
        return self

    def get_progress(self):
        return 0 if self.total_lines else 100.0 * self.line_counter / self.total_lines","class LineReader:


    def __init__(self, file_name):
        pass

    def has_next(self):
        pass

    def __next__(self):
        pass

    def __iter__(self):
        pass

    def get_progress(self):
        pass

",6,0,snippet_118,0.3333333333333333,"class LineReader:
    def __init__(self, file_name):
        self._file_name = file_name
        self._file = open(file_name, 'r', encoding='utf-8')
        self._total_size = os.path.getsize(file_name)
        first = self._file.readline()
        self._next_line = first if first != '' else None

    def has_next(self):
        return self._next_line is not None

    def __next__(self):
        if self._next_line is None:
            self._file.close()
            raise StopIteration
        current = self._next_line
        nxt = self._file.readline()
        self._next_line = nxt if nxt != '' else None
        return current

    def __iter__(self):
        return self

    def get_progress(self):
        if self._total_size == 0:
            return 1.0
        return self._file.tell() / self._total_size","class LineReader:
    def __init__(self, file_name):
        self.file_name = file_name
        self.file = open(file_name, 'r')
        self.current_line = None
        self._eof = False
        self._total_size = self._get_file_size()
        self._bytes_read = 0

    def _get_file_size(self):
        current_pos = self.file.tell()
        self.file.seek(0, 2)  # Seek to end
        size = self.file.tell()
        self.file.seek(current_pos)  # Return to original position
        return size

    def has_next(self):
        if self._eof:
            return False
        # Peek at the next line
        current_pos = self.file.tell()
        line = self.file.readline()
        self.file.seek(current_pos)
        if line == '':
            self._eof = True
            return False
        return True

    def __next__(self):
        if not self.has_next():
            raise StopIteration
        line = self.file.readline()
        if line == '':
            raise StopIteration
        self._bytes_read = self.file.tell()
        self.current_line = line.rstrip('\n')
        return self.current_line

    def __iter__(self):
        return self

    def get_progress(self):
        if self._total_size == 0:
            return 1.0
        return min(self._bytes_read / self._total_size, 1.0)

    def __del__(self):
        if hasattr(self, 'file') and not self.file.closed:
            self.file.close()","class LineReader:
    def __init__(self, file_name):
        self.file_name = file_name
        self.file = open(file_name, 'r')
        self.file.seek(0, 2)
        self.total_size = self.file.tell()
        self.file.seek(0)
        self.current_position = 0
        self._next_line = None
        self._has_next = True
        self._peek_next()

    def _peek_next(self):
        try:
            self._next_line = self.file.readline()
            if not self._next_line:
                self._has_next = False
                self.file.close()
            else:
                self.current_position = self.file.tell()
        except:
            self._has_next = False
            self.file.close()

    def has_next(self):
        return self._has_next

    def __next__(self):
        if not self._has_next:
            raise StopIteration
        
        line = self._next_line.rstrip('\n\r')
        self._peek_next()
        return line

    def __iter__(self):
        return self

    def get_progress(self):
        if self.total_size == 0:
            return 1.0
        return min(1.0, self.current_position / self.total_size)",no_docstr,0.6774193548387097,0.40217391304347827,0.29670329670329676,0.5806451612903226,0.4450662673266071,0.6118721461187214,0.44036697247706424,0.3271889400921659,0.8397810459136963,0.8825668096542358,0.8606424927711487,0.8780930638313293,0.8273826785714287,0.49230769230769234,0.3255813953488372,0.2421875,0.4384615384615385,0.2931400367898398,0.3708791208791209,0.2892561983471074,0.23480662983425415,0.7856425046920776,0.8558754920959473,0.8192565441131592,0.8482921719551086,0.7614179109589047,0.5882352941176471,0.3835616438356164,0.29493087557603687,0.47963800904977383,0.36690183680222715,0.46258503401360546,0.3583617747440273,0.2979452054794521,0.8084228038787842,0.8492245674133301,0.8283215165138245,0.8449599742889404,0.7787378448275861,0.2616171823211685,0.152660021797084,0.2695149221768556,0.4576271186440678,0.1666666666666666,0.3616721527390805,0.1301437901510186,0.3683338980181096,0.559322033898305,0.3888888888888889,0.3149215353067838,0.160330554361551,0.3022746075812151,0.4915254237288136,0.3055555555555556
327888,danielhrisca/asammdf,danielhrisca_asammdf/src/asammdf/gui/ui/gps_dialog.py,asammdf.gui.ui.gps_dialog.Ui_GPSDialog,"class Ui_GPSDialog(object):
    def setupUi(self, GPSDialog):
        if not GPSDialog.objectName():
            GPSDialog.setObjectName(u""GPSDialog"")
        GPSDialog.resize(623, 190)
        icon = QIcon()
        icon.addFile(u"":/globe.png"", QSize(), QIcon.Mode.Normal, QIcon.State.Off)
        GPSDialog.setWindowIcon(icon)
        GPSDialog.setSizeGripEnabled(True)
        self.gridLayout = QGridLayout(GPSDialog)
        self.gridLayout.setSpacing(1)
        self.gridLayout.setObjectName(u""gridLayout"")
        self.gridLayout.setContentsMargins(1, 1, 1, 1)
        self.label_3 = QLabel(GPSDialog)
        self.label_3.setObjectName(u""label_3"")

        self.gridLayout.addWidget(self.label_3, 0, 0, 1, 3)

        self.horizontalLayout = QHBoxLayout()
        self.horizontalLayout.setSpacing(1)
        self.horizontalLayout.setObjectName(u""horizontalLayout"")
        self.horizontalSpacer = QSpacerItem(40, 20, QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Minimum)

        self.horizontalLayout.addItem(self.horizontalSpacer)

        self.cancel_btn = QPushButton(GPSDialog)
        self.cancel_btn.setObjectName(u""cancel_btn"")

        self.horizontalLayout.addWidget(self.cancel_btn)

        self.horizontalSpacer_2 = QSpacerItem(20, 20, QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Minimum)

        self.horizontalLayout.addItem(self.horizontalSpacer_2)

        self.apply_btn = QPushButton(GPSDialog)
        self.apply_btn.setObjectName(u""apply_btn"")

        self.horizontalLayout.addWidget(self.apply_btn)

        self.horizontalLayout.setStretch(0, 1)

        self.gridLayout.addLayout(self.horizontalLayout, 5, 0, 1, 3)

        self.latitude = QLineEdit(GPSDialog)
        self.latitude.setObjectName(u""latitude"")

        self.gridLayout.addWidget(self.latitude, 2, 1, 1, 1)

        self.search_latitude_btn = QPushButton(GPSDialog)
        self.search_latitude_btn.setObjectName(u""search_latitude_btn"")
        icon1 = QIcon()
        icon1.addFile(u"":/search.png"", QSize(), QIcon.Mode.Normal, QIcon.State.Off)
        self.search_latitude_btn.setIcon(icon1)

        self.gridLayout.addWidget(self.search_latitude_btn, 2, 2, 1, 1)

        self.label_2 = QLabel(GPSDialog)
        self.label_2.setObjectName(u""label_2"")

        self.gridLayout.addWidget(self.label_2, 3, 0, 1, 1)

        self.label = QLabel(GPSDialog)
        self.label.setObjectName(u""label"")

        self.gridLayout.addWidget(self.label, 2, 0, 1, 1)

        self.search_longitude_btn = QPushButton(GPSDialog)
        self.search_longitude_btn.setObjectName(u""search_longitude_btn"")
        self.search_longitude_btn.setIcon(icon1)

        self.gridLayout.addWidget(self.search_longitude_btn, 3, 2, 1, 1)

        self.verticalSpacer = QSpacerItem(20, 20, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding)

        self.gridLayout.addItem(self.verticalSpacer, 1, 0, 1, 1)

        self.longitude = QLineEdit(GPSDialog)
        self.longitude.setObjectName(u""longitude"")

        self.gridLayout.addWidget(self.longitude, 3, 1, 1, 1)

        self.verticalSpacer_2 = QSpacerItem(20, 40, QSizePolicy.Policy.Minimum, QSizePolicy.Policy.Expanding)

        self.gridLayout.addItem(self.verticalSpacer_2, 4, 0, 1, 1)

        self.gridLayout.setRowStretch(4, 1)
        QWidget.setTabOrder(self.latitude, self.longitude)
        QWidget.setTabOrder(self.longitude, self.search_latitude_btn)
        QWidget.setTabOrder(self.search_latitude_btn, self.search_longitude_btn)
        QWidget.setTabOrder(self.search_longitude_btn, self.apply_btn)
        QWidget.setTabOrder(self.apply_btn, self.cancel_btn)

        self.retranslateUi(GPSDialog)

        QMetaObject.connectSlotsByName(GPSDialog)
    # setupUi

    def retranslateUi(self, GPSDialog):
        GPSDialog.setWindowTitle(QCoreApplication.translate(""GPSDialog"", u""GPS channels selection"", None))
        self.label_3.setText(QCoreApplication.translate(""GPSDialog"", u""Search for the latitude and longitude channels:"", None))
        self.cancel_btn.setText(QCoreApplication.translate(""GPSDialog"", u""Cancel"", None))
        self.apply_btn.setText(QCoreApplication.translate(""GPSDialog"", u""Apply"", None))
        self.search_latitude_btn.setText("""")
        self.label_2.setText(QCoreApplication.translate(""GPSDialog"", u""Longitude"", None))
        self.label.setText(QCoreApplication.translate(""GPSDialog"", u""Latitude"", None))
        self.search_longitude_btn.setText("""")","class Ui_GPSDialog(object):


    def setupUi(self, GPSDialog):
        pass

    def retranslateUi(self, GPSDialog):
        pass

",3,0,snippet_577,0.6,"class Ui_GPSDialog(object):
    def setupUi(self, GPSDialog):
        GPSDialog.setObjectName(""GPSDialog"")
        GPSDialog.resize(400, 150)
        self.gridLayout = QtWidgets.QGridLayout(GPSDialog)
        self.gridLayout.setObjectName(""gridLayout"")

        self.labelLatitude = QtWidgets.QLabel(GPSDialog)
        self.labelLatitude.setObjectName(""labelLatitude"")
        self.gridLayout.addWidget(self.labelLatitude, 0, 0, 1, 1)
        self.lineEditLatitude = QtWidgets.QLineEdit(GPSDialog)
        self.lineEditLatitude.setObjectName(""lineEditLatitude"")
        self.gridLayout.addWidget(self.lineEditLatitude, 0, 1, 1, 1)

        self.labelLongitude = QtWidgets.QLabel(GPSDialog)
        self.labelLongitude.setObjectName(""labelLongitude"")
        self.gridLayout.addWidget(self.labelLongitude, 1, 0, 1, 1)
        self.lineEditLongitude = QtWidgets.QLineEdit(GPSDialog)
        self.lineEditLongitude.setObjectName(""lineEditLongitude"")
        self.gridLayout.addWidget(self.lineEditLongitude, 1, 1, 1, 1)

        self.labelAltitude = QtWidgets.QLabel(GPSDialog)
        self.labelAltitude.setObjectName(""labelAltitude"")
        self.gridLayout.addWidget(self.labelAltitude, 2, 0, 1, 1)
        self.lineEditAltitude = QtWidgets.QLineEdit(GPSDialog)
        self.lineEditAltitude.setObjectName(""lineEditAltitude"")
        self.gridLayout.addWidget(self.lineEditAltitude, 2, 1, 1, 1)

        self.buttonBox = QtWidgets.QDialogButtonBox(GPSDialog)
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(
            QtWidgets.QDialogButtonBox.Cancel | QtWidgets.QDialogButtonBox.Ok
        )
        self.buttonBox.setObjectName(""buttonBox"")
        self.gridLayout.addWidget(self.buttonBox, 3, 0, 1, 2)

        self.retranslateUi(GPSDialog)
        self.buttonBox.accepted.connect(GPSDialog.accept)
        self.buttonBox.rejected.connect(GPSDialog.reject)
        QtCore.QMetaObject.connectSlotsByName(GPSDialog)

    def retranslateUi(self, GPSDialog):
        _translate = QtCore.QCoreApplication.translate
        GPSDialog.setWindowTitle(_translate(""GPSDialog"", ""GPS Coordinates""))
        self.labelLatitude.setText(_translate(""GPSDialog"", ""Latitude:""))
        self.labelLongitude.setText(_translate(""GPSDialog"", ""Longitude:""))
        self.labelAltitude.setText(_translate(""GPSDialog"", ""Altitude:""))","class Ui_GPSDialog(object):
    def setupUi(self, GPSDialog):
        GPSDialog.setObjectName(""GPSDialog"")
        GPSDialog.resize(400, 300)
        self.gridLayout = QtWidgets.QGridLayout(GPSDialog)
        self.gridLayout.setObjectName(""gridLayout"")
        
        self.label_latitude = QtWidgets.QLabel(GPSDialog)
        self.label_latitude.setObjectName(""label_latitude"")
        self.gridLayout.addWidget(self.label_latitude, 0, 0, 1, 1)
        
        self.lineEdit_latitude = QtWidgets.QLineEdit(GPSDialog)
        self.lineEdit_latitude.setObjectName(""lineEdit_latitude"")
        self.gridLayout.addWidget(self.lineEdit_latitude, 0, 1, 1, 1)
        
        self.label_longitude = QtWidgets.QLabel(GPSDialog)
        self.label_longitude.setObjectName(""label_longitude"")
        self.gridLayout.addWidget(self.label_longitude, 1, 0, 1, 1)
        
        self.lineEdit_longitude = QtWidgets.QLineEdit(GPSDialog)
        self.lineEdit_longitude.setObjectName(""lineEdit_longitude"")
        self.gridLayout.addWidget(self.lineEdit_longitude, 1, 1, 1, 1)
        
        self.label_altitude = QtWidgets.QLabel(GPSDialog)
        self.label_altitude.setObjectName(""label_altitude"")
        self.gridLayout.addWidget(self.label_altitude, 2, 0, 1, 1)
        
        self.lineEdit_altitude = QtWidgets.QLineEdit(GPSDialog)
        self.lineEdit_altitude.setObjectName(""lineEdit_altitude"")
        self.gridLayout.addWidget(self.lineEdit_altitude, 2, 1, 1, 1)
        
        self.buttonBox = QtWidgets.QDialogButtonBox(GPSDialog)
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel|QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.gridLayout.addWidget(self.buttonBox, 3, 0, 1, 2)
        
        self.retranslateUi(GPSDialog)
        self.buttonBox.accepted.connect(GPSDialog.accept)
        self.buttonBox.rejected.connect(GPSDialog.reject)
        QtCore.QMetaObject.connectSlotsByName(GPSDialog)

    def retranslateUi(self, GPSDialog):
        _translate = QtCore.QCoreApplication.translate
        GPSDialog.setWindowTitle(_translate(""GPSDialog"", ""GPS Coordinates""))
        self.label_latitude.setText(_translate(""GPSDialog"", ""Latitude:""))
        self.label_longitude.setText(_translate(""GPSDialog"", ""Longitude:""))
        self.label_altitude.setText(_translate(""GPSDialog"", ""Altitude:""))","class Ui_GPSDialog(object):
    def setupUi(self, GPSDialog):
        GPSDialog.setObjectName(""GPSDialog"")
        GPSDialog.resize(400, 300)
        self.verticalLayout = QtWidgets.QVBoxLayout(GPSDialog)
        self.verticalLayout.setObjectName(""verticalLayout"")
        
        self.groupBox = QtWidgets.QGroupBox(GPSDialog)
        self.groupBox.setObjectName(""groupBox"")
        self.formLayout = QtWidgets.QFormLayout(self.groupBox)
        self.formLayout.setObjectName(""formLayout"")
        
        self.label_latitude = QtWidgets.QLabel(self.groupBox)
        self.label_latitude.setObjectName(""label_latitude"")
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.LabelRole, self.label_latitude)
        
        self.lineEdit_latitude = QtWidgets.QLineEdit(self.groupBox)
        self.lineEdit_latitude.setObjectName(""lineEdit_latitude"")
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.FieldRole, self.lineEdit_latitude)
        
        self.label_longitude = QtWidgets.QLabel(self.groupBox)
        self.label_longitude.setObjectName(""label_longitude"")
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.LabelRole, self.label_longitude)
        
        self.lineEdit_longitude = QtWidgets.QLineEdit(self.groupBox)
        self.lineEdit_longitude.setObjectName(""lineEdit_longitude"")
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.FieldRole, self.lineEdit_longitude)
        
        self.label_altitude = QtWidgets.QLabel(self.groupBox)
        self.label_altitude.setObjectName(""label_altitude"")
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.LabelRole, self.label_altitude)
        
        self.lineEdit_altitude = QtWidgets.QLineEdit(self.groupBox)
        self.lineEdit_altitude.setObjectName(""lineEdit_altitude"")
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.FieldRole, self.lineEdit_altitude)
        
        self.verticalLayout.addWidget(self.groupBox)
        
        self.buttonBox = QtWidgets.QDialogButtonBox(GPSDialog)
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel|QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.verticalLayout.addWidget(self.buttonBox)
        
        self.retranslateUi(GPSDialog)
        self.buttonBox.accepted.connect(GPSDialog.accept)
        self.buttonBox.rejected.connect(GPSDialog.reject)
        QtCore.QMetaObject.connectSlotsByName(GPSDialog)

    def retranslateUi(self, GPSDialog):
        _translate = QtCore.QCoreApplication.translate
        GPSDialog.setWindowTitle(_translate(""GPSDialog"", ""GPS Coordinates""))
        self.groupBox.setTitle(_translate(""GPSDialog"", ""Location""))
        self.label_latitude.setText(_translate(""GPSDialog"", ""Latitude:""))
        self.label_longitude.setText(_translate(""GPSDialog"", ""Longitude:""))
        self.label_altitude.setText(_translate(""GPSDialog"", ""Altitude:""))",no_docstr,0.4127423822714682,0.2611111111111111,0.15041782729805012,0.37119113573407203,0.1909423945834634,0.8574423480083857,0.6428571428571429,0.5010526315789474,0.8789504766464233,0.8357135653495789,0.8567869067192078,0.8398448824882507,0.822588295081967,0.48598130841121495,0.2945113788487282,0.17181208053691274,0.39519359145527366,0.2454210589917964,0.8832391713747646,0.6735849056603773,0.499054820415879,0.8838552832603455,0.8380352854728699,0.860335648059845,0.8424022793769836,0.822588295081967,0.39948783610755445,0.1283697047496791,0.03346203346203346,0.2996158770806658,0.23186638749186497,0.8016528925619835,0.5016556291390728,0.29850746268656714,0.855323076248169,0.8283730149269104,0.8416323661804199,0.8309913277626038,0.8338814426229507,0.255774803721103,0.0608748226267587,0.0868643692161789,0.6495535714285714,0.2258064516129032,0.2551142958539719,0.058232791158234,0.0868643692161789,0.6495535714285714,0.2258064516129032,0.2288546817983136,0.0175770090849598,0.0296533540529949,0.6004464285714286,0.267741935483871
289068,childsish/lhc-python,childsish_lhc-python/src/lhc/entities/multiple_alignment/alignment.py,lhc.entities.multiple_alignment.alignment.Alignment,"class Alignment:
    END = 0
    DIAG = 1
    LEFT = 2
    UP = 3

    def __init__(self, s1: str, s2: str):
        self.s1 = s1
        self.s2 = s2

        self.scores = numpy.zeros((len(s1) + 1, len(s2) + 1), numpy.int32)
        self.pointers = numpy.zeros((len(s1) + 1, len(s2) + 1), numpy.int32)
        self.stop = [len(s1) - 1, len(s2) - 1]
        self.max = [len(s1) - 1, len(s2) - 1]

    def __str__(self) -> str:
        si = self.s1
        sj = self.s2
        i, j = self.stop

        a = []
        ai = []
        aj = []

        pointer = self.pointers[i, j]
        while pointer != Alignment.END:
            if pointer == Alignment.LEFT:
                ai.append('-')
                aj.append(sj[j])
                a.append(' ')
                j -= 1
            elif pointer == Alignment.UP:
                ai.append(si[i])
                aj.append('-')
                a.append(' ')
                i -= 1
            elif pointer == Alignment.DIAG:
                ai.append(si[i])
                aj.append(sj[j])
                a.append('|' if si[i] == sj[j] else '.')
                i -= 1
                j -= 1
            pointer = self.pointers[i, j]

        return ''.join(reversed(ai)) + '\n' + ''.join(reversed(a)) + '\n' + ''.join(reversed(aj))

    def get_entry(self, i: int, j: int):
        return self.scores[i, j], self.pointers[i, j]

    def set_entry(self, i: int, j: int, score: int, pointer: int):
        self.scores[i, j] = score
        self.pointers[i, j] = pointer

    def get_score(self) -> int:
        return self.scores[self.max[0], self.max[1]]","class Alignment:


    def __init__(self, s1: str, s2: str):
        pass

    def __str__(self) -> str:
        pass

    def get_entry(self, i: int, j: int):
        pass

    def set_entry(self, i: int, j: int, score: int, pointer: int):
        pass

    def get_score(self) -> int:
        pass

",6,0,snippet_402,0.1666666666666666,"class Alignment:

    def __init__(self, s1: str, s2: str):
        self.s1 = s1
        self.s2 = s2
        # matrix of (score, pointer) tuples
        self.matrix = [
            [(None, None) for _ in range(len(s2) + 1)]
            for _ in range(len(s1) + 1)
        ]

    def __str__(self) -> str:
        # header row
        cols = [""  ""] + list(self.s2)
        header = ""  "".join(cols)
        lines = [header]
        # each row
        for i, row in enumerate(self.matrix):
            label = self.s1[i - 1] if i > 0 else "" ""
            entries = []
            for score, ptr in row:
                s = str(score) if score is not None else "".""
                p = str(ptr) if ptr is not None else "".""
                entries.append(f""{s},{p}"")
            lines.append(label + "" "" + "" "".join(entries))
        return ""\n"".join(lines)

    def get_entry(self, i: int, j: int):
        if i < 0 or j < 0 or i > len(self.s1) or j > len(self.s2):
            raise IndexError(""Alignment indices out of range"")
        return self.matrix[i][j]

    def set_entry(self, i: int, j: int, score: int, pointer: int):
        if i < 0 or j < 0 or i > len(self.s1) or j > len(self.s2):
            raise IndexError(""Alignment indices out of range"")
        self.matrix[i][j] = (score, pointer)

    def get_score(self) -> int:
        sc, _ = self.matrix[len(self.s1)][len(self.s2)]
        return sc","class Alignment:
    def __init__(self, s1: str, s2: str):
        self.s1 = s1
        self.s2 = s2
        self.matrix = [[None for _ in range(len(s2) + 1)] for _ in range(len(s1) + 1)]
        self.final_score = None

    def __str__(self) -> str:
        result = """"
        for i in range(len(self.s1) + 1):
            for j in range(len(self.s2) + 1):
                if self.matrix[i][j] is None:
                    result += ""None\t""
                else:
                    result += f""({self.matrix[i][j][0]},{self.matrix[i][j][1]})\t""
            result += ""\n""
        return result

    def get_entry(self, i: int, j: int):
        if 0 <= i <= len(self.s1) and 0 <= j <= len(self.s2):
            return self.matrix[i][j]
        return None

    def set_entry(self, i: int, j: int, score: int, pointer: int):
        if 0 <= i <= len(self.s1) and 0 <= j <= len(self.s2):
            self.matrix[i][j] = (score, pointer)
            if i == len(self.s1) and j == len(self.s2):
                self.final_score = score

    def get_score(self) -> int:
        return self.final_score","class Alignment:
    def __init__(self, s1: str, s2: str):
        self.s1 = s1
        self.s2 = s2
        self.rows = len(s1) + 1
        self.cols = len(s2) + 1
        self.matrix = [[(0, 0) for _ in range(self.cols)] for _ in range(self.rows)]

    def __str__(self) -> str:
        result = []
        for i in range(self.rows):
            row_str = []
            for j in range(self.cols):
                score, pointer = self.matrix[i][j]
                row_str.append(f""({score},{pointer})"")
            result.append("" "".join(row_str))
        return ""\n"".join(result)

    def get_entry(self, i: int, j: int):
        return self.matrix[i][j]

    def set_entry(self, i: int, j: int, score: int, pointer: int):
        self.matrix[i][j] = (score, pointer)

    def get_score(self) -> int:
        return self.matrix[self.rows - 1][self.cols - 1][0]",no_docstr,0.5450121654501217,0.2591687041564792,0.19164619164619165,0.3795620437956205,0.3724182029717779,0.6852300242130751,0.4174757281553398,0.291970802919708,0.80390465259552,0.8047943115234375,0.8043492436408997,0.8047052025794983,0.747153525641026,0.5989304812834224,0.3225806451612903,0.21081081081081082,0.427807486631016,0.3589717197926557,0.7724719101123596,0.48732394366197185,0.3474576271186441,0.8416527509689331,0.8006488680839539,0.8206389546394348,0.8045685887336731,0.7478657692307692,0.5178571428571428,0.34131736526946105,0.27108433734939763,0.4821428571428572,0.28802590062807115,0.8064516129032258,0.5683453237410072,0.45126353790613716,0.8301451802253723,0.7965657711029053,0.8130089640617371,0.7998009324073792,0.7913126282051287,0.2769138955649812,0.1772372078592143,0.198487664903133,0.4696356275303643,0.2622950819672131,0.22864310617577,0.1748029434574504,0.1968832619141987,0.4008097165991903,0.1420765027322404,0.2461912172707864,0.1490055019783532,0.2019902027057749,0.4534412955465587,0.180327868852459
813293,uktrade/directory-client-core,uktrade_directory-client-core/directory_client_core/helpers.py,directory_client_core.helpers.PopulateResponseMixin,"class PopulateResponseMixin:

    @classmethod
    def from_response(cls, raw_response):
        response = cls()
        response.__setstate__(raw_response.__getstate__())
        return response","class PopulateResponseMixin:


    @classmethod
    def from_response(cls, raw_response):
        pass

",3,0,snippet_206,0.6666666666666666,"class PopulateResponseMixin:
    @classmethod
    def from_response(cls, raw_response):
        if hasattr(raw_response, 'json') and callable(raw_response.json):
            data = raw_response.json()
        else:
            data = raw_response

        if isinstance(data, str):
            data = json.loads(data)

        if not isinstance(data, dict):
            raise ValueError(f""Expected dict or JSON response, got {type(data).__name__}"")

        instance = cls(**data)
        setattr(instance, 'raw_response', raw_response)
        return instance","class PopulateResponseMixin:
    @classmethod
    def from_response(cls, raw_response):
        """"""
        Create an instance of the class from a raw response dictionary.
        
        Args:
            raw_response (dict): The raw response data to populate the object with
            
        Returns:
            An instance of the class populated with the response data
        """"""
        instance = cls()
        
        # Get all attributes that can be set on the instance
        for key, value in raw_response.items():
            if hasattr(instance, key):
                setattr(instance, key, value)
            elif hasattr(instance, f""_{key}""):
                # Try setting private attribute if public doesn't exist
                setattr(instance, f""_{key}"", value)
        
        return instance","class PopulateResponseMixin:
    @classmethod
    def from_response(cls, raw_response):
        instance = cls()
        
        if hasattr(raw_response, 'json'):
            try:
                data = raw_response.json()
            except (ValueError, AttributeError):
                data = {}
        elif isinstance(raw_response, dict):
            data = raw_response
        else:
            try:
                import json
                data = json.loads(raw_response)
            except (ValueError, TypeError):
                data = {}
        
        for key, value in data.items():
            if hasattr(instance, key):
                setattr(instance, key, value)
        
        return instance",no_docstr,0.3950617283950617,0.2278481012658228,0.18181818181818182,0.37037037037037035,0.23757158854243796,0.3412698412698413,0.232,0.1693548387096774,0.7362080216407776,0.8827511668205261,0.8028473258018494,0.8655228018760681,0.7540477669902912,0.29090909090909095,0.16666666666666669,0.13207547169811323,0.2545454545454546,0.17909004793363684,0.25333333333333335,0.16778523489932887,0.13513513513513514,0.6500635147094727,0.8653764724731445,0.7424241900444031,0.8376325964927673,0.7807039473684211,0.39999999999999997,0.23076923076923075,0.18421052631578946,0.35000000000000003,0.22174389348772006,0.30952380952380953,0.208,0.1693548387096774,0.67918860912323,0.8711607456207275,0.7632891535758972,0.8472143411636353,0.7515176363636363,0.4603438528801468,0.1101721283899165,0.4740604259878136,0.4,0.8571428571428571,0.5320298551286566,0.0643083301896871,0.5138110903249394,0.55,1.0,0.5370954109263105,0.0961242499769302,0.5022573937283119,0.55,1.0
741813,skelsec/msldap,skelsec_msldap/msldap/external/bloodhoundpy/acls.py,msldap.external.bloodhoundpy.acls.ACCESS_MASK,"class ACCESS_MASK(object):
    # Flag constants

    # These constants are only used when WRITING
    # and are then translated into their actual rights
    SET_GENERIC_READ        = 0x80000000
    SET_GENERIC_WRITE       = 0x04000000
    SET_GENERIC_EXECUTE     = 0x20000000
    SET_GENERIC_ALL         = 0x10000000
    # When reading, these constants are actually represented by
    # the following for Active Directory specific Access Masks
    # Reference: https://docs.microsoft.com/en-us/dotnet/api/system.directoryservices.activedirectoryrights?view=netframework-4.7.2
    GENERIC_READ            = 0x00020094
    GENERIC_WRITE           = 0x00020028
    GENERIC_EXECUTE         = 0x00020004
    GENERIC_ALL             = 0x000F01FF

    # These are actual rights (for all ACE types)
    MAXIMUM_ALLOWED         = 0x02000000
    ACCESS_SYSTEM_SECURITY  = 0x01000000
    SYNCHRONIZE             = 0x00100000
    WRITE_OWNER             = 0x00080000
    WRITE_DACL              = 0x00040000
    READ_CONTROL            = 0x00020000
    DELETE                  = 0x00010000

    # ACE type specific mask constants (for ACCESS_ALLOWED_OBJECT_ACE)
    # Note that while not documented, these also seem valid
    # for ACCESS_ALLOWED_ACE types
    ADS_RIGHT_DS_CONTROL_ACCESS         = 0x00000100
    ADS_RIGHT_DS_CREATE_CHILD           = 0x00000001
    ADS_RIGHT_DS_DELETE_CHILD           = 0x00000002
    ADS_RIGHT_DS_READ_PROP              = 0x00000010
    ADS_RIGHT_DS_WRITE_PROP             = 0x00000020
    ADS_RIGHT_DS_SELF                   = 0x00000008

    def __init__(self, mask):
        self.mask = mask

    def has_priv(self, priv):
        return self.mask & priv == priv

    def set_priv(self, priv):
        self.mask |= priv

    def remove_priv(self, priv):
        self.mask ^= priv

    def __repr__(self):
        out = []
        #for name, value in iteritems(vars(ACCESS_MASK)):
        for name, value in vars(ACCESS_MASK):
            if not name.startswith('_') and type(value) is int and self.has_priv(value):
                out.append(name)
        return ""<ACCESS_MASK RawMask=%d Flags=%s>"" % (self.mask, ' | '.join(out))","class ACCESS_MASK(object):


    def __init__(self, mask):
        pass

    def has_priv(self, priv):
        pass

    def set_priv(self, priv):
        pass

    def remove_priv(self, priv):
        pass

    def __repr__(self):
        pass

",6,0,snippet_518,0.5,"class ACCESS_MASK(object):
    def __init__(self, mask):
        if not isinstance(mask, int):
            raise TypeError(""mask must be an integer"")
        self._mask = mask

    def has_priv(self, priv):
        if not isinstance(priv, int):
            raise TypeError(""priv must be an integer"")
        return bool(self._mask & priv)

    def set_priv(self, priv):
        if not isinstance(priv, int):
            raise TypeError(""priv must be an integer"")
        self._mask |= priv

    def remove_priv(self, priv):
        if not isinstance(priv, int):
            raise TypeError(""priv must be an integer"")
        self._mask &= ~priv

    def __repr__(self):
        return f""{self.__class__.__name__}(0x{self._mask:08X})""","class ACCESS_MASK(object):
    def __init__(self, mask):
        self.mask = mask

    def has_priv(self, priv):
        return bool(self.mask & priv)

    def set_priv(self, priv):
        self.mask |= priv

    def remove_priv(self, priv):
        self.mask &= ~priv

    def __repr__(self):
        return f""ACCESS_MASK({self.mask})""","class ACCESS_MASK(object):

    def __init__(self, mask):
        self.mask = mask

    def has_priv(self, priv):
        return bool(self.mask & priv)

    def set_priv(self, priv):
        self.mask |= priv

    def remove_priv(self, priv):
        self.mask &= ~priv

    def __repr__(self):
        return f""ACCESS_MASK({self.mask})""",no_docstr,0.3005780346820809,0.20348837209302326,0.15204678362573099,0.24855491329479767,0.1347920545703545,0.7029702970297029,0.39800995024875624,0.31,0.7676256895065308,0.6578140258789062,0.7084900736808777,0.6673609018325806,0.7089018552036213,0.2983050847457627,0.2593856655290102,0.21993127147766323,0.2983050847457627,0.028955214657480386,0.9411764705882353,0.8118811881188119,0.75,0.8121286630630493,0.6017377376556396,0.6912795305252075,0.617741048336029,0.7616916742081457,0.2983050847457627,0.2593856655290102,0.21993127147766323,0.2983050847457627,0.028955214657480386,0.9411764705882353,0.8118811881188119,0.75,0.811859130859375,0.6012932062149048,0.690888524055481,0.6173037886619568,0.7616916742081457,0.1021556889160302,0.025426608714698,0.0628498266031025,0.2727272727272727,0.0476190476190476,0.1055985484565865,0.0028672574743756,0.1048083216333557,0.2909090909090909,0.0238095238095238,0.1055985484565865,0.0028672574743756,0.1048083216333557,0.2909090909090909,0.0238095238095238
92318,Azure/azure-sdk-for-python,Azure_azure-sdk-for-python/sdk/containerregistry/azure-containerregistry/samples/sample_hello_world.py,sample_hello_world.HelloWorld,"class HelloWorld(object):
    def __init__(self):
        load_dotenv(find_dotenv())
        self.endpoint = os.environ[""CONTAINERREGISTRY_ENDPOINT""]
        self.authority = get_authority(self.endpoint)
        self.credential = get_credential(self.authority)

    def basic_sample(self):
        load_registry(self.endpoint)
        # Instantiate an instance of ContainerRegistryClient
        # [START create_registry_client]
        with ContainerRegistryClient(self.endpoint, self.credential) as client:
            # [END create_registry_client]
            # Iterate through all the repositories
            for repository_name in client.list_repository_names():
                print(repository_name)
                if repository_name == ""library/hello-world"":
                    print(""Tags of repository library/hello-world:"")
                    for tag in client.list_tag_properties(repository_name):
                        print(tag.name)

                        # Make sure will have the permission to delete the repository later
                        client.update_manifest_properties(repository_name, tag.name, can_write=True, can_delete=True)

                    print(""Deleting "" + repository_name)
                    # [START delete_repository]
                    client.delete_repository(repository_name)","class HelloWorld(object):


    def __init__(self):
        pass

    def basic_sample(self):
        pass

",3,0,snippet_739,0.2727272727272727,"class HelloWorld(object):
    def __init__(self):
        self.message = ""Hello, World!""

    def basic_sample(self):
        print(self.message)","class HelloWorld(object):
    def __init__(self):
        self.message = ""Hello, World!""

    def basic_sample(self):
        return self.message","class HelloWorld(object):

    def __init__(self):
        self.message = ""Hello, World!""

    def basic_sample(self):
        return self.message",no_docstr,0.19736842105263155,0.12,0.08108108108108109,0.15789473684210528,0.003143616083494495,0.8780487804878049,0.725,0.6153846153846154,0.8263105750083923,0.5460690259933472,0.6575769782066345,0.5652389526367188,0.7313158181818182,0.18421052631578946,0.12,0.08108108108108109,0.15789473684210528,0.0021112957693040692,0.8461538461538461,0.6842105263157895,0.5675675675675675,0.8179159164428711,0.5403242111206055,0.6507534980773926,0.5593065023422241,0.723235090909091,0.18421052631578946,0.12,0.08108108108108109,0.15789473684210528,0.0021112957693040692,0.8461538461538461,0.6842105263157895,0.5675675675675675,0.8185684680938721,0.5414022207260132,0.6517416834831238,0.5603764653205872,0.723235090909091,0.3594202712417498,0.0004562388220136,0.0394975734177127,0.3977272727272727,0.0,0.3310889426327718,0.0007672880224652,0.0394975734177127,0.2840909090909091,0.0,0.3310889426327718,0.0007672880224652,0.0394975734177127,0.2840909090909091,0.0
725052,seatgeek/businesstime,seatgeek_businesstime/businesstime/holidays/__init__.py,businesstime.holidays.Holidays,"class Holidays(object):

    rules = []

    def month_length(self, year, month):
        return calendar.monthrange(year, month)[1]

    def _day_rule_matches(self, rule, dt):
        return dt.month == rule.get(""month"") and dt.day == rule.get(""day"")

    def _weekday_rule_matches(self, rule, dt):
        if dt.month == rule.get(""month"") and dt.weekday() == rule.get(
                ""weekday""):
            # Check for +week specification
            if math.floor((dt.day - 1) / 7) == rule.get(""week"") - 1:
                return True
            # Check for -week specification
            length = self.month_length(dt.year, dt.month)
            if math.floor((length - dt.day) / 7) + 1 == rule.get(""week"") * -1:
                return True
        return False

    def isholiday(self, dt):
        for r in self.rules:
            if self._day_rule_matches(r, dt) or self._weekday_rule_matches(
                    r, dt):
                return True
        return False

    def __call__(self, curr, end=None):
        while end is None or curr < end:
            if self.isholiday(curr):
                yield curr
            curr = curr + datetime.timedelta(days=1)","class Holidays(object):


    def month_length(self, year, month):
        pass

    def _day_rule_matches(self, rule, dt):
        pass

    def _weekday_rule_matches(self, rule, dt):
        pass

    def isholiday(self, dt):
        pass

    def __call__(self, curr, end=None):
        pass

",6,0,snippet_456,0.2413793103448276,"class Holidays(object):
    def __init__(self, rules=None):
        """"""
        rules is a list of dicts. Each dict is either:
        {""month"": M, ""day"": D}                    # fixed date holiday
        or
        {""month"": M, ""weekday"": W, ""n"": N}        # Nth W-day of month, N can be negative
        """"""
        self.rules = rules or []

    def month_length(self, year, month):
        return calendar.monthrange(year, month)[1]

    def _day_rule_matches(self, rule, dt):
        return dt.month == rule[""month""] and dt.day == rule[""day""]

    def _weekday_rule_matches(self, rule, dt):
        if dt.month != rule[""month""] or dt.weekday() != rule[""weekday""]:
            return False
        n = rule[""n""]
        # count occurrences of that weekday from start of month to dt
        if n > 0:
            count = 0
            for day in range(1, dt.day + 1):
                if datetime.date(dt.year, dt.month, day).weekday() == rule[""weekday""]:
                    count += 1
            return count == n
        # count from end of month backwards
        else:
            count = 0
            last_day = self.month_length(dt.year, dt.month)
            for day in range(last_day, dt.day - 1, -1):
                if datetime.date(dt.year, dt.month, day).weekday() == rule[""weekday""]:
                    count -= 1
            return count == n

    def isholiday(self, dt):
        for rule in self.rules:
            if ""day"" in rule:
                if self._day_rule_matches(rule, dt):
                    return True
            else:
                if self._weekday_rule_matches(rule, dt):
                    return True
        return False

    def __call__(self, curr, end=None):
        if end is None:
            return self.isholiday(curr)
        date = curr
        one_day = datetime.timedelta(days=1)
        while date <= end:
            if self.isholiday(date):
                yield date
            date += one_day","class Holidays(object):
    def __init__(self):
        self.rules = []

    def add_rule(self, rule):
        self.rules.append(rule)

    def month_length(self, year, month):
        return calendar.monthrange(year, month)[1]

    def _day_rule_matches(self, rule, dt):
        if rule.get('type') == 'date':
            return (rule.get('month') == dt.month and 
                    rule.get('day') == dt.day)
        return False

    def _weekday_rule_matches(self, rule, dt):
        if rule.get('type') == 'weekday':
            if rule.get('month') != dt.month:
                return False
            weekday = rule.get('weekday')
            week = rule.get('week')
            if week == 'last':
                # Check if it's the last occurrence of this weekday in the month
                days_in_month = self.month_length(dt.year, dt.month)
                last_occurrence = dt.replace(day=days_in_month)
                while last_occurrence.weekday() != weekday:
                    last_occurrence = last_occurrence.replace(day=last_occurrence.day - 1)
                return dt.day == last_occurrence.day
            else:
                # Check if it's the nth occurrence of this weekday in the month
                first_day = dt.replace(day=1)
                first_weekday = first_day.weekday()
                target_weekday_first = (weekday - first_weekday) % 7
                if target_weekday_first == 0:
                    target_weekday_first = 7
                target_date = 1 + target_weekday_first + (week - 1) * 7
                if target_date > self.month_length(dt.year, dt.month):
                    return False
                return dt.day == target_date
        return False

    def isholiday(self, dt):
        for rule in self.rules:
            if (self._day_rule_matches(rule, dt) or 
                self._weekday_rule_matches(rule, dt)):
                return True
        return False

    def __call__(self, curr, end=None):
        if end is None:
            return self.isholiday(curr)
        else:
            result = []
            current = curr
            while current <= end:
                if self.isholiday(current):
                    result.append(current)
                current += datetime.timedelta(days=1)
            return result","class Holidays(object):
    def __init__(self, rules=None):
        self.rules = rules or []

    def month_length(self, year, month):
        return calendar.monthrange(year, month)[1]

    def _day_rule_matches(self, rule, dt):
        if rule.get('month') and rule['month'] != dt.month:
            return False
        if rule.get('day') and rule['day'] != dt.day:
            return False
        if rule.get('year') and rule['year'] != dt.year:
            return False
        return True

    def _weekday_rule_matches(self, rule, dt):
        if rule.get('month') and rule['month'] != dt.month:
            return False
        if rule.get('weekday') is not None and rule['weekday'] != dt.weekday():
            return False
        if rule.get('week'):
            # Calculate which week of the month this is
            first_day = dt.replace(day=1)
            week_num = ((dt.day - 1) // 7) + 1
            if rule['week'] < 0:
                # Negative week means counting from end of month
                last_day = self.month_length(dt.year, dt.month)
                days_from_end = last_day - dt.day
                week_from_end = (days_from_end // 7) + 1
                if week_from_end != abs(rule['week']):
                    return False
            else:
                if week_num != rule['week']:
                    return False
        return True

    def isholiday(self, dt):
        if isinstance(dt, str):
            dt = datetime.strptime(dt, '%Y-%m-%d').date()
        elif isinstance(dt, datetime):
            dt = dt.date()
        
        for rule in self.rules:
            if rule.get('type') == 'day' or 'day' in rule:
                if self._day_rule_matches(rule, dt):
                    return True
            elif rule.get('type') == 'weekday' or 'weekday' in rule:
                if self._weekday_rule_matches(rule, dt):
                    return True
        return False

    def __call__(self, curr, end=None):
        if isinstance(curr, str):
            curr = datetime.strptime(curr, '%Y-%m-%d').date()
        elif isinstance(curr, datetime):
            curr = curr.date()
            
        if end is None:
            return self.isholiday(curr)
        
        if isinstance(end, str):
            end = datetime.strptime(end, '%Y-%m-%d').date()
        elif isinstance(end, datetime):
            end = end.date()
        
        holidays = []
        current = curr
        while current <= end:
            if self.isholiday(current):
                holidays.append(current)
            current += timedelta(days=1)
        return holidays",no_docstr,0.606516290726817,0.4382871536523929,0.3392405063291139,0.5463659147869674,0.43124129179059134,0.5551020408163265,0.4171779141104294,0.3463114754098361,0.8427419662475586,0.8780273199081421,0.8600229024887085,0.8743664026260376,0.8181836363636364,0.6238095238095237,0.45933014354066987,0.31730769230769235,0.5285714285714286,0.419361310870953,0.5310077519379846,0.4174757281553398,0.3326848249027237,0.8428577780723572,0.9100782871246338,0.87517911195755,0.9028775095939636,0.8141827872860637,0.5793991416309013,0.4008620689655173,0.2683982683982684,0.48927038626609437,0.3512595127183659,0.4511400651465798,0.3458401305057096,0.2777777777777778,0.8474183082580566,0.9047493934631348,0.8751459121704102,0.8986696004867554,0.7743331569343066,0.4453090728167777,0.1835382063160384,0.3417555752772193,0.5522388059701493,0.7037037037037037,0.4341292575628986,0.1765965090487896,0.303425219931384,0.6268656716417911,0.6296296296296297,0.4361083198087506,0.1427056746059687,0.3056155721985932,0.6417910447761194,0.654320987654321
828618,webrecorder/pywb,webrecorder_pywb/pywb/recorder/filters.py,pywb.recorder.filters.ExcludeSpecificHeaders,"class ExcludeSpecificHeaders(object):
    def __init__(self, exclude_headers=None):
        self.exclude_headers = [x.lower() for x in exclude_headers]

    def __call__(self, header):
        if header[0].lower() in self.exclude_headers:
            return None

        return header","class ExcludeSpecificHeaders(object):


    def __init__(self, exclude_headers=None):
        pass

    def __call__(self, header):
        pass

",3,0,snippet_250,1.0,"class ExcludeSpecificHeaders(object):
    def __init__(self, exclude_headers=None):
        if exclude_headers is None:
            exclude_headers = []
        self._exclude = set(h.lower() for h in exclude_headers)

    def __call__(self, header):
        return header.lower() not in self._exclude","class ExcludeSpecificHeaders(object):

    def __init__(self, exclude_headers=None):
        if exclude_headers is None:
            exclude_headers = []
        self.exclude_headers = [header.lower() for header in exclude_headers]

    def __call__(self, header):
        return header.lower() not in self.exclude_headers","class ExcludeSpecificHeaders(object):

    def __init__(self, exclude_headers=None):
        self.exclude_headers = exclude_headers or []

    def __call__(self, header):
        return header not in self.exclude_headers",no_docstr,0.8333333333333334,0.6,0.3823529411764706,0.6944444444444444,0.6991321113148731,0.8481012658227848,0.7051282051282052,0.5714285714285714,0.9220565557479858,0.9295271635055542,0.9257767796516418,0.9287747144699097,0.8848496363636363,0.8493150684931505,0.5915492957746479,0.43478260869565216,0.7397260273972601,0.7531870579876488,0.875,0.7468354430379747,0.6538461538461539,0.9412908554077148,0.9363008141517639,0.9387892484664917,0.9367973208427429,0.8930828301886793,0.7868852459016394,0.6440677966101696,0.4912280701754386,0.7540983606557377,0.6351922639814604,0.9642857142857143,0.8909090909090909,0.7962962962962963,0.9399956464767456,0.8935694694519043,0.9161947965621948,0.8980046510696411,0.8758182352941176,0.3401673912344003,0.1998573974138024,0.2481684893628795,0.3793103448275862,0.5333333333333333,0.488882306585285,0.3055649786621255,0.3672056269893592,0.4827586206896552,0.8,0.3605781660734298,0.334949051829208,0.3326509687863506,0.2413793103448276,0.5333333333333333
500488,iopipe/iopipe-python,iopipe_iopipe-python/iopipe/context.py,iopipe.context.LogWrapper,"class LogWrapper(object):
    def __init__(self, context):
        self.context = context
        self.logger = logging.getLogger()

    def __call__(self, key, value):
        warnings.warn(
            ""Calling context.iopipe.log() has been deprecated, use ""
            ""context.iopipe.metric() instead""
        )

        self.context.metric(key, value)

    def __getattr__(self, name):
        return getattr(self.logger, name)","class LogWrapper(object):


    def __init__(self, context):
        pass

    def __call__(self, key, value):
        pass

    def __getattr__(self, name):
        pass

",4,0,snippet_493,0.6,"class LogWrapper(object):
    def __init__(self, context):
        self._context = context

    def __call__(self, key, value):
        """"""
        Store a key/value pair in the wrapped context.
        Returns self to allow chaining.
        """"""
        try:
            # if context supports item assignment (e.g. dict)
            self._context[key] = value
        except Exception:
            # fallback to attribute assignment
            setattr(self._context, key, value)
        return self

    def __getattr__(self, name):
        """"""
        First try to get an item from the wrapped context (if it's a mapping),
        otherwise delegate attribute access to the context object.
        """"""
        # try item access
        try:
            return self._context[name]
        except Exception:
            # fallback to attribute access
            return getattr(self._context, name)","class LogWrapper(object):
    def __init__(self, context):
        self.context = context
        self.logs = {}

    def __call__(self, key, value):
        self.logs[key] = value
        return self

    def __getattr__(self, name):
        if name in self.logs:
            return self.logs[name]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{name}'"")","class LogWrapper(object):
    def __init__(self, context):
        self.context = context
        self.data = {}

    def __call__(self, key, value):
        self.data[key] = value
        return self

    def __getattr__(self, name):
        if name in self.data:
            return self.data[name]
        return getattr(self.context, name)",no_docstr,0.40540540540540543,0.273972602739726,0.19444444444444442,0.3918918918918919,0.34936101276907894,0.46994535519125685,0.33516483516483514,0.27071823204419887,0.7454267740249634,0.809604823589325,0.7761915326118469,0.8026939630508423,0.7803052272727272,0.574468085106383,0.391304347826087,0.3111111111111111,0.5531914893617021,0.49289504130818634,0.6106194690265486,0.4732142857142857,0.4144144144144144,0.8564569354057312,0.8302465081214905,0.8431480526924133,0.8327952027320862,0.7863269230769231,0.6363636363636364,0.5116279069767442,0.38095238095238093,0.6136363636363638,0.5365418349661402,0.7640449438202247,0.6590909090909091,0.5862068965517241,0.8961431384086609,0.8242141008377075,0.858674943447113,0.8308832049369812,0.8243260810810811,0.3502891572218876,0.0806966849027814,0.2494073124058217,0.4210526315789473,0.65,0.3842589430643457,0.3013845792167326,0.3435459298827557,0.3421052631578947,0.55,0.4146463941524498,0.3203028046217804,0.3435459298827557,0.3947368421052631,0.6
824151,wandb/client,wandb_client/wandb/apis/public/reports.py,wandb.apis.public.reports.PanelMetricsHelper,"class PanelMetricsHelper:
    FRONTEND_NAME_MAPPING = {
        ""Step"": ""_step"",
        ""Relative Time (Wall)"": ""_absolute_runtime"",
        ""Relative Time (Process)"": ""_runtime"",
        ""Wall Time"": ""_timestamp"",
    }
    FRONTEND_NAME_MAPPING_REVERSED = {v: k for k, v in FRONTEND_NAME_MAPPING.items()}

    RUN_MAPPING = {""Created Timestamp"": ""createdAt"", ""Latest Timestamp"": ""heartbeatAt""}
    RUN_MAPPING_REVERSED = {v: k for k, v in RUN_MAPPING.items()}

    def front_to_back(self, name):
        if name in self.FRONTEND_NAME_MAPPING:
            return self.FRONTEND_NAME_MAPPING[name]
        return name

    def back_to_front(self, name):
        if name in self.FRONTEND_NAME_MAPPING_REVERSED:
            return self.FRONTEND_NAME_MAPPING_REVERSED[name]
        return name

    # ScatterPlot and ParallelCoords have weird conventions
    def special_front_to_back(self, name):
        if name is None:
            return name

        name, *rest = name.split(""."")
        rest = ""."" + ""."".join(rest) if rest else """"

        # special case for config
        if name.startswith(""c::""):
            name = name[3:]
            return f""config:{name}.value{rest}""

        # special case for summary
        if name.startswith(""s::""):
            name = name[3:] + rest
            return f""summary:{name}""

        name = name + rest
        if name in self.RUN_MAPPING:
            return ""run:"" + self.RUN_MAPPING[name]
        if name in self.FRONTEND_NAME_MAPPING:
            return ""summary:"" + self.FRONTEND_NAME_MAPPING[name]
        if name == ""Index"":
            return name
        return ""summary:"" + name

    def special_back_to_front(self, name):
        if name is not None:
            kind, rest = name.split("":"", 1)

            if kind == ""config"":
                pieces = rest.split(""."")
                if len(pieces) <= 1:
                    raise ValueError(f""Invalid name: {name}"")
                elif len(pieces) == 2:
                    name = pieces[0]
                elif len(pieces) >= 3:
                    name = pieces[:1] + pieces[2:]
                    name = ""."".join(name)
                return f""c::{name}""

            elif kind == ""summary"":
                name = rest
                return f""s::{name}""

        if name is None:
            return name
        elif ""summary:"" in name:
            name = name.replace(""summary:"", """")
            return self.FRONTEND_NAME_MAPPING_REVERSED.get(name, name)
        elif ""run:"" in name:
            name = name.replace(""run:"", """")
            return self.RUN_MAPPING_REVERSED[name]
        return name","class PanelMetricsHelper:


    def front_to_back(self, name):
        pass

    def back_to_front(self, name):
        pass

    def special_front_to_back(self, name):
        pass

    def special_back_to_front(self, name):
        pass

",5,0,snippet_271,0.6190476190476191,"class PanelMetricsHelper:
    def front_to_back(self, name):
        if not name:
            return ''
        # camelCase or PascalCase to snake_case
        s1 = re.sub(r'(.)([A-Z][a-z]+)', r'\1_\2', name)
        s2 = re.sub(r'([a-z0-9])([A-Z])', r'\1_\2', s1)
        return s2.lower()

    def back_to_front(self, name):
        if not name:
            return ''
        parts = name.split('_')
        return parts[0] + ''.join(word.capitalize() for word in parts[1:])

    def special_front_to_back(self, name):
        if not name:
            return ''
        # replace spaces or hyphens with underscores, then camelsnake
        temp = re.sub(r'[\s\-]+', '_', name.strip())
        return self.front_to_back(temp)

    def special_back_to_front(self, name):
        if not name:
            return ''
        # snake or kebab to Title Case with spaces
        temp = re.sub(r'[_\-]+', ' ', name.strip())
        return temp.title()","class PanelMetricsHelper:
    def front_to_back(self, name):
        """"""Convert front panel name to back panel name""""""
        if name.startswith('front_'):
            return name.replace('front_', 'back_', 1)
        return 'back_' + name

    def back_to_front(self, name):
        """"""Convert back panel name to front panel name""""""
        if name.startswith('back_'):
            return name.replace('back_', 'front_', 1)
        return 'front_' + name

    def special_front_to_back(self, name):
        """"""Convert special front panel name to back panel name""""""
        special_mappings = {
            'front_panel': 'back_panel',
            'front_door': 'back_door',
            'front_window': 'back_window',
            'front_wall': 'back_wall',
            'front_side': 'back_side'
        }
        return special_mappings.get(name, self.front_to_back(name))

    def special_back_to_front(self, name):
        """"""Convert special back panel name to front panel name""""""
        special_mappings = {
            'back_panel': 'front_panel',
            'back_door': 'front_door',
            'back_window': 'front_window',
            'back_wall': 'front_wall',
            'back_side': 'front_side'
        }
        return special_mappings.get(name, self.back_to_front(name))","class PanelMetricsHelper:
    def __init__(self):
        self.front_to_back_mapping = {
            'width': 'depth',
            'height': 'height',
            'depth': 'width',
            'x': 'z',
            'y': 'y',
            'z': 'x',
            'left': 'front',
            'right': 'back',
            'front': 'right',
            'back': 'left',
            'top': 'top',
            'bottom': 'bottom'
        }
        
        self.back_to_front_mapping = {v: k for k, v in self.front_to_back_mapping.items()}
        
        self.special_front_to_back_mapping = {
            'panel_width': 'panel_depth',
            'panel_height': 'panel_height',
            'panel_depth': 'panel_width',
            'offset_x': 'offset_z',
            'offset_y': 'offset_y',
            'offset_z': 'offset_x',
            'margin_left': 'margin_front',
            'margin_right': 'margin_back',
            'margin_front': 'margin_right',
            'margin_back': 'margin_left',
            'margin_top': 'margin_top',
            'margin_bottom': 'margin_bottom'
        }
        
        self.special_back_to_front_mapping = {v: k for k, v in self.special_front_to_back_mapping.items()}

    def front_to_back(self, name):
        return self.front_to_back_mapping.get(name, name)

    def back_to_front(self, name):
        return self.back_to_front_mapping.get(name, name)

    def special_front_to_back(self, name):
        return self.special_front_to_back_mapping.get(name, name)

    def special_back_to_front(self, name):
        return self.special_back_to_front_mapping.get(name, name)",no_docstr,0.2969837587006961,0.1631701631701632,0.10304449648711944,0.23665893271461716,0.09076985786020374,0.6715328467153284,0.31135531135531136,0.21323529411764705,0.751532793045044,0.7254579663276672,0.7382652759552002,0.7279837727546692,0.7360597081712065,0.29646017699115046,0.15999999999999998,0.10714285714285714,0.2433628318584071,0.11969524213868839,0.6862745098039216,0.32131147540983607,0.22039473684210525,0.8088911771774292,0.7355287075042725,0.7704675197601318,0.7422606348991394,0.7425447276264594,0.3155737704918033,0.21810699588477367,0.128099173553719,0.2827868852459017,0.1622703794487228,0.5691489361702128,0.29333333333333333,0.22192513368983957,0.7974926233291626,0.7372287511825562,0.7661774754524231,0.7428421378135681,0.7431932295719847,0.1316530106048561,0.0271482926611948,0.0528106057420024,0.3294117647058823,0.1172413793103448,0.1077049804885019,0.0188521119194052,0.0321165591894369,0.2901960784313726,0.0896551724137931,0.1488359985172619,0.0446937231595937,0.0761404669878854,0.2745098039215686,0.2
427761,googleapis/google-cloud-python,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/googleapis_google-cloud-python/packages/google-cloud-dialogflow/google/cloud/dialogflow_v2/services/versions/transports/rest_base.py,dialogflow_v2.services.versions.transports.rest_base._BaseVersionsRestTransport._BaseCancelOperation,"class _BaseCancelOperation:
    def __hash__(self):  # pragma: NO COVER
        return NotImplementedError(""__hash__ must be implemented."")

    @staticmethod
    def _get_http_options():
        http_options: List[Dict[str, str]] = [
            {
                ""method"": ""post"",
                ""uri"": ""/v2/{name=projects/*/operations/*}:cancel"",
            },
            {
                ""method"": ""post"",
                ""uri"": ""/v2/{name=projects/*/locations/*/operations/*}:cancel"",
            },
        ]
        return http_options

    @staticmethod
    def _get_transcoded_request(http_options, request):
        request_kwargs = json_format.MessageToDict(request)
        transcoded_request = path_template.transcode(
            http_options, **request_kwargs)
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = json.loads(json.dumps(
            transcoded_request[""query_params""]))
        return query_params
","class _BaseCancelOperation:


    def __hash__(self):
        pass

    @staticmethod
    def _get_http_options():
        pass

    @staticmethod
    def _get_transcoded_request(http_options, request):
        pass

    @staticmethod
    def _get_query_params_json(transcoded_request):
        pass

",8,0,snippet_696,0.5,"class _BaseCancelOperation:

    def __hash__(self):
        return id(self)

    @staticmethod
    def _get_http_options():
        return [
            {
                ""method"": ""post"",
                ""uri"": ""/v1/{name=projects/*/operations/*}:cancel"",
                ""body"": ""*"",
            },
        ]

    @staticmethod
    def _get_transcoded_request(http_options, request):
        # Convert protobuf Message to dict if necessary
        if not isinstance(request, dict):
            try:
                request_dict = json_format.MessageToDict(
                    request,
                    including_default_value_fields=False,
                    preserving_proto_field_name=True,
                )
            except Exception:
                # Fallback for simple dataclasses or mappings
                request_dict = dict(request)
        else:
            request_dict = request
        return path_template.transcode(http_options, request_dict)

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = transcoded_request.get(""query_params"", {})
        return json.dumps(query_params)","class _BaseCancelOperation:

    def __hash__(self):
        return hash(type(self).__name__)

    @staticmethod
    def _get_http_options():
        return []

    @staticmethod
    def _get_transcoded_request(http_options, request):
        return request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        return {}","class _BaseCancelOperation:

    def __hash__(self):
        return hash(self.__class__.__name__)

    @staticmethod
    def _get_http_options():
        return {
            'method': 'POST',
            'uri': '/v1/{name=operations/**}:cancel',
            'body': '*'
        }

    @staticmethod
    def _get_transcoded_request(http_options, request):
        transcoded_request = {
            'uri': http_options['uri'].format(name=request.name),
            'method': http_options['method'],
            'query_params': {},
            'body': request
        }
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = transcoded_request.get('query_params', {})
        return {key: str(value) for key, value in query_params.items()}",no_docstr,0.6326530612244897,0.4329896907216495,0.3125,0.5612244897959183,0.5981111481336445,0.7792207792207793,0.591304347826087,0.5021834061135371,0.821555495262146,0.855935275554657,0.8383930921554565,0.8523682951927185,0.8014204255319148,0.5196850393700787,0.368,0.3089430894308943,0.5039370078740156,0.1207741448559023,0.9759036144578314,0.7439024390243902,0.6790123456790124,0.8584132194519043,0.678824245929718,0.7581284642219543,0.6933294534683228,0.758867659574468,0.7017543859649124,0.44970414201183434,0.311377245508982,0.6081871345029239,0.4216577114134805,0.8125,0.4869109947643979,0.38421052631578945,0.8711041212081909,0.8204991221427917,0.845044732093811,0.8252934813499451,0.7733356,0.2918072545267445,0.19373324090707,0.2556897358644549,0.3648648648648648,0.3529411764705882,0.1166998079517148,0.0619587559073832,0.1385447684272979,0.1486486486486486,0.1176470588235294,0.3309796733214776,0.2115566252094633,0.236368427376924,0.4054054054054054,0.4705882352941176
694994,ray-project/ray,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/ray-project_ray/rllib/utils/annotations.py,rllib.utils.annotations.override.OverrideCheck,"class OverrideCheck:
    def __init__(self, func, expected_parent_cls):
        self.func = func
        self.expected_parent_cls = expected_parent_cls

    def __set_name__(self, owner, name):
        # Check if the owner (the class) is a subclass of the expected base class
        if not issubclass(owner, self.expected_parent_cls):
            raise TypeError(
                f""When using the @override decorator, {owner.__name__} must be a ""
                f""subclass of {parent_cls.__name__}!""
            )
        # Set the function as a regular method on the class.
        setattr(owner, name, self.func)
","class OverrideCheck:


    def __init__(self, func, expected_parent_cls):
        pass


    def __set_name__(self, owner, name):
        pass

",3,0,snippet_305,0.8,"class OverrideCheck:
    def __init__(self, func, expected_parent_cls):
        self.func = func
        self.expected_parent_cls = expected_parent_cls

    def __set_name__(self, owner, name):
        if not issubclass(owner, self.expected_parent_cls):
            raise TypeError(
                f""{owner.__name__!r} is not a subclass of {self.expected_parent_cls.__name__!r}""
            )
        if not hasattr(self.expected_parent_cls, name):
            raise TypeError(
                f""Method {name!r} does not override any method of ""
                f""{self.expected_parent_cls.__name__!r}""
            )

    def __get__(self, instance, owner):
        return self.func.__get__(instance, owner)","class OverrideCheck:
    def __init__(self, func, expected_parent_cls):
        self.func = func
        self.expected_parent_cls = expected_parent_cls
        self.name = func.__name__

    def __set_name__(self, owner, name):
        if not issubclass(owner, self.expected_parent_cls):
            raise TypeError(f""{owner.__name__} must inherit from {self.expected_parent_cls.__name__}"")
        
        # Check if the method exists in the parent class
        if not hasattr(self.expected_parent_cls, self.name):
            raise TypeError(f""{self.name} is not defined in {self.expected_parent_cls.__name__}"")
        
        # Check if the method is actually overridden
        if getattr(self.expected_parent_cls, self.name) is self.func:
            raise TypeError(f""{self.name} in {owner.__name__} does not override the parent method"")
        
        # Set the function as an attribute of the owner class
        setattr(owner, name, self.func)","class OverrideCheck:
    def __init__(self, func, expected_parent_cls):
        self.func = func
        self.expected_parent_cls = expected_parent_cls
        self.name = None

    def __set_name__(self, owner, name):
        self.name = name
        
        # Check if the method exists in the expected parent class
        if not hasattr(self.expected_parent_cls, name):
            raise AttributeError(f""Method '{name}' does not exist in {self.expected_parent_cls.__name__}"")
        
        # Check if the owner class actually inherits from the expected parent
        if not issubclass(owner, self.expected_parent_cls):
            raise TypeError(f""Class {owner.__name__} does not inherit from {self.expected_parent_cls.__name__}"")
        
        # Set the actual method on the owner class
        setattr(owner, name, self.func)",no_docstr,0.6627218934911243,0.47904191616766467,0.41212121212121217,0.5798816568047338,0.533279974931777,0.6443298969072165,0.5077720207253886,0.4635416666666667,0.9089657068252563,0.8886752724647522,0.8987058997154236,0.8906633257865906,0.8303047272727272,0.638095238095238,0.49038461538461536,0.39805825242718446,0.5142857142857143,0.467165580534139,0.545816733067729,0.456,0.40963855421686746,0.8910419940948486,0.9051059484481812,0.8980188965797424,0.903679609298706,0.8047638571428571,0.6596858638743457,0.5396825396825397,0.44919786096256686,0.617801047120419,0.5589589694277153,0.6456310679611651,0.5463414634146342,0.4950980392156863,0.8999013900756836,0.8996863961219788,0.8997938632965088,0.8997078537940979,0.8454560909090909,0.5433191704234752,0.3316166347910672,0.3559457611885479,0.4857142857142857,1.0,0.5310428405697236,0.2987768427371916,0.4206326147797981,0.5714285714285714,0.8333333333333334,0.5284852407590669,0.3101764461058729,0.3990026121684898,0.5714285714285714,0.8333333333333334
149340,ManiacalLabs/BiblioPixel,ManiacalLabs_BiblioPixel/bibliopixel/project/clock.py,bibliopixel.project.clock.Clock,"class Clock:
    def __init__(self, is_flat_out=False):
        self.is_flat_out = is_flat_out
        self._time = time.time()

    def time(self):
        return self._time if self.is_flat_out else time.time()

    def sleep(self, delta_time):
        delta_time = max(delta_time, 0)
        # TODO: why is delta_time occasionally tiny and negative?
        if not self.is_flat_out:
            time.sleep(delta_time)
        else:
            self._time += delta_time","class Clock:


    def __init__(self, is_flat_out=False):
        pass

    def time(self):
        pass

    def sleep(self, delta_time):
        pass

",4,0,snippet_601,0.4285714285714285,"class Clock:
    def __init__(self, is_flat_out=False):
        self.is_flat_out = is_flat_out
        if self.is_flat_out:
            self._t = 0.0
        else:
            self._start = time.time()

    def time(self):
        if self.is_flat_out:
            return self._t
        return time.time() - self._start

    def sleep(self, delta_time):
        if self.is_flat_out:
            self._t += delta_time
        else:
            time.sleep(delta_time)","class Clock:
    def __init__(self, is_flat_out=False):
        self.is_flat_out = is_flat_out
        self.start_time = time.time()
        self.current_time = self.start_time

    def time(self):
        if self.is_flat_out:
            return self.current_time
        else:
            return time.time()

    def sleep(self, delta_time):
        if self.is_flat_out:
            self.current_time += delta_time
        else:
            time.sleep(delta_time)","class Clock:
    def __init__(self, is_flat_out=False):
        self.is_flat_out = is_flat_out
        self.current_time = time.time()
        self.start_time = self.current_time

    def time(self):
        if self.is_flat_out:
            return self.current_time
        else:
            return time.time()

    def sleep(self, delta_time):
        if self.is_flat_out:
            self.current_time += delta_time
        else:
            time.sleep(delta_time)",no_docstr,0.7761194029850746,0.6212121212121211,0.4615384615384615,0.6716417910447761,0.7165051920814867,0.8473282442748091,0.7230769230769231,0.6434108527131783,0.9276838302612305,0.8952416181564331,0.9111740589141846,0.898383378982544,0.8644702197802197,0.8333333333333334,0.6615384615384615,0.5156250000000001,0.7272727272727272,0.7450763710531038,0.912,0.8064516129032258,0.6991869918699187,0.9374262690544128,0.899381160736084,0.9180096983909607,0.9030460715293884,0.8849217857142856,0.8333333333333334,0.6615384615384615,0.5156250000000001,0.7272727272727272,0.7450763710531038,0.912,0.8064516129032258,0.6991869918699187,0.9373168349266052,0.8996386528015137,0.9180912971496582,0.9032697081565857,0.8849217857142856,0.4397433928518577,0.2758229197620718,0.280704999471446,0.6086956521739131,0.59375,0.4811775072516495,0.2622044417916935,0.2725599350409913,0.6086956521739131,0.78125,0.4733650072516495,0.2622044417916935,0.2725599350409913,0.6086956521739131,0.75
619503,openthread/openthread,tests/scripts/thread-cert/network_layer.py,thread-cert.network_layer.TimeSinceLastTransaction,"class TimeSinceLastTransaction(object):

    def __init__(self, seconds):
        self._seconds = seconds

    @property
    def seconds(self):
        return self._seconds

    def __eq__(self, other):
        common.expect_the_same_class(self, other)
        return self.seconds == other.seconds

    def __repr__(self):
        return ""TimeSinceLastTransaction(seconds={})"".format(self.seconds)","class TimeSinceLastTransaction(object):


    def __init__(self, seconds):
        pass

    @property
    def seconds(self):
        pass

    def __eq__(self, other):
        pass

    def __repr__(self):
        pass

",6,0,snippet_641,1.0,"class TimeSinceLastTransaction(object):
    def __init__(self, seconds):
        if not isinstance(seconds, (int, float)):
            raise TypeError(f""seconds must be int or float, not {type(seconds).__name__}"")
        if seconds < 0:
            raise ValueError(""seconds must be non-negative"")
        self._seconds = seconds

    @property
    def seconds(self):
        return self._seconds

    def __eq__(self, other):
        if not isinstance(other, TimeSinceLastTransaction):
            return NotImplemented
        return self.seconds == other.seconds

    def __repr__(self):
        return f""TimeSinceLastTransaction(seconds={self.seconds!r})""","class TimeSinceLastTransaction(object):
    def __init__(self, seconds):
        self._seconds = seconds

    @property
    def seconds(self):
        return self._seconds

    def __eq__(self, other):
        if not isinstance(other, TimeSinceLastTransaction):
            return False
        return self._seconds == other._seconds

    def __repr__(self):
        return f""TimeSinceLastTransaction({self._seconds})""","class TimeSinceLastTransaction(object):

    def __init__(self, seconds):
        self._seconds = seconds

    @property
    def seconds(self):
        return self._seconds

    def __eq__(self, other):
        if not isinstance(other, TimeSinceLastTransaction):
            return False
        return self._seconds == other._seconds

    def __repr__(self):
        return f""TimeSinceLastTransaction({self._seconds})""",no_docstr,0.6140350877192983,0.5357142857142857,0.45454545454545453,0.6140350877192983,0.5276841375424638,0.609271523178808,0.5133333333333333,0.4697986577181208,0.7990982532501221,0.8852551579475403,0.8399732112884521,0.8758124113082886,0.833335,0.8192771084337348,0.7160493827160495,0.6582278481012659,0.8192771084337348,0.7403554635141493,0.9157894736842105,0.7553191489361702,0.6881720430107527,0.9483321905136108,0.9310395121574402,0.9396063089370728,0.9327403903007507,0.9275369565217392,0.8192771084337348,0.7160493827160495,0.6582278481012659,0.8192771084337348,0.7403554635141493,0.9157894736842105,0.7553191489361702,0.6881720430107527,0.9485890865325928,0.9312987327575684,0.9398643970489502,0.9329993724822998,0.9275369565217392,0.5707700932441152,0.3532879695746502,0.7562504403861632,0.5945945945945946,0.5789473684210527,0.5612269613344465,0.5703815182048178,0.6844836528797681,0.6216216216216216,0.3684210526315789,0.5612269613344465,0.5703815182048178,0.6844836528797681,0.6216216216216216,0.3684210526315789
554230,lowandrew/OLCTools,lowandrew_OLCTools/olctools/accessoryFunctions/split_combined_file.py,olctools.accessoryFunctions.split_combined_file.Split,"class Split(object):

    def read_split_file(self):
        # Create a FASTA file for each record in the file
        for record in SeqIO.parse(self.allele_file, 'fasta'):
            # Create the file. Clean up the name a bit
            record.id = record.id.replace(':', '-').replace('_', '-')
            with open(os.path.join(self.output_path, f'{record.id}{self.extension}'), 'w') as split:
                # Update the record.id with a fake allele number to resemble an allele file
                if self.number:
                    record.id = record.id + '_0'
                    record.description = str()
                # Write the record in FASTA format to the allele file
                SeqIO.write(sequences=record,
                            handle=split,
                            format='fasta')

    def __init__(self, allele_file, extension='.fasta', number=True):
        if allele_file.startswith('~'):
            self.allele_file = os.path.abspath(os.path.expanduser(os.path.join(allele_file)))
        else:
            self.allele_file = os.path.abspath(os.path.join(allele_file))
        assert os.path.isfile(self.allele_file), f'Cannot locate the supplied allele file: {self.allele_file}'
        self.output_path = os.path.join(os.path.dirname(self.allele_file), 'alleles')
        make_path(self.output_path)
        self.extension = extension
        self.number = number","class Split(object):


    def read_split_file(self):
        pass

    def __init__(self, allele_file, extension='.fasta', number=True):
        pass

",3,0,snippet_90,0.3333333333333333,"class Split(object):
    def __init__(self, allele_file, extension='.fasta', number=True):
        self.allele_file = allele_file
        self.extension = extension if extension.startswith('.') else '.' + extension
        self.number = number
        self.read_split_file()

    def read_split_file(self):
        if os.path.isdir(self.allele_file):
            pattern = os.path.join(self.allele_file, f""*{self.extension}"")
            files = glob.glob(pattern)
        elif os.path.isfile(self.allele_file):
            files = [self.allele_file]
        else:
            raise ValueError(f""No such file or directory: {self.allele_file}"")

        for filepath in files:
            self._split_file(filepath)

    def _split_file(self, filepath):
        seqs = {}
        header = None
        with open(filepath) as f:
            for line in f:
                line = line.rstrip('\n')
                if not line:
                    continue
                if line.startswith('>'):
                    if header:
                        seqs[header] = ''.join(lines)
                    header = line[1:].split()[0]
                    lines = []
                else:
                    lines.append(line)
            if header:
                seqs[header] = ''.join(lines)

        base_dir = os.getcwd()
        idx = 1
        for h, seq in seqs.items():
            safe_h = re.sub(r'[^A-Za-z0-9._-]', '_', h)
            if self.number:
                fname = f""{idx}_{safe_h}{self.extension}""
            else:
                fname = f""{safe_h}{self.extension}""
            out_path = os.path.join(base_dir, fname)
            with open(out_path, 'w') as out:
                out.write(f"">{h}\n"")
                for i in range(0, len(seq), 60):
                    out.write(seq[i:i+60] + '\n')
            idx += 1","class Split(object):
    def read_split_file(self):
        pass

    def __init__(self, allele_file, extension='.fasta', number=True):
        self.allele_file = allele_file
        self.extension = extension
        self.number = number
        self.data = self.read_split_file()","class Split(object):
    
    def __init__(self, allele_file, extension='.fasta', number=True):
        self.allele_file = allele_file
        self.extension = extension
        self.number = number
        self.sequences = {}
        
    def read_split_file(self):
        try:
            with open(self.allele_file, 'r') as file:
                current_header = None
                current_sequence = []
                
                for line in file:
                    line = line.strip()
                    if line.startswith('>'):
                        if current_header is not None:
                            self.sequences[current_header] = ''.join(current_sequence)
                        current_header = line[1:]
                        current_sequence = []
                    else:
                        current_sequence.append(line)
                
                if current_header is not None:
                    self.sequences[current_header] = ''.join(current_sequence)
                    
            if self.number:
                for i, (header, sequence) in enumerate(self.sequences.items(), 1):
                    filename = f""{header.split()[0]}_{i}{self.extension}""
                    with open(filename, 'w') as output_file:
                        output_file.write(f"">{header}\n{sequence}\n"")
            else:
                for header, sequence in self.sequences.items():
                    filename = f""{header.split()[0]}{self.extension}""
                    with open(filename, 'w') as output_file:
                        output_file.write(f"">{header}\n{sequence}\n"")
                        
        except FileNotFoundError:
            print(f""Error: File '{self.allele_file}' not found."")
        except Exception as e:
            print(f""Error reading file: {e}"")",no_docstr,0.46464646464646464,0.26903553299492383,0.163265306122449,0.2373737373737374,0.3548516328848393,0.5160599571734475,0.34120171673819744,0.2537634408602151,0.7765847444534302,0.8042712211608887,0.7901855111122131,0.8014140129089355,0.7402104316546763,0.29629629629629634,0.22429906542056074,0.17924528301886794,0.25925925925925924,0.019695465266797715,0.9594594594594594,0.821917808219178,0.7222222222222222,0.859128475189209,0.6591022610664368,0.7459387183189392,0.6748136281967163,0.7285741428571432,0.4401114206128134,0.19047619047619047,0.12394366197183099,0.20055710306406685,0.3336408140094101,0.5390625,0.3133159268929504,0.2198952879581152,0.7785612344741821,0.7575464248657227,0.7679101228713989,0.7595967054367065,0.7075877544910176,0.2744552123575889,0.0734319712675804,0.1049470033554982,0.5390070921985816,0.3804347826086957,0.1358268373918622,0.0082774412854935,0.0977033587907434,0.3829787234042553,0.0543478260869565,0.2623681299238606,0.1077661490008506,0.1229428800994638,0.5035460992907801,0.3152173913043478
811706,tych0/xcffib,tych0_xcffib/module/__init__.py,module.ExtensionKey,"class ExtensionKey(object):
    def __init__(self, name):
        self.name = name
        self.c_key = ffi.new(""struct xcb_extension_t *"")
        self.c_name = ffi.new(""char[]"", self.name.encode())
        self.c_key.name = self.c_name
        self.c_key.global_id = 0

    def __hash__(self):
        return hash(self.name)

    def __eq__(self, o):
        return self.name == o.name

    def __ne__(self, o):
        return self.name != o.name","class ExtensionKey(object):


    def __init__(self, name):
        pass

    def __hash__(self):
        pass

    def __eq__(self, o):
        pass

    def __ne__(self, o):
        pass

",5,0,snippet_730,0.5,"class ExtensionKey(object):
    def __init__(self, name):
        if not isinstance(name, str):
            raise TypeError(""name must be a string"")
        self.name = name

    def __hash__(self):
        return hash(self.name)

    def __eq__(self, o):
        if not isinstance(o, ExtensionKey):
            return False
        return self.name == o.name

    def __ne__(self, o):
        return not self.__eq__(o)","class ExtensionKey(object):

    def __init__(self, name):
        self.name = name

    def __hash__(self):
        return hash(self.name)

    def __eq__(self, o):
        if not isinstance(o, ExtensionKey):
            return False
        return self.name == o.name

    def __ne__(self, o):
        return not self.__eq__(o)","class ExtensionKey(object):

    def __init__(self, name):
        self.name = name

    def __hash__(self):
        return hash(self.name)

    def __eq__(self, o):
        if not isinstance(o, ExtensionKey):
            return False
        return self.name == o.name

    def __ne__(self, o):
        return not self.__eq__(o)",no_docstr,0.5833333333333333,0.45762711864406785,0.39655172413793105,0.5833333333333333,0.5086172510511625,0.7948717948717948,0.6551724137931034,0.6086956521739131,0.8436083197593689,0.8286280632019043,0.8360511064529419,0.8301021456718445,0.8258275675675676,0.6111111111111112,0.5283018867924528,0.4807692307692308,0.6111111111111112,0.45506157665151326,0.8969072164948454,0.7708333333333334,0.7368421052631579,0.8736292123794556,0.8107181191444397,0.8409987688064575,0.8165985345840454,0.7988008108108108,0.6111111111111112,0.5283018867924528,0.4807692307692308,0.6111111111111112,0.45506157665151326,0.8969072164948454,0.7708333333333334,0.7368421052631579,0.8736292123794556,0.8107181191444397,0.8409987688064575,0.8165985345840454,0.7988008108108108,0.4308615777985886,0.4150193370982397,0.4467785300254673,0.5689655172413793,0.2926829268292683,0.4320998744144526,0.4469191443068349,0.4959462911138012,0.5172413793103449,0.2682926829268293,0.4320998744144526,0.4469191443068349,0.4959462911138012,0.5172413793103449,0.2682926829268293
627120,pandas-dev/pandas,pandas-dev_pandas/asv_bench/benchmarks/algos/isin.py,benchmarks.algos.isin.IsInLongSeriesLookUpDominates,"class IsInLongSeriesLookUpDominates:
    params = [
        [""int64"", ""int32"", ""float64"", ""float32"", ""object"", ""Int64"", ""Float64""],
        [5, 1000],
        [""random_hits"", ""random_misses"", ""monotone_hits"", ""monotone_misses""],
    ]
    param_names = [""dtype"", ""MaxNumber"", ""series_type""]

    def setup(self, dtype, MaxNumber, series_type):
        N = 10**7

        if series_type == ""random_hits"":
            array = np.random.randint(0, MaxNumber, N)
        if series_type == ""random_misses"":
            array = np.random.randint(0, MaxNumber, N) + MaxNumber
        if series_type == ""monotone_hits"":
            array = np.repeat(np.arange(MaxNumber), N // MaxNumber)
        if series_type == ""monotone_misses"":
            array = np.arange(N) + MaxNumber

        self.series = Series(array).astype(dtype)

        self.values = np.arange(MaxNumber).astype(dtype.lower())

    def time_isin(self, dtypes, MaxNumber, series_type):
        self.series.isin(self.values)","class IsInLongSeriesLookUpDominates:


    def setup(self, dtype, MaxNumber, series_type):
        pass

    def time_isin(self, dtypes, MaxNumber, series_type):
        pass

",3,0,snippet_753,0.6363636363636364,"class IsInLongSeriesLookUpDominates:

    def setup(self, dtype, MaxNumber, series_type):
        # create base data array
        data = np.arange(MaxNumber, dtype=dtype)
        # build the series or list
        if series_type == 'pandas':
            self.series = pd.Series(data)
        else:
            self.series = data.tolist()
        # build lookup values (a subset of the data)
        rng = np.random.RandomState(0)
        cnt = max(1, MaxNumber // 10)
        self.values = rng.choice(data, size=cnt, replace=False)

    def time_isin(self, dtype, MaxNumber, series_type):
        if series_type == 'pandas':
            return self.series.isin(self.values)
        else:
            lookup = set(self.values)
            return [x in lookup for x in self.series]","class IsInLongSeriesLookUpDominates:
    def setup(self, dtype, MaxNumber, series_type):
        import pandas as pd
        import numpy as np
        
        # Create series based on series_type
        if series_type == 'sorted':
            self.series = pd.Series(np.arange(MaxNumber, dtype=dtype))
        elif series_type == 'reverse_sorted':
            self.series = pd.Series(np.arange(MaxNumber, 0, -1, dtype=dtype))
        else:  # random
            np.random.seed(42)
            self.series = pd.Series(np.random.choice(MaxNumber, size=MaxNumber, replace=False).astype(dtype))
        
        # Create lookup values (small subset for lookup)
        np.random.seed(24)
        self.lookup_values = np.random.choice(self.series.values, size=1000, replace=False)

    def time_isin(self, dtypes, MaxNumber, series_type):
        self.series.isin(self.lookup_values)","class IsInLongSeriesLookUpDominates:
    def setup(self, dtype, MaxNumber, series_type):
        np.random.seed(1234)
        self.N = 10**7
        self.K = 10**6
        
        if series_type == 'object':
            self.series = pd.Series(np.random.choice(['foo', 'bar', 'baz'] * 1000, self.N))
            self.values = ['foo', 'bar']
        elif series_type == 'int64':
            self.series = pd.Series(np.random.randint(0, MaxNumber, self.N))
            self.values = np.random.randint(0, MaxNumber, self.K)
        elif series_type == 'float64':
            self.series = pd.Series(np.random.randn(self.N))
            self.values = np.random.randn(self.K)
        else:
            self.series = pd.Series(np.random.randint(0, MaxNumber, self.N), dtype=dtype)
            self.values = np.random.randint(0, MaxNumber, self.K)

    def time_isin(self, dtypes, MaxNumber, series_type):
        self.series.isin(self.values)",no_docstr,0.451923076923077,0.2524271844660194,0.14705882352941174,0.33653846153846156,0.26099960580896125,0.7005649717514124,0.4147727272727273,0.3142857142857143,0.7934228181838989,0.7881070375442505,0.7907560467720032,0.7886353731155396,0.7426926315789484,0.5339366515837104,0.2831050228310502,0.16589861751152077,0.3981900452488688,0.330314196980426,0.6971153846153846,0.42028985507246375,0.3155339805825243,0.8194813132286072,0.8013627529144287,0.8103207349777222,0.8031383752822876,0.7529264473684222,0.592274678111588,0.329004329004329,0.2270742358078603,0.4549356223175966,0.4023427031874677,0.6533864541832669,0.404,0.321285140562249,0.877592921257019,0.8308600187301636,0.85358726978302,0.8353081345558167,0.7800291902834012,0.2403269071030115,0.0969438035036664,0.1024590630036178,0.4761904761904761,0.2857142857142857,0.2294655198894911,0.1153843212498106,0.124555680386076,0.4571428571428571,0.2207792207792207,0.258130458698166,0.1697805398368199,0.1744296066441557,0.4285714285714285,0.2597402597402597
250958,avalente/appmetrics,avalente_appmetrics/appmetrics/reporter.py,appmetrics.reporter.CSVReporter,"class CSVReporter(object):
    histogram_header = (
        'time', 'n', 'min', 'max', 'arithmetic_mean', 'median', 'harmonic_mean', 'geometric_mean',
        'standard_deviation', 'variance', 'percentile_50', 'percentile_75', 'percentile_90',
        'percentile_95', 'percentile_99', 'percentile_99.9', 'kurtosis', 'skewness')

    meter_header = ('time', 'count', 'mean', 'one', 'five', 'fifteen', 'day')

    def __init__(self, directory):
        self.directory = directory

    def file_name(self, name, kind):
        file_name = os.path.join(self.directory, ""{}_{}.csv"".format(name, kind))

        if not os.path.exists(file_name):
            new = True
        else:
            new = False

        return file_name, new

    def dump_histogram(self, name, obj):

        # histogram doesn't fit into a tabular format
        obj.pop('histogram')

        # we already know its kind
        kind = obj.pop('kind')

        # flatten percentiles
        percentiles = obj.pop('percentile')
        for k, v in percentiles:
            obj['percentile_{}'.format(k)] = v

        # add the current time
        obj['time'] = time.time()

        file_name, new = self.file_name(name, kind)

        with open(file_name, ""a"" if py3comp.PY3 else ""ab"") as of:
            writer = csv.DictWriter(of, self.histogram_header)

            # if the file is new, write the header once
            if new:
                writer.writerow(dict(zip(self.histogram_header, self.histogram_header)))

            writer.writerow(obj)

        return file_name

    def dump_meter(self, name, obj):

        # we already know its kind
        kind = obj.pop('kind')

        # add the current time
        obj['time'] = time.time()

        file_name, new = self.file_name(name, kind)

        with open(file_name, ""a"" if py3comp.PY3 else ""ab"") as of:
            writer = csv.DictWriter(of, self.meter_header)

            # if the file is new, write the header once
            if new:
                writer.writerow(dict(zip(self.meter_header, self.meter_header)))

            writer.writerow(obj)

        return file_name

    def __call__(self, objects):
        for name, obj in py3comp.iteritems(objects):
            fun = getattr(self, ""dump_%s"" % obj.get('kind', ""unknown""), None)
            if fun:
                # protect the original object
                fun(name, obj.copy())","class CSVReporter(object):


    def __init__(self, directory):
        pass

    def file_name(self, name, kind):
        pass

    def dump_histogram(self, name, obj):
        pass

    def dump_meter(self, name, obj):
        pass

    def __call__(self, objects):
        pass

",6,0,snippet_165,0.1304347826086956,"class CSVReporter(object):

    def __init__(self, directory):
        self.directory = directory
        os.makedirs(self.directory, exist_ok=True)
        self._headers = {
            'histogram': ['timestamp', 'count', 'min', 'max', 'mean', 'stddev',
                          'p50', 'p75', 'p95', 'p98', 'p99', 'p999'],
            'meter': ['timestamp', 'count', 'mean_rate', 'm1_rate', 'm5_rate', 'm15_rate']
        }

    def file_name(self, name, kind):
        fname = f""{name}-{kind}.csv""
        return os.path.join(self.directory, fname)

    def dump_histogram(self, name, obj):
        fn = self.file_name(name, 'histogram')
        is_new = not os.path.exists(fn)
        with open(fn, 'a', newline='') as f:
            writer = csv.writer(f)
            if is_new:
                writer.writerow(self._headers['histogram'])
            ts = int(time.time())
            # expect obj to have count, min, max, mean, stddev and percentiles() -> dict
            cnt = getattr(obj, 'count', '')
            mn  = getattr(obj, 'min', '')
            mx  = getattr(obj, 'max', '')
            mean = getattr(obj, 'mean', '')
            std = getattr(obj, 'stddev', '')
            # percentiles: 50,75,95,98,99,99.9
            percs = {}
            if hasattr(obj, 'percentiles'):
                try:
                    percs = obj.percentiles()
                except:
                    percs = {}
            row = [
                ts, cnt, mn, mx, mean, std,
                percs.get(50, ''),
                percs.get(75, ''),
                percs.get(95, ''),
                percs.get(98, ''),
                percs.get(99, ''),
                percs.get(99.9, ''),
            ]
            writer.writerow(row)

    def dump_meter(self, name, obj):
        fn = self.file_name(name, 'meter')
        is_new = not os.path.exists(fn)
        with open(fn, 'a', newline='') as f:
            writer = csv.writer(f)
            if is_new:
                writer.writerow(self._headers['meter'])
            ts = int(time.time())
            cnt = getattr(obj, 'count', '')
            mean_rate = getattr(obj, 'mean_rate', '')
            m1 = getattr(obj, 'm1_rate', '')
            m5 = getattr(obj, 'm5_rate', '')
            m15 = getattr(obj, 'm15_rate', '')
            row = [ts, cnt, mean_rate, m1, m5, m15]
            writer.writerow(row)

    def __call__(self, objects):
        for name, obj in objects.items():
            # try histogram first
            try:
                self.dump_histogram(name, obj)
            except Exception:
                pass
            # then meter
            try:
                self.dump_meter(name, obj)
            except Exception:
                pass","class CSVReporter(object):
    def __init__(self, directory):
        self.directory = directory
        if not os.path.exists(directory):
            os.makedirs(directory)

    def file_name(self, name, kind):
        return os.path.join(self.directory, f""{name}_{kind}.csv"")

    def dump_histogram(self, name, obj):
        filename = self.file_name(name, 'histogram')
        file_exists = os.path.exists(filename)
        
        with open(filename, 'a', newline='') as csvfile:
            writer = csv.writer(csvfile)
            if not file_exists:
                writer.writerow(['timestamp', 'count', 'min', 'max', 'mean', 'stddev'])
            
            timestamp = datetime.now().isoformat()
            row = [timestamp, obj.get('count', 0), obj.get('min', 0), obj.get('max', 0), 
                   obj.get('mean', 0), obj.get('stddev', 0)]
            writer.writerow(row)

    def dump_meter(self, name, obj):
        filename = self.file_name(name, 'meter')
        file_exists = os.path.exists(filename)
        
        with open(filename, 'a', newline='') as csvfile:
            writer = csv.writer(csvfile)
            if not file_exists:
                writer.writerow(['timestamp', 'count', 'm1_rate', 'm5_rate', 'm15_rate', 'mean_rate'])
            
            timestamp = datetime.now().isoformat()
            row = [timestamp, obj.get('count', 0), obj.get('m1_rate', 0), obj.get('m5_rate', 0), 
                   obj.get('m15_rate', 0), obj.get('mean_rate', 0)]
            writer.writerow(row)

    def __call__(self, objects):
        for name, obj in objects.items():
            if 'histogram' in name.lower() or (isinstance(obj, dict) and 'count' in obj and 'mean' in obj):
                self.dump_histogram(name, obj)
            elif 'meter' in name.lower() or (isinstance(obj, dict) and 'm1_rate' in obj):
                self.dump_meter(name, obj)","class CSVReporter(object):

    def __init__(self, directory):
        self.directory = directory
        if not os.path.exists(directory):
            os.makedirs(directory)

    def file_name(self, name, kind):
        return os.path.join(self.directory, f""{name}_{kind}.csv"")

    def dump_histogram(self, name, obj):
        filename = self.file_name(name, ""histogram"")
        with open(filename, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['bucket', 'count'])
            if hasattr(obj, 'buckets'):
                for bucket, count in obj.buckets.items():
                    writer.writerow([bucket, count])
            elif hasattr(obj, 'items'):
                for bucket, count in obj.items():
                    writer.writerow([bucket, count])

    def dump_meter(self, name, obj):
        filename = self.file_name(name, ""meter"")
        with open(filename, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['metric', 'value'])
            if hasattr(obj, 'count'):
                writer.writerow(['count', obj.count])
            if hasattr(obj, 'rate'):
                writer.writerow(['rate', obj.rate])
            if hasattr(obj, 'mean_rate'):
                writer.writerow(['mean_rate', obj.mean_rate])
            if hasattr(obj, 'one_minute_rate'):
                writer.writerow(['one_minute_rate', obj.one_minute_rate])
            if hasattr(obj, 'five_minute_rate'):
                writer.writerow(['five_minute_rate', obj.five_minute_rate])
            if hasattr(obj, 'fifteen_minute_rate'):
                writer.writerow(['fifteen_minute_rate', obj.fifteen_minute_rate])

    def __call__(self, objects):
        for name, obj in objects.items():
            obj_type = type(obj).__name__.lower()
            if 'histogram' in obj_type or hasattr(obj, 'buckets'):
                self.dump_histogram(name, obj)
            elif 'meter' in obj_type or hasattr(obj, 'rate') or hasattr(obj, 'count'):
                self.dump_meter(name, obj)",no_docstr,0.4753820033955858,0.21465076660988075,0.11965811965811966,0.2920203735144313,0.34345770851319835,0.5857142857142857,0.314785373608903,0.2197452229299363,0.8168911337852478,0.8166857361793518,0.8167884349822998,0.8167062401771545,0.7742804724409452,0.4574669187145558,0.22011385199240985,0.13333333333333333,0.30623818525519847,0.3536810348187194,0.7024793388429752,0.38509316770186336,0.27385892116182575,0.8248724937438965,0.779693603515625,0.8016470074653625,0.7839875221252441,0.7213466600790516,0.43283582089552236,0.20973782771535582,0.13157894736842105,0.2947761194029851,0.3448437352139907,0.6673189823874756,0.34509803921568627,0.2475442043222004,0.825100302696228,0.7650495171546936,0.7939409613609314,0.7706583738327026,0.713441600790514,0.2819681505841888,0.0956001470623449,0.1099296125579245,0.463519313304721,0.4588235294117647,0.2210011758708981,0.0922799251145438,0.1105584062407982,0.463519313304721,0.2176470588235294,0.1995196721443934,0.0865901913231745,0.1126750663026196,0.463519313304721,0.1352941176470588
515102,jlesquembre/autopilot,jlesquembre_autopilot/src/autopilot/ui.py,autopilot.ui.TermStr,"class TermStr:

    def __init__(self, *args):
        self.args = args

    def addstr(self, win, y=0, x=0):
        pos = x
        attr = Color.none

        for arg in self.args:
            if type(arg) is Color:
                attr = arg
            elif type(arg) is str:
                if attr == Color.none:
                    win.addstr(y, pos, arg)
                else:
                    win.addstr(y, pos, arg, attr.value)

                pos += len(arg)

    def __len__(self):
        return sum([len(x) for x in self.args if type(x) is str])","class TermStr:


    def __init__(self, *args):
        pass

    def addstr(self, win, y=0, x=0):
        pass

    def __len__(self):
        pass

",4,0,snippet_73,0.5,"class TermStr:
    def __init__(self, *args):
        self._parts = []
        self._curattr = 0
        for arg in args:
            if isinstance(arg, int):
                self._curattr = arg
            else:
                s = str(arg)
                if s:
                    self._parts.append((s, self._curattr))

    def addstr(self, win, y=0, x=0):
        for s, attr in self._parts:
            try:
                win.addstr(y, x, s, attr)
            except TypeError:
                win.addstr(y, x, s)
            x += len(s)

    def __len__(self):
        return sum(len(s) for s, _ in self._parts)","class TermStr:
    def __init__(self, *args):
        if len(args) == 1 and isinstance(args[0], str):
            self.text = args[0]
        elif len(args) == 2 and isinstance(args[0], str) and isinstance(args[1], int):
            self.text = args[0]
            self.attr = args[1]
        else:
            self.text = """"
            self.attr = 0

    def addstr(self, win, y=0, x=0):
        if hasattr(self, 'attr'):
            win.addstr(y, x, self.text, self.attr)
        else:
            win.addstr(y, x, self.text)

    def __len__(self):
        return len(self.text)","class TermStr:
    def __init__(self, *args):
        self.segments = []
        if len(args) == 1:
            if isinstance(args[0], str):
                self.segments.append((args[0], None))
            else:
                self.segments = list(args[0])
        elif len(args) == 2:
            self.segments.append((args[0], args[1]))
        else:
            i = 0
            while i < len(args):
                if i + 1 < len(args) and not isinstance(args[i + 1], str):
                    self.segments.append((args[i], args[i + 1]))
                    i += 2
                else:
                    self.segments.append((args[i], None))
                    i += 1

    def addstr(self, win, y=0, x=0):
        current_x = x
        for text, attr in self.segments:
            if attr is not None:
                win.addstr(y, current_x, text, attr)
            else:
                win.addstr(y, current_x, text)
            current_x += len(text)

    def __len__(self):
        return sum(len(text) for text, attr in self.segments)",no_docstr,0.6274509803921569,0.3708609271523179,0.24161073825503357,0.457516339869281,0.5035683764959689,0.7116564417177914,0.48148148148148145,0.37267080745341613,0.8561521172523499,0.8671844005584717,0.8616330027580261,0.866068422794342,0.8137273529411764,0.5732484076433121,0.2709677419354839,0.20915032679738563,0.40764331210191085,0.43095393951767624,0.653179190751445,0.3953488372093023,0.30994152046783624,0.8249325752258301,0.8195642828941345,0.8222396373748779,0.8200979828834534,0.7653532236842107,0.5410628019323672,0.28292682926829266,0.187192118226601,0.40579710144927533,0.29852746534967767,0.4460431654676259,0.2743682310469314,0.21739130434782608,0.7760018110275269,0.8340981006622314,0.8040018081665039,0.8278999924659729,0.7730519148936177,0.3175110734889604,0.179132127312118,0.1867253711525805,0.4782608695652174,0.4259259259259259,0.2541392567052993,0.1558703786544184,0.1610087093584055,0.3478260869565217,0.3518518518518518,0.3184691574663209,0.1101017431692371,0.1895397820261592,0.4927536231884058,0.4814814814814814
665557,pydata/xarray,pydata_xarray/asv_bench/benchmarks/dataset_io.py,benchmarks.dataset_io.IOWriteNetCDFDask,"class IOWriteNetCDFDask:
    timeout = 60
    repeat = 1
    number = 5

    def setup(self):
        # TODO: Lazily skipped in CI as it is very demanding and slow.
        # Improve times and remove errors.
        _skip_slow()

        requires_dask()

        self.write = create_delayed_write()

    def time_write(self):
        self.write.compute()","class IOWriteNetCDFDask:


    def setup(self):
        pass

    def time_write(self):
        pass

",3,0,snippet_438,1.0,"class IOWriteNetCDFDask:

    def setup(self):
        # create a temporary file for writing
        tmp = tempfile.NamedTemporaryFile(suffix='.nc', delete=False)
        self.filename = tmp.name
        tmp.close()

        # create a Dask-backed xarray Dataset
        shape = (2000, 2000)
        chunks = (500, 500)
        data = da.random.random(shape, chunks=chunks)
        self.ds = xr.Dataset(
            {""data"": ((""x"", ""y""), data)},
            coords={""x"": np.arange(shape[0]), ""y"": np.arange(shape[1])},
        )

    def time_write(self):
        # write the Dataset to NetCDF
        self.ds.to_netcdf(self.filename, mode=""w"", engine=""netcdf4"")","class IOWriteNetCDFDask:
    def setup(self):
        # Create sample data with dask arrays
        self.temp_dir = TemporaryDirectory()
        self.file_path = os.path.join(self.temp_dir.name, ""test_data.nc"")
        
        # Create large dataset with dask arrays
        data_shape = (1000, 1000)
        chunks = (100, 100)
        
        # Create dask arrays
        temp_data = da.random.random(data_shape, chunks=chunks)
        pressure_data = da.random.random(data_shape, chunks=chunks)
        
        # Create xarray dataset
        self.dataset = xr.Dataset(
            {
                'temperature': (['x', 'y'], temp_data),
                'pressure': (['x', 'y'], pressure_data)
            },
            coords={
                'x': np.arange(data_shape[0]),
                'y': np.arange(data_shape[1])
            }
        )

    def time_write(self):
        # Write the dataset to NetCDF file
        self.dataset.to_netcdf(self.file_path)
        
    def teardown(self):
        # Clean up temporary directory
        self.temp_dir.cleanup()","class IOWriteNetCDFDask:
    def __init__(self):
        self.ds = None
        self.filename = None

    def setup(self):
        # Create a temporary file
        self.filename = tempfile.mktemp(suffix='.nc')
        
        # Create sample data with dask arrays
        time = np.arange(100)
        lat = np.linspace(-90, 90, 180)
        lon = np.linspace(-180, 180, 360)
        
        # Create dask arrays for the data variables
        temp_data = da.random.random((100, 180, 360), chunks=(10, 60, 120))
        precip_data = da.random.random((100, 180, 360), chunks=(10, 60, 120))
        
        # Create xarray dataset with dask arrays
        self.ds = xr.Dataset({
            'temperature': (['time', 'lat', 'lon'], temp_data),
            'precipitation': (['time', 'lat', 'lon'], precip_data)
        }, coords={
            'time': time,
            'lat': lat,
            'lon': lon
        })

    def time_write(self):
        self.ds.to_netcdf(self.filename, compute=True)
        
    def teardown(self):
        if self.filename and os.path.exists(self.filename):
            os.remove(self.filename)",no_docstr,0.24,0.11382113821138212,0.049586776859504134,0.192,0.13571226472504788,0.24719101123595505,0.11864406779661017,0.08522727272727272,0.6889963746070862,0.7497687339782715,0.718099057674408,0.7432132959365845,0.7472792156862746,0.18292682926829268,0.08641975308641975,0.037500000000000006,0.1585365853658537,0.10661495809942474,0.19583333333333333,0.09205020920502092,0.06722689075630252,0.6506029963493347,0.7282758951187134,0.6872518062591553,0.7196839451789856,0.7423449189189192,0.19101123595505617,0.07954545454545456,0.04597701149425287,0.14606741573033707,0.09332791191877278,0.18450184501845018,0.07407407407407407,0.05947955390334572,0.6359699368476868,0.7357625365257263,0.6822363138198853,0.7243956923484802,0.7291693750000005,0.213779455461919,0.025306598887908,0.0394886423146067,0.2903225806451613,0.5,0.2635284572783163,0.0173133588416691,0.0394886423146067,0.5806451612903226,0.4166666666666667,0.1585230379516252,0.0147333941908081,0.0414017683683807,0.1612903225806451,0.4166666666666667
170737,PyCQA/pylint,doc/data/messages/u/unused-private-member/good.py,good.Fruit,"class Fruit:
    FRUITS = {""apple"": ""red"", ""orange"": ""orange""}

    def __print_color(self, name, color):
        print(f""{name}: {color}"")

    def print(self):
        for fruit, color in self.FRUITS.items():
            self.__print_color(fruit, color)","class Fruit:


    def __print_color(self, name, color):
        pass

    def print(self):
        pass

",3,0,snippet_426,1.0,"class Fruit:
    def __init__(self, name, color):
        self.name = name
        self.color = color

    def __print_color(self, name, color):
        print(f""{name} is {color}"")

    def print(self):
        self.__print_color(self.name, self.color)","class Fruit:
    def __init__(self, name=""fruit"", color=""unknown""):
        self.name = name
        self.color = color

    def __print_color(self, name, color):
        print(f""The {name} is {color}"")

    def print(self):
        self.__print_color(self.name, self.color)","class Fruit:
    def __init__(self, name, color):
        self.name = name
        self.color = color

    def __print_color(self, name, color):
        print(f""{name} is {color}"")

    def print(self):
        self.__print_color(self.name, self.color)",no_docstr,0.6363636363636364,0.46874999999999994,0.3225806451612903,0.5757575757575757,0.5795236904100525,0.7402597402597403,0.5921052631578947,0.52,0.9123001098632812,0.8382484912872314,0.8737080693244934,0.8451082706451416,0.8190494285714286,0.6376811594202898,0.417910447761194,0.2769230769230769,0.5507246376811593,0.5468942370848509,0.7209302325581395,0.5294117647058824,0.42857142857142855,0.89957195520401,0.8466280698776245,0.8722974061965942,0.8516403436660767,0.8285731428571428,0.6363636363636364,0.46874999999999994,0.3225806451612903,0.5757575757575757,0.5795236904100525,0.7402597402597403,0.5921052631578947,0.52,0.9123001098632812,0.8382484912872314,0.8737080693244934,0.8451082706451416,0.8190494285714286,0.2400975216013633,0.1747094295777076,0.1796656192337607,0.3428571428571428,0.2631578947368421,0.2633393504367877,0.1669248652201571,0.1796656192337607,0.2857142857142857,0.4210526315789473,0.2400975216013633,0.1747094295777076,0.1796656192337607,0.3428571428571428,0.2631578947368421
537266,koolsb/pyblackbird,koolsb_pyblackbird/pyblackbird/__init__.py,pyblackbird.ZoneStatus,"class ZoneStatus(object):
    def __init__(self,
                 zone: int,
                 power: bool,
                 av: int,
                 ir: int):
        self.zone = zone
        self.power = power
        self.av = av
        self.ir = ir

    @classmethod
    def from_string(cls, zone: int, string: str):
        if not string:
            return None
        match_on = re.search (ZONE_PATTERN_ON, string)
        if not match_on:
            match_off = re.search (ZONE_PATTERN_OFF, string)
            if not match_off:
                return None
            return ZoneStatus(zone,0,None,None)
        return ZoneStatus(zone,1,*[int(m) for m in match_on.groups()])","class ZoneStatus(object):


    def __init__(self,
                 zone: int,
                 power: bool,
                 av: int,
                 ir: int):
        pass

    @classmethod
    def from_string(cls, zone: int, string: str):
        pass

",4,0,snippet_691,0.2727272727272727,"class ZoneStatus(object):
    def __init__(self, zone: int, power: bool, av: int, ir: int):
        self.zone = zone
        self.power = power
        self.av = av
        self.ir = ir

    @classmethod
    def from_string(cls, zone: int, string: str):
        """"""
        Expect string in the form ""power,av,ir""
        where power is 0/1 or true/false/on/off,
        av and ir are integers.
        """"""
        parts = [p.strip() for p in string.split("","")]
        if len(parts) != 3:
            raise ValueError(f""Invalid input '{string}'; expected 3 commaseparated values"")
        p_str, av_str, ir_str = parts

        p_low = p_str.lower()
        if p_low in (""1"", ""true"", ""on"", ""yes""):
            power = True
        elif p_low in (""0"", ""false"", ""off"", ""no""):
            power = False
        else:
            raise ValueError(f""Cannot parse power value '{p_str}'"")

        try:
            av = int(av_str)
        except ValueError:
            raise ValueError(f""Cannot parse av value '{av_str}' as int"")

        try:
            ir = int(ir_str)
        except ValueError:
            raise ValueError(f""Cannot parse ir value '{ir_str}' as int"")

        return cls(zone, power, av, ir)","class ZoneStatus(object):
    def __init__(self,
                 zone: int,
                 power: bool,
                 av: int,
                 ir: int):
        self.zone = zone
        self.power = power
        self.av = av
        self.ir = ir

    @classmethod
    def from_string(cls, zone: int, string: str):
        parts = string.split(',')
        power = parts[0].strip() == 'ON'
        av = int(parts[1].strip())
        ir = int(parts[2].strip())
        return cls(zone, power, av, ir)","class ZoneStatus(object):

    def __init__(self,
                 zone: int,
                 power: bool,
                 av: int,
                 ir: int):
        self.zone = zone
        self.power = power
        self.av = av
        self.ir = ir

    @classmethod
    def from_string(cls, zone: int, string: str):
        parts = string.strip().split()
        power = parts[0].lower() == 'on' if len(parts) > 0 else False
        av = int(parts[1]) if len(parts) > 1 else 0
        ir = int(parts[2]) if len(parts) > 2 else 0
        return cls(zone, power, av, ir)",no_docstr,0.40963855421686746,0.27530364372469635,0.2693877551020408,0.35341365461847385,0.2668015047793926,0.3776435045317221,0.23636363636363636,0.2127659574468085,0.7438713908195496,0.8275730609893799,0.7834930419921875,0.8183647394180298,0.7887538271604945,0.5874125874125875,0.48226950354609927,0.47482014388489213,0.5454545454545454,0.5003162765022201,0.7633587786259542,0.5769230769230769,0.5426356589147286,0.9085322618484497,0.8248894810676575,0.8646928071975708,0.832554280757904,0.8589757692307692,0.5625,0.43037974683544294,0.4230769230769231,0.525,0.51778458279058,0.6754966887417219,0.5133333333333333,0.4697986577181208,0.8689953088760376,0.8402465581893921,0.8543791770935059,0.8430355191230774,0.8449089583333333,0.4449582146842958,0.2289236751891081,0.4964490896513616,0.5211267605633803,0.5333333333333333,0.4874715490563405,0.489420413566149,0.4563969250692287,0.4929577464788732,0.5111111111111111,0.5012999642933073,0.4634037032659767,0.4873360600105387,0.5211267605633803,0.5333333333333333
335941,delvelabs/hammertime,delvelabs_hammertime/hammertime/http.py,hammertime.http.Result,"class Result:
    def __init__(self):
        self.attempt = 1
        self.read_length = -1  # -1 is unlimited
        self.redirects = []

    def __hash__(self):
        return hash(self.__dict__)

    def __eq__(self, other):
        return self.__dict__ == other.__dict__

    def __copy__(self):
        _copy = Result()
        _copy.attempt = self.attempt
        _copy.read_length = self.read_length
        _copy.redirects = copy(self.redirects)
        return _copy

    def __repr__(self):
        return repr(self.__dict__)","class Result:


    def __init__(self):
        pass

    def __hash__(self):
        pass

    def __eq__(self, other):
        pass

    def __copy__(self):
        pass

    def __repr__(self):
        pass

",6,0,snippet_221,1.0,"class Result:
    def __init__(self):
        pass

    def __hash__(self):
        items = tuple(sorted(self.__dict__.items()))
        return hash(items)

    def __eq__(self, other):
        if not isinstance(other, Result):
            return NotImplemented
        return self.__dict__ == other.__dict__

    def __copy__(self):
        new = type(self)()
        for k, v in self.__dict__.items():
            setattr(new, k, v)
        return new

    def __repr__(self):
        items = "", "".join(f""{k}={v!r}"" for k, v in sorted(self.__dict__.items()))
        return f""{self.__class__.__name__}({items})""","class Result:
    def __init__(self):
        self._data = {}

    def __hash__(self):
        return hash(tuple(sorted(self._data.items())))

    def __eq__(self, other):
        if not isinstance(other, Result):
            return False
        return self._data == other._data

    def __copy__(self):
        import copy
        new_result = Result()
        new_result._data = copy.copy(self._data)
        return new_result

    def __repr__(self):
        return f""Result({self._data})""","class Result:
    def __init__(self, value=None, error=None):
        self.value = value
        self.error = error
        self.is_success = error is None

    def __hash__(self):
        return hash((self.value, self.error, self.is_success))

    def __eq__(self, other):
        if not isinstance(other, Result):
            return False
        return (self.value == other.value and 
                self.error == other.error and 
                self.is_success == other.is_success)

    def __copy__(self):
        return Result(self.value, self.error)

    def __repr__(self):
        if self.is_success:
            return f""Result(value={repr(self.value)})""
        else:
            return f""Result(error={repr(self.error)})""",no_docstr,0.5072463768115941,0.3088235294117647,0.1940298507462687,0.43478260869565216,0.4604667847256619,0.5865384615384616,0.4396135265700483,0.3786407766990291,0.7897796034812927,0.7989251613616943,0.7943260073661804,0.7980011105537415,0.7635158783783785,0.5454545454545455,0.31932773109243695,0.20512820512820512,0.5454545454545455,0.5215272414895091,0.7103448275862069,0.5555555555555556,0.46153846153846156,0.8302978277206421,0.7967296838760376,0.8131674528121948,0.7999638915061951,0.8130859813084111,0.4675324675324675,0.25,0.14666666666666667,0.44155844155844154,0.3901030234715262,0.545,0.37185929648241206,0.29292929292929293,0.7923006415367126,0.7988462448120117,0.7955599427223206,0.7981868386268616,0.8085604729729728,0.2646913068338304,0.1821008319530942,0.2205240445050346,0.3666666666666666,0.2894736842105263,0.2487523561777725,0.1254757980154179,0.1397090652921633,0.4666666666666667,0.2631578947368421,0.2439538317177931,0.0471676503730922,0.0646125887787819,0.4166666666666667,0.4473684210526316
389619,freenode/cms7,freenode_cms7/cms7/modules/faq.py,cms7.modules.faq.FaqEntryWrapper,"class FaqEntryWrapper:
    def __init__(self, gs, entry):
        self.gs = gs
        self.entry = entry

    def __getattr__(self, k):
        return getattr(self.entry, k)

    @property
    def url(self):
        return self.gs.url_for(self.name)

    def render(self):
        return self.source.render(self.gs)","class FaqEntryWrapper:


    def __init__(self, gs, entry):
        pass

    def __getattr__(self, k):
        pass

    @property
    def url(self):
        pass

    def render(self):
        pass

",6,0,snippet_140,0.8333333333333334,"class FaqEntryWrapper:
    def __init__(self, gs, entry):
        self.gs = gs
        self.entry = entry

    def __getattr__(self, k):
        try:
            return getattr(self.entry, k)
        except AttributeError:
            raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{k}'"")

    @property
    def url(self):
        base = getattr(self.gs, 'base_url', '')
        slug = getattr(self.entry, 'slug', '')
        return urljoin(base.rstrip('/') + '/', slug)

    def render(self):
        q = getattr(self.entry, 'question', '')
        a = getattr(self.entry, 'answer', '')
        return (
            f""<div class=\""faq-entry\"">\n""
            f""  <h3><a href=\""{self.url}\"">{q}</a></h3>\n""
            f""  <div class=\""faq-answer\"">{a}</div>\n""
            f""</div>""
        )","class FaqEntryWrapper:
    def __init__(self, gs, entry):
        self.gs = gs
        self.entry = entry

    def __getattr__(self, k):
        return getattr(self.entry, k)

    @property
    def url(self):
        return f""{self.gs.base_url}/faq/{self.entry.id}""

    def render(self):
        return f""<div class='faq-entry'><h3>{self.entry.question}</h3><p>{self.entry.answer}</p></div>""","class FaqEntryWrapper:
    def __init__(self, gs, entry):
        self.gs = gs
        self.entry = entry

    def __getattr__(self, k):
        return getattr(self.entry, k)

    @property
    def url(self):
        return f""/faq/{self.entry.id}""

    def render(self):
        return self.gs.render_template('faq_entry.html', entry=self)",no_docstr,0.5507246376811594,0.3970588235294118,0.3283582089552239,0.5072463768115941,0.28535533426480025,0.3333333333333333,0.28225806451612906,0.24696356275303644,0.7187327146530151,0.9179545640945435,0.8062187433242798,0.8931965231895447,0.769233076923077,0.7551020408163266,0.6249999999999999,0.574468085106383,0.7551020408163266,0.5490771056504117,0.609375,0.5433070866141733,0.5,0.8535120487213135,0.9489290118217468,0.8986949324607849,0.9384379386901855,0.9302332558139536,0.8275862068965518,0.7294117647058823,0.6987951807228916,0.8045977011494253,0.7417281917030183,0.8125,0.7263157894736842,0.6914893617021277,0.9312465190887451,0.9552926421165466,0.943116307258606,0.9528322815895081,0.9429830263157895,0.6249911489185419,0.249665663023868,0.6783925781352493,0.6153846153846154,0.9565217391304348,0.7470177168913144,0.8266114125804572,0.8682599009156805,0.6410256410256411,0.6521739130434783,0.7796264125434882,0.8266114125804572,0.8682599009156805,0.6410256410256411,0.782608695652174
299724,cloudera/impyla,cloudera_impyla/impala/_thrift_gen/hive_metastore/ThriftHiveMetastore.py,impala._thrift_gen.hive_metastore.ThriftHiveMetastore.get_all_functions_args,"class get_all_functions_args(object):


    def read(self, iprot):
        if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
            iprot._fast_decode(self, iprot, [self.__class__, self.thrift_spec])
            return
        iprot.readStructBegin()
        while True:
            (fname, ftype, fid) = iprot.readFieldBegin()
            if ftype == TType.STOP:
                break
            else:
                iprot.skip(ftype)
            iprot.readFieldEnd()
        iprot.readStructEnd()

    def write(self, oprot):
        if oprot._fast_encode is not None and self.thrift_spec is not None:
            oprot.trans.write(oprot._fast_encode(self, [self.__class__, self.thrift_spec]))
            return
        oprot.writeStructBegin('get_all_functions_args')
        oprot.writeFieldStop()
        oprot.writeStructEnd()

    def validate(self):
        return

    def __repr__(self):
        L = ['%s=%r' % (key, value)
             for key, value in self.__dict__.items()]
        return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

    def __ne__(self, other):
        return not (self == other)","class get_all_functions_args(object):


    def read(self, iprot):
        pass

    def write(self, oprot):
        pass

    def validate(self):
        pass

    def __repr__(self):
        pass

    def __eq__(self, other):
        pass

    def __ne__(self, other):
        pass

",7,0,snippet_586,0.3809523809523809,"class get_all_functions_args(object):
    """"""
    Attributes:
     - (none)
    """"""

    def read(self, iprot):
        iprot.readStructBegin()
        while True:
            fname, ftype, fid = iprot.readFieldBegin()
            if ftype == TType.STOP:
                break
            iprot.skip(ftype)
            iprot.readFieldEnd()
        iprot.readStructEnd()
        self.validate()

    def write(self, oprot):
        self.validate()
        oprot.writeStructBegin('get_all_functions_args')
        # no fields
        oprot.writeFieldStop()
        oprot.writeStructEnd()

    def validate(self):
        # no required fields to check
        return

    def __repr__(self):
        return 'get_all_functions_args()'

    def __eq__(self, other):
        return isinstance(other, get_all_functions_args)

    def __ne__(self, other):
        return not self.__eq__(other)","class get_all_functions_args(object):

    def read(self, iprot):
        iprot.readStructBegin()
        while True:
            (fname, ftype, fid) = iprot.readFieldBegin()
            if ftype == 0:
                break
            else:
                iprot.skip(ftype)
            iprot.readFieldEnd()
        iprot.readStructEnd()

    def write(self, oprot):
        oprot.writeStructBegin('get_all_functions_args')
        oprot.writeFieldStop()
        oprot.writeStructEnd()

    def validate(self):
        return

    def __repr__(self):
        return '<get_all_functions_args>'

    def __eq__(self, other):
        if not isinstance(other, self.__class__):
            return False
        return True

    def __ne__(self, other):
        return not (self == other)","class get_all_functions_args(object):
    def __init__(self):
        pass

    def read(self, iprot):
        iprot.readStructBegin()
        while True:
            (fname, ftype, fid) = iprot.readFieldBegin()
            if ftype == TType.STOP:
                break
            else:
                iprot.skip(ftype)
            iprot.readFieldEnd()
        iprot.readStructEnd()

    def write(self, oprot):
        oprot.writeStructBegin('get_all_functions_args')
        oprot.writeFieldStop()
        oprot.writeStructEnd()

    def validate(self):
        return

    def __repr__(self):
        L = ['%s=%r' % (key, value)
             for key, value in self.__dict__.items()]
        return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

    def __ne__(self, other):
        return not (self == other)",no_docstr,0.5843621399176955,0.4730290456431535,0.38493723849372385,0.5679012345679013,0.34220000780683524,0.8571428571428571,0.7178217821782178,0.6318407960199005,0.8889684677124023,0.7979402542114258,0.8409983515739441,0.8061954975128174,0.8187848809523813,0.6206896551724137,0.5217391304347826,0.46491228070175433,0.5862068965517241,0.32145058108705177,0.9491525423728814,0.8806818181818182,0.84,0.9114086031913757,0.8001739382743835,0.8521767258644104,0.8100605010986328,0.8306895238095238,0.761904761904762,0.736,0.7096774193548387,0.7539682539682541,0.6497123816525031,0.9882352941176471,0.968503937007874,0.9446640316205533,0.9267868995666504,0.8464378714561462,0.884791910648346,0.8538404703140259,0.8981491666666667,0.2950897509754692,0.1859955441729987,0.2122206025860207,0.5071428571428571,0.275,0.368688119444998,0.2798398315451871,0.3520555033776619,0.5928571428571429,0.25,0.5959705505822722,0.598880613944876,0.6117873026699269,0.7857142857142857,0.3875
170343,PyCQA/pylint,doc/data/messages/m/method-hidden/good.py,good.Fruit,"class Fruit:
    def __init__(self, vitamins):
        self.vitamins = vitamins

    def antioxidants(self):
        pass","class Fruit:


    def __init__(self, vitamins):
        pass

    def antioxidants(self):
        pass

",3,0,snippet_474,1.0,"class Fruit:
    def __init__(self, vitamins):
        self.vitamins = vitamins

    def antioxidants(self):
        return [v for v in self.vitamins if v in {""A"", ""C"", ""E""}]","class Fruit:
    def __init__(self, vitamins):
        self.vitamins = vitamins

    def antioxidants(self):
        return f""This fruit contains vitamins: {', '.join(self.vitamins)}""","class Fruit:
    def __init__(self, vitamins):
        self.vitamins = vitamins

    def antioxidants(self):
        return sum(self.vitamins.values())",no_docstr,0.631578947368421,0.611111111111111,0.5882352941176471,0.631578947368421,0.49981495187059016,0.5094339622641509,0.5,0.49019607843137253,0.8513665795326233,0.9502413868904114,0.8980907797813416,0.9393324255943298,0.822224,0.7058823529411765,0.6874999999999999,0.6666666666666666,0.7058823529411765,0.553002037286421,0.5625,0.5531914893617021,0.5434782608695652,0.8725525140762329,0.9312010407447815,0.9009233117103577,0.9249836802482605,0.8508786842105264,0.8000000000000002,0.7857142857142857,0.7692307692307692,0.8000000000000002,0.7025271290576449,0.7105263157894737,0.7027027027027027,0.6944444444444444,0.9157637357711792,0.9530529975891113,0.934036374092102,0.9491878747940063,0.8854178125,0.7047812516955195,0.4116245235860851,0.8690389447344548,0.5384615384615384,1.0,0.7381295388220945,0.5450176720923848,0.8690389447344548,0.5384615384615384,1.0,0.8036390526721978,0.8070557274927982,0.8690389447344548,0.5384615384615384,1.0
817558,vaexio/vaex,vaexio_vaex/packages/vaex-core/vaex/encoding.py,vaex.encoding.vaex_task_result_encoding,"class vaex_task_result_encoding:
    @classmethod
    def encode(cls, encoding, result):
        return encoding.encode('vaex-evaluate-result', result)

    @classmethod
    def decode(cls, encoding, result_encoded):
        return encoding.decode('vaex-evaluate-result', result_encoded)","class vaex_task_result_encoding:


    @classmethod
    def encode(cls, encoding, result):
        pass

    @classmethod
    def decode(cls, encoding, result_encoded):
        pass

",5,0,snippet_492,0.5,"class vaex_task_result_encoding:

    @classmethod
    def encode(cls, encoding, result):
        if encoding is None or encoding == 'raw':
            return result

        if encoding == 'pickle':
            # serialize any Python object to bytes
            return pickle.dumps(result)

        if encoding == 'base64':
            # pickle, then base64-encode to ASCII string
            data = pickle.dumps(result)
            return base64.b64encode(data).decode('ascii')

        if encoding == 'json':
            # JSON-serialize; convert numpy arrays to lists
            def _default(o):
                if isinstance(o, np.ndarray):
                    return o.tolist()
                raise TypeError(f""Object of type {type(o).__name__} is not JSON serializable"")
            return json.dumps(result, default=_default)

        if encoding == 'ndarray_binary':
            # efficient binary encoding for numpy arrays
            if not isinstance(result, np.ndarray):
                raise ValueError(""ndarray_binary encoding requires a numpy.ndarray"")
            payload = {
                ""__array__"": True,
                ""dtype"": str(result.dtype),
                ""shape"": result.shape,
                ""data"": base64.b64encode(result.tobytes()).decode('ascii')
            }
            return payload

        raise ValueError(f""Unknown encoding: {encoding!r}"")

    @classmethod
    def decode(cls, encoding, result_encoded):
        if encoding is None or encoding == 'raw':
            return result_encoded

        if encoding == 'pickle':
            # deserialize from bytes
            return pickle.loads(result_encoded)

        if encoding == 'base64':
            # base64-decode then unpickle
            data = base64.b64decode(result_encoded)
            return pickle.loads(data)

        if encoding == 'json':
            # JSON-deserialize; numpy arrays remain lists
            return json.loads(result_encoded)

        if encoding == 'ndarray_binary':
            # reconstruct numpy array
            if not (isinstance(result_encoded, dict) and result_encoded.get(""__array__"")):
                raise ValueError(""Invalid ndarray_binary payload"")
            dtype = np.dtype(result_encoded[""dtype""])
            shape = tuple(result_encoded[""shape""])
            raw = base64.b64decode(result_encoded[""data""])
            array = np.frombuffer(raw, dtype=dtype)
            return array.reshape(shape)

        raise ValueError(f""Unknown encoding: {encoding!r}"")","class vaex_task_result_encoding:
    @classmethod
    def encode(cls, encoding, result):
        if encoding == 'json':
            import json
            return json.dumps(result)
        elif encoding == 'pickle':
            import pickle
            return pickle.dumps(result)
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")

    @classmethod
    def decode(cls, encoding, result_encoded):
        if encoding == 'json':
            import json
            return json.loads(result_encoded)
        elif encoding == 'pickle':
            import pickle
            return pickle.loads(result_encoded)
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")","class vaex_task_result_encoding:

    @classmethod
    def encode(cls, encoding, result):
        if encoding == 'pickle':
            return base64.b64encode(pickle.dumps(result)).decode('ascii')
        elif encoding == 'json':
            if isinstance(result, np.ndarray):
                return json.dumps({
                    'type': 'ndarray',
                    'data': result.tolist(),
                    'dtype': str(result.dtype),
                    'shape': result.shape
                })
            else:
                return json.dumps(result)
        elif encoding == 'raw':
            return result
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")

    @classmethod
    def decode(cls, encoding, result_encoded):
        if encoding == 'pickle':
            return pickle.loads(base64.b64decode(result_encoded.encode('ascii')))
        elif encoding == 'json':
            decoded = json.loads(result_encoded)
            if isinstance(decoded, dict) and decoded.get('type') == 'ndarray':
                return np.array(decoded['data'], dtype=decoded['dtype']).reshape(decoded['shape'])
            else:
                return decoded
        elif encoding == 'raw':
            return result_encoded
        else:
            raise ValueError(f""Unsupported encoding: {encoding}"")",no_docstr,0.19795221843003413,0.13058419243986255,0.10380622837370242,0.19795221843003413,0.08825078040260363,0.10778443113772455,0.086,0.07414829659318638,0.6013835072517395,0.8352566957473755,0.69928377866745,0.8039901852607727,0.6999218978102202,0.5242718446601942,0.33663366336633666,0.2828282828282828,0.48543689320388345,0.3168009980732068,0.38461538461538464,0.3023255813953488,0.2734375,0.7180488705635071,0.8507626056671143,0.7787923216819763,0.8353236317634583,0.7722245,0.36708860759493667,0.21794871794871795,0.1818181818181818,0.34177215189873417,0.17865356924480003,0.2125984251968504,0.17786561264822134,0.15079365079365079,0.6234529614448547,0.8211402893066406,0.708770215511322,0.7959033846855164,0.7238833582089554,0.4750207324097905,0.0451579994064928,0.5695988432761473,0.3478260869565217,0.9375,0.5068554810268279,0.1724969938746424,0.5695988432761473,0.3478260869565217,0.9375,0.5058322920345675,0.1059042379056009,0.5695988432761473,0.3478260869565217,1.0
780408,tanghaibao/jcvi,tanghaibao_jcvi/src/jcvi/graphics/landscape.py,jcvi.graphics.landscape.BinLine,"class BinLine:
    def __init__(self, row):
        args = row.split()
        self.chr = args[0]
        self.len = float(args[1])
        self.binlen = int(args[2])

    def __str__(self):
        return ""\t"".join(str(x) for x in (self.chr, self.len, self.binlen))

    def subtract(self, o):
        self.binlen -= o.len","class BinLine:


    def __init__(self, row):
        pass

    def __str__(self):
        pass

    def subtract(self, o):
        pass

",4,0,snippet_617,0.4285714285714285,"class BinLine:
    def __init__(self, row):
        # Accept a string like ""1010"" or an iterable of 0/1 ints
        try:
            self.bits = [int(x) for x in row]
        except Exception:
            raise ValueError(""Row must be iterable of 0/1"")
        for b in self.bits:
            if b not in (0, 1):
                raise ValueError(""Elements must be 0 or 1"")

    def __str__(self):
        return ''.join(str(b) for b in self.bits)

    def subtract(self, o):
        if not isinstance(o, BinLine):
            raise TypeError(""Operand must be a BinLine"")
        if len(self.bits) != len(o.bits):
            raise ValueError(""Lengths must match"")
        result = [(a ^ b) for a, b in zip(self.bits, o.bits)]
        return BinLine(result)","class BinLine:
    def __init__(self, row):
        self.row = row

    def __str__(self):
        return str(self.row)

    def subtract(self, o):
        if len(self.row) != len(o.row):
            raise ValueError(""Rows must have the same length"")
        result = []
        for i in range(len(self.row)):
            result.append(self.row[i] - o.row[i])
        return BinLine(result)","class BinLine:
    def __init__(self, row):
        self.row = row

    def __str__(self):
        return ''.join(map(str, self.row))

    def subtract(self, o):
        result = []
        borrow = 0
        
        for i in range(len(self.row) - 1, -1, -1):
            diff = self.row[i] - o.row[i] - borrow
            
            if diff < 0:
                diff += 2
                borrow = 1
            else:
                borrow = 0
                
            result.append(diff)
        
        result.reverse()
        return BinLine(result)",no_docstr,0.4,0.21518987341772153,0.12820512820512822,0.31250000000000006,0.279906236417182,0.4158415841584158,0.263681592039801,0.2,0.7010963559150696,0.8020700216293335,0.748191773891449,0.790682315826416,0.7637992715231787,0.5294117647058824,0.24,0.16326530612244897,0.39215686274509803,0.4350492000045565,0.7017543859649122,0.39823008849557523,0.29464285714285715,0.7977596521377563,0.782650887966156,0.7901330590248108,0.7841359376907349,0.7333359999999999,0.5137614678899083,0.22429906542056074,0.1523809523809524,0.36697247706422015,0.40609254489715746,0.6434108527131783,0.3671875,0.28346456692913385,0.7470221519470215,0.7851870059967041,0.7656292915344238,0.7811959385871887,0.7272754545454545,0.2522054559047627,0.0723496838599678,0.2322297155166587,0.28,0.4242424242424242,0.2458251788126805,0.1613267352251011,0.2086406466922878,0.28,0.3333333333333333,0.2672004723274854,0.1135339666378397,0.2110254984296775,0.32,0.4242424242424242
709863,rsalmaso/django-fluo,rsalmaso_django-fluo/fluo/db/backend.py,fluo.db.backend.Backend,"class Backend:
    def __init__(self, options):
        self.host = options.get(""host"")
        self.port = options.get(""port"")
        self.password = options.get(""password"")
        self.name = options.get(""name"")
        self.user = options.get(""user"")
        self.engine = options.get(""user"")
        self.options = options

    def do_createdb(self):
        raise ImproperlyConfigured(
            ""%s.%s.do_createdb is not implemented."" % (self.__class__.__module__, self.__class__.__name__),
        )

    def do_dropdb(self):
        raise ImproperlyConfigured(
            ""%s.%s.do_dropdb is not implemented."" % (self.__class__.__module__, self.__class__.__name__),
        )

    def connect(self):
        raise ImproperlyConfigured(
            ""%s.%s.connect is not implemented."" % (self.__class__.__module__, self.__class__.__name__),
        )

    def close(self):
        raise ImproperlyConfigured(
            ""%s.%s.close is not implemented."" % (self.__class__.__module__, self.__class__.__name__),
        )

    def createdb(self):
        raise ImproperlyConfigured(
            ""%s.%s.createdb is not implemented."" % (self.__class__.__module__, self.__class__.__name__),
        )

    def dropdb(self):
        raise ImproperlyConfigured(
            ""%s.%s.dropdb is not implemented."" % (self.__class__.__module__, self.__class__.__name__),
        )","class Backend:


    def __init__(self, options):
        pass

    def do_createdb(self):
        pass

    def do_dropdb(self):
        pass

    def connect(self):
        pass

    def close(self):
        pass

    def createdb(self):
        pass

    def dropdb(self):
        pass

",8,0,snippet_309,1.0,"class Backend:

    def __init__(self, options):
        self.options = options
        self.conn = None

    def do_createdb(self):
        self.connect()

    def do_dropdb(self):
        db = self.options.get('database', ':memory:')
        if db != ':memory:' and os.path.exists(db):
            os.remove(db)

    def connect(self):
        if self.conn is None:
            db = self.options.get('database', ':memory:')
            self.conn = sqlite3.connect(db)
        return self.conn

    def close(self):
        if self.conn:
            self.conn.close()
            self.conn = None

    def createdb(self):
        self.do_createdb()
        self.close()

    def dropdb(self):
        self.close()
        self.do_dropdb()","class Backend:
    def __init__(self, options):
        self.options = options
        self.connection = None

    def do_createdb(self):
        # Implementation for creating database
        raise NotImplementedError(""Subclasses must implement do_createdb"")

    def do_dropdb(self):
        # Implementation for dropping database
        raise NotImplementedError(""Subclasses must implement do_dropdb"")

    def connect(self):
        # Implementation for connecting to database
        raise NotImplementedError(""Subclasses must implement connect"")

    def close(self):
        # Implementation for closing database connection
        if self.connection:
            self.connection.close()
            self.connection = None

    def createdb(self):
        # Wrapper method for creating database
        try:
            self.do_createdb()
        except Exception as e:
            raise Exception(f""Failed to create database: {str(e)}"")

    def dropdb(self):
        # Wrapper method for dropping database
        try:
            self.do_dropdb()
        except Exception as e:
            raise Exception(f""Failed to drop database: {str(e)}"")","class Backend:
    def __init__(self, options):
        self.options = options
        self.connection = None
        self.db_exists = False

    def do_createdb(self):
        if not self.db_exists:
            self.db_exists = True
            return True
        return False

    def do_dropdb(self):
        if self.db_exists:
            self.db_exists = False
            return True
        return False

    def connect(self):
        if self.connection is None:
            self.connection = f""connection_to_{self.options.get('database', 'default_db')}""
        return self.connection

    def close(self):
        if self.connection is not None:
            self.connection = None
            return True
        return False

    def createdb(self):
        try:
            return self.do_createdb()
        except Exception:
            return False

    def dropdb(self):
        try:
            return self.do_dropdb()
        except Exception:
            return False",no_docstr,0.4615384615384616,0.2241379310344828,0.12173913043478261,0.3504273504273504,0.13968356041276037,0.7315789473684211,0.4708994708994709,0.32978723404255317,0.8165686726570129,0.7341355681419373,0.7731611132621765,0.741622269153595,0.7640023600000004,0.3582089552238806,0.18045112781954886,0.10606060606060606,0.3134328358208956,0.14478210614056955,0.5720930232558139,0.38317757009345793,0.26291079812206575,0.783437967300415,0.7604848146438599,0.7717907428741455,0.762719452381134,0.7720022800000005,0.4140625,0.2047244094488189,0.11111111111111112,0.34375,0.12484093935393258,0.6476683937823834,0.40625,0.2774869109947644,0.7974994778633118,0.7550015449523926,0.7756689190864563,0.7590464353561401,0.7373359600000007,0.2050176429016297,0.0627818802225907,0.0759689712099822,0.4496124031007752,0.2317073170731707,0.2046427175848295,0.0710018335806993,0.0807132984337935,0.4961240310077519,0.1707317073170731,0.1946616252784938,0.0762195269345452,0.0820828637615814,0.4496124031007752,0.1707317073170731
227807,alphatwirl/alphatwirl,alphatwirl_alphatwirl/alphatwirl/datasetloop/loop.py,alphatwirl.datasetloop.loop.DatasetLoop,"class DatasetLoop:

    def __init__(self, datasets, reader):
        self.datasets = datasets
        self.reader = reader

    def __repr__(self):
        name_value_pairs = (
            ('datasets', self.datasets),
            ('reader', self.reader),
        )
        return '{}({})'.format(
            self.__class__.__name__,
            ', '.join(['{}={!r}'.format(n, v) for n, v in name_value_pairs]),
        )

    def __call__(self):
        self.reader.begin()
        for dataset in self.datasets:
            self.reader.read(dataset)
        return self.reader.end()","class DatasetLoop:


    def __init__(self, datasets, reader):
        pass

    def __repr__(self):
        pass

    def __call__(self):
        pass

",4,0,snippet_690,0.75,"class DatasetLoop:
    def __init__(self, datasets, reader):
        """"""
        datasets: iterable of dataset identifiers (e.g., filenames or objects)
        reader: callable taking one dataset identifier and returning an iterable of records
        """"""
        if not hasattr(datasets, ""__iter__""):
            raise TypeError(""datasets must be an iterable"")
        if not callable(reader):
            raise TypeError(""reader must be callable"")
        self.datasets = list(datasets)
        self.reader = reader

    def __repr__(self):
        return (
            f""{self.__class__.__name__}(""
            f""datasets={self.datasets!r}, ""
            f""reader={self.reader!r}""
            f"")""
        )

    def __call__(self):
        for ds in self.datasets:
            for record in self.reader(ds):
                yield record","class DatasetLoop:
    def __init__(self, datasets, reader):
        self.datasets = datasets
        self.reader = reader
        self.current_index = 0

    def __repr__(self):
        return f""DatasetLoop(datasets={self.datasets}, reader={self.reader})""

    def __call__(self):
        if not self.datasets:
            raise StopIteration(""No datasets available"")
        
        dataset = self.datasets[self.current_index]
        result = self.reader(dataset)
        
        self.current_index = (self.current_index + 1) % len(self.datasets)
        
        return result","class DatasetLoop:
    def __init__(self, datasets, reader):
        self.datasets = datasets
        self.reader = reader
        self.current_index = 0

    def __repr__(self):
        return f""DatasetLoop(datasets={self.datasets}, reader={self.reader})""

    def __call__(self):
        while True:
            dataset = self.datasets[self.current_index]
            yield self.reader(dataset)
            self.current_index = (self.current_index + 1) % len(self.datasets)",no_docstr,0.5454545454545455,0.31578947368421056,0.2,0.4285714285714286,0.401161347160911,0.6030150753768844,0.36363636363636365,0.29441624365482233,0.7728216648101807,0.8414609432220459,0.8056820631027222,0.8340532183647156,0.7002613953488377,0.5806451612903226,0.4098360655737705,0.30000000000000004,0.5322580645161291,0.40808543859007507,0.7205882352941176,0.48148148148148145,0.373134328358209,0.8572285175323486,0.841910719871521,0.8495005965232849,0.8434178233146667,0.7650296721311475,0.6086956521739131,0.4424778761061947,0.32432432432432434,0.5565217391304348,0.38236282216389217,0.7768595041322314,0.525,0.4117647058823529,0.8751106858253479,0.8378167152404785,0.8560577630996704,0.8414024710655212,0.7677618852459015,0.2959395930667657,0.143819098260403,0.2661297501971361,0.4126984126984127,0.3611111111111111,0.389581991002681,0.2946881818732714,0.3033223218199919,0.3492063492063492,0.6111111111111112,0.3642920046544631,0.2835529241336388,0.2926627135318326,0.2698412698412698,0.6111111111111112
839884,zeaphoo/reston,zeaphoo_reston/reston/core/apk.py,reston.core.apk.ARSCResTablePackage,"class ARSCResTablePackage(object):

    def __init__(self, buff):
        self.start = buff.get_idx()
        self.id = unpack('<I', buff.read(4))[0]
        self.name = buff.readNullString(256)
        self.typeStrings = unpack('<I', buff.read(4))[0]
        self.lastPublicType = unpack('<I', buff.read(4))[0]
        self.keyStrings = unpack('<I', buff.read(4))[0]
        self.lastPublicKey = unpack('<I', buff.read(4))[0]
        self.mResId = self.id << 24

    def get_name(self):
        name = self.name.decode(""utf-16"", 'replace')
        name = name[:name.find(""\x00"")]
        return name","class ARSCResTablePackage(object):


    def __init__(self, buff):
        pass

    def get_name(self):
        pass

",3,0,snippet_453,0.75,"class ARSCResTablePackage(object):

    def __init__(self, buff):
        # Read header: type (2), headerSize (2), size (4), id (4)
        header_data = buff.read(12)
        self.type, self.header_size, self.size, self.id = struct.unpack('<HHII', header_data)

        # Read package name: 128 UTF-16LE chars
        name_bytes = buff.read(128 * 2)
        self.name = name_bytes.decode('utf-16le').rstrip('\x00')

        # Read string pool offsets: typeStrings, lastPublicType, keyStrings, lastPublicKey
        rest = buff.read(16)
        self.type_strings, self.last_public_type, self.key_strings, self.last_public_key = struct.unpack('<IIII', rest)

    def get_name(self):
        return self.name","class ARSCResTablePackage(object):
    def __init__(self, buff):
        self.header = buff.read(272)
        self.header_size = int.from_bytes(self.header[:2], byteorder='little')
        self.type = int.from_bytes(self.header[2:4], byteorder='little')
        self.package_id = int.from_bytes(self.header[8:12], byteorder='little')
        self.name = self.header[12:268].decode('utf-16le').rstrip('\x00')

    def get_name(self):
        return self.name","class ARSCResTablePackage(object):
    def __init__(self, buff):
        self.buff = buff
        self.header_size = int.from_bytes(buff[0:2], byteorder='little')
        self.type = int.from_bytes(buff[2:4], byteorder='little')
        self.size = int.from_bytes(buff[4:8], byteorder='little')
        self.id = int.from_bytes(buff[8:12], byteorder='little')
        self.name_offset = int.from_bytes(buff[12:16], byteorder='little')
        self.type_strings_offset = int.from_bytes(buff[16:20], byteorder='little')
        self.last_public_type = int.from_bytes(buff[20:24], byteorder='little')
        self.key_strings_offset = int.from_bytes(buff[24:28], byteorder='little')
        self.last_public_key = int.from_bytes(buff[28:32], byteorder='little')
        
    def get_name(self):
        if self.name_offset == 0:
            return """"
        
        name_start = self.name_offset
        name_length = int.from_bytes(self.buff[name_start:name_start+2], byteorder='little')
        
        if name_length == 0:
            return """"
            
        name_data = self.buff[name_start+2:name_start+2+(name_length*2)]
        return name_data.decode('utf-16le', errors='ignore').rstrip('\x00')",no_docstr,0.56,0.20809248554913296,0.08187134502923978,0.33142857142857146,0.37476912057691386,0.6197916666666666,0.3507853403141361,0.24210526315789474,0.8250524997711182,0.8539391160011292,0.8392473459243774,0.8509597182273865,0.7880455978260872,0.43055555555555564,0.2112676056338028,0.1285714285714286,0.3472222222222222,0.28127412530092133,0.7007299270072993,0.375,0.26666666666666666,0.8026794195175171,0.8014113903045654,0.8020449280738831,0.8015380501747131,0.7663066847826093,0.38866396761133604,0.1306122448979592,0.06584362139917695,0.30769230769230765,0.18717635351313014,0.4045584045584046,0.15714285714285714,0.10315186246418338,0.7348217964172363,0.805418848991394,0.768502414226532,0.7977545261383057,0.767215442622951,0.2085724338231523,0.0814763952425524,0.1237111728673941,0.4526315789473684,0.1764705882352941,0.2360477849419676,0.0886718822231063,0.1171291646655074,0.4736842105263157,0.2647058823529412,0.2480569992505188,0.0735928170226917,0.1217311552115819,0.3263157894736842,0.4705882352941176
14450,Azure/azure-cli-extensions,src/appservice-kube/azext_appservice_kube/custom.py,azext_appservice_kube.custom.WebAppClient,"class WebAppClient:
    @classmethod
    def create(cls, cmd, name, resource_group_name, webapp_json):
        management_hostname = cmd.cli_ctx.cloud.endpoints.resource_manager
        api_version = ""2020-12-01""
        sub_id = get_subscription_id(cmd.cli_ctx)

        url_fmt = ""{}/subscriptions/{}/resourceGroups/{}/providers/Microsoft.Web/sites/{}?api-version={}""
        request_url = url_fmt.format(
            management_hostname.strip('/'),
            sub_id,
            resource_group_name,
            name,
            api_version)

        r = send_raw_request(cmd.cli_ctx, ""PUT"", request_url, body=json.dumps(webapp_json))
        return r.json()

    @classmethod
    def restart(cls, cmd, resource_group_name, name, slot=None):
        management_hostname = cmd.cli_ctx.cloud.endpoints.resource_manager
        api_version = ""2020-12-01""
        sub_id = get_subscription_id(cmd.cli_ctx)

        if slot is not None:
            url_fmt = ""{}/subscriptions/{}/resourceGroups/{}/providers/""\
                      ""Microsoft.Web/sites/{}/slots/{}/restart?api-version={}""
            request_url = url_fmt.format(
                management_hostname.strip('/'),
                sub_id,
                resource_group_name,
                name,
                slot,
                api_version)
        else:
            url_fmt = ""{}/subscriptions/{}/resourceGroups/{}/providers/Microsoft.Web/sites/{}/restart?api-version={}""
            request_url = url_fmt.format(
                management_hostname.strip('/'),
                sub_id,
                resource_group_name,
                name,
                api_version)

        send_raw_request(cmd.cli_ctx, ""POST"", request_url)","class WebAppClient:


    @classmethod
    def create(cls, cmd, name, resource_group_name, webapp_json):
        pass

    @classmethod
    def restart(cls, cmd, resource_group_name, name, slot=None):
        pass

",5,0,snippet_71,0.4,"class WebAppClient:

    @classmethod
    def create(cls, cmd, name, resource_group_name, webapp_json):
        client = get_mgmt_service_client(cmd.cli_ctx, WebSiteManagementClient)
        site_envelope = Site(**webapp_json)
        return client.web_apps.create_or_update(resource_group_name, name, site_envelope)

    @classmethod
    def restart(cls, cmd, resource_group_name, name, slot=None):
        client = get_mgmt_service_client(cmd.cli_ctx, WebSiteManagementClient)
        if slot:
            return client.web_apps.restart_slot(resource_group_name, name, slot)
        return client.web_apps.restart(resource_group_name, name)","class WebAppClient:

    @classmethod
    def create(cls, cmd, name, resource_group_name, webapp_json):
        # Implementation for creating a web app
        # This would typically involve calling Azure SDK or REST API
        # to create a web app with the provided parameters
        pass

    @classmethod
    def restart(cls, cmd, resource_group_name, name, slot=None):
        # Implementation for restarting a web app
        # This would typically involve calling Azure SDK or REST API
        # to restart the specified web app, optionally in a specific slot
        pass","class WebAppClient:

    @classmethod
    def create(cls, cmd, name, resource_group_name, webapp_json):
        from azure.cli.command_modules.appservice.custom import create_webapp
        from azure.cli.core.commands import LongRunningOperation
        
        poller = create_webapp(cmd, resource_group_name, name, webapp_json.get('plan'), 
                              webapp_json.get('runtime'), webapp_json.get('startup_file'),
                              webapp_json.get('deployment_container_image_name'),
                              webapp_json.get('deployment_source_url'),
                              webapp_json.get('deployment_source_branch'),
                              webapp_json.get('deployment_local_git'),
                              webapp_json.get('docker_registry_server_password'),
                              webapp_json.get('docker_registry_server_user'),
                              webapp_json.get('multicontainer_config_type'),
                              webapp_json.get('multicontainer_config_file'),
                              webapp_json.get('tags'),
                              webapp_json.get('using_webapp_up'))
        
        return LongRunningOperation(cmd.cli_ctx)(poller)

    @classmethod
    def restart(cls, cmd, resource_group_name, name, slot=None):
        from azure.cli.command_modules.appservice.custom import restart_webapp
        
        return restart_webapp(cmd, resource_group_name, name, slot)",no_docstr,0.41509433962264153,0.2965779467680609,0.22988505747126434,0.3924528301886792,0.11402888760809549,0.8024691358024691,0.5590062111801242,0.4875,0.8480363488197327,0.7137740850448608,0.7751342058181763,0.7252565026283264,0.7742922421524664,0.23754789272030646,0.16988416988416988,0.1556420233463035,0.22222222222222224,0.022234592493314737,0.46788990825688076,0.42592592592592593,0.411214953271028,0.7492781281471252,0.667540431022644,0.7060514688491821,0.6749027967453003,0.7100178475336324,0.31419939577039274,0.1945288753799392,0.15902140672782875,0.2537764350453172,0.2176684641373333,0.6283783783783784,0.28135593220338984,0.22789115646258504,0.7910276651382446,0.7186970114707947,0.7531297206878662,0.7253293395042419,0.7414076681614359,0.2087669773466016,0.1153567854661219,0.180831525258077,0.2019230769230769,0.3369565217391304,0.1211284165220078,0.1529988551497849,0.163872670470019,0.048076923076923,0.1195652173913043,0.2980726807503372,0.1493882215999417,0.1812804278228118,0.3942307692307692,0.4673913043478261
236908,aouyar/healthgraph-api,aouyar_healthgraph-api/healthgraph/resources.py,healthgraph.resources.PropResourceLink,"class PropResourceLink(object):
    
    def __init__(self, clsname):
        self._clsname = clsname
    
    def __call__(self, resource=None):
        return ResourceLink(self._clsname, resource)","class PropResourceLink(object):


    def __init__(self, clsname):
        pass

    def __call__(self, resource=None):
        pass

",3,0,snippet_725,1.0,"class PropResourceLink(object):
    def __init__(self, clsname):
        self.clsname = clsname

    def __call__(self, resource=None):
        base = f""/{self.clsname}""
        if resource is None:
            return base
        try:
            rid = resource.id
        except AttributeError:
            raise AttributeError(f""Resource passed to {self.clsname} link has no 'id' attribute"")
        return f""{base}/{rid}""","class PropResourceLink(object):

    def __init__(self, clsname):
        self.clsname = clsname

    def __call__(self, resource=None):
        if resource is None:
            return self
        return resource","class PropResourceLink(object):
    def __init__(self, clsname):
        self.clsname = clsname

    def __call__(self, resource=None):
        def decorator(func):
            func._prop_resource_link = {
                'clsname': self.clsname,
                'resource': resource
            }
            return func
        return decorator",no_docstr,0.5588235294117647,0.48484848484848486,0.40625,0.5294117647058825,0.40355507967406185,0.4639175257731959,0.3958333333333333,0.35789473684210527,0.7940057516098022,0.9342638254165649,0.8584434390068054,0.9180469512939453,0.8051967532467532,0.8372093023255814,0.7317073170731707,0.6666666666666666,0.8372093023255814,0.7749072593032009,0.8723404255319149,0.8043478260869565,0.7555555555555555,0.9407387375831604,0.9592364430427551,0.9498975872993469,0.9573540687561035,0.9047628571428571,0.7450980392156863,0.653061224489796,0.5957446808510638,0.7058823529411764,0.5959626420652322,0.7058823529411765,0.582089552238806,0.5151515151515151,0.8765914440155029,0.936016321182251,0.9053297638893127,0.9297137260437012,0.854546909090909,0.4261735071246832,0.1858166011782272,0.5633218717649503,0.5555555555555556,0.4,0.5017624731832625,0.388172465412544,0.5633218717649503,0.5555555555555556,0.5,0.5019194977678482,0.2888005637508866,0.5633218717649503,0.5555555555555556,0.6
595580,neon-jungle/wagtailnews,neon-jungle_wagtailnews/wagtailnews/views/chooser.py,wagtailnews.views.chooser.BaseNewsItemChooserMixin,"class BaseNewsItemChooserMixin:
    def get_filter_form_class(self):
        filter_class = super().get_filter_form_class()

        allowed_news_types = get_allowed_news_types(self.request.user)

        allowed_cts = ContentType.objects.get_for_models(*allowed_news_types).values()
        self.newsindex_list = Page.objects.filter(
            content_type__in=allowed_cts
        ).specific()
        newsindex_count = self.newsindex_list.count()
        if newsindex_count > 1:
            return type(
                ""FilterForm"",
                (IndexFilterMixin, filter_class),
                {},
            )
        return filter_class

    def get_filter_form(self):
        FilterForm = self.get_filter_form_class()
        if self.newsindex_list.count() > 1:
            return FilterForm(self.request.GET, indexes=self.newsindex_list)
        return FilterForm(self.request.GET)

    @property
    def columns(self):
        columns = [self.title_column]
        columns += [Column(""status"", label=_(""Status""), accessor=""status_button"")]
        return columns","class BaseNewsItemChooserMixin:


    def get_filter_form_class(self):
        pass

    def get_filter_form_class(self):
        pass

    @property
    def columns(self):
        pass

",5,0,snippet_534,0.2857142857142857,"class BaseNewsItemChooserMixin:
    filterset_class = None

    def get_filterset_class(self):
        return self.filterset_class

    def get_filter_form_class(self):
        filterset_class = self.get_filterset_class()
        if not filterset_class:
            return None
        # django-filter 2.0
        form_cls = getattr(filterset_class, ""form"", None)
        if form_cls is not None:
            return form_cls
        # older django-filter
        return filterset_class.get_form_class()

    @property
    def columns(self):
        default = [
            (""title"", ""Title""),
            (""pub_date"", ""Publication Date""),
            (""author__username"", ""Author""),
        ]
        return getattr(self, ""chooser_columns"", default)","class BaseNewsItemChooserMixin:

    def get_filter_form_class(self):
        raise NotImplementedError(""Subclasses must implement get_filter_form_class method"")

    def get_filter_form_class(self):
        raise NotImplementedError(""Subclasses must implement get_filter_form_class method"")

    @property
    def columns(self):
        raise NotImplementedError(""Subclasses must implement columns property"")","class BaseNewsItemChooserMixin:
    
    def get_filter_form_class(self):
        from wagtail.admin.forms import WagtailAdminPageForm
        
        class NewsItemFilterForm(WagtailAdminPageForm):
            q = forms.CharField(
                label=_(""Search""),
                widget=forms.TextInput(attrs={'placeholder': _(""Search news items"")}),
                required=False
            )
            
        return NewsItemFilterForm

    @property
    def columns(self):
        return [
            {
                'name': 'title',
                'label': _('Title'),
                'sort_key': 'title',
            },
            {
                'name': 'date',
                'label': _('Date'),
                'sort_key': 'date',
            },
            {
                'name': 'status',
                'label': _('Status'),
                'sort_key': 'live',
            },
        ]",no_docstr,0.39593908629441626,0.15384615384615383,0.07253886010362694,0.3045685279187817,0.22519347472433215,0.6727272727272727,0.4024390243902439,0.22699386503067484,0.7784801721572876,0.7493897676467896,0.7636579871177673,0.7522006034851074,0.7445677717391311,0.33540372670807456,0.23899371069182387,0.17834394904458598,0.32298136645962733,0.06826259975989879,0.7777777777777778,0.625,0.4810126582278481,0.7512644529342651,0.6934337615966797,0.7211917042732239,0.6988130807876587,0.7373214673913043,0.22727272727272724,0.13793103448275862,0.10465116279069767,0.21590909090909088,0.1302232511535448,0.5555555555555556,0.2517482517482518,0.16901408450704225,0.7655312418937683,0.7516492009162903,0.7585267424583435,0.7530146837234497,0.6775394565217392,0.1463804986318783,0.0278947041282197,0.0328809984398867,0.2952380952380952,0.2295081967213114,0.0740402327786312,0.0379814905216027,0.0645806896171221,0.0952380952380952,0.0983606557377049,0.1561710177430953,0.0624906502697444,0.0713269101639951,0.2285714285714285,0.2622950819672131
646812,ployground/ploy,ployground_ploy/ploy/common.py,ploy.common.InstanceHooks,"class InstanceHooks(object):
    def __init__(self, instance):
        self.instance = instance

    def _iter_funcs(self, func_name):
        hooks = []
        for plugin in self.instance.master.ctrl.plugins.values():
            if 'get_hooks' not in plugin:
                continue
            hooks.extend(plugin['get_hooks']())
        if 'hooks' in self.instance.config:
            hooks.extend(self.instance.config['hooks'].hooks)
        for hook in hooks:
            func = getattr(hook, func_name, None)
            if func is not None:
                yield func

    def __getattr__(self, name):
        return lambda *args, **kwargs: [
            func(*args, **kwargs)
            for func in self._iter_funcs(name)]","class InstanceHooks(object):


    def __init__(self, instance):
        pass

    def _iter_funcs(self, func_name):
        pass

    def __getattr__(self, name):
        pass

",4,0,snippet_415,0.2941176470588235,"class InstanceHooks(object):
    def __init__(self, instance):
        self._instance = instance

    def _iter_funcs(self, func_name):
        inst = self._instance
        hook = getattr(inst, func_name, None)
        if hook is None:
            return
        if callable(hook):
            yield hook
        elif isinstance(hook, (list, tuple)):
            for fn in hook:
                if callable(fn):
                    yield fn

    def __getattr__(self, name):
        inst = self._instance
        attr = getattr(inst, name)
        if callable(attr):
            def wrapped(*args, **kwargs):
                for fn in self._iter_funcs(f'before_{name}'):
                    fn(*args, **kwargs)
                result = attr(*args, **kwargs)
                for fn in self._iter_funcs(f'after_{name}'):
                    fn(*args, **kwargs)
                return result
            return wrapped
        return attr","class InstanceHooks(object):
    def __init__(self, instance):
        self.instance = instance

    def _iter_funcs(self, func_name):
        if hasattr(self.instance, '_hooks') and func_name in self.instance._hooks:
            for func in self.instance._hooks[func_name]:
                yield func

    def __getattr__(self, name):
        def hook_wrapper(*args, **kwargs):
            results = []
            for func in self._iter_funcs(name):
                result = func(*args, **kwargs)
                results.append(result)
            return results
        return hook_wrapper","class InstanceHooks(object):

    def __init__(self, instance):
        self.instance = instance

    def _iter_funcs(self, func_name):
        for cls in type(self.instance).__mro__:
            if hasattr(cls, func_name):
                yield getattr(cls, func_name)

    def __getattr__(self, name):
        def hook_caller(*args, **kwargs):
            results = []
            for func in self._iter_funcs(name):
                result = func(self.instance, *args, **kwargs)
                results.append(result)
            return results
        return hook_caller",no_docstr,0.5561497326203209,0.3243243243243243,0.22950819672131145,0.4385026737967914,0.436656222961577,0.583732057416268,0.42788461538461536,0.3333333333333333,0.856447696685791,0.8606109619140625,0.8585243225097656,0.8601928353309631,0.7352967647058827,0.7058823529411764,0.4900662251655629,0.348993288590604,0.5620915032679739,0.5604218871785532,0.8732394366197183,0.6737588652482269,0.5785714285714286,0.8928912878036499,0.8546687364578247,0.8733620047569275,0.8583431839942932,0.7800475510204081,0.6266666666666666,0.3918918918918919,0.28767123287671237,0.5066666666666667,0.5118975197581237,0.8368794326241135,0.6142857142857143,0.5179856115107914,0.8634283542633057,0.8393166661262512,0.8512017726898193,0.8416670560836792,0.7596395918367348,0.3378367977057828,0.1422857810174419,0.1928577061019855,0.3703703703703703,0.6458333333333334,0.394196759653172,0.278677093278234,0.2911655008900097,0.4444444444444444,0.5625,0.3402603244441691,0.2334935612130136,0.2479181069340331,0.2962962962962963,0.5833333333333334
277787,buildbot/buildbot,master/buildbot/revlinks.py,buildbot.revlinks.RevlinkMultiplexer,"class RevlinkMultiplexer:
    def __init__(self, *revlinks):
        self.revlinks = revlinks

    def __call__(self, rev, repo):
        for revlink in self.revlinks:
            url = revlink(rev, repo)
            if url:
                return url
        return None","class RevlinkMultiplexer:


    def __init__(self, *revlinks):
        pass

    def __call__(self, rev, repo):
        pass

",3,0,snippet_214,0.8571428571428571,"class RevlinkMultiplexer:
    def __init__(self, *revlinks):
        self.revlinks = revlinks

    def __call__(self, rev, repo):
        outputs = []
        for rl in self.revlinks:
            result = rl(rev, repo)
            if result:
                outputs.append(result)
        if not outputs:
            return ''
        if len(outputs) == 1:
            return outputs[0]
        return '\n'.join(outputs)","class RevlinkMultiplexer:
    def __init__(self, *revlinks):
        self.revlinks = revlinks

    def __call__(self, rev, repo):
        for revlink in self.revlinks:
            try:
                result = revlink(rev, repo)
                if result:
                    return result
            except Exception:
                continue
        return None","class RevlinkMultiplexer:
    def __init__(self, *revlinks):
        self.revlinks = revlinks

    def __call__(self, rev, repo):
        for revlink in self.revlinks:
            result = revlink(rev, repo)
            if result:
                return result
        return None",no_docstr,0.6301369863013699,0.4788732394366197,0.40579710144927533,0.6301369863013699,0.4976177332885738,0.5591397849462365,0.4891304347826087,0.45054945054945056,0.8302603363990784,0.9276919364929199,0.8762761950492859,0.9169317483901978,0.8393590361445783,0.8387096774193549,0.7333333333333334,0.6551724137931035,0.8387096774193549,0.8079283298764401,0.859375,0.8095238095238095,0.7580645161290323,0.9362479448318481,0.9660007357597351,0.9508916735649109,0.9629406332969666,0.9607847058823529,0.896551724137931,0.7857142857142857,0.7037037037037037,0.896551724137931,0.8929900415777975,0.9482758620689655,0.8947368421052632,0.8392857142857143,0.9758991003036499,0.9759476184844971,0.9759232997894287,0.975942850112915,1.0,0.5501305635147654,0.3299634662767009,0.516392121115694,0.5416666666666666,0.8125,0.776786363796051,0.621115120365111,0.736030334819093,0.75,1.0,0.8646872433982536,0.7227186387739215,0.736030334819093,1.0,1.0
322220,cyrus-/cypy,cyrus-_cypy/cypy/__init__.py,cypy._new_initializer,"class _new_initializer(object):
    def __init__(self, cls):
        self.__cls = cls

    def __call__(self, *args, **kwargs):
        return self.__cls(*args, **kwargs)

    def __str__(self):
        return ""<new %s>"" % self.__cls

    def __repr__(self):
        return str(self)","class _new_initializer(object):


    def __init__(self, cls):
        pass

    def __call__(self, *args, **kwargs):
        pass

    def __str__(self):
        pass

    def __repr__(self):
        pass

",5,0,snippet_186,1.0,"class _new_initializer(object):
    def __init__(self, cls):
        self._cls = cls

    def __call__(self, *args, **kwargs):
        return self._cls(*args, **kwargs)

    def __str__(self):
        return f""<new initializer for {self._cls.__name__}>""

    def __repr__(self):
        return f""{self.__class__.__name__}({self._cls!r})""","class _new_initializer(object):
    def __init__(self, cls):
        self.cls = cls

    def __call__(self, *args, **kwargs):
        return self.cls(*args, **kwargs)

    def __str__(self):
        return f""_new_initializer({self.cls.__name__})""

    def __repr__(self):
        return f""_new_initializer({self.cls!r})""","class _new_initializer(object):
    def __init__(self, cls):
        self.cls = cls

    def __call__(self, *args, **kwargs):
        instance = self.cls.__new__(self.cls)
        if isinstance(instance, self.cls):
            instance.__init__(*args, **kwargs)
        return instance

    def __str__(self):
        return f""<_new_initializer for {self.cls.__name__}>""

    def __repr__(self):
        return f""_new_initializer({self.cls!r})""",no_docstr,0.8461538461538461,0.7368421052631577,0.6756756756756757,0.8461538461538461,0.6831172273446949,0.7421875,0.6850393700787402,0.626984126984127,0.9428402185440063,0.9738377332687378,0.9580883383750916,0.9706464409828186,0.9035097368421053,0.868421052631579,0.7567567567567567,0.6944444444444444,0.868421052631579,0.7093787817873622,0.8157894736842105,0.6902654867256637,0.6339285714285714,0.9524416327476501,0.9707662463188171,0.9615166783332825,0.968902051448822,0.9190484285714285,0.7415730337078652,0.5747126436781609,0.4470588235294118,0.7191011235955056,0.5507252832360195,0.6506849315068494,0.5517241379310345,0.4652777777777778,0.8908247947692871,0.9403786659240723,0.9149312376976013,0.9351766109466553,0.8510653191489362,0.6194274531754489,0.4973026662812633,0.5208483228911205,0.6470588235294118,0.8125,0.5726143174161239,0.4975501232439633,0.5208483228911205,0.6470588235294118,0.625,0.5212734541629946,0.3368756616854967,0.4393946255547172,0.5588235294117647,0.75
294453,cloud-custodian/cloud-custodian,tools/c7n_left/c7n_left/core.py,core.CollectionRunner,"class CollectionRunner:
    def __init__(self, policies, options, reporter):
        self.policies = policies
        self.options = options
        self.reporter = reporter
        self.provider = None

    def run(self) -> bool:
        # return value is used to signal process exit code.
        event = self.get_event()
        provider = self.get_provider()

        if not provider.match_dir(self.options.source_dir):
            log.warning(""no %s source files found"" % provider.type)
            return True

        graph = self.provider.parse(
            self.options.source_dir,
            self.options.var_files,
            self.options.terraform_workspace,
        )

        for p in self.policies:
            p.expand_variables(p.get_variables())
            p.validate()

        self.reporter.on_execution_started(self.policies, graph)
        # consider inverting this order to allow for results grouped by policy
        # at the moment, we're doing results grouped by resource.
        found = False
        for rtype, resources in graph.get_resources_by_type():
            if self.options.exec_filter:
                resources = self.options.exec_filter.filter_resources(rtype, resources)
            if not resources:
                continue
            for p in self.policies:
                if not self.match_type(rtype, p):
                    continue
                result_set = []
                try:
                    result_set = self.run_policy(p, graph, resources, event, rtype)
                except Exception as e:
                    found = True
                    self.reporter.on_policy_error(e, p, rtype, resources)
                if result_set:
                    self.reporter.on_results(p, result_set)
                if result_set and (
                    not self.options.warn_filter
                    or not self.options.warn_filter.filter_policies((p,))
                ):
                    found = True
        self.reporter.on_execution_ended()
        return found

    def run_policy(self, policy, graph, resources, event, resource_type):
        event = dict(event)
        event.update({""graph"": graph, ""resources"": resources, ""resource_type"": resource_type})
        self.reporter.on_policy_start(policy, event)
        return policy.push(event)

    def get_provider(self):
        provider_name = {p.provider_name for p in self.policies}.pop()
        self.provider = clouds[provider_name]()
        self.provider.initialize(self.options)
        return self.provider

    def get_event(self):
        return {""config"": self.options, ""env"": dict(os.environ)}

    @staticmethod
    def match_type(rtype, p):
        if isinstance(p.resource_type, str):
            return fnmatch.fnmatch(rtype, p.resource_type.split(""."", 1)[-1])
        found = False
        if isinstance(p.resource_type, list):
            for pr in p.resource_type:
                if fnmatch.fnmatch(rtype, pr.split(""."", 1)[-1]):
                    found = True
                    break
        return found","class CollectionRunner:


    def __init__(self, policies, options, reporter):
        pass

    def run(self) -> bool:
        pass

    def run_policy(self, policy, graph, resources, event, resource_type):
        pass

    def get_provider(self):
        pass

    def get_event(self):
        pass

    @staticmethod
    def match_type(rtype, p):
        pass

",8,0,snippet_185,0.2,"class CollectionRunner:

    def __init__(self, policies, options, reporter):
        self.policies = policies
        self.options = options
        self.reporter = reporter

    def run(self) -> bool:
        success = True
        provider = self.get_provider()
        event = self.get_event()
        for policy in self.policies:
            if not self.match_type(getattr(self.options, 'resource_type', None), policy):
                continue
            graph = None
            if hasattr(policy, 'get_graph'):
                graph = policy.get_graph(provider, event)
            resources = []
            if hasattr(policy, 'get_resources'):
                resources = policy.get_resources(provider, event)
            result = self.run_policy(policy, graph, resources, event, getattr(policy, 'resource_type', None))
            success = success and result
        return success

    def run_policy(self, policy, graph, resources, event, resource_type):
        try:
            if hasattr(self.reporter, 'on_start'):
                self.reporter.on_start(policy, event, resource_type)
            result = policy.run(graph, resources, event)
            if hasattr(self.reporter, 'on_complete'):
                self.reporter.on_complete(policy, result)
            return bool(result)
        except Exception as e:
            if hasattr(self.reporter, 'on_error'):
                self.reporter.on_error(policy, e)
            return False

    def get_provider(self):
        return getattr(self.options, 'provider', None)

    def get_event(self):
        return getattr(self.options, 'event', None)

    @staticmethod
    def match_type(rtype, p):
        if not rtype:
            return True
        rt = getattr(p, 'resource_type', None)
        if isinstance(rtype, str):
            return rt == rtype
        try:
            return any(rt == r for r in rtype)
        except TypeError:
            return False","class CollectionRunner:
    def __init__(self, policies, options, reporter):
        self.policies = policies
        self.options = options
        self.reporter = reporter
        self.provider = None
        self.event = None

    def run(self) -> bool:
        try:
            self.provider = self.get_provider()
            self.event = self.get_event()
            
            for policy in self.policies:
                resource_type = policy.get_resource_type()
                resources = self.provider.get_resources(resource_type)
                graph = self.provider.get_resource_graph(resource_type)
                
                self.run_policy(policy, graph, resources, self.event, resource_type)
            
            return True
        except Exception as e:
            if self.reporter:
                self.reporter.report_error(e)
            return False

    def run_policy(self, policy, graph, resources, event, resource_type):
        if self.match_type(resource_type, policy):
            policy.evaluate(resources, graph, event)
            if self.reporter:
                self.reporter.report_policy_result(policy, resources)

    def get_provider(self):
        # Assuming there's a provider factory or registry
        from .provider import ProviderFactory
        return ProviderFactory.get_provider(self.options)

    def get_event(self):
        # Assuming there's an event factory or context
        from .event import EventFactory
        return EventFactory.create_event(self.options)

    @staticmethod
    def match_type(rtype, p):
        policy_type = p.get_resource_type()
        return rtype == policy_type or policy_type == '*' or rtype in policy_type","class CollectionRunner:
    def __init__(self, policies, options, reporter):
        self.policies = policies
        self.options = options
        self.reporter = reporter
        self.provider = None
        self.event = None

    def run(self) -> bool:
        try:
            self.provider = self.get_provider()
            self.event = self.get_event()
            
            graph = {}
            resources = []
            
            for policy in self.policies:
                resource_type = policy.get('resource', '')
                if self.match_type(resource_type, policy):
                    self.run_policy(policy, graph, resources, self.event, resource_type)
            
            return True
        except Exception as e:
            if self.reporter:
                self.reporter.report_error(str(e))
            return False

    def run_policy(self, policy, graph, resources, event, resource_type):
        if not policy:
            return
        
        policy_name = policy.get('name', 'unnamed')
        
        try:
            # Execute policy logic here
            filters = policy.get('filters', [])
            actions = policy.get('actions', [])
            
            filtered_resources = []
            for resource in resources:
                if self._apply_filters(resource, filters):
                    filtered_resources.append(resource)
            
            for resource in filtered_resources:
                self._apply_actions(resource, actions)
                
        except Exception as e:
            if self.reporter:
                self.reporter.report_policy_error(policy_name, str(e))

    def get_provider(self):
        if hasattr(self.options, 'provider'):
            return self.options.provider
        return 'aws'

    def get_event(self):
        if hasattr(self.options, 'event'):
            return self.options.event
        return {}

    @staticmethod
    def match_type(rtype, p):
        if not rtype or not p:
            return False
        
        policy_resource = p.get('resource', '')
        if not policy_resource:
            return False
            
        return rtype == policy_resource or policy_resource == '*'

    def _apply_filters(self, resource, filters):
        for filter_config in filters:
            if not self._evaluate_filter(resource, filter_config):
                return False
        return True

    def _apply_actions(self, resource, actions):
        for action_config in actions:
            self._execute_action(resource, action_config)

    def _evaluate_filter(self, resource, filter_config):
        return True

    def _execute_action(self, resource, action_config):
        pass",no_docstr,0.5968028419182948,0.3315508021390374,0.20393559928443647,0.3658969804618117,0.30274482817497306,0.8514851485148515,0.5682382133995038,0.4154228855721393,0.8901935815811157,0.8309191465377808,0.8595356941223145,0.8364889025688171,0.769629073359073,0.5565862708719851,0.32029795158286783,0.1981308411214953,0.3970315398886827,0.2591194695335268,0.8786127167630058,0.6550724637681159,0.5058139534883721,0.8885204792022705,0.8112370371818542,0.8481217622756958,0.8183550238609314,0.7741335328185331,0.5814696485623003,0.2884615384615385,0.1639871382636656,0.3514376996805112,0.3770606242213219,0.7969639468690702,0.4695817490494297,0.3238095238095238,0.8738030195236206,0.8219857215881348,0.847102701663971,0.8268892765045166,0.7541852123552124,0.312023781930925,0.1763547162169277,0.203325412656991,0.4927536231884058,0.3756613756613756,0.2791460979945666,0.1453588957253824,0.1816579784244966,0.4456521739130434,0.3439153439153439,0.3224443701710489,0.1967047878105093,0.2174688281393868,0.4311594202898551,0.4444444444444444
109638,CoffeeForThinkers/MagentoModels,CoffeeForThinkers_MagentoModels/mm/routines/__init__.py,mm.routines._BlobArgumentWrapper,"class _BlobArgumentWrapper(object):
    def __init__(self, data):
        self.__data = data
        self.__encoded = None

    @property
    def encoded(self):
        if self.__encoded is None:
            self.__encoded = self.__data.encode('hex')

        return ('0x' + self.__encoded) if self.__encoded != '' else ""''""","class _BlobArgumentWrapper(object):


    def __init__(self, data):
        pass

    @property
    def encoded(self):
        pass

",4,0,snippet_180,0.4285714285714285,"class _BlobArgumentWrapper(object):
    def __init__(self, data):
        if isinstance(data, str):
            data = data.encode('utf-8')
        elif not isinstance(data, (bytes, bytearray)):
            raise TypeError('data must be bytes or str')
        self._data = data

    @property
    def encoded(self):
        return base64.b64encode(self._data).decode('ascii')","class _BlobArgumentWrapper(object):
    def __init__(self, data):
        self._data = data

    @property
    def encoded(self):
        return self._data","class _BlobArgumentWrapper(object):

    def __init__(self, data):
        self.data = data

    @property
    def encoded(self):
        if isinstance(self.data, str):
            return self.data.encode('utf-8')
        elif isinstance(self.data, bytes):
            return self.data
        else:
            return str(self.data).encode('utf-8')",no_docstr,0.47500000000000003,0.3333333333333333,0.21052631578947367,0.39999999999999997,0.4370735495992172,0.5681818181818182,0.4367816091954023,0.36046511627906974,0.8116711378097534,0.8596550226211548,0.8349742889404297,0.8546028137207031,0.72500275,0.6415094339622641,0.5098039215686275,0.40816326530612246,0.6037735849056604,0.23706407725367865,1.0,0.9210526315789473,0.8108108108108109,0.9346472024917603,0.7979278564453125,0.8608932495117188,0.8097730875015259,0.7965388311688312,0.6233766233766234,0.39999999999999997,0.3287671232876712,0.5714285714285715,0.44696306693747856,0.6875,0.4936708860759494,0.38461538461538464,0.8757272958755493,0.8681193590164185,0.8719067573547363,0.8688741326332092,0.8181836363636363,0.2336610502961652,0.1762069769448681,0.1834372242397928,0.425,0.15,0.2396159432680207,0.1090021429349592,0.1744616301371234,0.325,0.35,0.3250034765783927,0.2047746233610896,0.220239282952481,0.475,0.4
820557,vinci1it2000/schedula,vinci1it2000_schedula/schedula/utils/form/server/gdpr.py,schedula.utils.form.server.gdpr.GDPR,"class GDPR:
    def __init__(self, app, sitemap, *args, **kwargs):
        if app is not None:
            self.init_app(app, sitemap, *args, **kwargs)

    def init_app(self, app, sitemap, *args, **kwargs):
        app.extensions = getattr(app, 'extensions', {})
        app.register_blueprint(bp, url_prefix='/gdpr')
        app.extensions['schedula_gdpr'] = self
        if 'schedula_admin' in app.extensions:
            admin = app.extensions['schedula_admin']
            for v in (Consent,):
                admin.add_model(v, category=""GDPR"")","class GDPR:


    def __init__(self, app, sitemap, *args, **kwargs):
        pass

    def init_app(self, app, sitemap, *args, **kwargs):
        pass

",3,0,snippet_314,0.5,"class GDPR:

    def __init__(self, app=None, sitemap=None, *args, **kwargs):
        self.app = None
        self.sitemap = None
        if app is not None:
            self.init_app(app, sitemap, *args, **kwargs)

    def init_app(self, app, sitemap, *args, **kwargs):
        self.app = app
        self.sitemap = sitemap
        if not hasattr(app, 'extensions'):
            app.extensions = {}
        app.extensions['gdpr'] = self
        return self","class GDPR:

    def __init__(self, app, sitemap, *args, **kwargs):
        self.app = app
        self.sitemap = sitemap
        self.args = args
        self.kwargs = kwargs
        if app is not None:
            self.init_app(app, sitemap, *args, **kwargs)

    def init_app(self, app, sitemap, *args, **kwargs):
        self.app = app
        self.sitemap = sitemap
        self.args = args
        self.kwargs = kwargs
        
        # Store reference to self in app for easy access
        if not hasattr(app, 'extensions'):
            app.extensions = {}
        if 'gdpr' in app.extensions:
            raise RuntimeError(""Flask application already initialized for GDPR"")
        app.extensions['gdpr'] = self","class GDPR:
    def __init__(self, app=None, sitemap=None, *args, **kwargs):
        self.app = app
        self.sitemap = sitemap
        self.config = {}
        self.consent_types = ['necessary', 'analytics', 'marketing', 'preferences']
        self.cookie_banner_template = None
        self.privacy_policy_url = None
        self.cookie_policy_url = None
        self.consent_storage_key = 'gdpr_consent'
        
        if app is not None:
            self.init_app(app, sitemap, *args, **kwargs)

    def init_app(self, app, sitemap=None, *args, **kwargs):
        self.app = app
        if sitemap is not None:
            self.sitemap = sitemap
            
        # Set default configuration
        app.config.setdefault('GDPR_COOKIE_BANNER_ENABLED', True)
        app.config.setdefault('GDPR_CONSENT_REQUIRED', True)
        app.config.setdefault('GDPR_COOKIE_DOMAIN', None)
        app.config.setdefault('GDPR_COOKIE_SECURE', False)
        app.config.setdefault('GDPR_COOKIE_HTTPONLY', True)
        app.config.setdefault('GDPR_COOKIE_SAMESITE', 'Lax')
        app.config.setdefault('GDPR_CONSENT_EXPIRY_DAYS', 365)
        
        # Store configuration
        self.config.update(app.config)
        
        # Register template globals
        app.jinja_env.globals['gdpr'] = self
        
        # Register routes
        self._register_routes(app)
        
        # Add to app extensions
        if not hasattr(app, 'extensions'):
            app.extensions = {}
        app.extensions['gdpr'] = self

    def _register_routes(self, app):
        @app.route('/gdpr/consent', methods=['POST'])
        def set_consent():
            from flask import request, jsonify, make_response
            consent_data = request.get_json()
            response = make_response(jsonify({'status': 'success'}))
            
            cookie_options = {
                'max_age': self.config.get('GDPR_CONSENT_EXPIRY_DAYS', 365) * 24 * 60 * 60,
                'secure': self.config.get('GDPR_COOKIE_SECURE', False),
                'httponly': self.config.get('GDPR_COOKIE_HTTPONLY', True),
                'samesite': self.config.get('GDPR_COOKIE_SAMESITE', 'Lax')
            }
            
            if self.config.get('GDPR_COOKIE_DOMAIN'):
                cookie_options['domain'] = self.config['GDPR_COOKIE_DOMAIN']
            
            import json
            response.set_cookie(self.consent_storage_key, json.dumps(consent_data), **cookie_options)
            return response
        
        @app.route('/gdpr/consent', methods=['GET'])
        def get_consent():
            from flask import request, jsonify
            import json
            consent_cookie = request.cookies.get(self.consent_storage_key)
            if consent_cookie:
                try:
                    consent_data = json.loads(consent_cookie)
                    return jsonify(consent_data)
                except json.JSONDecodeError:
                    pass
            return jsonify({})

    def has_consent(self, consent_type='necessary'):
        from flask import request
        import json
        consent_cookie = request.cookies.get(self.consent_storage_key)
        if consent_cookie:
            try:
                consent_data = json.loads(consent_cookie)
                return consent_data.get(consent_type, False)
            except json.JSONDecodeError:
                pass
        return consent_type == 'necessary'

    def require_consent(self, consent_type):
        def decorator(f):
            from functools import wraps
            @wraps(f)
            def decorated_function(*args, **kwargs):
                if not self.has_consent(consent_type):
                    from flask import abort
                    abort(403)
                return f(*args, **kwargs)
            return decorated_function
        return decorator

    def get_consent_banner_html(self):
        if self.cookie_banner_template:
            from flask import render_template
            return render_template(self.cookie_banner_template, gdpr=self)
        return self._default_banner_html()

    def _default_banner_html(self):
        return '''
        <div id=""gdpr-banner"" style=""position: fixed; bottom: 0; left: 0; right: 0; background: #333; color: white; padding: 20px; z-index: 9999;"">
            <p>This website uses cookies to ensure you get the best experience. 
            <a href=""#"" onclick=""acceptAllCookies()"">Accept All</a> | 
            <a href=""#"" onclick=""showCookieSettings()"">Cookie Settings</a></p>
        </div>
        <script>
        function acceptAllCookies() {
            fetch('/gdpr/consent', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({necessary: true, analytics: true, marketing: true, preferences: true})
            }).then(() => document.getElementById('gdpr-banner').style.display = 'none');
        }
        </script>
        '''",no_docstr,0.6666666666666667,0.4958677685950413,0.38655462184873957,0.6178861788617885,0.5321501266191314,0.8362068965517241,0.6782608695652174,0.5964912280701754,0.9113951325416565,0.8517012596130371,0.8805376291275024,0.8573163747787476,0.811113,0.6143790849673202,0.47682119205298007,0.38926174496644295,0.5359477124183006,0.5664305003628505,0.6729559748427673,0.5506329113924051,0.49044585987261147,0.8583044409751892,0.8405209183692932,0.8493196368217468,0.8422660231590271,0.8043497826086956,0.16188870151770657,0.10829103214890017,0.07470288624787776,0.14502529510961215,0.08592377566674084,0.11581920903954802,0.08294062205466542,0.0660377358490566,0.681086540222168,0.8581407070159912,0.7594305276870728,0.8363978266716003,0.7109012038303717,0.4442786061846297,0.3960288939214141,0.4137126494611726,0.5423728813559322,0.425,0.4638992136693172,0.294013234652382,0.5272615861265818,0.559322033898305,0.475,0.4790188684897407,0.0475000634983849,0.3601008341893915,0.5084745762711864,0.0
529366,katerina7479/pypdflite,katerina7479_pypdflite/pypdflite/pdfobjects/pdfhtml.py,pypdflite.pdfobjects.pdfhtml.PDFHtml,"class PDFHtml(object):
    def __init__(self, parent, session, htmltext, formats=None, context=None):
        self.document = parent
        self.session = session
        self.htmltext = str(htmltext)
        self.context = {}
        if isinstance(context, dict):
            self.context = context
        self.formats = {}
        if isinstance(formats, dict):
            self.formats = formats
        self._parsehtml()
        self._runlist(self.commandlist)

    def _parsehtml(self):
        parser = PDFHTMLParser()
        parser.feed(self.htmltext)
        self.commandlist = parser.get_commandlist()

    def _runlist(self, mylist):
        for item in mylist:
            item.set_dependancies(self.session, self.document, self.formats, self.context)
            item.output()","class PDFHtml(object):


    def __init__(self, parent, session, htmltext, formats=None, context=None):
        pass

    def _parsehtml(self):
        pass

    def _runlist(self, mylist):
        pass

",4,0,snippet_702,0.7777777777777778,"class PDFHtml(object):

    def __init__(self, parent, session, htmltext, formats=None, context=None):
        self.parent = parent
        self.session = session
        self.htmltext = htmltext or ''
        self.formats = formats or {}
        self.context = context or {}

    def _parsehtml(self):
        class _Parser(HTMLParser):
            def __init__(self):
                super().__init__()
                self.commands = []

            def handle_starttag(self, tag, attrs):
                self.commands.append(('start', tag, dict(attrs)))

            def handle_endtag(self, tag):
                self.commands.append(('end', tag))

            def handle_data(self, data):
                if data:
                    self.commands.append(('data', data))

        p = _Parser()
        p.feed(self.htmltext)
        return p.commands

    def _runlist(self, mylist):
        c = self.parent
        lh = self.formats.get('line_height', 10)
        psp = self.formats.get('p_spacing', lh)
        for cmd in mylist:
            kind = cmd[0]
            if kind == 'start':
                tag, attrs = cmd[1], cmd[2]
                if tag in ('b', 'strong'):
                    c.set_font(style='B')
                elif tag in ('i', 'em'):
                    c.set_font(style='I')
                elif tag == 'u':
                    c.set_font(style='', underline=True)
                elif tag == 'br':
                    c.ln(lh)
                elif tag == 'p':
                    c.ln(psp)
                elif tag == 'img':
                    src = attrs.get('src', '')
                    w = attrs.get('width')
                    h = attrs.get('height')
                    try:
                        w = float(w) if w else None
                        h = float(h) if h else None
                    except:
                        w = h = None
                    c.image(src, w=w, h=h)
            elif kind == 'end':
                tag = cmd[1]
                if tag in ('b', 'strong', 'i', 'em', 'u'):
                    c.set_font(style='')
                elif tag == 'p':
                    c.ln(psp)
            elif kind == 'data':
                text = _html.unescape(cmd[1])
                if '\n' in text:
                    c.multi_cell(0, lh, text)
                else:
                    c.write(lh, text)","class PDFHtml(object):
    def __init__(self, parent, session, htmltext, formats=None, context=None):
        self.parent = parent
        self.session = session
        self.htmltext = htmltext
        self.formats = formats if formats is not None else {}
        self.context = context if context is not None else {}
        self.parsed_data = None

    def _parsehtml(self):
        # Simple HTML parsing simulation
        # In a real implementation, this would use an HTML parser like BeautifulSoup
        if self.htmltext:
            # Remove basic HTML tags for demonstration
            import re
            clean_text = re.sub('<[^<]+?>', '', self.htmltext)
            self.parsed_data = clean_text.strip()
        else:
            self.parsed_data = """"

    def _runlist(self, mylist):
        # Process a list of items
        # In a real implementation, this would perform operations on the list
        if not mylist:
            return []
        
        result = []
        for item in mylist:
            if isinstance(item, str):
                result.append(item.strip())
            else:
                result.append(str(item))
        
        return result","class PDFHtml(object):
    def __init__(self, parent, session, htmltext, formats=None, context=None):
        self.parent = parent
        self.session = session
        self.htmltext = htmltext
        self.formats = formats or {}
        self.context = context or {}
        self.parsed_content = []
        self._parsehtml()

    def _parsehtml(self):
        from html.parser import HTMLParser
        
        class PDFHTMLParser(HTMLParser):
            def __init__(self, pdf_html_instance):
                super().__init__()
                self.pdf_html = pdf_html_instance
                self.current_tag = None
                self.content_stack = []
                
            def handle_starttag(self, tag, attrs):
                self.current_tag = tag
                attr_dict = dict(attrs)
                self.content_stack.append({
                    'type': 'start_tag',
                    'tag': tag,
                    'attrs': attr_dict
                })
                
            def handle_endtag(self, tag):
                self.content_stack.append({
                    'type': 'end_tag',
                    'tag': tag
                })
                
            def handle_data(self, data):
                if data.strip():
                    self.content_stack.append({
                        'type': 'data',
                        'content': data.strip()
                    })
        
        parser = PDFHTMLParser(self)
        parser.feed(self.htmltext)
        self.parsed_content = parser.content_stack
        self._runlist(self.parsed_content)

    def _runlist(self, mylist):
        processed_items = []
        tag_stack = []
        
        for item in mylist:
            if item['type'] == 'start_tag':
                tag_stack.append(item['tag'])
                processed_items.append(item)
            elif item['type'] == 'end_tag':
                if tag_stack and tag_stack[-1] == item['tag']:
                    tag_stack.pop()
                processed_items.append(item)
            elif item['type'] == 'data':
                current_format = {}
                if tag_stack:
                    current_tag = tag_stack[-1]
                    if current_tag in self.formats:
                        current_format = self.formats[current_tag]
                
                processed_item = {
                    'type': 'formatted_data',
                    'content': item['content'],
                    'format': current_format,
                    'tags': tag_stack.copy()
                }
                processed_items.append(processed_item)
        
        self.processed_content = processed_items",no_docstr,0.35119047619047616,0.19161676646706588,0.1325301204819277,0.2619047619047619,0.19663849874497233,0.28435114503816794,0.19120458891013384,0.13984674329501914,0.7226869463920593,0.8664758205413818,0.7880762815475464,0.8495724201202393,0.7363662727272737,0.4907407407407407,0.3364485981308411,0.22641509433962265,0.41666666666666674,0.3840281891914885,0.5537190082644629,0.36099585062240663,0.2833333333333333,0.7796729803085327,0.86896812915802,0.821902334690094,0.8591286540031433,0.7911898275862069,0.4037267080745342,0.2625,0.169811320754717,0.32919254658385094,0.23936840187006736,0.307843137254902,0.2357563850687623,0.1889763779527559,0.7657240629196167,0.8803513646125793,0.8190465569496155,0.8673670887947083,0.754774845814978,0.3749769292089319,0.0952827412339272,0.3421920596805126,0.6162790697674418,0.4461538461538462,0.425269561570316,0.1666782952063031,0.3721459260302381,0.5930232558139535,0.5692307692307692,0.3958181207664913,0.1331410441031727,0.3914552314493755,0.627906976744186,0.4307692307692308
570999,merll/docker-map,merll_docker-map/dockermap/map/input.py,dockermap.map.input._NotSet,"class _NotSet(object):
    def __nonzero__(self):
        return False

    __bool__ = __nonzero__

    def __repr__(self):
        return ""<Value not set>""

    def __str__(self):
        return ""Not set""

    def __eq__(self, other):
        return isinstance(other, self.__class__)","class _NotSet(object):


    def __nonzero__(self):
        pass

    def __repr__(self):
        pass

    def __str__(self):
        pass

    def __eq__(self, other):
        pass

",5,0,snippet_170,1.0,"class _NotSet(object):

    def __nonzero__(self):
        return False

    def __repr__(self):
        return '<NotSet>'

    def __str__(self):
        return self.__repr__()

    def __eq__(self, other):
        return isinstance(other, _NotSet)","class _NotSet(object):

    def __nonzero__(self):
        return False

    def __repr__(self):
        return '_NotSet()'

    def __str__(self):
        return 'NotSet'

    def __eq__(self, other):
        return isinstance(other, _NotSet)","class _NotSet(object):

    def __nonzero__(self):
        return False

    def __repr__(self):
        return '<NotSet>'

    def __str__(self):
        return '<NotSet>'

    def __eq__(self, other):
        return isinstance(other, _NotSet)",no_docstr,0.8135593220338982,0.6666666666666667,0.5454545454545454,0.7796610169491525,0.6724795602440155,0.9078947368421053,0.7866666666666666,0.7162162162162162,0.9585309028625488,0.9281175136566162,0.9430790543556213,0.9310718178749084,0.9281052941176471,0.7931034482758621,0.6785714285714285,0.5555555555555556,0.7931034482758621,0.6117353513402216,0.8985507246376812,0.8088235294117647,0.7611940298507462,0.9667225480079651,0.9317044019699097,0.9488905072212219,0.9350916743278503,0.9607847058823529,0.7931034482758621,0.6785714285714285,0.5555555555555556,0.7931034482758621,0.6221219251541488,0.875,0.7746478873239436,0.7285714285714285,0.9659733176231384,0.9316375851631165,0.9484947919845581,0.9349609017372131,0.9607847058823529,0.590322286957182,0.4006236620994292,0.4310358560996691,0.6296296296296297,0.9,0.5060630276979228,0.4006236620994292,0.4310358560996691,0.5925925925925926,0.6,0.5060630276979228,0.4006236620994292,0.4310358560996691,0.5925925925925926,0.6
741635,skelsec/msldap,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/skelsec_msldap/msldap/relay/server.py,msldap.relay.server.LDAPServerSettings,"class LDAPServerSettings:
    def __init__(self, gssapi_factory):
        self.gssapi_factory = gssapi_factory

    @property
    def gssapi(self):
        return self.gssapi_factory()","class LDAPServerSettings:


    def __init__(self, gssapi_factory):
        pass

    @property
    def gssapi(self):
        pass

",4,0,snippet_339,0.75,"class LDAPServerSettings:
    def __init__(self, gssapi_factory):
        if not callable(gssapi_factory):
            raise TypeError(""gssapi_factory must be callable"")
        self._gssapi_factory = gssapi_factory
        self._gssapi_instance = None

    @property
    def gssapi(self):
        if self._gssapi_instance is None:
            self._gssapi_instance = self._gssapi_factory()
        return self._gssapi_instance","class LDAPServerSettings:
    def __init__(self, gssapi_factory):
        self._gssapi_factory = gssapi_factory
        self._gssapi = None

    @property
    def gssapi(self):
        if self._gssapi is None:
            self._gssapi = self._gssapi_factory()
        return self._gssapi","class LDAPServerSettings:

    def __init__(self, gssapi_factory):
        self._gssapi_factory = gssapi_factory
        self._gssapi = None

    @property
    def gssapi(self):
        if self._gssapi is None:
            self._gssapi = self._gssapi_factory()
        return self._gssapi",no_docstr,0.5882352941176471,0.5151515151515151,0.43750000000000006,0.5588235294117647,0.38953380456996417,0.44329896907216493,0.3958333333333333,0.3368421052631579,0.8563258647918701,0.9376494288444519,0.8951443433761597,0.9288285374641418,0.8131331818181818,0.7692307692307693,0.6799999999999999,0.5833333333333334,0.7307692307692308,0.5639138748925886,0.6323529411764706,0.5671641791044776,0.5,0.9361453652381897,0.9686216711997986,0.9521066546440125,0.9652730822563171,0.8562105882352941,0.7692307692307693,0.6799999999999999,0.5833333333333334,0.7307692307692308,0.5639138748925886,0.6323529411764706,0.5671641791044776,0.5,0.9360963702201843,0.9685957431793213,0.9520687460899353,0.9652446508407593,0.8562105882352941,0.4929868484477033,0.1689995053994423,0.4458050312485141,0.5,0.8571428571428571,0.4730303314647318,0.2320305803246989,0.4458050312485141,0.5,0.7142857142857143,0.4730303314647318,0.2320305803246989,0.4458050312485141,0.5,0.7142857142857143
744486,socialwifi/RouterOS-api,socialwifi_RouterOS-api/routeros_api/api_communicator/async_decorator.py,routeros_api.api_communicator.async_decorator.ResponsePromise,"class ResponsePromise(object):
    def __init__(self, receiver, tag):
        self.receiver = receiver
        self.tag = tag
        self.response = None

    def get(self):
        if self.response is None:
            self.response = self.receiver.receive(self.tag)
        return self.response

    def __iter__(self):
        return self.receiver.receive_iterator(self.tag)","class ResponsePromise(object):


    def __init__(self, receiver, tag):
        pass

    def get(self):
        pass

    def __iter__(self):
        pass

",4,0,snippet_336,0.8333333333333334,"class ResponsePromise(object):
    def __init__(self, receiver, tag):
        self._receiver = receiver
        self._tag = tag

    def get(self):
        return self._receiver.get(self._tag)

    def __iter__(self):
        yield self.get()","class ResponsePromise(object):
    def __init__(self, receiver, tag):
        self._receiver = receiver
        self._tag = tag
        self._result = None
        self._resolved = False

    def get(self):
        if not self._resolved:
            self._result = self._receiver.receive(self._tag)
            self._resolved = True
        return self._result

    def __iter__(self):
        yield self.get()","class ResponsePromise(object):
    def __init__(self, receiver, tag):
        self.receiver = receiver
        self.tag = tag
        self._result = None
        self._ready = False

    def get(self):
        if not self._ready:
            self._result = self.receiver.get_response(self.tag)
            self._ready = True
        return self._result

    def __iter__(self):
        return iter(self.get())",no_docstr,0.7027027027027027,0.5833333333333334,0.45714285714285713,0.6756756756756757,0.5404246396325593,0.9117647058823529,0.746268656716418,0.6212121212121212,0.9475843906402588,0.8882170915603638,0.9169408679008484,0.8938169479370117,0.8760696153846153,0.7472527472527473,0.5617977528089888,0.4367816091954023,0.7252747252747253,0.6035469777795823,0.7745098039215687,0.6039603960396039,0.47,0.9116377234458923,0.9443797469139099,0.9277199506759644,0.9410000443458557,0.9176478823529411,0.7526881720430108,0.5494505494505494,0.38202247191011235,0.7096774193548386,0.6420163837612552,0.7766990291262136,0.6372549019607843,0.5346534653465347,0.9184203743934631,0.9376019835472107,0.9279120564460754,0.9356478452682495,0.9233724137931034,0.3853999539018626,0.2083796272890529,0.2260773311755403,0.6428571428571429,0.4642857142857143,0.4300624159790295,0.2234892645699562,0.2705699231556855,0.6904761904761905,0.5357142857142857,0.5992922875047222,0.417050729163413,0.5039279446649997,0.6904761904761905,0.7857142857142857
148378,MacHu-GWU/superjson-project,MacHu-GWU_superjson-project/for_document.py,for_document.User,"class User(object):
    def __init__(self, id, name):
        self.id = id
        self.name = name

    def __repr__(self):
        return ""User(id=%r, name=%r)"" % (self.id, self.name)

    def __eq__(self, other):
        return self.id == other.id and self.name == other.name","class User(object):


    def __init__(self, id, name):
        pass

    def __repr__(self):
        pass

    def __eq__(self, other):
        pass

",4,0,snippet_683,1.0,"class User(object):
    def __init__(self, id, name):
        self.id = id
        self.name = name

    def __repr__(self):
        return f""User(id={self.id!r}, name={self.name!r})""

    def __eq__(self, other):
        if not isinstance(other, User):
            return NotImplemented
        return self.id == other.id and self.name == other.name","class User(object):
    def __init__(self, id, name):
        self.id = id
        self.name = name

    def __repr__(self):
        return f""User(id={self.id}, name='{self.name}')""

    def __eq__(self, other):
        if not isinstance(other, User):
            return False
        return self.id == other.id and self.name == other.name","class User(object):

    def __init__(self, id, name):
        self.id = id
        self.name = name

    def __repr__(self):
        return f""User({self.id}, '{self.name}')""

    def __eq__(self, other):
        if not isinstance(other, User):
            return False
        return self.id == other.id and self.name == other.name",no_docstr,0.9111111111111111,0.8181818181818182,0.627906976744186,0.8444444444444446,0.7657008743954608,0.8611111111111112,0.7570093457943925,0.6886792452830188,0.9174156785011292,0.977331280708313,0.9464260935783386,0.9709898233413696,0.9113932911392404,0.8863636363636364,0.7906976744186046,0.6666666666666666,0.8636363636363636,0.7746524924523209,0.8584905660377359,0.7714285714285715,0.7019230769230769,0.9407511353492737,0.9626044034957886,0.9515522718429565,0.9603734016418457,0.9177497402597403,0.8604651162790697,0.7857142857142856,0.7317073170731708,0.8604651162790697,0.7692405282276678,0.8529411764705882,0.7623762376237624,0.7,0.9400119781494141,0.9603254795074463,0.9500601887702942,0.9582547545433044,0.9177497402597403,0.6446009754284757,0.6537608249810561,0.7362372796313973,0.6666666666666666,0.5217391304347826,0.6446009754284757,0.6537608249810561,0.7362372796313973,0.6666666666666666,0.5217391304347826,0.6446009754284757,0.6537608249810561,0.7362372796313973,0.6666666666666666,0.5217391304347826
272911,brechtm/rinohtype,brechtm_rinohtype/src/rinoh/backend/pdf/__init__.py,rinoh.backend.pdf.Page,"class Page(object):
    def __init__(self, backend_document, width, height, rinoh_page):
        self.backend_document = backend_document
        rotate = SIDEWAYS_TO_ROTATE[rinoh_page.display_sideways]
        cos_pages = backend_document.cos_document.catalog['Pages']
        self.cos_page = cos_pages.new_page(float(width), float(height), rotate)
        self.width = width
        self.height = height
        self.rinoh_page = rinoh_page
        self.number = rinoh_page.number
        self.number_format = rinoh_page.number_format
        self.canvas = PageCanvas(self)
        self.backend_document.pages.append(self)

    def add_font_resource(self, font_name, font_rsc):
        page_rsc = self.cos_page['Resources']
        fonts_dict = page_rsc.setdefault('Font', cos.Dictionary())
        fonts_dict[font_name] = font_rsc","class Page(object):


    def __init__(self, backend_document, width, height, rinoh_page):
        pass

    def add_font_resource(self, font_name, font_rsc):
        pass

",3,0,snippet_535,0.75,"class Page(object):

    def __init__(self, backend_document, width, height, rinoh_page):
        self.backend_document = backend_document
        self.width = width
        self.height = height
        self.rinoh_page = rinoh_page
        self.font_resources = {}

    def add_font_resource(self, font_name, font_rsc):
        if font_name in self.font_resources:
            return
        self.font_resources[font_name] = font_rsc
        if hasattr(self.backend_document, 'add_font'):
            try:
                self.backend_document.add_font(font_name, font_rsc)
            except TypeError:
                self.backend_document.add_font(font_rsc)
        if hasattr(self.rinoh_page, 'add_font_resource'):
            self.rinoh_page.add_font_resource(font_name, font_rsc)","class Page(object):
    def __init__(self, backend_document, width, height, rinoh_page):
        self.backend_document = backend_document
        self.width = width
        self.height = height
        self.rinoh_page = rinoh_page
        self.font_resources = {}

    def add_font_resource(self, font_name, font_rsc):
        self.font_resources[font_name] = font_rsc","class Page(object):

    def __init__(self, backend_document, width, height, rinoh_page):
        self.backend_document = backend_document
        self.width = width
        self.height = height
        self.rinoh_page = rinoh_page
        self.font_resources = {}

    def add_font_resource(self, font_name, font_rsc):
        self.font_resources[font_name] = font_rsc",no_docstr,0.6019417475728156,0.4215686274509804,0.3465346534653465,0.49514563106796117,0.5075402118032589,0.7551020408163265,0.5333333333333333,0.4484536082474227,0.8853931427001953,0.8256499767303467,0.8544785380363464,0.83125901222229,0.8055574999999999,0.5844155844155844,0.513157894736842,0.45333333333333337,0.5714285714285714,0.25019640734388415,0.9381443298969072,0.8645833333333334,0.8210526315789474,0.9042282104492188,0.7904991507530212,0.8435476422309875,0.8005683422088623,0.7884636538461538,0.5844155844155844,0.513157894736842,0.45333333333333337,0.5714285714285714,0.25019640734388415,0.9381443298969072,0.8645833333333334,0.8210526315789474,0.9040138721466064,0.7904905080795288,0.8434494733810425,0.800543487071991,0.7884636538461538,0.4265936071223665,0.3728510619477868,0.3904143921827049,0.4743589743589743,0.46875,0.346829530679451,0.3053973202786889,0.3904143921827049,0.4102564102564102,0.28125,0.346829530679451,0.3053973202786889,0.3904143921827049,0.4102564102564102,0.28125
722629,scikit-hep/uproot,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/scikit-hep_uproot/uproot3/rootio.py,uproot3.rootio.ROOTDirectory._FileContext,"class _FileContext(object):
    def __init__(self, sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile):
        self.sourcepath, self.streamerinfos, self.streamerinfosmap, self.classes, self.compression, self.tfile = sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile
        self.uuid = tfile[""_fUUID""]

    def copy(self):
        out = ROOTDirectory._FileContext.__new__(
            ROOTDirectory._FileContext)
        out.__dict__.update(self.__dict__)
        return out
","class _FileContext(object):


    def __init__(self, sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile):
        pass


    def copy(self):
        pass

",3,0,snippet_235,0.75,"class _FileContext(object):
    def __init__(self, sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile):
        self.sourcepath = sourcepath
        self.streamerinfos = list(streamerinfos)
        self.streamerinfosmap = dict(streamerinfosmap)
        self.classes = list(classes)
        self.compression = compression
        self.tfile = tfile

    def copy(self):
        return _FileContext(
            self.sourcepath,
            copy.deepcopy(self.streamerinfos),
            copy.deepcopy(self.streamerinfosmap),
            copy.deepcopy(self.classes),
            self.compression,
            self.tfile
        )","class _FileContext(object):
    def __init__(self, sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile):
        self.sourcepath = sourcepath
        self.streamerinfos = streamerinfos
        self.streamerinfosmap = streamerinfosmap
        self.classes = classes
        self.compression = compression
        self.tfile = tfile

    def copy(self):
        return _FileContext(
            self.sourcepath,
            self.streamerinfos,
            self.streamerinfosmap,
            self.classes,
            self.compression,
            self.tfile
        )","class _FileContext(object):

    def __init__(self, sourcepath, streamerinfos, streamerinfosmap, classes, compression, tfile):
        self.sourcepath = sourcepath
        self.streamerinfos = streamerinfos
        self.streamerinfosmap = streamerinfosmap
        self.classes = classes
        self.compression = compression
        self.tfile = tfile

    def copy(self):
        return _FileContext(
            self.sourcepath,
            self.streamerinfos,
            self.streamerinfosmap,
            self.classes,
            self.compression,
            self.tfile
        )",no_docstr,0.7358490566037736,0.4807692307692308,0.39215686274509803,0.5849056603773586,0.5180944947577697,0.7288135593220338,0.49572649572649574,0.4051724137931034,0.8939110636711121,0.8884645700454712,0.8911795020103455,0.8890062570571899,0.8301299038461537,0.7835051546391754,0.5263157894736842,0.4946236559139785,0.6391752577319586,0.5437605412948766,0.8723404255319149,0.6881720430107527,0.6195652173913043,0.9386683106422424,0.894227147102356,0.915908932685852,0.898481011390686,0.8314193103448275,0.7835051546391754,0.5263157894736842,0.4946236559139785,0.6391752577319586,0.5437605412948766,0.8723404255319149,0.6881720430107527,0.6195652173913043,0.9385510087013245,0.8941457271575928,0.9158104658126831,0.8983963131904602,0.8314193103448275,0.4237688301375133,0.2872511063551186,0.3390312185726706,0.4102564102564102,0.6585365853658537,0.4756803665709684,0.3867400589230704,0.4496899752157128,0.358974358974359,0.7073170731707317,0.4756803665709684,0.3867400589230704,0.4496899752157128,0.358974358974359,0.7073170731707317
492673,idlesign/envbox,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/idlesign_envbox/docs/source/conf.py,conf.ModuleMock,"class ModuleMock(object):

    __all__ = []

    def __init__(self, *args, **kwargs):
        pass

    def __call__(self, *args, **kwargs):
        return ModuleMock()

    def __iter__(self):
        return iter([])

    @classmethod
    def __getattr__(cls, name):
        if name in ('__file__', '__path__'):
            return '/dev/null'
        elif name.upper() != name and name[0] == name[0].upper():
            # Mock classes.
            MockType = type(name, (ModuleMock,), {})
            MockType.__module__ = __name__
            return MockType
        return ModuleMock()
","class ModuleMock(object):



    def __init__(self, *args, **kwargs):
        pass


    def __call__(self, *args, **kwargs):
        pass


    def __iter__(self):
        pass

    @classmethod
    def __getattr__(cls, name):
        pass

",6,0,snippet_459,0.7272727272727273,"class ModuleMock(object):
    def __init__(self, *args, **kwargs):
        pass

    def __call__(self, *args, **kwargs):
        return type(self)(*args, **kwargs)

    def __iter__(self):
        return iter(())

    @classmethod
    def __getattr__(cls, name):
        return cls()","class ModuleMock(object):
    def __init__(self, *args, **kwargs):
        pass

    def __call__(self, *args, **kwargs):
        return ModuleMock()

    def __iter__(self):
        return iter([])

    @classmethod
    def __getattr__(cls, name):
        return ModuleMock()","class ModuleMock(object):
    def __init__(self, *args, **kwargs):
        self._name = kwargs.get('_name', 'ModuleMock')
        self._children = {}
        for key, value in kwargs.items():
            if not key.startswith('_'):
                setattr(self, key, value)

    def __call__(self, *args, **kwargs):
        return ModuleMock(_name=f""{self._name}()"")

    def __iter__(self):
        return iter([])

    def __getattr__(self, name):
        if name.startswith('_'):
            raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{name}'"")
        
        if name not in self._children:
            self._children[name] = ModuleMock(_name=f""{self._name}.{name}"")
        return self._children[name]

    @classmethod
    def __getattr__(cls, name):
        return ModuleMock(_name=name)",no_docstr,0.6067415730337079,0.528735632183908,0.44705882352941173,0.5842696629213483,0.31793287286372185,0.9213483146067416,0.8181818181818182,0.7471264367816092,0.9481926560401917,0.8145976066589355,0.8763328790664673,0.8262389302253723,0.7953236842105263,0.6511627906976745,0.6190476190476191,0.5365853658536585,0.6511627906976745,0.3028447131043142,1.0,0.9873417721518988,0.9615384615384616,0.9682760238647461,0.8251600861549377,0.8910077810287476,0.8375393152236938,0.8187152631578948,0.5066666666666666,0.3378378378378379,0.2191780821917808,0.4533333333333333,0.41909916749094805,0.592741935483871,0.3967611336032389,0.3130081300813008,0.7954339981079102,0.8308722376823425,0.8127670288085938,0.8271869421005249,0.7540131550802144,0.2936411152327365,0.1625128160932536,0.2606165128055453,0.3283582089552239,0.4230769230769231,0.359039550060146,0.2275769643079409,0.3762046572874077,0.4477611940298507,0.3846153846153846,0.328079112713732,0.1952058679310189,0.2376616736242534,0.417910447761194,0.4615384615384615
207921,WojciechMula/pyahocorasick,WojciechMula_pyahocorasick/tests/memdump_maxrealloc.py,memdump_maxrealloc.Application,"class Application(object):

    def __init__(self, path):
        self.path = path

    def run(self):
        with open(self.path, 'rt') as f:
            print(max(self.ids(f)))

    def ids(self, file):
        for i, line in enumerate(file):
            fields = line.split()
            if fields[0] == 'R':
                yield int(fields[1])","class Application(object):


    def __init__(self, path):
        pass

    def run(self):
        pass

    def ids(self, file):
        pass

",4,0,snippet_155,0.3333333333333333,"class Application(object):

    def __init__(self, path):
        self.path = path

    def run(self):
        files = []
        if os.path.isdir(self.path):
            for root, _, filenames in os.walk(self.path):
                for fn in filenames:
                    files.append(os.path.join(root, fn))
        elif os.path.isfile(self.path):
            files.append(self.path)

        for f in files:
            found = self.ids(f)
            if found:
                print(f)
                for i in sorted(found):
                    print(i)

    def ids(self, file):
        results = set()
        pattern = re.compile(r'\b\d+\b')
        try:
            with open(file, 'r') as fp:
                for line in fp:
                    for m in pattern.findall(line):
                        results.add(int(m))
        except (IOError, OSError):
            pass
        return results","class Application(object):
    def __init__(self, path):
        self.path = path
        self.data = {}

    def run(self):
        # Simulate running the application
        print(f""Running application from path: {self.path}"")
        return True

    def ids(self, file):
        # Return identifiers from the file
        if file not in self.data:
            self.data[file] = []
        return self.data[file]","class Application(object):

    def __init__(self, path):
        self.path = path

    def run(self):
        if os.path.exists(self.path):
            subprocess.run([self.path])

    def ids(self, file):
        if os.path.exists(file):
            with open(file, 'r') as f:
                return [line.strip() for line in f.readlines() if line.strip()]
        return []",no_docstr,0.46753246753246747,0.2763157894736842,0.18666666666666665,0.36363636363636365,0.298842415154762,0.39903846153846156,0.2995169082125604,0.22330097087378642,0.7198745012283325,0.8290708065032959,0.7706236243247986,0.8166826963424683,0.7592616666666671,0.5154639175257731,0.3157894736842105,0.23655913978494622,0.4329896907216495,0.4485330112565292,0.6082474226804123,0.4270833333333333,0.3473684210526316,0.828721821308136,0.8036677837371826,0.816002607345581,0.8061047792434692,0.7730519148936169,0.6666666666666666,0.40425531914893614,0.2826086956521739,0.4999999999999999,0.553352685255802,0.7333333333333333,0.5288461538461539,0.4368932038834951,0.8548704385757446,0.8516861796379089,0.8532753586769104,0.8520035743713379,0.7925190816326529,0.4112210642053676,0.1508866661469852,0.3736272203041149,0.3703703703703703,0.75,0.2918750644411607,0.2036143756522423,0.283330326556845,0.2222222222222222,0.4583333333333333,0.4606002152993428,0.3593699487247958,0.3811790606207234,0.3518518518518518,0.75
209947,a10networks/a10-neutron-lbaas,a10networks_a10-neutron-lbaas/a10_neutron_lbaas/a10_config.py,a10_neutron_lbaas.a10_config.ConfigModule,"class ConfigModule(object):
    def __init__(self, d, provider=None):
        self.__dict__.update(d)

        if provider is None or 'providers' not in d or provider not in d['providers']:
            return None

        for k, v in d['providers'][provider].items():
            if isinstance(v, dict):
                if k not in self.__dict__:
                    self.__dict__[k] = {}
                self.__dict__[k].update(v)
            else:
                self.__dict__[k] = v

    @classmethod
    def load(cls, path, provider=None):
        d = runpy.run_path(path)
        return ConfigModule(d, provider=provider)","class ConfigModule(object):


    def __init__(self, d, provider=None):
        pass

    @classmethod
    def load(cls, path, provider=None):
        pass

",4,0,snippet_255,0.3333333333333333,"class ConfigModule(object):
    def __init__(self, d, provider=None):
        if not isinstance(d, dict):
            raise TypeError(""ConfigModule expects a dict"")
        self._data = d
        self.provider = provider

    @classmethod
    def load(cls, path, provider=None):
        if not os.path.isfile(path):
            raise FileNotFoundError(f""No such file: {path}"")

        _, ext = os.path.splitext(path.lower())
        with open(path, 'r') as f:
            if ext in ('.yaml', '.yml'):
                if yaml is None:
                    raise ImportError(""PyYAML is required to load YAML files"")
                data = yaml.safe_load(f)
            elif ext == '.json':
                data = json.load(f)
            else:
                raise ValueError(f""Unsupported file extension: {ext}"")

        if not isinstance(data, dict):
            raise ValueError(""Configuration file must contain a JSON/YAML object at the top level"")

        return cls(data, provider)

    def get(self, key, default=None):
        return self._data.get(key, default)

    def __getitem__(self, key):
        return self._data[key]

    def __contains__(self, key):
        return key in self._data

    def keys(self):
        return self._data.keys()

    def items(self):
        return self._data.items()

    def as_dict(self):
        return dict(self._data)","class ConfigModule(object):
    def __init__(self, d, provider=None):
        self.data = d
        self.provider = provider

    @classmethod
    def load(cls, path, provider=None):
        import json
        with open(path, 'r') as f:
            data = json.load(f)
        return cls(data, provider)","class ConfigModule(object):

    def __init__(self, d, provider=None):
        self._data = d if isinstance(d, dict) else {}
        self._provider = provider
        for key, value in self._data.items():
            if isinstance(value, dict):
                setattr(self, key, ConfigModule(value, provider))
            else:
                setattr(self, key, value)

    @classmethod
    def load(cls, path, provider=None):
        if not os.path.exists(path):
            raise FileNotFoundError(f""Config file not found: {path}"")
        
        with open(path, 'r') as f:
            if path.endswith('.json'):
                data = json.load(f)
            else:
                # Assume it's a Python file
                content = f.read()
                data = {}
                exec(content, data)
                # Remove built-in variables
                data = {k: v for k, v in data.items() if not k.startswith('__')}
        
        return cls(data, provider)

    def __getitem__(self, key):
        return getattr(self, key)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __contains__(self, key):
        return hasattr(self, key)

    def get(self, key, default=None):
        return getattr(self, key, default)

    def to_dict(self):
        result = {}
        for key, value in self.__dict__.items():
            if not key.startswith('_'):
                if isinstance(value, ConfigModule):
                    result[key] = value.to_dict()
                else:
                    result[key] = value
        return result",no_docstr,0.40322580645161293,0.14634146341463414,0.09836065573770492,0.21774193548387094,0.2316314150934605,0.3761194029850746,0.2245508982035928,0.14714714714714713,0.7193243503570557,0.8181335926055908,0.7655538320541382,0.8070477247238159,0.7430328727272734,0.41379310344827586,0.2807017543859649,0.23214285714285712,0.39655172413793105,0.17487477913290678,0.8108108108108109,0.6027397260273972,0.5,0.8261159062385559,0.7600831389427185,0.7917250394821167,0.7662075161933899,0.7549044117647059,0.44357976653696496,0.21176470588235294,0.13438735177865613,0.26459143968871596,0.25023855817032187,0.3672922252010724,0.24731182795698925,0.1725067385444744,0.7502955198287964,0.8536169528961182,0.7986283302307129,0.8420217037200928,0.7322607419354846,0.2703898620130496,0.0785281378787125,0.1896751457899241,0.4383561643835616,0.375,0.2165426308120691,0.1305471931094934,0.1497215036547646,0.3150684931506849,0.2708333333333333,0.2918480812249246,0.0878438020758692,0.2376535456548796,0.3835616438356164,0.4583333333333333
215557,adewes/blitzdb,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/adewes_blitzdb/blitzdb/backends/file/serializers.py,blitzdb.backends.file.serializers.CJsonSerializer,"class CJsonSerializer(object):

    @classmethod
    def serialize(cls, data):
        return cjson.encode(data)

    @classmethod
    def deserialize(cls, data):
        return cjson.decode(data)
","class CJsonSerializer(object):


    @classmethod
    def serialize(cls, data):
        pass

    @classmethod
    def deserialize(cls, data):
        pass

",5,0,snippet_239,0.5,"class CJsonSerializer(object):

    @classmethod
    def serialize(cls, data):
        """"""
        Serialize a Python object to a JSON-formatted string.
        """"""
        return json.dumps(data)

    @classmethod
    def deserialize(cls, data):
        """"""
        Deserialize a JSON-formatted string (or bytes) to a Python object.
        """"""
        if isinstance(data, (bytes, bytearray)):
            data = data.decode('utf-8')
        return json.loads(data)","class CJsonSerializer(object):

    @classmethod
    def serialize(cls, data):
        return json.dumps(data)

    @classmethod
    def deserialize(cls, data):
        return json.loads(data)","class CJsonSerializer(object):

    @classmethod
    def serialize(cls, data):
        return json.dumps(data)

    @classmethod
    def deserialize(cls, data):
        return json.loads(data)",no_docstr,0.5,0.34285714285714286,0.29411764705882354,0.4722222222222222,0.3448146688229629,0.4,0.3404255319148936,0.3010752688172043,0.7690958976745605,0.9025917649269104,0.8305135369300842,0.8871923089027405,0.8502430434782609,0.8095238095238095,0.7,0.631578947368421,0.8095238095238095,0.8127314797724984,0.9024390243902439,0.8,0.7435897435897436,0.9726073741912842,0.9580528736114502,0.9652752876281738,0.9594887495040894,1.0,0.8095238095238095,0.7,0.631578947368421,0.8095238095238095,0.8127314797724984,0.9024390243902439,0.8,0.7435897435897436,0.9726073741912842,0.9580528736114502,0.9652752876281738,0.9594887495040894,1.0,0.6500747653751153,0.1670052870232178,0.5696574108408796,0.8636363636363636,1.0,0.8540146254200348,0.6997522298221912,0.7163062718579482,1.0,1.0,0.8540146254200348,0.6997522298221912,0.7163062718579482,1.0,1.0
722142,sci-bots/pygtkhelpers,sci-bots_pygtkhelpers/pygtkhelpers/ui/objectlist/view.py,pygtkhelpers.ui.objectlist.view.SubObjectTree,"class SubObjectTree(object):
    def __init__(self, items, item_paths):
        self.items = items
        self.item_paths = item_paths

    def copy(self):
        return copy.deepcopy(self)

    def __iter__(self):
        if self.item_paths:
            for i in range(len(self.items)):
                item_path = self.item_paths[i]
                yield self.items[i], item_path

    def __str__(self):
        return str(zip(self.items, self.item_paths))","class SubObjectTree(object):


    def __init__(self, items, item_paths):
        pass

    def copy(self):
        pass

    def __iter__(self):
        pass

    def __str__(self):
        pass

",5,0,snippet_467,1.0,"class SubObjectTree(object):
    def __init__(self, items, item_paths):
        self.items = []
        self.children = {}
        buckets = {}
        for item, path in zip(items, item_paths):
            if not path:
                self.items.append(item)
            else:
                key = path[0]
                rest = path[1:]
                if key not in buckets:
                    buckets[key] = ([], [])
                buckets[key][0].append(item)
                buckets[key][1].append(rest)
        for key, (sub_items, sub_paths) in buckets.items():
            self.children[key] = SubObjectTree(sub_items, sub_paths)

    def copy(self):
        new = SubObjectTree([], [])
        new.items = list(self.items)
        new.children = {k: v.copy() for k, v in self.children.items()}
        return new

    def __iter__(self):
        for key, subtree in self.children.items():
            yield key, subtree

    def __str__(self):
        lines = []
        def _rec(tree, indent):
            for it in tree.items:
                lines.append("" "" * indent + repr(it))
            for key, sub in tree.children.items():
                lines.append("" "" * indent + str(key))
                _rec(sub, indent + 2)
        _rec(self, 0)
        return ""\n"".join(lines)","class SubObjectTree(object):
    def __init__(self, items, item_paths):
        self.items = items
        self.item_paths = item_paths

    def copy(self):
        return SubObjectTree(self.items.copy(), self.item_paths.copy())

    def __iter__(self):
        return iter(self.items)

    def __str__(self):
        return f""SubObjectTree(items={self.items}, item_paths={self.item_paths})""","class SubObjectTree(object):

    def __init__(self, items, item_paths):
        self.items = items if items is not None else []
        self.item_paths = item_paths if item_paths is not None else []

    def copy(self):
        return SubObjectTree(self.items.copy(), self.item_paths.copy())

    def __iter__(self):
        return iter(self.items)

    def __str__(self):
        return f""SubObjectTree(items={self.items}, item_paths={self.item_paths})""",no_docstr,0.4688995215311005,0.24154589371980675,0.13658536585365855,0.3253588516746412,0.2340124605427346,0.3492537313432836,0.23053892215568864,0.15915915915915915,0.7329002022743225,0.8691582679748535,0.7952347993850708,0.8532941937446594,0.7356348275862068,0.7747747747747747,0.6422018348623854,0.4672897196261682,0.6666666666666666,0.6756652117320977,0.8803418803418803,0.7327586206896551,0.6521739130434783,0.9365441799163818,0.9013303518295288,0.9185999035835266,0.9047322273254395,0.819150744680851,0.7258064516129032,0.540983606557377,0.35,0.5967741935483871,0.6484552897885718,0.8148148148148148,0.6268656716417911,0.5338345864661654,0.8953514099121094,0.9023451209068298,0.8988346457481384,0.9016408920288086,0.7836901063829786,0.3265645296633707,0.0760653669598517,0.2890505605514397,0.3653846153846153,0.5757575757575758,0.4228388800817637,0.4468391693642279,0.4688753253218015,0.4423076923076923,0.3333333333333333,0.3539882276449838,0.3046758078105637,0.3601116016038702,0.3269230769230769,0.4242424242424242
426848,googleapis/google-cloud-python,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/googleapis_google-cloud-python/packages/google-cloud-dialogflow-cx/google/cloud/dialogflowcx_v3beta1/services/webhooks/transports/rest_base.py,dialogflowcx_v3beta1.services.webhooks.transports.rest_base._BaseWebhooksRestTransport._BaseListOperations,"class _BaseListOperations:
    def __hash__(self):  # pragma: NO COVER
        return NotImplementedError(""__hash__ must be implemented."")

    @staticmethod
    def _get_http_options():
        http_options: List[Dict[str, str]] = [
            {
                ""method"": ""get"",
                ""uri"": ""/v3beta1/{name=projects/*}/operations"",
            },
            {
                ""method"": ""get"",
                ""uri"": ""/v3beta1/{name=projects/*/locations/*}/operations"",
            },
        ]
        return http_options

    @staticmethod
    def _get_transcoded_request(http_options, request):
        request_kwargs = json_format.MessageToDict(request)
        transcoded_request = path_template.transcode(
            http_options, **request_kwargs)
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        query_params = json.loads(json.dumps(
            transcoded_request[""query_params""]))
        return query_params
","class _BaseListOperations:


    def __hash__(self):
        pass

    @staticmethod
    def _get_http_options():
        pass

    @staticmethod
    def _get_transcoded_request(http_options, request):
        pass

    @staticmethod
    def _get_query_params_json(transcoded_request):
        pass

",8,0,snippet_181,0.5,"class _BaseListOperations:
    def __hash__(self):
        return hash(self.__class__)

    @staticmethod
    def _get_http_options():
        """"""
        Returns a list of HTTP option templates. Subclasses should override
        this method to provide specific method, uri, and body field names.
        """"""
        return []

    @staticmethod
    def _get_transcoded_request(http_options, request):
        """"""
        Transcode a request dict into an HTTP request description.
        Picks the first matching http_option, formats its URI with request
        values, extracts the body, and treats the rest as query parameters.
        """"""
        for option in http_options:
            method = option.get(""method"")
            uri_template = option.get(""uri"", """")
            body_field = option.get(""body"")

            # Fill URI template
            try:
                uri = uri_template.format(**request)
            except Exception:
                uri = uri_template

            # Extract body if specified
            body = None
            if body_field and body_field in request:
                body = request[body_field]

            # Determine which fields to exclude from query params
            excluded = set()
            if body_field:
                excluded.add(body_field)
            # Exclude any fields used in the URI template
            for key in request:
                if ""{%s}"" % key in uri_template:
                    excluded.add(key)

            # Build query params
            query_params = {
                k: v for k, v in request.items() if k not in excluded
            }

            return {
                ""method"": method,
                ""uri"": uri,
                ""body"": body,
                ""query_params"": query_params,
            }

        raise ValueError(""No HTTP options provided for transcoding"")

    @staticmethod
    def _get_query_params_json(transcoded_request):
        """"""
        Return a JSON-serializable dict of query parameters from the
        transcoded request.
        """"""
        qp = transcoded_request.get(""query_params"", {})
        try:
            # Ensure all values are JSON-serializable
            return json.loads(json.dumps(qp, default=lambda o: o.__dict__))
        except Exception:
            # Fallback to a shallow copy
            return dict(qp)","class _BaseListOperations:
    def __hash__(self):
        return hash(id(self))

    @staticmethod
    def _get_http_options():
        return {}

    @staticmethod
    def _get_transcoded_request(http_options, request):
        return request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        return {}","class _BaseListOperations:

    def __hash__(self):
        return hash(id(self))

    @staticmethod
    def _get_http_options():
        return {
            'method': 'GET',
            'headers': {
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            }
        }

    @staticmethod
    def _get_transcoded_request(http_options, request):
        transcoded_request = {
            'method': http_options.get('method', 'GET'),
            'headers': http_options.get('headers', {}),
            'url': getattr(request, 'url', ''),
            'params': getattr(request, 'params', {}),
            'body': getattr(request, 'body', None)
        }
        return transcoded_request

    @staticmethod
    def _get_query_params_json(transcoded_request):
        params = transcoded_request.get('params', {})
        if not params:
            return '{}'
        
        import json
        return json.dumps(params, separators=(',', ':'))",no_docstr,0.38840579710144935,0.19241982507288627,0.11730205278592375,0.27246376811594203,0.2620770422260553,0.3978260869565217,0.25272331154684097,0.17903930131004367,0.7161870002746582,0.7716683745384216,0.7428932189941406,0.7657363414764404,0.7364647292418779,0.5161290322580645,0.37704918032786894,0.31666666666666665,0.5161290322580645,0.11181006767425802,0.974025974025974,0.7894736842105263,0.7333333333333333,0.8600655794143677,0.6755324602127075,0.7567113637924194,0.6903442740440369,0.7612317021276594,0.6250000000000001,0.39080459770114945,0.2558139534883721,0.5,0.385505420461786,0.6519607843137255,0.3891625615763547,0.32673267326732675,0.8342373371124268,0.7793543338775635,0.8058624863624573,0.7845155596733093,0.7706293564356435,0.2375842346323174,0.0353357217217189,0.1518851595738466,0.3513513513513513,0.4117647058823529,0.1166998079517148,0.0619587559073832,0.1385447684272979,0.1486486486486486,0.1176470588235294,0.2943521162418121,0.1526328894718684,0.194091950694108,0.4189189189189189,0.4117647058823529
350634,dpgaspar/Flask-AppBuilder,dpgaspar_Flask-AppBuilder/flask_appbuilder/models/generic/__init__.py,flask_appbuilder.models.generic.GenericColumn,"class GenericColumn(object):
    col_type = None
    primary_key = None
    unique = None
    nullable = None

    def __init__(self, col_type, primary_key=False, unique=False, nullable=False):
        self.col_type = col_type
        self.primary_key = primary_key
        self.unique = unique
        self.nullable = nullable

    def check_type(self, value):
        return isinstance(value, self.col_type)","class GenericColumn(object):


    def __init__(self, col_type, primary_key=False, unique=False, nullable=False):
        pass

    def check_type(self, value):
        pass

",3,0,snippet_175,1.0,"class GenericColumn(object):
    def __init__(self, col_type, primary_key=False, unique=False, nullable=False):
        self.col_type = col_type
        self.primary_key = primary_key
        self.unique = unique
        self.nullable = nullable

    def check_type(self, value):
        if value is None:
            if self.nullable:
                return True
            raise ValueError(""Null value not allowed for this column"")
        if not isinstance(value, self.col_type):
            expected = (
                self.col_type.__name__
                if isinstance(self.col_type, type)
                else "", "".join(t.__name__ for t in self.col_type)
            )
            raise TypeError(f""Expected type {expected}, got {type(value).__name__}"")
        return True","class GenericColumn(object):
    def __init__(self, col_type, primary_key=False, unique=False, nullable=False):
        self.col_type = col_type
        self.primary_key = primary_key
        self.unique = unique
        self.nullable = nullable

    def check_type(self, value):
        if value is None:
            return self.nullable
        return isinstance(value, self.col_type)","class GenericColumn(object):

    def __init__(self, col_type, primary_key=False, unique=False, nullable=False):
        self.col_type = col_type
        self.primary_key = primary_key
        self.unique = unique
        self.nullable = nullable

    def check_type(self, value):
        if value is None:
            return self.nullable
        return isinstance(value, self.col_type)",no_docstr,0.6301369863013698,0.5416666666666666,0.4929577464788733,0.5753424657534246,0.4482984415725671,0.48404255319148937,0.44385026737967914,0.41935483870967744,0.8125127553939819,0.9410661458969116,0.8720773458480835,0.9264087677001953,0.7711465671641791,0.8712871287128713,0.787878787878788,0.7422680412371133,0.8316831683168318,0.8253803031408804,0.9247311827956989,0.8913043478260869,0.8571428571428571,0.9616528749465942,0.9632180333137512,0.9624347686767578,0.9630612730979919,0.88889,0.8712871287128713,0.787878787878788,0.7422680412371133,0.8316831683168318,0.8253803031408804,0.9247311827956989,0.8913043478260869,0.8571428571428571,0.9618297219276428,0.9632883071899414,0.9625585079193115,0.9631423354148865,0.88889,0.4613509904465031,0.3253927238042959,0.5546396163600946,0.6216216216216216,0.34375,0.5217836451356961,0.5858858032573505,0.5713501286367851,0.6486486486486487,0.28125,0.5217836451356961,0.5858858032573505,0.5713501286367851,0.6486486486486487,0.28125
155349,NASA-AMMOS/AIT-Core,ait/core/api.py,core.api.TlmWrapperAttr,"class TlmWrapperAttr(object):
    def __init__(self, buffers):
        super(TlmWrapperAttr, self).__init__()
        self._buffers = buffers

    def __getattr__(self, name):
        return TlmWrapper(self._buffers[name])","class TlmWrapperAttr(object):


    def __init__(self, buffers):
        pass

    def __getattr__(self, name):
        pass

",3,0,snippet_558,1.0,"class TlmWrapperAttr(object):
    def __init__(self, buffers):
        # buffers: an iterable of objects or dict-like
        self._buffers = list(buffers)

    def __getattr__(self, name):
        for buf in self._buffers:
            # try object attribute
            try:
                return getattr(buf, name)
            except AttributeError:
                pass
            # try dict-like access
            try:
                return buf[name]
            except (TypeError, KeyError):
                pass
        raise AttributeError(f""{self.__class__.__name__!r} object has no attribute {name!r}"")","class TlmWrapperAttr(object):
    def __init__(self, buffers):
        self._buffers = buffers

    def __getattr__(self, name):
        if name in self._buffers:
            return self._buffers[name]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{name}'"")","class TlmWrapperAttr(object):

    def __init__(self, buffers):
        self._buffers = buffers

    def __getattr__(self, name):
        if name in self._buffers:
            return self._buffers[name]
        raise AttributeError(f""'{self.__class__.__name__}' object has no attribute '{name}'"")",no_docstr,0.43678160919540227,0.30588235294117644,0.21686746987951808,0.39080459770114945,0.34872626036401544,0.4603174603174603,0.336,0.27419354838709675,0.7199424505233765,0.8849033117294312,0.793944776058197,0.8650816679000854,0.7564126923076923,0.6666666666666667,0.5090909090909091,0.4150943396226415,0.631578947368421,0.5330714733961586,0.6162790697674418,0.5294117647058824,0.4642857142857143,0.8828415870666504,0.9342052340507507,0.9077974557876587,0.928801417350769,0.7939414545454545,0.6666666666666667,0.5090909090909091,0.4150943396226415,0.631578947368421,0.5330714733961586,0.6162790697674418,0.5294117647058824,0.4642857142857143,0.882938027381897,0.9344038367271423,0.9079422354698181,0.9289888739585876,0.7939414545454545,0.3275628122695939,0.0986757138772775,0.386575535201098,0.2916666666666667,0.5333333333333333,0.4374247082646073,0.3489214645008508,0.6007773685575784,0.3333333333333333,0.4666666666666667,0.4374247082646073,0.3489214645008508,0.6007773685575784,0.3333333333333333,0.4666666666666667
722663,scikit-hep/uproot,scikit-hep_uproot/uproot3/tree.py,uproot3.tree._LazyTree,"class _LazyTree(object):
    def __init__(self, path, treepath, tree, interpretation, flatten, awkwardlib, basketcache, keycache, executor):
        self.path = path
        self.treepath = treepath
        self.tree = tree
        self.interpretation = interpretation
        self.flatten = flatten
        self.awkwardlib = awkwardlib
        self.basketcache = basketcache
        self.keycache = keycache
        self.executor = executor
        self._init()

    def _init(self):
        if self.tree is None:
            self.tree = uproot3.rootio.open(self.path)[self.treepath]
        if self.basketcache is None:
            self.basketcache = uproot3.cache.ThreadSafeArrayCache(1024**2)   # 1 MB
        if self.keycache is None:
            self.keycache = {}                                              # unlimited

    def __getstate__(self):
        return {""path"": self.path,
                ""treepath"": self.treepath,
                ""interpretation"": self.interpretation,
                ""flatten"": self.flatten,
                ""awkwardlib"": self.awkwardlib}

    def __setstate__(self, state):
        self.path = state[""path""]
        self.treepath = state[""treepath""]
        self.tree = None
        self.interpretation = state[""interpretation""]
        self.flatten = state[""flatten""]
        self.awkwardlib = state[""awkwardlib""]
        self.basketcache = None
        self.keycache = None
        self.executor = None
        self._init()

    def __call__(self, branch, entrystart, entrystop):
        return self.tree[branch].array(interpretation=self.interpretation[branch], entrystart=entrystart, entrystop=entrystop, flatten=self.flatten, awkwardlib=self.awkwardlib, cache=None, basketcache=self.basketcache, keycache=self.keycache, executor=self.executor)","class _LazyTree(object):


    def __init__(self, path, treepath, tree, interpretation, flatten, awkwardlib, basketcache, keycache, executor):
        pass

    def _init(self):
        pass

    def __getstate__(self):
        pass

    def __setstate__(self, state):
        pass

    def __call__(self, branch, entrystart, entrystop):
        pass

",6,0,snippet_94,1.0,"class _LazyTree(object):

    __slots__ = (""path"", ""treepath"", ""tree"", ""interpretation"", ""flatten"",
                 ""awkwardlib"", ""basketcache"", ""keycache"", ""executor"", ""_initialized"")

    def __init__(self, path, treepath, tree, interpretation,
                 flatten, awkwardlib, basketcache, keycache, executor):
        self.path = path
        self.treepath = treepath
        self.tree = tree
        self.interpretation = interpretation
        self.flatten = flatten
        self.awkwardlib = awkwardlib
        self.basketcache = basketcache
        self.keycache = keycache
        self.executor = executor
        self._initialized = (tree is not None)

    def _init(self):
        if not self._initialized:
            import uproot
            f = uproot.open(self.path)
            self.tree = f[self.treepath]
            self._initialized = True

    def __getstate__(self):
        state = {
            ""path"":        self.path,
            ""treepath"":    self.treepath,
            ""interpretation"": self.interpretation,
            ""flatten"":     self.flatten,
            ""awkwardlib"":  self.awkwardlib,
            ""basketcache"": self.basketcache,
            ""keycache"":    self.keycache,
            ""executor"":    self.executor
        }
        return state

    def __setstate__(self, state):
        self.path = state[""path""]
        self.treepath = state[""treepath""]
        self.interpretation = state[""interpretation""]
        self.flatten = state[""flatten""]
        self.awkwardlib = state[""awkwardlib""]
        self.basketcache = state[""basketcache""]
        self.keycache = state[""keycache""]
        self.executor = state[""executor""]
        self.tree = None
        self._initialized = False

    def __call__(self, branch, entrystart, entrystop):
        self._init()
        arr = self.tree.array(
            branch,
            entry_start=entrystart,
            entry_stop=entrystop,
            library=self.awkwardlib,
            executor=self.executor,
            cache_baskets=self.basketcache,
            cache_keys=self.keycache
        )
        if self.flatten:
            return self.awkwardlib.flatten(arr)
        else:
            return self.interpretation(arr)","class _LazyTree(object):
    def __init__(self, path, treepath, tree, interpretation, flatten, awkwardlib, basketcache, keycache, executor):
        self.path = path
        self.treepath = treepath
        self.tree = tree
        self.interpretation = interpretation
        self.flatten = flatten
        self.awkwardlib = awkwardlib
        self.basketcache = basketcache
        self.keycache = keycache
        self.executor = executor
        self._init()

    def _init(self):
        pass

    def __getstate__(self):
        return (self.path, self.treepath, self.tree, self.interpretation, self.flatten, 
                self.awkwardlib, self.basketcache, self.keycache, self.executor)

    def __setstate__(self, state):
        self.path, self.treepath, self.tree, self.interpretation, self.flatten, \
        self.awkwardlib, self.basketcache, self.keycache, self.executor = state
        self._init()

    def __call__(self, branch, entrystart, entrystop):
        # This would typically fetch data from the tree based on the parameters
        # Implementation would depend on the specific use case
        pass","class _LazyTree(object):
    def __init__(self, path, treepath, tree, interpretation, flatten, awkwardlib, basketcache, keycache, executor):
        self._path = path
        self._treepath = treepath
        self._tree = tree
        self._interpretation = interpretation
        self._flatten = flatten
        self._awkwardlib = awkwardlib
        self._basketcache = basketcache
        self._keycache = keycache
        self._executor = executor
        self._initialized = False

    def _init(self):
        if not self._initialized:
            if self._tree is None:
                import uproot
                file = uproot.open(self._path)
                self._tree = file[self._treepath]
            self._initialized = True

    def __getstate__(self):
        state = self.__dict__.copy()
        # Remove unpicklable entries
        if '_tree' in state and hasattr(state['_tree'], '_file'):
            state['_tree'] = None
        state['_initialized'] = False
        return state

    def __setstate__(self, state):
        self.__dict__.update(state)
        self._initialized = False

    def __call__(self, branch, entrystart, entrystop):
        self._init()
        return self._tree.array(
            branch,
            entrystart=entrystart,
            entrystop=entrystop,
            interpretation=self._interpretation,
            flatten=self._flatten,
            awkwardlib=self._awkwardlib,
            basketcache=self._basketcache,
            keycache=self._keycache,
            executor=self._executor
        )",no_docstr,0.8213333333333332,0.6380697050938339,0.5013477088948787,0.6666666666666666,0.6556462917994633,0.7603485838779956,0.6441048034934498,0.5754923413566739,0.9138500094413757,0.9172210097312927,0.9155324101448059,0.9168828129768372,0.8628855319148941,0.6778523489932886,0.6148648648648649,0.435374149659864,0.6174496644295302,0.43394131435646666,0.8907563025210085,0.7763713080168776,0.6864406779661016,0.9054571390151978,0.8780324459075928,0.8915339708328247,0.880699872970581,0.8115960869565226,0.7165109034267914,0.5642633228840125,0.4668769716088328,0.6355140186915887,0.5067034646667764,0.7737003058103975,0.588957055214724,0.4523076923076923,0.9034278392791748,0.9123694896697998,0.9078766703605652,0.9114673733711243,0.8396151304347828,0.4895364826805477,0.4600791623869314,0.5535934938152801,0.7317073170731707,0.2127659574468085,0.42366538486709,0.3892394458387584,0.3932096736330615,0.4512195121951219,0.4609929078014184,0.3650874980586793,0.1971999563735791,0.206585427661865,0.6097560975609756,0.4468085106382978
735093,serge-sans-paille/pythran,serge-sans-paille_pythran/pythran/cxxgen.py,pythran.cxxgen.TryExcept,"class TryExcept(object):
    def __init__(self, try_, except_):
        self.try_ = try_
        self.except_ = except_

    def generate(self):
        yield ""try""

        for line in self.try_.generate():
            yield line

        for exception in self.except_:
            for line in exception.generate():
                yield ""  "" + line","class TryExcept(object):


    def __init__(self, try_, except_):
        pass

    def generate(self):
        pass

",3,0,snippet_371,0.4444444444444444,"class TryExcept(object):
    def __init__(self, try_, except_):
        self.try_ = try_
        self.except_ = except_

    def generate(self):
        def _lines(block):
            if hasattr(block, 'generate'):
                code = block.generate()
            else:
                code = block
            if isinstance(code, str):
                return code.splitlines()
            if isinstance(code, list):
                result = []
                for part in code:
                    if hasattr(part, 'generate'):
                        sub = part.generate()
                    else:
                        sub = part
                    if isinstance(sub, str):
                        result.extend(sub.splitlines())
                    elif isinstance(sub, list):
                        result.extend(sub)
                    else:
                        result.extend(str(sub).splitlines())
                return result
            return str(code).splitlines()

        try_lines = _lines(self.try_)
        except_lines = _lines(self.except_)

        out = [""try:""]
        out += [""    "" + line for line in try_lines]
        out.append(""except:"")
        out += [""    "" + line for line in except_lines]
        return ""\n"".join(out)","class TryExcept(object):
    def __init__(self, try_, except_):
        self.try_ = try_
        self.except_ = except_

    def generate(self):
        return f""try:\n{self.try_}\nexcept:\n{self.except_}""","class TryExcept(object):

    def __init__(self, try_, except_):
        self.try_ = try_
        self.except_ = except_

    def generate(self):
        try_code = self.try_.generate() if hasattr(self.try_, 'generate') else str(self.try_)
        except_code = self.except_.generate() if hasattr(self.except_, 'generate') else str(self.except_)
        
        return f""try:\n    {try_code}\nexcept:\n    {except_code}""",no_docstr,0.43870967741935474,0.3006535947712418,0.2251655629139073,0.36129032258064514,0.24915159417184493,0.3,0.25096525096525096,0.2054263565891473,0.7019820213317871,0.8717736601829529,0.7777184247970581,0.8511856198310852,0.7448585185185191,0.6666666666666667,0.5625,0.48387096774193555,0.6666666666666667,0.594191199733155,0.8235294117647058,0.7313432835820896,0.6818181818181818,0.8869004249572754,0.822717547416687,0.8536041975021362,0.8287147879600525,0.8356823943661972,0.5106382978723405,0.41304347826086957,0.3555555555555556,0.5106382978723405,0.4540238265123164,0.5079365079365079,0.448,0.4112903225806452,0.8433653712272644,0.8620664477348328,0.8526133894920349,0.860159158706665,0.8109984536082474,0.5178289892855493,0.1809238494354065,0.5139352312499142,0.5128205128205128,0.8636363636363636,0.3451266098214766,0.262643087508904,0.3497980837117344,0.358974358974359,0.4090909090909091,0.5018833524384316,0.3721875404942064,0.3497980837117344,0.5128205128205128,0.7727272727272727
338425,devopshq/youtrack,devopshq_youtrack/youtrack/youtrack.py,youtrack.youtrack.Py3Cmp,"class Py3Cmp:
    def __eq__(self, other):
        return self.__cmp__(other) == 0

    def __ne__(self, other):
        return self.__cmp__(other) != 0

    def __gt__(self, other):
        return self.__cmp__(other) > 0

    def __lt__(self, other):
        return self.__cmp__(other) < 0

    def __ge__(self, other):
        return self.__cmp__(other) >= 0

    def __le__(self, other):
        return self.__cmp__(other) <= 0","class Py3Cmp:


    def __eq__(self, other):
        pass

    def __ne__(self, other):
        pass

    def __gt__(self, other):
        pass

    def __lt__(self, other):
        pass

    def __ge__(self, other):
        pass

    def __le__(self, other):
        pass

",7,0,snippet_637,1.0,"class Py3Cmp:
    def __eq__(self, other):
        try:
            r = self.cmp(other)
        except Exception:
            return NotImplemented
        return r == 0

    def __ne__(self, other):
        try:
            r = self.cmp(other)
        except Exception:
            return NotImplemented
        return r != 0

    def __lt__(self, other):
        try:
            r = self.cmp(other)
        except Exception:
            return NotImplemented
        return r < 0

    def __le__(self, other):
        try:
            r = self.cmp(other)
        except Exception:
            return NotImplemented
        return r <= 0

    def __gt__(self, other):
        try:
            r = self.cmp(other)
        except Exception:
            return NotImplemented
        return r > 0

    def __ge__(self, other):
        try:
            r = self.cmp(other)
        except Exception:
            return NotImplemented
        return r >= 0","class Py3Cmp:
    def __eq__(self, other):
        return NotImplemented

    def __ne__(self, other):
        return NotImplemented

    def __gt__(self, other):
        return NotImplemented

    def __lt__(self, other):
        return NotImplemented

    def __ge__(self, other):
        return NotImplemented

    def __le__(self, other):
        return NotImplemented","class Py3Cmp:
    def __init__(self, obj, *args):
        self.obj = obj

    def __eq__(self, other):
        return self.obj == other.obj

    def __ne__(self, other):
        return self.obj != other.obj

    def __gt__(self, other):
        return self.obj > other.obj

    def __lt__(self, other):
        return self.obj < other.obj

    def __ge__(self, other):
        return self.obj >= other.obj

    def __le__(self, other):
        return self.obj <= other.obj",no_docstr,0.7272727272727273,0.4868421052631578,0.33333333333333337,0.5974025974025974,0.5546897042700616,0.6907216494845361,0.5647668393782384,0.4375,0.7585936784744263,0.9249612092971802,0.8335573077201843,0.9051111340522766,0.812501875,0.6808510638297872,0.5652173913043479,0.4444444444444445,0.6808510638297872,0.389920463235775,0.9318181818181818,0.8735632183908046,0.813953488372093,0.8286444544792175,0.8824386596679688,0.8546958565711975,0.8767470121383667,0.8510653191489362,0.7333333333333334,0.5423728813559321,0.4310344827586207,0.7333333333333334,0.6169245950386816,0.7837837837837838,0.6462585034013606,0.5684931506849316,0.890533447265625,0.8980387449264526,0.8942703008651733,0.8972825407981873,0.8758182352941176,0.5338986851231207,0.2095077990540776,0.4554987061442874,0.4705882352941176,1.0,0.3659741467262846,0.350297614382089,0.39595191369952,0.1176470588235294,0.6,0.4681205951315472,0.3020468213529148,0.3684747748595485,0.2352941176470588,0.9666666666666668
737982,shymonk/django-datatable,shymonk_django-datatable/table/columns/base.py,table.columns.base.ColumnHeader,"class ColumnHeader(object):
    def __init__(self, text=None, attrs=None, row_order=0):
        self.text = text
        self.base_attrs = attrs or {}
        self.row_order = row_order

    @property
    def attrs(self):
        return AttributesDict(self.base_attrs).render()","class ColumnHeader(object):


    def __init__(self, text=None, attrs=None, row_order=0):
        pass

    @property
    def attrs(self):
        pass

",4,0,snippet_694,0.8,"class ColumnHeader(object):

    def __init__(self, text=None, attrs=None, row_order=0):
        self.text = text
        self._attrs = {} if attrs is None else dict(attrs)
        self.row_order = row_order

    @property
    def attrs(self):
        return self._attrs","class ColumnHeader(object):

    def __init__(self, text=None, attrs=None, row_order=0):
        self._text = text
        self._attrs = attrs or {}
        self._row_order = row_order

    @property
    def attrs(self):
        return self._attrs","class ColumnHeader(object):

    def __init__(self, text=None, attrs=None, row_order=0):
        self.text = text
        self._attrs = attrs if attrs is not None else {}
        self.row_order = row_order

    @property
    def attrs(self):
        return self._attrs",no_docstr,0.8493150684931507,0.7042253521126761,0.6666666666666666,0.8493150684931507,0.800051308499261,0.918918918918919,0.821917808219178,0.7361111111111112,0.9381324052810669,0.9247332215309143,0.9313845634460449,0.9260558485984802,0.9152550847457628,0.9411764705882353,0.8484848484848486,0.8125,0.9411764705882353,0.8067482935563655,0.9710144927536232,0.8970588235294118,0.8208955223880597,0.9748924970626831,0.9343404769897461,0.9541858434677124,0.9382432103157043,0.960452372881356,0.8493150684931507,0.732394366197183,0.6666666666666666,0.8493150684931507,0.8103208419585446,0.9166666666666666,0.8591549295774648,0.8,0.9416823387145996,0.9274259805679321,0.9344998002052307,0.9288321137428284,0.9378537288135593,0.6389622286804845,0.564926870711699,0.6639682960038593,0.4848484848484848,0.8421052631578947,0.6529785454975117,0.5861137788133826,0.5999630826025019,0.6363636363636364,0.7894736842105263,0.6560210569487908,0.583899712825618,0.7132307669631657,0.4848484848484848,0.8421052631578947
632406,pantsbuild/pex,pantsbuild_pex/pex/commands/command.py,pex.commands.command.JsonMixin,"class JsonMixin(object):
    @staticmethod
    def add_json_options(
        parser,  # type: _ActionsContainer
        entity,  # type: str
        include_switch=True,  # type: bool
    ):
        flags = (""-i"", ""--indent"") if include_switch else (""--indent"",)
        parser.add_argument(
            *flags,
            type=int,
            default=None,
            help=""Pretty-print {entity} json with the given indent."".format(entity=entity)
        )

    @staticmethod
    def dump_json(
        options,  # type: Namespace
        data,  # type: Dict[str, Any]
        out,  # type: IO
        **json_dump_kwargs  # type: Any
    ):
        if options.indent is not None and options.indent > 0:
            # Python 2.7 uses ', ' for the list item separator regardless of indent which is
            # different from Python 3 and leads to trailing whitespace in the output; so, we
            # normalize here to the Python 3 style for consistent, more generally useful output.
            json_dump_kwargs.update(separators=("","", "": ""))
        json.dump(data, out, indent=options.indent, **json_dump_kwargs)","class JsonMixin(object):


    @staticmethod
    def add_json_options(
        parser,  # type: _ActionsContainer
        entity,  # type: str
        include_switch=True,  # type: bool
    ):
        pass

    @staticmethod
    def dump_json(
        options,  # type: Namespace
        data,  # type: Dict[str, Any]
        out,  # type: IO
        **json_dump_kwargs  # type: Any
    ):
        pass

",5,0,snippet_476,0.5,"class JsonMixin(object):

    @staticmethod
    def add_json_options(
        parser,  # type: _ActionsContainer
        entity,  # type: str
        include_switch=True,  # type: bool
    ):
        if include_switch:
            parser.add_argument(
                '--%s-json' % entity,
                action='store_true',
                dest='json',
                help='Output %s as JSON' % entity,
            )
        parser.add_argument(
            '--json-indent',
            type=int,
            default=None,
            dest='json_indent',
            help='Indentation level for JSON output',
        )
        parser.add_argument(
            '--json-sort-keys',
            action='store_true',
            default=False,
            dest='json_sort_keys',
            help='Sort the JSON output keys',
        )

    @staticmethod
    def dump_json(
        options,  # type: Namespace
        data,  # type: Dict[str, Any]
        out,  # type: IO
        **json_dump_kwargs  # type: Any
    ):
        if getattr(options, 'json', True) is False:
            return False
        indent = getattr(options, 'json_indent', None)
        sort_keys = getattr(options, 'json_sort_keys', False)
        json_dump_kwargs.setdefault('indent', indent)
        json_dump_kwargs.setdefault('sort_keys', sort_keys)
        if 'separators' not in json_dump_kwargs and indent is None:
            json_dump_kwargs['separators'] = (',', ':')
        json.dump(data, out, **json_dump_kwargs)
        out.write('\n')
        return True","class JsonMixin(object):

    @staticmethod
    def add_json_options(
        parser,  # type: _ActionsContainer
        entity,  # type: str
        include_switch=True,  # type: bool
    ):
        if include_switch:
            parser.add_argument(
                '--json',
                action='store_true',
                help=f'Output {entity} information in JSON format'
            )
        parser.add_argument(
            '--indent',
            type=int,
            default=2,
            help='JSON indentation level (default: 2)'
        )
        parser.add_argument(
            '--compact',
            action='store_true',
            help='Output compact JSON without extra whitespace'
        )

    @staticmethod
    def dump_json(
        options,  # type: Namespace
        data,  # type: Dict[str, Any]
        out,  # type: IO
        **json_dump_kwargs  # type: Any
    ):
        if hasattr(options, 'compact') and options.compact:
            json_dump_kwargs.setdefault('separators', (',', ':'))
            json_dump_kwargs.setdefault('indent', None)
        elif hasattr(options, 'indent'):
            json_dump_kwargs.setdefault('indent', options.indent)
        
        json.dump(data, out, **json_dump_kwargs)
        out.write('\n')","class JsonMixin(object):

    @staticmethod
    def add_json_options(
        parser,  # type: _ActionsContainer
        entity,  # type: str
        include_switch=True,  # type: bool
    ):
        if include_switch:
            parser.add_argument(
                '--json',
                action='store_true',
                help=f'Output {entity} in JSON format'
            )
        parser.add_argument(
            '--json-indent',
            type=int,
            metavar='N',
            help='JSON output indentation level'
        )
        parser.add_argument(
            '--json-sort-keys',
            action='store_true',
            help='Sort JSON output keys'
        )

    @staticmethod
    def dump_json(
        options,  # type: Namespace
        data,  # type: Dict[str, Any]
        out,  # type: IO
        **json_dump_kwargs  # type: Any
    ):
        dump_kwargs = json_dump_kwargs.copy()
        
        if hasattr(options, 'json_indent') and options.json_indent is not None:
            dump_kwargs['indent'] = options.json_indent
        
        if hasattr(options, 'json_sort_keys') and options.json_sort_keys:
            dump_kwargs['sort_keys'] = True
        
        json.dump(data, out, **dump_kwargs)",no_docstr,0.5762711864406779,0.3754266211604096,0.3161512027491408,0.4813559322033898,0.4438830807874227,0.560126582278481,0.41904761904761906,0.37261146496815284,0.8335344791412354,0.8255814909934998,0.829538881778717,0.8263699412345886,0.7814229508196721,0.6147859922178989,0.4470588235294118,0.3715415019762846,0.5136186770428014,0.5443584870687151,0.6705882352941176,0.515748031496063,0.466403162055336,0.8680973052978516,0.8382898569107056,0.8529332280158997,0.8411781191825867,0.8037244670050762,0.5931558935361216,0.4137931034482759,0.3243243243243243,0.5095057034220533,0.5405898001630112,0.6979591836734694,0.5286885245901639,0.4609053497942387,0.8615291118621826,0.8286791443824768,0.8447849154472351,0.8318510055541992,0.811113,0.4930126657107422,0.3519935687532285,0.3629949471970848,0.423728813559322,0.8333333333333334,0.4091161367362055,0.3248265380500602,0.338191681211146,0.4067796610169492,0.5666666666666667,0.4090678267380505,0.3291685016815151,0.3506056301294439,0.3898305084745763,0.5666666666666667
150098,MasoniteFramework/masonite,MasoniteFramework_masonite/src/masonite/api/authentication/AuthenticatesTokens.py,src.masonite.api.authentication.AuthenticatesTokens.AuthenticatesTokens,"class AuthenticatesTokens:

    __TOKEN_COLUMN__ = ""api_token""

    def generate_jwt(self):
        token = Api.generate_token()

        setattr(self, self.__TOKEN_COLUMN__, token)
        self.save()
        return token

    def attempt_by_token(self, token):
        return self.where(self.__TOKEN_COLUMN__, token).first()","class AuthenticatesTokens:


    def generate_jwt(self):
        pass

    def attempt_by_token(self, token):
        pass

",3,0,snippet_313,1.0,"class AuthenticatesTokens:
    def __init__(self, payload, secret_key, algorithm='HS256', expiration=3600):
        self.payload = payload
        self.secret_key = secret_key
        self.algorithm = algorithm
        self.expiration = expiration

    def generate_jwt(self):
        data = self.payload.copy()
        data['exp'] = datetime.utcnow() + timedelta(seconds=self.expiration)
        token = jwt.encode(data, self.secret_key, algorithm=self.algorithm)
        if isinstance(token, bytes):
            token = token.decode('utf-8')
        return token

    def attempt_by_token(self, token):
        try:
            return jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
        except (jwt.ExpiredSignatureError, jwt.InvalidTokenError):
            return None","class AuthenticatesTokens:
    def __init__(self, secret_key: str = ""your-secret-key"", algorithm: str = ""HS256""):
        self.secret_key = secret_key
        self.algorithm = algorithm
        self.authenticated_user = None

    def generate_jwt(self, user_id: int, expires_in: int = 3600) -> str:
        """"""
        Generate a JWT token for the given user ID.
        
        Args:
            user_id: The ID of the user
            expires_in: Token expiration time in seconds (default: 1 hour)
            
        Returns:
            str: The generated JWT token
        """"""
        payload = {
            'user_id': user_id,
            'exp': datetime.datetime.utcnow() + datetime.timedelta(seconds=expires_in),
            'iat': datetime.datetime.utcnow()
        }
        token = jwt.encode(payload, self.secret_key, algorithm=self.algorithm)
        return token

    def attempt_by_token(self, token: str) -> Optional[Dict[str, Any]]:
        """"""
        Attempt to authenticate a user by JWT token.
        
        Args:
            token: The JWT token to validate
            
        Returns:
            dict: User data if token is valid, None otherwise
        """"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            user_id = payload.get('user_id')
            
            # Simulate user lookup - in a real implementation, you'd query a database
            if user_id:
                self.authenticated_user = {
                    'id': user_id,
                    'authenticated': True
                }
                return self.authenticated_user
            
        except jwt.ExpiredSignatureError:
            # Token has expired
            pass
        except jwt.InvalidTokenError:
            # Token is invalid
            pass
            
        self.authenticated_user = None
        return None","class AuthenticatesTokens:
    def __init__(self, secret_key: str = ""default_secret_key"", algorithm: str = ""HS256""):
        self.secret_key = secret_key
        self.algorithm = algorithm

    def generate_jwt(self, payload: Optional[Dict[str, Any]] = None, expires_in: int = 3600) -> str:
        if payload is None:
            payload = {}
        
        # Add expiration time
        payload['exp'] = datetime.datetime.utcnow() + datetime.timedelta(seconds=expires_in)
        payload['iat'] = datetime.datetime.utcnow()
        
        return jwt.encode(payload, self.secret_key, algorithm=self.algorithm)

    def attempt_by_token(self, token: str) -> Optional[Dict[str, Any]]:
        try:
            decoded_payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            return decoded_payload
        except jwt.ExpiredSignatureError:
            return None
        except jwt.InvalidTokenError:
            return None
        except Exception:
            return None",no_docstr,0.4,0.19512195121951217,0.1322314049586777,0.35200000000000004,0.23383130296234722,0.3850574712643678,0.21965317919075145,0.1511627906976744,0.6918171644210815,0.7544102072715759,0.7217592000961304,0.7476457953453064,0.7813874675324676,0.24267782426778245,0.10970464135021098,0.06808510638297872,0.19246861924686193,0.10689057941197826,0.21329639889196675,0.10277777777777777,0.055710306406685235,0.6244627237319946,0.7519378662109375,0.6822972297668457,0.7368952035903931,0.7356348275862071,0.2702702702702703,0.136986301369863,0.08333333333333333,0.2162162162162162,0.15086796347535286,0.3125,0.14349775784753363,0.07657657657657657,0.6292921304702759,0.7265684008598328,0.6744407415390015,0.7155080437660217,0.7456165789473687,0.2857388086142732,0.0887141864447582,0.2535874532410928,0.4117647058823529,0.3888888888888889,0.2608214320964007,0.019220196639668,0.1743923291315555,0.2941176470588235,0.5555555555555556,0.2235342159629375,0.008193962108645,0.0362696991287257,0.2941176470588235,0.5555555555555556
42511,Azure/azure-sdk-for-python,Azure_azure-sdk-for-python/sdk/communication/azure-communication-jobrouter/tests/_validators.py,_validators.LabelOperatorValidator,"class LabelOperatorValidator(object):
    @staticmethod
    def validate_label_operator(actual, expected, **kwargs):
        try:
            assert actual == expected
        except AssertionError:
            assert LabelOperator._value2member_map_[actual] == LabelOperator.__getattr__(expected.split(""."", 1)[1])","class LabelOperatorValidator(object):


    @staticmethod
    def validate_label_operator(actual, expected, **kwargs):
        pass

",3,0,snippet_378,0.625,"class LabelOperatorValidator(object):

    @staticmethod
    def validate_label_operator(actual, expected, **kwargs):
        # Handle None values
        if actual is None and expected is None:
            return True
        if actual is None or expected is None:
            if not kwargs.get('allow_none', False):
                raise AssertionError(f""Actual or expected operator is None: actual={actual}, expected={expected}"")
            return True

        # Normalize synonyms
        _synonyms = {
            '=': '==', 'equals': '==', '==': '==',
            '!=': '!=', 'not_equals': '!=',
            'in': 'in', 'notin': 'notin',
            'exists': 'exists', 'has': 'exists'
        }
        def _norm(op):
            return _synonyms.get(op, op)

        actual_norm = _norm(actual)

        # Compare against single or multiple expected values
        if isinstance(expected, (list, tuple, set)):
            expected_norms = {_norm(e) for e in expected}
            if actual_norm not in expected_norms:
                raise AssertionError(f""Operator '{actual}' not in expected set {expected}"")
        else:
            expected_norm = _norm(expected)
            if actual_norm != expected_norm:
                raise AssertionError(f""Operator '{actual}' does not match expected '{expected}'"")

        return True","class LabelOperatorValidator(object):

    @staticmethod
    def validate_label_operator(actual, expected, **kwargs):
        """"""
        Validate label operator based on actual and expected values.
        
        Args:
            actual: The actual value to validate
            expected: The expected value or pattern
            **kwargs: Additional validation parameters
            
        Returns:
            bool: True if validation passes, False otherwise
        """"""
        # Handle None values
        if actual is None and expected is None:
            return True
        if actual is None or expected is None:
            return False
            
        # Handle string comparisons
        if isinstance(actual, str) and isinstance(expected, str):
            return actual == expected
            
        # Handle numeric comparisons
        if isinstance(actual, (int, float)) and isinstance(expected, (int, float)):
            return actual == expected
            
        # Handle list/tuple comparisons
        if isinstance(actual, (list, tuple)) and isinstance(expected, (list, tuple)):
            if len(actual) != len(expected):
                return False
            return all(LabelOperatorValidator.validate_label_operator(a, e, **kwargs) 
                      for a, e in zip(actual, expected))
            
        # Handle dictionary comparisons
        if isinstance(actual, dict) and isinstance(expected, dict):
            if set(actual.keys()) != set(expected.keys()):
                return False
            return all(LabelOperatorValidator.validate_label_operator(actual[key], expected[key], **kwargs)
                      for key in actual.keys())
        
        # Default comparison
        return actual == expected","class LabelOperatorValidator(object):

    @staticmethod
    def validate_label_operator(actual, expected, **kwargs):
        if actual is None and expected is None:
            return True
        
        if actual is None or expected is None:
            return False
        
        if isinstance(expected, str):
            return str(actual) == expected
        
        if isinstance(expected, (int, float)):
            return actual == expected
        
        if isinstance(expected, bool):
            return bool(actual) == expected
        
        if isinstance(expected, list):
            return actual in expected
        
        if isinstance(expected, dict):
            operator = expected.get('operator', 'eq')
            value = expected.get('value')
            
            if operator == 'eq':
                return actual == value
            elif operator == 'ne':
                return actual != value
            elif operator == 'gt':
                return actual > value
            elif operator == 'gte':
                return actual >= value
            elif operator == 'lt':
                return actual < value
            elif operator == 'lte':
                return actual <= value
            elif operator == 'in':
                return actual in value
            elif operator == 'not_in':
                return actual not in value
            elif operator == 'contains':
                return value in actual
            elif operator == 'startswith':
                return str(actual).startswith(str(value))
            elif operator == 'endswith':
                return str(actual).endswith(str(value))
            elif operator == 'regex':
                import re
                return bool(re.search(str(value), str(actual)))
        
        return str(actual) == str(expected)",no_docstr,0.19047619047619044,0.1325301204819277,0.10975609756097561,0.19047619047619044,0.11092533192333281,0.17627118644067796,0.09863945578231292,0.07849829351535836,0.6568467020988464,0.8301792144775391,0.7334108352661133,0.8088352084159851,0.7038597107438026,0.14705882352941177,0.10891089108910891,0.09,0.14705882352941177,0.11116120884613678,0.17197452229299362,0.09584664536741214,0.08333333333333333,0.6662659645080566,0.8062981367111206,0.7296239733695984,0.7897005677223206,0.7145243069306944,0.15075376884422112,0.11167512690355332,0.09230769230769231,0.15075376884422112,0.10595618409836562,0.14705882352941177,0.09836065573770492,0.08223684210526316,0.637843132019043,0.8044493794441223,0.7115234732627869,0.7839717864990234,0.6985168152866245,0.4220619577644348,0.0453192148012697,0.3215000448278979,0.3214285714285714,1.0,0.4253435650594559,0.0438789641277616,0.3717810103957765,0.2857142857142857,1.0,0.433732061470349,0.041718664057048,0.3717810103957765,0.3214285714285714,1.0
519954,joshua-stone/DerPyBooru,joshua-stone_DerPyBooru/derpibooru/query.py,derpibooru.query.Query_Field,"class Query_Field(object):
  def __init__(self, name, is_neg=False):
    self.name = name
    self.is_neg = is_neg

  def __neg__(self):
    return self.__class__(self.name, is_neg=True)","class Query_Field(object):


  def __init__(self, name, is_neg=False):
    pass

  def __neg__(self):
    pass

",3,0,snippet_187,1.0,"class Query_Field(object):

    def __init__(self, name, is_neg=False):
        self.name = name
        self.is_neg = bool(is_neg)

    def __neg__(self):
        return Query_Field(self.name, not self.is_neg)","class Query_Field(object):
    def __init__(self, name, is_neg=False):
        self.name = name
        self.is_neg = is_neg

    def __neg__(self):
        return Query_Field(self.name, not self.is_neg)","class Query_Field(object):

    def __init__(self, name, is_neg=False):
        self.name = name
        self.is_neg = is_neg

    def __neg__(self):
        return Query_Field(self.name, not self.is_neg)",no_docstr,0.9032258064516129,0.7666666666666667,0.6551724137931035,0.870967741935484,0.8171353282114887,0.9142857142857143,0.8115942028985508,0.7352941176470589,0.9530999660491943,0.9524655342102051,0.9527826905250549,0.9525290727615356,0.9420295652173912,0.9180327868852459,0.8135593220338982,0.736842105263158,0.8852459016393444,0.8473884740720197,0.9552238805970149,0.8787878787878788,0.8307692307692308,0.965512752532959,0.9579153060913086,0.9616990089416504,0.9586696028709412,0.962121590909091,0.9180327868852459,0.8135593220338982,0.736842105263158,0.8852459016393444,0.8473884740720197,0.9552238805970149,0.8787878787878788,0.8307692307692308,0.9653063416481018,0.9575400352478027,0.961407482624054,0.9583109617233276,0.962121590909091,0.5617090891965962,0.6540585844910979,0.7138957847176474,0.5217391304347826,0.3571428571428571,0.6667650286183626,0.8172460049207133,0.8839756002359669,0.6086956521739131,0.3571428571428571,0.6667650286183626,0.8172460049207133,0.8839756002359669,0.6086956521739131,0.3571428571428571
381290,falkr/stmpy,falkr_stmpy/examples/examples.py,examples.examples.Blink,"class Blink:
    def on(self):
        print(""on"")
        self.stm.start_timer(""t"", 1000)

    def off(self):
        print(""off"")
        self.stm.start_timer(""t"", 1000)","class Blink:


    def on(self):
        pass

    def off(self):
        pass

",3,0,snippet_226,1.0,"class Blink:
    def __init__(self, interval=1.0, callback=None):
        self.interval = interval
        self.callback = callback or self._default_callback
        self._stop_event = threading.Event()
        self._thread = None

    def _default_callback(self, state):
        print(f""{'ON' if state else 'OFF'}"")

    def _run(self):
        state = False
        while not self._stop_event.is_set():
            state = not state
            self.callback(state)
            time.sleep(self.interval)

    def on(self):
        if self._thread is None or not self._thread.is_alive():
            self._stop_event.clear()
            self._thread = threading.Thread(target=self._run)
            self._thread.daemon = True
            self._thread.start()

    def off(self):
        if self._thread and self._thread.is_alive():
            self._stop_event.set()
            self._thread.join()","class Blink:
    def __init__(self):
        self._is_on = False

    def on(self):
        self._is_on = True
        return self

    def off(self):
        self._is_on = False
        return self

    def is_on(self):
        return self._is_on

    def is_off(self):
        return not self._is_on

    def toggle(self):
        self._is_on = not self._is_on
        return self","class Blink:
    def __init__(self):
        self.state = False
    
    def on(self):
        self.state = True
    
    def off(self):
        self.state = False",no_docstr,0.20588235294117646,0.08955223880597016,0.04545454545454545,0.17647058823529413,0.10384649505662202,0.1630901287553648,0.09913793103448276,0.06926406926406926,0.6059262156486511,0.7535399198532104,0.671718955039978,0.735619068145752,0.7154500000000008,0.3,0.20512820512820512,0.07894736842105263,0.3,0.17127903769599417,0.3177570093457944,0.1509433962264151,0.10476190476190476,0.7672498226165771,0.7656155228614807,0.7664318084716797,0.7657786011695862,0.6929855263157895,0.45454545454545453,0.28571428571428575,0.15,0.45454545454545453,0.28161404440427223,0.6097560975609756,0.4,0.28205128205128205,0.8411849737167358,0.7983244061470032,0.8191943764686584,0.8024129271507263,0.7500025,0.2239428451785605,0.0190053027940864,0.1319384917132592,0.3448275862068966,0.4,0.1759964942415898,0.0341164507703413,0.1319384917132592,0.1379310344827586,0.4,0.1625951565681193,0.0805111000764593,0.1319384917132592,0.1379310344827586,0.3
531933,kinegratii/django-echarts,kinegratii_django-echarts/django_echarts/utils/burl.py,django_echarts.utils.burl.BUrl,"class BUrl:
    def __init__(self, url):
        self._url = url
        self._scheme, self._netloc, self._path, self._query_string, self._fragment = urlsplit(url)
        self._query_params = parse_qs(self._query_string)

    def replace(self, name, value, only_replace=False):
        if name not in self._query_params:
            if only_replace:
                return self
            self._query_params[name] = []
        self._query_params[name] = [value]
        return self

    def append(self, name, value):
        if name not in self._query_params:
            self._query_params[name] = []
        self._query_params[name].append(value)
        return self

    def delete(self, name):
        if name in self._query_params:
            del self._query_params[name]
        return self

    @property
    def url(self):
        new_query_string = urlencode(self._query_params, doseq=True)
        return urlunsplit((self._scheme, self._netloc, self._path, new_query_string, self._fragment))","class BUrl:


    def __init__(self, url):
        pass

    def replace(self, name, value, only_replace=False):
        pass

    def append(self, name, value):
        pass

    def delete(self, name):
        pass

    @property
    def url(self):
        pass

",7,0,snippet_713,0.25,"class BUrl:
    def __init__(self, url):
        self._parsed = urlparse(url)
        self._params = parse_qsl(self._parsed.query, keep_blank_values=True)

    def replace(self, name, value, only_replace=False):
        value = str(value)
        found = False
        new_params = []
        for k, v in self._params:
            if k == name:
                if not found:
                    new_params.append((name, value))
                    found = True
            else:
                new_params.append((k, v))
        self._params = new_params
        if not found and not only_replace:
            self._params.append((name, value))

    def append(self, name, value):
        self._params.append((name, str(value)))

    def delete(self, name):
        self._params = [(k, v) for k, v in self._params if k != name]

    @property
    def url(self):
        query = urlencode(self._params, doseq=True)
        parts = (
            self._parsed.scheme,
            self._parsed.netloc,
            self._parsed.path,
            self._parsed.params,
            query,
            self._parsed.fragment
        )
        return urlunparse(parts)","class BUrl:
    def __init__(self, url):
        self._url = url
        parsed = urlparse(url)
        self._scheme = parsed.scheme
        self._netloc = parsed.netloc
        self._path = parsed.path
        self._params = parsed.params
        self._query = parsed.query
        self._fragment = parsed.fragment
        self._query_params = parse_qs(parsed.query, keep_blank_values=True)

    def replace(self, name, value, only_replace=False):
        if only_replace and name not in self._query_params:
            return self
        self._query_params[name] = [str(value)]
        return self

    def append(self, name, value):
        if name in self._query_params:
            self._query_params[name].append(str(value))
        else:
            self._query_params[name] = [str(value)]
        return self

    def delete(self, name):
        if name in self._query_params:
            del self._query_params[name]
        return self

    @property
    def url(self):
        query_string = urlencode(self._query_params, doseq=True)
        return urlunparse((
            self._scheme,
            self._netloc,
            self._path,
            self._params,
            query_string,
            self._fragment
        ))","class BUrl:
    def __init__(self, url):
        self._parsed = urlparse(url)
        self._params = parse_qs(self._parsed.query, keep_blank_values=True)
    
    def replace(self, name, value, only_replace=False):
        if only_replace and name not in self._params:
            return self
        
        new_burl = BUrl(self.url)
        new_burl._params[name] = [str(value)]
        return new_burl
    
    def append(self, name, value):
        new_burl = BUrl(self.url)
        if name in new_burl._params:
            new_burl._params[name].append(str(value))
        else:
            new_burl._params[name] = [str(value)]
        return new_burl
    
    def delete(self, name):
        new_burl = BUrl(self.url)
        if name in new_burl._params:
            del new_burl._params[name]
        return new_burl
    
    @property
    def url(self):
        query_string = urlencode(self._params, doseq=True)
        return urlunparse((
            self._parsed.scheme,
            self._parsed.netloc,
            self._parsed.path,
            self._parsed.params,
            query_string,
            self._parsed.fragment
        ))",no_docstr,0.6463878326996197,0.29885057471264376,0.1544401544401544,0.532319391634981,0.49697510371793946,0.6947368421052632,0.5,0.35335689045936397,0.8269053101539612,0.8701039552688599,0.8479547500610352,0.8655820488929749,0.7944220264317186,0.8717948717948717,0.7453874538745388,0.62453531598513,0.8131868131868132,0.7644755791173315,0.847972972972973,0.7593220338983051,0.6938775510204082,0.9051500558853149,0.9263904094696045,0.915647029876709,0.9242215752601624,0.8834819911504423,0.7089552238805971,0.4511278195488721,0.2575757575757575,0.626865671641791,0.5977528439133211,0.78125,0.5923344947735192,0.46153846153846156,0.8310791254043579,0.9031378030776978,0.8656114339828491,0.8953744769096375,0.8638511267605634,0.2350391220019622,0.1377337863105797,0.1806278299023972,0.4166666666666667,0.2051282051282051,0.5247863295918695,0.4593956382136204,0.5588201929743707,0.59375,0.4871794871794871,0.3466338369894452,0.209413536341124,0.2324102731551184,0.5729166666666666,0.3717948717948718
519230,jopohl/urh,jopohl_urh/src/urh/ui/ui_modulation.py,urh.ui.ui_modulation.Ui_DialogModulation,"class Ui_DialogModulation(object):
    def setupUi(self, DialogModulation):
        DialogModulation.setObjectName(""DialogModulation"")
        DialogModulation.resize(977, 1041)
        icon = QtGui.QIcon()
        icon.addPixmap(
            QtGui.QPixmap("":/icons/icons/modulation.svg""),
            QtGui.QIcon.Normal,
            QtGui.QIcon.Off,
        )
        DialogModulation.setWindowIcon(icon)
        self.verticalLayout = QtWidgets.QVBoxLayout(DialogModulation)
        self.verticalLayout.setObjectName(""verticalLayout"")
        self.gridLayout_5 = QtWidgets.QGridLayout()
        self.gridLayout_5.setObjectName(""gridLayout_5"")
        self.comboBoxCustomModulations = QtWidgets.QComboBox(DialogModulation)
        self.comboBoxCustomModulations.setEditable(True)
        self.comboBoxCustomModulations.setInsertPolicy(
            QtWidgets.QComboBox.InsertAtCurrent
        )
        self.comboBoxCustomModulations.setSizeAdjustPolicy(
            QtWidgets.QComboBox.AdjustToContents
        )
        self.comboBoxCustomModulations.setObjectName(""comboBoxCustomModulations"")
        self.comboBoxCustomModulations.addItem("""")
        self.gridLayout_5.addWidget(self.comboBoxCustomModulations, 0, 0, 1, 1)
        self.btnAddModulation = QtWidgets.QToolButton(DialogModulation)
        icon = QtGui.QIcon.fromTheme(""list-add"")
        self.btnAddModulation.setIcon(icon)
        self.btnAddModulation.setObjectName(""btnAddModulation"")
        self.gridLayout_5.addWidget(self.btnAddModulation, 0, 1, 1, 1)
        self.btnRemoveModulation = QtWidgets.QToolButton(DialogModulation)
        icon = QtGui.QIcon.fromTheme(""list-remove"")
        self.btnRemoveModulation.setIcon(icon)
        self.btnRemoveModulation.setObjectName(""btnRemoveModulation"")
        self.gridLayout_5.addWidget(self.btnRemoveModulation, 0, 2, 1, 1)
        self.verticalLayout.addLayout(self.gridLayout_5)
        self.scrollArea = QtWidgets.QScrollArea(DialogModulation)
        self.scrollArea.setFrameShape(QtWidgets.QFrame.NoFrame)
        self.scrollArea.setWidgetResizable(True)
        self.scrollArea.setObjectName(""scrollArea"")
        self.scrollAreaWidgetContents_2 = QtWidgets.QWidget()
        self.scrollAreaWidgetContents_2.setGeometry(QtCore.QRect(0, 0, 965, 984))
        self.scrollAreaWidgetContents_2.setObjectName(""scrollAreaWidgetContents_2"")
        self.gridLayout_7 = QtWidgets.QGridLayout(self.scrollAreaWidgetContents_2)
        self.gridLayout_7.setObjectName(""gridLayout_7"")
        self.label_5 = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.label_5.setFont(font)
        self.label_5.setObjectName(""label_5"")
        self.gridLayout_7.addWidget(self.label_5, 2, 0, 1, 1)
        self.lEqual = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.lEqual.sizePolicy().hasHeightForWidth())
        self.lEqual.setSizePolicy(sizePolicy)
        self.lEqual.setMaximumSize(QtCore.QSize(32, 32))
        self.lEqual.setText("""")
        self.lEqual.setPixmap(QtGui.QPixmap("":/icons/icons/equals.svg""))
        self.lEqual.setScaledContents(True)
        self.lEqual.setAlignment(QtCore.Qt.AlignCenter)
        self.lEqual.setObjectName(""lEqual"")
        self.gridLayout_7.addWidget(self.lEqual, 4, 2, 1, 1)
        self.label_6 = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.label_6.setFont(font)
        self.label_6.setObjectName(""label_6"")
        self.gridLayout_7.addWidget(self.label_6, 4, 0, 1, 1)
        spacerItem = QtWidgets.QSpacerItem(
            40, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum
        )
        self.gridLayout_7.addItem(spacerItem, 8, 1, 1, 1)
        self.label_7 = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.label_7.setFont(font)
        self.label_7.setObjectName(""label_7"")
        self.gridLayout_7.addWidget(self.label_7, 8, 0, 1, 1)
        spacerItem1 = QtWidgets.QSpacerItem(
            40, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum
        )
        self.gridLayout_7.addItem(spacerItem1, 2, 3, 1, 1)
        spacerItem2 = QtWidgets.QSpacerItem(
            40, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum
        )
        self.gridLayout_7.addItem(spacerItem2, 4, 1, 1, 1)
        self.label_4 = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        font = QtGui.QFont()
        font.setBold(True)
        font.setWeight(75)
        self.label_4.setFont(font)
        self.label_4.setObjectName(""label_4"")
        self.gridLayout_7.addWidget(self.label_4, 0, 0, 1, 1)
        self.gVOriginalSignal = ZoomAndDropableGraphicView(
            self.scrollAreaWidgetContents_2
        )
        self.gVOriginalSignal.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOff)
        self.gVOriginalSignal.setHorizontalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)
        self.gVOriginalSignal.setRenderHints(
            QtGui.QPainter.Antialiasing | QtGui.QPainter.HighQualityAntialiasing
        )
        self.gVOriginalSignal.setDragMode(QtWidgets.QGraphicsView.NoDrag)
        self.gVOriginalSignal.setObjectName(""gVOriginalSignal"")
        self.gridLayout_7.addWidget(self.gVOriginalSignal, 9, 1, 1, 3)
        self.scrollArea_5 = QtWidgets.QScrollArea(self.scrollAreaWidgetContents_2)
        self.scrollArea_5.setFrameShape(QtWidgets.QFrame.NoFrame)
        self.scrollArea_5.setWidgetResizable(True)
        self.scrollArea_5.setObjectName(""scrollArea_5"")
        self.scrollAreaWidgetContents_5 = QtWidgets.QWidget()
        self.scrollAreaWidgetContents_5.setGeometry(QtCore.QRect(0, 0, 373, 330))
        self.scrollAreaWidgetContents_5.setObjectName(""scrollAreaWidgetContents_5"")
        self.gridLayout_4 = QtWidgets.QGridLayout(self.scrollAreaWidgetContents_5)
        self.gridLayout_4.setObjectName(""gridLayout_4"")
        self.lCurrentSearchResult = QtWidgets.QLabel(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.lCurrentSearchResult.sizePolicy().hasHeightForWidth()
        )
        self.lCurrentSearchResult.setSizePolicy(sizePolicy)
        self.lCurrentSearchResult.setMinimumSize(QtCore.QSize(0, 0))
        self.lCurrentSearchResult.setMaximumSize(QtCore.QSize(16777215, 16777215))
        self.lCurrentSearchResult.setAlignment(QtCore.Qt.AlignCenter)
        self.lCurrentSearchResult.setObjectName(""lCurrentSearchResult"")
        self.gridLayout_4.addWidget(self.lCurrentSearchResult, 3, 1, 1, 2)
        self.cbShowDataBitsOnly = QtWidgets.QCheckBox(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.cbShowDataBitsOnly.sizePolicy().hasHeightForWidth()
        )
        self.cbShowDataBitsOnly.setSizePolicy(sizePolicy)
        self.cbShowDataBitsOnly.setMinimumSize(QtCore.QSize(0, 0))
        self.cbShowDataBitsOnly.setMaximumSize(QtCore.QSize(16777215, 16777215))
        self.cbShowDataBitsOnly.setObjectName(""cbShowDataBitsOnly"")
        self.gridLayout_4.addWidget(self.cbShowDataBitsOnly, 2, 0, 1, 5)
        self.btnSearchPrev = QtWidgets.QPushButton(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.btnSearchPrev.sizePolicy().hasHeightForWidth()
        )
        self.btnSearchPrev.setSizePolicy(sizePolicy)
        self.btnSearchPrev.setMaximumSize(QtCore.QSize(16777215, 16777215))
        self.btnSearchPrev.setText("""")
        icon = QtGui.QIcon.fromTheme(""go-previous"")
        self.btnSearchPrev.setIcon(icon)
        self.btnSearchPrev.setObjectName(""btnSearchPrev"")
        self.gridLayout_4.addWidget(self.btnSearchPrev, 3, 0, 1, 1)
        self.lTotalSearchresults = QtWidgets.QLabel(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.lTotalSearchresults.sizePolicy().hasHeightForWidth()
        )
        self.lTotalSearchresults.setSizePolicy(sizePolicy)
        self.lTotalSearchresults.setMaximumSize(QtCore.QSize(16777215, 16777215))
        self.lTotalSearchresults.setAlignment(QtCore.Qt.AlignCenter)
        self.lTotalSearchresults.setObjectName(""lTotalSearchresults"")
        self.gridLayout_4.addWidget(self.lTotalSearchresults, 3, 4, 1, 1)
        self.treeViewSignals = ModulatorTreeView(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.treeViewSignals.sizePolicy().hasHeightForWidth()
        )
        self.treeViewSignals.setSizePolicy(sizePolicy)
        self.treeViewSignals.setProperty(""showDropIndicator"", True)
        self.treeViewSignals.setDragEnabled(True)
        self.treeViewSignals.setDragDropMode(QtWidgets.QAbstractItemView.DragOnly)
        self.treeViewSignals.setHeaderHidden(True)
        self.treeViewSignals.setObjectName(""treeViewSignals"")
        self.gridLayout_4.addWidget(self.treeViewSignals, 0, 0, 1, 6)
        self.lSlash = QtWidgets.QLabel(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.lSlash.sizePolicy().hasHeightForWidth())
        self.lSlash.setSizePolicy(sizePolicy)
        self.lSlash.setMaximumSize(QtCore.QSize(7, 16777215))
        self.lSlash.setObjectName(""lSlash"")
        self.gridLayout_4.addWidget(self.lSlash, 3, 3, 1, 1)
        self.btnSearchNext = QtWidgets.QPushButton(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.btnSearchNext.sizePolicy().hasHeightForWidth()
        )
        self.btnSearchNext.setSizePolicy(sizePolicy)
        self.btnSearchNext.setMaximumSize(QtCore.QSize(16777215, 16777215))
        self.btnSearchNext.setText("""")
        icon = QtGui.QIcon.fromTheme(""go-next"")
        self.btnSearchNext.setIcon(icon)
        self.btnSearchNext.setObjectName(""btnSearchNext"")
        self.gridLayout_4.addWidget(self.btnSearchNext, 3, 5, 1, 1)
        self.chkBoxLockSIV = QtWidgets.QCheckBox(self.scrollAreaWidgetContents_5)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.chkBoxLockSIV.sizePolicy().hasHeightForWidth()
        )
        self.chkBoxLockSIV.setSizePolicy(sizePolicy)
        self.chkBoxLockSIV.setObjectName(""chkBoxLockSIV"")
        self.gridLayout_4.addWidget(self.chkBoxLockSIV, 1, 0, 1, 5)
        self.scrollArea_5.setWidget(self.scrollAreaWidgetContents_5)
        self.gridLayout_7.addWidget(self.scrollArea_5, 9, 0, 1, 1)
        self.horizontalLayout = QtWidgets.QHBoxLayout()
        self.horizontalLayout.setObjectName(""horizontalLayout"")
        self.lSamplesInViewModulatedText = QtWidgets.QLabel(
            self.scrollAreaWidgetContents_2
        )
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.lSamplesInViewModulatedText.sizePolicy().hasHeightForWidth()
        )
        self.lSamplesInViewModulatedText.setSizePolicy(sizePolicy)
        self.lSamplesInViewModulatedText.setObjectName(""lSamplesInViewModulatedText"")
        self.horizontalLayout.addWidget(self.lSamplesInViewModulatedText)
        self.lSamplesInViewModulated = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Maximum
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.lSamplesInViewModulated.sizePolicy().hasHeightForWidth()
        )
        self.lSamplesInViewModulated.setSizePolicy(sizePolicy)
        self.lSamplesInViewModulated.setObjectName(""lSamplesInViewModulated"")
        self.horizontalLayout.addWidget(self.lSamplesInViewModulated)
        self.label_9 = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        self.label_9.setObjectName(""label_9"")
        self.horizontalLayout.addWidget(self.label_9)
        self.lModulatedSelectedSamples = QtWidgets.QLabel(
            self.scrollAreaWidgetContents_2
        )
        self.lModulatedSelectedSamples.setObjectName(""lModulatedSelectedSamples"")
        self.horizontalLayout.addWidget(self.lModulatedSelectedSamples)
        self.gridLayout_7.addLayout(self.horizontalLayout, 6, 1, 1, 1)
        self.scrollArea_3 = QtWidgets.QScrollArea(self.scrollAreaWidgetContents_2)
        self.scrollArea_3.setFrameShape(QtWidgets.QFrame.NoFrame)
        self.scrollArea_3.setWidgetResizable(True)
        self.scrollArea_3.setObjectName(""scrollArea_3"")
        self.scrollAreaWidgetContents_3 = QtWidgets.QWidget()
        self.scrollAreaWidgetContents_3.setGeometry(QtCore.QRect(0, 0, 373, 141))
        self.scrollAreaWidgetContents_3.setObjectName(""scrollAreaWidgetContents_3"")
        self.gridLayout_2 = QtWidgets.QGridLayout(self.scrollAreaWidgetContents_3)
        self.gridLayout_2.setObjectName(""gridLayout_2"")
        self.spinBoxSampleRate = KillerDoubleSpinBox(self.scrollAreaWidgetContents_3)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.spinBoxSampleRate.sizePolicy().hasHeightForWidth()
        )
        self.spinBoxSampleRate.setSizePolicy(sizePolicy)
        self.spinBoxSampleRate.setDecimals(10)
        self.spinBoxSampleRate.setMinimum(0.001)
        self.spinBoxSampleRate.setMaximum(999999999.0)
        self.spinBoxSampleRate.setObjectName(""spinBoxSampleRate"")
        self.gridLayout_2.addWidget(self.spinBoxSampleRate, 2, 1, 1, 1)
        spacerItem3 = QtWidgets.QSpacerItem(
            20, 40, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding
        )
        self.gridLayout_2.addItem(spacerItem3, 3, 0, 1, 1)
        self.label_3 = QtWidgets.QLabel(self.scrollAreaWidgetContents_3)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.label_3.sizePolicy().hasHeightForWidth())
        self.label_3.setSizePolicy(sizePolicy)
        self.label_3.setObjectName(""label_3"")
        self.gridLayout_2.addWidget(self.label_3, 2, 0, 1, 1)
        self.label = QtWidgets.QLabel(self.scrollAreaWidgetContents_3)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.label.sizePolicy().hasHeightForWidth())
        self.label.setSizePolicy(sizePolicy)
        self.label.setObjectName(""label"")
        self.gridLayout_2.addWidget(self.label, 1, 0, 1, 1)
        self.spinBoxSamplesPerSymbol = QtWidgets.QSpinBox(
            self.scrollAreaWidgetContents_3
        )
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.spinBoxSamplesPerSymbol.sizePolicy().hasHeightForWidth()
        )
        self.spinBoxSamplesPerSymbol.setSizePolicy(sizePolicy)
        self.spinBoxSamplesPerSymbol.setMinimum(1)
        self.spinBoxSamplesPerSymbol.setMaximum(999999)
        self.spinBoxSamplesPerSymbol.setObjectName(""spinBoxSamplesPerSymbol"")
        self.gridLayout_2.addWidget(self.spinBoxSamplesPerSymbol, 1, 1, 1, 1)
        self.linEdDataBits = QtWidgets.QLineEdit(self.scrollAreaWidgetContents_3)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.linEdDataBits.sizePolicy().hasHeightForWidth()
        )
        self.linEdDataBits.setSizePolicy(sizePolicy)
        self.linEdDataBits.setObjectName(""linEdDataBits"")
        self.gridLayout_2.addWidget(self.linEdDataBits, 0, 0, 1, 2)
        self.scrollArea_3.setWidget(self.scrollAreaWidgetContents_3)
        self.gridLayout_7.addWidget(self.scrollArea_3, 3, 0, 1, 1)
        self.scrollArea_2 = QtWidgets.QScrollArea(self.scrollAreaWidgetContents_2)
        self.scrollArea_2.setFrameShape(QtWidgets.QFrame.NoFrame)
        self.scrollArea_2.setWidgetResizable(True)
        self.scrollArea_2.setObjectName(""scrollArea_2"")
        self.scrollAreaWidgetContents = QtWidgets.QWidget()
        self.scrollAreaWidgetContents.setGeometry(QtCore.QRect(0, 0, 353, 143))
        self.scrollAreaWidgetContents.setObjectName(""scrollAreaWidgetContents"")
        self.gridLayout = QtWidgets.QGridLayout(self.scrollAreaWidgetContents)
        self.gridLayout.setObjectName(""gridLayout"")
        self.lCarrierFreq = QtWidgets.QLabel(self.scrollAreaWidgetContents)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.lCarrierFreq.sizePolicy().hasHeightForWidth())
        self.lCarrierFreq.setSizePolicy(sizePolicy)
        self.lCarrierFreq.setObjectName(""lCarrierFreq"")
        self.gridLayout.addWidget(self.lCarrierFreq, 0, 0, 1, 1)
        self.doubleSpinBoxCarrierFreq = KillerDoubleSpinBox(
            self.scrollAreaWidgetContents
        )
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.doubleSpinBoxCarrierFreq.sizePolicy().hasHeightForWidth()
        )
        self.doubleSpinBoxCarrierFreq.setSizePolicy(sizePolicy)
        self.doubleSpinBoxCarrierFreq.setSuffix("""")
        self.doubleSpinBoxCarrierFreq.setDecimals(10)
        self.doubleSpinBoxCarrierFreq.setMinimum(0.0)
        self.doubleSpinBoxCarrierFreq.setMaximum(99999999999.0)
        self.doubleSpinBoxCarrierFreq.setObjectName(""doubleSpinBoxCarrierFreq"")
        self.gridLayout.addWidget(self.doubleSpinBoxCarrierFreq, 0, 1, 1, 1)
        self.label_2 = QtWidgets.QLabel(self.scrollAreaWidgetContents)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.label_2.sizePolicy().hasHeightForWidth())
        self.label_2.setSizePolicy(sizePolicy)
        self.label_2.setObjectName(""label_2"")
        self.gridLayout.addWidget(self.label_2, 1, 0, 1, 1)
        self.doubleSpinBoxCarrierPhase = QtWidgets.QDoubleSpinBox(
            self.scrollAreaWidgetContents
        )
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.doubleSpinBoxCarrierPhase.sizePolicy().hasHeightForWidth()
        )
        self.doubleSpinBoxCarrierPhase.setSizePolicy(sizePolicy)
        self.doubleSpinBoxCarrierPhase.setDecimals(3)
        self.doubleSpinBoxCarrierPhase.setMaximum(360.0)
        self.doubleSpinBoxCarrierPhase.setObjectName(""doubleSpinBoxCarrierPhase"")
        self.gridLayout.addWidget(self.doubleSpinBoxCarrierPhase, 1, 1, 1, 1)
        self.btnAutoDetect = QtWidgets.QPushButton(self.scrollAreaWidgetContents)
        self.btnAutoDetect.setEnabled(False)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.btnAutoDetect.sizePolicy().hasHeightForWidth()
        )
        self.btnAutoDetect.setSizePolicy(sizePolicy)
        self.btnAutoDetect.setObjectName(""btnAutoDetect"")
        self.gridLayout.addWidget(self.btnAutoDetect, 2, 0, 1, 2)
        spacerItem4 = QtWidgets.QSpacerItem(
            20, 40, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding
        )
        self.gridLayout.addItem(spacerItem4, 3, 0, 1, 1)
        self.scrollArea_2.setWidget(self.scrollAreaWidgetContents)
        self.gridLayout_7.addWidget(self.scrollArea_2, 1, 0, 1, 1)
        self.lPlus = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.lPlus.sizePolicy().hasHeightForWidth())
        self.lPlus.setSizePolicy(sizePolicy)
        self.lPlus.setMaximumSize(QtCore.QSize(32, 32))
        self.lPlus.setText("""")
        self.lPlus.setPixmap(QtGui.QPixmap("":/icons/icons/plus.svg""))
        self.lPlus.setScaledContents(True)
        self.lPlus.setAlignment(QtCore.Qt.AlignCenter)
        self.lPlus.setObjectName(""lPlus"")
        self.gridLayout_7.addWidget(self.lPlus, 2, 2, 1, 1)
        self.gVCarrier = ZoomableGraphicView(self.scrollAreaWidgetContents_2)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Expanding
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.gVCarrier.sizePolicy().hasHeightForWidth())
        self.gVCarrier.setSizePolicy(sizePolicy)
        self.gVCarrier.setAcceptDrops(False)
        self.gVCarrier.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOff)
        self.gVCarrier.setHorizontalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)
        self.gVCarrier.setRenderHints(
            QtGui.QPainter.Antialiasing | QtGui.QPainter.HighQualityAntialiasing
        )
        self.gVCarrier.setDragMode(QtWidgets.QGraphicsView.NoDrag)
        self.gVCarrier.setObjectName(""gVCarrier"")
        self.gridLayout_7.addWidget(self.gVCarrier, 1, 1, 1, 3)
        spacerItem5 = QtWidgets.QSpacerItem(
            40, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum
        )
        self.gridLayout_7.addItem(spacerItem5, 2, 1, 1, 1)
        self.gVModulated = ZoomableGraphicView(self.scrollAreaWidgetContents_2)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Expanding
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.gVModulated.sizePolicy().hasHeightForWidth())
        self.gVModulated.setSizePolicy(sizePolicy)
        self.gVModulated.setAcceptDrops(False)
        self.gVModulated.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOff)
        self.gVModulated.setHorizontalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)
        self.gVModulated.setRenderHints(
            QtGui.QPainter.Antialiasing | QtGui.QPainter.HighQualityAntialiasing
        )
        self.gVModulated.setDragMode(QtWidgets.QGraphicsView.NoDrag)
        self.gVModulated.setObjectName(""gVModulated"")
        self.gridLayout_7.addWidget(self.gVModulated, 5, 1, 1, 3)
        self.gVData = ZoomableGraphicView(self.scrollAreaWidgetContents_2)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Expanding
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.gVData.sizePolicy().hasHeightForWidth())
        self.gVData.setSizePolicy(sizePolicy)
        self.gVData.setAcceptDrops(False)
        self.gVData.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOff)
        self.gVData.setHorizontalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)
        self.gVData.setRenderHints(
            QtGui.QPainter.Antialiasing | QtGui.QPainter.HighQualityAntialiasing
        )
        self.gVData.setDragMode(QtWidgets.QGraphicsView.NoDrag)
        self.gVData.setObjectName(""gVData"")
        self.gridLayout_7.addWidget(self.gVData, 3, 1, 1, 3)
        self.scrollArea_4 = QtWidgets.QScrollArea(self.scrollAreaWidgetContents_2)
        self.scrollArea_4.setFrameShape(QtWidgets.QFrame.NoFrame)
        self.scrollArea_4.setWidgetResizable(True)
        self.scrollArea_4.setObjectName(""scrollArea_4"")
        self.scrollAreaWidgetContents_4 = QtWidgets.QWidget()
        self.scrollAreaWidgetContents_4.setGeometry(QtCore.QRect(0, 0, 353, 227))
        self.scrollAreaWidgetContents_4.setObjectName(""scrollAreaWidgetContents_4"")
        self.gridLayout_3 = QtWidgets.QGridLayout(self.scrollAreaWidgetContents_4)
        self.gridLayout_3.setObjectName(""gridLayout_3"")
        self.spinBoxBitsPerSymbol = QtWidgets.QSpinBox(self.scrollAreaWidgetContents_4)
        self.spinBoxBitsPerSymbol.setMinimum(1)
        self.spinBoxBitsPerSymbol.setMaximum(10)
        self.spinBoxBitsPerSymbol.setObjectName(""spinBoxBitsPerSymbol"")
        self.gridLayout_3.addWidget(self.spinBoxBitsPerSymbol, 1, 1, 1, 1)
        self.spinBoxGaussBT = QtWidgets.QDoubleSpinBox(self.scrollAreaWidgetContents_4)
        self.spinBoxGaussBT.setMinimum(0.01)
        self.spinBoxGaussBT.setMaximum(0.99)
        self.spinBoxGaussBT.setSingleStep(0.01)
        self.spinBoxGaussBT.setObjectName(""spinBoxGaussBT"")
        self.gridLayout_3.addWidget(self.spinBoxGaussBT, 3, 1, 1, 1)
        self.lGaussWidth = QtWidgets.QLabel(self.scrollAreaWidgetContents_4)
        self.lGaussWidth.setObjectName(""lGaussWidth"")
        self.gridLayout_3.addWidget(self.lGaussWidth, 4, 0, 1, 1)
        self.lGaussBT = QtWidgets.QLabel(self.scrollAreaWidgetContents_4)
        self.lGaussBT.setObjectName(""lGaussBT"")
        self.gridLayout_3.addWidget(self.lGaussBT, 3, 0, 1, 1)
        self.spinBoxGaussFilterWidth = QtWidgets.QDoubleSpinBox(
            self.scrollAreaWidgetContents_4
        )
        self.spinBoxGaussFilterWidth.setMinimum(0.01)
        self.spinBoxGaussFilterWidth.setMaximum(100.0)
        self.spinBoxGaussFilterWidth.setSingleStep(0.01)
        self.spinBoxGaussFilterWidth.setProperty(""value"", 1.0)
        self.spinBoxGaussFilterWidth.setObjectName(""spinBoxGaussFilterWidth"")
        self.gridLayout_3.addWidget(self.spinBoxGaussFilterWidth, 4, 1, 1, 1)
        self.labelBitsPerSymbol = QtWidgets.QLabel(self.scrollAreaWidgetContents_4)
        self.labelBitsPerSymbol.setObjectName(""labelBitsPerSymbol"")
        self.gridLayout_3.addWidget(self.labelBitsPerSymbol, 1, 0, 1, 1)
        spacerItem6 = QtWidgets.QSpacerItem(
            20, 40, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding
        )
        self.gridLayout_3.addItem(spacerItem6, 5, 0, 1, 1)
        spacerItem7 = QtWidgets.QSpacerItem(
            20, 40, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding
        )
        self.gridLayout_3.addItem(spacerItem7, 5, 1, 1, 1)
        self.lineEditParameters = QtWidgets.QLineEdit(self.scrollAreaWidgetContents_4)
        self.lineEditParameters.setClearButtonEnabled(False)
        self.lineEditParameters.setObjectName(""lineEditParameters"")
        self.gridLayout_3.addWidget(self.lineEditParameters, 2, 1, 1, 1)
        self.comboBoxModulationType = QtWidgets.QComboBox(
            self.scrollAreaWidgetContents_4
        )
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.comboBoxModulationType.sizePolicy().hasHeightForWidth()
        )
        self.comboBoxModulationType.setSizePolicy(sizePolicy)
        self.comboBoxModulationType.setMaximumSize(QtCore.QSize(16777215, 16777215))
        self.comboBoxModulationType.setObjectName(""comboBoxModulationType"")
        self.comboBoxModulationType.addItem("""")
        self.comboBoxModulationType.addItem("""")
        self.comboBoxModulationType.addItem("""")
        self.comboBoxModulationType.addItem("""")
        self.gridLayout_3.addWidget(self.comboBoxModulationType, 0, 0, 1, 2)
        self.labelParameters = QtWidgets.QLabel(self.scrollAreaWidgetContents_4)
        self.labelParameters.setObjectName(""labelParameters"")
        self.gridLayout_3.addWidget(self.labelParameters, 2, 0, 1, 1)
        self.scrollArea_4.setWidget(self.scrollAreaWidgetContents_4)
        self.gridLayout_7.addWidget(self.scrollArea_4, 5, 0, 1, 1)
        spacerItem8 = QtWidgets.QSpacerItem(
            40, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum
        )
        self.gridLayout_7.addItem(spacerItem8, 4, 3, 1, 1)
        spacerItem9 = QtWidgets.QSpacerItem(
            40, 20, QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Minimum
        )
        self.gridLayout_7.addItem(spacerItem9, 8, 3, 1, 1)
        self.lEqual_qm = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.lEqual_qm.sizePolicy().hasHeightForWidth())
        self.lEqual_qm.setSizePolicy(sizePolicy)
        self.lEqual_qm.setMaximumSize(QtCore.QSize(32, 32))
        self.lEqual_qm.setText("""")
        self.lEqual_qm.setPixmap(QtGui.QPixmap("":/icons/icons/equals_qm.svg""))
        self.lEqual_qm.setScaledContents(True)
        self.lEqual_qm.setAlignment(QtCore.Qt.AlignCenter)
        self.lEqual_qm.setObjectName(""lEqual_qm"")
        self.gridLayout_7.addWidget(self.lEqual_qm, 8, 2, 1, 1)
        self.horizontalLayout_2 = QtWidgets.QHBoxLayout()
        self.horizontalLayout_2.setObjectName(""horizontalLayout_2"")
        self.lSamplesInViewOrigSignalText = QtWidgets.QLabel(
            self.scrollAreaWidgetContents_2
        )
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Maximum, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.lSamplesInViewOrigSignalText.sizePolicy().hasHeightForWidth()
        )
        self.lSamplesInViewOrigSignalText.setSizePolicy(sizePolicy)
        self.lSamplesInViewOrigSignalText.setObjectName(""lSamplesInViewOrigSignalText"")
        self.horizontalLayout_2.addWidget(self.lSamplesInViewOrigSignalText)
        self.lSamplesInViewOrigSignal = QtWidgets.QLabel(
            self.scrollAreaWidgetContents_2
        )
        sizePolicy = QtWidgets.QSizePolicy(
            QtWidgets.QSizePolicy.Preferred, QtWidgets.QSizePolicy.Preferred
        )
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(
            self.lSamplesInViewOrigSignal.sizePolicy().hasHeightForWidth()
        )
        self.lSamplesInViewOrigSignal.setSizePolicy(sizePolicy)
        self.lSamplesInViewOrigSignal.setObjectName(""lSamplesInViewOrigSignal"")
        self.horizontalLayout_2.addWidget(self.lSamplesInViewOrigSignal)
        self.label_10 = QtWidgets.QLabel(self.scrollAreaWidgetContents_2)
        self.label_10.setObjectName(""label_10"")
        self.horizontalLayout_2.addWidget(self.label_10)
        self.lOriginalSignalSamplesSelected = QtWidgets.QLabel(
            self.scrollAreaWidgetContents_2
        )
        self.lOriginalSignalSamplesSelected.setObjectName(
            ""lOriginalSignalSamplesSelected""
        )
        self.horizontalLayout_2.addWidget(self.lOriginalSignalSamplesSelected)
        self.gridLayout_7.addLayout(self.horizontalLayout_2, 10, 1, 1, 1)
        self.gridLayout_7.setRowStretch(1, 1)
        self.gridLayout_7.setRowStretch(3, 1)
        self.gridLayout_7.setRowStretch(5, 1)
        self.gridLayout_7.setRowStretch(8, 1)
        self.scrollArea.setWidget(self.scrollAreaWidgetContents_2)
        self.verticalLayout.addWidget(self.scrollArea)

        self.retranslateUi(DialogModulation)
        DialogModulation.setTabOrder(self.btnAddModulation, self.scrollArea_2)
        DialogModulation.setTabOrder(self.scrollArea_2, self.doubleSpinBoxCarrierFreq)
        DialogModulation.setTabOrder(
            self.doubleSpinBoxCarrierFreq, self.doubleSpinBoxCarrierPhase
        )
        DialogModulation.setTabOrder(self.doubleSpinBoxCarrierPhase, self.btnAutoDetect)
        DialogModulation.setTabOrder(self.btnAutoDetect, self.scrollArea_3)
        DialogModulation.setTabOrder(self.scrollArea_3, self.linEdDataBits)
        DialogModulation.setTabOrder(self.linEdDataBits, self.spinBoxSamplesPerSymbol)
        DialogModulation.setTabOrder(
            self.spinBoxSamplesPerSymbol, self.spinBoxSampleRate
        )
        DialogModulation.setTabOrder(self.spinBoxSampleRate, self.scrollArea_4)
        DialogModulation.setTabOrder(self.scrollArea_4, self.comboBoxModulationType)
        DialogModulation.setTabOrder(
            self.comboBoxModulationType, self.spinBoxBitsPerSymbol
        )
        DialogModulation.setTabOrder(self.spinBoxBitsPerSymbol, self.lineEditParameters)
        DialogModulation.setTabOrder(self.lineEditParameters, self.spinBoxGaussBT)
        DialogModulation.setTabOrder(self.spinBoxGaussBT, self.spinBoxGaussFilterWidth)
        DialogModulation.setTabOrder(self.spinBoxGaussFilterWidth, self.scrollArea_5)
        DialogModulation.setTabOrder(self.scrollArea_5, self.treeViewSignals)
        DialogModulation.setTabOrder(self.treeViewSignals, self.chkBoxLockSIV)
        DialogModulation.setTabOrder(self.chkBoxLockSIV, self.gVCarrier)
        DialogModulation.setTabOrder(self.gVCarrier, self.gVData)
        DialogModulation.setTabOrder(self.gVData, self.gVModulated)
        DialogModulation.setTabOrder(self.gVModulated, self.gVOriginalSignal)
        DialogModulation.setTabOrder(self.gVOriginalSignal, self.cbShowDataBitsOnly)
        DialogModulation.setTabOrder(self.cbShowDataBitsOnly, self.btnSearchPrev)
        DialogModulation.setTabOrder(self.btnSearchPrev, self.btnSearchNext)
        DialogModulation.setTabOrder(self.btnSearchNext, self.btnRemoveModulation)
        DialogModulation.setTabOrder(
            self.btnRemoveModulation, self.comboBoxCustomModulations
        )
        DialogModulation.setTabOrder(self.comboBoxCustomModulations, self.scrollArea)

    def retranslateUi(self, DialogModulation):
        _translate = QtCore.QCoreApplication.translate
        DialogModulation.setWindowTitle(_translate(""DialogModulation"", ""Modulation""))
        self.comboBoxCustomModulations.setItemText(
            0, _translate(""DialogModulation"", ""My Modulation"")
        )
        self.btnAddModulation.setText(_translate(""DialogModulation"", ""...""))
        self.btnRemoveModulation.setText(_translate(""DialogModulation"", ""...""))
        self.label_5.setText(_translate(""DialogModulation"", ""Data (raw bits)""))
        self.label_6.setText(_translate(""DialogModulation"", ""Modulation""))
        self.label_7.setText(
            _translate(""DialogModulation"", ""Original Signal (drag&drop)"")
        )
        self.label_4.setText(_translate(""DialogModulation"", ""Carrier""))
        self.lCurrentSearchResult.setText(_translate(""DialogModulation"", ""-""))
        self.cbShowDataBitsOnly.setText(
            _translate(""DialogModulation"", ""Show Only Data Sequence\n"" ""(10)"")
        )
        self.lTotalSearchresults.setText(_translate(""DialogModulation"", ""-""))
        self.lSlash.setText(_translate(""DialogModulation"", ""/""))
        self.chkBoxLockSIV.setText(
            _translate(""DialogModulation"", ""Lock view to original signal"")
        )
        self.lSamplesInViewModulatedText.setText(
            _translate(""DialogModulation"", ""Samples in View:"")
        )
        self.lSamplesInViewModulated.setToolTip(
            _translate(
                ""DialogModulation"",
                '<html><head/><body><p>Shown Samples in View:</p><p><span style="" font-weight:600; color:#ff0000;"">Red</span> - if samples in view differ from original signal</p><p><span style="" font-weight:600;"">Normal</span> - if samples in view are equal to the original signal</p></body></html>',
            )
        )
        self.lSamplesInViewModulated.setText(
            _translate(""DialogModulation"", ""101010121"")
        )
        self.label_9.setText(_translate(""DialogModulation"", ""Samples selected:""))
        self.lModulatedSelectedSamples.setText(_translate(""DialogModulation"", ""0""))
        self.label_3.setText(_translate(""DialogModulation"", ""Sample Rate (Sps):""))
        self.label.setText(_translate(""DialogModulation"", ""Samples per Symbol:""))
        self.linEdDataBits.setPlaceholderText(
            _translate(""DialogModulation"", ""Enter Data Bits here"")
        )
        self.lCarrierFreq.setText(_translate(""DialogModulation"", ""Frequency:""))
        self.label_2.setText(_translate(""DialogModulation"", ""Phase:""))
        self.doubleSpinBoxCarrierPhase.setSuffix(_translate(""DialogModulation"", """"))
        self.btnAutoDetect.setToolTip(
            _translate(
                ""DialogModulation"",
                '<html><head/><body><p>Auto detect the frequency based on the original signal. You have to select a signal (<span style="" font-weight:600;"">bottom of this window</span>) to use this feature.</p><p><br/></p><p>Select a signal by dragging it from the tree and dropping it on the graphics pane to the right.</p></body></html>',
            )
        )
        self.btnAutoDetect.setText(
            _translate(""DialogModulation"", ""Auto detect from original signal"")
        )
        self.lGaussWidth.setText(_translate(""DialogModulation"", ""Gauss filter width:""))
        self.lGaussBT.setText(_translate(""DialogModulation"", ""Gauss BT:""))
        self.labelBitsPerSymbol.setText(
            _translate(""DialogModulation"", ""Bits per Symbol:"")
        )
        self.comboBoxModulationType.setItemText(
            0, _translate(""DialogModulation"", ""Amplitude Shift Keying (ASK)"")
        )
        self.comboBoxModulationType.setItemText(
            1, _translate(""DialogModulation"", ""Frequency Shift Keying (FSK)"")
        )
        self.comboBoxModulationType.setItemText(
            2, _translate(""DialogModulation"", ""Gaussian Frequency Shift Keying (GFSK)"")
        )
        self.comboBoxModulationType.setItemText(
            3, _translate(""DialogModulation"", ""Phase Shift Keying (PSK)"")
        )
        self.labelParameters.setText(_translate(""DialogModulation"", ""Parameters:""))
        self.lSamplesInViewOrigSignalText.setText(
            _translate(""DialogModulation"", ""Samples in View:"")
        )
        self.lSamplesInViewOrigSignal.setToolTip(
            _translate(
                ""DialogModulation"",
                '<html><head/><body><p>Shown Samples in View:</p><p><span style="" font-weight:600; color:#ff0000;"">Red</span> - if samples in view differ from original signal</p><p><span style="" font-weight:600;"">Normal</span> - if samples in view are equal to the original signal</p></body></html>',
            )
        )
        self.lSamplesInViewOrigSignal.setText(_translate(""DialogModulation"", ""0""))
        self.label_10.setText(_translate(""DialogModulation"", ""Samples selected:""))
        self.lOriginalSignalSamplesSelected.setText(_translate(""DialogModulation"", ""0""))","class Ui_DialogModulation(object):


    def setupUi(self, DialogModulation):
        pass

    def retranslateUi(self, DialogModulation):
        pass

",3,0,snippet_332,1.0,"class Ui_DialogModulation(object):
    def setupUi(self, DialogModulation):
        DialogModulation.setObjectName(""DialogModulation"")
        DialogModulation.resize(400, 180)
        self.verticalLayout = QtWidgets.QVBoxLayout(DialogModulation)
        self.verticalLayout.setObjectName(""verticalLayout"")
        self.formLayout = QtWidgets.QFormLayout()
        self.formLayout.setObjectName(""formLayout"")
        self.labelModType = QtWidgets.QLabel(DialogModulation)
        self.labelModType.setObjectName(""labelModType"")
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.LabelRole, self.labelModType)
        self.comboModType = QtWidgets.QComboBox(DialogModulation)
        self.comboModType.setObjectName(""comboModType"")
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.FieldRole, self.comboModType)
        self.labelFrequency = QtWidgets.QLabel(DialogModulation)
        self.labelFrequency.setObjectName(""labelFrequency"")
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.LabelRole, self.labelFrequency)
        self.spinFrequency = QtWidgets.QDoubleSpinBox(DialogModulation)
        self.spinFrequency.setObjectName(""spinFrequency"")
        self.spinFrequency.setRange(0.0, 1e6)
        self.spinFrequency.setSingleStep(1.0)
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.FieldRole, self.spinFrequency)
        self.labelAmplitude = QtWidgets.QLabel(DialogModulation)
        self.labelAmplitude.setObjectName(""labelAmplitude"")
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.LabelRole, self.labelAmplitude)
        self.spinAmplitude = QtWidgets.QDoubleSpinBox(DialogModulation)
        self.spinAmplitude.setObjectName(""spinAmplitude"")
        self.spinAmplitude.setRange(0.0, 100.0)
        self.spinAmplitude.setSingleStep(0.1)
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.FieldRole, self.spinAmplitude)
        self.verticalLayout.addLayout(self.formLayout)
        self.buttonBox = QtWidgets.QDialogButtonBox(DialogModulation)
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel | QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.verticalLayout.addWidget(self.buttonBox)
        self.retranslateUi(DialogModulation)
        self.buttonBox.accepted.connect(DialogModulation.accept)
        self.buttonBox.rejected.connect(DialogModulation.reject)
        QtCore.QMetaObject.connectSlotsByName(DialogModulation)

    def retranslateUi(self, DialogModulation):
        _translate = QtCore.QCoreApplication.translate
        DialogModulation.setWindowTitle(_translate(""DialogModulation"", ""Modulation Settings""))
        self.labelModType.setText(_translate(""DialogModulation"", ""Modulation Type:""))
        self.comboModType.clear()
        self.comboModType.addItems([
            _translate(""DialogModulation"", ""AM""),
            _translate(""DialogModulation"", ""FM""),
            _translate(""DialogModulation"", ""PM""),
            _translate(""DialogModulation"", ""QAM""),
            _translate(""DialogModulation"", ""PSK"")
        ])
        self.labelFrequency.setText(_translate(""DialogModulation"", ""Carrier Frequency (Hz):""))
        self.labelAmplitude.setText(_translate(""DialogModulation"", ""Carrier Amplitude:""))","class Ui_DialogModulation(object):
    def setupUi(self, DialogModulation):
        DialogModulation.setObjectName(""DialogModulation"")
        DialogModulation.resize(400, 300)
        self.buttonBox = QtWidgets.QDialogButtonBox(DialogModulation)
        self.buttonBox.setGeometry(QtCore.QRect(30, 240, 341, 32))
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel|QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.comboBox = QtWidgets.QComboBox(DialogModulation)
        self.comboBox.setGeometry(QtCore.QRect(150, 50, 201, 22))
        self.comboBox.setObjectName(""comboBox"")
        self.label = QtWidgets.QLabel(DialogModulation)
        self.label.setGeometry(QtCore.QRect(30, 50, 111, 21))
        self.label.setObjectName(""label"")
        self.label_2 = QtWidgets.QLabel(DialogModulation)
        self.label_2.setGeometry(QtCore.QRect(30, 90, 111, 21))
        self.label_2.setObjectName(""label_2"")
        self.spinBox = QtWidgets.QSpinBox(DialogModulation)
        self.spinBox.setGeometry(QtCore.QRect(150, 90, 201, 22))
        self.spinBox.setObjectName(""spinBox"")
        self.label_3 = QtWidgets.QLabel(DialogModulation)
        self.label_3.setGeometry(QtCore.QRect(30, 130, 111, 21))
        self.label_3.setObjectName(""label_3"")
        self.doubleSpinBox = QtWidgets.QDoubleSpinBox(DialogModulation)
        self.doubleSpinBox.setGeometry(QtCore.QRect(150, 130, 201, 22))
        self.doubleSpinBox.setObjectName(""doubleSpinBox"")
        
        self.retranslateUi(DialogModulation)
        self.buttonBox.accepted.connect(DialogModulation.accept)
        self.buttonBox.rejected.connect(DialogModulation.reject)
        QtCore.QMetaObject.connectSlotsByName(DialogModulation)

    def retranslateUi(self, DialogModulation):
        _translate = QtCore.QCoreApplication.translate
        DialogModulation.setWindowTitle(_translate(""DialogModulation"", ""Modulation Settings""))
        self.label.setText(_translate(""DialogModulation"", ""Modulation Type:""))
        self.label_2.setText(_translate(""DialogModulation"", ""Frequency (Hz):""))
        self.label_3.setText(_translate(""DialogModulation"", ""Amplitude:""))","class Ui_DialogModulation(object):
    def setupUi(self, DialogModulation):
        DialogModulation.setObjectName(""DialogModulation"")
        DialogModulation.resize(400, 300)
        self.verticalLayout = QtWidgets.QVBoxLayout(DialogModulation)
        self.verticalLayout.setObjectName(""verticalLayout"")
        
        self.groupBoxModulation = QtWidgets.QGroupBox(DialogModulation)
        self.groupBoxModulation.setObjectName(""groupBoxModulation"")
        self.formLayout = QtWidgets.QFormLayout(self.groupBoxModulation)
        self.formLayout.setObjectName(""formLayout"")
        
        self.labelModulationType = QtWidgets.QLabel(self.groupBoxModulation)
        self.labelModulationType.setObjectName(""labelModulationType"")
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.LabelRole, self.labelModulationType)
        
        self.comboBoxModulationType = QtWidgets.QComboBox(self.groupBoxModulation)
        self.comboBoxModulationType.setObjectName(""comboBoxModulationType"")
        self.comboBoxModulationType.addItem("""")
        self.comboBoxModulationType.addItem("""")
        self.comboBoxModulationType.addItem("""")
        self.formLayout.setWidget(0, QtWidgets.QFormLayout.FieldRole, self.comboBoxModulationType)
        
        self.labelFrequency = QtWidgets.QLabel(self.groupBoxModulation)
        self.labelFrequency.setObjectName(""labelFrequency"")
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.LabelRole, self.labelFrequency)
        
        self.spinBoxFrequency = QtWidgets.QSpinBox(self.groupBoxModulation)
        self.spinBoxFrequency.setMinimum(1)
        self.spinBoxFrequency.setMaximum(10000)
        self.spinBoxFrequency.setValue(100)
        self.spinBoxFrequency.setObjectName(""spinBoxFrequency"")
        self.formLayout.setWidget(1, QtWidgets.QFormLayout.FieldRole, self.spinBoxFrequency)
        
        self.labelAmplitude = QtWidgets.QLabel(self.groupBoxModulation)
        self.labelAmplitude.setObjectName(""labelAmplitude"")
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.LabelRole, self.labelAmplitude)
        
        self.doubleSpinBoxAmplitude = QtWidgets.QDoubleSpinBox(self.groupBoxModulation)
        self.doubleSpinBoxAmplitude.setMinimum(0.1)
        self.doubleSpinBoxAmplitude.setMaximum(10.0)
        self.doubleSpinBoxAmplitude.setValue(1.0)
        self.doubleSpinBoxAmplitude.setObjectName(""doubleSpinBoxAmplitude"")
        self.formLayout.setWidget(2, QtWidgets.QFormLayout.FieldRole, self.doubleSpinBoxAmplitude)
        
        self.verticalLayout.addWidget(self.groupBoxModulation)
        
        self.buttonBox = QtWidgets.QDialogButtonBox(DialogModulation)
        self.buttonBox.setOrientation(QtCore.Qt.Horizontal)
        self.buttonBox.setStandardButtons(QtWidgets.QDialogButtonBox.Cancel|QtWidgets.QDialogButtonBox.Ok)
        self.buttonBox.setObjectName(""buttonBox"")
        self.verticalLayout.addWidget(self.buttonBox)
        
        self.retranslateUi(DialogModulation)
        self.buttonBox.accepted.connect(DialogModulation.accept)
        self.buttonBox.rejected.connect(DialogModulation.reject)
        QtCore.QMetaObject.connectSlotsByName(DialogModulation)

    def retranslateUi(self, DialogModulation):
        _translate = QtCore.QCoreApplication.translate
        DialogModulation.setWindowTitle(_translate(""DialogModulation"", ""Modulation Settings""))
        self.groupBoxModulation.setTitle(_translate(""DialogModulation"", ""Modulation Parameters""))
        self.labelModulationType.setText(_translate(""DialogModulation"", ""Type:""))
        self.comboBoxModulationType.setItemText(0, _translate(""DialogModulation"", ""AM""))
        self.comboBoxModulationType.setItemText(1, _translate(""DialogModulation"", ""FM""))
        self.comboBoxModulationType.setItemText(2, _translate(""DialogModulation"", ""PM""))
        self.labelFrequency.setText(_translate(""DialogModulation"", ""Frequency (Hz):""))
        self.labelAmplitude.setText(_translate(""DialogModulation"", ""Amplitude:""))",no_docstr,0.09142561983471074,0.04237726098191214,0.022750775594622547,0.08316115702479339,5.686577753276195e-06,0.8373983739837398,0.6351791530944625,0.46818923327895595,0.9074403643608093,0.8000122308731079,0.8503468036651611,0.8095966577529907,0.6942720631579141,0.07700366684127814,0.05293501048218029,0.0367068694284216,0.06862231534834994,2.342563265503808e-07,0.8524590163934426,0.6796714579055442,0.5802469135802469,0.9148829579353333,0.7818494439125061,0.8431509137153625,0.7933860421180725,0.6880031200000197,0.10547875064004096,0.056352459016393436,0.037929267042542285,0.09626216077828981,2.4161522309980116e-05,0.8492753623188406,0.683599419448476,0.5348837209302325,0.9173648357391357,0.8078001737594604,0.8591033220291138,0.8175647258758545,0.6990439452631764,0.1846635679746803,2.7688342069562194e-07,0.0100105483521811,0.6821409066084108,0.0465025400547088,0.1696301082106438,7.734308936298478e-09,0.0091576914660245,0.6365374112506826,0.0328253223915592,0.1972020034081234,3.575572020977978e-07,0.0114297975666794,0.725013653741125,0.0523642047674873
536853,kontron/python-ipmi,kontron_python-ipmi/pyipmi/interfaces/rmcp.py,pyipmi.interfaces.rmcp.RmcpMsg,"class RmcpMsg(object):
    RMCP_HEADER_FORMAT = '!BxBB'
    ASF_RMCP_V_1_0 = 6
    version = None
    seq_number = None
    class_of_msg = None

    def __init__(self, class_of_msg=None):
        if class_of_msg is not None:
            self.class_of_msg = class_of_msg

    def pack(self, sdu, seq_number):
        pdu = struct.pack(self.RMCP_HEADER_FORMAT, self.ASF_RMCP_V_1_0,
                          seq_number, self.class_of_msg)
        if sdu is not None:
            pdu += sdu
        return pdu

    def unpack(self, pdu):
        header_len = struct.calcsize(self.RMCP_HEADER_FORMAT)
        header = pdu[:header_len]
        (self.version, self.seq_number, self.class_of_msg) = \
            struct.unpack(self.RMCP_HEADER_FORMAT, header)
        sdu = pdu[header_len:]

        if self.version != self.ASF_RMCP_V_1_0:
            raise DecodingError('invalid RMCP version field')

        return sdu","class RmcpMsg(object):


    def __init__(self, class_of_msg=None):
        pass

    def pack(self, sdu, seq_number):
        pass

    def unpack(self, pdu):
        pass

",4,0,snippet_162,0.5,"class RmcpMsg(object):
    RMCP_VERSION = 0x06
    RMCP_RESERVED = 0x00
    HEADER_LEN = 4

    def __init__(self, class_of_msg=None):
        self.version = self.RMCP_VERSION
        self.reserved = self.RMCP_RESERVED
        self.class_of_msg = class_of_msg if class_of_msg is not None else 0x07
        self.seq_number = None
        self.sdu = None

    def pack(self, sdu, seq_number):
        if not isinstance(sdu, (bytes, bytearray)):
            raise TypeError(""SDU must be bytes or bytearray"")
        if not (0 <= seq_number <= 0xFF):
            raise ValueError(""Sequence number must be in 0..255"")
        hdr = struct.pack('!BBBB', self.version, self.reserved, seq_number, self.class_of_msg)
        return hdr + sdu

    def unpack(self, pdu):
        if not isinstance(pdu, (bytes, bytearray)):
            raise TypeError(""PDU must be bytes or bytearray"")
        if len(pdu) < self.HEADER_LEN:
            raise ValueError(""PDU too short for RMCP header"")
        self.version, self.reserved, self.seq_number, self.class_of_msg = struct.unpack('!BBBB', pdu[:4])
        self.sdu = pdu[4:]
        return self.sdu","class RmcpMsg(object):
    def __init__(self, class_of_msg=None):
        self.class_of_msg = class_of_msg
        self.version = 0x06
        self.reserved = 0x00
        self.seq_number = 0
        self.sdu = b''

    def pack(self, sdu, seq_number):
        self.sdu = sdu
        self.seq_number = seq_number
        
        # RMCP header: version, reserved, seq_number, class
        header = bytes([
            self.version,
            self.reserved,
            self.seq_number & 0xFF,
            self.class_of_msg if self.class_of_msg is not None else 0x00
        ])
        
        # Combine header and SDU
        pdu = header + self.sdu
        return pdu

    def unpack(self, pdu):
        if len(pdu) < 4:
            raise ValueError(""PDU too short to contain RMCP header"")
        
        # Extract header fields
        self.version = pdu[0]
        self.reserved = pdu[1]
        self.seq_number = pdu[2]
        self.class_of_msg = pdu[3]
        
        # Extract SDU (payload)
        self.sdu = pdu[4:]
        
        return self.sdu, self.seq_number","class RmcpMsg(object):

    def __init__(self, class_of_msg=None):
        self.version = 0x06
        self.reserved = 0x00
        self.sequence_number = 0x00
        self.class_of_msg = class_of_msg if class_of_msg is not None else 0x07
        self.data = b''

    def pack(self, sdu, seq_number):
        self.data = sdu
        self.sequence_number = seq_number & 0xFF
        data_length = len(sdu)
        
        header = struct.pack('!BBBB', 
                           self.version,
                           self.reserved, 
                           self.sequence_number,
                           self.class_of_msg)
        
        pdu = header + sdu
        return pdu

    def unpack(self, pdu):
        if len(pdu) < 4:
            raise ValueError(""PDU too short"")
        
        header = pdu[:4]
        self.version, self.reserved, self.sequence_number, self.class_of_msg = struct.unpack('!BBBB', header)
        
        self.data = pdu[4:]
        
        return {
            'version': self.version,
            'reserved': self.reserved,
            'sequence_number': self.sequence_number,
            'class_of_msg': self.class_of_msg,
            'data': self.data
        }",no_docstr,0.6505190311418685,0.41811846689895477,0.27368421052631586,0.4359861591695502,0.4676146383220411,0.6366666666666667,0.451505016722408,0.35570469798657717,0.8035102486610413,0.864682674407959,0.8329748511314392,0.8581494092941284,0.7705449302325585,0.644194756554307,0.3924528301886792,0.2661596958174905,0.47191011235955055,0.486571031151509,0.6984126984126984,0.4581673306772908,0.36,0.8343767523765564,0.8338165283203125,0.8340965509414673,0.8338724970817566,0.7771557865168541,0.6264150943396227,0.41064638783269963,0.2911877394636015,0.4528301886792453,0.5126750239548236,0.7072243346007605,0.49236641221374045,0.38697318007662834,0.8478962779045105,0.8298383951187134,0.8387701511383057,0.8316094875335693,0.8040143055555556,0.2400685038736109,0.092676700812287,0.1466625532410659,0.3670886075949367,0.3538461538461538,0.2262685407196106,0.1010521440053212,0.1446257189704922,0.3670886075949367,0.2923076923076923,0.2644647644116572,0.1532989117419537,0.1890781595366128,0.3924050632911392,0.3230769230769231
215508,addok/addok,addok_addok/addok/autocomplete.py,addok.autocomplete.EdgeNgramIndexer,"class EdgeNgramIndexer:
    @staticmethod
    def index(pipe, key, doc, tokens, **kwargs):
        if config.INDEX_EDGE_NGRAMS:  # Allow to disable for mass indexing.
            for token in tokens.keys():
                index_edge_ngrams(pipe, token)

    @staticmethod
    def deindex(db, key, doc, tokens, **kwargs):
        if config.INDEX_EDGE_NGRAMS:
            for token in tokens:
                tkey = dbkeys.token_key(token)
                if not DB.exists(tkey):
                    deindex_edge_ngrams(token)","class EdgeNgramIndexer:


    @staticmethod
    def index(pipe, key, doc, tokens, **kwargs):
        pass

    @staticmethod
    def deindex(db, key, doc, tokens, **kwargs):
        pass

",5,0,snippet_28,0.1666666666666666,"class EdgeNgramIndexer:

    @staticmethod
    def index(pipe, key, doc, tokens, min_gram=1, max_gram=20):
        """"""
        For each token, generate edge n-grams of lengths from min_gram up to max_gram (or token length)
        and add the document ID to the corresponding Redis set.
        """"""
        for token in tokens:
            token_length = len(token)
            upper = min(max_gram, token_length)
            for n in range(min_gram, upper + 1):
                ngram = token[:n]
                set_key = f""{key}:{ngram}""
                pipe.sadd(set_key, doc)

    @staticmethod
    def deindex(db, key, doc, tokens, min_gram=1, max_gram=20):
        """"""
        Remove the document ID from all edge n-gram sets for the given tokens.
        If after removal a set is empty, delete the key from Redis.
        """"""
        for token in tokens:
            token_length = len(token)
            upper = min(max_gram, token_length)
            for n in range(min_gram, upper + 1):
                ngram = token[:n]
                set_key = f""{key}:{ngram}""
                db.srem(set_key, doc)
                if db.scard(set_key) == 0:
                    db.delete(set_key)","class EdgeNgramIndexer:

    @staticmethod
    def index(pipe, key, doc, tokens, **kwargs):
        min_gram = kwargs.get('min_gram', 1)
        max_gram = kwargs.get('max_gram', 3)
        
        for token in tokens:
            # Generate edge n-grams (prefixes and suffixes)
            for i in range(min_gram, min(max_gram + 1, len(token) + 1)):
                # Prefix n-grams
                prefix = token[:i]
                pipe.sadd(f""{key}:edge_ngram:{prefix}"", doc)
                
                # Suffix n-grams
                suffix = token[-i:]
                pipe.sadd(f""{key}:edge_ngram:{suffix}"", doc)

    @staticmethod
    def deindex(db, key, doc, tokens, **kwargs):
        min_gram = kwargs.get('min_gram', 1)
        max_gram = kwargs.get('max_gram', 3)
        
        for token in tokens:
            # Remove edge n-grams (prefixes and suffixes)
            for i in range(min_gram, min(max_gram + 1, len(token) + 1)):
                # Prefix n-grams
                prefix = token[:i]
                db.srem(f""{key}:edge_ngram:{prefix}"", doc)
                
                # Suffix n-grams
                suffix = token[-i:]
                db.srem(f""{key}:edge_ngram:{suffix}"", doc)","class EdgeNgramIndexer:

    @staticmethod
    def index(pipe, key, doc, tokens, **kwargs):
        min_gram = kwargs.get('min_gram', 1)
        max_gram = kwargs.get('max_gram', 3)
        
        for token in tokens:
            token_str = str(token).lower()
            for i in range(min_gram, min(len(token_str) + 1, max_gram + 1)):
                ngram = token_str[:i]
                pipe.sadd(f""{key}:{ngram}"", doc)

    @staticmethod
    def deindex(db, key, doc, tokens, **kwargs):
        min_gram = kwargs.get('min_gram', 1)
        max_gram = kwargs.get('max_gram', 3)
        
        for token in tokens:
            token_str = str(token).lower()
            for i in range(min_gram, min(len(token_str) + 1, max_gram + 1)):
                ngram = token_str[:i]
                db.srem(f""{key}:{ngram}"", doc)",no_docstr,0.32888888888888884,0.17937219730941703,0.14479638009049772,0.28444444444444444,0.1797359829282888,0.2920962199312715,0.16896551724137931,0.11764705882352941,0.705631673336029,0.7938151359558105,0.747130274772644,0.7840172648429871,0.7885735428571428,0.3584905660377359,0.20952380952380956,0.17307692307692307,0.32075471698113206,0.20122551895563287,0.3,0.18394648829431437,0.1476510067114094,0.7235527038574219,0.8172160387039185,0.7675374746322632,0.8067724108695984,0.7648833035714285,0.3908045977011494,0.25581395348837205,0.21176470588235294,0.3448275862068966,0.2494840550207956,0.36554621848739494,0.22784810126582278,0.1864406779661017,0.7478681206703186,0.8097735047340393,0.7775906920433044,0.8031255602836609,0.78178912371134,0.4068407587297428,0.1162136146961034,0.3653160868895345,0.3333333333333333,0.8125,0.4123079207005278,0.1617004733388048,0.404197876129973,0.3333333333333333,0.75,0.4331534819367558,0.2246141073708888,0.4024442648205787,0.3555555555555555,0.75
114269,DataDog/integrations-core,clickhouse/datadog_checks/clickhouse/utils.py,datadog_checks.clickhouse.utils.ErrorSanitizer,"class ErrorSanitizer(object):
    def __init__(self, password):
        self.password = password

    @staticmethod
    def clean(error):
        return STACK_TRACE_LEFTOVER.sub('', error)

    def scrub(self, error):
        if self.password:
            return error.replace(self.password, '**********')

        return error","class ErrorSanitizer(object):


    def __init__(self, password):
        pass

    @staticmethod
    def clean(error):
        pass

    def scrub(self, error):
        pass

",5,0,snippet_427,1.0,"class ErrorSanitizer(object):

    def __init__(self, password):
        self._password = '' if password is None else str(password)

    @staticmethod
    def clean(error):
        # Convert exceptions or any object to a plain string
        if isinstance(error, BaseException):
            try:
                # If the exception has args, join them
                return ' '.join(str(arg) for arg in error.args)
            except Exception:
                return str(error)
        return str(error)

    def scrub(self, error):
        """"""
        Return a sanitized string form of the error,
        masking any occurrence of the stored password.
        """"""
        msg = self.clean(error)
        if self._password:
            mask = '*' * len(self._password)
            # escape the password for safe literal replacement
            import re
            pattern = re.escape(self._password)
            msg = re.sub(pattern, mask, msg)
        return msg","class ErrorSanitizer(object):

    def __init__(self, password):
        self.password = password

    @staticmethod
    def clean(error):
        if isinstance(error, Exception):
            return str(error)
        return error

    def scrub(self, error):
        if isinstance(error, Exception):
            error_str = str(error)
            if self.password in error_str:
                return error_str.replace(self.password, '*' * len(self.password))
            return error_str
        elif isinstance(error, str):
            if self.password in error:
                return error.replace(self.password, '*' * len(self.password))
            return error
        return error","class ErrorSanitizer(object):

    def __init__(self, password):
        self.password = password

    @staticmethod
    def clean(error):
        import re
        # Remove common sensitive patterns
        patterns = [
            r'password[=:\s]+[^\s\n]+',
            r'token[=:\s]+[^\s\n]+',
            r'key[=:\s]+[^\s\n]+',
            r'secret[=:\s]+[^\s\n]+',
            r'api_key[=:\s]+[^\s\n]+',
            r'auth[=:\s]+[^\s\n]+',
            r'credential[=:\s]+[^\s\n]+',
        ]
        
        cleaned_error = str(error)
        for pattern in patterns:
            cleaned_error = re.sub(pattern, lambda m: m.group().split('=')[0] + '=***' if '=' in m.group() else m.group().split(':')[0] + ':***' if ':' in m.group() else m.group().split()[0] + ' ***', cleaned_error, flags=re.IGNORECASE)
        
        return cleaned_error

    def scrub(self, error):
        error_str = str(error)
        if self.password and self.password in error_str:
            error_str = error_str.replace(self.password, '***')
        return self.clean(error_str)",no_docstr,0.41666666666666663,0.29577464788732394,0.21428571428571433,0.3611111111111111,0.258015294762277,0.36082474226804123,0.2538860103626943,0.1875,0.6932241916656494,0.8335787057876587,0.7569501996040344,0.817036509513855,0.777013724137931,0.5555555555555556,0.5283018867924528,0.4807692307692307,0.5555555555555556,0.4154713215139661,0.4896551724137931,0.4027777777777778,0.36363636363636365,0.8132408261299133,0.8688585162162781,0.8401301503181458,0.862956702709198,0.8136501574803149,0.36363636363636365,0.28220858895705525,0.2360248447204969,0.35151515151515156,0.1812597880595021,0.2175141242937853,0.17847025495750707,0.1534090909090909,0.6316549777984619,0.8250830173492432,0.7155271768569946,0.8005677461624146,0.7588349769585259,0.2562439702900446,0.0604290187292591,0.2848931827772397,0.3939393939393939,0.2857142857142857,0.5837881909996414,0.2501084271215978,0.6001958520284828,0.4848484848484848,1.0,0.4972353147716103,0.1386957971331543,0.5190766307844557,0.5454545454545454,0.7857142857142857
780674,tariqdaouda/pyGeno,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/tariqdaouda_pyGeno/pyGeno/importation/Genomes.py,pyGeno.importation.Genomes._importGenomeObjects.Store,"class Store(object):

    def __init__(self, conf):
        self.conf = conf
        self.chromosomes = {}

        self.genes = {}
        self.transcripts = {}
        self.proteins = {}
        self.exons = {}

    def batch_save(self):
        self.conf.db.beginTransaction()

        for c in self.genes.itervalues():
            c.save()
            conf.removeFromDBRegistery(c)

        for c in self.transcripts.itervalues():
            c.save()
            conf.removeFromDBRegistery(c.exons)
            conf.removeFromDBRegistery(c)

        for c in self.proteins.itervalues():
            c.save()
            conf.removeFromDBRegistery(c)

        self.conf.db.endTransaction()

        del (self.genes)
        del (self.transcripts)
        del (self.proteins)
        del (self.exons)

        self.genes = {}
        self.transcripts = {}
        self.proteins = {}
        self.exons = {}

        gc.collect()

    def save_chros(self):
        pBar = ProgressBar(nbEpochs=len(self.chromosomes))
        for c in self.chromosomes.itervalues():
            pBar.update(label='Chr %s' % c.number)
            c.save()
        pBar.close()
","class Store(object):



    def __init__(self, conf):
        pass


    def batch_save(self):
        pass


    def save_chros(self):
        pass

",4,0,snippet_612,0.2727272727272727,"class Store(object):

    def __init__(self, conf):
        self.conf = conf.copy() if isinstance(conf, dict) else {}
        self.batch_file = self.conf.get('batch_file', 'batch.jsonl')
        self.chros_file = self.conf.get('chros_file', 'chros.json')
        self.batch_size = self.conf.get('batch_size', 1000)
        bp = os.path.dirname(self.batch_file) or '.'
        cp = os.path.dirname(self.chros_file) or '.'
        os.makedirs(bp, exist_ok=True)
        os.makedirs(cp, exist_ok=True)
        self._batch = []
        self._chros = []

    def batch_save(self, item):
        self._batch.append(item)
        if len(self._batch) >= self.batch_size:
            self._flush_batch()

    def save_chros(self):
        with open(self.chros_file, 'w') as f:
            json.dump(self._chros, f, indent=2)

    def _flush_batch(self):
        with open(self.batch_file, 'a') as f:
            for record in self._batch:
                f.write(json.dumps(record) + ""\n"")
        self._batch = []","class Store(object):
    def __init__(self, conf):
        self.conf = conf
        self.data = []

    def batch_save(self):
        # Save all data in batch
        if self.data:
            # Simulate saving data
            saved_count = len(self.data)
            self.data = []
            return saved_count
        return 0

    def save_chros(self):
        # Save chromosome data
        return self.batch_save()","class Store(object):
    def __init__(self, conf):
        self.conf = conf
        self.batch_data = []
        self.chromosomes = []
        self.batch_size = conf.get('batch_size', 100) if conf else 100
        self.storage_path = conf.get('storage_path', './data') if conf else './data'
        
    def batch_save(self):
        if not self.batch_data:
            return
        
        import os
        import json
        
        os.makedirs(self.storage_path, exist_ok=True)
        
        batch_file = os.path.join(self.storage_path, f'batch_{len(self.batch_data)}.json')
        with open(batch_file, 'w') as f:
            json.dump(self.batch_data, f, indent=2)
        
        self.batch_data.clear()
    
    def save_chros(self):
        if not self.chromosomes:
            return
            
        import os
        import pickle
        
        os.makedirs(self.storage_path, exist_ok=True)
        
        chros_file = os.path.join(self.storage_path, 'chromosomes.pkl')
        with open(chros_file, 'wb') as f:
            pickle.dump(self.chromosomes, f)",no_docstr,0.34883720930232553,0.1484375,0.09448818897637795,0.2790697674418604,0.28635282241361987,0.5197368421052632,0.25742574257425743,0.17549668874172186,0.7184032797813416,0.7037153244018555,0.710983395576477,0.7051570415496826,0.7506107664233581,0.3333333333333333,0.20481927710843376,0.15853658536585366,0.30952380952380953,0.08847201232509726,0.6421052631578947,0.5212765957446809,0.44086021505376344,0.7725135684013367,0.6545066237449646,0.7086308002471924,0.6646597385406494,0.7325608139534888,0.31250000000000006,0.16535433070866143,0.11111111111111112,0.2734375,0.2841150672082546,0.48872180451127817,0.2528301886792453,0.1856060606060606,0.725679337978363,0.7325348854064941,0.7290909886360168,0.7318435311317444,0.745480581395349,0.2577318556503226,0.0914957659945511,0.0958178450076779,0.554140127388535,0.2894736842105263,0.2009651252658262,0.0789015514697437,0.1067893217021766,0.4076433121019108,0.2105263157894736,0.295647852808975,0.1079150847514382,0.1088700911509048,0.4394904458598726,0.5263157894736842
296728,cloud-custodian/cloud-custodian,tools/c7n_gcp/c7n_gcp/query.py,c7n_gcp.query.ResourceQuery,"class ResourceQuery:

    def __init__(self, session_factory):
        self.session_factory = session_factory

    def filter(self, resource_manager, **params):
        m = resource_manager.resource_type
        session = local_session(self.session_factory)
        client = session.client(
            m.service, m.version, m.component)

        # depends on resource scope
        if m.scope in ('project', 'zone'):
            project = session.get_default_project()
            if m.scope_template:
                project = m.scope_template.format(project)
            if m.scope_key:
                params[m.scope_key] = project
            else:
                params['project'] = project

        if m.scope == 'zone':
            if session.get_default_zone():
                params['zone'] = session.get_default_zone()

        enum_op, path, extra_args = m.enum_spec
        if extra_args:
            params.update(extra_args)
        return self._invoke_client_enum(
            client, enum_op, params, path)

    def _invoke_client_enum(self, client, enum_op, params, path):
        if client.supports_pagination(enum_op):
            results = []
            for page in client.execute_paged_query(enum_op, params):
                page_items = jmespath_search(path, page)
                if page_items:
                    results.extend(page_items)
            return results
        else:
            return jmespath_search(path,
                client.execute_query(enum_op, verb_arguments=params))","class ResourceQuery:


    def __init__(self, session_factory):
        pass

    def filter(self, resource_manager, **params):
        pass

    def _invoke_client_enum(self, client, enum_op, params, path):
        pass

",4,0,snippet_541,0.1428571428571428,"class ResourceQuery:

    def __init__(self, session_factory):
        self._session_factory = session_factory

    def filter(self, resource_manager, **params):
        """"""
        Call the manager's enumeration operation and return all items.
        """"""
        # create a client/session from the factory
        client = self._session_factory()
        # invoke the enumeration and return a list
        return list(self._invoke_client_enum(
            client,
            resource_manager.enum_op,
            params,
            resource_manager.path
        ))

    def _invoke_client_enum(self, client, enum_op, params, path):
        """"""
        Invoke a client operation (with pagination if available), drill into
        the resulting structure by `path`, and yield each element.
        """"""
        # try to use a paginator if the client supports it
        try:
            paginator = client.get_paginator(enum_op)
        except Exception:
            paginator = None

        if paginator:
            pages = paginator.paginate(**params)
        else:
            operation = getattr(client, enum_op)
            pages = [operation(**params)]

        # for each page, walk down the nested keys and yield items
        for page in pages:
            data = page
            # allow path to be a string with dots or a list/tuple
            if isinstance(path, str):
                keys = path.split('.')
            else:
                keys = path

            for k in keys:
                data = data.get(k, {})

            if isinstance(data, list):
                for item in data:
                    yield item","class ResourceQuery:
    def __init__(self, session_factory):
        self.session_factory = session_factory

    def filter(self, resource_manager, **params):
        results = []
        session = self.session_factory()
        try:
            client = resource_manager.get_client(session)
            enum_op = resource_manager.get_enum_operation()
            path = resource_manager.get_path()
            results = self._invoke_client_enum(client, enum_op, params, path)
        finally:
            session.close()
        return results

    def _invoke_client_enum(self, client, enum_op, params, path):
        operation = getattr(client, enum_op)
        if params:
            return list(operation(**params))
        else:
            return list(operation())","class ResourceQuery:
    def __init__(self, session_factory):
        self.session_factory = session_factory
        self.filters = []
        self.params = {}

    def filter(self, resource_manager, **params):
        self.resource_manager = resource_manager
        self.params.update(params)
        return self

    def _invoke_client_enum(self, client, enum_op, params, path):
        try:
            operation = getattr(client, enum_op)
            response = operation(**params)
            
            if path:
                result = response
                for key in path.split('.'):
                    if isinstance(result, dict):
                        result = result.get(key, [])
                    else:
                        result = getattr(result, key, [])
                return result
            
            return response
        except Exception as e:
            return []",no_docstr,0.45197740112994345,0.25,0.18285714285714288,0.3276836158192091,0.36113727141671115,0.5987654320987654,0.3498452012383901,0.2608695652173913,0.7841885685920715,0.8109421730041504,0.7973411083221436,0.8081849217414856,0.7723600000000005,0.5533596837944664,0.3426294820717131,0.26506024096385544,0.4347826086956522,0.2751316160869928,0.9209039548022598,0.6704545454545454,0.5428571428571428,0.8995286226272583,0.7883259057998657,0.8402640223503113,0.7981933951377869,0.80217,0.42519685039370075,0.24603174603174602,0.192,0.3543307086614173,0.21171271265759803,0.8,0.5114942528735632,0.3988439306358382,0.8396927714347839,0.7757340669631958,0.8064472675323486,0.7816881537437439,0.7547450000000009,0.2713308959810316,0.1000753910643491,0.1740441794818509,0.4307692307692308,0.3804347826086957,0.267742770844538,0.1569091244517075,0.2038612900301233,0.4384615384615384,0.2717391304347826,0.218340166791019,0.1408728172739983,0.1644276492211815,0.3615384615384615,0.2065217391304347
699222,rdeits/meshcat-python,rdeits_meshcat-python/src/meshcat/animation.py,meshcat.animation.AnimationClip,"class AnimationClip(object):
    __slots__ = [""tracks"", ""fps"", ""name""]

    def __init__(self, tracks=None, fps=30, name=u""default""):
        if tracks is None:
            self.tracks = {}
        else:
            self.tracks = tracks
        self.fps = fps
        self.name = name

    def set_property(self, frame, property, jstype, value):
        if property not in self.tracks:
            self.tracks[property] = AnimationTrack(property, jstype)
        track = self.tracks[property]
        track.set_property(frame, value)

    def lower(self):
        return {
            u""fps"": self.fps,
            u""name"": str(self.name),
            u""tracks"": [t.lower() for t in self.tracks.values()]
        }","class AnimationClip(object):


    def __init__(self, tracks=None, fps=30, name=u""default""):
        pass

    def set_property(self, frame, property, jstype, value):
        pass

    def lower(self):
        pass

",4,0,snippet_242,1.0,"class AnimationClip(object):

    def __init__(self, tracks=None, fps=30, name=u""default""):
        self.tracks = {} if tracks is None else tracks
        self.fps = fps
        self.name = name

    def set_property(self, frame, property, jstype, value):
        if property not in self.tracks:
            self.tracks[property] = {}
        if jstype not in self.tracks[property]:
            self.tracks[property][jstype] = []
        self.tracks[property][jstype].append({
            'frame': frame,
            'value': value
        })

    def lower(self):
        output = {
            'name': self.name,
            'fps': self.fps,
            'tracks': []
        }
        for prop, jsmap in self.tracks.items():
            for jstype, keylist in jsmap.items():
                sorted_keys = sorted(keylist, key=lambda k: k['frame'])
                output['tracks'].append({
                    'property': prop,
                    'type': jstype,
                    'keys': sorted_keys
                })
        return output","class AnimationClip(object):
    def __init__(self, tracks=None, fps=30, name=u""default""):
        self.tracks = tracks if tracks is not None else {}
        self.fps = fps
        self.name = name

    def set_property(self, frame, property, jstype, value):
        if frame not in self.tracks:
            self.tracks[frame] = {}
        if property not in self.tracks[frame]:
            self.tracks[frame][property] = {}
        self.tracks[frame][property][jstype] = value

    def lower(self):
        return {
            ""tracks"": self.tracks,
            ""fps"": self.fps,
            ""name"": self.name
        }","class AnimationClip(object):

    def __init__(self, tracks=None, fps=30, name=u""default""):
        self.tracks = tracks if tracks is not None else {}
        self.fps = fps
        self.name = name

    def set_property(self, frame, property, jstype, value):
        if property not in self.tracks:
            self.tracks[property] = {}
        
        self.tracks[property][frame] = {
            'type': jstype,
            'value': value
        }

    def lower(self):
        return self.name.lower()",no_docstr,0.7216494845360825,0.53125,0.39999999999999997,0.6185567010309279,0.5183350237816463,0.68,0.49107142857142855,0.4170403587443946,0.8583363890647888,0.9059897065162659,0.8815194964408875,0.9009875059127808,0.7880205529953919,0.8374999999999999,0.6582278481012659,0.44871794871794873,0.6875,0.6142958504699221,0.8853503184713376,0.7307692307692307,0.6258064516129033,0.9383841156959534,0.9036849737167358,0.9207077026367188,0.9070390462875366,0.8479181875,0.786206896551724,0.6433566433566434,0.5106382978723405,0.7310344827586207,0.4743724621327383,0.9586776859504132,0.7916666666666666,0.7142857142857143,0.9346115589141846,0.8939393758773804,0.913823127746582,0.8978466391563416,0.8291683749999998,0.4214072614104709,0.315938973235249,0.4571900724066346,0.5375,0.375,0.3754204376351296,0.388590301472865,0.4059485919247965,0.475,0.2321428571428571,0.4068247286969905,0.4090496341633097,0.4378921377675095,0.5125,0.2678571428571428
131461,IndicoDataSolutions/Passage,IndicoDataSolutions_Passage/passage/layers.py,passage.layers.OneHot,"class OneHot(object):

    def __init__(self, n_features, weights=None):
        self.settings = locals()
        del self.settings['self']
        self.size = n_features
        self.n_features = n_features
        self.input = T.imatrix()
        self.params = []

    def output(self, dropout_active=False):
        return theano_one_hot(self.input.flatten(), self.n_features).reshape((self.input.shape[0], self.input.shape[1], self.size))","class OneHot(object):


    def __init__(self, n_features, weights=None):
        pass

    def output(self, dropout_active=False):
        pass

",3,0,snippet_366,0.75,"class OneHot(object):
    def __init__(self, n_features, weights=None):
        self.n_features = n_features
        if weights is None:
            self.keep_probs = np.ones(self.n_features, dtype=float)
        else:
            w = np.array(weights, dtype=float)
            if w.ndim == 0:
                w = np.full(self.n_features, w, dtype=float)
            if w.shape != (self.n_features,):
                raise ValueError(""weights must be a scalar or array of length n_features"")
            self.keep_probs = w

    def output(self, dropout_active=False):
        if dropout_active:
            mask = np.random.binomial(1, self.keep_probs)
            # Inverted dropout scaling
            mask = mask / self.keep_probs
        else:
            mask = np.ones(self.n_features, dtype=float)
        return np.diag(mask)","class OneHot(object):
    def __init__(self, n_features, weights=None):
        self.n_features = n_features
        if weights is None:
            self.weights = np.ones(n_features)
        else:
            self.weights = np.array(weights)
            if len(self.weights) != n_features:
                raise ValueError(""Length of weights must match n_features"")
    
    def output(self, dropout_active=False):
        if dropout_active:
            # Apply dropout by setting some weights to zero
            dropout_mask = np.random.binomial(1, 0.5, self.n_features)
            return self.weights * dropout_mask
        else:
            return self.weights.copy()","class OneHot(object):
    def __init__(self, n_features, weights=None):
        self.n_features = n_features
        self.weights = weights
        self._output = None
    
    def output(self, dropout_active=False):
        if self._output is None:
            import numpy as np
            self._output = np.eye(self.n_features)
        
        if dropout_active and self.weights is not None:
            return self._output * self.weights
        
        return self._output",no_docstr,0.4378698224852071,0.28742514970059885,0.2181818181818182,0.37869822485207105,0.3238254114496277,0.47619047619047616,0.2966507177033493,0.2403846153846154,0.7308599948883057,0.8272852897644043,0.7760890126228333,0.8165127038955688,0.8008405660377358,0.4755244755244756,0.31205673758865243,0.24460431654676257,0.4195804195804196,0.4263456445511907,0.5909090909090909,0.39869281045751637,0.32894736842105265,0.7919607758522034,0.8242013454437256,0.8077594637870789,0.8208596706390381,0.8078097297297296,0.5546218487394957,0.376068376068376,0.31304347826086953,0.5042016806722689,0.46541957448192434,0.7,0.5504587155963303,0.4537037037037037,0.8516741991043091,0.833970308303833,0.8427292704582214,0.8357075452804565,0.79166875,0.3109145405323963,0.099932011144275,0.2561211089685034,0.4464285714285714,0.4411764705882353,0.306033483481488,0.1285890288246345,0.254158350479469,0.5178571428571429,0.3235294117647059,0.2895863861719953,0.176246017737924,0.254158350479469,0.375,0.3529411764705882
284574,cecton/destream,cecton_destream/destream/decompressors/p7zip.py,destream.decompressors.p7zip.Member,"class Member:
    def __init__(self, hunk):
        info = parse_hunk(hunk)
        info[""filename""] = info[""path""]
        info[""size""] = int(info[""size""])
        info[""packed_size""] = int(info[""packed_size""] or ""0"")
        info[""block""] = int(info[""block""] or ""0"")
        if info[""crc""]:
            info[""crc""] = reduce(
                lambda x, y: x * 256 + y,
                struct.unpack(""BBBB"", binascii.unhexlify(info[""crc""])),
                0,
            )
        self.__dict__.update(info)

    def isfile(self):
        return self.attributes[0] != ""D""

    def isdir(self):
        return self.attributes[0] == ""D""","class Member:


    def __init__(self, hunk):
        pass

    def isfile(self):
        pass

    def isdir(self):
        pass

",4,0,snippet_576,0.1818181818181818,"class Member:
    def __init__(self, hunk):
        self._path = Path(hunk)

    def isfile(self):
        return self._path.is_file()

    def isdir(self):
        return self._path.is_dir()","class Member:
    def __init__(self, hunk):
        self.hunk = hunk

    def isfile(self):
        return not self.isdir()

    def isdir(self):
        return hasattr(self.hunk, 'isdir') and self.hunk.isdir()","class Member:
    def __init__(self, hunk):
        self.hunk = hunk
        self.name = hunk.get('name', '')
        self.type = hunk.get('type', '')
        self.mode = hunk.get('mode', 0)
        self.size = hunk.get('size', 0)

    def isfile(self):
        return self.type == 'file' or (hasattr(self, 'mode') and self.mode & 0o170000 == 0o100000)

    def isdir(self):
        return self.type == 'dir' or (hasattr(self, 'mode') and self.mode & 0o170000 == 0o040000)",no_docstr,0.3762376237623763,0.26262626262626265,0.2061855670103093,0.33663366336633666,0.06182766886721274,0.8813559322033898,0.6206896551724138,0.543859649122807,0.8210606575012207,0.644094705581665,0.7218904495239258,0.6582828760147095,0.7344348901098907,0.36893203883495146,0.23762376237623764,0.1616161616161616,0.34951456310679613,0.048275486838796594,0.8421052631578947,0.5535714285714286,0.43636363636363634,0.7834692001342773,0.6431598663330078,0.7064148187637329,0.6548880934715271,0.7179515384615391,0.36231884057971014,0.22058823529411764,0.1492537313432836,0.30434782608695654,0.20121315096766568,0.5801526717557252,0.27692307692307694,0.23255813953488372,0.7745641469955444,0.7329912781715393,0.7532045245170593,0.736946702003479,0.7692330769230772,0.0979310341942005,0.035813581661915,0.1215077030649763,0.1363636363636363,0.0980392156862745,0.1445781524054013,0.0550669386421906,0.1215077030649763,0.2840909090909091,0.1176470588235294,0.2094937611815288,0.1189597683178671,0.1325625134848968,0.2727272727272727,0.3137254901960784
618540,openthread/openthread,tests/scripts/thread-cert/mle.py,thread-cert.mle.MleMessageFactory,"class MleMessageFactory:

    def __init__(self, aux_sec_hdr_factory, mle_command_factory, crypto_engine):
        self._aux_sec_hdr_factory = aux_sec_hdr_factory
        self._mle_command_factory = mle_command_factory
        self._crypto_engine = crypto_engine

    def _create_mle_secured_message(self, data, message_info):
        aux_sec_hdr = self._aux_sec_hdr_factory.parse(data, message_info)

        enc_data_length = len(data.getvalue())

        enc_data = bytearray(data.read(enc_data_length - data.tell() - self._crypto_engine.mic_length))
        mic = bytearray(data.read())

        dec_data = self._crypto_engine.decrypt(enc_data, mic, message_info)

        command = self._mle_command_factory.parse(io.BytesIO(dec_data), message_info)

        return MleMessageSecured(aux_sec_hdr, command, mic)

    def _create_mle_message(self, data, message_info):
        command = self._mle_command_factory.parse(data, message_info)

        return MleMessage(command)

    def parse(self, data, message_info):
        security_indicator = ord(data.read(1))

        if security_indicator == 0:
            return self._create_mle_secured_message(data, message_info)

        elif security_indicator == 255:
            return self._create_mle_message(data, message_info)

        else:
            raise RuntimeError(
                ""Could not create MLE message. Unknown security indicator value: {}"".format(security_indicator))","class MleMessageFactory:


    def __init__(self, aux_sec_hdr_factory, mle_command_factory, crypto_engine):
        pass

    def _create_mle_secured_message(self, data, message_info):
        pass

    def _create_mle_message(self, data, message_info):
        pass

    def parse(self, data, message_info):
        pass

",5,0,snippet_184,0.3333333333333333,"class MleMessageFactory:

    def __init__(self, aux_sec_hdr_factory, mle_command_factory, crypto_engine):
        self.aux_sec_hdr_factory = aux_sec_hdr_factory
        self.mle_command_factory = mle_command_factory
        self.crypto_engine = crypto_engine

    def _create_mle_secured_message(self, data, message_info):
        # first build the plaintext MLE payload
        plaintext = self.mle_command_factory.create(data, message_info)
        # build the auxiliary security header
        aux_hdr = self.aux_sec_hdr_factory.create(message_info)
        # derive encryption parameters
        key = self.crypto_engine.get_key(message_info, aux_hdr)
        nonce = aux_hdr.nonce
        aad = aux_hdr.header
        # encrypt
        ciphertext = self.crypto_engine.encrypt(plaintext, key, nonce, aad)
        # prepend AAD/header to ciphertext
        return aad + ciphertext

    def _create_mle_message(self, data, message_info):
        # build an unsecured MLE payload
        return self.mle_command_factory.create(data, message_info)

    def parse(self, data, message_info):
        # determine whether the incoming message is secured
        if getattr(message_info, 'security_enabled', False):
            # parse and strip the auxiliary security header
            aux_hdr, header_len = self.aux_sec_hdr_factory.parse(data)
            aad = data[:header_len]
            ciphertext = data[header_len:]
            # derive decryption parameters
            key = self.crypto_engine.get_key(message_info, aux_hdr)
            nonce = aux_hdr.nonce
            # decrypt
            plaintext = self.crypto_engine.decrypt(ciphertext, key, nonce, aad)
            # parse the decrypted MLE command
            command = self.mle_command_factory.parse(plaintext, message_info)
            return {'aux_sec_hdr': aux_hdr, 'command': command}
        else:
            # parse an unsecured MLE command directly
            command = self.mle_command_factory.parse(data, message_info)
            return {'command': command}","class MleMessageFactory:
    def __init__(self, aux_sec_hdr_factory, mle_command_factory, crypto_engine):
        self._aux_sec_hdr_factory = aux_sec_hdr_factory
        self._mle_command_factory = mle_command_factory
        self._crypto_engine = crypto_engine

    def _create_mle_secured_message(self, data, message_info):
        # Parse auxiliary security header
        aux_sec_hdr, offset = self._aux_sec_hdr_factory.parse(data, message_info)
        
        # Decrypt the payload
        encrypted_payload = data[offset:]
        decrypted_payload = self._crypto_engine.decrypt(encrypted_payload, message_info)
        
        # Parse the MLE command from decrypted payload
        mle_command = self._mle_command_factory.parse(decrypted_payload, message_info)
        
        # Create and return secured MLE message
        return {
            'aux_sec_hdr': aux_sec_hdr,
            'mle_command': mle_command,
            'is_secured': True
        }

    def _create_mle_message(self, data, message_info):
        # Parse MLE command directly from data
        mle_command = self._mle_command_factory.parse(data, message_info)
        
        # Create and return unsecured MLE message
        return {
            'mle_command': mle_command,
            'is_secured': False
        }

    def parse(self, data, message_info):
        # Check if message is secured by looking at message info or data structure
        if message_info.is_secured:
            return self._create_mle_secured_message(data, message_info)
        else:
            return self._create_mle_message(data, message_info)","class MleMessageFactory:

    def __init__(self, aux_sec_hdr_factory, mle_command_factory, crypto_engine):
        self._aux_sec_hdr_factory = aux_sec_hdr_factory
        self._mle_command_factory = mle_command_factory
        self._crypto_engine = crypto_engine

    def _create_mle_secured_message(self, data, message_info):
        aux_sec_hdr = self._aux_sec_hdr_factory.parse(data, message_info)
        
        encrypted_data = data[aux_sec_hdr.get_length():]
        decrypted_data = self._crypto_engine.decrypt(encrypted_data, aux_sec_hdr, message_info)
        
        command = self._mle_command_factory.parse(decrypted_data, message_info)
        
        return MleSecuredMessage(aux_sec_hdr, command)

    def _create_mle_message(self, data, message_info):
        command = self._mle_command_factory.parse(data, message_info)
        return MleMessage(command)

    def parse(self, data, message_info):
        if len(data) == 0:
            raise ValueError(""Empty data"")
        
        security_suite = data[0]
        
        if security_suite == 0:
            return self._create_mle_message(data[1:], message_info)
        else:
            return self._create_mle_secured_message(data[1:], message_info)",no_docstr,0.6064814814814815,0.4511627906976744,0.37383177570093457,0.43518518518518523,0.4853920437589334,0.6622807017543859,0.45054945054945056,0.3832599118942731,0.8521704077720642,0.8746252059936523,0.863251805305481,0.8723265528678894,0.8033873828125004,0.6649076517150396,0.5411140583554376,0.46933333333333327,0.6332453825857519,0.6321202583453406,0.7582417582417582,0.6418732782369146,0.6022099447513812,0.8915992975234985,0.8810867071151733,0.8863118290901184,0.8821267485618591,0.8287054166666665,0.7988165680473372,0.6785714285714286,0.6107784431137725,0.757396449704142,0.690011079508125,0.9079754601226994,0.8123076923076923,0.7469135802469136,0.9525846242904663,0.9073905944824219,0.929438591003418,0.9117161631584167,0.8672852777777778,0.3047056097290913,0.1139501237241472,0.2130305956025746,0.408695652173913,0.4831460674157303,0.4053480884058917,0.248726050515266,0.3423780764351208,0.4347826086956521,0.5955056179775281,0.5251962103056815,0.4271291445175675,0.4542126092601168,0.5565217391304348,0.6629213483146067
170714,PyCQA/pylint,doc/data/messages/t/too-many-public-methods/good.py,good.LaserBeam,"class LaserBeam:
    def __init__(self):
        pass

    def fire(self):
        pass

    def activate_super(self):
        pass

    def destroy_planet(self):
        pass","class LaserBeam:


    def __init__(self):
        pass

    def fire(self):
        pass

    def activate_super(self):
        pass

    def destroy_planet(self):
        pass

",5,0,snippet_499,1.0,"class LaserBeam:
    def __init__(self):
        self.super_mode = False

    def fire(self):
        print(""Firing laser beam."")

    def activate_super(self):
        if not self.super_mode:
            self.super_mode = True
            print(""Super mode activated."")
        else:
            print(""Super mode already active."")

    def destroy_planet(self):
        if self.super_mode:
            print(""Planet destroyed!"")
            self.super_mode = False
        else:
            print(""Super mode not active. Cannot destroy planet."")","class LaserBeam:
    def __init__(self):
        self.is_firing = False
        self.super_mode = False
        self.charge_level = 100

    def fire(self):
        if self.charge_level > 0:
            self.is_firing = True
            self.charge_level -= 10
            return ""Laser beam fired!""
        else:
            return ""Insufficient charge!""

    def activate_super(self):
        if self.charge_level >= 50:
            self.super_mode = True
            self.charge_level -= 50
            return ""Super mode activated!""
        else:
            return ""Not enough charge to activate super mode!""

    def destroy_planet(self):
        if self.super_mode and self.charge_level >= 100:
            self.charge_level = 0
            return ""Planet destroyed!""
        else:
            return ""Insufficient power to destroy planet!""","class LaserBeam:
    def __init__(self):
        self.power_level = 1
        self.is_active = False
        self.super_mode = False
        self.charge = 0
        self.max_charge = 100

    def fire(self):
        if self.is_active and self.charge >= 10:
            self.charge -= 10
            damage = self.power_level * 10
            if self.super_mode:
                damage *= 5
            return damage
        return 0

    def activate_super(self):
        if self.charge >= 50:
            self.super_mode = True
            self.is_active = True
            self.charge -= 50
            self.power_level *= 3
            return True
        return False

    def destroy_planet(self):
        if self.super_mode and self.charge >= 80:
            self.charge = 0
            self.super_mode = False
            self.power_level = 1
            self.is_active = False
            return ""Planet destroyed!""
        return ""Insufficient power to destroy planet""",no_docstr,0.38554216867469876,0.2962962962962963,0.20253164556962025,0.38554216867469876,0.25466509427661865,0.2857142857142857,0.256,0.22580645161290322,0.732875645160675,0.8809953331947327,0.8001383543014526,0.8635424971580505,0.7491434020618557,0.27118644067796605,0.20689655172413793,0.14035087719298245,0.27118644067796605,0.1768488064685015,0.19889502762430938,0.17777777777777778,0.1564245810055866,0.637678325176239,0.8334330320358276,0.7225316166877747,0.8086103200912476,0.7268197744360901,0.2352941176470588,0.1791044776119403,0.12121212121212122,0.2352941176470588,0.1545277073299472,0.17391304347826086,0.1553398058252427,0.13658536585365855,0.6353055834770203,0.8260453343391418,0.7182275652885437,0.8019676804542542,0.7131811627906977,0.1977867696200652,0.0761113766887584,0.2545093860020286,0.2105263157894736,0.25,0.1894366525553782,0.0427109084300108,0.2545093860020286,0.2105263157894736,0.25,0.1876091596088727,0.0354009366439887,0.2545093860020286,0.2105263157894736,0.25
688691,quora/qcore,quora_qcore/qcore/enum.py,qcore.enum.EnumValueGenerator,"class EnumValueGenerator:
    def __init__(self, start=1):
        self._next_value = start

    def reset(self, start=1):
        self._next_value = start

    def next(self):
        result = self._next_value
        self._next_value += 1
        return result

    def __call__(self):
        return self.next()

    def __repr__(self):
        return ""%s(%r)"" % (self.__class__.__name__, self._next_value)","class EnumValueGenerator:


    def __init__(self, start=1):
        pass

    def reset(self, start=1):
        pass

    def next(self):
        pass

    def __call__(self):
        pass

    def __repr__(self):
        pass

",6,0,snippet_623,1.0,"class EnumValueGenerator:
    def __init__(self, start=1):
        self.start = start
        self.current = start - 1

    def reset(self, start=1):
        self.start = start
        self.current = start - 1

    def next(self):
        self.current += 1
        return self.current

    def __call__(self):
        return self.next()

    def __repr__(self):
        return f""{self.__class__.__name__}(start={self.start}, next={self.current + 1})""","class EnumValueGenerator:
    def __init__(self, start=1):
        self.current = start
        self.start = start

    def reset(self, start=1):
        self.current = start
        self.start = start

    def next(self):
        value = self.current
        self.current += 1
        return value

    def __call__(self):
        return self.next()

    def __repr__(self):
        return f""EnumValueGenerator(start={self.start}, current={self.current})""","class EnumValueGenerator:
    def __init__(self, start=1):
        self.start = start
        self.current = start

    def reset(self, start=1):
        self.start = start
        self.current = start

    def next(self):
        value = self.current
        self.current += 1
        return value

    def __call__(self):
        return self.next()

    def __repr__(self):
        return f""EnumValueGenerator(start={self.start}, current={self.current})""",no_docstr,0.7102803738317757,0.49523809523809526,0.38834951456310685,0.6915887850467289,0.6322946433789634,0.75,0.6259541984732825,0.5384615384615384,0.918929934501648,0.9206888675689697,0.9198085069656372,0.9205126762390137,0.8692823529411764,0.7115384615384615,0.5294117647058824,0.42,0.6730769230769231,0.5968781239153158,0.782608695652174,0.6578947368421053,0.5663716814159292,0.9298279881477356,0.9181358218193054,0.923944890499115,0.9192917943000793,0.9219865957446809,0.7115384615384615,0.5294117647058824,0.42,0.6730769230769231,0.5968781239153158,0.782608695652174,0.6578947368421053,0.5663716814159292,0.92917799949646,0.9170858860015869,0.9230923056602478,0.9182808995246887,0.9219865957446809,0.5097616217076639,0.3121372564096279,0.3952593987711965,0.5909090909090909,0.7407407407407407,0.6193043880500596,0.4172803476742279,0.48923013381894,0.6818181818181818,0.8888888888888888,0.6193043880500596,0.4172803476742279,0.48923013381894,0.6818181818181818,0.8888888888888888
626198,pandas-dev/pandas,pandas-dev_pandas/asv_bench/benchmarks/frame_methods.py,benchmarks.frame_methods.ToDict,"class ToDict:
    params = [[""dict"", ""list"", ""series"", ""split"", ""records"", ""index""]]
    param_names = [""orient""]

    def setup(self, orient):
        data = np.random.randint(0, 1000, size=(10000, 4))
        self.int_df = DataFrame(data)
        self.datetimelike_df = self.int_df.astype(""timedelta64[ns]"")

    def time_to_dict_ints(self, orient):
        self.int_df.to_dict(orient=orient)

    def time_to_dict_datetimelike(self, orient):
        self.datetimelike_df.to_dict(orient=orient)","class ToDict:


    def setup(self, orient):
        pass

    def time_to_dict_ints(self, orient):
        pass

    def time_to_dict_datetimelike(self, orient):
        pass

",4,0,snippet_174,1.0,"class ToDict:
    def __init__(self, data):
        self.data = data

    def setup(self, orient):
        if orient == 'ints':
            return self.time_to_dict_ints(orient)
        elif orient == 'datetimelike':
            return self.time_to_dict_datetimelike(orient)
        else:
            raise ValueError(f""Unknown orient: {orient!r}"")

    def time_to_dict_ints(self, orient):
        result = {}
        for key, val in self.data.items():
            if hasattr(val, 'timestamp'):
                # datetime-like  epoch seconds as int
                result[key] = int(val.timestamp())
            else:
                result[key] = int(val)
        return result

    def time_to_dict_datetimelike(self, orient):
        result = {}
        for key, val in self.data.items():
            if isinstance(val, datetime):
                result[key] = val
            else:
                # assume numeric  convert from epoch seconds
                result[key] = datetime.fromtimestamp(int(val))
        return result","class ToDict:
    def setup(self, orient):
        pass

    def time_to_dict_ints(self, orient):
        pass

    def time_to_dict_datetimelike(self, orient):
        pass","class ToDict:
    def __init__(self):
        self.df_ints = None
        self.df_datetimelike = None

    def setup(self, orient):
        # Create DataFrame with integer data
        np.random.seed(42)
        data_ints = np.random.randint(0, 1000, size=(1000, 10))
        self.df_ints = pd.DataFrame(data_ints, columns=[f'col_{i}' for i in range(10)])
        
        # Create DataFrame with datetime-like data
        dates = pd.date_range('2020-01-01', periods=1000, freq='D')
        timestamps = pd.to_datetime(dates)
        timedeltas = pd.to_timedelta(np.arange(1000), unit='D')
        
        self.df_datetimelike = pd.DataFrame({
            'dates': dates,
            'timestamps': timestamps,
            'timedeltas': timedeltas,
            'periods': pd.period_range('2020-01', periods=1000, freq='D')
        })

    def time_to_dict_ints(self, orient):
        return self.df_ints.to_dict(orient=orient)

    def time_to_dict_datetimelike(self, orient):
        return self.df_datetimelike.to_dict(orient=orient)",no_docstr,0.4505494505494506,0.2222222222222222,0.1348314606741573,0.3186813186813186,0.2759645012948361,0.4933920704845815,0.252212389380531,0.1688888888888889,0.7227186560630798,0.7874040007591248,0.7536759972572327,0.7804190516471863,0.7509388202247196,0.4444444444444444,0.36363636363636365,0.27906976744186046,0.4444444444444444,0.05656367885769323,0.9302325581395349,0.8571428571428571,0.7804878048780488,0.8573452234268188,0.7534177303314209,0.8020287752151489,0.7626627087593079,0.7262900000000001,0.4875621890547264,0.30150753768844224,0.23350253807106602,0.44776119402985076,0.32409743681931447,0.4431818181818182,0.30038022813688214,0.25572519083969464,0.7620173692703247,0.844523012638092,0.8011515736579895,0.8354771137237549,0.7665153917050697,0.1642210568807735,0.0279379450206841,0.076325076353415,0.3898305084745763,0.1627906976744186,0.0516331342439323,0.0365829655348559,0.0725904859067782,0.0508474576271186,0.0465116279069767,0.2747138342854456,0.0386061653610393,0.0886291481307626,0.576271186440678,0.3953488372093023
634675,pbrisk/mathtoolspy,pbrisk_mathtoolspy/mathtoolspy/utils/math_fcts.py,mathtoolspy.utils.math_fcts.FctWithCount,"class FctWithCount(object):
    def __init__(self, fct):
        self.fct = fct
        self.number_of_calls = 0

    def __call__(self, x):
        self.number_of_calls += 1
        return self.fct(x)","class FctWithCount(object):


    def __init__(self, fct):
        pass

    def __call__(self, x):
        pass

",3,0,snippet_477,1.0,"class FctWithCount(object):
    def __init__(self, fct):
        self.fct = fct
        self.count = 0

    def __call__(self, x):
        self.count += 1
        return self.fct(x)","class FctWithCount(object):
    def __init__(self, fct):
        self.fct = fct
        self.count = 0

    def __call__(self, x):
        self.count += 1
        return self.fct(x)","class FctWithCount(object):
    def __init__(self, fct):
        self.fct = fct
        self.count = 0

    def __call__(self, x):
        self.count += 1
        return self.fct(x)",no_docstr,0.8461538461538461,0.76,0.6666666666666667,0.8461538461538461,0.7940981971427863,0.9629629629629629,0.9245283018867925,0.8846153846153846,0.9796719551086426,0.9421508312225342,0.9605451226234436,0.9457731246948242,1.0,0.8461538461538461,0.76,0.6666666666666667,0.8461538461538461,0.7940981971427863,0.9629629629629629,0.9245283018867925,0.8846153846153846,0.9796719551086426,0.9421508312225342,0.9605451226234436,0.9457731246948242,1.0,0.8461538461538461,0.76,0.6666666666666667,0.8461538461538461,0.7940981971427863,0.9629629629629629,0.9245283018867925,0.8846153846153846,0.9796719551086426,0.9421508312225342,0.9605451226234436,0.9457731246948242,1.0,0.8466883849619825,0.6888365053466561,0.697917034501274,1.0,1.0,0.8466883849619825,0.6888365053466561,0.697917034501274,1.0,1.0,0.8466883849619825,0.6888365053466561,0.697917034501274,1.0,1.0
829850,westonplatter/fast_arrow,westonplatter_fast_arrow/fast_arrow/resources/account.py,fast_arrow.resources.account.Account,"class Account(object):

    @classmethod
    def all(cls, client):
        request_url = ""https://api.robinhood.com/accounts/""
        data = client.get(request_url)
        results = data[""results""]
        while data[""next""]:
            data = client.get(data[""next""])
            results.extend(data[""results""])
        return results

    @classmethod
    def all_urls(cls, client):
        accounts = cls.all(client)
        urls = [x[""url""] for x in accounts]
        return urls","class Account(object):


    @classmethod
    def all(cls, client):
        pass

    @classmethod
    def all_urls(cls, client):
        pass

",5,0,snippet_152,0.2222222222222222,"class Account(object):
    def __init__(self, **data):
        for k, v in data.items():
            setattr(self, k, v)

    @classmethod
    def all(cls, client):
        accounts = client.paginate('/accounts', 'accounts')
        return [cls(**acct) for acct in accounts]

    @classmethod
    def all_urls(cls, client):
        accounts = client.paginate('/accounts', 'accounts')
        return [acct.get('url') for acct in accounts]","class Account(object):

    @classmethod
    def all(cls, client):
        """"""
        Retrieve all accounts for the given client.
        
        Args:
            client: The client object used to make the API request
            
        Returns:
            A list of Account objects
        """"""
        # Assuming there's an endpoint to fetch all accounts
        response = client.get('/accounts')
        accounts = []
        for account_data in response.get('data', []):
            accounts.append(cls(**account_data))
        return accounts

    @classmethod
    def all_urls(cls, client):
        """"""
        Retrieve all account URLs for the given client.
        
        Args:
            client: The client object used to make the API request
            
        Returns:
            A list of URLs for all accounts
        """"""
        # Assuming there's an endpoint to fetch account URLs
        response = client.get('/accounts/urls')
        return response.get('urls', [])","class Account(object):
    def __init__(self, client, data=None):
        self.client = client
        self.data = data or {}
    
    @classmethod
    def all(cls, client):
        accounts = []
        urls = cls.all_urls(client)
        for url in urls:
            response = client.get(url)
            if response and 'accounts' in response:
                for account_data in response['accounts']:
                    accounts.append(cls(client, account_data))
        return accounts

    @classmethod
    def all_urls(cls, client):
        response = client.get('/accounts')
        if response and 'urls' in response:
            return response['urls']
        return []",no_docstr,0.5137614678899083,0.2803738317757009,0.17142857142857143,0.42201834862385323,0.33757100115131505,0.5892857142857143,0.3333333333333333,0.2636363636363636,0.8183980584144592,0.8281745314598083,0.823257327079773,0.8271864652633667,0.7889929357798164,0.4311377245508982,0.1818181818181818,0.12269938650306748,0.35928143712574856,0.2762732102145288,0.483695652173913,0.24043715846994534,0.1813186813186813,0.7473355531692505,0.8121953010559082,0.7784166932106018,0.8052070736885071,0.837922110091743,0.5648854961832062,0.23255813953488372,0.14173228346456693,0.4122137404580153,0.37217236148746075,0.5985915492957746,0.3546099290780142,0.24285714285714285,0.8414430618286133,0.8308185338973999,0.8360970616340637,0.8318688869476318,0.8161783088235294,0.3086013449413852,0.2053278803186559,0.2354267057960914,0.3214285714285714,0.4722222222222222,0.2727097127712302,0.0778021989008029,0.2293064934539592,0.3392857142857143,0.4444444444444444,0.2874616710520112,0.1144855730651725,0.1940912698730311,0.5357142857142857,0.3055555555555556
380334,facebook/watchman,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/facebook_watchman/build/fbcode_builder/getdeps/fetcher.py,getdeps.fetcher.download_url_to_file_with_progress.Progress,"class Progress(object):
    last_report = 0

    def write_update(self, total, amount):
        if total == -1:
            total = ""(Unknown)""

        if sys.stdout.isatty():
            sys.stdout.write(""\r downloading %s of %s "" % (amount, total))
        else:
            # When logging to CI logs, avoid spamming the logs and print
            # status every few seconds
            now = time.time()
            if now - self.last_report > 5:
                sys.stdout.write("".. %s of %s "" % (amount, total))
                self.last_report = now
        sys.stdout.flush()

    def progress_pycurl(self, total, amount, _uploadtotal, _uploadamount):
        self.write_update(total, amount)
","class Progress(object):



    def write_update(self, total, amount):
        pass


    def progress_pycurl(self, total, amount, _uploadtotal, _uploadamount):
        pass

",3,0,snippet_721,0.4444444444444444,"class Progress(object):

    def write_update(self, total, amount):
        if total <= 0:
            return
        percent = float(amount) / total * 100
        sys.stdout.write(""\rProgress: {}/{} ({:.2f}%)"".format(amount, total, percent))
        sys.stdout.flush()
        if amount >= total:
            sys.stdout.write(""\n"")
            sys.stdout.flush()

    def progress_pycurl(self, total, amount, _uploadtotal, _uploadamount):
        # Download progress
        if total and total > 0:
            self.write_update(total, amount)
        # Upload progress
        if _uploadtotal and _uploadtotal > 0:
            self.write_update(_uploadtotal, _uploadamount)
        return 0","class Progress(object):
    def write_update(self, total, amount):
        if total > 0:
            percent = (amount / total) * 100
            print(f""\rProgress: {percent:.1f}% ({amount}/{total})"", end='', flush=True)
        else:
            print(f""\rProgress: {amount} bytes"", end='', flush=True)

    def progress_pycurl(self, total, amount, _uploadtotal, _uploadamount):
        self.write_update(total, amount)","class Progress(object):
    def __init__(self):
        self.last_percent = -1

    def write_update(self, total, amount):
        if total == 0:
            return
        
        percent = int((amount * 100) / total)
        if percent != self.last_percent:
            self.last_percent = percent
            print(f""\rProgress: {percent}% ({amount}/{total})"", end="""", flush=True)
            if percent == 100:
                print()

    def progress_pycurl(self, total, amount, _uploadtotal, _uploadamount):
        self.write_update(total, amount)",no_docstr,0.5696202531645569,0.38461538461538464,0.2727272727272727,0.46835443037974683,0.5076615776003568,0.7212121212121212,0.5,0.4049079754601227,0.8674423694610596,0.80727219581604,0.8362764120101929,0.8129109740257263,0.7900283464566928,0.4848484848484849,0.3538461538461538,0.28125,0.46969696969696967,0.3199309582741689,0.7264957264957265,0.46551724137931033,0.391304347826087,0.8252125382423401,0.7462437152862549,0.7837439775466919,0.7534539103507996,0.7526906451612903,0.5416666666666667,0.33802816901408445,0.2571428571428571,0.45833333333333337,0.402424095037641,0.7142857142857143,0.48201438848920863,0.3695652173913043,0.8509626388549805,0.7793787717819214,0.813599169254303,0.7859905958175659,0.7688195161290322,0.3176950770173811,0.1635506993422521,0.1846251861228495,0.4090909090909091,0.5135135135135135,0.1990816683058448,0.1196558486816797,0.1758518237226987,0.2575757575757575,0.2432432432432432,0.320933153453258,0.1653774431753646,0.2023027545852515,0.3484848484848485,0.5675675675675675
267469,blazelibs/blazeutils,blazelibs_blazeutils/blazeutils/strings.py,blazeutils.strings.StringIndenter,"class StringIndenter(object):

    def __init__(self):
        self.output = []
        self.level = 0
        self.indent_with = '    '

    def dec(self, value, level=None):
        self.level -= 1
        return self.render(value, level=level)

    def inc(self, value, level=None):
        self.render(value, level=level)
        self.level += 1

    def __call__(self, value, level=None):
        self.render(value, level=level)

    def render(self, value, level=None):
        self.output.append('%s%s' % (self.indent(level), value))

    def indent(self, level=None):
        if level is None:
            return self.indent_with * self.level
        else:
            return self.indent_with * level

    def get(self):
        retval = '\n'.join(self.output)
        self.output = []
        return retval","class StringIndenter(object):


    def __init__(self):
        pass

    def dec(self, value, level=None):
        pass

    def inc(self, value, level=None):
        pass

    def __call__(self, value, level=None):
        pass

    def render(self, value, level=None):
        pass

    def indent(self, level=None):
        pass

    def get(self):
        pass

",8,0,snippet_190,1.0,"class StringIndenter(object):
    def __init__(self):
        self._level = 0
        self._lines = []

    def dec(self, value, level=None):
        self._level = max(self._level - 1, 0)
        return self.render(value, level)

    def inc(self, value, level=None):
        self.render(value, level)
        self._level += 1
        return self

    def __call__(self, value, level=None):
        return self.render(value, level)

    def render(self, value, level=None):
        text = str(value)
        indent_str = self.indent(level)
        for line in text.split('\n'):
            self._lines.append(f""{indent_str}{line}"")
        return self

    def indent(self, level=None):
        lvl = self._level if level is None else level
        return ' ' * (lvl * 4)

    def get(self):
        return '\n'.join(self._lines)","class StringIndenter(object):
    def __init__(self):
        self._content = []
        self._current_level = 0
        self._indent_size = 4

    def dec(self, value, level=None):
        if level is None:
            level = self._current_level - 1
        self._current_level = max(0, level)
        self._content.append(self.indent(self._current_level) + str(value))
        return self

    def inc(self, value, level=None):
        if level is None:
            level = self._current_level + 1
        self._current_level = level
        self._content.append(self.indent(self._current_level) + str(value))
        return self

    def __call__(self, value, level=None):
        return self.render(value, level)

    def render(self, value, level=None):
        if level is None:
            level = self._current_level
        self._content.append(self.indent(level) + str(value))
        return self

    def indent(self, level=None):
        if level is None:
            level = self._current_level
        return ' ' * (level * self._indent_size)

    def get(self):
        return '\n'.join(self._content)","class StringIndenter(object):

    def __init__(self):
        self._level = 0
        self._indent_string = ""    ""

    def dec(self, value, level=None):
        if level is not None:
            self._level = max(0, level)
        else:
            self._level = max(0, self._level - 1)
        return self.render(value, self._level)

    def inc(self, value, level=None):
        if level is not None:
            self._level = level
        else:
            self._level += 1
        return self.render(value, self._level)

    def __call__(self, value, level=None):
        return self.render(value, level)

    def render(self, value, level=None):
        if level is None:
            level = self._level
        return self.indent(level) + str(value)

    def indent(self, level=None):
        if level is None:
            level = self._level
        return self._indent_string * level

    def get(self):
        return self._level",no_docstr,0.8246445497630331,0.631578947368421,0.4830917874396135,0.6919431279620853,0.6672613706702506,0.8181818181818182,0.6652173913043479,0.5458515283842795,0.9066994190216064,0.9147331714630127,0.9106985926628113,0.9139233231544495,0.8417524242424242,0.7242798353909465,0.4730290456431535,0.3263598326359833,0.6337448559670782,0.5071279876592529,0.6552901023890785,0.5171232876712328,0.3848797250859107,0.8640403151512146,0.8898071050643921,0.8767344951629639,0.8871614336967468,0.8360897933884298,0.7873303167420814,0.6301369863013699,0.4700460829493088,0.6968325791855204,0.63416251883147,0.7805907172995781,0.6398305084745762,0.5106382978723404,0.8970222473144531,0.8881322145462036,0.8925551176071167,0.8890132904052734,0.8240288324873096,0.5047913199915826,0.2254703488382366,0.2630826862301342,0.5306122448979592,0.0,0.498424677139379,0.20569741659722,0.2982053735929491,0.4897959183673469,0.0,0.5013870818508768,0.2411256598847389,0.3256471573146863,0.4387755102040816,0.0
153935,Microsoft/vsts-cd-manager,Microsoft_vsts-cd-manager/aex_accounts/account.py,Microsoft_vsts-cd-manager.aex_accounts.account.Account,"class Account(object):

    def __init__(self, api_version, base_url=None, creds=None):

        self.config = AccountConfiguration(api_version, base_url)
        self._client = ServiceClient(creds, self.config)
        client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
        self._deserialize = Deserializer(client_models)
        self.api_version = api_version

    def create_account(self, collection_name, preferred_region):

        # Construct URL
        url = '/_apis/hostacquisition/collections'

        # Construct parameters
        query_parameters = {}
        query_parameters[""api-version""] = self.api_version
        query_parameters[""collectionName""] = collection_name
        query_parameters[""preferredRegion""] = preferred_region

        # Construct and send request
        request = self._client.post(url, query_parameters)
        response = self._client.send(request)

        # Handle Response
        deserialized = None
        if response.status_code not in [200]:
            print(""POST"", request.url, file=stderr)
            print(""response:"", response.status_code, file=stderr)
            print(response.text, file=stderr)
            raise HttpOperationError(self._deserialize, response)
        else:
            deserialized = self._deserialize('Collection', response)

        return deserialized

    def regions(self):

        # Construct URL
        url = '/_apis/hostacquisition/regions'

        # Construct and send request
        request = self._client.get(url)
        response = self._client.send(request)

        # Handle Response
        deserialized = None
        if response.status_code not in [200]:
            print(""GET"", request.url, file=stderr)
            print(""response:"", response.status_code, file=stderr)
            print(response.text, file=stderr)
            raise HttpOperationError(self._deserialize, response)
        else:
            deserialized = self._deserialize('Regions', response)

        return deserialized","class Account(object):


    def __init__(self, api_version, base_url=None, creds=None):
        pass

    def create_account(self, collection_name, preferred_region):
        pass

    def regions(self):
        pass

",4,0,snippet_521,0.2727272727272727,"class Account(object):
    DEFAULT_BASE_URL = ""https://api.example.com""
    SUPPORTED_REGIONS = [""us-east-1"", ""us-west-1"", ""eu-central-1"", ""ap-southeast-1""]

    def __init__(self, api_version, base_url=None, creds=None):
        self.api_version = api_version
        self.base_url = base_url or self.DEFAULT_BASE_URL
        self.creds = creds or {}
        self._accounts = {}

    def create_account(self, collection_name, preferred_region):
        if preferred_region not in self.SUPPORTED_REGIONS:
            raise ValueError(f""Region '{preferred_region}' is not supported."")
        account_id = str(uuid.uuid4())
        account = {
            ""id"": account_id,
            ""collection_name"": collection_name,
            ""preferred_region"": preferred_region,
            ""api_version"": self.api_version,
        }
        self._accounts[account_id] = account
        return account

    def regions(self):
        return list(self.SUPPORTED_REGIONS)","class Account(object):
    def __init__(self, api_version, base_url=None, creds=None):
        self.api_version = api_version
        self.base_url = base_url or ""https://api.example.com""
        self.creds = creds
        self.accounts = {}
        self.available_regions = [""us-east-1"", ""us-west-2"", ""eu-west-1"", ""ap-southeast-1""]

    def create_account(self, collection_name, preferred_region):
        if preferred_region not in self.available_regions:
            raise ValueError(f""Region {preferred_region} is not available"")
        
        account_id = f""acc_{len(self.accounts) + 1:04d}""
        account = {
            ""id"": account_id,
            ""collection_name"": collection_name,
            ""region"": preferred_region,
            ""status"": ""active""
        }
        self.accounts[account_id] = account
        return account

    def regions(self):
        return self.available_regions","class Account(object):
    def __init__(self, api_version, base_url=None, creds=None):
        self.api_version = api_version
        self.base_url = base_url or ""https://api.example.com""
        self.creds = creds or {}
        self._regions_cache = None

    def create_account(self, collection_name, preferred_region):
        account_data = {
            'collection_name': collection_name,
            'preferred_region': preferred_region,
            'api_version': self.api_version,
            'created_at': self._get_timestamp(),
            'status': 'active'
        }
        return account_data

    def regions(self):
        if self._regions_cache is None:
            self._regions_cache = [
                'us-east-1',
                'us-west-2',
                'eu-west-1',
                'ap-southeast-1',
                'ap-northeast-1'
            ]
        return self._regions_cache

    def _get_timestamp(self):
        import datetime
        return datetime.datetime.utcnow().isoformat()",no_docstr,0.3803680981595092,0.20987654320987653,0.14906832298136646,0.2576687116564417,0.1968489913802046,0.7468879668049793,0.39166666666666666,0.2803347280334728,0.7689852118492126,0.6802027821540833,0.7218744158744812,0.6881477236747742,0.7421594411764706,0.3584905660377359,0.20253164556962028,0.1464968152866242,0.27044025157232704,0.16626308787781133,0.7194570135746606,0.39545454545454545,0.2831050228310502,0.7808642983436584,0.6780518889427185,0.725835382938385,0.687098503112793,0.7549044117647065,0.3875,0.20754716981132076,0.15822784810126583,0.2875,0.16506900768881924,0.7751196172248804,0.42788461538461536,0.3333333333333333,0.774384617805481,0.6786473393440247,0.7233619689941406,0.6871424913406372,0.7578455588235302,0.1388075903592969,0.0462514391745054,0.0711218120556155,0.3233532934131736,0.1145038167938931,0.1452690153801433,0.0544535563126472,0.0881711636163002,0.2934131736526946,0.1450381679389313,0.1659265556539188,0.0490063035488272,0.0808972953067348,0.3353293413173652,0.1984732824427481
108247,CityOfZion/neo-python,CityOfZion_neo-python/neo/VM/InteropService.py,neo.VM.InteropService.CollectionMixin,"class CollectionMixin:

    def __init__(self):
        self.IsSynchronized = False
        self.SyncRoot = None

    @property
    def Count(self):
        return 0

    def Contains(self, item):
        pass

    def Clear(self):
        pass

    def CopyTo(self, array, index):
        pass","class CollectionMixin:


    def __init__(self):
        pass

    @property
    def Count(self):
        pass

    def Contains(self, item):
        pass

    def Clear(self):
        pass

    def CopyTo(self, array, index):
        pass

",7,0,snippet_404,0.8571428571428571,"class CollectionMixin:

    def __init__(self):
        self._items = []

    @property
    def Count(self):
        return len(self._items)

    def Contains(self, item):
        return item in self._items

    def Clear(self):
        self._items.clear()

    def CopyTo(self, array, index):
        count = len(self._items)
        if index < 0 or index + count > len(array):
            raise IndexError(""Index out of range"")
        for i, item in enumerate(self._items):
            array[index + i] = item","class CollectionMixin:
    def __init__(self):
        pass

    @property
    def Count(self):
        raise NotImplementedError(""Count property must be implemented by subclass"")

    def Contains(self, item):
        raise NotImplementedError(""Contains method must be implemented by subclass"")

    def Clear(self):
        raise NotImplementedError(""Clear method must be implemented by subclass"")

    def CopyTo(self, array, index):
        raise NotImplementedError(""CopyTo method must be implemented by subclass"")","class CollectionMixin:
    def __init__(self):
        self._items = []

    @property
    def Count(self):
        return len(self._items)

    def Contains(self, item):
        return item in self._items

    def Clear(self):
        self._items.clear()

    def CopyTo(self, array, index):
        for i, item in enumerate(self._items):
            array[index + i] = item",no_docstr,0.5208333333333334,0.3829787234042553,0.2826086956521739,0.4791666666666667,0.3534347787470098,0.4153846153846154,0.3488372093023256,0.3046875,0.7960262298583984,0.8567981123924255,0.8252949118614197,0.850306510925293,0.7708356249999999,0.4888888888888889,0.38636363636363635,0.25581395348837205,0.46666666666666673,0.4265519738236586,0.47474747474747475,0.42857142857142855,0.38144329896907214,0.7559964656829834,0.8743728995323181,0.8108872175216675,0.8608927130699158,0.7843158823529411,0.6153846153846153,0.4736842105263158,0.3513513513513514,0.5897435897435898,0.4719856621274656,0.5463917525773195,0.46875,0.4105263157894737,0.8630082011222839,0.8634498119354248,0.8632289171218872,0.8634056448936462,0.8107014814814815,0.3365158600847232,0.1605265406802473,0.3188702329919788,0.2666666666666666,0.6,0.311300773781502,0.1449380658113947,0.2669316959812801,0.4333333333333333,0.4,0.331275518556457,0.241239091868632,0.3171963156905292,0.2666666666666666,0.5
528838,karimbahgat/PyCRS,karimbahgat_PyCRS/pycrs/elements/parameters.py,pycrs.elements.parameters.SemiMinorRadius,"class SemiMinorRadius:
    proj4 = ""+b""
    def __init__(self, value):
        self.value = value

    def to_proj4(self):
        return ""%s=%s"" % (self.proj4, self.value)

    def to_esri_wkt(self):
        return str(self.value)

    def to_ogc_wkt(self):
        return str(self.value)","class SemiMinorRadius:


    def __init__(self, value):
        pass

    def to_proj4(self):
        pass

    def to_esri_wkt(self):
        pass

    def to_ogc_wkt(self):
        pass

",5,0,snippet_317,1.0,"class SemiMinorRadius:
    def __init__(self, value):
        try:
            self.value = float(value)
        except (TypeError, ValueError):
            raise ValueError(f""Invalid numeric value for semiminor radius: {value}"")

    def to_proj4(self):
        # PROJ.4 parameter for semiminor axis is ""+b=""
        return f""+b={self.value}""

    def to_esri_wkt(self):
        # ESRI WKT uses PARAMETER[""Semi_Minor_Axis"", <value>]
        return f'PARAMETER[""Semi_Minor_Axis"",{self.value}]'

    def to_ogc_wkt(self):
        # OGC WKT uses lowercase parameter name ""semi_minor""
        return f'PARAMETER[""semi_minor"",{self.value}]'","class SemiMinorRadius:
    def __init__(self, value):
        self.value = value

    def to_proj4(self):
        return f""+b={self.value}""

    def to_esri_wkt(self):
        return f'SEMI_MINOR_RADIUS[{self.value}]'

    def to_ogc_wkt(self):
        return f'SEMI_MINOR_RADIUS[{self.value}]'","class SemiMinorRadius:
    def __init__(self, value):
        self.value = float(value)

    def to_proj4(self):
        return f""+b={self.value}""

    def to_esri_wkt(self):
        return f""PARAMETER[\""Semi_Minor\"",{self.value}]""

    def to_ogc_wkt(self):
        return f""PARAMETER[\""semi_minor\"",{self.value}]""",no_docstr,0.532258064516129,0.3606557377049181,0.24999999999999994,0.5161290322580645,0.33676190278143137,0.4583333333333333,0.32934131736526945,0.25301204819277107,0.7415274381637573,0.8946089744567871,0.8109068274497986,0.876514196395874,0.7991987951807229,0.8048780487804876,0.675,0.5641025641025641,0.7804878048780488,0.6423267849093256,0.7415730337078652,0.6477272727272727,0.5517241379310345,0.8716906309127808,0.9299404621124268,0.8998738527297974,0.9237675070762634,0.8615398461538462,0.7951807228915662,0.6419753086419754,0.5063291139240507,0.7710843373493975,0.5583674701517527,0.6826923076923077,0.5533980582524272,0.46078431372549017,0.8707991242408752,0.9242839217185974,0.8967447876930237,0.9186416864395142,0.8308474626865671,0.1591488221038459,0.0353855502278725,0.0809089863078118,0.2571428571428571,0.2631578947368421,0.3509848544802416,0.4193068024252118,0.4553093072250779,0.3714285714285714,0.1578947368421052,0.2594783911145864,0.2719624081789895,0.2982819833470254,0.2571428571428571,0.2105263157894736
204658,TrafficSenseMSD/SumoTools,TrafficSenseMSD_SumoTools/traci/_trafficlight.py,traci._trafficlight.Phase,"class Phase:

    def __init__(self, duration, duration1, duration2, phaseDef):
        self._duration = duration
        self._duration1 = duration1 # minimum duration (only for actuated tls)
        self._duration2 = duration2 # maximum duration (only for actuated tls)
        self._phaseDef = phaseDef

    def __repr__(self):
        return (""Phase:\nduration: %s\nminDuration: %s\nmaxDuration: %s\nphaseDef: %s\n"" %
                (self._duration, self._duration1, self._duration2, self._phaseDef))","class Phase:


    def __init__(self, duration, duration1, duration2, phaseDef):
        pass

    def __repr__(self):
        pass

",3,0,snippet_102,1.0,"class Phase:
    def __init__(self, duration, duration1, duration2, phaseDef):
        if not isinstance(duration, (int, float)):
            raise TypeError(""duration must be a number"")
        if not isinstance(duration1, (int, float)):
            raise TypeError(""duration1 must be a number"")
        if not isinstance(duration2, (int, float)):
            raise TypeError(""duration2 must be a number"")
        if duration1 + duration2 != duration:
            raise ValueError(""duration1 + duration2 must equal duration"")
        self.duration = duration
        self.duration1 = duration1
        self.duration2 = duration2
        self.phaseDef = phaseDef

    def __repr__(self):
        return (f""Phase(duration={self.duration}, ""
                f""duration1={self.duration1}, ""
                f""duration2={self.duration2}, ""
                f""phaseDef={self.phaseDef!r})"")","class Phase:
    def __init__(self, duration, duration1, duration2, phaseDef):
        self.duration = duration
        self.duration1 = duration1
        self.duration2 = duration2
        self.phaseDef = phaseDef

    def __repr__(self):
        return f""Phase(duration={self.duration}, duration1={self.duration1}, duration2={self.duration2}, phaseDef={self.phaseDef})""","class Phase:
    def __init__(self, duration, duration1, duration2, phaseDef):
        self.duration = duration
        self.duration1 = duration1
        self.duration2 = duration2
        self.phaseDef = phaseDef

    def __repr__(self):
        return f""Phase(duration={self.duration}, duration1={self.duration1}, duration2={self.duration2}, phaseDef={self.phaseDef})""",no_docstr,0.4864864864864865,0.39726027397260283,0.2638888888888889,0.4594594594594595,0.2957932410510534,0.4358974358974359,0.29381443298969073,0.20207253886010362,0.7997039556503296,0.8255693912506104,0.8124308586120605,0.8229078054428101,0.7770441721854303,0.7446808510638298,0.6304347826086957,0.4666666666666667,0.723404255319149,0.4003690277543786,0.8222222222222222,0.5730337078651685,0.4431818181818182,0.9512604475021362,0.851051926612854,0.8983703851699829,0.8601125478744507,0.8985517391304348,0.7446808510638298,0.6304347826086957,0.4666666666666667,0.723404255319149,0.4003690277543786,0.8222222222222222,0.5730337078651685,0.4431818181818182,0.9512604475021362,0.851051926612854,0.8983703851699829,0.8601125478744507,0.8985517391304348,0.3990592686362841,0.1527383826861572,0.2628535305686567,0.5806451612903226,0.6,0.4102358357386882,0.2129285220635156,0.2628535305686567,0.6451612903225806,0.52,0.4102358357386882,0.2129285220635156,0.2628535305686567,0.6451612903225806,0.52
691284,rande/python-simple-ioc,rande_python-simple-ioc/ioc/extra/tornado/__init__.py,ioc.extra.tornado.TornadoManager,"class TornadoManager(object):
    STOPPED = 0
    STARTED = 1

    def __init__(self):
        self.ioloops = {}
        self.status = {}

    def add_ioloop(self, name, ioloop):
        self.ioloops[name] = ioloop
        self.status[name] = TornadoManager.STOPPED

    def stop(self, name):
        if self.status[name] == TornadoManager.STARTED:
            self.ioloops[name].stop()

    def start(self, name):
        if self.status[name] == TornadoManager.STOPPED:
            self.ioloops[name].start()

    def start_all(self):
        for name, loop in self.ioloops.iteritems():
            self.start(name)

    def stop_all(self):
        for name, loop in self.ioloops.iteritems():
            self.stop(name)","class TornadoManager(object):


    def __init__(self):
        pass

    def add_ioloop(self, name, ioloop):
        pass

    def stop(self, name):
        pass

    def start(self, name):
        pass

    def start_all(self):
        pass

    def stop_all(self):
        pass

",7,0,snippet_196,0.5,"class TornadoManager(object):
    def __init__(self):
        self._loops = {}

    def add_ioloop(self, name, ioloop):
        if name in self._loops:
            raise ValueError(""IOLoop with name '{}' already exists"".format(name))
        self._loops[name] = {'loop': ioloop, 'thread': None}

    def start(self, name):
        if name not in self._loops:
            raise KeyError(""No IOLoop named '{}'"".format(name))
        info = self._loops[name]
        thread = info['thread']
        if thread and thread.is_alive():
            return
        t = threading.Thread(target=info['loop'].start, name='IOLoop-{}'.format(name))
        t.daemon = True
        info['thread'] = t
        t.start()

    def stop(self, name):
        if name not in self._loops:
            raise KeyError(""No IOLoop named '{}'"".format(name))
        info = self._loops[name]
        info['loop'].stop()
        t = info['thread']
        if t:
            t.join()
            info['thread'] = None

    def start_all(self):
        for name in self._loops:
            self.start(name)

    def stop_all(self):
        for name in self._loops:
            self.stop(name)","class TornadoManager(object):
    def __init__(self):
        self.ioloops = {}

    def add_ioloop(self, name, ioloop):
        self.ioloops[name] = ioloop

    def stop(self, name):
        if name in self.ioloops:
            self.ioloops[name].stop()

    def start(self, name):
        if name in self.ioloops:
            self.ioloops[name].start()

    def start_all(self):
        for ioloop in self.ioloops.values():
            ioloop.start()

    def stop_all(self):
        for ioloop in self.ioloops.values():
            ioloop.stop()","class TornadoManager(object):

    def __init__(self):
        self.ioloops = {}
        self.threads = {}

    def add_ioloop(self, name, ioloop):
        self.ioloops[name] = ioloop

    def stop(self, name):
        if name in self.ioloops:
            ioloop = self.ioloops[name]
            ioloop.add_callback(ioloop.stop)
            if name in self.threads:
                self.threads[name].join()
                del self.threads[name]

    def start(self, name):
        if name in self.ioloops:
            ioloop = self.ioloops[name]
            thread = threading.Thread(target=ioloop.start)
            thread.daemon = True
            self.threads[name] = thread
            thread.start()

    def start_all(self):
        for name in self.ioloops:
            if name not in self.threads or not self.threads[name].is_alive():
                self.start(name)

    def stop_all(self):
        for name in list(self.ioloops.keys()):
            self.stop(name)",no_docstr,0.543859649122807,0.33628318584070793,0.22321428571428575,0.4824561403508772,0.3764240733612802,0.5165562913907285,0.3687707641196013,0.28,0.7827895879745483,0.8307819962501526,0.8060720562934875,0.8257195949554443,0.7624266181818188,0.758169934640523,0.5827814569536424,0.4697986577181208,0.7320261437908496,0.6135556058277407,0.9290780141843972,0.8142857142857143,0.7194244604316546,0.9327542781829834,0.87481689453125,0.9028570652008057,0.8802847266197205,0.9198320253164557,0.6600985221674877,0.48756218905472637,0.36180904522613067,0.6206896551724139,0.5801045107264403,0.6956521739130435,0.5764192139737991,0.4868421052631579,0.8462303280830383,0.8597489595413208,0.8529360294342041,0.8583776354789734,0.8446617475728154,0.3144342497227697,0.1386413895729799,0.2689083434004958,0.5168539325842697,0.3333333333333333,0.3831996053166246,0.3455656492153455,0.3875087428770942,0.6067415730337079,0.1929824561403508,0.3872155744636323,0.2674017948097603,0.3792330242353859,0.6741573033707865,0.2280701754385964
188967,SpockBotMC/SpockBot,SpockBotMC_SpockBot/spockbot/mcp/extensions.py,spockbot.mcp.extensions.ExtensionPCTS14,"class ExtensionPCTS14:
    @staticmethod
    def decode_extra(packet, bbuff):
        if packet.data['has_position']:
            packet.data['block_loc'] = datautils.unpack(MC_POSITION, bbuff)
        return packet

    @staticmethod
    def encode_extra(packet):
        o = b''
        if packet.data['has_position']:
            datautils.pack(MC_POSITION, packet.data['block_loc'])
        return o","class ExtensionPCTS14:


    @staticmethod
    def decode_extra(packet, bbuff):
        pass

    @staticmethod
    def encode_extra(packet):
        pass

",5,0,snippet_685,0.3333333333333333,"class ExtensionPCTS14:
    @staticmethod
    def decode_extra(packet, bbuff):
        # read all remaining bytes as the extensions payload
        packet.extra = bbuff.read()

    @staticmethod
    def encode_extra(packet):
        # return the stored payload (or empty if none)
        return getattr(packet, 'extra', b'')","class ExtensionPCTS14:
    @staticmethod
    def decode_extra(packet, bbuff):
        # Extract the extra data length from the packet
        extra_len = packet.get('extra_len', 0)
        
        # If there's no extra data, return early
        if extra_len == 0:
            return
        
        # Read the extra data from the byte buffer
        extra_data = bbuff.read(extra_len)
        
        # Store the extra data in the packet
        packet['extra_data'] = extra_data

    @staticmethod
    def encode_extra(packet):
        # Get the extra data from the packet
        extra_data = packet.get('extra_data', b'')
        
        # Set the extra data length in the packet
        packet['extra_len'] = len(extra_data)
        
        # Return the extra data to be written to the byte buffer
        return extra_data","class ExtensionPCTS14:

    @staticmethod
    def decode_extra(packet, bbuff):
        if len(bbuff) < 4:
            return False
        
        packet.picture_id = int.from_bytes(bbuff[:2], byteorder='big')
        packet.temporal_layer_zero_index = int.from_bytes(bbuff[2:4], byteorder='big')
        
        return True

    @staticmethod
    def encode_extra(packet):
        if not hasattr(packet, 'picture_id') or not hasattr(packet, 'temporal_layer_zero_index'):
            return b''
        
        extra_data = packet.picture_id.to_bytes(2, byteorder='big')
        extra_data += packet.temporal_layer_zero_index.to_bytes(2, byteorder='big')
        
        return extra_data",no_docstr,0.47058823529411764,0.26506024096385544,0.22222222222222227,0.39999999999999997,0.30801506284306174,0.65625,0.4126984126984127,0.3548387096774194,0.8221879005432129,0.8000220060348511,0.8109535574913025,0.8021847009658813,0.8152628915662651,0.3612903225806452,0.1437908496732026,0.11920529801324505,0.2967741935483871,0.20164188625890903,0.37349397590361444,0.16363636363636364,0.13414634146341464,0.7511081099510193,0.8201353549957275,0.7841054797172546,0.8126668930053711,0.7836901063829786,0.4122137404580153,0.18604651162790697,0.15748031496062992,0.366412213740458,0.22523251431194874,0.4049079754601227,0.19753086419753085,0.14285714285714285,0.7418111562728882,0.8227378129959106,0.7801815271377563,0.8138591647148132,0.802471111111111,0.2636701059853846,0.1871358656921329,0.2687073489470798,0.3488372093023256,0.25,0.3502377165399849,0.0666681999705813,0.2722671623133895,0.3953488372093023,0.6666666666666666,0.3690467144346586,0.1712022897168731,0.3263023974791258,0.3953488372093023,0.5833333333333334
291746,chuck1/codemach,chuck1_codemach/test/wrapper_class.py,wrapper_class.Wrapper,"class Wrapper:
    def __init__(self, *args):
        print(""Wrapper __init__"", args)

    def __call__(self, *args):
        print(""Wrapper __call__"", args)","class Wrapper:


    def __init__(self, *args):
        pass

    def __call__(self, *args):
        pass

",3,0,snippet_563,1.0,"class Wrapper:
    def __init__(self, *funcs):
        self.funcs = funcs

    def __call__(self, *args):
        return [f(*args) for f in self.funcs]","class Wrapper:
    def __init__(self, *args):
        self.args = args

    def __call__(self, *args):
        return self.args + args","class Wrapper:
    def __init__(self, *args):
        if len(args) == 1 and callable(args[0]):
            self.func = args[0]
            self.args = ()
            self.kwargs = {}
        else:
            self.func = None
            self.args = args
            self.kwargs = {}

    def __call__(self, *args, **kwargs):
        if self.func is None:
            # Being used as a decorator with arguments
            if len(args) == 1 and callable(args[0]) and not kwargs:
                self.func = args[0]
                return self
            else:
                # Store additional arguments
                self.args = self.args + args
                self.kwargs.update(kwargs)
                return self
        else:
            # Execute the wrapped function
            return self.func(*(self.args + args), **{**self.kwargs, **kwargs})",no_docstr,0.5128205128205129,0.37837837837837834,0.2857142857142857,0.5128205128205129,0.5007951105770914,0.6530612244897959,0.5833333333333334,0.5106382978723404,0.8442087769508362,0.8986183404922485,0.8705642223358154,0.8928638100624084,0.8240758333333333,0.6857142857142857,0.5454545454545455,0.45161290322580644,0.6857142857142857,0.490829364212876,0.7804878048780488,0.7,0.6666666666666666,0.9196563959121704,0.9087802767753601,0.9141860008239746,0.9098562598228455,0.8611125,0.21428571428571427,0.14545454545454545,0.11111111111111109,0.21428571428571427,0.15612961009321877,0.1958762886597938,0.15544041450777202,0.125,0.6102078557014465,0.7978660464286804,0.6915320754051208,0.7740612030029297,0.7148875471698112,0.3625741382014186,0.207061938283276,0.2827082987329249,0.2105263157894736,0.75,0.3556404270506298,0.3290385879986622,0.3829968044143835,0.2105263157894736,0.5,0.3355797482583459,0.0455939569204009,0.3361987203235091,0.2105263157894736,0.75
164724,PSPC-SPAC-buyandsell/didauth,PSPC-SPAC-buyandsell_didauth/didauth/base.py,didauth.base.VerifierBase,"class VerifierBase:
    def __init__(self, _key_type, _pubkey=None):
        self._pubkey = None

    @property
    def public_key(self) -> bytes:
        pass

    def _verify(self, _message: bytes, _signature: bytes) -> bool:
        raise SystemError('Not implemented')

    def verify(self, message, signature, signature_format=None) -> bool:
        if signature_format:
            signature = decode_string(signature, signature_format)
        return self._verify(message, signature)","class VerifierBase:


    def __init__(self, _key_type, _pubkey=None):
        pass

    @property
    def public_key(self) -> bytes:
        pass

    def _verify(self, _message: bytes, _signature: bytes) -> bool:
        pass

    def verify(self, message, signature, signature_format=None) -> bool:
        pass

",6,0,snippet_337,0.8571428571428571,"class VerifierBase:

    def __init__(self, _key_type, _pubkey=None):
        self._key_type = _key_type
        if _pubkey is not None and not isinstance(_pubkey, (bytes, bytearray)):
            raise TypeError(""public key must be bytes"")
        self._pubkey = _pubkey

    @property
    def public_key(self) -> bytes:
        if self._pubkey is None:
            raise ValueError(""no public key set"")
        return bytes(self._pubkey)

    def _verify(self, _message: bytes, _signature: bytes) -> bool:
        raise NotImplementedError(""subclasses must implement _verify"")

    def verify(self, message, signature, signature_format=None) -> bool:
        if isinstance(message, str):
            message = message.encode('utf-8')
        if isinstance(signature, str):
            fmt = (signature_format or '').lower()
            if fmt in ('hex',):
                signature = bytes.fromhex(signature)
            elif fmt in ('base64', 'b64'):
                signature = base64.b64decode(signature)
            else:
                signature = signature.encode('utf-8')
        return self._verify(message, signature)","class VerifierBase:
    def __init__(self, _key_type, _pubkey=None):
        self._key_type = _key_type
        self._pubkey = _pubkey

    @property
    def public_key(self) -> bytes:
        return self._pubkey

    def _verify(self, _message: bytes, _signature: bytes) -> bool:
        # This is a base implementation that should be overridden by subclasses
        raise NotImplementedError(""_verify method must be implemented by subclass"")

    def verify(self, message, signature, signature_format=None) -> bool:
        # Convert message to bytes if it isn't already
        if not isinstance(message, bytes):
            message = str(message).encode('utf-8')
        
        # Convert signature to bytes if it isn't already
        if not isinstance(signature, bytes):
            signature = bytes(signature)
            
        return self._verify(message, signature)","class VerifierBase:
    def __init__(self, _key_type, _pubkey=None):
        self._key_type = _key_type
        self._pubkey = _pubkey

    @property
    def public_key(self) -> bytes:
        return self._pubkey

    def _verify(self, _message: bytes, _signature: bytes) -> bool:
        raise NotImplementedError(""Subclasses must implement _verify method"")

    def verify(self, message, signature, signature_format=None) -> bool:
        if isinstance(message, str):
            message = message.encode('utf-8')
        if isinstance(signature, str):
            signature = signature.encode('utf-8')
        return self._verify(message, signature)",no_docstr,0.5363128491620113,0.4293785310734463,0.3428571428571428,0.5251396648044693,0.3876044109862662,0.43253968253968256,0.38247011952191234,0.352,0.7732950448989868,0.9004626870155334,0.8320478796958923,0.885894238948822,0.7906997674418604,0.5911949685534591,0.4331210191082802,0.36129032258064514,0.5786163522012578,0.5039174259175228,0.5691489361702128,0.4919786096256685,0.45698924731182794,0.8156352043151855,0.9227341413497925,0.8658855557441711,0.9107750058174133,0.88347,0.6929133858267718,0.592,0.4878048780487805,0.6929133858267718,0.6273072908619907,0.6928104575163399,0.618421052631579,0.5761589403973509,0.8783376216888428,0.9351632595062256,0.9058601260185242,0.9291519522666931,0.88889,0.5311789687615971,0.2449298413764512,0.5994830033669071,0.6136363636363636,0.6666666666666666,0.5012353976712913,0.2535176272902994,0.5451950071659099,0.6136363636363636,0.5925925925925926,0.5607178854266407,0.4478498392153019,0.5887927462623047,0.6136363636363636,0.5925925925925926
665601,pydata/xarray,pydata_xarray/asv_bench/benchmarks/merge.py,benchmarks.merge.DatasetAddVariable,"class DatasetAddVariable:
    param_names = [""existing_elements""]
    params = [[0, 10, 100, 1000]]

    def setup(self, existing_elements):
        self.datasets = {}
        # Dictionary insertion is fast(er) than xarray.Dataset insertion
        d = {}
        for i in range(existing_elements):
            d[f""var{i}""] = i
        self.dataset = xr.merge([d])

        d = {f""set_2_{i}"": i for i in range(existing_elements)}
        self.dataset2 = xr.merge([d])

    def time_variable_insertion(self, existing_elements):
        dataset = self.dataset
        dataset[""new_var""] = 0

    def time_merge_two_datasets(self, existing_elements):
        xr.merge([self.dataset, self.dataset2])","class DatasetAddVariable:


    def setup(self, existing_elements):
        pass

    def time_variable_insertion(self, existing_elements):
        pass

    def time_merge_two_datasets(self, existing_elements):
        pass

",4,0,snippet_372,0.75,"class DatasetAddVariable:

    def setup(self, existing_elements):
        self.size = existing_elements
        data = np.arange(self.size)
        self.ds = xr.Dataset({f'var{i}': ('x', data) for i in range(self.size)})

    def time_variable_insertion(self, existing_elements):
        data = np.arange(self.size)
        ds = self.ds.copy()
        for i in range(existing_elements):
            ds[f'new_var_{i}'] = ('x', data)

    def time_merge_two_datasets(self, existing_elements):
        data = np.arange(existing_elements)
        ds2 = xr.Dataset({f'other{i}': ('x', data) for i in range(existing_elements)})
        self.ds.merge(ds2)","class DatasetAddVariable:

    def setup(self, existing_elements):
        # Create initial dataset with existing elements
        self.df1 = pd.DataFrame({
            'id': range(existing_elements),
            'value1': np.random.randn(existing_elements),
            'category': np.random.choice(['A', 'B', 'C'], existing_elements)
        })
        
        # Create second dataset for merging
        self.df2 = pd.DataFrame({
            'id': range(existing_elements),
            'value2': np.random.randn(existing_elements),
            'group': np.random.choice(['X', 'Y', 'Z'], existing_elements)
        })
        
        # Create a copy for insertion test
        self.df_copy = self.df1.copy()

    def time_variable_insertion(self, existing_elements):
        # Add a new column/variable to the dataset
        self.df_copy['new_variable'] = np.random.randn(existing_elements)

    def time_merge_two_datasets(self, existing_elements):
        # Merge two datasets on the 'id' column
        merged_df = pd.merge(self.df1, self.df2, on='id', how='inner')
        return merged_df","class DatasetAddVariable:
    def setup(self, existing_elements):
        self.ds = xr.Dataset()
        for i in range(existing_elements):
            self.ds[f'var_{i}'] = xr.DataArray(
                np.random.randn(100, 50),
                dims=['x', 'y'],
                coords={'x': np.arange(100), 'y': np.arange(50)}
            )
        
        self.new_var = xr.DataArray(
            np.random.randn(100, 50),
            dims=['x', 'y'],
            coords={'x': np.arange(100), 'y': np.arange(50)}
        )
        
        self.ds2 = xr.Dataset({
            'new_var': self.new_var
        })

    def time_variable_insertion(self, existing_elements):
        self.ds['new_variable'] = self.new_var

    def time_merge_two_datasets(self, existing_elements):
        xr.merge([self.ds, self.ds2])",no_docstr,0.6222222222222222,0.38202247191011235,0.28409090909090906,0.4444444444444444,0.4577423258759516,0.6810810810810811,0.45108695652173914,0.3442622950819672,0.8753349781036377,0.8756184577941895,0.8754767179489136,0.8755900263786316,0.7329219254658391,0.41818181818181815,0.23853211009174313,0.15740740740740744,0.3454545454545454,0.2964000952224513,0.48,0.26907630522088355,0.20161290322580644,0.7657692432403564,0.795701801776886,0.7804486751556396,0.7926036715507507,0.7372768472906415,0.4867724867724868,0.34224598930481287,0.2702702702702703,0.4656084656084656,0.3985531532224758,0.5844748858447488,0.3853211009174312,0.28110599078341014,0.8315483331680298,0.8581427931785583,0.8446363210678101,0.8554070591926575,0.7678298507462692,0.1871183943800309,0.1067890840873762,0.1172651962320328,0.3287671232876712,0.1956521739130435,0.2055014280014336,0.0301425970899198,0.0452877724500614,0.2465753424657534,0.5,0.2140217745166939,0.0904383846170545,0.0994783739619307,0.3835616438356164,0.2826086956521739
795584,tilezen/tilequeue,tilezen_tilequeue/tilequeue/query/postgres.py,tilequeue.query.postgres.TemplateQueryGenerator,"class TemplateQueryGenerator(object):

    def __init__(self, template_finder):
        self.template_finder = template_finder

    def __call__(self, source, bounds, zoom):
        template = self.template_finder(source)

        # TODO bounds padding
        padded_bounds = dict(
            polygon=bounds,
            line=bounds,
            point=bounds,
        )

        query = template.render(bounds=padded_bounds, zoom=zoom)
        return query","class TemplateQueryGenerator(object):


    def __init__(self, template_finder):
        pass

    def __call__(self, source, bounds, zoom):
        pass

",3,0,snippet_512,1.0,"class TemplateQueryGenerator(object):
    def __init__(self, template_finder):
        self.template_finder = template_finder

    def __call__(self, source, bounds, zoom):
        minx, miny, maxx, maxy = bounds
        template = self.template_finder(source, zoom)
        return template.format(
            source=source,
            minx=minx,
            miny=miny,
            maxx=maxx,
            maxy=maxy,
            zoom=zoom
        )","class TemplateQueryGenerator(object):

    def __init__(self, template_finder):
        self.template_finder = template_finder

    def __call__(self, source, bounds, zoom):
        template = self.template_finder(source, bounds, zoom)
        if template is None:
            return None
        return template.query(bounds, zoom)","class TemplateQueryGenerator(object):

    def __init__(self, template_finder):
        self.template_finder = template_finder

    def __call__(self, source, bounds, zoom):
        template = self.template_finder(source, bounds, zoom)
        if template is None:
            return None
        
        # Extract bounds coordinates
        minx, miny, maxx, maxy = bounds
        
        # Create substitution dictionary
        substitutions = {
            'minx': minx,
            'miny': miny,
            'maxx': maxx,
            'maxy': maxy,
            'zoom': zoom,
            'source': source
        }
        
        # Perform template substitution
        try:
            query = template.format(**substitutions)
            return query
        except (KeyError, ValueError):
            return template",no_docstr,0.6373626373626373,0.5393258426966293,0.45977011494252873,0.5934065934065934,0.6540023611315013,0.78125,0.631578947368421,0.5851063829787234,0.8386521339416504,0.8497893810272217,0.8441839814186096,0.8486623764038086,0.8725502941176471,0.746987951807229,0.5925925925925926,0.5569620253164557,0.674698795180723,0.611636489376579,0.9078947368421053,0.8,0.7297297297297297,0.9270799160003662,0.8676165342330933,0.8963630795478821,0.8732174038887024,0.8656729850746269,0.5641025641025642,0.4695652173913043,0.3893805309734513,0.547008547008547,0.4775921156700388,0.5652173913043478,0.45985401459854014,0.41911764705882354,0.7675143480300903,0.851097583770752,0.8071478605270386,0.8419288396835327,0.8160937931034482,0.4648124651545748,0.4082657763109114,0.4304213137446175,0.4848484848484848,0.5357142857142857,0.4505992143514624,0.4297453425935445,0.4678896100504003,0.3333333333333333,0.5714285714285714,0.425651113314289,0.2268154478837698,0.5050097845941655,0.3636363636363636,0.6071428571428571
289153,childsish/sofia,childsish_sofia/sofia/execution_engines/buffer.py,sofia.execution_engines.buffer.Buffer,"class Buffer(object):
    def __init__(self, keys, n=None):
        self.keys = keys
        self.n = n
        self.items = [[] for key in keys]

    def __contains__(self, item):
        return item in self.keys

    def is_readable(self):
        return all(len(input) > 0 for input in self.items)

    def is_writable(self, key):
        if key not in self.keys:
            raise ValueError('Key mismatched. Please check that all attributes match.')
        return len(self.items[self.keys.index(key)]) < self.n

    def read(self):
        return self.items

    def write(self, key, values):
        for i, k in enumerate(self.keys):
            if key == k:
                self.items[i].extend(values)","class Buffer(object):


    def __init__(self, keys, n=None):
        pass

    def __contains__(self, item):
        pass

    def is_readable(self):
        pass

    def is_writable(self, key):
        pass

    def read(self):
        pass

    def write(self, key, values):
        pass

",7,0,snippet_491,1.0,"class Buffer(object):

    def __init__(self, keys, n=None):
        self._keys = set(keys)
        self._n = n
        self._buffer = deque()

    def __contains__(self, item):
        return item in self._keys

    def is_readable(self):
        return bool(self._buffer)

    def is_writable(self, key):
        if key not in self._keys:
            return False
        if self._n is None:
            return True
        return len(self._buffer) < self._n

    def read(self):
        if not self.is_readable():
            raise BufferError(""Buffer is empty"")
        return self._buffer.popleft()

    def write(self, key, values):
        if key not in self._keys:
            raise KeyError(f""Invalid key: {key}"")
        if not self.is_writable(key):
            raise BufferError(""Buffer is full"")
        self._buffer.append((key, values))","class Buffer(object):
    def __init__(self, keys, n=None):
        self.keys = keys
        self.n = n
        self.data = {key: [] for key in keys}
        self.read_positions = {key: 0 for key in keys}
    
    def __contains__(self, item):
        return item in self.keys
    
    def is_readable(self):
        for key in self.keys:
            if len(self.data[key]) > self.read_positions[key]:
                return True
        return False
    
    def is_writable(self, key):
        if key not in self.keys:
            return False
        if self.n is None:
            return True
        return len(self.data[key]) < self.n
    
    def read(self):
        result = {}
        for key in self.keys:
            if len(self.data[key]) > self.read_positions[key]:
                result[key] = self.data[key][self.read_positions[key]]
                self.read_positions[key] += 1
            else:
                result[key] = None
        return result
    
    def write(self, key, values):
        if key not in self.keys:
            return False
        if self.n is not None and len(self.data[key]) + len(values) > self.n:
            return False
        self.data[key].extend(values)
        return True","class Buffer(object):
    def __init__(self, keys, n=None):
        self.keys = keys
        self.n = n if n is not None else 1000
        self.data = {key: [] for key in keys}
        self.min_length = 0
    
    def __contains__(self, item):
        return item in self.keys
    
    def is_readable(self):
        return self.min_length > 0
    
    def is_writable(self, key):
        if key not in self.keys:
            return False
        return len(self.data[key]) < self.n
    
    def read(self):
        if not self.is_readable():
            return None
        result = {}
        for key in self.keys:
            result[key] = self.data[key].pop(0)
        self._update_min_length()
        return result
    
    def write(self, key, values):
        if key not in self.keys:
            return False
        if not isinstance(values, list):
            values = [values]
        for value in values:
            if len(self.data[key]) < self.n:
                self.data[key].append(value)
            else:
                return False
        self._update_min_length()
        return True
    
    def _update_min_length(self):
        self.min_length = min(len(self.data[key]) for key in self.keys)",no_docstr,0.6478873239436621,0.49289099526066354,0.3923444976076555,0.6009389671361502,0.5070180164693203,0.6473214285714286,0.5022421524663677,0.4009009009009009,0.8723064064979553,0.8684476613998413,0.8703727126121521,0.8688320517539978,0.8202265168539326,0.5886792452830188,0.44866920152091255,0.36015325670498083,0.5283018867924528,0.43701242108768246,0.5346534653465347,0.4271523178807947,0.3654485049833887,0.8338745832443237,0.870658278465271,0.851869523525238,0.8668345212936401,0.8029120238095239,0.5833333333333334,0.44274809160305345,0.3461538461538461,0.5151515151515151,0.43778600505257614,0.543046357615894,0.42524916943521596,0.36333333333333334,0.840022087097168,0.8791981339454651,0.859163761138916,0.8751168847084045,0.8013625306122449,0.3628654508510869,0.2599804111735252,0.2914813922308222,0.5,0.4,0.5089005446082949,0.2742349121345901,0.4675756920192102,0.4756097560975609,0.8181818181818182,0.4727185105978619,0.2864603514996433,0.4802451764793879,0.4878048780487805,0.6363636363636364
282103,candango/firenado,candango_firenado/examples/chatdemo/__init__.py,chatdemo.MessageBuffer,"class MessageBuffer(object):

    def __init__(self):
        self.waiters = set()
        self.cache = []
        self.cache_size = 200

    def wait_for_messages(self, cursor=None):
        # Construct a Future to return to our caller.  This allows
        # wait_for_messages to be yielded from a coroutine even though
        # it is not a coroutine itself.  We will set the result of the
        # Future when results are available.
        result_future = Future()
        if cursor:
            new_count = 0
            for msg in reversed(self.cache):
                if msg['id'] == cursor:
                    break
                new_count += 1
            if new_count:
                result_future.set_result(self.cache[-new_count:])
                return result_future
        self.waiters.add(result_future)
        return result_future

    def cancel_wait(self, future):
        self.waiters.remove(future)
        # Set an empty result to unblock any coroutines waiting.
        future.set_result([])

    def new_messages(self, messages):
        logging.info(""Sending new message to %r listeners"", len(self.waiters))
        for future in self.waiters:
            future.set_result(messages)
        self.waiters = set()
        self.cache.extend(messages)
        if len(self.cache) > self.cache_size:
            self.cache = self.cache[-self.cache_size:]","class MessageBuffer(object):


    def __init__(self):
        pass

    def wait_for_messages(self, cursor=None):
        pass

    def cancel_wait(self, future):
        pass

    def new_messages(self, messages):
        pass

",5,0,snippet_684,0.25,"class MessageBuffer(object):

    def __init__(self):
        self._lock = threading.Lock()
        self._buffer = []  # list of (seq, message)
        self._next_seq = 1
        self._pending = []  # list of (future, cursor)

    def wait_for_messages(self, cursor=None):
        if cursor is None:
            cursor = 0
        fut = concurrent.futures.Future()
        with self._lock:
            new = [msg for seq, msg in self._buffer if seq > cursor]
            if new:
                fut.set_result(new)
            else:
                self._pending.append((fut, cursor))
        return fut

    def cancel_wait(self, future):
        with self._lock:
            for i, (fut, cursor) in enumerate(self._pending):
                if fut is future:
                    fut.cancel()
                    del self._pending[i]
                    break

    def new_messages(self, messages):
        with self._lock:
            for msg in messages:
                self._buffer.append((self._next_seq, msg))
                self._next_seq += 1
            to_notify = []
            for fut, cursor in self._pending:
                if fut.cancelled():
                    continue
                new = [msg for seq, msg in self._buffer if seq > cursor]
                if new:
                    to_notify.append((fut, new))
            for fut, new in to_notify:
                if not fut.done():
                    fut.set_result(new)
                self._pending = [(f, c) for f, c in self._pending if f is not fut]","class MessageBuffer(object):
    def __init__(self):
        self._messages = deque()
        self._waiters = []
        self._lock = threading.RLock()
        self._cancelled = set()

    def wait_for_messages(self, cursor=None):
        future = asyncio.Future()
        
        with self._lock:
            # Check if there are already messages available
            if cursor is None:
                if len(self._messages) > 0:
                    future.set_result(list(self._messages))
                    return future
            else:
                # Find messages after cursor
                available_messages = []
                for msg in self._messages:
                    if hasattr(msg, 'id') and msg.id > cursor:
                        available_messages.append(msg)
                
                if available_messages:
                    future.set_result(available_messages)
                    return future
            
            # No messages available, add to waiters
            waiter_id = id(future)
            self._waiters.append((waiter_id, future, cursor))
            future._waiter_id = waiter_id
            
        return future

    def cancel_wait(self, future):
        if hasattr(future, '_waiter_id'):
            waiter_id = future._waiter_id
            with self._lock:
                self._cancelled.add(waiter_id)
                # Remove from waiters list
                self._waiters = [(wid, f, cursor) for wid, f, cursor in self._waiters if wid != waiter_id]
            
            if not future.done():
                future.cancel()

    def new_messages(self, messages):
        if not messages:
            return
            
        with self._lock:
            # Add new messages
            for msg in messages:
                self._messages.append(msg)
            
            # Notify waiting futures
            notified_waiters = []
            for waiter_id, future, cursor in self._waiters:
                if waiter_id in self._cancelled:
                    continue
                    
                try:
                    if cursor is None:
                        # Return all messages
                        future.set_result(list(self._messages))
                        notified_waiters.append(waiter_id)
                    else:
                        # Return messages after cursor
                        available_messages = []
                        for msg in self._messages:
                            if hasattr(msg, 'id') and msg.id > cursor:
                                available_messages.append(msg)
                        
                        if available_messages:
                            future.set_result(available_messages)
                            notified_waiters.append(waiter_id)
                except Exception as e:
                    future.set_exception(e)
                    notified_waiters.append(waiter_id)
            
            # Remove notified waiters
            self._waiters = [(wid, f, cursor) for wid, f, cursor in self._waiters 
                           if wid not in notified_waiters and wid not in self._cancelled]
            
            # Clean up cancelled set
            for waiter_id in list(self._cancelled):
                if waiter_id not in [wid for wid, _, _ in self._waiters]:
                    self._cancelled.discard(waiter_id)","class MessageBuffer(object):
    def __init__(self):
        self._messages = deque()
        self._waiters = []
        self._lock = threading.Lock()
        self._message_id = 0

    def wait_for_messages(self, cursor=None):
        with self._lock:
            if cursor is None:
                cursor = 0
            
            # Check if we have messages after the cursor
            available_messages = []
            for msg_id, message in self._messages:
                if msg_id > cursor:
                    available_messages.append((msg_id, message))
            
            if available_messages:
                # Return immediately if we have messages
                future = asyncio.Future()
                future.set_result(available_messages)
                return future
            
            # No messages available, create a future to wait
            future = asyncio.Future()
            self._waiters.append((cursor, future))
            return future

    def cancel_wait(self, future):
        with self._lock:
            self._waiters = [(cursor, f) for cursor, f in self._waiters if f != future]
            if not future.done():
                future.cancel()

    def new_messages(self, messages):
        with self._lock:
            # Add messages to buffer
            for message in messages:
                self._message_id += 1
                self._messages.append((self._message_id, message))
            
            # Notify waiters
            completed_waiters = []
            for cursor, future in self._waiters:
                if not future.done():
                    # Get messages after cursor
                    available_messages = []
                    for msg_id, message in self._messages:
                        if msg_id > cursor:
                            available_messages.append((msg_id, message))
                    
                    if available_messages:
                        future.set_result(available_messages)
                        completed_waiters.append((cursor, future))
            
            # Remove completed waiters
            for waiter in completed_waiters:
                if waiter in self._waiters:
                    self._waiters.remove(waiter)",no_docstr,0.4318181818181818,0.1657142857142857,0.09770114942528736,0.31250000000000006,0.31362122856439373,0.5758426966292135,0.28732394366197184,0.1864406779661017,0.7852121591567993,0.77723628282547,0.7812038064002991,0.7780265212059021,0.7871366315789473,0.4,0.18875502008032127,0.10080645161290323,0.312,0.22186801657590807,0.37073170731707317,0.21498371335504887,0.1370309951060359,0.7947156429290771,0.8001811504364014,0.7974390387535095,0.7996311783790588,0.7710606047516202,0.48469387755102045,0.2512820512820513,0.13402061855670103,0.35714285714285715,0.3030031023270704,0.5271867612293144,0.2962085308056872,0.17814726840855108,0.825965166091919,0.8067896366119385,0.8162647485733032,0.8086670637130737,0.7926187947882736,0.2380855037970875,0.0550264446601261,0.0708570049392236,0.4786324786324786,0.3478260869565217,0.3080594104613031,0.0321898652722973,0.0707278211660034,0.5641025641025641,0.5652173913043478,0.299208393280563,0.0437714428954056,0.0664772175549772,0.5213675213675214,0.5652173913043478
627096,pandas-dev/pandas,pandas-dev_pandas/asv_bench/benchmarks/indexing.py,benchmarks.indexing.MethodLookup,"class MethodLookup:
    def setup_cache(self):
        s = Series()
        return s

    def time_lookup_iloc(self, s):
        s.iloc

    def time_lookup_loc(self, s):
        s.loc","class MethodLookup:


    def setup_cache(self):
        pass

    def time_lookup_iloc(self, s):
        pass

    def time_lookup_loc(self, s):
        pass

",4,0,snippet_700,1.0,"class MethodLookup:

    def setup_cache(self):
        import random
        random.seed(0)

    def time_lookup_iloc(self, s):
        import random
        from timeit import default_timer as timer
        n = min(1000, len(s))
        positions = random.sample(range(len(s)), n)
        start = timer()
        for pos in positions:
            _ = s.iloc[pos]
        return timer() - start

    def time_lookup_loc(self, s):
        import random
        from timeit import default_timer as timer
        n = min(1000, len(s))
        labels = random.sample(list(s.index), n)
        start = timer()
        for label in labels:
            _ = s.loc[label]
        return timer() - start","class MethodLookup:
    def setup_cache(self):
        self.s = pd.Series(np.random.randn(1000000))
        self.s.index = pd.date_range('2000-01-01', periods=len(self.s), freq='D')
        self.lookup_index = len(self.s) // 2
        self.lookup_label = self.s.index[len(self.s) // 2]

    def time_lookup_iloc(self, s):
        _ = s.iloc[self.lookup_index]

    def time_lookup_loc(self, s):
        _ = s.loc[self.lookup_label]","class MethodLookup:
    def __init__(self):
        self.df = None
        self.series = None

    def setup_cache(self):
        import pandas as pd
        import numpy as np
        
        n = 10000
        self.df = pd.DataFrame({
            'A': np.random.randn(n),
            'B': np.random.randn(n),
            'C': np.random.randn(n)
        })
        self.series = pd.Series(np.random.randn(n))

    def time_lookup_iloc(self, s):
        for i in range(100):
            _ = self.series.iloc[i]

    def time_lookup_loc(self, s):
        for i in range(100):
            _ = self.series.loc[i]",no_docstr,0.4347826086956522,0.3008849557522124,0.2162162162162162,0.38260869565217387,0.2365301307620465,0.2909090909090909,0.23170731707317074,0.19631901840490798,0.6724765300750732,0.8897716999053955,0.7660121917724609,0.8619207143783569,0.7324588157894739,0.5319148936170213,0.43478260869565216,0.3555555555555555,0.5319148936170213,0.2717251039963728,0.3310344827586207,0.2708333333333333,0.22377622377622378,0.7704267501831055,0.8966417908668518,0.8287563323974609,0.8821893334388733,0.765842561983471,0.3888888888888889,0.2830188679245283,0.21153846153846154,0.3888888888888889,0.22107598060968509,0.26993865030674846,0.2222222222222222,0.18012422360248448,0.6750844717025757,0.8282121419906616,0.7438493967056274,0.8098427057266235,0.744591298701299,0.4199565669611552,0.0598869069340247,0.2913679323391676,0.4285714285714285,0.9,0.2365808299437863,0.1289767849299987,0.2792512967499085,0.238095238095238,0.3,0.1311166957948526,0.0402344351345391,0.1461371099496334,0.238095238095238,0.1
663941,pyQode/pyqode.core,pyQode_pyqode.core/pyqode/core/_forms/pnl_read_only_ui.py,pyqode.core._forms.pnl_read_only_ui.Ui_Form,"class Ui_Form(object):
    def setupUi(self, Form):
        Form.setObjectName(""Form"")
        Form.resize(964, 67)
        self.horizontalLayout_2 = QtWidgets.QHBoxLayout(Form)
        self.horizontalLayout_2.setObjectName(""horizontalLayout_2"")
        self.lblDescription = QtWidgets.QLabel(Form)
        sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.Preferred)
        sizePolicy.setHorizontalStretch(0)
        sizePolicy.setVerticalStretch(0)
        sizePolicy.setHeightForWidth(self.lblDescription.sizePolicy().hasHeightForWidth())
        self.lblDescription.setSizePolicy(sizePolicy)
        self.lblDescription.setWordWrap(True)
        self.lblDescription.setObjectName(""lblDescription"")
        self.horizontalLayout_2.addWidget(self.lblDescription)

        self.retranslateUi(Form)
        QtCore.QMetaObject.connectSlotsByName(Form)

    def retranslateUi(self, Form):

        Form.setWindowTitle(_(""Form""))
        self.lblDescription.setText(_(""<html><head/><body><p>The file you opened is read-only.</p><p>Use &quot;save as&quot; or change the file\'s permission to edit the document...</p></body></html>""))","class Ui_Form(object):


    def setupUi(self, Form):
        pass

    def retranslateUi(self, Form):
        pass

",3,0,snippet_158,1.0,"class Ui_Form(object):
    def setupUi(self, Form):
        Form.setObjectName(""Form"")
        Form.resize(400, 300)
        self.label = QtWidgets.QLabel(Form)
        self.label.setGeometry(QtCore.QRect(50, 50, 300, 40))
        self.label.setObjectName(""label"")
        self.pushButton = QtWidgets.QPushButton(Form)
        self.pushButton.setGeometry(QtCore.QRect(150, 200, 100, 30))
        self.pushButton.setObjectName(""pushButton"")
        self.retranslateUi(Form)
        QtCore.QMetaObject.connectSlotsByName(Form)

    def retranslateUi(self, Form):
        _translate = QtCore.QCoreApplication.translate
        Form.setWindowTitle(_translate(""Form"", ""Sample Form""))
        self.label.setText(_translate(""Form"", ""Hello, World!""))
        self.pushButton.setText(_translate(""Form"", ""Click Me""))","class Ui_Form(object):
    def setupUi(self, Form):
        Form.setObjectName(""Form"")
        Form.resize(400, 300)
        self.retranslateUi(Form)

    def retranslateUi(self, Form):
        Form.setWindowTitle(""Form"")","class Ui_Form(object):
    def setupUi(self, Form):
        Form.setObjectName(""Form"")
        Form.resize(400, 300)
        
    def retranslateUi(self, Form):
        Form.setWindowTitle(""Form"")",no_docstr,0.4195121951219512,0.2660098522167488,0.208955223880597,0.3902439024390244,0.3950181386846035,0.702020202020202,0.5076142131979695,0.41836734693877553,0.8567678928375244,0.7593634724617004,0.8051304221153259,0.7680957913398743,0.8292700000000002,0.3194444444444444,0.29577464788732394,0.2571428571428572,0.3194444444444444,0.02236470802658313,0.9636363636363636,0.9259259259259259,0.8867924528301887,0.9002526998519897,0.6206860542297363,0.7347755432128906,0.6405788660049438,0.7528480000000006,0.2836879432624114,0.25899280575539574,0.23357664233576644,0.2836879432624114,0.012266051545679916,0.9591836734693877,0.9166666666666666,0.8723404255319149,0.9039921760559082,0.6102702021598816,0.7286444902420044,0.6307647824287415,0.7414660000000007,0.4134205306485656,0.1773684726332393,0.1905993642467373,0.625,0.6607142857142857,0.1841592400973716,0.0311893527100128,0.1340190362509025,0.4285714285714285,0.1428571428571428,0.1597346888338785,0.0243264753856926,0.1324694228069644,0.3928571428571428,0.0892857142857142
149091,Mangopay/mangopay2-python-sdk,Mangopay_mangopay2-python-sdk/mangopay/auth.py,mangopay.auth.StorageStrategyBase,"class StorageStrategyBase(object):

    def get(self, env_key):
        pass

    def store(self, token, env_key):
        pass","class StorageStrategyBase(object):


    def get(self, env_key):
        pass

    def store(self, token, env_key):
        pass

",3,0,snippet_111,1.0,"class StorageStrategyBase(object):
    def __init__(self):
        self._store = {}

    def get(self, env_key):
        return self._store.get(env_key, None)

    def store(self, token, env_key):
        self._store[env_key] = token","class StorageStrategyBase(object):

    def get(self, env_key):
        raise NotImplementedError(""Subclasses must implement get method"")

    def store(self, token, env_key):
        raise NotImplementedError(""Subclasses must implement store method"")","class StorageStrategyBase(object):

    def get(self, env_key):
        raise NotImplementedError(""Subclasses must implement get method"")

    def store(self, token, env_key):
        raise NotImplementedError(""Subclasses must implement store method"")",no_docstr,0.5957446808510638,0.5333333333333333,0.4186046511627907,0.5957446808510638,0.37982992238762364,0.4084507042253521,0.38571428571428573,0.34782608695652173,0.8805065155029297,0.9162814617156982,0.898037850856781,0.9125736355781555,0.798613125,0.6363636363636364,0.5714285714285714,0.5,0.6363636363636364,0.5390824209848649,0.5686274509803921,0.54,0.5102040816326531,0.8041708469390869,0.9528472423553467,0.872218668460846,0.9355505704879761,0.8476205714285714,0.6363636363636364,0.5714285714285714,0.5,0.6363636363636364,0.5390824209848649,0.5686274509803921,0.54,0.5102040816326531,0.8041708469390869,0.9528472423553467,0.872218668460846,0.9355505704879761,0.8476205714285714,0.3421592238357747,0.2157614635827856,0.4028754317603134,0.25,0.5,0.5238580870949192,0.2847994216380736,0.5606329267416034,0.25,1.0,0.5238580870949192,0.2847994216380736,0.5606329267416034,0.25,1.0
837416,yeraydiazdiaz/lunr.py,lunr/token_set_builder.py,lunr.token_set_builder.TokenSetBuilder,"class TokenSetBuilder:
    def __init__(self):
        self.previous_word = """"
        self.root = TokenSet()
        self.unchecked_nodes = []
        self.minimized_nodes = {}

    def insert(self, word):
        if word < self.previous_word:
            raise BaseLunrException(""Out of order word insertion"")

        common_prefix = 0
        for i in range(min(len(word), len(self.previous_word))):
            if word[i] != self.previous_word[i]:
                break

            common_prefix += 1

        self.minimize(common_prefix)

        node = (
            self.root if not self.unchecked_nodes else self.unchecked_nodes[-1][""child""]
        )

        for i in range(common_prefix, len(word)):
            next_node = TokenSet()
            char = word[i]

            node.edges[char] = next_node

            self.unchecked_nodes.append(
                {""parent"": node, ""char"": char, ""child"": next_node}
            )

            node = next_node

        node.final = True
        self.previous_word = word

    def finish(self):
        self.minimize(0)

    def minimize(self, down_to):
        for i in range(len(self.unchecked_nodes) - 1, down_to - 1, -1):
            node = self.unchecked_nodes[i]
            child_key = str(node[""child""])

            if child_key in self.minimized_nodes:
                node[""parent""].edges[node[""char""]] = self.minimized_nodes[child_key]
            else:
                node[""child""]._str = child_key
                self.minimized_nodes[child_key] = node[""child""]

            self.unchecked_nodes.pop()","class TokenSetBuilder:


    def __init__(self):
        pass

    def insert(self, word):
        pass

    def finish(self):
        pass

    def minimize(self, down_to):
        pass

",5,0,snippet_189,0.1666666666666666,"class TokenSetBuilder:
    class _Node:
        __slots__ = (""final"", ""transitions"")
        def __init__(self):
            self.final = False
            self.transitions = {}

        def __hash__(self):
            items = tuple(sorted((ch, id(nd)) for ch, nd in self.transitions.items()))
            return hash((self.final, items))

        def __eq__(self, other):
            if self.final != other.final:
                return False
            if self.transitions.keys() != other.transitions.keys():
                return False
            for ch, nd in self.transitions.items():
                if other.transitions[ch] is not nd:
                    return False
            return True

    def __init__(self):
        self.root = self._Node()
        self.register = {}
        self.previous_word = """"
        self.frontier = [self.root]

    def insert(self, word):
        if word < self.previous_word:
            raise ValueError(""Words must be inserted in non-decreasing lex order"")
        # find common prefix length
        common = 0
        max_common = min(len(word), len(self.previous_word))
        while common < max_common and word[common] == self.previous_word[common]:
            common += 1
        # minimize states beyond common prefix
        self.minimize(common)
        # add suffix for the new word
        node = self.frontier[common]
        for ch in word[common:]:
            nxt = self._Node()
            node.transitions[ch] = nxt
            self.frontier.append(nxt)
            node = nxt
        node.final = True
        self.previous_word = word

    def minimize(self, down_to):
        # minimize all states deeper than down_to
        for i in range(len(self.frontier) - 1, down_to, -1):
            node = self.frontier.pop()
            parent = self.frontier[i - 1]
            ch = self.previous_word[i - 1]
            registered = self.register.get(node)
            if registered is not None:
                parent.transitions[ch] = registered
            else:
                self.register[node] = node

    def finish(self):
        self.minimize(0)
        return self.root","class TokenSetBuilder:
    def __init__(self):
        self.words = set()
        self.finished = False
        self.minimized = False

    def insert(self, word):
        if self.finished:
            raise RuntimeError(""Cannot insert after finish() has been called"")
        self.words.add(word)

    def finish(self):
        if not self.finished:
            self.finished = True
        return self.words

    def minimize(self, down_to):
        if not self.finished:
            raise RuntimeError(""finish() must be called before minimize()"")
        if self.minimized:
            return self.words
            
        if len(self.words) <= down_to:
            self.minimized = True
            return self.words
            
        # Sort words by length and then lexicographically
        sorted_words = sorted(self.words, key=lambda x: (len(x), x))
        self.words = set(sorted_words[:down_to])
        self.minimized = True
        return self.words","class TokenSetBuilder:
    def __init__(self):
        self.words = set()
        self.finished = False
        self.token_set = None

    def insert(self, word):
        if not self.finished:
            self.words.add(word.lower())

    def finish(self):
        self.finished = True
        self.token_set = frozenset(self.words)
        return self.token_set

    def minimize(self, down_to):
        if self.finished and len(self.words) > down_to:
            sorted_words = sorted(self.words, key=len, reverse=True)
            self.words = set(sorted_words[:down_to])
            self.token_set = frozenset(self.words)
        return self.token_set if self.finished else None",no_docstr,0.5243619489559165,0.2983682983682984,0.19672131147540986,0.38515081206496515,0.3832081374352218,0.5991820040899796,0.36885245901639346,0.2546201232032854,0.7984244227409363,0.829900860786438,0.8138583898544312,0.8266419768333435,0.7514428148148142,0.3569023569023569,0.16271186440677968,0.08873720136518772,0.2760942760942761,0.16767489137248887,0.7067307692307693,0.41545893719806765,0.23786407766990292,0.8008973598480225,0.7402197122573853,0.7693639993667603,0.7458705902099609,0.7632422429906548,0.336996336996337,0.15498154981549814,0.09665427509293681,0.2710622710622711,0.12135699945688738,0.7441860465116279,0.4269005847953216,0.27647058823529413,0.8123337030410767,0.7041540145874023,0.7543852925300598,0.7136578559875488,0.7559733644859816,0.2827613207366328,0.1228350283924145,0.2101895617965818,0.5672514619883041,0.2307692307692307,0.192963638177793,0.0561659180174392,0.0683651978966118,0.3567251461988304,0.2905982905982906,0.1586778738070624,0.0398500468792754,0.0671961312099728,0.2456140350877192,0.282051282051282
500123,ionelmc/python-cogen,ionelmc_python-cogen/cogen/web/async.py,cogen.web.async.COGENOperationCall,"class COGENOperationCall(object):
    def __init__(self, gate, obj):
        self.gate = gate
        self.obj = obj

    def __call__(self, *args, **kwargs):
        self.gate.operation = self.obj(*args, **kwargs)
        return """"","class COGENOperationCall(object):


    def __init__(self, gate, obj):
        pass

    def __call__(self, *args, **kwargs):
        pass

",3,0,snippet_653,1.0,"class COGENOperationCall(object):
    def __init__(self, gate, obj):
        if not (callable(gate) or isinstance(gate, str)):
            raise TypeError(""gate must be a callable or a string name"")
        self.gate = gate
        self.obj = obj

    def __call__(self, *args, **kwargs):
        if callable(self.gate):
            return self.gate(self.obj, *args, **kwargs)
        else:
            method = getattr(self.obj, self.gate)
            if not callable(method):
                raise TypeError(f""Attribute '{self.gate}' of object is not callable"")
            return method(*args, **kwargs)","class COGENOperationCall(object):
    def __init__(self, gate, obj):
        self.gate = gate
        self.obj = obj

    def __call__(self, *args, **kwargs):
        return self.gate(self.obj, *args, **kwargs)","class COGENOperationCall(object):

    def __init__(self, gate, obj):
        self.gate = gate
        self.obj = obj

    def __call__(self, *args, **kwargs):
        return self.gate(self.obj, *args, **kwargs)",no_docstr,0.5098039215686275,0.44000000000000006,0.36734693877551017,0.5098039215686275,0.3835454191103282,0.43506493506493504,0.3790849673202614,0.34210526315789475,0.7515280842781067,0.9151518940925598,0.8253082036972046,0.8956515789031982,0.7955202521008403,0.9811320754716981,0.9019607843137256,0.816326530612245,0.9433962264150944,0.8569433266525125,0.984375,0.9047619047619048,0.8548387096774194,0.9717234969139099,0.9654974937438965,0.9686004519462585,0.9661165475845337,0.9382722222222222,0.9811320754716981,0.9019607843137256,0.816326530612245,0.9433962264150944,0.8569433266525125,0.984375,0.9047619047619048,0.8548387096774194,0.9713621139526367,0.9651386737823486,0.9682404398918152,0.965757429599762,0.9382722222222222,0.530715796845206,0.240885627048535,0.6635867557345878,0.5517241379310345,0.6666666666666666,0.7232249788523026,0.7295466777263768,0.7438130077977761,0.5862068965517241,0.8333333333333334,0.7232249788523026,0.7295466777263768,0.7438130077977761,0.5862068965517241,0.8333333333333334
7834,AtteqCom/zsl,AtteqCom_zsl/src/zsl/db/helpers/query_filter.py,zsl.db.helpers.query_filter.OperatorCompareDates,"class OperatorCompareDates:
    """"""
    Compares only dates, year is not taken into account.
    Compared date value must be string in format '%m-%d'
    """"""

    @staticmethod
    def apply(q, attr, v):
        return q.filter(func.date_format(attr, '%m-%d') == v)","class OperatorCompareDates:
    '''
    Compares only dates, year is not taken into account.
    Compared date value must be string in format '%m-%d'
    '''

    @staticmethod
    def apply(q, attr, v):
        pass

",3,1,snippet_122,1.0,"class OperatorCompareDates:
    '''
    Compares only dates, year is not taken into account.
    Compared date value must be string in format '%m-%d'
    '''

    @staticmethod
    def apply(q, attr, v):
        try:
            month_str, day_str = v.split('-')
            month, day = int(month_str), int(day_str)
        except Exception:
            raise ValueError(f""Invalid date format '{v}', expected '%m-%d'"")
        return q.filter(
            extract('month', attr) == month,
            extract('day', attr) == day
        )","class OperatorCompareDates:
    '''
    Compares only dates, year is not taken into account.
    Compared date value must be string in format '%m-%d'
    '''

    @staticmethod
    def apply(q, attr, v):
        # Extract month and day from the query value
        query_month, query_day = map(int, q.split('-'))
        # Extract month and day from the attribute value
        attr_month, attr_day = map(int, attr.split('-'))
        
        # Compare months first
        if query_month < attr_month:
            return True
        elif query_month > attr_month:
            return False
        else:
            # If months are equal, compare days
            return query_day < attr_day","class OperatorCompareDates:
    '''
    Compares only dates, year is not taken into account.
    Compared date value must be string in format '%m-%d'
    '''

    @staticmethod
    def apply(q, attr, v):
        try:
            target_date = datetime.strptime(v, '%m-%d')
            target_month_day = (target_date.month, target_date.day)
            
            def date_filter(obj):
                obj_date_value = getattr(obj, attr, None)
                if obj_date_value is None:
                    return False
                
                if isinstance(obj_date_value, str):
                    try:
                        obj_date = datetime.strptime(obj_date_value, '%m-%d')
                        obj_month_day = (obj_date.month, obj_date.day)
                        return obj_month_day == target_month_day
                    except ValueError:
                        return False
                elif hasattr(obj_date_value, 'month') and hasattr(obj_date_value, 'day'):
                    obj_month_day = (obj_date_value.month, obj_date_value.day)
                    return obj_month_day == target_month_day
                else:
                    return False
            
            return filter(date_filter, q)
        except ValueError:
            return q",partial_docstr,0.7058823529411765,0.6,0.5306122448979592,0.607843137254902,0.41032644880081687,0.512,0.3951612903225806,0.34146341463414637,0.8339308500289917,0.9430454969406128,0.8851380944252014,0.9308657050132751,0.7827737078651685,0.4799999999999999,0.4227642276422765,0.41322314049586784,0.464,0.292681069709123,0.3732394366197183,0.2765957446808511,0.24285714285714285,0.755224347114563,0.9093948006629944,0.8251702189445496,0.8912019729614258,0.7848122784810126,0.39325842696629215,0.3181818181818182,0.28735632183908044,0.3595505617977528,0.19020898560094096,0.23461538461538461,0.1891891891891892,0.15503875968992248,0.6940985918045044,0.9141361713409424,0.7890647053718567,0.8860474228858948,0.7380978571428575,0.5927962858049498,0.3771745742868584,0.6998929218741169,0.2941176470588235,1.0,0.5612408633516517,0.2544092514407473,0.6964365549070356,0.2941176470588235,1.0,0.5864753615751737,0.2308379130002441,0.7032988274180978,0.4117647058823529,1.0
737691,shoprunback/openflow,shoprunback_openflow/openflow/datasource.py,openflow.datasource.DataSource,"class DataSource:
    """"""
    Extracts raw data then restitute it as an arranged DataFrame.

    Args:
        preprocess (lambda): Preprocess DataFrame before transformation
    """"""
    def __init__(self, fetch, preprocess=None):
        self.fetch = fetch
        self.preprocess = preprocess or (lambda df: df)
        self.context = None
        self.df = None
        self.outputs = []

    def add_output(self, name, function):
        """"""
        Adds an output to the DataSource. The order in which the outputs are appended is important if previous outputs are reused.

        Args:
            name (str): Name of the output
            function (lambda): Function to apply to DataFrame

        Examples:
            >>> add_output('double', lambda df: 2 * df['number'])
        """"""
        self.outputs.append((name, function))

    def transform(self, df):
        """"""
        Transforms a DataFrame in place. Computes all outputs of the DataFrame.

        Args:
            df (pandas.DataFrame): DataFrame to transform.
        """"""
        for name, function in self.outputs:
            df[name] = function(df)

    def get_dataframe(self, force_computation=False):
        """"""
        Preprocesses then transforms the return of fetch().

        Args:
            force_computation (bool, optional) : Defaults to False. If set to True, forces the computation of DataFrame at each call.

        Returns:
            pandas.DataFrame: Preprocessed and transformed DataFrame.
        """"""
        # returns df if it was already computed
        if self.df is not None and not force_computation: return self.df

        self.df = self.fetch(self.context)

        # compute df = transform(preprocess(df)
        self.df = self.preprocess(self.df)
        self.transform(self.df)

        return self.df

    def set_context(self, context):
        """"""
        Set context for runtime. Will be passed to fetch() function.

        Args:
            context (obj): Context to be passed to fetch().
        """"""
        self.context = context","class DataSource:
    '''
    Extracts raw data then restitute it as an arranged DataFrame.

    Args:
        preprocess (lambda): Preprocess DataFrame before transformation
    '''

    def __init__(self, fetch, preprocess=None):
        pass

    def add_output(self, name, function):
    '''
        Adds an output to the DataSource. The order in which the outputs are appended is important if previous outputs are reused.

        Args:
            name (str): Name of the output
            function (lambda): Function to apply to DataFrame

        Examples:
            >>> add_output('double', lambda df: 2 * df['number'])
        '''
        pass

    def transform(self, df):
    '''
        Transforms a DataFrame in place. Computes all outputs of the DataFrame.

        Args:
            df (pandas.DataFrame): DataFrame to transform.
        '''
        pass

    def get_dataframe(self, force_computation=False):
    '''
        Preprocesses then transforms the return of fetch().

        Args:
            force_computation (bool, optional) : Defaults to False. If set to True, forces the computation of DataFrame at each call.

        Returns:
            pandas.DataFrame: Preprocessed and transformed DataFrame.
        '''
        pass

    def set_context(self, context):
    '''
        Set context for runtime. Will be passed to fetch() function.

        Args:
            context (obj): Context to be passed to fetch().
        '''
        pass

",6,5,snippet_259,0.6923076923076923,"class DataSource:
    '''
    Extracts raw data then restitute it as an arranged DataFrame.

    Args:
        preprocess (lambda): Preprocess DataFrame before transformation
    '''

    def __init__(self, fetch, preprocess=None):
        self.fetch = fetch
        self.preprocess = preprocess
        self._outputs = []
        self._context = None
        self._cached_df = None

    def add_output(self, name, function):
        '''
        Adds an output to the DataSource. The order in which the outputs are appended is important if previous outputs are reused.

        Args:
            name (str): Name of the output
            function (lambda): Function to apply to DataFrame

        Examples:
            >>> add_output('double', lambda df: 2 * df['number'])
        '''
        self._outputs.append((name, function))

    def transform(self, df):
        '''
        Transforms a DataFrame in place. Computes all outputs of the DataFrame.

        Args:
            df (pandas.DataFrame): DataFrame to transform.
        '''
        for name, func in self._outputs:
            df[name] = func(df)

    def get_dataframe(self, force_computation=False):
        '''
        Preprocesses then transforms the return of fetch().

        Args:
            force_computation (bool, optional) : Defaults to False. If set to True, forces the computation of DataFrame at each call.

        Returns:
            pandas.DataFrame: Preprocessed and transformed DataFrame.
        '''
        if force_computation or self._cached_df is None:
            df = self.fetch(self._context) if self._context is not None else self.fetch()
            if self.preprocess:
                df = self.preprocess(df)
            self.transform(df)
            self._cached_df = df
        return self._cached_df

    def set_context(self, context):
        '''
        Set context for runtime. Will be passed to fetch() function.

        Args:
            context (obj): Context to be passed to fetch().
        '''
        self._context = context","class DataSource:
    '''
    Extracts raw data then restitute it as an arranged DataFrame.

    Args:
        preprocess (lambda): Preprocess DataFrame before transformation
    '''

    def __init__(self, fetch, preprocess=None):
        self.fetch = fetch
        self.preprocess = preprocess
        self.outputs = []
        self.context = None
        self._cached_dataframe = None

    def add_output(self, name, function):
        '''
        Adds an output to the DataSource. The order in which the outputs are appended is important if previous outputs are reused.

        Args:
            name (str): Name of the output
            function (lambda): Function to apply to DataFrame

        Examples:
            >>> add_output('double', lambda df: 2 * df['number'])
        '''
        self.outputs.append((name, function))

    def transform(self, df):
        '''
        Transforms a DataFrame in place. Computes all outputs of the DataFrame.

        Args:
            df (pandas.DataFrame): DataFrame to transform.
        '''
        for name, function in self.outputs:
            df[name] = function(df)

    def get_dataframe(self, force_computation=False):
        '''
        Preprocesses then transforms the return of fetch().

        Args:
            force_computation (bool, optional) : Defaults to False. If set to True, forces the computation of DataFrame at each call.

        Returns:
            pandas.DataFrame: Preprocessed and transformed DataFrame.
        '''
        if not force_computation and self._cached_dataframe is not None:
            return self._cached_dataframe.copy()

        # Fetch raw data
        if self.context is not None:
            df = self.fetch(self.context)
        else:
            df = self.fetch()

        # Preprocess if needed
        if self.preprocess is not None:
            df = self.preprocess(df)

        # Transform DataFrame
        self.transform(df)

        # Cache the result
        self._cached_dataframe = df.copy()
        
        return df

    def set_context(self, context):
        '''
        Set context for runtime. Will be passed to fetch() function.

        Args:
            context (obj): Context to be passed to fetch().
        '''
        self.context = context
        # Invalidate cache when context changes
        self._cached_dataframe = None","class DataSource:
    '''
    Extracts raw data then restitute it as an arranged DataFrame.

    Args:
        preprocess (lambda): Preprocess DataFrame before transformation
    '''

    def __init__(self, fetch, preprocess=None):
        self.fetch = fetch
        self.preprocess = preprocess
        self.outputs = []
        self.context = None
        self._cached_dataframe = None

    def add_output(self, name, function):
        '''
        Adds an output to the DataSource. The order in which the outputs are appended is important if previous outputs are reused.

        Args:
            name (str): Name of the output
            function (lambda): Function to apply to DataFrame

        Examples:
            >>> add_output('double', lambda df: 2 * df['number'])
        '''
        self.outputs.append((name, function))

    def transform(self, df):
        '''
        Transforms a DataFrame in place. Computes all outputs of the DataFrame.

        Args:
            df (pandas.DataFrame): DataFrame to transform.
        '''
        for name, function in self.outputs:
            df[name] = function(df)

    def get_dataframe(self, force_computation=False):
        '''
        Preprocesses then transforms the return of fetch().

        Args:
            force_computation (bool, optional) : Defaults to False. If set to True, forces the computation of DataFrame at each call.

        Returns:
            pandas.DataFrame: Preprocessed and transformed DataFrame.
        '''
        if self._cached_dataframe is None or force_computation:
            if self.context is not None:
                df = self.fetch(self.context)
            else:
                df = self.fetch()
            
            if self.preprocess is not None:
                df = self.preprocess(df)
            
            self.transform(df)
            self._cached_dataframe = df
        
        return self._cached_dataframe

    def set_context(self, context):
        '''
        Set context for runtime. Will be passed to fetch() function.

        Args:
            context (obj): Context to be passed to fetch().
        '''
        self.context = context",partial_docstr,0.9372384937238494,0.8571428571428572,0.7805907172995781,0.8870292887029289,0.7785910724984394,0.9095354523227384,0.8112745098039216,0.7248157248157249,0.9711635708808899,0.9707469344139099,0.9709551930427551,0.9707885980606079,0.9197215706806283,0.8976377952755904,0.8102766798418971,0.7500000000000001,0.8543307086614172,0.7641734925664287,0.8466666666666667,0.7616926503340757,0.6919642857142857,0.945337176322937,0.9646511077880859,0.9548965096473694,0.9626842737197876,0.9004534841628958,0.9294605809128631,0.8541666666666667,0.7949790794979078,0.8921161825726143,0.7996087057300256,0.9095354523227384,0.8308823529411765,0.7665847665847666,0.9631568789482117,0.9629660248756409,0.9630614519119263,0.962985098361969,0.9212738190954773,0.6809185425591778,0.6615896261295837,0.6678992837961066,0.7471264367816092,0.6470588235294118,0.6900405913092094,0.6398576531516159,0.7164845633360664,0.7126436781609196,0.6911764705882353,0.7147113754206338,0.7076197878164167,0.7129228064962744,0.7471264367816092,0.6911764705882353
282822,carpyncho/feets,carpyncho_feets/doc/source/JSAnimation/IPython_display.py,JSAnimation.IPython_display._NameOnlyTemporaryFile,"class _NameOnlyTemporaryFile(object):
    """"""A context-managed temporary file which is not opened.

    The file should be accessible by name on any system.

    Parameters
    ----------
    suffix : string
        The suffix of the temporary file (default = '')
    prefix : string
        The prefix of the temporary file (default = '_tmp_')
    hash_length : string
        The length of the random hash.  The size of the hash space will
        be 16 ** hash_length (default=8)
    seed : integer
        the seed for the random number generator.  If not specified, the
        system time will be used as a seed.
    absolute : boolean
        If true, return an absolute path to a temporary file in the current
        working directory.

    Example
    -------

    >>> with _NameOnlyTemporaryFile(seed=0, absolute=False) as f:
    ...     print(f)
    ...
    _tmp_d82c07cd
    >>> os.path.exists('_tmp_d82c07cd')  # file removed after context
    False

    """"""
    def __init__(self, prefix='_tmp_', suffix='', hash_length=8,
                 seed=None, absolute=True):
        rng = random.Random(seed)
        self.name = '%s%0*x%s' % (prefix, hash_length,
                                  rng.getrandbits(4 * hash_length), suffix)
        if absolute:
            self.name = os.path.abspath(self.name)

    def __enter__(self):
        return self

    def __exit__(self, *exc_info):
        if os.path.exists(self.name):
            os.remove(self.name)","class _NameOnlyTemporaryFile(object):
    '''A context-managed temporary file which is not opened.

    The file should be accessible by name on any system.

    Parameters
    ----------
    suffix : string
        The suffix of the temporary file (default = '')
    prefix : string
        The prefix of the temporary file (default = '_tmp_')
    hash_length : string
        The length of the random hash.  The size of the hash space will
        be 16 ** hash_length (default=8)
    seed : integer
        the seed for the random number generator.  If not specified, the
        system time will be used as a seed.
    absolute : boolean
        If true, return an absolute path to a temporary file in the current
        working directory.

    Example
    -------

    >>> with _NameOnlyTemporaryFile(seed=0, absolute=False) as f:
    ...     print(f)
    ...
    _tmp_d82c07cd
    >>> os.path.exists('_tmp_d82c07cd')  # file removed after context
    False

    '''

    def __init__(self, prefix='_tmp_', suffix='', hash_length=8,
                 seed=None, absolute=True):
        pass

    def __enter__(self):
        pass

    def __exit__(self, *exc_info):
        pass

",4,1,snippet_518,0.2857142857142857,"class _NameOnlyTemporaryFile(object):
    '''A context-managed temporary file which is not opened.

    The file should be accessible by name on any system.

    Parameters
    ----------
    suffix : string
        The suffix of the temporary file (default = '')
    prefix : string
        The prefix of the temporary file (default = '_tmp_')
    hash_length : integer
        The length of the random hash.  The size of the hash space will
        be 16 ** hash_length (default=8)
    seed : integer
        the seed for the random number generator.  If not specified, the
        system time will be used as a seed.
    absolute : boolean
        If true, return an absolute path to a temporary file in the current
        working directory.
    '''
    def __init__(self, prefix='_tmp_', suffix='', hash_length=8,
                 seed=None, absolute=True):
        self.prefix = prefix
        self.suffix = suffix
        self.hash_length = hash_length
        # initialize RNG
        if seed is None:
            self._rng = random.Random()
        else:
            self._rng = random.Random(seed)
        self.absolute = absolute
        self.name = None

    def __enter__(self):
        # generate a unique filename
        while True:
            # random hex string of given length
            rand_int = self._rng.getrandbits(4 * self.hash_length)
            hash_str = format(rand_int, '0{}x'.format(self.hash_length))
            base = f""{self.prefix}{hash_str}{self.suffix}""
            if self.absolute:
                candidate = os.path.abspath(base)
            else:
                candidate = base
            if not os.path.exists(candidate):
                break
        # create the file by touching it
        open(candidate, 'a').close()
        self.name = candidate
        return self.name

    def __exit__(self, *exc_info):
        try:
            if self.name and os.path.exists(self.name):
                os.remove(self.name)
        except Exception:
            pass
        # propagate exceptions if any
        return False","class _NameOnlyTemporaryFile(object):
    '''A context-managed temporary file which is not opened.

    The file should be accessible by name on any system.

    Parameters
    ----------
    suffix : string
        The suffix of the temporary file (default = '')
    prefix : string
        The prefix of the temporary file (default = '_tmp_')
    hash_length : string
        The length of the random hash.  The size of the hash space will
        be 16 ** hash_length (default=8)
    seed : integer
        the seed for the random number generator.  If not specified, the
        system time will be used as a seed.
    absolute : boolean
        If true, return an absolute path to a temporary file in the current
        working directory.

    Example
    -------

    >>> with _NameOnlyTemporaryFile(seed=0, absolute=False) as f:
    ...     print(f)
    ...
    _tmp_d82c07cd
    >>> os.path.exists('_tmp_d82c07cd')  # file removed after context
    False

    '''

    def __init__(self, prefix='_tmp_', suffix='', hash_length=8,
                 seed=None, absolute=True):
        self.prefix = prefix
        self.suffix = suffix
        self.hash_length = hash_length
        self.absolute = absolute
        
        # Set up random seed
        if seed is not None:
            self.random_state = random.Random(seed)
        else:
            self.random_state = random.Random()
            
        self.file_path = None

    def __enter__(self):
        # Generate random hex string
        hex_chars = '0123456789abcdef'
        random_hash = ''.join(self.random_state.choice(hex_chars) 
                             for _ in range(self.hash_length))
        
        # Create filename
        filename = self.prefix + random_hash + self.suffix
        
        # Get temporary directory
        if self.absolute:
            temp_dir = os.getcwd()
        else:
            temp_dir = ''
            
        self.file_path = os.path.join(temp_dir, filename)
        
        # Ensure the file exists by creating it
        with open(self.file_path, 'w'):
            pass
            
        return self.file_path

    def __exit__(self, *exc_info):
        # Remove the temporary file if it exists
        if self.file_path and os.path.exists(self.file_path):
            os.remove(self.file_path)
        return False","class _NameOnlyTemporaryFile(object):
    '''A context-managed temporary file which is not opened.

    The file should be accessible by name on any system.

    Parameters
    ----------
    suffix : string
        The suffix of the temporary file (default = '')
    prefix : string
        The prefix of the temporary file (default = '_tmp_')
    hash_length : string
        The length of the random hash.  The size of the hash space will
        be 16 ** hash_length (default=8)
    seed : integer
        the seed for the random number generator.  If not specified, the
        system time will be used as a seed.
    absolute : boolean
        If true, return an absolute path to a temporary file in the current
        working directory.

    Example
    -------

    >>> with _NameOnlyTemporaryFile(seed=0, absolute=False) as f:
    ...     print(f)
    ...
    _tmp_d82c07cd
    >>> os.path.exists('_tmp_d82c07cd')  # file removed after context
    False

    '''

    def __init__(self, prefix='_tmp_', suffix='', hash_length=8,
                 seed=None, absolute=True):
        self.prefix = prefix
        self.suffix = suffix
        self.hash_length = hash_length
        self.seed = seed
        self.absolute = absolute
        self.filename = None

    def __enter__(self):
        if self.seed is not None:
            random.seed(self.seed)
        
        hash_chars = '0123456789abcdef'
        hash_str = ''.join(random.choice(hash_chars) for _ in range(self.hash_length))
        
        self.filename = self.prefix + hash_str + self.suffix
        
        if self.absolute:
            self.filename = os.path.abspath(self.filename)
        
        with open(self.filename, 'w'):
            pass
        
        return self.filename

    def __exit__(self, *exc_info):
        if self.filename and os.path.exists(self.filename):
            os.remove(self.filename)",partial_docstr,0.7699316628701594,0.6681922196796339,0.5839080459770115,0.6879271070615034,0.6045548922536971,0.6951501154734411,0.5879629629629629,0.5406032482598608,0.890421986579895,0.9198468923568726,0.9048953056335449,0.9168171882629395,0.7852458893280639,0.7366167023554604,0.6623655913978495,0.6220302375809935,0.7152034261241971,0.5892175278664209,0.636734693877551,0.5828220858895705,0.5512295081967213,0.8932663202285767,0.9491733908653259,0.9203716516494751,0.9432697296142578,0.7997218907563031,0.8277511961722488,0.7692307692307692,0.7101449275362318,0.8038277511961723,0.7011764815644347,0.7566909975669099,0.6926829268292682,0.6577017114914425,0.9239852428436279,0.9523167014122009,0.9379370212554932,0.9494056105613708,0.8181836363636367,0.6091215660781512,0.5212702372619614,0.7029480690199733,0.5932203389830508,0.6190476190476191,0.6479335470114398,0.549839220044083,0.8296270099710066,0.5932203389830508,0.6190476190476191,0.6879861854650776,0.6807179876258057,0.8319208623862401,0.6440677966101694,0.5952380952380952
557580,magrathealabs/feito,magrathealabs_feito/feito/github/api.py,feito.github.api.API,"class API:
    GITHUB_API_URL = 'https://api.github.com'

    # TODO: Add username and password authentication methods
    def __init__(self, user, repo, token=None, password=None):
        """"""
        param user: str -> Github username
        param token: str -> Github oauth token
        param repo: str -> Github repository name
        param password: str -> Github user password
        """"""
        self.user = user
        self.repo = repo
        self.token = token
        self.password = password

        if token:
            self.auth_header = {'authorization': f'token {token}'}

    def create_comment_commit(self, body, commit_id, path, position, pr_id):
        """"""
        Posts a comment to a given commit at a certain pull request.
        Check https://developer.github.com/v3/pulls/comments/#create-a-comment

        param body: str -> Comment text
        param commit_id: str -> SHA of the commit
        param path: str -> Relative path of the file to be commented
        param position: int -> The position in the diff to add a review comment
        param pr_id: int -> Github pull request id
        """"""
        comments_url = f""{self.GITHUB_API_URL}/repos/{self.user}/{self.repo}/pulls/{pr_id}/comments""
        data = {'body': body, 'commit_id': commit_id, 'path': path, 'position': position}

        return requests.post(comments_url, json=data, headers=self.auth_header)","class API:


    def __init__(self, user, repo, token=None, password=None):
    '''
        param user: str -> Github username
        param token: str -> Github oauth token
        param repo: str -> Github repository name
        param password: str -> Github user password
        '''
        pass

    def create_comment_commit(self, body, commit_id, path, position, pr_id):
    '''
        Posts a comment to a given commit at a certain pull request.
        Check https://developer.github.com/v3/pulls/comments/#create-a-comment

        param body: str -> Comment text
        param commit_id: str -> SHA of the commit
        param path: str -> Relative path of the file to be commented
        param position: int -> The position in the diff to add a review comment
        param pr_id: int -> Github pull request id
        '''
        pass

",3,2,snippet_47,1.0,"class API:
    def __init__(self, user, repo, token=None, password=None):
        '''
        param user: str -> Github username
        param token: str -> Github oauth token
        param repo: str -> Github repository name
        param password: str -> Github user password
        '''
        self.user = user
        self.repo = repo
        if token:
            self.auth = (user, token)
        elif password:
            self.auth = (user, password)
        else:
            raise ValueError(""Either token or password must be provided"")

    def create_comment_commit(self, body, commit_id, path, position, pr_id):
        '''
        Posts a comment to a given commit at a certain pull request.
        Check https://developer.github.com/v3/pulls/comments/#create-a-comment

        param body: str -> Comment text
        param commit_id: str -> SHA of the commit
        param path: str -> Relative path of the file to be commented
        param position: int -> The position in the diff to add a review comment
        param pr_id: int -> Github pull request id
        '''
        url = f""https://api.github.com/repos/{self.user}/{self.repo}/pulls/{pr_id}/comments""
        payload = {
            ""body"": body,
            ""commit_id"": commit_id,
            ""path"": path,
            ""position"": position
        }
        response = requests.post(url, json=payload, auth=self.auth)
        response.raise_for_status()
        return response.json()","class API:
    def __init__(self, user, repo, token=None, password=None):
        '''
        param user: str -> Github username
        param token: str -> Github oauth token
        param repo: str -> Github repository name
        param password: str -> Github user password
        '''
        self.user = user
        self.repo = repo
        self.token = token
        self.password = password
        
        if token:
            self.auth = (user, token)
        elif password:
            self.auth = (user, password)
        else:
            self.auth = None

    def create_comment_commit(self, body, commit_id, path, position, pr_id):
        '''
        Posts a comment to a given commit at a certain pull request.
        Check https://developer.github.com/v3/pulls/comments/#create-a-comment

        param body: str -> Comment text
        param commit_id: str -> SHA of the commit
        param path: str -> Relative path of the file to be commented
        param position: int -> The position in the diff to add a review comment
        param pr_id: int -> Github pull request id
        '''
        url = f""https://api.github.com/repos/{self.user}/{self.repo}/pulls/{pr_id}/comments""
        
        data = {
            ""body"": body,
            ""commit_id"": commit_id,
            ""path"": path,
            ""position"": position
        }
        
        headers = {
            ""Accept"": ""application/vnd.github.v3+json""
        }
        
        if self.auth:
            response = requests.post(url, json=data, auth=self.auth, headers=headers)
        else:
            response = requests.post(url, json=data, headers=headers)
        
        return response","class API:
    def __init__(self, user, repo, token=None, password=None):
        '''
        param user: str -> Github username
        param token: str -> Github oauth token
        param repo: str -> Github repository name
        param password: str -> Github user password
        '''
        self.user = user
        self.repo = repo
        self.token = token
        self.password = password
        self.base_url = f""https://api.github.com/repos/{user}/{repo}""
        
        if token:
            self.auth = ('token', token)
        elif password:
            self.auth = (user, password)
        else:
            self.auth = None

    def create_comment_commit(self, body, commit_id, path, position, pr_id):
        '''
        Posts a comment to a given commit at a certain pull request.
        Check https://developer.github.com/v3/pulls/comments/#create-a-comment

        param body: str -> Comment text
        param commit_id: str -> SHA of the commit
        param path: str -> Relative path of the file to be commented
        param position: int -> The position in the diff to add a review comment
        param pr_id: int -> Github pull request id
        '''
        url = f""{self.base_url}/pulls/{pr_id}/comments""
        
        data = {
            ""body"": body,
            ""commit_id"": commit_id,
            ""path"": path,
            ""position"": position
        }
        
        headers = {
            ""Accept"": ""application/vnd.github.v3+json"",
            ""Content-Type"": ""application/json""
        }
        
        if self.token:
            headers[""Authorization""] = f""token {self.token}""
            response = requests.post(url, headers=headers, data=json.dumps(data))
        elif self.password:
            response = requests.post(url, headers=headers, data=json.dumps(data), auth=(self.user, self.password))
        else:
            response = requests.post(url, headers=headers, data=json.dumps(data))
        
        return response",partial_docstr,0.8733153638814016,0.7804878048780488,0.7247956403269755,0.8301886792452831,0.7445848045178466,0.8652694610778443,0.7297297297297297,0.6716867469879518,0.9417576789855957,0.9417303800582886,0.9417440295219421,0.941733181476593,0.8924061392405063,0.8785529715762274,0.8051948051948052,0.7624020887728459,0.8320413436692506,0.723764966446848,0.8075880758807588,0.7119565217391305,0.659400544959128,0.926205575466156,0.931588351726532,0.9288891553878784,0.931047260761261,0.8554436224489795,0.8266033254156769,0.7255369928400955,0.6714628297362111,0.7505938242280286,0.5877721591527572,0.6770601336302895,0.5803571428571429,0.5167785234899329,0.8851078748703003,0.917290210723877,0.9009117484092712,0.9139670729637146,0.7958200000000002,0.6130839580888767,0.6655759178146591,0.680655263378057,0.6875,0.4186046511627907,0.6190932941969722,0.6504651264653384,0.7277975852062716,0.65625,0.4418604651162791,0.735542870335861,0.5836047985917974,0.7179416827516466,0.640625,0.0
14385,Azure/azure-cli-extensions,src/application-insights/azext_applicationinsights/vendored_sdks/mgmt_applicationinsights/v2015_05_01/_application_insights_management_client.py,azext_applicationinsights.vendored_sdks.mgmt_applicationinsights.v2015_05_01._application_insights_management_client.ApplicationInsightsManagementClient,"class ApplicationInsightsManagementClient(object):
    """"""Composite Swagger for Application Insights Management Client.

    :ivar operations: Operations operations
    :vartype operations: azure.mgmt.applicationinsights.v2015_05_01.operations.Operations
    :ivar annotations: AnnotationsOperations operations
    :vartype annotations: azure.mgmt.applicationinsights.v2015_05_01.operations.AnnotationsOperations
    :ivar api_keys: APIKeysOperations operations
    :vartype api_keys: azure.mgmt.applicationinsights.v2015_05_01.operations.APIKeysOperations
    :ivar export_configurations: ExportConfigurationsOperations operations
    :vartype export_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ExportConfigurationsOperations
    :ivar component_current_billing_features: ComponentCurrentBillingFeaturesOperations operations
    :vartype component_current_billing_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentCurrentBillingFeaturesOperations
    :ivar component_quota_status: ComponentQuotaStatusOperations operations
    :vartype component_quota_status: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentQuotaStatusOperations
    :ivar component_feature_capabilities: ComponentFeatureCapabilitiesOperations operations
    :vartype component_feature_capabilities: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentFeatureCapabilitiesOperations
    :ivar component_available_features: ComponentAvailableFeaturesOperations operations
    :vartype component_available_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentAvailableFeaturesOperations
    :ivar proactive_detection_configurations: ProactiveDetectionConfigurationsOperations operations
    :vartype proactive_detection_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ProactiveDetectionConfigurationsOperations
    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentsOperations
    :ivar work_item_configurations: WorkItemConfigurationsOperations operations
    :vartype work_item_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkItemConfigurationsOperations
    :ivar favorites: FavoritesOperations operations
    :vartype favorites: azure.mgmt.applicationinsights.v2015_05_01.operations.FavoritesOperations
    :ivar web_test_locations: WebTestLocationsOperations operations
    :vartype web_test_locations: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestLocationsOperations
    :ivar web_tests: WebTestsOperations operations
    :vartype web_tests: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestsOperations
    :ivar analytics_items: AnalyticsItemsOperations operations
    :vartype analytics_items: azure.mgmt.applicationinsights.v2015_05_01.operations.AnalyticsItemsOperations
    :ivar workbooks: WorkbooksOperations operations
    :vartype workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkbooksOperations
    :ivar my_workbooks: MyWorkbooksOperations operations
    :vartype my_workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.MyWorkbooksOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    """"""

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        if not base_url:
            base_url = 'https://management.azure.com'
        self._config = ApplicationInsightsManagementClientConfiguration(credential, subscription_id, **kwargs)
        self._client = ARMPipelineClient(base_url=base_url, config=self._config, **kwargs)

        client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
        self._serialize = Serializer(client_models)
        self._deserialize = Deserializer(client_models)

        self.operations = Operations(
            self._client, self._config, self._serialize, self._deserialize)
        self.annotations = AnnotationsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.api_keys = APIKeysOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.export_configurations = ExportConfigurationsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.component_current_billing_features = ComponentCurrentBillingFeaturesOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.component_quota_status = ComponentQuotaStatusOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.component_feature_capabilities = ComponentFeatureCapabilitiesOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.component_available_features = ComponentAvailableFeaturesOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.proactive_detection_configurations = ProactiveDetectionConfigurationsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.components = ComponentsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.work_item_configurations = WorkItemConfigurationsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.favorites = FavoritesOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.web_test_locations = WebTestLocationsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.web_tests = WebTestsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.analytics_items = AnalyticsItemsOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.workbooks = WorkbooksOperations(
            self._client, self._config, self._serialize, self._deserialize)
        self.my_workbooks = MyWorkbooksOperations(
            self._client, self._config, self._serialize, self._deserialize)

    def close(self):
        # type: () -> None
        self._client.close()

    def __enter__(self):
        # type: () -> ApplicationInsightsManagementClient
        self._client.__enter__()
        return self

    def __exit__(self, *exc_details):
        # type: (Any) -> None
        self._client.__exit__(*exc_details)","class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar operations: Operations operations
    :vartype operations: azure.mgmt.applicationinsights.v2015_05_01.operations.Operations
    :ivar annotations: AnnotationsOperations operations
    :vartype annotations: azure.mgmt.applicationinsights.v2015_05_01.operations.AnnotationsOperations
    :ivar api_keys: APIKeysOperations operations
    :vartype api_keys: azure.mgmt.applicationinsights.v2015_05_01.operations.APIKeysOperations
    :ivar export_configurations: ExportConfigurationsOperations operations
    :vartype export_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ExportConfigurationsOperations
    :ivar component_current_billing_features: ComponentCurrentBillingFeaturesOperations operations
    :vartype component_current_billing_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentCurrentBillingFeaturesOperations
    :ivar component_quota_status: ComponentQuotaStatusOperations operations
    :vartype component_quota_status: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentQuotaStatusOperations
    :ivar component_feature_capabilities: ComponentFeatureCapabilitiesOperations operations
    :vartype component_feature_capabilities: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentFeatureCapabilitiesOperations
    :ivar component_available_features: ComponentAvailableFeaturesOperations operations
    :vartype component_available_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentAvailableFeaturesOperations
    :ivar proactive_detection_configurations: ProactiveDetectionConfigurationsOperations operations
    :vartype proactive_detection_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ProactiveDetectionConfigurationsOperations
    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentsOperations
    :ivar work_item_configurations: WorkItemConfigurationsOperations operations
    :vartype work_item_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkItemConfigurationsOperations
    :ivar favorites: FavoritesOperations operations
    :vartype favorites: azure.mgmt.applicationinsights.v2015_05_01.operations.FavoritesOperations
    :ivar web_test_locations: WebTestLocationsOperations operations
    :vartype web_test_locations: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestLocationsOperations
    :ivar web_tests: WebTestsOperations operations
    :vartype web_tests: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestsOperations
    :ivar analytics_items: AnalyticsItemsOperations operations
    :vartype analytics_items: azure.mgmt.applicationinsights.v2015_05_01.operations.AnalyticsItemsOperations
    :ivar workbooks: WorkbooksOperations operations
    :vartype workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkbooksOperations
    :ivar my_workbooks: MyWorkbooksOperations operations
    :vartype my_workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.MyWorkbooksOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        pass

    def close(self):
        pass

    def __enter__(self):
        pass

    def __exit__(self, *exc_details):
        pass

",5,1,snippet_791,0.3636363636363636,"class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar operations: Operations operations
    :vartype operations: azure.mgmt.applicationinsights.v2015_05_01.operations.Operations
    :ivar annotations: AnnotationsOperations operations
    :vartype annotations: azure.mgmt.applicationinsights.v2015_05_01.operations.AnnotationsOperations
    :ivar api_keys: APIKeysOperations operations
    :vartype api_keys: azure.mgmt.applicationinsights.v2015_05_01.operations.APIKeysOperations
    :ivar export_configurations: ExportConfigurationsOperations operations
    :vartype export_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ExportConfigurationsOperations
    :ivar component_current_billing_features: ComponentCurrentBillingFeaturesOperations operations
    :vartype component_current_billing_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentCurrentBillingFeaturesOperations
    :ivar component_quota_status: ComponentQuotaStatusOperations operations
    :vartype component_quota_status: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentQuotaStatusOperations
    :ivar component_feature_capabilities: ComponentFeatureCapabilitiesOperations operations
    :vartype component_feature_capabilities: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentFeatureCapabilitiesOperations
    :ivar component_available_features: ComponentAvailableFeaturesOperations operations
    :vartype component_available_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentAvailableFeaturesOperations
    :ivar proactive_detection_configurations: ProactiveDetectionConfigurationsOperations operations
    :vartype proactive_detection_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ProactiveDetectionConfigurationsOperations
    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentsOperations
    :ivar work_item_configurations: WorkItemConfigurationsOperations operations
    :vartype work_item_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkItemConfigurationsOperations
    :ivar favorites: FavoritesOperations operations
    :vartype favorites: azure.mgmt.applicationinsights.v2015_05_01.operations.FavoritesOperations
    :ivar web_test_locations: WebTestLocationsOperations operations
    :vartype web_test_locations: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestLocationsOperations
    :ivar web_tests: WebTestsOperations operations
    :vartype web_tests: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestsOperations
    :ivar analytics_items: AnalyticsItemsOperations operations
    :vartype analytics_items: azure.mgmt.applicationinsights.v2015_05_01.operations.AnalyticsItemsOperations
    :ivar workbooks: WorkbooksOperations operations
    :vartype workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkbooksOperations
    :ivar my_workbooks: MyWorkbooksOperations operations
    :vartype my_workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.MyWorkbooksOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        self.config = ApplicationInsightsManagementClientConfiguration(
            credential, subscription_id
        )
        if base_url is not None:
            self.config.base_url = base_url
        for key, value in kwargs.items():
            setattr(self.config, key, value)
        self._client = ServiceClient(credential, self.config)

        self.operations = Operations(self._client, self.config)
        self.annotations = AnnotationsOperations(self._client, self.config)
        self.api_keys = APIKeysOperations(self._client, self.config)
        self.export_configurations = ExportConfigurationsOperations(
            self._client, self.config
        )
        self.component_current_billing_features = (
            ComponentCurrentBillingFeaturesOperations(self._client, self.config)
        )
        self.component_quota_status = ComponentQuotaStatusOperations(
            self._client, self.config
        )
        self.component_feature_capabilities = (
            ComponentFeatureCapabilitiesOperations(self._client, self.config)
        )
        self.component_available_features = (
            ComponentAvailableFeaturesOperations(self._client, self.config)
        )
        self.proactive_detection_configurations = (
            ProactiveDetectionConfigurationsOperations(self._client, self.config)
        )
        self.components = ComponentsOperations(self._client, self.config)
        self.work_item_configurations = WorkItemConfigurationsOperations(
            self._client, self.config
        )
        self.favorites = FavoritesOperations(self._client, self.config)
        self.web_test_locations = WebTestLocationsOperations(
            self._client, self.config
        )
        self.web_tests = WebTestsOperations(self._client, self.config)
        self.analytics_items = AnalyticsItemsOperations(self._client, self.config)
        self.workbooks = WorkbooksOperations(self._client, self.config)
        self.my_workbooks = MyWorkbooksOperations(self._client, self.config)

    def close(self):
        self._client.close()

    def __enter__(self):
        return self

    def __exit__(self, *exc_details):
        self.close()","class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar operations: Operations operations
    :vartype operations: azure.mgmt.applicationinsights.v2015_05_01.operations.Operations
    :ivar annotations: AnnotationsOperations operations
    :vartype annotations: azure.mgmt.applicationinsights.v2015_05_01.operations.AnnotationsOperations
    :ivar api_keys: APIKeysOperations operations
    :vartype api_keys: azure.mgmt.applicationinsights.v2015_05_01.operations.APIKeysOperations
    :ivar export_configurations: ExportConfigurationsOperations operations
    :vartype export_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ExportConfigurationsOperations
    :ivar component_current_billing_features: ComponentCurrentBillingFeaturesOperations operations
    :vartype component_current_billing_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentCurrentBillingFeaturesOperations
    :ivar component_quota_status: ComponentQuotaStatusOperations operations
    :vartype component_quota_status: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentQuotaStatusOperations
    :ivar component_feature_capabilities: ComponentFeatureCapabilitiesOperations operations
    :vartype component_feature_capabilities: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentFeatureCapabilitiesOperations
    :ivar component_available_features: ComponentAvailableFeaturesOperations operations
    :vartype component_available_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentAvailableFeaturesOperations
    :ivar proactive_detection_configurations: ProactiveDetectionConfigurationsOperations operations
    :vartype proactive_detection_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ProactiveDetectionConfigurationsOperations
    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentsOperations
    :ivar work_item_configurations: WorkItemConfigurationsOperations operations
    :vartype work_item_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkItemConfigurationsOperations
    :ivar favorites: FavoritesOperations operations
    :vartype favorites: azure.mgmt.applicationinsights.v2015_05_01.operations.FavoritesOperations
    :ivar web_test_locations: WebTestLocationsOperations operations
    :vartype web_test_locations: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestLocationsOperations
    :ivar web_tests: WebTestsOperations operations
    :vartype web_tests: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestsOperations
    :ivar analytics_items: AnalyticsItemsOperations operations
    :vartype analytics_items: azure.mgmt.applicationinsights.v2015_05_01.operations.AnalyticsItemsOperations
    :ivar workbooks: WorkbooksOperations operations
    :vartype workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkbooksOperations
    :ivar my_workbooks: MyWorkbooksOperations operations
    :vartype my_workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.MyWorkbooksOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        self._credential = credential
        self._subscription_id = subscription_id
        self._base_url = base_url
        
        if base_url is None:
            self._base_url = ""https://management.azure.com""
        
        # Initialize all operation clients
        from azure.mgmt.applicationinsights.v2015_05_01.operations import Operations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import AnnotationsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import APIKeysOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import ExportConfigurationsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import ComponentCurrentBillingFeaturesOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import ComponentQuotaStatusOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import ComponentFeatureCapabilitiesOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import ComponentAvailableFeaturesOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import ProactiveDetectionConfigurationsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import ComponentsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import WorkItemConfigurationsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import FavoritesOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import WebTestLocationsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import WebTestsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import AnalyticsItemsOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import WorkbooksOperations
        from azure.mgmt.applicationinsights.v2015_05_01.operations import MyWorkbooksOperations
        
        self.operations = Operations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.annotations = AnnotationsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.api_keys = APIKeysOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.export_configurations = ExportConfigurationsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.component_current_billing_features = ComponentCurrentBillingFeaturesOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.component_quota_status = ComponentQuotaStatusOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.component_feature_capabilities = ComponentFeatureCapabilitiesOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.component_available_features = ComponentAvailableFeaturesOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.proactive_detection_configurations = ProactiveDetectionConfigurationsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.components = ComponentsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.work_item_configurations = WorkItemConfigurationsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.favorites = FavoritesOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.web_test_locations = WebTestLocationsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.web_tests = WebTestsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.analytics_items = AnalyticsItemsOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.workbooks = WorkbooksOperations(self._credential, self._subscription_id, self._base_url, **kwargs)
        self.my_workbooks = MyWorkbooksOperations(self._credential, self._subscription_id, self._base_url, **kwargs)

    def close(self):
        # type: () -> None
        # Close all operation clients
        self.operations.close()
        self.annotations.close()
        self.api_keys.close()
        self.export_configurations.close()
        self.component_current_billing_features.close()
        self.component_quota_status.close()
        self.component_feature_capabilities.close()
        self.component_available_features.close()
        self.proactive_detection_configurations.close()
        self.components.close()
        self.work_item_configurations.close()
        self.favorites.close()
        self.web_test_locations.close()
        self.web_tests.close()
        self.analytics_items.close()
        self.workbooks.close()
        self.my_workbooks.close()

    def __enter__(self):
        # type: () -> ApplicationInsightsManagementClient
        return self

    def __exit__(self, *exc_details):
        # type: (*Any) -> None
        self.close()","class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar operations: Operations operations
    :vartype operations: azure.mgmt.applicationinsights.v2015_05_01.operations.Operations
    :ivar annotations: AnnotationsOperations operations
    :vartype annotations: azure.mgmt.applicationinsights.v2015_05_01.operations.AnnotationsOperations
    :ivar api_keys: APIKeysOperations operations
    :vartype api_keys: azure.mgmt.applicationinsights.v2015_05_01.operations.APIKeysOperations
    :ivar export_configurations: ExportConfigurationsOperations operations
    :vartype export_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ExportConfigurationsOperations
    :ivar component_current_billing_features: ComponentCurrentBillingFeaturesOperations operations
    :vartype component_current_billing_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentCurrentBillingFeaturesOperations
    :ivar component_quota_status: ComponentQuotaStatusOperations operations
    :vartype component_quota_status: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentQuotaStatusOperations
    :ivar component_feature_capabilities: ComponentFeatureCapabilitiesOperations operations
    :vartype component_feature_capabilities: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentFeatureCapabilitiesOperations
    :ivar component_available_features: ComponentAvailableFeaturesOperations operations
    :vartype component_available_features: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentAvailableFeaturesOperations
    :ivar proactive_detection_configurations: ProactiveDetectionConfigurationsOperations operations
    :vartype proactive_detection_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.ProactiveDetectionConfigurationsOperations
    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2015_05_01.operations.ComponentsOperations
    :ivar work_item_configurations: WorkItemConfigurationsOperations operations
    :vartype work_item_configurations: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkItemConfigurationsOperations
    :ivar favorites: FavoritesOperations operations
    :vartype favorites: azure.mgmt.applicationinsights.v2015_05_01.operations.FavoritesOperations
    :ivar web_test_locations: WebTestLocationsOperations operations
    :vartype web_test_locations: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestLocationsOperations
    :ivar web_tests: WebTestsOperations operations
    :vartype web_tests: azure.mgmt.applicationinsights.v2015_05_01.operations.WebTestsOperations
    :ivar analytics_items: AnalyticsItemsOperations operations
    :vartype analytics_items: azure.mgmt.applicationinsights.v2015_05_01.operations.AnalyticsItemsOperations
    :ivar workbooks: WorkbooksOperations operations
    :vartype workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.WorkbooksOperations
    :ivar my_workbooks: MyWorkbooksOperations operations
    :vartype my_workbooks: azure.mgmt.applicationinsights.v2015_05_01.operations.MyWorkbooksOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        if not base_url:
            base_url = 'https://management.azure.com'
        
        self._config = ApplicationInsightsManagementClientConfiguration(credential, subscription_id, **kwargs)
        self._client = ARMPipelineClient(base_url=base_url, config=self._config, **kwargs)
        
        client_models = {k: v for k, v in kwargs.items() if k.endswith('_models')}
        self._serialize = kwargs.get('serializer')
        self._deserialize = kwargs.get('deserializer')
        
        self.operations = Operations(self._client, self._config, self._serialize, self._deserialize)
        self.annotations = AnnotationsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.api_keys = APIKeysOperations(self._client, self._config, self._serialize, self._deserialize)
        self.export_configurations = ExportConfigurationsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.component_current_billing_features = ComponentCurrentBillingFeaturesOperations(self._client, self._config, self._serialize, self._deserialize)
        self.component_quota_status = ComponentQuotaStatusOperations(self._client, self._config, self._serialize, self._deserialize)
        self.component_feature_capabilities = ComponentFeatureCapabilitiesOperations(self._client, self._config, self._serialize, self._deserialize)
        self.component_available_features = ComponentAvailableFeaturesOperations(self._client, self._config, self._serialize, self._deserialize)
        self.proactive_detection_configurations = ProactiveDetectionConfigurationsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.components = ComponentsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.work_item_configurations = WorkItemConfigurationsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.favorites = FavoritesOperations(self._client, self._config, self._serialize, self._deserialize)
        self.web_test_locations = WebTestLocationsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.web_tests = WebTestsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.analytics_items = AnalyticsItemsOperations(self._client, self._config, self._serialize, self._deserialize)
        self.workbooks = WorkbooksOperations(self._client, self._config, self._serialize, self._deserialize)
        self.my_workbooks = MyWorkbooksOperations(self._client, self._config, self._serialize, self._deserialize)

    def close(self):
        self._client.close()

    def __enter__(self):
        self._client.__enter__()
        return self

    def __exit__(self, *exc_details):
        self._client.__exit__(*exc_details)",partial_docstr,0.89666951323655,0.8656971770744225,0.8209083119108825,0.8812980358667806,0.6965543764986155,0.9884281581485053,0.9140926640926641,0.8763285024154589,0.9765322208404541,0.9380554556846619,0.9569071531295776,0.9417662024497986,0.8824327054108219,0.704863424383744,0.5950633755837226,0.5611222444889779,0.6675549633577615,0.618217738182532,0.6987811955890888,0.6074332171893148,0.5566531086577571,0.9493796229362488,0.940689206123352,0.945014476776123,0.941551148891449,0.8437812393162398,0.9809825673534072,0.9650793650793651,0.9507154213036566,0.9793977812995246,0.9447546549661853,0.9898911353032659,0.9766536964980544,0.9688473520249221,0.9828753471374512,0.9825873374938965,0.9827313423156738,0.9826160669326782,0.9842210650887574,0.4525355607480603,0.5394091779851939,0.5527959309867873,0.5236051502145923,0.194331983805668,0.6469570310022583,0.4956281514378179,0.5771785133437475,0.5150214592274678,0.0,0.7395995455686346,0.7184800690058283,0.7220296317479719,0.9227467811158798,0.5951417004048583
582908,molmod/molmod,molmod_molmod/molmod/isotopes.py,molmod.isotopes.Ame2003,"class Ame2003(object):
    """"""An interface to a subset of the data from Ame2003.

       This object contains an attribute masses. This is a dictionary whose keys
       are the proton numbers (Z) and values are the corresponding values are
       again dictionaries. The latter dictionaries have the mass number (A) as
       keys and the corresponding isotope masses in atomic units as values. E.g.
       self.masses[6][12] is the mass of carbon 12.

       If you use this interface, cite the following references:

       The AME2003 atomic mass evaluation (I). Evaluation of input data, adjustment
       procedures. A.H. Wapstra, G. Audi, and C. Thibault. Nuclear Physics A729,
       129 (2003).

       The AME2003 atomic mass evaluation (II). Tables, graphs, and references. G.
       Audi, A.H. Wapstra, and C. Thibault. Nuclear Physics A729, 337 (2003).
    """"""
    def __init__(self):
        """"""
           An object of this type is created in this module, so there is not
           need to construct it manually.
        """"""
        self.masses = {}

        def add_mass(N, Z, mass):
            """"""Put a new mass into the dictionary""""""
            n_masses = self.masses.setdefault(Z, {})
            n_masses[Z+N] = mass

        with pkg_resources.resource_stream(__name__, 'data/mass.mas03') as f:
            for i in range(39):
                next(f)
            for line in f:
                N = int(line[ 5:10])
                Z = int(line[10:15])
                mass = float(line[96:114].replace(b"" "", b"""").replace(b""#"", b""""))*1e-6*amu
                add_mass(N, Z, mass)","class Ame2003(object):
    '''An interface to a subset of the data from Ame2003.

       This object contains an attribute masses. This is a dictionary whose keys
       are the proton numbers (Z) and values are the corresponding values are
       again dictionaries. The latter dictionaries have the mass number (A) as
       keys and the corresponding isotope masses in atomic units as values. E.g.
       self.masses[6][12] is the mass of carbon 12.

       If you use this interface, cite the following references:

       The AME2003 atomic mass evaluation (I). Evaluation of input data, adjustment
       procedures. A.H. Wapstra, G. Audi, and C. Thibault. Nuclear Physics A729,
       129 (2003).

       The AME2003 atomic mass evaluation (II). Tables, graphs, and references. G.
       Audi, A.H. Wapstra, and C. Thibault. Nuclear Physics A729, 337 (2003).
    '''

    def __init__(self):
    '''
           An object of this type is created in this module, so there is not
           need to construct it manually.
        '''
        pass

        def add_mass(N, Z, mass):
    '''Put a new mass into the dictionary'''
                pass

",3,3,snippet_647,0.2222222222222222,"class Ame2003(object):
    '''An interface to a subset of the data from Ame2003.

       This object contains an attribute masses. This is a dictionary whose keys
       are the proton numbers (Z) and values are the corresponding values are
       again dictionaries. The latter dictionaries have the mass number (A) as
       keys and the corresponding isotope masses in atomic units as values. E.g.
       self.masses[6][12] is the mass of carbon 12.

       If you use this interface, cite the following references:

       The AME2003 atomic mass evaluation (I). Evaluation of input data, adjustment
       procedures. A.H. Wapstra, G. Audi, and C. Thibault. Nuclear Physics A729,
       129 (2003).

       The AME2003 atomic mass evaluation (II). Tables, graphs, and references. G.
       Audi, A.H. Wapstra, and C. Thibault. Nuclear Physics A729, 337 (2003).
    '''
    def __init__(self):
        '''
           An object of this type is created in this module, so there is not
           need to construct it manually.
        '''
        self.masses = {}

    def add_mass(self, N, Z, mass):
        '''Put a new mass into the dictionary'''
        A = N + Z
        if Z not in self.masses:
            self.masses[Z] = {}
        self.masses[Z][A] = mass","class Ame2003(object):
    '''An interface to a subset of the data from Ame2003.

       This object contains an attribute masses. This is a dictionary whose keys
       are the proton numbers (Z) and values are the corresponding values are
       again dictionaries. The latter dictionaries have the mass number (A) as
       keys and the corresponding isotope masses in atomic units as values. E.g.
       self.masses[6][12] is the mass of carbon 12.

       If you use this interface, cite the following references:

       The AME2003 atomic mass evaluation (I). Evaluation of input data, adjustment
       procedures. A.H. Wapstra, G. Audi, and C. Thibault. Nuclear Physics A729,
       129 (2003).

       The AME2003 atomic mass evaluation (II). Tables, graphs, and references. G.
       Audi, A.H. Wapstra, and C. Thibault. Nuclear Physics A729, 337 (2003).
    '''

    def __init__(self):
        '''
           An object of this type is created in this module, so there is not
           need to construct it manually.
        '''
        self.masses = {}

    def add_mass(self, N, Z, mass):
        '''Put a new mass into the dictionary'''
        A = N + Z
        if Z not in self.masses:
            self.masses[Z] = {}
        self.masses[Z][A] = mass","class Ame2003(object):
    '''An interface to a subset of the data from Ame2003.

       This object contains an attribute masses. This is a dictionary whose keys
       are the proton numbers (Z) and values are the corresponding values are
       again dictionaries. The latter dictionaries have the mass number (A) as
       keys and the corresponding isotope masses in atomic units as values. E.g.
       self.masses[6][12] is the mass of carbon 12.

       If you use this interface, cite the following references:

       The AME2003 atomic mass evaluation (I). Evaluation of input data, adjustment
       procedures. A.H. Wapstra, G. Audi, and C. Thibault. Nuclear Physics A729,
       129 (2003).

       The AME2003 atomic mass evaluation (II). Tables, graphs, and references. G.
       Audi, A.H. Wapstra, and C. Thibault. Nuclear Physics A729, 337 (2003).
    '''

    def __init__(self):
        '''
           An object of this type is created in this module, so there is not
           need to construct it manually.
        '''
        self.masses = {}

    def add_mass(self, N, Z, mass):
        '''Put a new mass into the dictionary'''
        A = N + Z
        if Z not in self.masses:
            self.masses[Z] = {}
        self.masses[Z][A] = mass",partial_docstr,0.8585365853658538,0.8186274509803921,0.7980295566502463,0.8439024390243903,0.5738469391217733,0.9530685920577617,0.855072463768116,0.8181818181818182,0.9784824848175049,0.8933513164520264,0.9339810609817505,0.9011918902397156,0.7679348101265824,0.8585365853658538,0.8186274509803921,0.7980295566502463,0.8439024390243903,0.5738469391217733,0.9530685920577617,0.855072463768116,0.8181818181818182,0.9784560203552246,0.8934314250946045,0.9340127110481262,0.9012630581855774,0.7679348101265824,0.8585365853658538,0.8186274509803921,0.7980295566502463,0.8439024390243903,0.5738469391217733,0.9530685920577617,0.855072463768116,0.8181818181818182,0.9784560203552246,0.8934314250946045,0.9340127110481262,0.9012630581855774,0.7679348101265824,0.4658099042675778,0.736283899181281,0.7392006158482138,0.1428571428571428,0.2448979591836734,0.4658099042675778,0.736283899181281,0.7392006158482138,0.1428571428571428,0.2448979591836734,0.4658099042675778,0.736283899181281,0.7392006158482138,0.1428571428571428,0.2448979591836734
842212,zsimic/runez,zsimic_runez/src/runez/colors/__init__.py,runez.colors.Renderable,"class Renderable:
    """"""A render-able (color or style) named object""""""

    def __init__(self, name):
        self.name = name

    def __repr__(self):
        return self.name

    def __call__(self, text, size=None):
        """"""
        Allows for convenient call of the form:

        >>> import runez
        >>> runez.blue(""foo"")
        'foo'
        """"""
        text = short(text, size=size) if size else stringified(text)
        return self.rendered(text) if text else """"

    def rendered(self, text):
        return text","class Renderable:
    '''A render-able (color or style) named object'''

    def __init__(self, name):
        pass

    def __repr__(self):
        pass

    def __call__(self, text, size=None):
    '''
        Allows for convenient call of the form:

        >>> import runez
        >>> runez.blue(""foo"")
        'foo'
        '''
        pass

    def rendered(self, text):
        pass

",5,2,snippet_489,0.7777777777777778,"class Renderable:
    '''A render-able (color or style) named object'''

    _BASE_COLOR_CODES = {
        ""black"": 30, ""red"": 31, ""green"": 32, ""yellow"": 33,
        ""blue"": 34, ""magenta"": 35, ""cyan"": 36, ""white"": 37
    }
    _STYLE_CODES = {
        ""bold"": 1, ""underline"": 4, ""reversed"": 7
    }

    def __init__(self, name):
        self.name = name
        parts = name.split(""_"")
        codes = []
        bright = ""bright"" in parts
        bg = ""bg"" in parts
        for p in parts:
            if p in self._STYLE_CODES:
                codes.append(self._STYLE_CODES[p])
            elif p in self._BASE_COLOR_CODES:
                base = self._BASE_COLOR_CODES[p]
                offset = (10 if bg else 0) + (60 if bright else 0)
                codes.append(base + offset)
        if codes:
            self._prefix = ""\033["" + "";"".join(str(c) for c in codes) + ""m""
            self._suffix = ""\033[0m""
        else:
            self._prefix = """"
            self._suffix = """"

    def __repr__(self):
        return f""<Renderable {self.name}>""

    def __call__(self, text, size=None):
        s = str(text)
        if size is not None:
            n = int(size)
            width = abs(n)
            if len(s) > width:
                s = s[:width]
            elif len(s) < width:
                if n > 0:
                    s = s.ljust(width)
                else:
                    s = s.rjust(width)
        return self.rendered(s)

    def rendered(self, text):
        return f""{self._prefix}{text}{self._suffix}""","class Renderable:
    '''A render-able (color or style) named object'''

    def __init__(self, name):
        self.name = name

    def __repr__(self):
        return f""Renderable({self.name!r})""

    def __call__(self, text, size=None):
        '''
        Allows for convenient call of the form:

        >>> import runez
        >>> runez.blue(""foo"")
        'foo'
        '''
        return self.rendered(text)

    def rendered(self, text):
        return str(text)","class Renderable:
    '''A render-able (color or style) named object'''

    def __init__(self, name):
        self.name = name

    def __repr__(self):
        return self.name

    def __call__(self, text, size=None):
        '''
        Allows for convenient call of the form:

        >>> import runez
        >>> runez.blue(""foo"")
        'foo'
        '''
        return self.rendered(text)

    def rendered(self, text):
        return str(text)",partial_docstr,0.3715415019762846,0.26294820717131473,0.2008032128514056,0.33992094861660077,0.1947503138112664,0.26968973747016706,0.18421052631578946,0.1486810551558753,0.6664929389953613,0.7919598817825317,0.7238296270370483,0.777326762676239,0.7207474734042555,0.859504132231405,0.7731092436974789,0.7008547008547008,0.859504132231405,0.6924193725383464,0.905982905982906,0.8103448275862069,0.7391304347826086,0.9642901420593262,0.9426277875900269,0.9533358812332153,0.9447500109672546,0.870834625,0.8813559322033898,0.8275862068965517,0.7894736842105262,0.8813559322033898,0.6804968003696165,0.9532710280373832,0.8962264150943396,0.8380952380952381,0.9823355078697205,0.946196436882019,0.9639273881912231,0.9496902227401733,0.9000009999999999,0.4512242692872052,0.0921618871779108,0.2960685233042435,0.4166666666666667,0.0,0.5015377560740475,0.4950380160580493,0.5111130082381405,0.4444444444444444,0.5555555555555556,0.5655996586371312,0.5445897330104366,0.5604014941306809,0.5277777777777778,0.6296296296296297
312140,coghost/izen,coghost_izen/izen/amq.py,izen.amq.Topic,"class Topic(object):
    """"""
         ``topic`` 

    .. code:: python

        # 
        conf = {
            ""hostname"": ""127.0.0.1"",
            ""port"": 1883,
            ""username"": """",
            ""password"": """"
        }

    """"""

    def __init__(self, conf=None):
        conf = conf if conf else {}
        self.conf = {
            'hostname': conf.get('hostname', 'localhost'),
            'port': conf.get('port', 1883),
            'auth': {
                'username': conf.get('username', 'admin'),
                'password': conf.get('password', 'admin'),
            }
        }

    def run(self, handler=None):
        pass","class Topic(object):
    '''
         ``topic`` 

    .. code:: python

        # 
        conf = {
            ""hostname"": ""127.0.0.1"",
            ""port"": 1883,
            ""username"": """",
            ""password"": """"
        }

    '''

    def __init__(self, conf=None):
        pass

    def run(self, handler=None):
        pass

",3,1,snippet_364,1.0,"class Topic(object):
    '''
         ``topic`` 

    .. code:: python

        # 
        conf = {
            ""hostname"": ""127.0.0.1"",
            ""port"": 1883,
            ""username"": """",
            ""password"": """"
        }

    '''
    def __init__(self, conf=None):
        if not isinstance(conf, dict):
            raise ValueError(""conf must be a dict"")
        for key in (""hostname"", ""port"", ""username"", ""password""):
            if key not in conf:
                raise KeyError(f""missing required conf field: {key}"")
        self._conf = conf
        self._handler = None
        self._client = mqtt.Client()
        user = conf.get(""username"") or None
        pwd = conf.get(""password"") or None
        if user is not None:
            self._client.username_pw_set(user, pwd)
        self._client.on_connect = self._on_connect
        self._client.on_message = self._on_message

    def _on_connect(self, client, userdata, flags, rc):
        # 
        client.subscribe(""#"")

    def _on_message(self, client, userdata, msg):
        if self._handler:
            try:
                self._handler(msg.topic, msg.payload)
            except Exception:
                pass

    def run(self, handler=None):
        '''
        handler  func(topic, payload)
        '''
        self._handler = handler
        self._client.connect(self._conf[""hostname""], self._conf[""port""])
        self._client.loop_forever()","class Topic(object):
    '''
         ``topic`` 

    .. code:: python

        # 
        conf = {
            ""hostname"": ""127.0.0.1"",
            ""port"": 1883,
            ""username"": """",
            ""password"": """"
        }

    '''

    def __init__(self, conf=None):
        self.conf = conf or {}
        self.client = mqtt.Client()
        
        # 
        if self.conf.get(""username"") and self.conf.get(""password""):
            self.client.username_pw_set(self.conf[""username""], self.conf[""password""])
        
        # 
        self.client.on_connect = self._on_connect
        self.client.on_message = self._on_message
        
        self.handler = None

    def _on_connect(self, client, userdata, flags, rc):
        if rc == 0:
            print(""Connected to MQTT broker"")
            # topic
            client.subscribe(""#"")
        else:
            print(f""Failed to connect, return code {rc}"")

    def _on_message(self, client, userdata, msg):
        if self.handler:
            try:
                payload = msg.payload.decode('utf-8')
                # JSON
                try:
                    payload = json.loads(payload)
                except:
                    pass
                self.handler(msg.topic, payload)
            except Exception as e:
                print(f""Error in message handler: {e}"")

    def run(self, handler=None):
        self.handler = handler
        try:
            self.client.connect(
                self.conf.get(""hostname"", ""127.0.0.1""),
                self.conf.get(""port"", 1883),
                60
            )
            self.client.loop_forever()
        except KeyboardInterrupt:
            print(""Interrupted"")
            self.client.disconnect()
        except Exception as e:
            print(f""Error: {e}"")
            self.client.disconnect()","class Topic(object):
    '''
         ``topic`` 

    .. code:: python

        # 
        conf = {
            ""hostname"": ""127.0.0.1"",
            ""port"": 1883,
            ""username"": """",
            ""password"": """"
        }

    '''

    def __init__(self, conf=None):
        self.conf = conf or {}
        self.hostname = self.conf.get(""hostname"", ""127.0.0.1"")
        self.port = self.conf.get(""port"", 1883)
        self.username = self.conf.get(""username"", """")
        self.password = self.conf.get(""password"", """")
        self.client = mqtt.Client()
        
        if self.username:
            self.client.username_pw_set(self.username, self.password)
        
        self.handler = None

    def run(self, handler=None):
        self.handler = handler
        
        def on_connect(client, userdata, flags, rc):
            if rc == 0:
                client.subscribe(""#"")
        
        def on_message(client, userdata, msg):
            if self.handler:
                try:
                    payload = msg.payload.decode('utf-8')
                    self.handler(msg.topic, payload)
                except Exception as e:
                    pass
        
        self.client.on_connect = on_connect
        self.client.on_message = on_message
        
        self.client.connect(self.hostname, self.port, 60)
        self.client.loop_forever()",partial_docstr,0.4454976303317535,0.2966507177033493,0.24154589371980678,0.3696682464454976,0.2592228711862459,0.35195530726256985,0.23809523809523808,0.20786516853932585,0.7542367577552795,0.9473090171813965,0.8398191332817078,0.9236646890640259,0.7431932295719855,0.41004184100418417,0.29535864978902954,0.22978723404255316,0.3263598326359832,0.2526276860154484,0.32682926829268294,0.2396088019559902,0.20588235294117646,0.7585972547531128,0.9502741098403931,0.8436858654022217,0.9268550276756287,0.7459864759036151,0.48484848484848486,0.35714285714285715,0.2783505154639175,0.4747474747474747,0.317710852028722,0.40063091482649843,0.3037974683544304,0.2634920634920635,0.8407045006752014,0.9588192701339722,0.8958855271339417,0.9455350041389465,0.7519404651162792,0.3772137537502292,0.1892807557395451,0.4296311852575767,0.4705882352941176,0.4193548387096774,0.4173968986132125,0.1792620154467155,0.4378271602838071,0.5686274509803921,0.4838709677419355,0.4474802175089478,0.237046974314451,0.4358593479667545,0.5686274509803921,0.5483870967741935
532777,klahnakoski/mo-logs,mo_logs/log_usingNothing.py,mo_logs.log_usingNothing.StructuredLogger,"class StructuredLogger:
    """"""
    ABSTRACT BASE CLASS FOR JSON LOGGING
    """"""

    def write(self, template, params):
        pass

    def stop(self):
        pass","class StructuredLogger:
    '''
    ABSTRACT BASE CLASS FOR JSON LOGGING
    '''

    def write(self, template, params):
        pass

    def stop(self):
        pass

",3,1,snippet_53,1.0,"class StructuredLogger:
    '''
    ABSTRACT BASE CLASS FOR JSON LOGGING
    '''

    def __init__(self, stream=None):
        self.stream = stream or sys.stdout

    def write(self, template, params):
        """"""
        Write a JSON log entry.
        template: str with format placeholders.
        params: dict of values to format into template and include in the record.
        """"""
        record = {
            ""timestamp"": datetime.utcnow().isoformat() + ""Z"",
            ""message"": template.format(**params) if params else template
        }
        if params:
            record.update(params)
        json.dump(record, self.stream)
        self.stream.write(""\n"")
        self.stream.flush()

    def stop(self):
        """"""Flush the stream.""""""
        try:
            self.stream.flush()
        except Exception:
            pass","class StructuredLogger(metaclass=abc.ABCMeta):
    '''
    ABSTRACT BASE CLASS FOR JSON LOGGING
    '''

    @abc.abstractmethod
    def write(self, template, params):
        pass

    @abc.abstractmethod
    def stop(self):
        pass","class StructuredLogger(ABC):
    '''
    ABSTRACT BASE CLASS FOR JSON LOGGING
    '''

    @abstractmethod
    def write(self, template, params):
        pass

    @abstractmethod
    def stop(self):
        pass",partial_docstr,0.3119266055045872,0.2616822429906542,0.20952380952380953,0.3119266055045872,0.14764885082275267,0.18032786885245902,0.15384615384615385,0.11602209944751381,0.6521705389022827,0.893144965171814,0.7538691163063049,0.8613195419311523,0.7183126760563384,0.8372093023255813,0.6829268292682927,0.5128205128205128,0.8372093023255813,0.5238037550683039,0.6222222222222222,0.5227272727272727,0.4418604651162791,0.8591716289520264,0.9820076823234558,0.9164921045303345,0.9681657552719116,0.8632492307692308,0.923076923076923,0.7567567567567567,0.5714285714285714,0.923076923076923,0.6402590605382001,0.7567567567567568,0.6388888888888888,0.5428571428571428,0.9154790043830872,0.9875568151473999,0.9501529335975647,0.9798423051834106,0.9139793548387096,0.4063377077136921,0.1044840491707807,0.4754122362294423,0.5454545454545454,0.5,0.6941924166441498,0.4881010344921759,0.5613959048116961,0.7272727272727273,1.0,0.6941924166441498,0.4881010344921759,0.5613959048116961,0.7272727272727273,1.0
7940,AustralianSynchrotron/lightflow,AustralianSynchrotron_lightflow/lightflow/queue/models.py,lightflow.queue.models.WorkerStats,"class WorkerStats:
    """""" Represents the worker information returned from celery.

    Args:
        name (str): The name of the worker.
        broker (BrokerStats): A reference to a BrokerStats Object the worker is using.
        pid (int): The PID of the worker.
        process_pids (int): The PIDs of the concurrent task processes.
        concurrency (int): The number of concurrent processes.
        job_count (int): The number of jobs this worker has processed so far.
        queues (list): A list of QueueStats objects that represent the queues this
            worker is listening on.
    """"""
    def __init__(self, name, broker, pid, process_pids,
                 concurrency, job_count, queues):
        self.name = name
        self.broker = broker
        self.pid = pid
        self.process_pids = process_pids
        self.concurrency = concurrency
        self.job_count = job_count
        self.queues = queues

    @classmethod
    def from_celery(cls, name, worker_dict, queues):
        """""" Create a WorkerStats object from the dictionary returned by celery.

        Args:
            name (str): The name of the worker.
            worker_dict (dict): The dictionary as returned by celery.
            queues (list): A list of QueueStats objects that represent the queues this
                worker is listening on.

        Returns:
            WorkerStats: A fully initialized WorkerStats object.
        """"""
        return WorkerStats(
            name=name,
            broker=BrokerStats.from_celery(worker_dict['broker']),
            pid=worker_dict['pid'],
            process_pids=worker_dict['pool']['processes'],
            concurrency=worker_dict['pool']['max-concurrency'],
            job_count=worker_dict['pool']['writes']['total'],
            queues=queues
        )

    def to_dict(self):
        """""" Return a dictionary of the worker stats.

        Returns:
            dict: Dictionary of the stats.
        """"""
        return {
            'name': self.name,
            'broker': self.broker.to_dict(),
            'pid': self.pid,
            'process_pids': self.process_pids,
            'concurrency': self.concurrency,
            'job_count': self.job_count,
            'queues': [q.to_dict() for q in self.queues]
        }","class WorkerStats:
    ''' Represents the worker information returned from celery.

    Args:
        name (str): The name of the worker.
        broker (BrokerStats): A reference to a BrokerStats Object the worker is using.
        pid (int): The PID of the worker.
        process_pids (int): The PIDs of the concurrent task processes.
        concurrency (int): The number of concurrent processes.
        job_count (int): The number of jobs this worker has processed so far.
        queues (list): A list of QueueStats objects that represent the queues this
            worker is listening on.
    '''

    def __init__(self, name, broker, pid, process_pids,
                 concurrency, job_count, queues):
        pass

    @classmethod
    def from_celery(cls, name, worker_dict, queues):
    ''' Create a WorkerStats object from the dictionary returned by celery.

        Args:
            name (str): The name of the worker.
            worker_dict (dict): The dictionary as returned by celery.
            queues (list): A list of QueueStats objects that represent the queues this
                worker is listening on.

        Returns:
            WorkerStats: A fully initialized WorkerStats object.
        '''
        pass

    def to_dict(self):
    ''' Return a dictionary of the worker stats.

        Returns:
            dict: Dictionary of the stats.
        '''
        pass

",5,3,snippet_231,0.5714285714285714,"class WorkerStats:
    ''' Represents the worker information returned from celery.

    Args:
        name (str): The name of the worker.
        broker (BrokerStats): A reference to a BrokerStats Object the worker is using.
        pid (int): The PID of the worker.
        process_pids (int): The PIDs of the concurrent task processes.
        concurrency (int): The number of concurrent processes.
        job_count (int): The number of jobs this worker has processed so far.
        queues (list): A list of QueueStats objects that represent the queues this
            worker is listening on.
    '''

    def __init__(self, name, broker, pid, process_pids,
                 concurrency, job_count, queues):
        self.name = name
        self.broker = broker
        self.pid = pid
        self.process_pids = process_pids
        self.concurrency = concurrency
        self.job_count = job_count
        self.queues = queues

    @classmethod
    def from_celery(cls, name, worker_dict, queues):
        ''' Create a WorkerStats object from the dictionary returned by celery.

            Args:
                name (str): The name of the worker.
                worker_dict (dict): The dictionary as returned by celery.
                queues (list): A list of QueueStats objects that represent the queues this
                    worker is listening on.

            Returns:
                WorkerStats: A fully initialized WorkerStats object.
        '''
        broker = worker_dict.get('broker')
        pid = worker_dict.get('pid')
        # celery may report processes under 'processes' or 'pool' -> 'processes'
        process_pids = worker_dict.get('processes') \
                       or worker_dict.get('pool', {}).get('processes', [])
        # celery may report concurrency under 'concurrency' or 'pool' -> 'max-concurrency'
        concurrency = worker_dict.get('concurrency') \
                      or worker_dict.get('pool', {}).get('max-concurrency')
        # celery may report total tasks processed under 'total' or 'job_count'
        job_count = worker_dict.get('total') or worker_dict.get('job_count', 0)

        return cls(name, broker, pid, process_pids, concurrency, job_count, queues)

    def to_dict(self):
        ''' Return a dictionary of the worker stats.

            Returns:
                dict: Dictionary of the stats.
        '''
        return {
            'name': self.name,
            'broker': getattr(self.broker, 'to_dict', lambda: self.broker)(),
            'pid': self.pid,
            'process_pids': list(self.process_pids),
            'concurrency': self.concurrency,
            'job_count': self.job_count,
            'queues': [q.to_dict() for q in self.queues],
        }","class WorkerStats:
    ''' Represents the worker information returned from celery.

    Args:
        name (str): The name of the worker.
        broker (BrokerStats): A reference to a BrokerStats Object the worker is using.
        pid (int): The PID of the worker.
        process_pids (int): The PIDs of the concurrent task processes.
        concurrency (int): The number of concurrent processes.
        job_count (int): The number of jobs this worker has processed so far.
        queues (list): A list of QueueStats objects that represent the queues this
            worker is listening on.
    '''

    def __init__(self, name, broker, pid, process_pids,
                 concurrency, job_count, queues):
        self.name = name
        self.broker = broker
        self.pid = pid
        self.process_pids = process_pids
        self.concurrency = concurrency
        self.job_count = job_count
        self.queues = queues

    @classmethod
    def from_celery(cls, name, worker_dict, queues):
        ''' Create a WorkerStats object from the dictionary returned by celery.

        Args:
            name (str): The name of the worker.
            worker_dict (dict): The dictionary as returned by celery.
            queues (list): A list of QueueStats objects that represent the queues this
                worker is listening on.

        Returns:
            WorkerStats: A fully initialized WorkerStats object.
        '''
        return cls(
            name=name,
            broker=None,  # broker is not provided in the method signature
            pid=worker_dict.get('pid'),
            process_pids=worker_dict.get('process_pids', []),
            concurrency=worker_dict.get('concurrency'),
            job_count=worker_dict.get('job_count', 0),
            queues=queues
        )

    def to_dict(self):
        ''' Return a dictionary of the worker stats.

        Returns:
            dict: Dictionary of the stats.
        '''
        return {
            'name': self.name,
            'pid': self.pid,
            'process_pids': self.process_pids,
            'concurrency': self.concurrency,
            'job_count': self.job_count,
            'queues': [queue.to_dict() for queue in self.queues] if self.queues else []
        }","class WorkerStats:
    ''' Represents the worker information returned from celery.

    Args:
        name (str): The name of the worker.
        broker (BrokerStats): A reference to a BrokerStats Object the worker is using.
        pid (int): The PID of the worker.
        process_pids (int): The PIDs of the concurrent task processes.
        concurrency (int): The number of concurrent processes.
        job_count (int): The number of jobs this worker has processed so far.
        queues (list): A list of QueueStats objects that represent the queues this
            worker is listening on.
    '''

    def __init__(self, name, broker, pid, process_pids,
                 concurrency, job_count, queues):
        self.name = name
        self.broker = broker
        self.pid = pid
        self.process_pids = process_pids
        self.concurrency = concurrency
        self.job_count = job_count
        self.queues = queues

    @classmethod
    def from_celery(cls, name, worker_dict, queues):
        ''' Create a WorkerStats object from the dictionary returned by celery.

        Args:
            name (str): The name of the worker.
            worker_dict (dict): The dictionary as returned by celery.
            queues (list): A list of QueueStats objects that represent the queues this
                worker is listening on.

        Returns:
            WorkerStats: A fully initialized WorkerStats object.
        '''
        broker = worker_dict.get('broker')
        pid = worker_dict.get('pid')
        process_pids = worker_dict.get('pool', {}).get('processes', [])
        concurrency = worker_dict.get('pool', {}).get('max-concurrency', 0)
        job_count = worker_dict.get('total', 0)
        
        return cls(name, broker, pid, process_pids, concurrency, job_count, queues)

    def to_dict(self):
        ''' Return a dictionary of the worker stats.

        Returns:
            dict: Dictionary of the stats.
        '''
        return {
            'name': self.name,
            'broker': self.broker,
            'pid': self.pid,
            'process_pids': self.process_pids,
            'concurrency': self.concurrency,
            'job_count': self.job_count,
            'queues': self.queues
        }",partial_docstr,0.8794567062818336,0.82793867120954,0.7863247863247864,0.865874363327674,0.7126864141997046,0.7658802177858439,0.7109090909090909,0.6648451730418944,0.9389561414718628,0.9754221439361572,0.9568418264389038,0.971648633480072,0.8900123232323233,0.9213483146067416,0.8796992481203008,0.8452830188679246,0.9176029962546817,0.8310837242752734,0.9155555555555556,0.8530066815144766,0.8125,0.971520721912384,0.9780154228210449,0.9747572541236877,0.9773619771003723,0.9173797435897435,0.9378531073446328,0.888468809073724,0.8500948766603416,0.9303201506591336,0.8150172036889931,0.9030837004405287,0.82560706401766,0.7809734513274337,0.97303307056427,0.9738442301750183,0.973438560962677,0.9737630486488342,0.8953985355648535,0.7175593587410086,0.6662795989728303,0.8588211259956867,0.6494845360824743,0.6956521739130435,0.7488059760302112,0.8082632643271381,0.8605001586940505,0.6597938144329897,0.6666666666666666,0.7277944696590265,0.7964377373651197,0.8459518550017497,0.5876288659793815,0.6811594202898551
768715,stitchfix/pyxley,stitchfix_pyxley/pyxley/ui.py,pyxley.ui.SimpleComponent,"class SimpleComponent(object):
    """"""Simple class for rendering a single component.

        Rather than requiring a collection of filters and charts, this
        function will render a single react component with props
        passed as a dictionary.

        Args:
            layout (str): Type of react component to create.
            src_file (str): javascript file containing the component.
            component_id (str): html element id.
            props (dict): props for the component.
    """"""
    def __init__(self, layout, src_file, component_id, props):
        self.layout = layout
        self.src_file = src_file
        self.component_id = component_id
        self.props = props

    def render(self, path):
        """"""Render the component to a javascript file.""""""
        return ReactComponent(
            self.layout,
            self.src_file,
            self.component_id,
            props=self.props,
            static_path=path)","class SimpleComponent(object):
    '''Simple class for rendering a single component.

        Rather than requiring a collection of filters and charts, this
        function will render a single react component with props
        passed as a dictionary.

        Args:
            layout (str): Type of react component to create.
            src_file (str): javascript file containing the component.
            component_id (str): html element id.
            props (dict): props for the component.
    '''

    def __init__(self, layout, src_file, component_id, props):
        pass

    def render(self, path):
    '''Render the component to a javascript file.'''
        pass

",3,2,snippet_743,1.0,"class SimpleComponent(object):
    '''Simple class for rendering a single component.

    Rather than requiring a collection of filters and charts, this
    function will render a single React component with props
    passed as a dictionary.

    Args:
        layout (str): Name of the React component to render.
        src_file (str): JavaScript module path containing the component.
        component_id (str): HTML element id to mount the component into.
        props (dict): Props for the component.
    '''

    def __init__(self, layout, src_file, component_id, props):
        if not isinstance(layout, str):
            raise TypeError(""layout must be a string"")
        if not isinstance(src_file, str):
            raise TypeError(""src_file must be a string"")
        if not isinstance(component_id, str):
            raise TypeError(""component_id must be a string"")
        if not isinstance(props, dict):
            raise TypeError(""props must be a dictionary"")

        self.layout = layout
        self.src_file = src_file
        self.component_id = component_id
        self.props = props

    def render(self, path):
        '''Render the component to a JavaScript file.'''
        props_json = json.dumps(self.props, indent=2)
        content = f""""""import React from 'react';
import ReactDOM from 'react-dom';
import {{ {self.layout} }} from '{self.src_file}';

const props = {props_json};

ReactDOM.render(
  React.createElement({self.layout}, props),
  document.getElementById('{self.component_id}')
);
""""""
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)","class SimpleComponent(object):
    '''Simple class for rendering a single component.

        Rather than requiring a collection of filters and charts, this
        function will render a single react component with props
        passed as a dictionary.

        Args:
            layout (str): Type of react component to create.
            src_file (str): javascript file containing the component.
            component_id (str): html element id.
            props (dict): props for the component.
    '''

    def __init__(self, layout, src_file, component_id, props):
        self.layout = layout
        self.src_file = src_file
        self.component_id = component_id
        self.props = props

    def render(self, path):
        '''Render the component to a javascript file.'''
        import json
        import os

        # Create the directory if it doesn't exist
        directory = os.path.dirname(path)
        if directory and not os.path.exists(directory):
            os.makedirs(directory)

        # Convert props to JSON string
        props_json = json.dumps(self.props)

        # Read the source file
        with open(self.src_file, 'r') as f:
            src_content = f.read()

        # Create the rendered content
        rendered_content = f'''
// Generated component file
{src_content}

// Render component
const props = {props_json};
const element = React.createElement({self.layout}, props);
ReactDOM.render(element, document.getElementById('{self.component_id}'));
'''

        # Write to the output file
        with open(path, 'w') as f:
            f.write(rendered_content)","class SimpleComponent(object):
    '''Simple class for rendering a single component.

        Rather than requiring a collection of filters and charts, this
        function will render a single react component with props
        passed as a dictionary.

        Args:
            layout (str): Type of react component to create.
            src_file (str): javascript file containing the component.
            component_id (str): html element id.
            props (dict): props for the component.
    '''

    def __init__(self, layout, src_file, component_id, props):
        self.layout = layout
        self.src_file = src_file
        self.component_id = component_id
        self.props = props

    def render(self, path):
        '''Render the component to a javascript file.'''
        import json
        import os
        
        props_json = json.dumps(self.props)
        
        js_content = f""""""
import React from 'react';
import ReactDOM from 'react-dom';
import {self.layout} from './{self.src_file}';

const props = {props_json};

ReactDOM.render(
    React.createElement({self.layout}, props),
    document.getElementById('{self.component_id}')
);
""""""
        
        with open(path, 'w') as f:
            f.write(js_content.strip())",partial_docstr,0.6707692307692308,0.5820433436532507,0.5233644859813085,0.64,0.4186066659827579,0.5013550135501355,0.41304347826086957,0.3542234332425068,0.824673056602478,0.9463895559310913,0.8813487887382507,0.9326245784759521,0.7841126943005182,0.7047619047619047,0.65814696485623,0.630225080385852,0.6793650793650793,0.49201572159190754,0.5339233038348082,0.4881656804733728,0.456973293768546,0.8343287706375122,0.9721758365631104,0.8979930281639099,0.9563746452331543,0.7977548314606743,0.8208955223880597,0.7744360902255639,0.7424242424242424,0.7985074626865671,0.6118212418545379,0.6666666666666666,0.6072727272727273,0.5656934306569343,0.8831807374954224,0.9758566617965698,0.9272087216377258,0.965722918510437,0.8437515624999999,0.5836625574515855,0.3295569128966604,0.6064758053889441,0.6129032258064516,0.7857142857142857,0.6991887425477776,0.4610161895687036,0.8368908543551261,0.6774193548387096,0.8214285714285714,0.7238920666432667,0.6295199569391532,0.8386289547952037,0.6774193548387096,0.75
187749,SmartTeleMax/iktomi,SmartTeleMax_iktomi/iktomi/forms/perms.py,iktomi.forms.perms.FieldPerm,"class FieldPerm(object):
    '''
    Default permission getter for Field objects

    Ancestor should override the :meth:`check` method. They can use field.env
    to get any values from outside. For example::

        class RoleBased(FieldPerm):
            def __init__(self, role_perms):
                self.role_perms = role_perms

            def check(self, field):
                user = field.env.user
                perms = set(self.role_perms.get('*', ''))
                for role in user.roles:
                    perms.update(self.role_perms.get(role, ''))
                return perms
    '''

    permissions = None

    def __init__(self, permissions=None):
        if permissions is not None:
            self.permissions = set(permissions)

    def get_perms(self, obj):
        '''
        Returns combined Environment's and object's permissions.
        Resulting condition is intersection of them.
        '''
        return self.available(obj) & self.check(obj)

    def available(self, field):
        '''
        Returns permissions according environment's limiting condition.
        Determined by object's context

        Allows only field's parents' permissions
        '''
        return field.parent.permissions

    def check(self, field):
        '''
        Returns permissions determined by object itself
        '''
        if self.permissions is None:
            return field.parent.permissions
        return self.permissions

    def __repr__(self):
        return '{}({})'.format(self.__class__.__name__, str(self.permissions))","class FieldPerm(object):
    '''
    Default permission getter for Field objects

    Ancestor should override the :meth:`check` method. They can use field.env
    to get any values from outside. For example::

        class RoleBased(FieldPerm):
            def __init__(self, role_perms):
                self.role_perms = role_perms

            def check(self, field):
                user = field.env.user
                perms = set(self.role_perms.get('*', ''))
                for role in user.roles:
                    perms.update(self.role_perms.get(role, ''))
                return perms
    '''

            def __init__(self, role_perms):
                        pass

    def get_perms(self, obj):
    '''
        Returns combined Environment's and object's permissions.
        Resulting condition is intersection of them.
        '''
        pass

    def available(self, field):
    '''
        Returns permissions according environment's limiting condition.
        Determined by object's context

        Allows only field's parents' permissions
        '''
        pass

            def check(self, field):
    '''
        Returns permissions determined by object itself
        '''
                        pass

    def __repr__(self):
        pass

",6,4,snippet_703,1.0,"class FieldPerm(object):
    """"""
    Default permission getter for Field objects

    Ancestor should override the :meth:`check` method. They can use field.env
    to get any values from outside. For example::

        class RoleBased(FieldPerm):
            def __init__(self, role_perms):
                self.role_perms = role_perms

            def check(self, field):
                user = field.env.user
                perms = set(self.role_perms.get('*', ''))
                for role in user.roles:
                    perms.update(self.role_perms.get(role, ''))
                return perms
    """"""
    def __init__(self):
        super(FieldPerm, self).__init__()

    def get_perms(self, field):
        """"""
        Returns combined Environment's and object's permissions.
        Resulting condition is intersection of them.
        """"""
        # permissions determined by the object itself
        obj_perms = self.check(field) or set()

        # environment-level permissions: could be a dict, a callable, or a flat iterable
        env_perms = getattr(field.env, 'perms', {})
        if callable(env_perms):
            env_p = set(env_perms(field) or ())
        elif isinstance(env_perms, dict):
            # by field name, or '*' for default
            name = getattr(field, 'name', None)
            env_p = set(env_perms.get(name, env_perms.get('*', ())) or ())
        else:
            env_p = set(env_perms or ())

        return obj_perms & env_p

    def available(self, field):
        """"""
        Returns permissions according environment's limiting condition.
        Determined by object's context

        Allows only field's parents' permissions
        """"""
        # environment limiting condition
        env_limit = getattr(field.env, 'limit', {})
        if callable(env_limit):
            lim = set(env_limit(field) or ())
        elif isinstance(env_limit, dict):
            name = getattr(field, 'name', None)
            lim = set(env_limit.get(name, env_limit.get('*', ())) or ())
        else:
            lim = set(env_limit or ())

        # start with environment limit
        perms = lim
        # intersect with each parent's effective permissions
        for parent in getattr(field, 'parents', ()):
            perms &= self.get_perms(parent)

        return perms

    def check(self, field):
        """"""
        Returns permissions determined by object itself.
        Ancestors should override this.
        """"""
        return set()

    def __repr__(self):
        return '<%s>' % self.__class__.__name__","class FieldPerm(object):
    '''
    Default permission getter for Field objects

    Ancestor should override the :meth:`check` method. They can use field.env
    to get any values from outside. For example::

        class RoleBased(FieldPerm):
            def __init__(self, role_perms):
                self.role_perms = role_perms

            def check(self, field):
                user = field.env.user
                perms = set(self.role_perms.get('*', ''))
                for role in user.roles:
                    perms.update(self.role_perms.get(role, ''))
                return perms
    '''

    def __init__(self, role_perms):
        self.role_perms = role_perms

    def get_perms(self, obj):
        '''
        Returns combined Environment's and object's permissions.
        Resulting condition is intersection of them.
        '''
        env_perms = self.available(obj)
        obj_perms = self.check(obj)
        return env_perms & obj_perms

    def available(self, field):
        '''
        Returns permissions according environment's limiting condition.
        Determined by object's context

        Allows only field's parents' permissions
        '''
        if hasattr(field, 'env') and hasattr(field.env, 'perms'):
            return set(field.env.perms)
        return set()

    def check(self, field):
        '''
        Returns permissions determined by object itself
        '''
        return set()

    def __repr__(self):
        return '<FieldPerm>'","class FieldPerm(object):
    '''
    Default permission getter for Field objects

    Ancestor should override the :meth:`check` method. They can use field.env
    to get any values from outside. For example::

        class RoleBased(FieldPerm):
            def __init__(self, role_perms):
                self.role_perms = role_perms

            def check(self, field):
                user = field.env.user
                perms = set(self.role_perms.get('*', ''))
                for role in user.roles:
                    perms.update(self.role_perms.get(role, ''))
                return perms
    '''

    def __init__(self, role_perms=None):
        self.role_perms = role_perms or {}

    def get_perms(self, obj):
        '''
        Returns combined Environment's and object's permissions.
        Resulting condition is intersection of them.
        '''
        available_perms = self.available(obj)
        check_perms = self.check(obj)
        return available_perms & check_perms

    def available(self, field):
        '''
        Returns permissions according environment's limiting condition.
        Determined by object's context

        Allows only field's parents' permissions
        '''
        if hasattr(field, 'parent') and field.parent:
            return self.get_perms(field.parent)
        return set(['r', 'w'])

    def check(self, field):
        '''
        Returns permissions determined by object itself
        '''
        return set(['r', 'w'])

    def __repr__(self):
        return f""{self.__class__.__name__}({self.role_perms})""",partial_docstr,0.648068669527897,0.5301724137931034,0.49350649350649356,0.5965665236051503,0.4039213168380498,0.48217317487266553,0.38945578231292516,0.35093696763202725,0.8509807586669922,0.9268024563789368,0.8872747421264648,0.9186176061630249,0.7452960132890367,0.8411764705882354,0.7455621301775148,0.7023809523809524,0.8117647058823528,0.775759848965373,0.8973509933774835,0.7873754152823921,0.73,0.9518381357192993,0.9412468671798706,0.9465128779411316,0.9422953128814697,0.7979818181818181,0.8603988603988604,0.7564469914040115,0.6858789625360231,0.8205128205128205,0.7727291785979941,0.8482142857142857,0.7731343283582089,0.7035928143712575,0.9485269784927368,0.9508441686630249,0.949684202671051,0.95061194896698,0.8048265131578948,0.4871731978341328,0.3373313927114522,0.6324140302040262,0.4,0.5789473684210527,0.6166699040054232,0.7547547938683631,0.7496441203989439,0.3833333333333333,0.5789473684210527,0.6132162089782579,0.7435715927070701,0.7496441203989439,0.4333333333333333,0.5263157894736842
318415,cqlengine/cqlengine,cqlengine_cqlengine/cqlengine/models.py,cqlengine.models.ColumnDescriptor,"class ColumnDescriptor(object):
    """"""
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    """"""

    def __init__(self, column):
        """"""
        :param column:
        :type column: columns.Column
        :return:
        """"""
        self.column = column
        self.query_evaluator = ColumnQueryEvaluator(self.column)

    def __get__(self, instance, owner):
        """"""
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        """"""
        try:
            return instance._values[self.column.column_name].getval()
        except AttributeError as e:
            return self.query_evaluator

    def __set__(self, instance, value):
        """"""
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        """"""
        if instance:
            return instance._values[self.column.column_name].setval(value)
        else:
            raise AttributeError('cannot reassign column values')

    def __delete__(self, instance):
        """"""
        Sets the column value to None, if possible
        """"""
        if instance:
            if self.column.can_delete:
                instance._values[self.column.column_name].delval()
            else:
                raise AttributeError('cannot delete {} columns'.format(self.column.column_name))","class ColumnDescriptor(object):
    '''
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    '''

    def __init__(self, column):
    '''
        :param column:
        :type column: columns.Column
        :return:
        '''
        pass

    def __get__(self, instance, owner):
    '''
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        '''
        pass

    def __set__(self, instance, value):
    '''
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        '''
        pass

    def __delete__(self, instance):
    '''
        Sets the column value to None, if possible
        '''
        pass

",5,5,snippet_50,0.2727272727272727,"class ColumnDescriptor(object):
    """"""
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries.
    """"""
    def __init__(self, column):
        """"""
        :param column: columns.Column instance
        """"""
        self.column = column
        # the name under which this column's value is stored on the instance
        self.name = column.name

    def __get__(self, instance, owner):
        """"""
        Returns either the column (when accessed on the class) or the
        stored value (when accessed on an instance).
        """"""
        if instance is None:
            return self.column
        # assume instance._values is a dict-like value manager
        return instance._values.get(self.name, None)

    def __set__(self, instance, value):
        """"""
        Sets the value on an instance. Raises if attempted on the class.
        """"""
        if instance is None:
            raise AttributeError(
                ""Cannot set column value on the class itself.""
            )
        # store the value in the instance's value manager
        instance._values[self.name] = value

    def __delete__(self, instance):
        """"""
        Sets the column value to None, if the column is nullable.
        """"""
        if instance is None:
            raise AttributeError(
                ""Cannot delete column value on the class itself.""
            )
        # check nullable property if present
        nullable = getattr(self.column, 'nullable', True)
        if not nullable:
            raise AttributeError(
                ""Column '%s' is not nullable, cannot delete."" % self.name
            )
        instance._values[self.name] = None","class ColumnDescriptor(object):
    '''
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    '''

    def __init__(self, column):
        '''
        :param column:
        :type column: columns.Column
        :return:
        '''
        self.column = column

    def __get__(self, instance, owner):
        '''
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        '''
        if instance is None:
            return self.column
        return instance._values.get(self.column.name, None)

    def __set__(self, instance, value):
        '''
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        '''
        if instance is None:
            raise AttributeError(""Cannot set column value on class"")
        instance._values[self.column.name] = value

    def __delete__(self, instance):
        '''
        Sets the column value to None, if possible
        '''
        if instance is None:
            raise AttributeError(""Cannot delete column value on class"")
        instance._values[self.column.name] = None","class ColumnDescriptor(object):
    '''
    Handles the reading and writing of column values to and from
    a model instance's value manager, as well as creating
    comparator queries
    '''

    def __init__(self, column):
        '''
        :param column:
        :type column: columns.Column
        :return:
        '''
        self.column = column

    def __get__(self, instance, owner):
        '''
        Returns either the value or column, depending
        on if an instance is provided or not

        :param instance: the model instance
        :type instance: Model
        '''
        if instance is None:
            return self.column
        return instance._values.get(self.column.column_name)

    def __set__(self, instance, value):
        '''
        Sets the value on an instance, raises an exception with classes
        TODO: use None instance to create update statements
        '''
        if instance is None:
            raise AttributeError(""Cannot set attribute on class"")
        instance._values[self.column.column_name] = value

    def __delete__(self, instance):
        '''
        Sets the column value to None, if possible
        '''
        if instance is None:
            raise AttributeError(""Cannot delete attribute on class"")
        instance._values[self.column.column_name] = None",partial_docstr,0.6719999999999999,0.45040214477211793,0.34501347708894875,0.5279999999999999,0.5449728309379815,0.7063953488372093,0.5189504373177842,0.4415204678362573,0.8654344081878662,0.8764277696609497,0.8708963990211487,0.8753159046173096,0.8003895930232559,0.8492307692307692,0.7678018575851394,0.6791277258566979,0.7815384615384615,0.590718484249504,0.8779527559055118,0.7391304347826086,0.6547619047619048,0.9494046568870544,0.9153950214385986,0.9320896863937378,0.9186859726905823,0.8089687719298246,0.8553846153846153,0.7863777089783281,0.7165109034267914,0.7999999999999999,0.6201070580094347,0.88671875,0.7725490196078432,0.6968503937007874,0.9500831365585327,0.9183011651039124,0.9339218139648438,0.9213833808898926,0.8109180701754386,0.4205024225038373,0.30572604380151,0.4511173490963228,0.4024390243902439,0.5227272727272727,0.4946651560041847,0.5743316047105254,0.6016682654259472,0.4390243902439024,0.3636363636363636,0.5002760473117502,0.5853080206055166,0.6009402928099989,0.4512195121951219,0.3636363636363636
199239,StyXman/ayrton,StyXman_ayrton/ayrton/expansion.py,ayrton.expansion.ToExpand,"class ToExpand (object):
    def __init__ (self, s, indexes=None):
        self.text= s
        if indexes is None:
            self.find_indexes ()
        else:
            # I have to deep copy the Group
            self.indexes= []
            for i in indexes:
                self.indexes.append (Group (*list (i)))

    def find_indexes (self):
        self.indexes= []
        current= {}
        seq= 0

        # iterate from left to right over the chars
        for i, c in enumerate (self.text):
            # if the char is {, try to find the first closing }
            # but if another { is found, use that as the matching one for the }
            if   c=='{' and self.text[i-1]!='\\':
                data= Group (i)
                # print (data)
                self.indexes.append (data)
                # we make sure we point to the same list,
                # so we can add the pointer to the closing bracket when we find it
                current[seq]= data
                seq+= 1
            elif c=='}' and self.text[i-1]!='\\':
                # we append to the element the pointer to the closing bracket
                try:
                    data= current[seq-1]
                    data.add_right (i)
                    # print (data)
                    seq-= 1
                except KeyError:
                    # there is no corresponding opening bracket; just ignore
                    pass

        # remove indexes for unmatched open brackes
        # unmatched closing brackets are ignored in the try/except up there
        self.indexes= [ i for i in self.indexes if i.right is not None ]
        # print (self.indexes)

    def expand_one (self):
        ""expand the more-to-the-left/outer bracket, return a list of ToExpand's""
        data= self.indexes.pop (0)

        left_cb, right_cb= data
        prefix= self.text[:left_cb]
        # the body includes the {}'s
        body= self.text[left_cb:right_cb+1]
        postfix= self.text[right_cb+1:]
        # print (""pre:%r b:%r post:%r"" % (prefix, body, postfix))

        # will hold the expansion of the body
        expanded= []
        # do not count the opening bracket
        last= 1
        split_here= False
        comma_found= False
        # index for the position in the original string of the beginning of
        # the current body starts
        # we need it because the indexes are based on the positions on the
        # original string
        base= left_cb+1

        for i, c in enumerate (body):
            if c==',' and body[i-1]!='\\':
                split_here= True
                # check if this comma belongs to a inner group
                for l, r in self.indexes:
                    # TODO: show that this cannot actually happen
                    if l>right_cb:
                        # stop searching, this pair is beyond us
                        break

                    orig_i= base+i
                    # print (s, l, orig_i, r)

                    if l<orig_i and orig_i<r:
                        # print 'not splitting, comma @%d(%d) between {%d,%d}' % (orig_i, i, l, r)
                        split_here= False
                        # stop searching too
                        break

                if split_here:
                    comma_found= True
                    dst= body[last:i]
                    te= ToExpand (prefix+dst+postfix)
                    expanded.append (te)
                    # print ('split!', expanded)
                    last= i+1 # point to the next char, not the comma itself

        # only add the last element if a comma was found
        if comma_found:
            # do not count the closing bracket
            dst= body[last:-1]
            te= ToExpand (prefix+dst+postfix)
            expanded.append (te)
            # print ('append', expanded)
        else:
            # otherwise, just leave untouched
            # (except for the index we already removed at the beginning of this method)
            expanded.append (self)

        return expanded

    def fully_expanded (self):
        # just check how many indexes are left
        return len (self.indexes)==0

    def __repr__ (self):
        return ""ToExpand (%s, %s)"" % (self.text, self.indexes)","class ToExpand (object):


    def __init__ (self, s, indexes=None):
        pass

    def find_indexes (self):
        pass

    def expand_one (self):
    '''expand the more-to-the-left/outer bracket, return a list of ToExpand's'''
        pass

    def fully_expanded (self):
        pass

    def __repr__ (self):
        pass

",6,1,snippet_173,0.4285714285714285,"class ToExpand(object):
    def __init__(self, s, indexes=None):
        self.s = s
        if indexes is None:
            self.indexes = self.find_indexes()
        else:
            self.indexes = indexes

    def find_indexes(self):
        s = self.s
        level = 0
        start = None
        for i, ch in enumerate(s):
            if ch == '(':
                if level == 0:
                    start = i
                level += 1
            elif ch == ')':
                level -= 1
                if level == 0 and start is not None:
                    content = s[start+1:i]
                    # check for a toplevel '|'
                    lvl = 0
                    for c in content:
                        if c == '(':
                            lvl += 1
                        elif c == ')':
                            lvl -= 1
                        elif c == '|' and lvl == 0:
                            return (start, i)
                    return None
        return None

    def expand_one(self):
        if self.indexes is None:
            return []
        start, end = self.indexes
        content = self.s[start+1:end]
        parts = []
        last = 0
        lvl = 0
        for i, ch in enumerate(content):
            if ch == '(':
                lvl += 1
            elif ch == ')':
                lvl -= 1
            elif ch == '|' and lvl == 0:
                parts.append(content[last:i])
                last = i + 1
        parts.append(content[last:])
        results = []
        for part in parts:
            new_s = self.s[:start] + part + self.s[end+1:]
            results.append(ToExpand(new_s))
        return results

    def fully_expanded(self):
        return self.indexes is None

    def __repr__(self):
        return f""ToExpand({self.s!r})""","class ToExpand(object):
    def __init__(self, s, indexes=None):
        self.s = s
        if indexes is None:
            self.indexes = self.find_indexes()
        else:
            self.indexes = indexes

    def find_indexes(self):
        indexes = []
        stack = []
        for i, char in enumerate(self.s):
            if char == '[':
                stack.append(i)
            elif char == ']':
                if stack:
                    start = stack.pop()
                    indexes.append((start, i))
        return indexes

    def expand_one(self):
        '''expand the more-to-the-left/outer bracket, return a list of ToExpand's'''
        if not self.indexes:
            return []
        
        # Find the outermost bracket (leftmost opening bracket)
        outermost = min(self.indexes, key=lambda x: x[0])
        start, end = outermost
        
        # Get the part before the bracket, inside the bracket, and after the bracket
        before = self.s[:start]
        inside = self.s[start+1:end]
        after = self.s[end+1:]
        
        # Split the inside content by comma
        parts = [part.strip() for part in inside.split(',')]
        
        # Create new ToExpand objects for each possibility
        result = []
        for part in parts:
            new_s = before + part + after
            # Recalculate indexes for the new string
            new_obj = ToExpand(new_s)
            result.append(new_obj)
        
        return result

    def fully_expanded(self):
        return len(self.indexes) == 0

    def __repr__(self):
        return f""ToExpand('{self.s}', {self.indexes})""","class ToExpand (object):

    def __init__ (self, s, indexes=None):
        self.s = s
        self.indexes = indexes if indexes is not None else self.find_indexes()

    def find_indexes (self):
        indexes = []
        depth = 0
        start = -1
        
        for i, char in enumerate(self.s):
            if char == '{':
                if depth == 0:
                    start = i
                depth += 1
            elif char == '}':
                depth -= 1
                if depth == 0 and start != -1:
                    indexes.append((start, i))
                    start = -1
        
        return indexes

    def expand_one (self):
        '''expand the more-to-the-left/outer bracket, return a list of ToExpand's'''
        if not self.indexes:
            return [self]
        
        start, end = self.indexes[0]
        bracket_content = self.s[start+1:end]
        options = bracket_content.split(',')
        
        result = []
        for option in options:
            new_s = self.s[:start] + option + self.s[end+1:]
            result.append(ToExpand(new_s))
        
        return result

    def fully_expanded (self):
        return len(self.indexes) == 0

    def __repr__ (self):
        return self.s",partial_docstr,0.33379310344827584,0.1466113416320885,0.07212205270457699,0.23724137931034484,0.13335513570233018,0.765,0.43859649122807015,0.2814070351758794,0.8479785919189453,0.7323965430259705,0.7859609723091125,0.742517352104187,0.7797880120481933,0.351313969571231,0.18862690707350901,0.12239221140472877,0.26556016597510373,0.11698697769323711,0.8033240997229917,0.4777777777777778,0.3426183844011142,0.8428679704666138,0.7583776116371155,0.7983936667442322,0.7660566568374634,0.793174759036145,0.3204747774480713,0.18452380952380953,0.12835820895522387,0.26112759643916916,0.06237447600881204,0.8489208633093526,0.5523465703971119,0.391304347826087,0.862055778503418,0.7441635131835938,0.7987831234931946,0.7544815540313721,0.7791186746987955,0.16928955682094,0.0096295536832128,0.0204885572950636,0.3596837944664031,0.2873563218390804,0.1816922317596898,0.0137900969556233,0.0353858084121532,0.4189723320158103,0.2586206896551724,0.1707499355071989,0.0120907006449212,0.0561936717959411,0.3675889328063241,0.2471264367816092
740129,sirfoga/pyhal,sirfoga_pyhal/hal/files/parsers.py,hal.files.parsers.Parser,"class Parser:
    """"""Mother of all data-files parsers""""""

    def __init__(self, file_path):
        """"""
        :param file_path: path to file
        """"""
        self.path = file_path
        self.lines = None  # list of lines in database

    def get_lines(self):
        """"""Gets lines in file

        :return: Lines in file
        """"""
        with open(self.path, ""r"") as data:
            self.lines = data.readlines()  # store data in arrays

        return self.lines","class Parser:
    '''Mother of all data-files parsers'''

    def __init__(self, file_path):
    '''
        :param file_path: path to file
        '''
        pass

    def get_lines(self):
    '''Gets lines in file

        :return: Lines in file
        '''
        pass

",3,3,snippet_446,0.6,"class Parser:
    '''Mother of all data-files parsers'''

    def __init__(self, file_path):
        '''
        :param file_path: path to file
        '''
        self.file_path = file_path

    def get_lines(self):
        '''Gets lines in file

        :return: Lines in file
        '''
        with open(self.file_path, 'r') as f:
            return f.read().splitlines()","class Parser:
    '''Mother of all data-files parsers'''

    def __init__(self, file_path):
        '''
        :param file_path: path to file
        '''
        self.file_path = file_path

    def get_lines(self):
        '''Gets lines in file

        :return: Lines in file
        '''
        with open(self.file_path, 'r') as file:
            return file.readlines()","class Parser:
    '''Mother of all data-files parsers'''

    def __init__(self, file_path):
        '''
        :param file_path: path to file
        '''
        self.file_path = file_path

    def get_lines(self):
        '''Gets lines in file

        :return: Lines in file
        '''
        with open(self.file_path, 'r') as file:
            return file.readlines()",partial_docstr,0.7706422018348624,0.691588785046729,0.6285714285714286,0.7706422018348624,0.42894830128274525,0.8023255813953488,0.6235294117647059,0.4880952380952381,0.9705533981323242,0.9344974756240845,0.9521842002868652,0.9379819631576538,0.9155564,0.7962962962962963,0.6981132075471699,0.6346153846153846,0.7777777777777777,0.4325908768461195,0.8414634146341463,0.6790123456790124,0.5375,0.977211594581604,0.9362772703170776,0.9563065767288208,0.9402157068252563,0.9244452,0.7962962962962963,0.6981132075471699,0.6346153846153846,0.7777777777777777,0.4325908768461195,0.8414634146341463,0.6790123456790124,0.5375,0.977211594581604,0.9362772703170776,0.9563065767288208,0.9402157068252563,0.9244452,0.3518114898425315,0.2257420064749004,0.2528052006670617,0.5757575757575758,0.3529411764705882,0.3518114898425315,0.2257420064749004,0.2528052006670617,0.5757575757575758,0.3529411764705882,0.3518114898425315,0.2257420064749004,0.2528052006670617,0.5757575757575758,0.3529411764705882
117060,Duke-GCB/DukeDSClient,Duke-GCB_DukeDSClient/ddsc/core/projectuploader.py,ddsc.core.projectuploader.UploadContext,"class UploadContext(object):
    """"""
    Values passed to a background worker.
    Contains UploadSettings and parameters specific to the function to be run.
    """"""
    def __init__(self, settings, params, message_queue, task_id):
        """"""
        Setup context so it can be passed.
        :param settings: UploadSettings: project level info
        :param params: tuple: values specific to the function being run
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        """"""
        self.data_service_auth_data = settings.get_data_service_auth_data()
        self.config = settings.config
        self.project_name_or_id = settings.project_name_or_id
        self.project_id = settings.project_id
        self.params = params
        self.message_queue = message_queue
        self.task_id = task_id

    def make_data_service(self):
        """"""
        Recreate data service from within background worker.
        :return: DataServiceApi
        """"""
        return UploadSettings.rebuild_data_service(self.config, self.data_service_auth_data)

    def send_message(self, data):
        """"""
        Sends a message to the command's on_message(data) method.
        :param data: object: data sent to on_message
        """"""
        self.message_queue.put((self.task_id, data))

    def start_waiting(self):
        """"""
        Called when we start waiting for project to be ready for file uploads.
        """"""
        self.send_message(True)

    def done_waiting(self):
        """"""
        Called when project is ready for file uploads (after waiting).
        """"""
        self.send_message(False)","class UploadContext(object):
    '''
    Values passed to a background worker.
    Contains UploadSettings and parameters specific to the function to be run.
    '''

    def __init__(self, settings, params, message_queue, task_id):
    '''
        Setup context so it can be passed.
        :param settings: UploadSettings: project level info
        :param params: tuple: values specific to the function being run
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        pass

    def make_data_service(self):
    '''
        Recreate data service from within background worker.
        :return: DataServiceApi
        '''
        pass

    def send_message(self, data):
    '''
        Sends a message to the command's on_message(data) method.
        :param data: object: data sent to on_message
        '''
        pass

    def start_waiting(self):
    '''
        Called when we start waiting for project to be ready for file uploads.
        '''
        pass

    def done_waiting(self):
    '''
        Called when project is ready for file uploads (after waiting).
        '''
        pass

",6,6,snippet_629,0.4285714285714285,"class UploadContext(object):
    '''
    Values passed to a background worker.
    Contains UploadSettings and parameters specific to the function to be run.
    '''

    def __init__(self, settings, params, message_queue, task_id):
        '''
        Setup context so it can be passed.
        :param settings: UploadSettings: project level info
        :param params: tuple: values specific to the function being run
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        self.settings = settings
        self.params = params
        self.message_queue = message_queue
        self.task_id = task_id

    def make_data_service(self):
        '''
        Recreate data service from within background worker.
        :return: DataServiceApi
        '''
        return DataServiceApi(
            base_url=self.settings.base_url,
            api_key=self.settings.api_key,
            timeout=getattr(self.settings, 'timeout', None)
        )

    def send_message(self, data):
        '''
        Sends a message to the command's on_message(data) method.
        :param data: object: data sent to on_message
        '''
        self.message_queue.put((self.task_id, data))

    def start_waiting(self):
        '''
        Called when we start waiting for project to be ready for file uploads.
        '''
        self.send_message({'event': 'start_waiting'})

    def done_waiting(self):
        '''
        Called when project is ready for file uploads (after waiting).
        '''
        self.send_message({'event': 'done_waiting'})","class UploadContext(object):
    '''
    Values passed to a background worker.
    Contains UploadSettings and parameters specific to the function to be run.
    '''

    def __init__(self, settings, params, message_queue, task_id):
        '''
        Setup context so it can be passed.
        :param settings: UploadSettings: project level info
        :param params: tuple: values specific to the function being run
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        self.settings = settings
        self.params = params
        self.message_queue = message_queue
        self.task_id = task_id

    def make_data_service(self):
        '''
        Recreate data service from within background worker.
        :return: DataServiceApi
        '''
        return self.settings.make_data_service()

    def send_message(self, data):
        '''
        Sends a message to the command's on_message(data) method.
        :param data: object: data sent to on_message
        '''
        self.message_queue.put((self.task_id, data))

    def start_waiting(self):
        '''
        Called when we start waiting for project to be ready for file uploads.
        '''
        self.send_message({'status': 'waiting', 'message': 'Waiting for project to be ready for file uploads'})

    def done_waiting(self):
        '''
        Called when project is ready for file uploads (after waiting).
        '''
        self.send_message({'status': 'ready', 'message': 'Project is ready for file uploads'})","class UploadContext(object):
    '''
    Values passed to a background worker.
    Contains UploadSettings and parameters specific to the function to be run.
    '''

    def __init__(self, settings, params, message_queue, task_id):
        '''
        Setup context so it can be passed.
        :param settings: UploadSettings: project level info
        :param params: tuple: values specific to the function being run
        :param message_queue: Queue: queue background process can send messages to us on
        :param task_id: int: id of this command's task so message will be routed correctly
        '''
        self.settings = settings
        self.params = params
        self.message_queue = message_queue
        self.task_id = task_id

    def make_data_service(self):
        '''
        Recreate data service from within background worker.
        :return: DataServiceApi
        '''
        return self.settings.make_data_service()

    def send_message(self, data):
        '''
        Sends a message to the command's on_message(data) method.
        :param data: object: data sent to on_message
        '''
        self.message_queue.put((self.task_id, data))

    def start_waiting(self):
        '''
        Called when we start waiting for project to be ready for file uploads.
        '''
        self.send_message({'message_type': 'start_waiting'})

    def done_waiting(self):
        '''
        Called when project is ready for file uploads (after waiting).
        '''
        self.send_message({'message_type': 'done_waiting'})",partial_docstr,0.869158878504673,0.8215962441314554,0.8066037735849056,0.8551401869158879,0.6804026317156193,0.8797653958944281,0.7764705882352941,0.7168141592920354,0.9581840634346008,0.95290207862854,0.9555358290672302,0.9534277319908142,0.8614471686746987,0.8717948717948717,0.8243559718969554,0.8047058823529412,0.8578088578088577,0.6702202874965439,0.8727272727272727,0.8054711246200608,0.7469512195121951,0.959084153175354,0.9435605406761169,0.9512590169906616,0.9450902342796326,0.8488627950310559,0.889423076923077,0.8502415458937198,0.8300970873786407,0.8846153846153847,0.6661148977908513,0.9148264984227129,0.8386075949367089,0.7777777777777778,0.9640432000160217,0.9427135586738586,0.9532590508460999,0.9448039531707764,0.8832283439490447,0.6152391658607264,0.7316430105735935,0.7395748468991624,0.5522388059701493,0.4375,0.5940644959762886,0.6945189579015145,0.7395748468991624,0.5671641791044776,0.375,0.6032038319793153,0.7310763019136209,0.7395748468991624,0.5671641791044776,0.375
516056,jmoiron/johnny-cache,jmoiron_johnny-cache/johnny/middleware.py,jmoiron_johnny-cache.johnny.middleware.QueryCacheMiddleware,"class QueryCacheMiddleware(object):
    """"""
    This middleware class monkey-patches django's ORM to maintain
    generational info on each table (model) and to automatically cache all
    querysets created via the ORM.  This should be the first middleware
    in your middleware stack.
    """"""
    __state = {}  # Alex Martelli's borg pattern

    def __init__(self):
        self.__dict__ = self.__state
        self.disabled = settings.DISABLE_QUERYSET_CACHE
        self.installed = getattr(self, 'installed', False)
        if not self.installed and not self.disabled:
            # when we install, lets refresh the blacklist, just in case johnny
            # was loaded before the setting exists somehow...
            cache.blacklist = settings.BLACKLIST
            self.query_cache_backend = cache.get_backend()
            self.query_cache_backend.patch()
            self.installed = True

    def unpatch(self):
        self.query_cache_backend.unpatch()
        self.query_cache_backend.flush_query_cache()
        self.installed = False","class QueryCacheMiddleware(object):
    '''
    This middleware class monkey-patches django's ORM to maintain
    generational info on each table (model) and to automatically cache all
    querysets created via the ORM.  This should be the first middleware
    in your middleware stack.
    '''

    def __init__(self):
        pass

    def unpatch(self):
        pass

",3,1,snippet_555,0.2857142857142857,"class QueryCacheMiddleware(object):
    """"""
    This middleware class monkey-patches Django's ORM to maintain
    generational info on each table (model) and to automatically cache all
    querysets created via the ORM. This should be the first middleware
    in your middleware stack.
    """"""
    _cache = {}
    _generations = {}
    _patched = False
    _orig_fetch_all = None
    _invalidate = None

    def __init__(self):
        if not self.__class__._patched:
            # patch QuerySet._fetch_all
            self.__class__._orig_fetch_all = QuerySet._fetch_all

            def _patched_fetch_all(self):
                if self._result_cache is not None:
                    return
                sql, params = self.query.sql_with_params()
                tables = tuple(sorted(self.query.tables))
                gens = tuple(
                    (t, QueryCacheMiddleware._generations.get(t, 0))
                    for t in tables
                )
                key = (sql, params, gens)
                cache = QueryCacheMiddleware._cache
                if key in cache:
                    self._result_cache = cache[key]
                else:
                    QueryCacheMiddleware._orig_fetch_all(self)
                    cache[key] = list(self._result_cache)

            QuerySet._fetch_all = _patched_fetch_all

            # connect signals to invalidate on save/delete
            def invalidate(sender, **kwargs):
                table = sender._meta.db_table
                QueryCacheMiddleware._generations[table] = (
                    QueryCacheMiddleware._generations.get(table, 0) + 1
                )

            self.__class__._invalidate = invalidate
            signals.post_save.connect(invalidate)
            signals.post_delete.connect(invalidate)

            self.__class__._patched = True

    def unpatch(self):
        if not self.__class__._patched:
            return

        QuerySet._fetch_all = self.__class__._orig_fetch_all
        signals.post_save.disconnect(self.__class__._invalidate)
        signals.post_delete.disconnect(self.__class__._invalidate)

        self.__class__._patched = False
        QueryCacheMiddleware._cache.clear()
        QueryCacheMiddleware._generations.clear()","class QueryCacheMiddleware(object):
    '''
    This middleware class monkey-patches django's ORM to maintain
    generational info on each table (model) and to automatically cache all
    querysets created via the ORM.  This should be the first middleware
    in your middleware stack.
    '''

    def __init__(self):
        self.patched = False
        self.original_manager = None
        self.original_queryset = None

    def unpatch(self):
        if not self.patched:
            return
            
        # Restore original Django ORM methods
        if self.original_manager:
            import django.db.models.manager
            django.db.models.manager.Manager.get_queryset = self.original_manager
            
        if self.original_queryset:
            import django.db.models.query
            django.db.models.query.QuerySet.__iter__ = self.original_queryset
            
        self.patched = False","class QueryCacheMiddleware(object):
    '''
    This middleware class monkey-patches django's ORM to maintain
    generational info on each table (model) and to automatically cache all
    querysets created via the ORM.  This should be the first middleware
    in your middleware stack.
    '''

    def __init__(self):
        self._patched = False
        self._original_methods = {}
        self._lock = threading.Lock()
        self._generations = {}
        self._patch_orm()

    def _patch_orm(self):
        if self._patched:
            return
            
        with self._lock:
            if self._patched:
                return
                
            # Store original methods
            self._original_methods['queryset_iterator'] = QuerySet.__iter__
            self._original_methods['queryset_count'] = QuerySet.count
            self._original_methods['queryset_exists'] = QuerySet.exists
            self._original_methods['model_save'] = models.Model.save
            self._original_methods['model_delete'] = models.Model.delete
            
            # Patch QuerySet methods
            QuerySet.__iter__ = self._cached_iterator
            QuerySet.count = self._cached_count
            QuerySet.exists = self._cached_exists
            
            # Patch Model methods to invalidate cache
            models.Model.save = self._invalidating_save
            models.Model.delete = self._invalidating_delete
            
            # Connect to bulk operations
            signals.post_save.connect(self._invalidate_model_cache)
            signals.post_delete.connect(self._invalidate_model_cache)
            
            self._patched = True

    def _get_cache_key(self, queryset):
        query_str = str(queryset.query)
        model_name = queryset.model._meta.label
        generation = self._get_generation(model_name)
        
        key_data = f""{model_name}:{generation}:{query_str}""
        return f""querycache:{hashlib.md5(key_data.encode()).hexdigest()}""

    def _get_generation(self, model_name):
        if model_name not in self._generations:
            self._generations[model_name] = cache.get(f""generation:{model_name}"", 0)
        return self._generations[model_name]

    def _increment_generation(self, model_name):
        self._generations[model_name] = self._get_generation(model_name) + 1
        cache.set(f""generation:{model_name}"", self._generations[model_name], None)

    def _cached_iterator(self, queryset):
        cache_key = self._get_cache_key(queryset)
        cached_result = cache.get(cache_key)
        
        if cached_result is not None:
            for item in cached_result:
                yield item
        else:
            result = list(QueryCacheMiddleware._original_methods['queryset_iterator'](queryset))
            cache.set(cache_key, result, 300)  # Cache for 5 minutes
            for item in result:
                yield item

    def _cached_count(self, queryset):
        cache_key = self._get_cache_key(queryset) + "":count""
        cached_result = cache.get(cache_key)
        
        if cached_result is not None:
            return cached_result
        else:
            result = QueryCacheMiddleware._original_methods['queryset_count'](queryset)
            cache.set(cache_key, result, 300)
            return result

    def _cached_exists(self, queryset):
        cache_key = self._get_cache_key(queryset) + "":exists""
        cached_result = cache.get(cache_key)
        
        if cached_result is not None:
            return cached_result
        else:
            result = QueryCacheMiddleware._original_methods['queryset_exists'](queryset)
            cache.set(cache_key, result, 300)
            return result

    def _invalidating_save(self, model_instance, *args, **kwargs):
        result = QueryCacheMiddleware._original_methods['model_save'](model_instance, *args, **kwargs)
        self._increment_generation(model_instance._meta.label)
        return result

    def _invalidating_delete(self, model_instance, *args, **kwargs):
        result = QueryCacheMiddleware._original_methods['model_delete'](model_instance, *args, **kwargs)
        self._increment_generation(model_instance._meta.label)
        return result

    def _invalidate_model_cache(self, sender, **kwargs):
        if hasattr(sender, '_meta'):
            self._increment_generation(sender._meta.label)

    def unpatch(self):
        if not self._patched:
            return
            
        with self._lock:
            if not self._patched:
                return
                
            # Restore original methods
            QuerySet.__iter__ = self._original_methods['queryset_iterator']
            QuerySet.count = self._original_methods['queryset_count']
            QuerySet.exists = self._original_methods['queryset_exists']
            models.Model.save = self._original_methods['model_save']
            models.Model.delete = self._original_methods['model_delete']
            
            # Disconnect signals
            signals.post_save.disconnect(self._invalidate_model_cache)
            signals.post_delete.disconnect(self._invalidate_model_cache)
            
            self._patched = False",partial_docstr,0.4431818181818182,0.28,0.23563218390804597,0.375,0.2335972779066123,0.3493723849372385,0.22851153039832284,0.15966386554621848,0.755852997303009,0.8205206394195557,0.786860466003418,0.8135601282119751,0.7745437864077672,0.5321888412017167,0.38961038961038963,0.35807860262008734,0.4978540772532189,0.3688351123279377,0.6941176470588235,0.46745562130177515,0.36904761904761907,0.8554692268371582,0.8155723214149475,0.8350445628166199,0.8193937540054321,0.78591,0.2332361516034985,0.14912280701754385,0.12023460410557187,0.2099125364431487,0.1028907969446473,0.14947552447552448,0.10148731408573929,0.07180385288966724,0.7277007699012756,0.8294637799263,0.7752571105957031,0.8180243372917175,0.7101115037594007,0.3746807520438637,0.259699173624787,0.4214925286472689,0.5384615384615384,0.2790697674418604,0.3417850349085162,0.3561001864271123,0.3784818136720689,0.4,0.2325581395348837,0.3622533089247514,0.1220815907767703,0.4095792298954015,0.6615384615384615,0.2558139534883721
360903,edx/opaque-keys,edx_opaque-keys/opaque_keys/edx/django/models.py,opaque_keys.edx.django.models._Creator,"class _Creator:
    """"""
    DO NOT REUSE THIS CLASS. Provided for backwards compatibility only!

    A placeholder class that provides a way to set the attribute on the model.
    """"""

    def __init__(self, field):
        self.field = field

    def __get__(self, obj, type=None):  # pylint: disable=redefined-builtin
        if obj is None:
            return self  # pragma: no cover
        return obj.__dict__[self.field.name]

    def __set__(self, obj, value):
        obj.__dict__[self.field.name] = self.field.to_python(value)","class _Creator:
    '''
    DO NOT REUSE THIS CLASS. Provided for backwards compatibility only!

    A placeholder class that provides a way to set the attribute on the model.
    '''

    def __init__(self, field):
        pass

    def __get__(self, obj, type=None):
        pass

    def __set__(self, obj, value):
        pass

",4,1,snippet_258,1.0,"class _Creator:
    '''
    DO NOT REUSE THIS CLASS. Provided for backwards compatibility only!

    A placeholder class that provides a way to set the attribute on the model.
    '''

    def __init__(self, field):
        self.field = field

    def __get__(self, obj, type=None):
        return self

    def __set__(self, obj, value):
        setattr(obj, self.field.name, value)","class _Creator:
    '''
    DO NOT REUSE THIS CLASS. Provided for backwards compatibility only!

    A placeholder class that provides a way to set the attribute on the model.
    '''

    def __init__(self, field):
        self.field = field

    def __get__(self, obj, type=None):
        if obj is None:
            return self
        return obj.__dict__.get(self.field.name)

    def __set__(self, obj, value):
        obj.__dict__[self.field.name] = value","class _Creator:
    '''
    DO NOT REUSE THIS CLASS. Provided for backwards compatibility only!

    A placeholder class that provides a way to set the attribute on the model.
    '''

    def __init__(self, field):
        self.field = field

    def __get__(self, obj, type=None):
        if obj is None:
            return self
        return obj.__dict__[self.field.attname]

    def __set__(self, obj, value):
        obj.__dict__[self.field.attname] = self.field.to_python(value)",partial_docstr,0.8160000000000001,0.7479674796747967,0.6942148760330579,0.8160000000000001,0.524195969750709,0.9473684210526315,0.8723404255319149,0.8064516129032258,0.9704872369766235,0.8762024641036987,0.9209378957748413,0.8847984075546265,0.8755567999999999,0.9117647058823529,0.8507462686567164,0.803030303030303,0.9117647058823529,0.7498310392298588,0.9752066115702479,0.8916666666666667,0.8403361344537815,0.9876405000686646,0.9113478660583496,0.9479616284370422,0.9184426069259644,0.9422227999999999,0.920863309352518,0.8613138686131386,0.8,0.920863309352518,0.8176687027626032,0.96875,0.9212598425196851,0.873015873015873,0.9833464622497559,0.9231585264205933,0.9523024559020996,0.9288436770439148,0.9911112000000001,0.5882734755504062,0.5777574071510446,0.5924793521934374,0.5428571428571428,0.64,0.6845019780243353,0.6913011277172157,0.7095639272372682,0.6571428571428571,0.68,0.8383210426266021,0.6678208367638477,0.6854633337425607,1.0,1.0
502011,itamarst/crochet,itamarst_crochet/crochet/_shutdown.py,crochet._shutdown.FunctionRegistry,"class FunctionRegistry(object):
    """"""
    A registry of functions that can be called all at once.
    """"""

    def __init__(self):
        self._functions = []

    def register(self, f, *args, **kwargs):
        """"""
        Register a function and arguments to be called later.
        """"""
        self._functions.append(lambda: f(*args, **kwargs))

    def run(self):
        """"""
        Run all registered functions in reverse order of registration.
        """"""
        for f in reversed(self._functions):
            try:
                f()
            except Exception:
                log.err()","class FunctionRegistry(object):
    '''
    A registry of functions that can be called all at once.
    '''

    def __init__(self):
        pass

    def register(self, f, *args, **kwargs):
    '''
        Register a function and arguments to be called later.
        '''
        pass

    def run(self):
    '''
        Run all registered functions in reverse order of registration.
        '''
        pass

",4,3,snippet_174,0.8888888888888888,"class FunctionRegistry(object):
    '''
    A registry of functions that can be called all at once.
    '''

    def __init__(self):
        self._registry = []

    def register(self, f, *args, **kwargs):
        '''
        Register a function and arguments to be called later.
        '''
        if not callable(f):
            raise TypeError(""First argument must be callable"")
        self._registry.append((f, args, kwargs))

    def run(self):
        '''
        Run all registered functions in reverse order of registration.
        '''
        for func, args, kwargs in reversed(self._registry):
            func(*args, **kwargs)","class FunctionRegistry(object):
    '''
    A registry of functions that can be called all at once.
    '''

    def __init__(self):
        self._functions = []

    def register(self, f, *args, **kwargs):
        '''
        Register a function and arguments to be called later.
        '''
        self._functions.append((f, args, kwargs))

    def run(self):
        '''
        Run all registered functions in reverse order of registration.
        '''
        for f, args, kwargs in reversed(self._functions):
            f(*args, **kwargs)","class FunctionRegistry(object):
    '''
    A registry of functions that can be called all at once.
    '''

    def __init__(self):
        self._functions = []

    def register(self, f, *args, **kwargs):
        '''
        Register a function and arguments to be called later.
        '''
        self._functions.append((f, args, kwargs))

    def run(self):
        '''
        Run all registered functions in reverse order of registration.
        '''
        for f, args, kwargs in reversed(self._functions):
            f(*args, **kwargs)",partial_docstr,0.7913669064748202,0.7007299270072993,0.6518518518518519,0.7769784172661871,0.6503183235412128,0.7785714285714286,0.6330935251798561,0.5579710144927537,0.9081714153289795,0.935886561870575,0.9218207001686096,0.9330391883850098,0.8687956382978722,0.9218749999999999,0.8730158730158729,0.8387096774193549,0.9218749999999999,0.7047307180880045,0.8852459016393442,0.8016528925619835,0.7333333333333333,0.9739071726799011,0.9585771560668945,0.9661812782287598,0.9600883722305298,0.9157096551724139,0.9218749999999999,0.8730158730158729,0.8387096774193549,0.9218749999999999,0.7047307180880045,0.8852459016393442,0.8016528925619835,0.7333333333333333,0.9739071726799011,0.9585771560668945,0.9661812782287598,0.9600883722305298,0.9157096551724139,0.5897045414414246,0.4725832373711035,0.547346039505706,0.4888888888888889,0.85,0.6307041093956838,0.5879453486873466,0.5959822000064995,0.4888888888888889,0.85,0.6307041093956838,0.5879453486873466,0.5959822000064995,0.4888888888888889,0.85
259417,bearyinnovative/bearychat.py,bearyinnovative_bearychat.py/bearychat/rtm_client.py,bearychat.rtm_client.RTMClient,"class RTMClient(object):
    """"""Real Time Message client

    Attributes:
        current_team(RTMCurrentTeam): service of current team
        user(RTMUser): service of current user
        channel(RTMChannel): service of current channel
    """"""

    def __init__(self, token, api_base=""https://rtm.bearychat.com""):
        """"""
        Args:
            token(str): rtm token
            api_base(str): api url base
        """"""
        self._token = token
        self._api_base = api_base
        self.current_team = RTMCurrentTeam(self)
        self.user = RTMUser(self)
        self.channel = RTMChannel(self)

    def start(self):
        """"""Gets the rtm ws_host and user information

        Returns:
            None if request failed,
            else a dict containing ""user""(User) and ""ws_host""
        """"""
        resp = self.post('start')

        if resp.is_fail():
            return None
        if 'result' not in resp.data:
            return None

        result = resp.data['result']
        return {
            'user': result['user'],
            'ws_host': result['ws_host'],
        }

    def do(self,
           resource,
           method,
           params=None,
           data=None,
           json=None,
           headers=None):
        """"""Does the request job

        Args:
            resource(str): resource uri(relative path)
            method(str): HTTP method
            params(dict): uri queries
            data(dict): HTTP body(form)
            json(dict): HTTP body(json)
            headers(dict): HTTP headers

        Returns:
            RTMResponse
        """"""
        uri = ""{0}/{1}"".format(self._api_base, resource)
        if not params:
            params = {}
        params.update({'token': self._token})

        req = Request(
            method=method,
            url=uri,
            params=params,
            headers=headers,
            data=data,
            json=json)
        s = Session()
        prepped = s.prepare_request(req)
        resp = s.send(prepped)

        return RTMResponse(resp)

    def get(self, resource, params=None, headers=None):
        """"""Sends a GET request

        Returns:
            RTMResponse
        """"""
        return self.do(resource, 'GET', params=params, headers=headers)

    def post(self, resource, data=None, json=None):
        """"""Sends a POST request

        Returns:
            RTMResponse
        """"""
        return self.do(resource, 'POST', data=data, json=json)","class RTMClient(object):
    '''Real Time Message client

    Attributes:
        current_team(RTMCurrentTeam): service of current team
        user(RTMUser): service of current user
        channel(RTMChannel): service of current channel
    '''

    def __init__(self, token, api_base=""https://rtm.bearychat.com""):
    '''
        Args:
            token(str): rtm token
            api_base(str): api url base
        '''
        pass

    def start(self):
    '''Gets the rtm ws_host and user information

        Returns:
            None if request failed,
            else a dict containing ""user""(User) and ""ws_host""
        '''
        pass

    def do(self,
           resource,
           method,
           params=None,
           data=None,
           json=None,
           headers=None):
    '''Does the request job

        Args:
            resource(str): resource uri(relative path)
            method(str): HTTP method
            params(dict): uri queries
            data(dict): HTTP body(form)
            json(dict): HTTP body(json)
            headers(dict): HTTP headers

        Returns:
            RTMResponse
        '''
        pass

    def get(self, resource, params=None, headers=None):
    '''Sends a GET request

        Returns:
            RTMResponse
        '''
        pass

    def post(self, resource, data=None, json=None):
    '''Sends a POST request

        Returns:
            RTMResponse
        '''
        pass

",6,6,snippet_436,0.2727272727272727,"class RTMClient(object):
    '''Real Time Message client

    Attributes:
        current_team(RTMCurrentTeam): service of current team
        user(RTMUser): service of current user
        channel(RTMChannel): service of current channel
    '''

    def __init__(self, token, api_base=""https://rtm.bearychat.com""):
        '''
        Args:
            token(str): rtm token
            api_base(str): api url base
        '''
        self.token = token
        self.api_base = api_base.rstrip('/')
        self.session = requests.Session()
        self.current_team = RTMCurrentTeam(self)
        self.user = RTMUser(self)
        self.channel = RTMChannel(self)

    def start(self):
        '''Gets the rtm ws_host and user information

        Returns:
            None if request failed,
            else a dict containing ""user""(User) and ""ws_host""
        '''
        resp = self.get(""rtm.start"")
        if not getattr(resp, ""ok"", False):
            return None
        body = resp.json()
        return {
            ""user"": body.get(""user""),
            ""ws_host"": body.get(""ws_host"")
        }

    def do(self,
           resource,
           method,
           params=None,
           data=None,
           json=None,
           headers=None):
        '''Does the request job

        Args:
            resource(str): resource uri(relative path)
            method(str): HTTP method
            params(dict): uri queries
            data(dict): HTTP body(form)
            json(dict): HTTP body(json)
            headers(dict): HTTP headers

        Returns:
            RTMResponse
        '''
        url = ""{}/{}"".format(self.api_base, resource.lstrip('/'))
        params = {} if params is None else dict(params)
        params['token'] = self.token
        hdrs = {} if headers is None else dict(headers)
        r = self.session.request(method.upper(), url,
                                 params=params,
                                 data=data,
                                 json=json,
                                 headers=hdrs)
        return RTMResponse(r)

    def get(self, resource, params=None, headers=None):
        '''Sends a GET request

        Returns:
            RTMResponse
        '''
        return self.do(resource, ""GET"", params=params, headers=headers)

    def post(self, resource, data=None, json=None):
        '''Sends a POST request

        Returns:
            RTMResponse
        '''
        return self.do(resource, ""POST"", data=data, json=json)","class RTMClient(object):
    '''Real Time Message client

    Attributes:
        current_team(RTMCurrentTeam): service of current team
        user(RTMUser): service of current user
        channel(RTMChannel): service of current channel
    '''

    def __init__(self, token, api_base=""https://rtm.bearychat.com""):
        '''
        Args:
            token(str): rtm token
            api_base(str): api url base
        '''
        self.token = token
        self.api_base = api_base
        self.current_team = RTMCurrentTeam()
        self.user = RTMUser()
        self.channel = RTMChannel()

    def start(self):
        '''Gets the rtm ws_host and user information

        Returns:
            None if request failed,
            else a dict containing ""user""(User) and ""ws_host""
        '''
        try:
            response = self.post(""/start"")
            if response.status_code == 200:
                return response.data
            return None
        except:
            return None

    def do(self,
           resource,
           method,
           params=None,
           data=None,
           json=None,
           headers=None):
        '''Does the request job

        Args:
            resource(str): resource uri(relative path)
            method(str): HTTP method
            params(dict): uri queries
            data(dict): HTTP body(form)
            json(dict): HTTP body(json)
            headers(dict): HTTP headers

        Returns:
            RTMResponse
        '''
        url = self.api_base + resource
        if headers is None:
            headers = {}
        headers['Authorization'] = f'Bearer {self.token}'
        
        try:
            response = requests.request(
                method=method,
                url=url,
                params=params,
                data=data,
                json=json,
                headers=headers
            )
            return RTMResponse(response.status_code, response.json() if response.content else None)
        except Exception as e:
            return RTMResponse(0, None)

    def get(self, resource, params=None, headers=None):
        '''Sends a GET request

        Returns:
            RTMResponse
        '''
        return self.do(resource, 'GET', params=params, headers=headers)

    def post(self, resource, data=None, json=None):
        '''Sends a POST request

        Returns:
            RTMResponse
        '''
        return self.do(resource, 'POST', data=data, json=json)","class RTMClient(object):
    '''Real Time Message client

    Attributes:
        current_team(RTMCurrentTeam): service of current team
        user(RTMUser): service of current user
        channel(RTMChannel): service of current channel
    '''

    def __init__(self, token, api_base=""https://rtm.bearychat.com""):
        '''
        Args:
            token(str): rtm token
            api_base(str): api url base
        '''
        self.token = token
        self.api_base = api_base
        self.current_team = RTMCurrentTeam(self)
        self.user = RTMUser(self)
        self.channel = RTMChannel(self)

    def start(self):
        '''Gets the rtm ws_host and user information

        Returns:
            None if request failed,
            else a dict containing ""user""(User) and ""ws_host""
        '''
        response = self.get(""/start"")
        if response.status_code == 200:
            return response.json()
        return None

    def do(self,
           resource,
           method,
           params=None,
           data=None,
           json=None,
           headers=None):
        '''Does the request job

        Args:
            resource(str): resource uri(relative path)
            method(str): HTTP method
            params(dict): uri queries
            data(dict): HTTP body(form)
            json(dict): HTTP body(json)
            headers(dict): HTTP headers

        Returns:
            RTMResponse
        '''
        url = self.api_base + resource
        if headers is None:
            headers = {}
        headers['Authorization'] = f'Bearer {self.token}'
        
        response = requests.request(
            method=method,
            url=url,
            params=params,
            data=data,
            json=json,
            headers=headers
        )
        return RTMResponse(response)

    def get(self, resource, params=None, headers=None):
        '''Sends a GET request

        Returns:
            RTMResponse
        '''
        return self.do(resource, 'GET', params=params, headers=headers)

    def post(self, resource, data=None, json=None):
        '''Sends a POST request

        Returns:
            RTMResponse
        '''
        return self.do(resource, 'POST', data=data, json=json)",partial_docstr,0.8809073724007562,0.7855787476280834,0.7276190476190476,0.8582230623818525,0.7103594758976749,0.8571428571428571,0.6946564885496184,0.6195028680688337,0.9491294622421265,0.9522444009780884,0.9506843686103821,0.9519320130348206,0.8879153508771931,0.8439306358381502,0.7775628626692457,0.7184466019417476,0.8208092485549133,0.6727185174718296,0.8927038626609443,0.7591397849462366,0.6788793103448276,0.9433234930038452,0.9413111209869385,0.9423162341117859,0.9415120482444763,0.8932937500000001,0.8680000000000001,0.8072289156626505,0.7620967741935484,0.852,0.6604974750377329,0.9241379310344827,0.8110599078341014,0.7413394919168591,0.9457986950874329,0.9290968179702759,0.9373733401298523,0.930740475654602,0.9004075,0.5497390422832447,0.5425023909171967,0.5555133393443086,0.6827586206896552,0.4181818181818181,0.6752018116397006,0.5285114994783316,0.5378129884597812,0.6344827586206897,0.0,0.7068229214436058,0.5597963864817167,0.5640470234306377,0.7034482758620689,0.0
352010,dr4ke616/pinky,dr4ke616_pinky/pinky/core/hash.py,pinky.core.hash.ConsistentHash,"class ConsistentHash(object):
    """""" ConsistentHash(n,r) creates a consistent hash object for a
        cluster of size n, using r replicas.

        It has three attributes. num_machines and num_replics are
        self-explanatory.  hash_tuples is a list of tuples (j,k,hash),
        where j ranges over machine numbers (0...n-1), k ranges over
        replicas (0...r-1), and hash is the corresponding hash value,
        in the range [0,1).  The tuples are sorted by increasing hash
        value.

        The class has a single instance method, get_machine(key), which
        returns the number of the machine to which key should be
        mapped.
    """"""

    def __init__(self, num_machines=1, num_replicas=1):
        self.num_machines = num_machines
        self.num_replicas = num_replicas
        hash_tuples = [
            (j, k, self.hash(str(j)+""_""+str(k)))
            for j in range(self.num_machines)
            for k in range(self.num_replicas)
        ]

        # Sort the hash tuples based on just the hash values
        hash_tuples.sort(lambda x, y: cmp(x[2], y[2]))
        self.hash_tuples = hash_tuples

    def get_machine(self, key):
        """""" Returns the number of the machine which key gets sent to.
        """"""
        h = self.hash(key)

        # edge case where we cycle past hash value of 1 and back to 0.
        if h > self.hash_tuples[-1][2]:
            return self.hash_tuples[0][0]

        hash_values = map(lambda x: x[2], self.hash_tuples)
        index = bisect.bisect_left(hash_values, h)
        return self.hash_tuples[index][0]

    @classmethod
    def hash(cls, key):
        """""" hash(key) returns a hash in the range [0,1)
        """"""
        return (int(hashlib.md5(key).hexdigest(), 16) % 1000000)/1000000.0","class ConsistentHash(object):
    ''' ConsistentHash(n,r) creates a consistent hash object for a
        cluster of size n, using r replicas.

        It has three attributes. num_machines and num_replics are
        self-explanatory.  hash_tuples is a list of tuples (j,k,hash),
        where j ranges over machine numbers (0...n-1), k ranges over
        replicas (0...r-1), and hash is the corresponding hash value,
        in the range [0,1).  The tuples are sorted by increasing hash
        value.

        The class has a single instance method, get_machine(key), which
        returns the number of the machine to which key should be
        mapped.
    '''

    def __init__(self, num_machines=1, num_replicas=1):
        pass

    def get_machine(self, key):
    ''' Returns the number of the machine which key gets sent to.
        '''
        pass

    @classmethod
    def hash(cls, key):
    ''' hash(key) returns a hash in the range [0,1)
        '''
        pass

",5,3,snippet_210,0.6666666666666666,"class ConsistentHash(object):
    ''' ConsistentHash(n,r) creates a consistent hash object for a
        cluster of size n, using r replicas.

        It has three attributes. num_machines and num_replics are
        self-explanatory.  hash_tuples is a list of tuples (j,k,hash),
        where j ranges over machine numbers (0...n-1), k ranges over
        replicas (0...r-1), and hash is the corresponding hash value,
        in the range [0,1).  The tuples are sorted by increasing hash
        value.

        The class has a single instance method, get_machine(key), which
        returns the number of the machine to which key should be
        mapped.
    '''

    def __init__(self, num_machines=1, num_replicas=1):
        self.num_machines = num_machines
        self.num_replicas = num_replicas
        # build and sort all (machine, replica, hash) tuples
        self.hash_tuples = []
        for j in range(self.num_machines):
            for k in range(self.num_replicas):
                h = self.hash(f""{j}-{k}"")
                self.hash_tuples.append((j, k, h))
        self.hash_tuples.sort(key=lambda t: t[2])
        # extract sorted hash list for bisection
        self._sorted_hashes = [t[2] for t in self.hash_tuples]

    def get_machine(self, key):
        ''' Returns the number of the machine which key gets sent to.
        '''
        h_key = self.hash(key)
        idx = bisect.bisect_left(self._sorted_hashes, h_key)
        if idx == len(self._sorted_hashes):
            idx = 0
        machine, _, _ = self.hash_tuples[idx]
        return machine

    @classmethod
    def hash(cls, key):
        ''' hash(key) returns a hash in the range [0,1)
        '''
        # normalize key to bytes
        if isinstance(key, bytes):
            key_bytes = key
        elif isinstance(key, str):
            key_bytes = key.encode('utf-8')
        else:
            key_bytes = str(key).encode('utf-8')
        # compute MD5 digest and map to [0,1)
        digest = hashlib.md5(key_bytes).digest()
        intval = int.from_bytes(digest, byteorder='big')
        return intval / float(1 << (8 * len(digest)))","class ConsistentHash(object):
    ''' ConsistentHash(n,r) creates a consistent hash object for a
        cluster of size n, using r replicas.

        It has three attributes. num_machines and num_replicas are
        self-explanatory.  hash_tuples is a list of tuples (j,k,hash),
        where j ranges over machine numbers (0...n-1), k ranges over
        replicas (0...r-1), and hash is the corresponding hash value,
        in the range [0,1).  The tuples are sorted by increasing hash
        value.

        The class has a single instance method, get_machine(key), which
        returns the number of the machine to which key should be
        mapped.
    '''

    def __init__(self, num_machines=1, num_replicas=1):
        self.num_machines = num_machines
        self.num_replicas = num_replicas
        self.hash_tuples = []
        
        for j in range(num_machines):
            for k in range(num_replicas):
                hash_value = self.hash(f""{j},{k}"")
                self.hash_tuples.append((j, k, hash_value))
        
        self.hash_tuples.sort(key=lambda x: x[2])

    def get_machine(self, key):
        ''' Returns the number of the machine which key gets sent to.
        '''
        if not self.hash_tuples:
            return None
            
        key_hash = self.hash(key)
        
        # Binary search for the first hash >= key_hash
        left, right = 0, len(self.hash_tuples)
        while left < right:
            mid = (left + right) // 2
            if self.hash_tuples[mid][2] < key_hash:
                left = mid + 1
            else:
                right = mid
        
        # If we've gone past the end, wrap around to the beginning
        if left == len(self.hash_tuples):
            left = 0
            
        return self.hash_tuples[left][0]

    @classmethod
    def hash(cls, key):
        ''' hash(key) returns a hash in the range [0,1)
        '''
        from hashlib import md5
        return int(md5(key.encode()).hexdigest(), 16) / (2**128)","class ConsistentHash(object):
    ''' ConsistentHash(n,r) creates a consistent hash object for a
        cluster of size n, using r replicas.

        It has three attributes. num_machines and num_replics are
        self-explanatory.  hash_tuples is a list of tuples (j,k,hash),
        where j ranges over machine numbers (0...n-1), k ranges over
        replicas (0...r-1), and hash is the corresponding hash value,
        in the range [0,1).  The tuples are sorted by increasing hash
        value.

        The class has a single instance method, get_machine(key), which
        returns the number of the machine to which key should be
        mapped.
    '''

    def __init__(self, num_machines=1, num_replicas=1):
        self.num_machines = num_machines
        self.num_replicas = num_replicas
        self.hash_tuples = []
        
        for j in range(num_machines):
            for k in range(num_replicas):
                hash_key = f""{j}:{k}""
                hash_value = self.hash(hash_key)
                self.hash_tuples.append((j, k, hash_value))
        
        self.hash_tuples.sort(key=lambda x: x[2])

    def get_machine(self, key):
        ''' Returns the number of the machine which key gets sent to.
        '''
        if not self.hash_tuples:
            return 0
            
        key_hash = self.hash(key)
        hash_values = [t[2] for t in self.hash_tuples]
        
        idx = bisect.bisect_right(hash_values, key_hash)
        if idx == len(self.hash_tuples):
            idx = 0
            
        return self.hash_tuples[idx][0]

    @classmethod
    def hash(cls, key):
        ''' hash(key) returns a hash in the range [0,1)
        '''
        key_str = str(key)
        hash_obj = hashlib.md5(key_str.encode('utf-8'))
        hash_int = int(hash_obj.hexdigest(), 16)
        return hash_int / (2**128)",partial_docstr,0.773851590106007,0.6631205673758866,0.6156583629893239,0.6855123674911662,0.6082907245030835,0.7241379310344828,0.5834932821497121,0.5326923076923077,0.8868275284767151,0.926223874092102,0.9060976505279541,0.9221274256706238,0.7773873851590106,0.8413284132841329,0.6814814814814815,0.6022304832713756,0.7453874538745389,0.6906054882227665,0.8343949044585988,0.6659574468085107,0.5927505330490405,0.9077795743942261,0.9208851456642151,0.9142853617668152,0.9195576310157776,0.8146629875518672,0.8560606060606061,0.7110266159695817,0.6259541984732824,0.7651515151515152,0.7205425646103895,0.8458149779735683,0.7130242825607064,0.6327433628318584,0.9380413293838501,0.9340722560882568,0.9360525608062744,0.934467613697052,0.7965388311688312,0.5484710252060147,0.5048860887858199,0.5995282584908154,0.5048543689320388,0.5846153846153846,0.5501620837172411,0.5249559339007691,0.5902555077643118,0.4854368932038835,0.6,0.5828172649071965,0.5843841013312565,0.5975197603886425,0.5339805825242718,0.6153846153846154
338304,devision-io/metasdk,devision-io_metasdk/metasdk/services/MailService.py,metasdk.services.MailService.MailService,"class MailService:
    def __init__(self, app):
        """"""
        :type app: metasdk.MetaApp
        """"""
        self.__app = app
        self.__options = {}
        self.__data_get_cache = {}
        self.__metadb = app.db(""meta"")
        self.log = app.log

    def submit_mail(self, send_from, send_to, subject, body, unique_id=None):
        """"""
             
        :param send_from: 
        :param send_to: 
        :param subject:  
        :param body:  .   HTML
        :param unique_id:   .  -  md5 +     .    unique_id   
        """"""
        self.__metadb.update(""""""
        INSERT INTO meta.mail(""template"", ""from"", ""to"", ""subject"", ""body"", ""attachments"", ""unique_id"")
        VALUES ('meta', :send_from, :send_to, :subject, :body, null, :unique_id)
        ON CONFLICT (unique_id) DO NOTHING
        """""", {
            ""send_from"": send_from,
            ""send_to"": send_to,
            ""subject"": subject,
            ""body"": body,
            ""unique_id"": unique_id
        })","class MailService:


    def __init__(self, app):
    '''
        :type app: metasdk.MetaApp
        '''
        pass

    def submit_mail(self, send_from, send_to, subject, body, unique_id=None):
    '''
             
        :param send_from: 
        :param send_to: 
        :param subject:  
        :param body:  .   HTML
        :param unique_id:   .  -  md5 +     .    unique_id   
        '''
        pass

",3,2,snippet_525,0.75,"class MailService:
    def __init__(self, app):
        """"""
            :type app: metasdk.MetaApp
        """"""
        self.app = app
        self._coll = app.db['mail_queue']
        self._coll.create_index('unique_id', unique=True, sparse=True)

    def submit_mail(self, send_from, send_to, subject, body, unique_id=None):
        """"""
                 
            :param send_from: 
            :param send_to: 
            :param subject:  
            :param body:  .   HTML
            :param unique_id:   .  -  md5 +     .    unique_id   
        """"""
        doc = {
            'send_from': send_from,
            'send_to': send_to,
            'subject': subject,
            'body': body,
            'created_at': datetime.utcnow()
        }
        if unique_id is not None:
            doc['unique_id'] = unique_id
        try:
            result = self._coll.insert_one(doc)
        except DuplicateKeyError:
            return
        return result.inserted_id","class MailService:
    def __init__(self, app):
        '''
        :type app: metasdk.MetaApp
        '''
        self.app = app
        self.sent_mails = set()

    def submit_mail(self, send_from, send_to, subject, body, unique_id=None):
        '''
             
        :param send_from: 
        :param send_to: 
        :param subject:  
        :param body:  .   HTML
        :param unique_id:   .  -  md5 +     .    unique_id   
        '''
        if unique_id is not None:
            if unique_id in self.sent_mails:
                return False
            self.sent_mails.add(unique_id)
        
        # Here you would typically add the mail to a queue or send it via SMTP
        # For now, we'll just simulate the action
        mail_data = {
            'from': send_from,
            'to': send_to,
            'subject': subject,
            'body': body,
            'unique_id': unique_id
        }
        
        # Simulate adding to queue or sending
        # In a real implementation, this might involve:
        # - Adding to a message queue (RabbitMQ, Redis, etc.)
        # - Sending via SMTP
        # - Calling an external mail service API
        
        return True","class MailService:
    def __init__(self, app):
        '''
        :type app: metasdk.MetaApp
        '''
        self.app = app
        self.mail_queue = []
        self.sent_unique_ids = set()

    def submit_mail(self, send_from, send_to, subject, body, unique_id=None):
        '''
             
        :param send_from: 
        :param send_to: 
        :param subject:  
        :param body:  .   HTML
        :param unique_id:   .  -  md5 +     .    unique_id   
        '''
        if unique_id is None:
            unique_id = hashlib.md5(f""{send_from}{send_to}{subject}{body}{time.time()}"".encode()).hexdigest()
        
        if unique_id in self.sent_unique_ids:
            return False
        
        mail_data = {
            'send_from': send_from,
            'send_to': send_to,
            'subject': subject,
            'body': body,
            'unique_id': unique_id
        }
        
        self.mail_queue.append(mail_data)
        self.sent_unique_ids.add(unique_id)
        return True",partial_docstr,0.6956521739130435,0.5756097560975609,0.5123152709359606,0.6086956521739131,0.5262289667284848,0.8089430894308943,0.6408163265306123,0.5860655737704918,0.9392794370651245,0.9470956921577454,0.9431713819503784,0.9463081955909729,0.8286402112676057,0.5795918367346938,0.4773662551440329,0.41493775933609955,0.5306122448979591,0.4871271968099062,0.6826568265682657,0.5333333333333333,0.4684014869888476,0.8725636005401611,0.9075971245765686,0.8897356390953064,0.9039676189422607,0.8260886956521738,0.709090909090909,0.6055045871559633,0.5462962962962964,0.6545454545454544,0.5330512396458796,0.7802197802197802,0.5735294117647058,0.4870848708487085,0.9238864183425903,0.9229271411895752,0.9234065413475037,0.923022985458374,0.8061021568627451,0.5634083627907408,0.5607900840108443,0.5696385296615669,0.5306122448979592,0.5925925925925926,0.4815738006386657,0.354434433807719,0.5023218420651601,0.5510204081632653,0.5185185185185185,0.5271256328736733,0.4965694103075286,0.5053571574683434,0.5510204081632653,0.5555555555555556
494753,indranilsinharoy/pyzos,indranilsinharoy_pyzos/pyzos/zosutils.py,pyzos.zosutils.ZOSPropMapper,"class ZOSPropMapper(object):
    """"""Descriptor for mapping ZOS object properties to corresponding wrapper classes
    """"""
    def __init__(self, zos_interface_attr, property_name, setter=False, cast_to=None):
        """"""
        @param zos_interface_attr : attribute used to dispatch method/property calls to 
        the zos_object (it hold the zos_object)
        @param propname : string, like 'SystemName' for IOpticalSystem
        @param setter : if False, a read-only data descriptor is created
        @param cast_to : Name of class (generally the base class) whose property to call
        """"""
        self.property_name = property_name  # property_name is a string like 'SystemName' for IOpticalSystem
        self.zos_interface_attr = zos_interface_attr  
        self.setter = setter
        self.cast_to = cast_to

    def __get__(self, obj, objtype):
        if self.cast_to:   
            return wrapped_zos_object(getattr(_CastTo(obj.__dict__[self.zos_interface_attr], self.cast_to), self.property_name))
        else:
            return wrapped_zos_object(getattr(obj.__dict__[self.zos_interface_attr], self.property_name))
    
    def __set__(self, obj, value):
        if self.setter:
            if self.cast_to:
                setattr(_CastTo(obj.__dict__[self.zos_interface_attr], self.cast_to), self.property_name, value)
            else:
                setattr(obj.__dict__[self.zos_interface_attr], self.property_name, value)
        else:
            raise AttributeError(""Can't set {}"".format(self.property_name))","class ZOSPropMapper(object):
    '''Descriptor for mapping ZOS object properties to corresponding wrapper classes
    '''

    def __init__(self, zos_interface_attr, property_name, setter=False, cast_to=None):
    '''
        @param zos_interface_attr : attribute used to dispatch method/property calls to 
        the zos_object (it hold the zos_object)
        @param propname : string, like 'SystemName' for IOpticalSystem
        @param setter : if False, a read-only data descriptor is created
        @param cast_to : Name of class (generally the base class) whose property to call
        '''
        pass

    def __get__(self, obj, objtype):
        pass

    def __set__(self, obj, value):
        pass

",4,2,snippet_626,1.0,"class ZOSPropMapper(object):
    '''Descriptor for mapping ZOS object properties to corresponding wrapper classes
    '''

    def __init__(self, zos_interface_attr, property_name, setter=False, cast_to=None):
        self.zos_interface_attr = zos_interface_attr
        self.property_name = property_name
        self.setter = setter
        self.cast_to = cast_to

    def __get__(self, obj, objtype):
        if obj is None:
            return self
        iface = getattr(obj, self.cast_to) if self.cast_to else getattr(obj, self.zos_interface_attr)
        return getattr(iface, self.property_name)

    def __set__(self, obj, value):
        if not self.setter:
            raise AttributeError(""can't set attribute"")
        iface = getattr(obj, self.cast_to) if self.cast_to else getattr(obj, self.zos_interface_attr)
        setattr(iface, self.property_name, value)","class ZOSPropMapper(object):
    '''Descriptor for mapping ZOS object properties to corresponding wrapper classes
    '''

    def __init__(self, zos_interface_attr, property_name, setter=False, cast_to=None):
        '''
        @param zos_interface_attr : attribute used to dispatch method/property calls to 
        the zos_object (it hold the zos_object)
        @param propname : string, like 'SystemName' for IOpticalSystem
        @param setter : if False, a read-only data descriptor is created
        @param cast_to : Name of class (generally the base class) whose property to call
        '''
        self.zos_interface_attr = zos_interface_attr
        self.property_name = property_name
        self.setter = setter
        self.cast_to = cast_to

    def __get__(self, obj, objtype):
        if obj is None:
            return self
        zos_interface = getattr(obj, self.zos_interface_attr)
        if self.cast_to:
            zos_interface = getattr(zos_interface, self.cast_to)
        return getattr(zos_interface, self.property_name)

    def __set__(self, obj, value):
        if not self.setter:
            raise AttributeError(""can't set attribute"")
        zos_interface = getattr(obj, self.zos_interface_attr)
        if self.cast_to:
            zos_interface = getattr(zos_interface, self.cast_to)
        setattr(zos_interface, self.property_name, value)","class ZOSPropMapper(object):
    '''Descriptor for mapping ZOS object properties to corresponding wrapper classes
    '''

    def __init__(self, zos_interface_attr, property_name, setter=False, cast_to=None):
        '''
        @param zos_interface_attr : attribute used to dispatch method/property calls to 
        the zos_object (it hold the zos_object)
        @param propname : string, like 'SystemName' for IOpticalSystem
        @param setter : if False, a read-only data descriptor is created
        @param cast_to : Name of class (generally the base class) whose property to call
        '''
        self.zos_interface_attr = zos_interface_attr
        self.property_name = property_name
        self.setter = setter
        self.cast_to = cast_to

    def __get__(self, obj, objtype):
        if obj is None:
            return self
        
        zos_obj = getattr(obj, self.zos_interface_attr)
        
        if self.cast_to:
            zos_obj = self.cast_to(zos_obj)
        
        return getattr(zos_obj, self.property_name)

    def __set__(self, obj, value):
        if not self.setter:
            raise AttributeError(""can't set attribute"")
        
        zos_obj = getattr(obj, self.zos_interface_attr)
        
        if self.cast_to:
            zos_obj = self.cast_to(zos_obj)
        
        setattr(zos_obj, self.property_name, value)",partial_docstr,0.6835443037974683,0.5222929936305732,0.43589743589743585,0.569620253164557,0.36502687294275116,0.9315068493150684,0.7889908256880734,0.6866359447004609,0.902535080909729,0.8390834331512451,0.8696534037590027,0.8450242280960083,0.8425941666666665,0.8563829787234042,0.748663101604278,0.6666666666666666,0.7553191489361702,0.6291753759997726,0.9166666666666666,0.797427652733119,0.7161290322580646,0.9596836566925049,0.9468181133270264,0.9532074928283691,0.948089063167572,0.8388905,0.8556149732620321,0.7311827956989247,0.654054054054054,0.748663101604278,0.6141802368507414,0.9188311688311688,0.7882736156351792,0.7058823529411765,0.9596468210220337,0.9469242095947266,0.9532430768013,0.9481812119483948,0.8388905,0.4285815483150418,0.2058370241979164,0.255783541356623,0.4431818181818182,0.8095238095238095,0.6244302489228576,0.6176554793748404,0.643232904483978,0.4431818181818182,0.7936507936507936,0.6268912215151635,0.6274993697440644,0.643232904483978,0.4431818181818182,0.7936507936507936
285431,census-instrumentation/opencensus-python,census-instrumentation_opencensus-python/opencensus/stats/aggregation.py,opencensus.stats.aggregation.SumAggregation,"class SumAggregation(object):
    """"""Sum Aggregation describes that data collected and aggregated with this
    method will be summed

    :type sum: int or float
    :param sum: the initial sum to be used in the aggregation

    """"""
    def __init__(self, sum=None):
        self._initial_sum = sum or 0

    def new_aggregation_data(self, measure):
        """"""Get a new AggregationData for this aggregation.""""""
        value_type = MetricDescriptorType.to_type_class(
            self.get_metric_type(measure))
        return aggregation_data.SumAggregationData(
            value_type=value_type, sum_data=self._initial_sum)

    @staticmethod
    def get_metric_type(measure):
        """"""Get the MetricDescriptorType for the metric produced by this
        aggregation and measure.
        """"""
        if isinstance(measure, measure_module.MeasureInt):
            return MetricDescriptorType.CUMULATIVE_INT64
        if isinstance(measure, measure_module.MeasureFloat):
            return MetricDescriptorType.CUMULATIVE_DOUBLE
        raise ValueError","class SumAggregation(object):
    '''Sum Aggregation describes that data collected and aggregated with this
    method will be summed

    :type sum: int or float
    :param sum: the initial sum to be used in the aggregation

    '''

    def __init__(self, sum=None):
        pass

    def new_aggregation_data(self, measure):
    '''Get a new AggregationData for this aggregation.'''
        pass

    @staticmethod
    def get_metric_type(measure):
    '''Get the MetricDescriptorType for the metric produced by this
        aggregation and measure.
        '''
        pass

",5,3,snippet_798,0.5555555555555556,"class SumAggregation(object):
    '''Sum Aggregation describes that data collected and aggregated with this
    method will be summed

    :type sum: int or float
    :param sum: the initial sum to be used in the aggregation
    '''

    def __init__(self, sum=None):
        self._initial_sum = sum if sum is not None else 0

    def new_aggregation_data(self, measure):
        '''Get a new AggregationData for this aggregation.'''
        return SumData(self._initial_sum)

    @staticmethod
    def get_metric_type(measure):
        '''Get the MetricDescriptorType for the metric produced by this
        aggregation and measure.
        '''
        if measure.value_type == MeasureType.DOUBLE:
            return MetricDescriptorType.CUMULATIVE_DOUBLE
        return MetricDescriptorType.CUMULATIVE_INT64","class SumAggregation(object):
    '''Sum Aggregation describes that data collected and aggregated with this
    method will be summed

    :type sum: int or float
    :param sum: the initial sum to be used in the aggregation

    '''

    def __init__(self, sum=None):
        self.sum = sum if sum is not None else 0

    def new_aggregation_data(self, measure):
        '''Get a new AggregationData for this aggregation.'''
        from opencensus.stats.aggregation_data import SumAggregationData
        return SumAggregationData(self.sum)

    @staticmethod
    def get_metric_type(measure):
        '''Get the MetricDescriptorType for the metric produced by this
        aggregation and measure.
        '''
        from opencensus.stats.measurement import Measurement
        from opencensus.stats.metric_utils import get_metric_type_from_measure
        return get_metric_type_from_measure(measure)","class SumAggregation(object):
    '''Sum Aggregation describes that data collected and aggregated with this
    method will be summed

    :type sum: int or float
    :param sum: the initial sum to be used in the aggregation

    '''

    def __init__(self, sum=None):
        self.sum = sum if sum is not None else 0

    def new_aggregation_data(self, measure):
        '''Get a new AggregationData for this aggregation.'''
        return SumAggregationData(self.sum)

    @staticmethod
    def get_metric_type(measure):
        '''Get the MetricDescriptorType for the metric produced by this
        aggregation and measure.
        '''
        if hasattr(measure, 'unit') and 'int' in str(type(measure.unit)).lower():
            return 'CUMULATIVE_INT64'
        return 'CUMULATIVE_DOUBLE'",partial_docstr,0.8363636363636364,0.7522935779816514,0.7037037037037038,0.7818181818181817,0.5372891543302252,0.9144736842105263,0.8013245033112583,0.74,0.9526039361953735,0.9233173727989197,0.9377321004867554,0.9261646866798401,0.8785058878504672,0.7574468085106383,0.6437768240343348,0.5800865800865801,0.6978723404255319,0.5173063092148595,0.8187134502923976,0.6470588235294118,0.5680473372781065,0.9067708253860474,0.8810251355171204,0.89371258020401,0.8835337162017822,0.8691601869158879,0.8018018018018018,0.6727272727272727,0.6146788990825689,0.7747747747747747,0.48044633529403535,0.8571428571428571,0.6993464052287581,0.6118421052631579,0.9352415204048157,0.9113216400146484,0.9231266975402832,0.9136584401130676,0.8286621495327102,0.4901587546718849,0.5964560808598037,0.6070360806848791,0.4,0.3571428571428571,0.4907188887700457,0.5475555507166145,0.5596057186492827,0.32,0.5357142857142857,0.4427467560160517,0.5584558563492199,0.5711025962864156,0.32,0.3214285714285714
505655,jayclassless/tidypy,src/tidypy/progress.py,tidypy.progress.Progress,"class Progress:
    """"""
    An interface for receiving events that occur during the execution of the
    TidyPy tool suite.
    """"""

    def __init__(self):
        self.current_tools = []
        self.completed_tools = []
        self._lock = Lock()

    def on_start(self):
        """"""
        Called when the execution of the TidyPy tool suite begins.
        """"""

    def on_tool_start(self, tool):
        """"""
        Called when an individual tool begins execution.

        :param tool: the name of the tool that is starting
        :type tool: str
        """"""

        with self._lock:
            self.current_tools.append(tool)

    def on_tool_finish(self, tool):
        """"""
        Called when an individual tool completes execution.

        :param tool: the name of the tool that completed
        :type tool: str
        """"""

        with self._lock:
            if tool in self.current_tools:
                self.current_tools.remove(tool)
                self.completed_tools.append(tool)

    def on_finish(self):
        """"""
        Called after all tools in the suite have completed.
        """"""","class Progress:
    '''
    An interface for receiving events that occur during the execution of the
    TidyPy tool suite.
    '''

    def __init__(self):
        pass

    def on_start(self):
    '''
        Called when the execution of the TidyPy tool suite begins.
        '''
        pass

    def on_tool_start(self, tool):
    '''
        Called when an individual tool begins execution.

        :param tool: the name of the tool that is starting
        :type tool: str
        '''
        pass

    def on_tool_finish(self, tool):
    '''
        Called when an individual tool completes execution.

        :param tool: the name of the tool that completed
        :type tool: str
        '''
        pass

    def on_finish(self):
    '''
        Called after all tools in the suite have completed.
        '''
        pass

",6,5,snippet_688,0.2727272727272727,"class Progress:
    '''
    An interface for receiving events that occur during the execution of the
    TidyPy tool suite.
    '''

    def __init__(self):
        self._suite_start = None
        self._suite_end = None
        self._tool_start_times = {}
        self._tool_durations = {}

    def on_start(self):
        '''
        Called when the execution of the TidyPy tool suite begins.
        '''
        self._suite_start = time.time()
        print(""TidyPy suite starting..."")

    def on_tool_start(self, tool):
        '''
        Called when an individual tool begins execution.

        :param tool: the name of the tool that is starting
        :type tool: str
        '''
        self._tool_start_times[tool] = time.time()
        print(f""  [START] Tool '{tool}'"")

    def on_tool_finish(self, tool):
        '''
        Called when an individual tool completes execution.

        :param tool: the name of the tool that completed
        :type tool: str
        '''
        start = self._tool_start_times.get(tool)
        if start is None:
            print(f""  [WARNING] Finished '{tool}' without start time"")
            return
        end = time.time()
        duration = end - start
        self._tool_durations[tool] = duration
        print(f""  [DONE ] Tool '{tool}' finished in {duration:.2f}s"")

    def on_finish(self):
        '''
        Called after all tools in the suite have completed.
        '''
        self._suite_end = time.time()
        total_suite = self._suite_end - self._suite_start if self._suite_start else 0
        print(""TidyPy suite finished."")
        print(f""Total suite time: {total_suite:.2f}s"")
        if self._tool_durations:
            print(""Tool summary:"")
            for tool, dur in self._tool_durations.items():
                print(f""  - {tool}: {dur:.2f}s"")","class Progress:
    '''
    An interface for receiving events that occur during the execution of the
    TidyPy tool suite.
    '''

    def __init__(self):
        pass

    def on_start(self):
        '''
        Called when the execution of the TidyPy tool suite begins.
        '''
        pass

    def on_tool_start(self, tool):
        '''
        Called when an individual tool begins execution.

        :param tool: the name of the tool that is starting
        :type tool: str
        '''
        pass

    def on_tool_finish(self, tool):
        '''
        Called when an individual tool completes execution.

        :param tool: the name of the tool that completed
        :type tool: str
        '''
        pass

    def on_finish(self):
        '''
        Called after all tools in the suite have completed.
        '''
        pass","class Progress:
    '''
    An interface for receiving events that occur during the execution of the
    TidyPy tool suite.
    '''

    def __init__(self):
        pass

    def on_start(self):
        '''
        Called when the execution of the TidyPy tool suite begins.
        '''
        pass

    def on_tool_start(self, tool):
        '''
        Called when an individual tool begins execution.

        :param tool: the name of the tool that is starting
        :type tool: str
        '''
        pass

    def on_tool_finish(self, tool):
        '''
        Called when an individual tool completes execution.

        :param tool: the name of the tool that completed
        :type tool: str
        '''
        pass

    def on_finish(self):
        '''
        Called after all tools in the suite have completed.
        '''
        pass",partial_docstr,0.6243093922651933,0.5333333333333333,0.5027932960893854,0.6022099447513811,0.361689656490737,0.47404063205417607,0.3438914027149321,0.29024943310657597,0.8044818639755249,0.9085123538970947,0.8533381819725037,0.896914005279541,0.76876,0.8270042194092827,0.7914893617021277,0.7553648068669527,0.8270042194092827,0.46581146224625125,0.9032258064516129,0.8376623376623377,0.7712418300653595,0.9587365984916687,0.9073231816291809,0.9323216080665588,0.912214994430542,0.8118298387096774,0.8270042194092827,0.7914893617021277,0.7553648068669527,0.8270042194092827,0.46581146224625125,0.9032258064516129,0.8376623376623377,0.7712418300653595,0.9587365984916687,0.9073231816291809,0.9323216080665588,0.912214994430542,0.8118298387096774,0.4589488941722341,0.3842064578696085,0.6240029119227767,0.4137931034482758,0.4137931034482758,0.3599065009095943,0.6069634340113097,0.6085246385925848,0.0862068965517241,0.1379310344827586,0.3599065009095943,0.6069634340113097,0.6085246385925848,0.0862068965517241,0.1379310344827586
167459,PetrochukM/PyTorch-NLP,PetrochukM_PyTorch-NLP/torchnlp/encoders/encoder.py,torchnlp.encoders.encoder.Encoder,"class Encoder(object):
    """"""
    Base class for a encoder employing an identity function.

    Args:
        enforce_reversible (bool, optional): Check for reversibility on ``Encoder.encode`` and
          ``Encoder.decode``. Formally, reversible means:
          ``Encoder.decode(Encoder.encode(object_)) == object_``.
    """"""

    def __init__(self, enforce_reversible=False):
        self.enforce_reversible = enforce_reversible

    def encode(self, object_):
        """""" Encodes an object.

        Args:
            object_ (object): Object to encode.

        Returns:
            object: Encoding of the object.
        """"""
        if self.enforce_reversible:
            self.enforce_reversible = False
            encoded_decoded = self.decode(self.encode(object_))
            self.enforce_reversible = True
            if encoded_decoded != object_:
                raise ValueError('Encoding is not reversible for ""%s""' % object_)

        return object_

    def batch_encode(self, iterator, *args, **kwargs):
        """"""
        Args:
            batch (list): Batch of objects to encode.
            *args: Arguments passed to ``encode``.
            **kwargs: Keyword arguments passed to ``encode``.

        Returns:
            list: Batch of encoded objects.
        """"""
        return [self.encode(object_, *args, **kwargs) for object_ in iterator]

    def decode(self, encoded):
        """""" Decodes an object.

        Args:
            object_ (object): Encoded object.

        Returns:
            object: Object decoded.
        """"""
        if self.enforce_reversible:
            self.enforce_reversible = False
            decoded_encoded = self.encode(self.decode(encoded))
            self.enforce_reversible = True
            if decoded_encoded != encoded:
                raise ValueError('Decoding is not reversible for ""%s""' % encoded)

        return encoded

    def batch_decode(self, iterator, *args, **kwargs):
        """"""
        Args:
            iterator (list): Batch of encoded objects.
            *args: Arguments passed to ``decode``.
            **kwargs: Keyword arguments passed to ``decode``.

        Returns:
            list: Batch of decoded objects.
        """"""
        return [self.decode(encoded, *args, **kwargs) for encoded in iterator]","class Encoder(object):
    '''
    Base class for a encoder employing an identity function.

    Args:
        enforce_reversible (bool, optional): Check for reversibility on ``Encoder.encode`` and
          ``Encoder.decode``. Formally, reversible means:
          ``Encoder.decode(Encoder.encode(object_)) == object_``.
    '''

    def __init__(self, enforce_reversible=False):
        pass

    def encode(self, object_):
    ''' Encodes an object.

        Args:
            object_ (object): Object to encode.

        Returns:
            object: Encoding of the object.
        '''
        pass

    def batch_encode(self, iterator, *args, **kwargs):
    '''
        Args:
            batch (list): Batch of objects to encode.
            *args: Arguments passed to ``encode``.
            **kwargs: Keyword arguments passed to ``encode``.

        Returns:
            list: Batch of encoded objects.
        '''
        pass

    def decode(self, encoded):
    ''' Decodes an object.

        Args:
            object_ (object): Encoded object.

        Returns:
            object: Object decoded.
        '''
        pass

    def batch_decode(self, iterator, *args, **kwargs):
    '''
        Args:
            iterator (list): Batch of encoded objects.
            *args: Arguments passed to ``decode``.
            **kwargs: Keyword arguments passed to ``decode``.

        Returns:
            list: Batch of decoded objects.
        '''
        pass

",6,5,snippet_359,0.8823529411764706,"class Encoder(object):
    '''
    Base class for a encoder employing an identity function.

    Args:
        enforce_reversible (bool, optional): Check for reversibility on ``Encoder.encode`` and
          ``Encoder.decode``. Formally, reversible means:
          ``Encoder.decode(Encoder.encode(object_)) == object_``.
    '''

    def __init__(self, enforce_reversible=False):
        self.enforce_reversible = enforce_reversible

    def encode(self, object_):
        '''
        Encodes an object.

        Args:
            object_ (object): Object to encode.

        Returns:
            object: Encoding of the object.
        '''
        encoded = object_
        if self.enforce_reversible:
            decoded = self.decode(encoded)
            if decoded != object_:
                raise ValueError(f""Reversibility check failed: decode(encode(obj)) != obj (got {decoded!r} != {object_!r})"")
        return encoded

    def batch_encode(self, iterator, *args, **kwargs):
        '''
        Args:
            batch (list): Batch of objects to encode.
            *args: Arguments passed to ``encode``.
            **kwargs: Keyword arguments passed to ``encode``.

        Returns:
            list: Batch of encoded objects.
        '''
        return [self.encode(item) for item in iterator]

    def decode(self, encoded):
        '''
        Decodes an object.

        Args:
            object_ (object): Encoded object.

        Returns:
            object: Object decoded.
        '''
        decoded = encoded
        if self.enforce_reversible:
            reencoded = self.encode(decoded)
            if reencoded != encoded:
                raise ValueError(f""Reversibility check failed: encode(decode(enc)) != enc (got {reencoded!r} != {encoded!r})"")
        return decoded

    def batch_decode(self, iterator, *args, **kwargs):
        '''
        Args:
            iterator (list): Batch of encoded objects.
            *args: Arguments passed to ``decode``.
            **kwargs: Keyword arguments passed to ``decode``.

        Returns:
            list: Batch of decoded objects.
        '''
        return [self.decode(item) for item in iterator]","class Encoder(object):
    '''
    Base class for a encoder employing an identity function.

    Args:
        enforce_reversible (bool, optional): Check for reversibility on ``Encoder.encode`` and
          ``Encoder.decode``. Formally, reversible means:
          ``Encoder.decode(Encoder.encode(object_)) == object_``.
    '''

    def __init__(self, enforce_reversible=False):
        self.enforce_reversible = enforce_reversible

    def encode(self, object_):
        ''' Encodes an object.

        Args:
            object_ (object): Object to encode.

        Returns:
            object: Encoding of the object.
        '''
        encoded = object_
        if self.enforce_reversible:
            if self.decode(encoded) != object_:
                raise ValueError(""Encoding is not reversible"")
        return encoded

    def batch_encode(self, iterator, *args, **kwargs):
        '''
        Args:
            iterator (list): Batch of objects to encode.
            *args: Arguments passed to ``encode``.
            **kwargs: Keyword arguments passed to ``encode``.

        Returns:
            list: Batch of encoded objects.
        '''
        return [self.encode(obj, *args, **kwargs) for obj in iterator]

    def decode(self, encoded):
        ''' Decodes an object.

        Args:
            encoded (object): Encoded object.

        Returns:
            object: Object decoded.
        '''
        return encoded

    def batch_decode(self, iterator, *args, **kwargs):
        '''
        Args:
            iterator (list): Batch of encoded objects.
            *args: Arguments passed to ``decode``.
            **kwargs: Keyword arguments passed to ``decode``.

        Returns:
            list: Batch of decoded objects.
        '''
        return [self.decode(obj, *args, **kwargs) for obj in iterator]","class Encoder(object):
    '''
    Base class for a encoder employing an identity function.

    Args:
        enforce_reversible (bool, optional): Check for reversibility on ``Encoder.encode`` and
          ``Encoder.decode``. Formally, reversible means:
          ``Encoder.decode(Encoder.encode(object_)) == object_``.
    '''

    def __init__(self, enforce_reversible=False):
        self.enforce_reversible = enforce_reversible

    def encode(self, object_):
        ''' Encodes an object.

        Args:
            object_ (object): Object to encode.

        Returns:
            object: Encoding of the object.
        '''
        encoded = object_
        
        if self.enforce_reversible:
            decoded = self.decode(encoded)
            if decoded != object_:
                raise ValueError(""Encoding is not reversible"")
        
        return encoded

    def batch_encode(self, iterator, *args, **kwargs):
        '''
        Args:
            batch (list): Batch of objects to encode.
            *args: Arguments passed to ``encode``.
            **kwargs: Keyword arguments passed to ``encode``.

        Returns:
            list: Batch of encoded objects.
        '''
        return [self.encode(obj, *args, **kwargs) for obj in iterator]

    def decode(self, encoded):
        ''' Decodes an object.

        Args:
            object_ (object): Encoded object.

        Returns:
            object: Object decoded.
        '''
        return encoded

    def batch_decode(self, iterator, *args, **kwargs):
        '''
        Args:
            iterator (list): Batch of encoded objects.
            *args: Arguments passed to ``decode``.
            **kwargs: Keyword arguments passed to ``decode``.

        Returns:
            list: Batch of decoded objects.
        '''
        return [self.decode(obj, *args, **kwargs) for obj in iterator]",partial_docstr,0.8451327433628318,0.7555555555555554,0.6964285714285714,0.8053097345132743,0.7116157691432959,0.8527472527472527,0.7687224669603524,0.7019867549668874,0.9486736059188843,0.9565765857696533,0.9526087641716003,0.9557804465293884,0.891626699507389,0.8633093525179857,0.7903614457831326,0.7312348668280871,0.8393285371702638,0.6567594874921955,0.9576719576719577,0.8859416445623343,0.8271276595744681,0.9655593633651733,0.9374455809593201,0.9512948393821716,0.9401831030845642,0.8801325615763547,0.8735083532219571,0.815347721822542,0.766265060240964,0.8544152744630072,0.6734466747333862,0.9607329842931938,0.8976377952755905,0.8421052631578947,0.9746635556221008,0.9417335391044617,0.9579156637191772,0.9449261426925659,0.8899846798029556,0.5427089665706644,0.5987664175629719,0.5946046599872912,0.4,0.5774647887323944,0.5420652161291526,0.572252787855401,0.5768827986775179,0.5684210526315789,0.4507042253521127,0.5696425324969758,0.5971642353499556,0.5989744639485486,0.5894736842105263,0.4929577464788732
217012,agramian/subprocess-manager,agramian_subprocess-manager/subprocess_manager/nbstream_readerwriter.py,subprocess_manager.nbstream_readerwriter.NonBlockingStreamReaderWriter,"class NonBlockingStreamReaderWriter:
    """"""A non-blocking stream reader/writer
    """"""

    def __init__(self, stream, print_stream=True, log_file=None):
        """"""Initialize the stream reader/writer

        Positional arguments:
        stream -- the stream to read from.
                  Usually a process' stdout or stderr.
        log_file -- the file to write the stream output to
        """"""
        # Queue to hold stream
        self._q = Queue()
        # string to hold cumulative output
        self._output = """"
        # verify arguments
        assert_variable_type(log_file, [str, NoneType])
        assert_variable_type(stream, FileType)

        def _populate_queue(stream, queue, log_file):
            """""" Collect lines from 'stream', put them in 'queue'.
            Write the stream output to the log_file if it was supplied.
            """"""
            while True:
                line = stream.readline()
                if line:
                    queue.put(line)
                    if print_stream:
                        print(line)
                    self._output += line + ""\r\n""
                    if log_file is not None:
                        with open(log_file, 'a') as f:
                            f.write(line)
                else:
                    return

        self._t = Thread(target = _populate_queue,
                         args = (stream, self._q, log_file))
        self._t.daemon = True
        self._t.start() #start collecting lines from the stream

    def get_all_output(self):
        return self._output

    def readline(self, timeout = 0.1):
        """"""Try to read a line from the stream queue.
        """"""
        try:
            return self._q.get(block = timeout is not None,
                               timeout = timeout)
        except Empty:
            return None","class NonBlockingStreamReaderWriter:
    '''A non-blocking stream reader/writer
    '''

    def __init__(self, stream, print_stream=True, log_file=None):
    '''Initialize the stream reader/writer

        Positional arguments:
        stream -- the stream to read from.
                  Usually a process' stdout or stderr.
        log_file -- the file to write the stream output to
        '''
        pass

        def _populate_queue(stream, queue, log_file):
    ''' Collect lines from 'stream', put them in 'queue'.
            Write the stream output to the log_file if it was supplied.
            '''
                pass

    def get_all_output(self):
        pass

    def readline(self, timeout = 0.1):
    '''Try to read a line from the stream queue.
        '''
        pass

",5,4,snippet_201,0.2142857142857142,"class NonBlockingStreamReaderWriter:
    '''A non-blocking stream reader/writer
    '''

    def __init__(self, stream, print_stream=True, log_file=None):
        '''Initialize the stream reader/writer

        Positional arguments:
        stream -- the stream to read from.
                  Usually a process' stdout or stderr.
        log_file -- the file to write the stream output to
        '''
        self.stream = stream
        self.print_stream = print_stream
        self.queue = queue.Queue()
        if log_file:
            if isinstance(log_file, str):
                self.log_file_handle = open(log_file, 'a')
            else:
                self.log_file_handle = log_file
        else:
            self.log_file_handle = None
        self._thread = threading.Thread(
            target=self._populate_queue,
            args=(self.stream, self.queue, self.log_file_handle),
            daemon=True
        )
        self._thread.start()

    def _populate_queue(self, stream, queue, log_file_handle):
        ''' Collect lines from 'stream', put them in 'queue'.
            Write the stream output to the log_file if it was supplied.
        '''
        while True:
            line = stream.readline()
            if line == '' or line is None:
                break
            queue.put(line)
            if self.print_stream:
                sys.stdout.write(line)
                sys.stdout.flush()
            if log_file_handle:
                try:
                    log_file_handle.write(line)
                    log_file_handle.flush()
                except:
                    pass
        if log_file_handle and hasattr(log_file_handle, 'close'):
            try:
                log_file_handle.close()
            except:
                pass

    def get_all_output(self):
        lines = []
        try:
            while True:
                lines.append(self.queue.get_nowait())
        except queue.Empty:
            pass
        return lines

    def readline(self, timeout=0.1):
        '''Try to read a line from the stream queue.
        '''
        try:
            return self.queue.get(timeout=timeout)
        except queue.Empty:
            return None","class NonBlockingStreamReaderWriter:
    '''A non-blocking stream reader/writer
    '''

    def __init__(self, stream, print_stream=True, log_file=None):
        '''Initialize the stream reader/writer

        Positional arguments:
        stream -- the stream to read from.
                  Usually a process' stdout or stderr.
        log_file -- the file to write the stream output to
        '''
        self.stream = stream
        self.print_stream = print_stream
        self.log_file = log_file
        self.queue = queue.Queue()
        self.thread = threading.Thread(target=self._populate_queue, 
                                     args=(self.stream, self.queue, self.log_file))
        self.thread.daemon = True
        self.thread.start()

    def _populate_queue(self, stream, queue, log_file):
        ''' Collect lines from 'stream', put them in 'queue'.
        Write the stream output to the log_file if it was supplied.
        '''
        logfile_handle = None
        if log_file:
            logfile_handle = open(log_file, 'w')
        
        try:
            for line in iter(stream.readline, ''):
                queue.put(line)
                if self.print_stream:
                    sys.stdout.write(line)
                    sys.stdout.flush()
                if logfile_handle:
                    logfile_handle.write(line)
                    logfile_handle.flush()
        finally:
            if logfile_handle:
                logfile_handle.close()

    def get_all_output(self):
        lines = []
        while not self.queue.empty():
            try:
                lines.append(self.queue.get_nowait())
            except queue.Empty:
                break
        return lines

    def readline(self, timeout=0.1):
        '''Try to read a line from the stream queue.
        '''
        try:
            return self.queue.get(timeout=timeout)
        except queue.Empty:
            return None","class NonBlockingStreamReaderWriter:
    '''A non-blocking stream reader/writer
    '''

    def __init__(self, stream, print_stream=True, log_file=None):
        '''Initialize the stream reader/writer

        Positional arguments:
        stream -- the stream to read from.
                  Usually a process' stdout or stderr.
        log_file -- the file to write the stream output to
        '''
        self.stream = stream
        self.print_stream = print_stream
        self.log_file = log_file
        self.queue = queue.Queue()
        self.thread = threading.Thread(target=self._populate_queue, args=(stream, self.queue, log_file))
        self.thread.daemon = True
        self.thread.start()

    def _populate_queue(self, stream, queue, log_file):
        ''' Collect lines from 'stream', put them in 'queue'.
            Write the stream output to the log_file if it was supplied.
            '''
        try:
            for line in iter(stream.readline, b''):
                if isinstance(line, bytes):
                    line = line.decode('utf-8', errors='replace')
                line = line.rstrip('\n\r')
                if line:
                    queue.put(line)
                    if self.print_stream:
                        print(line)
                    if log_file:
                        with open(log_file, 'a') as f:
                            f.write(line + '\n')
        except:
            pass
        finally:
            stream.close()

    def get_all_output(self):
        lines = []
        while True:
            try:
                line = self.queue.get_nowait()
                lines.append(line)
            except queue.Empty:
                break
        return lines

    def readline(self, timeout=0.1):
        '''Try to read a line from the stream queue.
        '''
        try:
            return self.queue.get(timeout=timeout)
        except queue.Empty:
            return None",partial_docstr,0.72,0.5491071428571429,0.4618834080717489,0.6000000000000001,0.5098827390402014,0.6605922551252847,0.4954337899543379,0.40503432494279173,0.8975520730018616,0.9000218510627747,0.8987852931022644,0.8997743129730225,0.7891853311258282,0.738095238095238,0.5598086124401913,0.46634615384615385,0.5952380952380952,0.5645433221191583,0.7284595300261096,0.5471204188481675,0.45144356955380577,0.9100816249847412,0.8964518308639526,0.9032153487205505,0.8977963924407959,0.7875479120879123,0.7743467933491687,0.6157517899761337,0.5227817745803358,0.655581947743468,0.6139113283877959,0.7473684210526316,0.6094986807387863,0.5079365079365079,0.9140369892120361,0.9134102463722229,0.9137235283851624,0.9134728908538818,0.8066003412969288,0.4237079079080665,0.3900043339810807,0.3978754259934315,0.4363636363636363,0.4705882352941176,0.4147351733999527,0.3650275810239128,0.379207230222957,0.4,0.5147058823529411,0.4655947966751576,0.402049362227704,0.4127362415852258,0.5181818181818182,0.5294117647058824
506241,jazzband/django-ddp,jazzband_django-ddp/dddp/alea.py,dddp.alea.Mash,"class Mash(object):

    """"""
    `Mash` hasing algorithm.

    >>> mash = Mash()
    >>> mash(' ')
    0.8633289230056107
    >>> mash(' ')
    0.15019597788341343
    >>> mash(' ')
    0.9176952994894236
    """"""

    def __init__(self):
        """"""Initialise state.""""""
        self.n = 0xefc8249d

    def __call__(self, data):
        """"""Return mash, updating internal state.""""""
        data = str(data)
        for byte in data:
            self.n += ord(byte)
            h = 0.02519603282416938 * self.n
            self.n = floor(h)
            h -= self.n
            h *= self.n
            self.n = floor(h)
            h -= self.n
            self.n += h * 0x100000000
        res = self.n * 2.3283064365386963e-10  # 2^-32
        return res","class Mash(object):
    '''
    `Mash` hasing algorithm.

    >>> mash = Mash()
    >>> mash(' ')
    0.8633289230056107
    >>> mash(' ')
    0.15019597788341343
    >>> mash(' ')
    0.9176952994894236
    '''

    def __init__(self):
    '''Initialise state.'''
        pass

    def __call__(self, data):
    '''Return mash, updating internal state.'''
        pass

",3,3,snippet_35,1.0,"class Mash(object):
    '''
    `Mash` hashing algorithm.

    >>> mash = Mash()
    >>> mash(' ')
    0.8633289230056107
    >>> mash(' ')
    0.15019597788341343
    >>> mash(' ')
    0.9176952994894236
    '''

    def __init__(self):
        '''Initialise state.'''
        self._n = 0xefc8249d

    def __call__(self, data):
        '''Return mash, updating internal state.'''
        for c in str(data):
            self._n += ord(c)
            h = 0.02519603282416938 * self._n
            self._n = int(h)
            h -= self._n
            h *= self._n
            self._n = int(h)
            h -= self._n
            self._n += int(h * 4294967296)
        return (self._n & 0xFFFFFFFF) * 2.3283064365386963e-10","class Mash(object):
    '''
    `Mash` hasing algorithm.

    >>> mash = Mash()
    >>> mash(' ')
    0.8633289230056107
    >>> mash(' ')
    0.15019597788341343
    >>> mash(' ')
    0.9176952994894236
    '''

    def __init__(self):
        '''Initialise state.'''
        self.state = 0x6a09e667f3bcc908

    def __call__(self, data):
        '''Return mash, updating internal state.'''
        # Convert data to bytes if it's a string
        if isinstance(data, str):
            data = data.encode('utf-8')
        
        # Process each byte
        for byte in data:
            self.state = (self.state * 0x9e3779b1 + byte) & 0xffffffffffffffff
        
        # Return a float between 0 and 1
        result = (self.state >> 12) / (2**52)
        return result","class Mash(object):
    '''
    `Mash` hasing algorithm.

    >>> mash = Mash()
    >>> mash(' ')
    0.8633289230056107
    >>> mash(' ')
    0.15019597788341343
    >>> mash(' ')
    0.9176952994894236
    '''

    def __init__(self):
        '''Initialise state.'''
        self.n = 0xefc8249d

    def __call__(self, data):
        '''Return mash, updating internal state.'''
        for char in data:
            self.n += ord(char)
            h = 0.02519603282416938 * self.n
            self.n = int(h) * 4294967296
            h -= int(h)
            h *= self.n
            self.n = int(h) * 4294967296
            h -= int(h)
            self.n += int(h * 4294967296)
        
        return (self.n & 0xffffffff) * 2.3283064365386963e-10",partial_docstr,0.8734177215189873,0.7307692307692308,0.6233766233766234,0.8481012658227849,0.6542900624938367,0.8370786516853933,0.6836158192090396,0.5511363636363636,0.9546205401420593,0.9558460712432861,0.9552328586578369,0.9557234048843384,0.9531685123966942,0.5679012345679012,0.45,0.4050632911392405,0.5555555555555556,0.4773797588529245,0.703030303030303,0.5121951219512195,0.43558282208588955,0.8537055253982544,0.8584902286529541,0.8560912013053894,0.858009397983551,0.8044096694214875,0.8176100628930817,0.6751592356687898,0.5935483870967743,0.8050314465408805,0.6667653122004813,0.8362573099415205,0.7235294117647059,0.6272189349112426,0.9346526265144348,0.9581879377365112,0.9462739825248718,0.9557811617851257,0.9283753719008265,0.5541099888818146,0.3383422345378319,0.3505003183920239,0.7321428571428571,0.7954545454545454,0.351492135785025,0.2959535454873689,0.330794218431952,0.3928571428571428,0.3863636363636363,0.4967866094908783,0.4763476642566562,0.4864481243562075,0.6607142857142857,0.3636363636363636
666073,pydsigner/taskit,pydsigner_taskit/taskit/common.py,taskit.common.PickleCodec,"class PickleCodec(object):
    
    """"""
    Basic codec using pickle (default version) for encoding. Do not use if 
    cross-language support is desired.
    """"""
    
    @staticmethod
    def encode(obj):
        return pickle.dumps(obj)
    @staticmethod
    def decode(enc):
        return pickle.loads(enc)","class PickleCodec(object):
    '''
    Basic codec using pickle (default version) for encoding. Do not use if 
    cross-language support is desired.
    '''

    @staticmethod
    def encode(obj):
        pass

    @staticmethod
    def decode(enc):
        pass

",5,1,snippet_44,1.0,"class PickleCodec(object):
    '''
    Basic codec using pickle (default version) for encoding. Do not use if 
    cross-language support is desired.
    '''

    @staticmethod
    def encode(obj):
        return pickle.dumps(obj)

    @staticmethod
    def decode(enc):
        return pickle.loads(enc)","class PickleCodec(object):
    '''
    Basic codec using pickle (default version) for encoding. Do not use if 
    cross-language support is desired.
    '''

    @staticmethod
    def encode(obj):
        return pickle.dumps(obj)

    @staticmethod
    def decode(enc):
        return pickle.loads(enc)","class PickleCodec(object):
    '''
    Basic codec using pickle (default version) for encoding. Do not use if 
    cross-language support is desired.
    '''

    @staticmethod
    def encode(obj):
        return pickle.dumps(obj)

    @staticmethod
    def decode(enc):
        return pickle.loads(enc)",partial_docstr,1.0,1.0,1.0,1.0,0.8681803793248862,0.9661016949152542,0.9310344827586207,0.8947368421052632,0.9947036504745483,0.9947036504745483,0.9947036504745483,0.9947037696838379,1.0,1.0,1.0,1.0,1.0,0.8681803793248862,0.9661016949152542,0.9310344827586207,0.8947368421052632,0.9947036504745483,0.9947036504745483,0.9947036504745483,0.9947037696838379,1.0,1.0,1.0,1.0,1.0,0.8681803793248862,0.9661016949152542,0.9310344827586207,0.8947368421052632,0.9947036504745483,0.9947036504745483,0.9947036504745483,0.9947037696838379,1.0,0.9156016716569164,0.8272321735438268,0.8351745130838387,1.0,1.0,0.9156016716569164,0.8272321735438268,0.8351745130838387,1.0,1.0,0.9156016716569164,0.8272321735438268,0.8351745130838387,1.0,1.0
404878,google/grr,google_grr/grr/server/grr_response_server/databases/mysql_pool.py,grr_response_server.databases.mysql_pool.Pool,"class Pool(object):
  """"""A Pool of database connections.

  A simple pool, with a maximum number of simultaneous connections. Primary goal
  is to do the right thing when using MySQLdb in obvious ways (our use case),
  but we also try to stay loosely within the PEP-249 standard.

  Intends to be thread safe in that multiple connections can be requested and
  used by multiple threads without synchronization, but operations on each
  connection (and its associated cursors) are assumed to be serial.
  """"""

  def __init__(self, connect_func, max_size=10):
    """"""Creates a ConnectionPool.

    Args:
     connect_func: A closure which returns a new connection to the underlying
       database, i.e. a MySQLdb.Connection. Should raise or block if the
       database is unavailable.
     max_size: The maximum number of simultaneous connections.
    """"""
    self.connect_func = connect_func
    self.limiter = threading.BoundedSemaphore(max_size)
    self.idle_conns = []  # Atomic access only!!
    self.closed = False

  def get(self, blocking=True):
    """"""Gets a connection.

    Args:
      blocking: Whether to block when max_size connections are already in use.
        If false, may return None.

    Returns:
      A connection to the database.

    Raises:
      PoolAlreadyClosedError: if close() method was already called on
      this pool.
    """"""
    if self.closed:
      raise PoolAlreadyClosedError(""Connection pool is already closed."")

    # NOTE: Once we acquire capacity from the semaphore, it is essential that we
    # return it eventually. On success, this responsibility is delegated to
    # _ConnectionProxy.
    if not self.limiter.acquire(blocking=blocking):
      return None
    c = None
    # pop is atomic, but if we did a check first, it would not be atomic with
    # the pop.
    try:
      c = self.idle_conns.pop()
    except IndexError:
      # Create a connection, release the pool allocation if it fails.
      try:
        c = self.connect_func()
      except Exception:
        self.limiter.release()
        raise
    return _ConnectionProxy(self, c)

  def close(self):
    self.closed = True
    for conn in self.idle_conns:
      conn.close()","class Pool(object):
    '''A Pool of database connections.

  A simple pool, with a maximum number of simultaneous connections. Primary goal
  is to do the right thing when using MySQLdb in obvious ways (our use case),
  but we also try to stay loosely within the PEP-249 standard.

  Intends to be thread safe in that multiple connections can be requested and
  used by multiple threads without synchronization, but operations on each
  connection (and its associated cursors) are assumed to be serial.
  '''

  def __init__(self, connect_func, max_size=10):
    '''Creates a ConnectionPool.

    Args:
     connect_func: A closure which returns a new connection to the underlying
       database, i.e. a MySQLdb.Connection. Should raise or block if the
       database is unavailable.
     max_size: The maximum number of simultaneous connections.
    '''
    pass

  def get(self, blocking=True):
    '''Gets a connection.

    Args:
      blocking: Whether to block when max_size connections are already in use.
        If false, may return None.

    Returns:
      A connection to the database.

    Raises:
      PoolAlreadyClosedError: if close() method was already called on
      this pool.
    '''
    pass

  def close(self):
    pass

",4,3,snippet_732,0.2307692307692307,"class Pool(object):
    '''A Pool of database connections.'''

    def __init__(self, connect_func, max_size=10):
        '''Creates a ConnectionPool.'''
        self._connect = connect_func
        self._max_size = max_size
        self._lock = threading.Condition()
        self._idle = []
        self._total = 0
        self._closed = False

    def get(self, blocking=True):
        '''Gets a connection.'''
        with self._lock:
            if self._closed:
                raise PoolAlreadyClosedError(""Pool is closed"")
            while True:
                if self._idle:
                    conn = self._idle.pop()
                    return _ConnectionProxy(conn, self)
                if self._total < self._max_size:
                    conn = self._connect()
                    self._total += 1
                    return _ConnectionProxy(conn, self)
                if not blocking:
                    return None
                self._lock.wait()
                if self._closed:
                    raise PoolAlreadyClosedError(""Pool is closed"")

    def _return(self, conn):
        with self._lock:
            if self._closed:
                try:
                    conn.close()
                except Exception:
                    pass
                self._total -= 1
            else:
                self._idle.append(conn)
            self._lock.notify()

    def close(self):
        '''Closes the pool and all idle connections.'''
        with self._lock:
            if self._closed:
                return
            self._closed = True
            for conn in self._idle:
                try:
                    conn.close()
                except Exception:
                    pass
                self._total -= 1
            self._idle = []
            self._lock.notify_all()","class Pool(object):
    '''A Pool of database connections.

  A simple pool, with a maximum number of simultaneous connections. Primary goal
  is to do the right thing when using MySQLdb in obvious ways (our use case),
  but we also try to stay loosely within the PEP-249 standard.

  Intends to be thread safe in that multiple connections can be requested and
  used by multiple threads without synchronization, but operations on each
  connection (and its associated cursors) are assumed to be serial.
  '''

    def __init__(self, connect_func, max_size=10):
        '''Creates a ConnectionPool.

        Args:
         connect_func: A closure which returns a new connection to the underlying
           database, i.e. a MySQLdb.Connection. Should raise or block if the
           database is unavailable.
         max_size: The maximum number of simultaneous connections.
        '''
        self._connect_func = connect_func
        self._max_size = max_size
        self._connections = queue.Queue(maxsize=max_size)
        self._created_connections = 0
        self._lock = threading.Lock()
        self._closed = False

        # Pre-populate the pool with connections
        for _ in range(max_size):
            conn = self._connect_func()
            self._connections.put(conn)
            self._created_connections += 1

    def get(self, blocking=True):
        '''Gets a connection.

        Args:
          blocking: Whether to block when max_size connections are already in use.
            If false, may return None.

        Returns:
          A connection to the database.

        Raises:
          PoolAlreadyClosedError: if close() method was already called on
          this pool.
        '''
        with self._lock:
            if self._closed:
                raise PoolAlreadyClosedError(""Pool is already closed"")

        try:
            return self._connections.get(blocking=blocking)
        except queue.Empty:
            return None

    def put(self, connection):
        '''Returns a connection to the pool.

        Args:
          connection: A connection to return to the pool.
        '''
        with self._lock:
            if self._closed:
                connection.close()
                return

        try:
            self._connections.put(connection, block=False)
        except queue.Full:
            # If the pool is full, close the connection
            connection.close()

    def close(self):
        with self._lock:
            if self._closed:
                return
            self._closed = True

        # Close all connections in the pool
        while not self._connections.empty():
            try:
                conn = self._connections.get_nowait()
                conn.close()
            except queue.Empty:
                break","class Pool(object):
    '''A Pool of database connections.

  A simple pool, with a maximum number of simultaneous connections. Primary goal
  is to do the right thing when using MySQLdb in obvious ways (our use case),
  but we also try to stay loosely within the PEP-249 standard.

  Intends to be thread safe in that multiple connections can be requested and
  used by multiple threads without synchronization, but operations on each
  connection (and its associated cursors) are assumed to be serial.
  '''

    def __init__(self, connect_func, max_size=10):
        '''Creates a ConnectionPool.

        Args:
         connect_func: A closure which returns a new connection to the underlying
           database, i.e. a MySQLdb.Connection. Should raise or block if the
           database is unavailable.
         max_size: The maximum number of simultaneous connections.
        '''
        self._connect_func = connect_func
        self._max_size = max_size
        self._pool = queue.Queue(maxsize=max_size)
        self._lock = threading.Lock()
        self._closed = False
        self._created_connections = 0

    def get(self, blocking=True):
        '''Gets a connection.

        Args:
          blocking: Whether to block when max_size connections are already in use.
            If false, may return None.

        Returns:
          A connection to the database.

        Raises:
          PoolAlreadyClosedError: if close() method was already called on
          this pool.
        '''
        if self._closed:
            raise PoolAlreadyClosedError(""Pool has been closed"")

        try:
            connection = self._pool.get(block=False)
            return PooledConnection(connection, self)
        except queue.Empty:
            with self._lock:
                if self._closed:
                    raise PoolAlreadyClosedError(""Pool has been closed"")
                
                if self._created_connections < self._max_size:
                    connection = self._connect_func()
                    self._created_connections += 1
                    return PooledConnection(connection, self)
            
            if blocking:
                if self._closed:
                    raise PoolAlreadyClosedError(""Pool has been closed"")
                connection = self._pool.get(block=True)
                return PooledConnection(connection, self)
            else:
                return None

    def _return_connection(self, connection):
        if not self._closed:
            try:
                self._pool.put(connection, block=False)
            except queue.Full:
                pass

    def close(self):
        with self._lock:
            self._closed = True
            while not self._pool.empty():
                try:
                    connection = self._pool.get(block=False)
                    if hasattr(connection, 'close'):
                        connection.close()
                except queue.Empty:
                    break",partial_docstr,0.44161358811040335,0.24733475479744138,0.15845824411134904,0.3227176220806794,0.2789593425680571,0.6504297994269341,0.3620689655172414,0.2420749279538905,0.850338339805603,0.7554714679718018,0.8001026511192322,0.7639948725700378,0.8044464000000006,0.7503974562798092,0.6283891547049442,0.5824,0.6899841017488076,0.5742320044997401,0.6901140684410646,0.5638095238095238,0.4866412213740458,0.9012453556060791,0.8910332918167114,0.8961102366447449,0.8920440077781677,0.80689,0.7145135566188198,0.6144,0.5874799357945425,0.6698564593301436,0.5441078924344813,0.6580406654343808,0.5277777777777778,0.46382189239332094,0.9061294794082642,0.8859878778457642,0.8959454894065857,0.8879615664482117,0.8025909708737864,0.3257783262140055,0.0394216941523136,0.0651100504200205,0.6666666666666666,0.5319148936170213,0.5681338564195615,0.564209263621394,0.576998209012098,0.6206896551724138,0.5106382978723404,0.5530043230211114,0.5559176697215782,0.5673248608074748,0.6206896551724138,0.4680851063829787
122775,GNS3/gns3-server,GNS3_gns3-server/gns3server/compute/dynamips/adapters/wic_1t.py,gns3server.compute.dynamips.adapters.wic_1t.WIC_1T,"class WIC_1T(object):

    """"""
    WIC-1T Serial
    """"""

    def __init__(self):

        self._interfaces = 1

    def __str__(self):

        return ""WIC-1T""

    @property
    def interfaces(self):
        """"""
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        """"""

        return self._interfaces","class WIC_1T(object):
    '''
    WIC-1T Serial
    '''

    def __init__(self):
        pass

    def __str__(self):
        pass

    @property
    def interfaces(self):
    '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        pass

",5,2,snippet_737,0.8,"class WIC_1T(object):
    '''
    WIC-1T Serial
    '''

    def __init__(self):
        self._interfaces = 1

    def __str__(self):
        return self.__class__.__doc__.strip()

    @property
    def interfaces(self):
        '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        return self._interfaces","class WIC_1T(object):
    '''
    WIC-1T Serial
    '''

    def __init__(self):
        self._interfaces = 1

    def __str__(self):
        return ""WIC-1T Serial""

    @property
    def interfaces(self):
        '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        return self._interfaces","class WIC_1T(object):
    '''
    WIC-1T Serial
    '''

    def __init__(self):
        self._name = ""WIC-1T""
        self._description = ""1-port serial WIC""
        self._interface_count = 1

    def __str__(self):
        return self._name

    @property
    def interfaces(self):
        '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        return self._interface_count",partial_docstr,0.9249999999999999,0.8974358974358975,0.868421052631579,0.9249999999999999,0.6989117101460779,0.7613636363636364,0.7011494252873564,0.6395348837209303,0.9697715044021606,0.9863317608833313,0.9779815077781677,0.9846503138542175,0.9444450000000001,0.9873417721518987,0.9610389610389611,0.9333333333333332,0.9873417721518987,0.7975667204349676,0.9333333333333333,0.8783783783783784,0.821917808219178,0.9927454590797424,0.9938470721244812,0.9932959675788879,0.9937368035316467,1.0,0.8222222222222223,0.7500000000000001,0.6744186046511628,0.7777777777777778,0.6145254542381242,0.7070707070707071,0.6122448979591837,0.5360824742268041,0.9240987300872803,0.9535832405090332,0.9386095404624939,0.9505504369735718,0.88889,0.7366218934683972,0.6271498825163946,0.6375195095390125,0.6818181818181818,1.0,0.8116179311792152,0.6089522151778484,0.6375195095390125,1.0,1.0,0.657382595099848,0.4386135568748001,0.5545531871609555,0.6363636363636364,0.0
825277,wangwenpei/cliez,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/wangwenpei_cliez/cliez/slot.py,cliez.slot.SlotComponent.Handle,"class Handle(object):
    """"""

    * `initialize`

    initial resource, e.g: database handle

    * `__enter__`

    get next data to do,you can fetch one or more data.

    * `slot`

    user custom code

    * `__exit__`

    when slot finished, call this method

    """"""

    def __init__(self, component):
        """"""
        Don't override this method unless you know what you're doing.
        :param component:
        :return:
        """"""
        self.component = component
        self.options = component.options
        self.initialize()

    def initialize(self):
        """"""
        Hook for subclass initialization.

        This block is execute before thread initial
        """"""
        pass

    def __enter__(self):
        """"""
        ...note::
            You **MUST** return False when no data to do.

        The return value will be used in `Slot.slot`
        """"""
        self.component.error_message(
            ""please overwrite `__enter__` method,""
            ""and make sure return False when no data to execute."")
        return False

    def __exit__(self, exc_type, exc_val, exc_tb):
        """"""
        When slot done, will call this method.
        """"""

        if self.options.thread_sleep_time:

            if self.options.thread_sleep_range:
                sleep_time = random.randint(
                    self.options.thread_sleep_time,
                    self.options.thread_sleep_time +
                    self.options.thread_sleep_range)
                pass
            else:
                sleep_time = self.options.thread_sleep_time
                pass

            sleep(sleep_time)

        pass

    def slot(self, msg):
        """"""
        Add your custom code at here.
        """"""

        pass
","class Handle(object):
    '''

    * `initialize`

    initial resource, e.g: database handle

    * `__enter__`

    get next data to do,you can fetch one or more data.

    * `slot`

    user custom code

    * `__exit__`

    when slot finished, call this method

    '''


    def __init__(self, component):
    '''
        Don't override this method unless you know what you're doing.
        :param component:
        :return:
        '''
        pass


    def initialize(self):
    '''
        Hook for subclass initialization.

        This block is execute before thread initial
        '''
        pass


    def __enter__(self):
    '''
        ...note::
            You **MUST** return False when no data to do.

        The return value will be used in `Slot.slot`
        '''
        pass


    def __exit__(self, exc_type, exc_val, exc_tb):
    '''
        When slot done, will call this method.
        '''
        pass


    def slot(self, msg):
    '''
        Add your custom code at here.
        '''
        pass

",6,6,snippet_807,0.3,"class Handle(object):
    def __init__(self, component):
        self.component = component
        self._iter = None
        self.initialize()

    def initialize(self):
        pass

    def __enter__(self):
        if self._iter is None:
            try:
                self._iter = iter(self.component)
            except TypeError:
                self._iter = None
        if self._iter is not None:
            try:
                return next(self._iter)
            except StopIteration:
                return False
        return False

    def __exit__(self, exc_type, exc_val, exc_tb):
        close = getattr(self.component, ""close"", None)
        if callable(close):
            try:
                close()
            except Exception:
                pass
        return False

    def slot(self, msg):
        pass","class Handle(object):
    '''

    * `initialize`

    initial resource, e.g: database handle

    * `__enter__`

    get next data to do,you can fetch one or more data.

    * `slot`

    user custom code

    * `__exit__`

    when slot finished, call this method

    '''

    def __init__(self, component):
        '''
        Don't override this method unless you know what you're doing.
        :param component:
        :return:
        '''
        self.component = component


    def initialize(self):
        '''
        Hook for subclass initialization.

        This block is execute before thread initial
        '''
        pass


    def __enter__(self):
        '''
        ...note::
            You **MUST** return False when no data to do.

        The return value will be used in `Slot.slot`
        '''
        return False


    def __exit__(self, exc_type, exc_val, exc_tb):
        '''
        When slot done, will call this method.
        '''
        pass


    def slot(self, msg):
        '''
        Add your custom code at here.
        '''
        pass","class Handle(object):
    '''

    * `initialize`

    initial resource, e.g: database handle

    * `__enter__`

    get next data to do,you can fetch one or more data.

    * `slot`

    user custom code

    * `__exit__`

    when slot finished, call this method

    '''

    def __init__(self, component):
        '''
        Don't override this method unless you know what you're doing.
        :param component:
        :return:
        '''
        self.component = component

    def initialize(self):
        '''
        Hook for subclass initialization.

        This block is execute before thread initial
        '''
        pass

    def __enter__(self):
        '''
        ...note::
            You **MUST** return False when no data to do.

        The return value will be used in `Slot.slot`
        '''
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        '''
        When slot done, will call this method.
        '''
        pass

    def slot(self, msg):
        '''
        Add your custom code at here.
        '''
        pass",partial_docstr,0.39855072463768115,0.24087591240875914,0.15441176470588233,0.3115942028985507,0.16585772330984752,0.7941176470588235,0.5266272189349113,0.4226190476190476,0.7980078458786011,0.6993162035942078,0.7454095482826233,0.7080731391906738,0.7443788343558284,0.7834394904458599,0.7628205128205129,0.7419354838709677,0.7834394904458599,0.4418643513067372,0.9459459459459459,0.8868778280542986,0.8318181818181818,0.9606084823608398,0.8776002526283264,0.9172302484512329,0.8852498531341553,0.8241326380368098,0.7834394904458599,0.7500000000000001,0.7290322580645161,0.7770700636942676,0.4387461779708982,0.9459459459459459,0.8778280542986425,0.8227272727272728,0.9584223031997681,0.8754451274871826,0.9150564670562744,0.8830905556678772,0.8220876687116565,0.3124227491180762,0.0478944431855008,0.0949472382183109,0.5068493150684932,0.6,0.4394959781137272,0.5550958896062729,0.5782304886020608,0.4246575342465753,0.2,0.4360667045532852,0.5441237081421176,0.5641842059614343,0.410958904109589,0.225
298456,cloud9ers/gurumate,cloud9ers_gurumate/environment/lib/python2.7/site-packages/IPython/core/autocall.py,IPython.core.autocall.IPyAutocall,"class IPyAutocall(object):
    """""" Instances of this class are always autocalled
    
    This happens regardless of 'autocall' variable state. Use this to
    develop macro-like mechanisms.
    """"""
    _ip = None
    rewrite = True
    def __init__(self, ip=None):
        self._ip = ip
    
    def set_ip(self, ip):
        """""" Will be used to set _ip point to current ipython instance b/f call
        
        Override this method if you don't want this to happen.
        
        """"""
        self._ip = ip","class IPyAutocall(object):
    ''' Instances of this class are always autocalled
    
    This happens regardless of 'autocall' variable state. Use this to
    develop macro-like mechanisms.
    '''

    def __init__(self, ip=None):
        pass

    def set_ip(self, ip):
    ''' Will be used to set _ip point to current ipython instance b/f call
        
        Override this method if you don't want this to happen.
        
        '''
        pass

",3,2,snippet_419,1.0,"class IPyAutocall(object):
    ''' Instances of this class are always autocalled
    
    This happens regardless of 'autocall' variable state. Use this to
    develop macro-like mechanisms.
    '''
    def __init__(self, ip=None):
        self._ip = None
        if ip is not None:
            self.set_ip(ip)

    def set_ip(self, ip):
        ''' Will be used to set _ip point to current ipython instance b/f call
        
        Override this method if you don't want this to happen.
        
        '''
        self._ip = ip

    def __call__(self, arg_s=None, *args, **kwargs):
        return self.call(arg_s, *args, **kwargs)

    def call(self, arg_s, *args, **kwargs):
        raise NotImplementedError(""Subclasses must implement the call() method"")","class IPyAutocall(object):
    ''' Instances of this class are always autocalled
    
    This happens regardless of 'autocall' variable state. Use this to
    develop macro-like mechanisms.
    '''

    def __init__(self, ip=None):
        self._ip = ip

    def set_ip(self, ip):
        ''' Will be used to set _ip point to current ipython instance b/f call
        
        Override this method if you don't want this to happen.
        
        '''
        self._ip = ip","class IPyAutocall(object):
    ''' Instances of this class are always autocalled
    
    This happens regardless of 'autocall' variable state. Use this to
    develop macro-like mechanisms.
    '''

    def __init__(self, ip=None):
        self._ip = ip

    def set_ip(self, ip):
        ''' Will be used to set _ip point to current ipython instance b/f call
        
        Override this method if you don't want this to happen.
        
        '''
        self._ip = ip",partial_docstr,0.7745664739884394,0.7485380116959063,0.7100591715976332,0.7514450867052023,0.4956967552682987,0.5444444444444444,0.49162011173184356,0.4550561797752809,0.8564179539680481,0.9757210612297058,0.9121851921081543,0.9623154401779175,0.800002,0.9701492537313433,0.9545454545454545,0.9384615384615386,0.9701492537313433,0.7811958614847041,0.9583333333333334,0.9157894736842105,0.8723404255319149,0.9906878471374512,0.9802217483520508,0.9854270219802856,0.9812583327293396,0.9466671999999999,0.9701492537313433,0.9545454545454545,0.9384615384615386,0.9701492537313433,0.7811958614847041,0.9583333333333334,0.9157894736842105,0.8723404255319149,0.9906878471374512,0.9802217483520508,0.9854270219802856,0.9812583327293396,0.9466671999999999,0.5498393813193073,0.5580795839433945,0.7365160365719299,0.6190476190476191,0.2857142857142857,0.5595308269584963,0.7537084174726292,0.746319652266118,0.6666666666666666,0.0714285714285714,0.5595308269584963,0.7537084174726292,0.746319652266118,0.6666666666666666,0.0714285714285714
504845,jashort/SmartFileSorter,jashort_SmartFileSorter/smartfilesorter/actionplugins/stopprocessing.py,smartfilesorter.actionplugins.stopprocessing.StopProcessing,"class StopProcessing(object):
    """"""
    Stop processing rules and actions for the given file
    """"""
    config_name = 'stop-processing'

    def __init__(self, value=None):
        # Nothing to do here - just call the parent __init__ function for logging
        self.continue_processing = False

    @staticmethod
    def do_action(target, dry_run=False):
        """"""
        :param target: Full path and filename
        :param dry_run: True - don't actually perform action. False: perform action. No effect for this rule.
        :return: None
        """"""
        raise StopProcessingException()","class StopProcessing(object):
    '''
    Stop processing rules and actions for the given file
    '''

    def __init__(self, value=None):
        pass

    @staticmethod
    def do_action(target, dry_run=False):
    '''
        :param target: Full path and filename
        :param dry_run: True - don't actually perform action. False: perform action. No effect for this rule.
        :return: None
        '''
        pass

",4,2,snippet_473,1.0,"class StopProcessing(object):
    '''
    Stop processing rules and actions for the given file
    '''

    def __init__(self, value=None):
        self.value = value

    @staticmethod
    def do_action(target, dry_run=False):
        """"""
        :param target: Full path and filename
        :param dry_run: True - don't actually perform action. False: perform action. No effect for this rule.
        :return: None
        """"""
        raise StopProcessing(value=target)","class StopProcessing(object):
    '''
    Stop processing rules and actions for the given file
    '''

    def __init__(self, value=None):
        self.value = value

    @staticmethod
    def do_action(target, dry_run=False):
        '''
        :param target: Full path and filename
        :param dry_run: True - don't actually perform action. False: perform action. No effect for this rule.
        :return: None
        '''
        pass","class StopProcessing(object):
    '''
    Stop processing rules and actions for the given file
    '''

    def __init__(self, value=None):
        self.value = value

    @staticmethod
    def do_action(target, dry_run=False):
        '''
        :param target: Full path and filename
        :param dry_run: True - don't actually perform action. False: perform action. No effect for this rule.
        :return: None
        '''
        return None",partial_docstr,0.8062015503875969,0.7559055118110235,0.7200000000000001,0.8062015503875969,0.6670062915938015,0.9313725490196079,0.8514851485148515,0.81,0.9631385207176208,0.8963726758956909,0.9285570383071899,0.9026297926902771,0.9245290566037736,0.8095238095238096,0.7580645161290323,0.721311475409836,0.8095238095238096,0.5782504231053687,0.9239130434782609,0.8571428571428571,0.8,0.96037358045578,0.8883976936340332,0.9229845404624939,0.8951061964035034,0.9182398113207547,0.8031496062992126,0.752,0.7154471544715448,0.8031496062992126,0.5807072195904917,0.9139784946236559,0.8478260869565217,0.7912087912087912,0.9611737132072449,0.8897560238838196,0.9240870475769043,0.8964166641235352,0.9182398113207547,0.424692079924493,0.5682590757278158,0.6039391956609773,0.3043478260869565,0.2222222222222222,0.3605130299968415,0.497189832679471,0.5294033501098274,0.3043478260869565,0.1111111111111111,0.3612919665073109,0.5003055787213485,0.5294033501098274,0.3043478260869565,0.1111111111111111
358191,edaniszewski/bison,edaniszewski_bison/bison/scheme.py,bison.scheme.Scheme,"class Scheme(object):
    """"""The `Scheme` specifies the expected options for a configuration.

    It provides the template for what is expected when parsing and building
    configuration state. Additionally, it allows the user to specify default
    values for various fields. The `Scheme` allows for validation across all
    specified options, to the extent that the constraints are specified on
    those options.
    """"""

    def __init__(self, *args):
        self.args = args
        self._flat = None

    def build_defaults(self):
        """"""Build a dictionary of default values from the `Scheme`.

        Returns:
            dict: The default configurations as set by the `Scheme`.

        Raises:
            errors.InvalidSchemeError: The `Scheme` does not contain
                valid options.
        """"""
        defaults = {}
        for arg in self.args:
            if not isinstance(arg, _BaseOpt):
                raise errors.InvalidSchemeError('Unable to build default for non-Option type')

            # if there is a default set, add it to the defaults dict
            if not isinstance(arg.default, NoDefault):
                defaults[arg.name] = arg.default

            # if we have a dict option, build the defaults for its scheme.
            # if any defaults exist, use them.
            if isinstance(arg, DictOption):
                if arg.scheme:
                    b = arg.scheme.build_defaults()
                    if b:
                        defaults[arg.name] = b
        return defaults

    def flatten(self):
        """"""Flatten the scheme into a dictionary where the keys are
        compound 'dot' notation keys, and the values are the corresponding
        options.

        Returns:
            dict: The flattened `Scheme`.
        """"""
        if self._flat is None:
            flat = {}
            for arg in self.args:
                if isinstance(arg, Option):
                    flat[arg.name] = arg

                elif isinstance(arg, ListOption):
                    flat[arg.name] = arg

                elif isinstance(arg, DictOption):
                    flat[arg.name] = arg
                    if arg.scheme:
                        for k, v in arg.scheme.flatten().items():
                            flat[arg.name + '.' + k] = v

            self._flat = flat
        return self._flat

    def validate(self, config):
        """"""Validate the given config against the `Scheme`.

        Args:
            config (dict): The configuration to validate.

        Raises:
            errors.SchemeValidationError: The configuration fails
                validation against the `Schema`.
        """"""
        if not isinstance(config, dict):
            raise errors.SchemeValidationError(
                'Scheme can only validate a dictionary config, but was given '
                '{} (type: {})'.format(config, type(config))
            )

        for arg in self.args:
            # the option exists in the config
            if arg.name in config:
                arg.validate(arg.name, config[arg.name])

            # the option does not exist in the config
            else:
                # if the option is not required, then it is fine to omit.
                # otherwise, its omission constitutes a validation error unless
                # a default value is specified for the option.
                if arg.required and isinstance(arg.default, NoDefault):
                    raise errors.SchemeValidationError(
                        'Option ""{}"" is required, but not found.'.format(arg.name)
                    )","class Scheme(object):
    '''The `Scheme` specifies the expected options for a configuration.

    It provides the template for what is expected when parsing and building
    configuration state. Additionally, it allows the user to specify default
    values for various fields. The `Scheme` allows for validation across all
    specified options, to the extent that the constraints are specified on
    those options.
    '''

    def __init__(self, *args):
        pass

    def build_defaults(self):
    '''Build a dictionary of default values from the `Scheme`.

        Returns:
            dict: The default configurations as set by the `Scheme`.

        Raises:
            errors.InvalidSchemeError: The `Scheme` does not contain
                valid options.
        '''
        pass

    def flatten(self):
    '''Flatten the scheme into a dictionary where the keys are
        compound 'dot' notation keys, and the values are the corresponding
        options.

        Returns:
            dict: The flattened `Scheme`.
        '''
        pass

    def validate(self, config):
    '''Validate the given config against the `Scheme`.

        Args:
            config (dict): The configuration to validate.

        Raises:
            errors.SchemeValidationError: The configuration fails
                validation against the `Schema`.
        '''
        pass

",5,4,snippet_589,0.3333333333333333,"class Scheme(object):
    '''The `Scheme` specifies the expected options for a configuration.

    It provides the template for what is expected when parsing and building
    configuration state. Additionally, it allows the user to specify default
    values for various fields. The `Scheme` allows for validation across all
    specified options, to the extent that the constraints are specified on
    those options.
    '''

    def __init__(self, *args):
        self._options = {}
        for item in args:
            if not isinstance(item, tuple) or len(item) not in (2, 3):
                raise errors.InvalidSchemeError(f""Invalid option definition: {item!r}"")
            name = item[0]
            default = item[1]
            validator = item[2] if len(item) == 3 else None
            if not isinstance(name, str):
                raise errors.InvalidSchemeError(f""Option name must be a string: {name!r}"")
            self._options[name] = {
                'default': default,
                'validator': validator
            }

    def build_defaults(self):
        '''Build a dictionary of default values from the `Scheme`.

        Returns:
            dict: The default configurations as set by the `Scheme`.

        Raises:
            errors.InvalidSchemeError: The `Scheme` does not contain
                valid options.
        '''
        defaults = {}
        for key, spec in self._options.items():
            default = spec['default']
            if isinstance(default, Scheme):
                defaults[key] = default.build_defaults()
            else:
                defaults[key] = default
        return defaults

    def flatten(self):
        '''Flatten the scheme into a dictionary where the keys are
        compound 'dot' notation keys, and the values are the corresponding
        options.

        Returns:
            dict: The flattened `Scheme`.
        '''
        flat = {}
        for key, spec in self._options.items():
            flat[key] = spec
            default = spec['default']
            if isinstance(default, Scheme):
                nested = default.flatten()
                for nk, ns in nested.items():
                    flat[f""{key}.{nk}""] = ns
        return flat

    def validate(self, config):
        '''Validate the given config against the `Scheme`.

        Args:
            config (dict): The configuration to validate.

        Raises:
            errors.SchemeValidationError: The configuration fails
                validation against the `Schema`.
        '''
        if not isinstance(config, dict):
            raise errors.SchemeValidationError(""Config must be a dict"")
        # Check for unexpected keys
        for key in config:
            if key not in self._options:
                raise errors.SchemeValidationError(f""Unexpected key: {key}"")
        for key, spec in self._options.items():
            default = spec['default']
            validator = spec['validator']
            if key in config:
                value = config[key]
                if isinstance(default, Scheme):
                    if not isinstance(value, dict):
                        raise errors.SchemeValidationError(f""Expected dict at '{key}'"")
                    default.validate(value)
                else:
                    if validator and not validator(value):
                        raise errors.SchemeValidationError(f""Validation failed for key '{key}'"")
            else:
                # missing key
                if not isinstance(default, Scheme) and default is None:
                    raise errors.SchemeValidationError(f""Missing required key: '{key}'"")","class Scheme(object):
    '''The `Scheme` specifies the expected options for a configuration.

    It provides the template for what is expected when parsing and building
    configuration state. Additionally, it allows the user to specify default
    values for various fields. The `Scheme` allows for validation across all
    specified options, to the extent that the constraints are specified on
    those options.
    '''

    def __init__(self, *args):
        self.options = {}
        for arg in args:
            if isinstance(arg, dict):
                self.options.update(arg)
            else:
                raise TypeError(""Scheme arguments must be dictionaries"")

    def build_defaults(self):
        '''Build a dictionary of default values from the `Scheme`.

        Returns:
            dict: The default configurations as set by the `Scheme`.

        Raises:
            errors.InvalidSchemeError: The `Scheme` does not contain
                valid options.
        '''
        try:
            from . import errors
        except ImportError:
            class errors:
                class InvalidSchemeError(Exception):
                    pass
        
        if not isinstance(self.options, dict):
            raise errors.InvalidSchemeError(""Scheme options must be a dictionary"")
        
        defaults = {}
        for key, option in self.options.items():
            if hasattr(option, 'default'):
                defaults[key] = option.default
            elif isinstance(option, dict) and 'default' in option:
                defaults[key] = option['default']
        return defaults

    def flatten(self):
        '''Flatten the scheme into a dictionary where the keys are
        compound 'dot' notation keys, and the values are the corresponding
        options.

        Returns:
            dict: The flattened `Scheme`.
        '''
        def _flatten_dict(d, parent_key='', sep='.'):
            items = []
            for k, v in d.items():
                new_key = f""{parent_key}{sep}{k}"" if parent_key else k
                if isinstance(v, dict) and not hasattr(v, 'validate'):
                    items.extend(_flatten_dict(v, new_key, sep=sep).items())
                else:
                    items.append((new_key, v))
            return dict(items)
        
        return _flatten_dict(self.options)

    def validate(self, config):
        '''Validate the given config against the `Scheme`.

        Args:
            config (dict): The configuration to validate.

        Raises:
            errors.SchemeValidationError: The configuration fails
                validation against the `Schema`.
        '''
        try:
            from . import errors
        except ImportError:
            class errors:
                class SchemeValidationError(Exception):
                    pass
        
        if not isinstance(config, dict):
            raise errors.SchemeValidationError(""Configuration must be a dictionary"")
        
        for key, option in self.options.items():
            if key in config:
                value = config[key]
                # Check if option has a validate method (assuming it's an Option-like object)
                if hasattr(option, 'validate'):
                    try:
                        option.validate(value)
                    except Exception as e:
                        raise errors.SchemeValidationError(f""Validation failed for '{key}': {str(e)}"")
                # Check if option is a dict with validation rules
                elif isinstance(option, dict):
                    if 'type' in option and not isinstance(value, option['type']):
                        raise errors.SchemeValidationError(f""Type mismatch for '{key}': expected {option['type'].__name__}"")
                    if 'required' in option and option['required'] and value is None:
                        raise errors.SchemeValidationError(f""Required field '{key}' is None"")
            else:
                # Check if option is required
                if isinstance(option, dict) and option.get('required', False):
                    raise errors.SchemeValidationError(f""Required field '{key}' is missing"")","class Scheme(object):
    '''The `Scheme` specifies the expected options for a configuration.

    It provides the template for what is expected when parsing and building
    configuration state. Additionally, it allows the user to specify default
    values for various fields. The `Scheme` allows for validation across all
    specified options, to the extent that the constraints are specified on
    those options.
    '''

    def __init__(self, *args):
        self.options = {}
        for arg in args:
            if hasattr(arg, 'key'):
                self.options[arg.key] = arg
            else:
                # Handle nested schemes or other objects
                if hasattr(arg, '__dict__'):
                    for key, value in arg.__dict__.items():
                        if hasattr(value, 'key'):
                            self.options[value.key] = value

    def build_defaults(self):
        '''Build a dictionary of default values from the `Scheme`.

        Returns:
            dict: The default configurations as set by the `Scheme`.

        Raises:
            errors.InvalidSchemeError: The `Scheme` does not contain
                valid options.
        '''
        defaults = {}
        
        for key, option in self.options.items():
            if hasattr(option, 'default') and option.default is not None:
                # Handle nested keys with dot notation
                if '.' in key:
                    keys = key.split('.')
                    current = defaults
                    for k in keys[:-1]:
                        if k not in current:
                            current[k] = {}
                        current = current[k]
                    current[keys[-1]] = option.default
                else:
                    defaults[key] = option.default
        
        return defaults

    def flatten(self):
        '''Flatten the scheme into a dictionary where the keys are
        compound 'dot' notation keys, and the values are the corresponding
        options.

        Returns:
            dict: The flattened `Scheme`.
        '''
        return dict(self.options)

    def validate(self, config):
        '''Validate the given config against the `Scheme`.

        Args:
            config (dict): The configuration to validate.

        Raises:
            errors.SchemeValidationError: The configuration fails
                validation against the `Schema`.
        '''
        def _get_nested_value(data, key):
            if '.' in key:
                keys = key.split('.')
                current = data
                for k in keys:
                    if isinstance(current, dict) and k in current:
                        current = current[k]
                    else:
                        return None
                return current
            else:
                return data.get(key)

        for key, option in self.options.items():
            value = _get_nested_value(config, key)
            
            # Check if required option is present
            if hasattr(option, 'required') and option.required and value is None:
                raise errors.SchemeValidationError(f""Required option '{key}' is missing"")
            
            # Validate the value if present
            if value is not None and hasattr(option, 'validate'):
                try:
                    option.validate(value)
                except Exception as e:
                    raise errors.SchemeValidationError(f""Validation failed for option '{key}': {str(e)}"")",partial_docstr,0.6539923954372624,0.4726810673443456,0.4152866242038217,0.5424588086185044,0.5135519407581369,0.7026627218934911,0.482962962962963,0.3991097922848665,0.8841778039932251,0.8798478841781616,0.8820074796676636,0.8802789449691772,0.7587255011135857,0.6390532544378699,0.4531435349940688,0.38525564803804996,0.5136094674556212,0.4574519505532331,0.6416337285902504,0.43271767810026385,0.34478203434610305,0.8694050312042236,0.8852694034576416,0.8772655129432678,0.883656919002533,0.758532598425197,0.6319895968790636,0.4458930899608866,0.39738562091503266,0.5045513654096229,0.48406017538567886,0.7259615384615384,0.5008025682182986,0.387459807073955,0.8787426948547363,0.8831749558448792,0.8809532523155212,0.8827296495437622,0.733004328358209,0.3954983222950679,0.4037456888192399,0.42308268553682,0.4325842696629213,0.3225806451612903,0.4195266785929633,0.4108637860321929,0.4380475677017479,0.4662921348314606,0.3629032258064516,0.3951324415128,0.3986381301303583,0.4193871052938032,0.4157303370786517,0.3467741935483871
537366,kore-plugins/kore-shell,kore-plugins_kore-shell/kore_shell/lib/parsers.py,kore_shell.lib.parsers.KVParser,"class KVParser(object):

    def __init__(self, kv_sep='=', keys_sep='.'):
        self.kv_sep = kv_sep
        self.keys_sep = keys_sep

    def parse(self, kv):
        """"""
        Parses key value string into dict

        Examples:
            >> parser.parse('test1.test2=value')
            {'test1': {'test2': 'value'}}

            >> parser.parse('test=value')
            {'test': 'value'}
        """"""
        key, val = kv.split(self.kv_sep, 1)
        keys = key.split(self.keys_sep)
        for k in reversed(keys):
            val = {k: val}
        return val","class KVParser(object):


    def __init__(self, kv_sep='=', keys_sep='.'):
        pass

    def parse(self, kv):
    '''
        Parses key value string into dict

        Examples:
            >> parser.parse('test1.test2=value')
            {'test1': {'test2': 'value'}}

            >> parser.parse('test=value')
            {'test': 'value'}
        '''
        pass

",3,1,snippet_148,1.0,"class KVParser(object):
    def __init__(self, kv_sep='=', keys_sep='.'):
        self.kv_sep = kv_sep
        self.keys_sep = keys_sep

    def parse(self, kv):
        '''
        Parses key value string into dict

        Examples:
            >> parser.parse('test1.test2=value')
            {'test1': {'test2': 'value'}}

            >> parser.parse('test=value')
            {'test': 'value'}
        '''
        key_str, value = kv.split(self.kv_sep, 1)
        parts = key_str.split(self.keys_sep) if self.keys_sep else [key_str]
        result = current = {}
        for part in parts[:-1]:
            current[part] = {}
            current = current[part]
        current[parts[-1]] = value
        return result","class KVParser(object):
    def __init__(self, kv_sep='=', keys_sep='.'):
        self.kv_sep = kv_sep
        self.keys_sep = keys_sep

    def parse(self, kv):
        '''
        Parses key value string into dict

        Examples:
            >> parser.parse('test1.test2=value')
            {'test1': {'test2': 'value'}}

            >> parser.parse('test=value')
            {'test': 'value'}
        '''
        if self.kv_sep not in kv:
            return {}
        
        key_part, value = kv.split(self.kv_sep, 1)
        keys = key_part.split(self.keys_sep)
        
        result = {}
        current = result
        
        for i, key in enumerate(keys):
            if i == len(keys) - 1:
                current[key] = value
            else:
                if key not in current:
                    current[key] = {}
                current = current[key]
        
        return result","class KVParser(object):

    def __init__(self, kv_sep='=', keys_sep='.'):
        self.kv_sep = kv_sep
        self.keys_sep = keys_sep

    def parse(self, kv):
        '''
        Parses key value string into dict

        Examples:
            >> parser.parse('test1.test2=value')
            {'test1': {'test2': 'value'}}

            >> parser.parse('test=value')
            {'test': 'value'}
        '''
        if self.kv_sep not in kv:
            return {}
        
        key_part, value = kv.split(self.kv_sep, 1)
        keys = key_part.split(self.keys_sep)
        
        result = {}
        current = result
        
        for key in keys[:-1]:
            current[key] = {}
            current = current[key]
        
        current[keys[-1]] = value
        
        return result",partial_docstr,0.7870967741935485,0.69281045751634,0.662251655629139,0.7741935483870968,0.6721804645840875,0.7340425531914894,0.6577540106951871,0.6290322580645161,0.9225006103515625,0.9675449132919312,0.9444860219955444,0.9628435373306274,0.9035097368421052,0.7380952380952381,0.6506024096385542,0.621951219512195,0.7380952380952381,0.6315375268262922,0.6811594202898551,0.6213592233009708,0.5951219512195122,0.8856982588768005,0.9596017599105835,0.9211701154708862,0.9516609907150269,0.8756231343283583,0.7898089171974523,0.6967741935483871,0.6666666666666667,0.7898089171974523,0.6759443386450694,0.7315789473684211,0.6613756613756614,0.6382978723404256,0.9172002077102661,0.9642285108566284,0.9401265978813171,0.9593096971511841,0.893558487394958,0.6607028240285887,0.4777213961021834,0.6274554914100208,0.6666666666666666,0.8709677419354839,0.6761119758365937,0.3994944499121475,0.6636324088873762,0.7380952380952381,0.9032258064516128,0.6893993657718093,0.4764535334625337,0.6636324088873762,0.7142857142857143,0.9032258064516128
215080,adamrehn/ue4cli,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/adamrehn_ue4cli/ue4cli/UnrealManagerFactory.py,ue4cli.UnrealManagerFactory.UnrealManagerFactory,"class UnrealManagerFactory:
    """"""
    Factory class for creating UnrealManagerBase instances
    """"""

    @staticmethod
    def create():
        """"""
        Creates an Unreal manager instance for the current platform
        """"""
        return UnrealManagerImp()","class UnrealManagerFactory:
    '''
    Factory class for creating UnrealManagerBase instances
    '''

    @staticmethod
    def create():
    '''
        Creates an Unreal manager instance for the current platform
        '''
        pass

",3,2,snippet_698,1.0,"class UnrealManagerFactory:
    '''
    Factory class for creating UnrealManagerBase instances
    '''

    @staticmethod
    def create():
        '''
        Creates an Unreal manager instance for the current platform
        '''
        platform = sys.platform
        if platform.startswith(""win""):
            from unreal_manager.windows import WindowsUnrealManager
            return WindowsUnrealManager()
        elif platform.startswith(""linux""):
            from unreal_manager.linux import LinuxUnrealManager
            return LinuxUnrealManager()
        elif platform == ""darwin"":
            from unreal_manager.mac import MacUnrealManager
            return MacUnrealManager()
        else:
            raise NotImplementedError(f""Unsupported platform: {platform}"")","class UnrealManagerFactory:
    '''
    Factory class for creating UnrealManagerBase instances
    '''

    @staticmethod
    def create():
        '''
        Creates an Unreal manager instance for the current platform
        '''
        import platform
        from .unreal_manager_base import UnrealManagerBase
        from .unreal_manager_windows import UnrealManagerWindows
        from .unreal_manager_linux import UnrealManagerLinux
        from .unreal_manager_mac import UnrealManagerMac

        system = platform.system().lower()
        
        if system == 'windows':
            return UnrealManagerWindows()
        elif system == 'linux':
            return UnrealManagerLinux()
        elif system == 'darwin':
            return UnrealManagerMac()
        else:
            return UnrealManagerBase()","class UnrealManagerFactory:
    '''
    Factory class for creating UnrealManagerBase instances
    '''

    @staticmethod
    def create():
        '''
        Creates an Unreal manager instance for the current platform
        '''
        system = platform.system().lower()
        
        if system == 'windows':
            from .windows_unreal_manager import WindowsUnrealManager
            return WindowsUnrealManager()
        elif system == 'darwin':
            from .mac_unreal_manager import MacUnrealManager
            return MacUnrealManager()
        elif system == 'linux':
            from .linux_unreal_manager import LinuxUnrealManager
            return LinuxUnrealManager()
        else:
            raise NotImplementedError(f""Unreal manager not implemented for platform: {system}"")",partial_docstr,0.4827586206896552,0.4470588235294118,0.4337349397590361,0.4827586206896552,0.21978611340914384,0.32456140350877194,0.20353982300884957,0.16071428571428573,0.714715838432312,0.9437664151191711,0.8134241700172424,0.9144600033760071,0.7508442424242424,0.4666666666666667,0.43181818181818177,0.41860465116279066,0.4666666666666667,0.20086567781614892,0.25217391304347825,0.20175438596491227,0.1592920353982301,0.7473177313804626,0.9374406337738037,0.8316515684127808,0.9141831398010254,0.7452855660377359,0.4666666666666667,0.43181818181818177,0.41860465116279066,0.4666666666666667,0.20183978793295226,0.26495726495726496,0.19827586206896552,0.1565217391304348,0.7072004079818726,0.9446855783462524,0.8088718056678772,0.9139927625656128,0.7483685294117646,0.5695683768681106,0.2443303216865964,0.5793977312403916,0.4545454545454545,0.0,0.5847170767581167,0.2140160303375297,0.5793977312403916,0.5454545454545454,0.0,0.561989804030844,0.2140160303375297,0.5793977312403916,0.4545454545454545,0.0
349463,doraemonext/wechat-python-sdk,doraemonext_wechat-python-sdk/wechat_sdk/lib/crypto/base.py,wechat_sdk.lib.crypto.base.BaseCrypto,"class BaseCrypto(object):
    """"""""""""

    def __init__(self, key):
        # self.key = base64.b64decode(key+""="")
        self.key = key
        # AESCBC
        self.mode = AES.MODE_CBC

    def encrypt(self, text, appid):
        """"""

        @param text: 
        @return: 
        """"""
        # 16
        text = self.get_random_str() + struct.pack(""I"", socket.htonl(len(text))) + to_binary(text) + appid
        # 
        pkcs7 = PKCS7Encoder()
        text = pkcs7.encode(text)
        # 
        cryptor = AES.new(self.key, self.mode, self.key[:16])
        try:
            ciphertext = cryptor.encrypt(text)
            # BASE64
            return base64.b64encode(ciphertext)
        except Exception as e:
            raise EncryptAESError(e)

    def decrypt(self, text, appid):
        """"""

        @param text: 
        @return: 
        """"""
        try:
            cryptor = AES.new(self.key, self.mode, self.key[:16])
            # BASE64AES-CBC
            plain_text = cryptor.decrypt(base64.b64decode(text))
        except Exception as e:
            raise DecryptAESError(e)

        try:
            if six.PY2:
                pad = ord(plain_text[-1])
            else:
                pad = plain_text[-1]
            # 
            # pkcs7 = PKCS7Encoder()
            # plain_text = pkcs7.encode(plain_text)
            # 16
            content = plain_text[16:-pad]
            xml_len = socket.ntohl(struct.unpack(""I"", content[: 4])[0])
            xml_content = content[4: xml_len + 4]
            from_appid = content[xml_len + 4:]
        except Exception as e:
            raise IllegalBuffer(e)
        if from_appid != appid:
            raise ValidateAppIDError()
        return xml_content

    def get_random_str(self):
        """""" 16

        @return: 16
        """"""
        rule = string.ascii_letters + string.digits
        return """".join(random.sample(rule, 16))","class BaseCrypto(object):
    ''''''

    def __init__(self, key):
        pass

    def encrypt(self, text, appid):
    '''

        @param text: 
        @return: 
        '''
        pass

    def decrypt(self, text, appid):
    '''

        @param text: 
        @return: 
        '''
        pass

    def get_random_str(self):
    ''' 16

        @return: 16
        '''
        pass

",5,4,snippet_342,0.2142857142857142,"class BaseCrypto(object):
    ''''''

    def __init__(self, key):
        self.key = base64.b64decode(key + '=')
        self.iv = self.key[:16]
        self.block_size = 32

    def encrypt(self, text, appid):
        # 
        random_str = self.get_random_str().encode('utf-8')
        text_bytes = text.encode('utf-8')
        appid_bytes = appid.encode('utf-8')
        msg_len = struct.pack('!I', len(text_bytes))
        raw = random_str + msg_len + text_bytes + appid_bytes
        # PKCS7 Padding
        pad_len = self.block_size - (len(raw) % self.block_size)
        raw += bytes([pad_len]) * pad_len
        cipher = AES.new(self.key, AES.MODE_CBC, self.iv)
        encrypted = cipher.encrypt(raw)
        return base64.b64encode(encrypted).decode('utf-8')

    def decrypt(self, text, appid):
        cipher_data = base64.b64decode(text)
        cipher = AES.new(self.key, AES.MODE_CBC, self.iv)
        decrypted = cipher.decrypt(cipher_data)
        # 
        pad_len = decrypted[-1]
        decrypted = decrypted[:-pad_len]
        # 
        content = decrypted[16:]
        msg_len = struct.unpack('!I', content[:4])[0]
        xml_msg = content[4:4+msg_len]
        recv_appid = content[4+msg_len:].decode('utf-8')
        if recv_appid != appid:
            raise ValueError(""AppID mismatch"")
        return xml_msg.decode('utf-8')

    def get_random_str(self):
        return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(16))","class BaseCrypto(object):
    ''''''

    def __init__(self, key):
        # keybase64AES
        self.key = base64.b64decode(key + ""="")
        self.iv = self.key[:16]

    def encrypt(self, text, appid):
        '''

        @param text: 
        @return: 
        '''
        # 16
        random_str = self.get_random_str()
        
        # 
        text_length = len(text)
        
        # 
        plaintext = random_str + str(text_length).zfill(8) + text + appid
        
        # 
        amount_to_pad = AES.block_size - (len(plaintext) % AES.block_size)
        if amount_to_pad == 0:
            amount_to_pad = AES.block_size
        pad_chr = chr(amount_to_pad)
        plaintext += pad_chr * amount_to_pad
        
        # AES
        cipher = AES.new(self.key, AES.MODE_CBC, self.iv)
        ciphertext = cipher.encrypt(plaintext.encode('utf-8'))
        
        # base64
        return base64.b64encode(ciphertext).decode('utf-8')

    def decrypt(self, text, appid):
        '''

        @param text: 
        @return: 
        '''
        # base64
        ciphertext = base64.b64decode(text)
        
        # AES
        cipher = AES.new(self.key, AES.MODE_CBC, self.iv)
        plaintext = cipher.decrypt(ciphertext).decode('utf-8')
        
        # 
        pad = ord(plaintext[-1])
        plaintext = plaintext[:-pad]
        
        # 
        random_str = plaintext[:16]
        msg_len = int(plaintext[16:24])
        msg = plaintext[24:24+msg_len]
        appid_from_msg = plaintext[24+msg_len:]
        
        # appid
        if appid_from_msg != appid:
            raise Exception(""Invalid appid"")
        
        return msg

    def get_random_str(self):
        ''' 16

        @return: 16
        '''
        return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(16))","class BaseCrypto(object):
    ''''''

    def __init__(self, key):
        self.key = base64.b64decode(key + ""="")
        self.mode = AES.MODE_CBC

    def encrypt(self, text, appid):
        '''

        @param text: 
        @return: 
        '''
        text = text.encode('utf-8')
        random_str = self.get_random_str().encode('utf-8')
        text_length = struct.pack(""I"", socket.htonl(len(text)))
        appid = appid.encode('utf-8')
        
        content = random_str + text_length + text + appid
        content_length = len(content)
        
        # PKCS7 padding
        pad_length = 32 - (content_length % 32)
        if pad_length == 0:
            pad_length = 32
        
        padded_content = content + (chr(pad_length) * pad_length).encode('utf-8')
        
        iv = self.key[:16]
        cipher = AES.new(self.key, self.mode, iv)
        encrypted = cipher.encrypt(padded_content)
        
        return base64.b64encode(encrypted).decode('utf-8')

    def decrypt(self, text, appid):
        '''

        @param text: 
        @return: 
        '''
        cipher_text = base64.b64decode(text)
        iv = self.key[:16]
        cipher = AES.new(self.key, self.mode, iv)
        decrypted = cipher.decrypt(cipher_text)
        
        # Remove padding
        pad_length = decrypted[-1]
        if isinstance(pad_length, str):
            pad_length = ord(pad_length)
        
        content = decrypted[:-pad_length]
        
        # Extract components
        random_str = content[:16]
        text_length = struct.unpack(""I"", socket.ntohl(struct.unpack(""I"", content[16:20])[0]).to_bytes(4, 'big'))[0]
        text = content[20:20+text_length]
        from_appid = content[20+text_length:]
        
        return text.decode('utf-8')

    def get_random_str(self):
        ''' 16

        @return: 16
        '''
        return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(16))",partial_docstr,0.5527638190954773,0.3181818181818182,0.20812182741116753,0.4623115577889447,0.4271467175168559,0.7104622871046229,0.4585365853658537,0.33251833740831294,0.8600564002990723,0.7712817788124084,0.81325364112854,0.7793259024620056,0.8048572268907562,0.5566502463054187,0.32673267326732675,0.22388059701492538,0.42857142857142855,0.45690821989197905,0.7048054919908466,0.45642201834862384,0.33793103448275863,0.8846285939216614,0.8719154000282288,0.8782259821891785,0.8731701970100403,0.802471111111111,0.6093023255813954,0.38785046728971967,0.2910798122065728,0.46511627906976744,0.5160535564901427,0.7053941908713693,0.49480249480249483,0.39375,0.893947958946228,0.8663951754570007,0.8799559473991394,0.8690738081932068,0.8027068257756564,0.237497006889973,0.058222647647539,0.0631563793278995,0.4406779661016949,0.3879310344827586,0.2924468082805337,0.1351485328303446,0.1370641824659576,0.4406779661016949,0.4568965517241379,0.3013389335271759,0.1505554581647398,0.1518682673719787,0.4632768361581921,0.4396551724137931
685886,quantrocket-llc/ibapi-grease,quantrocket-llc_ibapi-grease/ibapi_grease/lock.py,ibapi_grease.lock.FakeLock,"class FakeLock(object):
    """"""
    This is a dummy lock to disable locking of the IB socket connection, which
    is slow and unnecessary. https://github.com/InteractiveBrokers/tws-api/issues/464
    """"""
    def acquire(self):
        pass

    def release(self):
        pass","class FakeLock(object):
    '''
    This is a dummy lock to disable locking of the IB socket connection, which
    is slow and unnecessary. https://github.com/InteractiveBrokers/tws-api/issues/464
    '''

    def acquire(self):
        pass

    def release(self):
        pass

",3,1,snippet_72,1.0,"class FakeLock(object):
    '''
    This is a dummy lock to disable locking of the IB socket connection, which
    is slow and unnecessary. https://github.com/InteractiveBrokers/tws-api/issues/464
    '''

    def acquire(self):
        return True

    def release(self):
        pass","class FakeLock(object):
    '''
    This is a dummy lock to disable locking of the IB socket connection, which
    is slow and unnecessary. https://github.com/InteractiveBrokers/tws-api/issues/464
    '''

    def acquire(self):
        pass

    def release(self):
        pass","class FakeLock(object):
    '''
    This is a dummy lock to disable locking of the IB socket connection, which
    is slow and unnecessary. https://github.com/InteractiveBrokers/tws-api/issues/464
    '''

    def acquire(self):
        pass

    def release(self):
        pass

    def __enter__(self):
        self.acquire()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()
        return False",partial_docstr,0.9599999999999999,0.9315068493150684,0.9014084507042254,0.9599999999999999,0.8333519318655754,0.9322033898305084,0.8793103448275862,0.8245614035087719,0.9844328165054321,0.996003270149231,0.9901842474937439,0.9948340058326721,0.9722225,1.0,1.0,1.0,1.0,0.8659727029754526,0.9655172413793104,0.9298245614035088,0.8928571428571429,0.9986953139305115,0.9986953139305115,0.9986953139305115,0.9986953139305115,1.0,0.7872340425531915,0.782608695652174,0.7777777777777778,0.7872340425531915,0.5140291188632828,0.5384615384615384,0.5145631067961165,0.49019607843137253,0.8996160626411438,0.9891082048416138,0.9422419667243958,0.9793657064437866,0.8141044230769231,0.7970788441446134,0.7074355287362128,0.7308798478422407,0.75,1.0,0.9122951031510496,0.82066080152207,0.8285196110821281,1.0,1.0,0.7838774479619369,0.5569901807656197,0.8285196110821281,0.75,1.0
125663,GoogleCloudPlatform/datastore-ndb-python,GoogleCloudPlatform_datastore-ndb-python/ndb/eventloop.py,ndb.eventloop._Clock,"class _Clock(object):
  """"""A clock to determine the current time, in seconds.""""""

  def now(self):
    """"""Returns the number of seconds since epoch.""""""
    return time.time()

  def sleep(self, seconds):
    """"""Sleeps for the desired number of seconds.""""""
    time.sleep(seconds)","class _Clock(object):
    '''A clock to determine the current time, in seconds.'''

  def now(self):
    '''Returns the number of seconds since epoch.'''
    pass

  def sleep(self, seconds):
    '''Sleeps for the desired number of seconds.'''
    pass

",3,3,snippet_611,1.0,"class _Clock(object):
    '''A clock to determine the current time, in seconds.'''

    def now(self):
        '''Returns the number of seconds since epoch.'''
        return time.time()

    def sleep(self, seconds):
        '''Sleeps for the desired number of seconds.'''
        time.sleep(seconds)","class _Clock(object):
    '''A clock to determine the current time, in seconds.'''

    def now(self):
        '''Returns the number of seconds since epoch.'''
        return time.time()

    def sleep(self, seconds):
        '''Sleeps for the desired number of seconds.'''
        time.sleep(seconds)","class _Clock(object):
    '''A clock to determine the current time, in seconds.'''

    def now(self):
        '''Returns the number of seconds since epoch.'''
        return time.time()

    def sleep(self, seconds):
        '''Sleeps for the desired number of seconds.'''
        time.sleep(seconds)",partial_docstr,1.0,1.0,1.0,1.0,0.6340294482386416,0.90625,0.8095238095238095,0.7096774193548387,0.9891141057014465,0.9891141057014465,0.9891141057014465,0.9891141057014465,1.0,1.0,1.0,1.0,1.0,0.6340294482386416,0.90625,0.8095238095238095,0.7096774193548387,0.9891141057014465,0.9891141057014465,0.9891141057014465,0.9891141057014465,1.0,1.0,1.0,1.0,1.0,0.6340294482386416,0.90625,0.8095238095238095,0.7096774193548387,0.9891141057014465,0.9891141057014465,0.9891141057014465,0.9891141057014465,1.0,0.7663462385017673,0.5267368863197448,0.5386480676873244,1.0,1.0,0.7663462385017673,0.5267368863197448,0.5386480676873244,1.0,1.0,0.7663462385017673,0.5267368863197448,0.5386480676873244,1.0,1.0
549181,lionel/counterparts,lionel_counterparts/counterparts.py,counterparts.CounterpartMapping,"class CounterpartMapping:
    """"""This class carries the pieces needed to perform mappings.

    Sections represent groups that enable this mapping to apply
    different rules depending on attributes of the input.  The two
    sections here are COUNTERPART_MAP and COUNTERPART_DIR.

    CounterpartMapping is much like a collections.Mapping, but it does
    not support the __iter__ and __len__ methods specified for that
    class.  Unlike mapping functions with a fixed set of keys, the
    domain may be unknown when the COUNTERPART_DIR section is present
    in the config.

    """"""
    def __init__(self, map_config):

        logger.debug(""NEW: CounterpartMapping w/%s"", map_config)
        self._map_config = map_config

    def __getitem__(self, known):
        """"""If the counterpart is named explicitly in COUNTERPART_MAP, return
        it.  When `prepend_path` is given in the COUNTERPART_DIR
        section, it is prepended to all input that lacks an explicitly
        named counterpart in COUNTERPART_MAP.

        """"""

        try:
            counterpart = self._map_config.get(""COUNTERPART_MAP"", known)
            logger.debug(""Result for %s: %s"", known, counterpart)
        except (config_parser.NoSectionError, config_parser.NoOptionError):
            try:
                msg = ""Nothing for '%s';"" % (known)
                prepend = self._map_config.get(""COUNTERPART_DIR"",
                                               ""prepend_path"")
                counterpart = os.path.join(prepend, os.path.relpath(known))
                logger.debug(""%s result with prepend (%s): %s"",
                             msg, prepend, counterpart)
            except config_parser.NoSectionError:
                logger.debug(""%s (and no prepend_path)"", msg)
                raise KeyError(""Mapping not found in COUNTERPART_MAP: "" +
                               ""%s"" % (known))

        return counterpart","class CounterpartMapping:
    '''This class carries the pieces needed to perform mappings.

    Sections represent groups that enable this mapping to apply
    different rules depending on attributes of the input.  The two
    sections here are COUNTERPART_MAP and COUNTERPART_DIR.

    CounterpartMapping is much like a collections.Mapping, but it does
    not support the __iter__ and __len__ methods specified for that
    class.  Unlike mapping functions with a fixed set of keys, the
    domain may be unknown when the COUNTERPART_DIR section is present
    in the config.

    '''

    def __init__(self, map_config):
        pass

    def __getitem__(self, known):
    '''If the counterpart is named explicitly in COUNTERPART_MAP, return
        it.  When `prepend_path` is given in the COUNTERPART_DIR
        section, it is prepended to all input that lacks an explicitly
        named counterpart in COUNTERPART_MAP.

        '''
        pass

",3,2,snippet_356,0.4285714285714285,"class CounterpartMapping:
    '''This class carries the pieces needed to perform mappings.

    Sections represent groups that enable this mapping to apply
    different rules depending on attributes of the input.  The two
    sections here are COUNTERPART_MAP and COUNTERPART_DIR.

    CounterpartMapping is much like a collections.Mapping, but it does
    not support the __iter__ and __len__ methods specified for that
    class.  Unlike mapping functions with a fixed set of keys, the
    domain may be unknown when the COUNTERPART_DIR section is present
    in the config.
    '''

    def __init__(self, map_config):
        self._map = {}
        self._prepend = None
        if map_config is None:
            return
        cm = map_config.get('COUNTERPART_MAP')
        if cm:
            self._map.update(cm)
        cd = map_config.get('COUNTERPART_DIR')
        if cd:
            self._prepend = cd.get('prepend_path')

    def __getitem__(self, known):
        '''If the counterpart is named explicitly in COUNTERPART_MAP, return
        it.  When `prepend_path` is given in the COUNTERPART_DIR
        section, it is prepended to all input that lacks an explicitly
        named counterpart in COUNTERPART_MAP.
        '''
        if known in self._map:
            return self._map[known]
        if self._prepend is not None:
            return os.path.join(self._prepend, known)
        raise KeyError(known)","class CounterpartMapping:
    '''This class carries the pieces needed to perform mappings.

    Sections represent groups that enable this mapping to apply
    different rules depending on attributes of the input.  The two
    sections here are COUNTERPART_MAP and COUNTERPART_DIR.

    CounterpartMapping is much like a collections.Mapping, but it does
    not support the __iter__ and __len__ methods specified for that
    class.  Unlike mapping functions with a fixed set of keys, the
    domain may be unknown when the COUNTERPART_DIR section is present
    in the config.

    '''

    def __init__(self, map_config):
        self.map_config = map_config
        self.counterpart_map = map_config.get('COUNTERPART_MAP', {})
        self.counterpart_dir = map_config.get('COUNTERPART_DIR', {})

    def __getitem__(self, known):
        '''If the counterpart is named explicitly in COUNTERPART_MAP, return
        it.  When `prepend_path` is given in the COUNTERPART_DIR
        section, it is prepended to all input that lacks an explicitly
        named counterpart in COUNTERPART_MAP.

        '''
        if known in self.counterpart_map:
            return self.counterpart_map[known]
        
        prepend_path = self.counterpart_dir.get('prepend_path')
        if prepend_path is not None:
            return prepend_path + known
        
        raise KeyError(known)","class CounterpartMapping:
    '''This class carries the pieces needed to perform mappings.

    Sections represent groups that enable this mapping to apply
    different rules depending on attributes of the input.  The two
    sections here are COUNTERPART_MAP and COUNTERPART_DIR.

    CounterpartMapping is much like a collections.Mapping, but it does
    not support the __iter__ and __len__ methods specified for that
    class.  Unlike mapping functions with a fixed set of keys, the
    domain may be unknown when the COUNTERPART_DIR section is present
    in the config.

    '''

    def __init__(self, map_config):
        self.counterpart_map = map_config.get('COUNTERPART_MAP', {})
        self.counterpart_dir = map_config.get('COUNTERPART_DIR', {})
        self.prepend_path = self.counterpart_dir.get('prepend_path', '')

    def __getitem__(self, known):
        '''If the counterpart is named explicitly in COUNTERPART_MAP, return
        it.  When `prepend_path` is given in the COUNTERPART_DIR
        section, it is prepended to all input that lacks an explicitly
        named counterpart in COUNTERPART_MAP.

        '''
        if known in self.counterpart_map:
            return self.counterpart_map[known]
        elif self.prepend_path:
            return self.prepend_path + known
        else:
            raise KeyError(known)",partial_docstr,0.792270531400966,0.6990291262135921,0.6487804878048781,0.7149758454106279,0.5039251939251987,0.8610169491525423,0.6972789115646258,0.6416382252559727,0.9345254898071289,0.8923316597938538,0.9129413962364197,0.896378755569458,0.7777800000000002,0.8345679012345678,0.7196029776674938,0.6783042394014962,0.7555555555555555,0.4810124876725865,0.89568345323741,0.7256317689530686,0.6630434782608695,0.9465672969818115,0.8868840932846069,0.9157542586326599,0.8925116658210754,0.7834296610169494,0.8229426433915212,0.7017543859649122,0.6649874055415618,0.7331670822942644,0.4706587650655379,0.894927536231884,0.7127272727272728,0.6532846715328468,0.9451441764831543,0.8824384212493896,0.9127155542373657,0.8883320689201355,0.7740135593220343,0.4879149209992094,0.5942121140384576,0.6113864022104651,0.3614457831325301,0.3846153846153846,0.4701473119893369,0.587335690939878,0.6120672734215475,0.3734939759036144,0.3076923076923077,0.4747942685275849,0.5786963996991838,0.6056984686650944,0.3493975903614458,0.3653846153846153
207931,WojciechMula/pyahocorasick,WojciechMula_pyahocorasick/etc/py/pyahocorasick.py,pyahocorasick.TrieNode,"class TrieNode(object):
    """"""
    Node of trie/Aho-Corasick automaton
    """"""

    __slots__ = ['char', 'output', 'fail', 'children']

    def __init__(self, char):
        """"""
        Constructs an empty node
        """"""

        self.char = char  # character
        self.output = nil  # an output function for this node
        self.fail = nil  # fail link used by Aho-Corasick automaton
        self.children = {}  # children

    def __repr__(self):
        """"""
        Textual representation of node.
        """"""

        if self.output is not nil:
            return ""<TrieNode '%s' '%s'>"" % (self.char, self.output)
        else:
            return ""<TrieNode '%s'>"" % self.char","class TrieNode(object):
    '''
    Node of trie/Aho-Corasick automaton
    '''

    def __init__(self, char):
    '''
        Constructs an empty node
        '''
        pass

    def __repr__(self):
    '''
        Textual representation of node.
        '''
        pass

",3,3,snippet_269,0.6,"class TrieNode(object):
    '''
    Node of trie/Aho-Corasick automaton
    '''

    def __init__(self, char):
        '''
        Constructs an empty node
        '''
        self.char = char
        self.children = {}
        self.fail = None
        self.output = []

    def __repr__(self):
        '''
        Textual representation of node.
        '''
        return f""TrieNode(char={self.char!r}, children={list(self.children.keys())}, fail={id(self.fail)}, output={self.output})""","class TrieNode(object):
    '''
    Node of trie/Aho-Corasick automaton
    '''

    def __init__(self, char):
        '''
        Constructs an empty node
        '''
        self.char = char
        self.children = {}
        self.is_end_of_word = False
        self.fail = None
        self.output = []

    def __repr__(self):
        '''
        Textual representation of node.
        '''
        return f""TrieNode(char='{self.char}', children={list(self.children.keys())}, is_end_of_word={self.is_end_of_word})""","class TrieNode(object):
    '''
    Node of trie/Aho-Corasick automaton
    '''

    def __init__(self, char):
        '''
        Constructs an empty node
        '''
        self.char = char
        self.children = {}
        self.is_end_of_word = False
        self.failure_link = None
        self.output_link = None
        self.patterns = []

    def __repr__(self):
        '''
        Textual representation of node.
        '''
        return f""TrieNode('{self.char}')""",partial_docstr,0.734375,0.47619047619047616,0.33870967741935487,0.59375,0.3818315605979233,0.7295081967213115,0.512396694214876,0.39166666666666666,0.9192284941673279,0.8771705627441406,0.8977071642875671,0.8812023997306824,0.8138156756756757,0.6518518518518519,0.43609022556390975,0.32061068702290074,0.5481481481481482,0.3907958975336554,0.6865671641791045,0.45864661654135336,0.3484848484848485,0.8847153186798096,0.8705291748046875,0.8775649070739746,0.8719272613525391,0.8168186486486485,0.64,0.4552845528455285,0.34710743801652894,0.56,0.33111701828416845,0.8113207547169812,0.5333333333333333,0.40384615384615385,0.909061074256897,0.8739440441131592,0.8911567330360413,0.8773331046104431,0.8138156756756757,0.1928306907467436,0.1140059349985539,0.1456111423696915,0.4347826086956521,0.0769230769230769,0.1943524630731851,0.1193080301370514,0.1463961365369597,0.4347826086956521,0.0769230769230769,0.1921446181992913,0.1160308111294055,0.1408419760490305,0.4347826086956521,0.0769230769230769
377786,fabioz/PyDev.Debugger,fabioz_PyDev.Debugger/pydevd_attach_to_process/winappdbg/win32/defines.py,winappdbg.win32.defines.DefaultStringType,"class DefaultStringType(object):
    """"""
    Decorator that uses the default version (A or W) to call
    based on the configuration of the L{GuessStringType} decorator.

    @see: L{GuessStringType.t_default}

    @type fn_ansi: function
    @ivar fn_ansi: ANSI version of the API function to call.
    @type fn_unicode: function
    @ivar fn_unicode: Unicode (wide) version of the API function to call.
    """"""

    def __init__(self, fn_ansi, fn_unicode):
        """"""
        @type  fn_ansi: function
        @param fn_ansi: ANSI version of the API function to call.
        @type  fn_unicode: function
        @param fn_unicode: Unicode (wide) version of the API function to call.
        """"""
        self.fn_ansi = fn_ansi
        self.fn_unicode = fn_unicode

        # Copy the wrapped function attributes.
        try:
            self.__name__ = self.fn_ansi.__name__[:-1]  # remove the A or W
        except AttributeError:
            pass
        try:
            self.__module__ = self.fn_ansi.__module__
        except AttributeError:
            pass
        try:
            self.__doc__ = self.fn_ansi.__doc__
        except AttributeError:
            pass

    def __call__(self, *argv, **argd):
        # Get the appropriate function based on the default.
        if GuessStringType.t_default == GuessStringType.t_ansi:
            fn = self.fn_ansi
        else:
            fn = self.fn_unicode

        # Call the function and return the result
        return fn(*argv, **argd)","class DefaultStringType(object):
    '''
    Decorator that uses the default version (A or W) to call
    based on the configuration of the L{GuessStringType} decorator.

    @see: L{GuessStringType.t_default}

    @type fn_ansi: function
    @ivar fn_ansi: ANSI version of the API function to call.
    @type fn_unicode: function
    @ivar fn_unicode: Unicode (wide) version of the API function to call.
    '''

    def __init__(self, fn_ansi, fn_unicode):
    '''
        @type  fn_ansi: function
        @param fn_ansi: ANSI version of the API function to call.
        @type  fn_unicode: function
        @param fn_unicode: Unicode (wide) version of the API function to call.
        '''
        pass

    def __call__(self, *argv, **argd):
        pass

",3,2,snippet_52,0.4,"class DefaultStringType(object):
    '''
    Decorator that uses the default version (A or W) to call
    based on the configuration of the L{GuessStringType} decorator.

    @see: L{GuessStringType.t_default}

    @type fn_ansi: function
    @ivar fn_ansi: ANSI version of the API function to call.
    @type fn_unicode: function
    @ivar fn_unicode: Unicode (wide) version of the API function to call.
    '''
    def __init__(self, fn_ansi, fn_unicode):
        '''
        @type  fn_ansi: function
        @param fn_ansi: ANSI version of the API function to call.
        @type  fn_unicode: function
        @param fn_unicode: Unicode (wide) version of the API function to call.
        '''
        self.fn_ansi = fn_ansi
        self.fn_unicode = fn_unicode
        update_wrapper(self, fn_ansi)

    def __call__(self, *argv, **argd):
        from __main__ import GuessStringType
        t = GuessStringType.t_default
        if t == 'W':
            return self.fn_unicode(*argv, **argd)
        return self.fn_ansi(*argv, **argd)","class DefaultStringType(object):
    '''
    Decorator that uses the default version (A or W) to call
    based on the configuration of the L{GuessStringType} decorator.

    @see: L{GuessStringType.t_default}

    @type fn_ansi: function
    @ivar fn_ansi: ANSI version of the API function to call.
    @type fn_unicode: function
    @ivar fn_unicode: Unicode (wide) version of the API function to call.
    '''

    def __init__(self, fn_ansi, fn_unicode):
        '''
        @type  fn_ansi: function
        @param fn_ansi: ANSI version of the API function to call.
        @type  fn_unicode: function
        @param fn_unicode: Unicode (wide) version of the API function to call.
        '''
        self.fn_ansi = fn_ansi
        self.fn_unicode = fn_unicode

    def __call__(self, *argv, **argd):
        from GuessStringType import t_default
        if t_default == 'A':
            return self.fn_ansi(*argv, **argd)
        else:
            return self.fn_unicode(*argv, **argd)","class DefaultStringType(object):
    '''
    Decorator that uses the default version (A or W) to call
    based on the configuration of the L{GuessStringType} decorator.

    @see: L{GuessStringType.t_default}

    @type fn_ansi: function
    @ivar fn_ansi: ANSI version of the API function to call.
    @type fn_unicode: function
    @ivar fn_unicode: Unicode (wide) version of the API function to call.
    '''

    def __init__(self, fn_ansi, fn_unicode):
        '''
        @type  fn_ansi: function
        @param fn_ansi: ANSI version of the API function to call.
        @type  fn_unicode: function
        @param fn_unicode: Unicode (wide) version of the API function to call.
        '''
        self.fn_ansi = fn_ansi
        self.fn_unicode = fn_unicode

    def __call__(self, *argv, **argd):
        from . import GuessStringType
        if GuessStringType.t_default == GuessStringType.t_ansi:
            return self.fn_ansi(*argv, **argd)
        else:
            return self.fn_unicode(*argv, **argd)",partial_docstr,0.8048780487804879,0.7423312883435583,0.6913580246913581,0.7682926829268293,0.5656967391274038,0.9130434782608695,0.8293650793650794,0.7768924302788844,0.950560450553894,0.8979523181915283,0.9235077500343323,0.9029496312141418,0.8091622137404579,0.8074534161490684,0.7312500000000001,0.6918238993710693,0.7763975155279503,0.5389623556154957,0.9369747899159664,0.8649789029535865,0.8177966101694916,0.9598478078842163,0.9037586450576782,0.930959165096283,0.9090708494186401,0.7913506870229008,0.804953560371517,0.7538940809968848,0.7210031347962383,0.7925696594427244,0.5619254423563955,0.9380165289256198,0.8838174273858921,0.8416666666666667,0.9578876495361328,0.900969922542572,0.9285573959350586,0.9063555002212524,0.7964396946564885,0.4788371107860292,0.5003948677055308,0.5213515959405303,0.4057971014492754,0.4878048780487805,0.4436743580028907,0.4919231235281107,0.5203140751854669,0.3478260869565217,0.4146341463414634,0.4592303624529936,0.5035596316122551,0.5320185873761066,0.3623188405797101,0.4390243902439024
504603,jaraco/tempora,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/jaraco_tempora/tempora/timing.py,tempora.timing.IntervalGovernor,"class IntervalGovernor:
    """"""
    Decorate a function to only allow it to be called once per
    min_interval. Otherwise, it returns None.

    >>> gov = IntervalGovernor(30)
    >>> gov.min_interval.total_seconds()
    30.0
    """"""

    def __init__(self, min_interval) -> None:
        if isinstance(min_interval, numbers.Number):
            # type: ignore[arg-type] # python/mypy#3186#issuecomment-1571512649
            min_interval = datetime.timedelta(seconds=min_interval)
        self.min_interval = min_interval
        self.last_call = None

    def decorate(self, func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            allow = not self.last_call or self.last_call.split() > self.min_interval
            if allow:
                self.last_call = Stopwatch()
                return func(*args, **kwargs)

        return wrapper

    __call__ = decorate","class IntervalGovernor:
    '''
    Decorate a function to only allow it to be called once per
    min_interval. Otherwise, it returns None.

    >>> gov = IntervalGovernor(30)
    >>> gov.min_interval.total_seconds()
    30.0
    '''


    def __init__(self, min_interval) -> None:
        pass


    def decorate(self, func):
        pass

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
                pass

",5,1,snippet_93,0.2222222222222222,"class IntervalGovernor:
    '''
    Decorate a function to only allow it to be called once per
    min_interval. Otherwise, it returns None.

    >>> gov = IntervalGovernor(30)
    >>> gov.min_interval.total_seconds()
    30.0
    '''

    def __init__(self, min_interval) -> None:
        if isinstance(min_interval, datetime.timedelta):
            self.min_interval = min_interval
        elif isinstance(min_interval, (int, float)):
            self.min_interval = datetime.timedelta(seconds=min_interval)
        else:
            raise ValueError(""min_interval must be a timedelta or number of seconds"")

    def decorate(self, func):
        last_call = None

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            nonlocal last_call
            now = datetime.datetime.now()
            if last_call is None or (now - last_call) >= self.min_interval:
                last_call = now
                return func(*args, **kwargs)
            return None

        return wrapper","class IntervalGovernor:
    '''
    Decorate a function to only allow it to be called once per
    min_interval. Otherwise, it returns None.

    >>> gov = IntervalGovernor(30)
    >>> gov.min_interval.total_seconds()
    30.0
    '''

    def __init__(self, min_interval) -> None:
        self.min_interval = timedelta(seconds=min_interval) if isinstance(min_interval, (int, float)) else min_interval
        self.last_called = None

    def decorate(self, func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            current_time = time.time()
            
            if self.last_called is None or (current_time - self.last_called) >= self.min_interval.total_seconds():
                self.last_called = current_time
                return func(*args, **kwargs)
            else:
                return None
        
        return wrapper","class IntervalGovernor:
    '''
    Decorate a function to only allow it to be called once per
    min_interval. Otherwise, it returns None.

    >>> gov = IntervalGovernor(30)
    >>> gov.min_interval.total_seconds()
    30.0
    '''

    def __init__(self, min_interval) -> None:
        self.min_interval = datetime.timedelta(seconds=min_interval)
        self.last_called = None

    def decorate(self, func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            now = datetime.datetime.now()
            if self.last_called is None or now - self.last_called >= self.min_interval:
                self.last_called = now
                return func(*args, **kwargs)
            return None
        return wrapper",partial_docstr,0.7713004484304932,0.6334841628959277,0.5296803652968036,0.6816143497757847,0.6754598412607643,0.7991071428571429,0.6636771300448431,0.581081081081081,0.9160212278366089,0.896727442741394,0.9062716960906982,0.8986201882362366,0.8282845454545454,0.7729468599033817,0.6536585365853659,0.541871921182266,0.7342995169082125,0.6902497950530443,0.8507462686567164,0.715,0.628140703517588,0.9313340187072754,0.8868005275726318,0.9085218906402588,0.8910613656044006,0.8448291379310345,0.7731958762886597,0.6875,0.6,0.7525773195876287,0.6412932257829664,0.9011627906976745,0.7953216374269005,0.7294117647058823,0.9420725703239441,0.880197286605835,0.9100844264030457,0.8860166072845459,0.8678174137931035,0.4866080153577108,0.4248051957168471,0.5132726468334613,0.5873015873015873,0.4210526315789473,0.5390286510786935,0.4988686669598316,0.512300239777666,0.5396825396825397,0.6052631578947368,0.5643259677918124,0.5024257733829401,0.5151120159129644,0.5555555555555556,0.6842105263157895
569204,mcs07/MolVS,mcs07_MolVS/molvs/metal.py,molvs.metal.MetalDisconnector,"class MetalDisconnector(object):
    """"""Class for breaking covalent bonds between metals and organic atoms under certain conditions.""""""

    def __init__(self):
        log.debug('Initializing MetalDisconnector')
        # Initialize SMARTS to identify relevant substructures
        # TODO: Use atomic numbers instead of element symbols in SMARTS to allow for isotopes?
        self._metal_nof = Chem.MolFromSmarts('[Li,Na,K,Rb,Cs,Fr,Be,Mg,Ca,Sr,Ba,Ra,Sc,Ti,V,Cr,Mn,Fe,Co,Ni,Cu,Zn,Al,Ga,Y,Zr,Nb,Mo,Tc,Ru,Rh,Pd,Ag,Cd,In,Sn,Hf,Ta,W,Re,Os,Ir,Pt,Au,Hg,Tl,Pb,Bi]~[N,O,F]')
        self._metal_non = Chem.MolFromSmarts('[Al,Sc,Ti,V,Cr,Mn,Fe,Co,Ni,Cu,Zn,Y,Zr,Nb,Mo,Tc,Ru,Rh,Pd,Ag,Cd,Hf,Ta,W,Re,Os,Ir,Pt,Au]~[B,C,Si,P,As,Sb,S,Se,Te,Cl,Br,I,At]')

    def __call__(self, mol):
        """"""Calling a MetalDisconnector instance like a function is the same as calling its disconnect(mol) method.""""""
        return self.disconnect(mol)

    def disconnect(self, mol):
        """"""Break covalent bonds between metals and organic atoms under certain conditions.

        The algorithm works as follows:

        - Disconnect N, O, F from any metal.
        - Disconnect other non-metals from transition metals + Al (but not Hg, Ga, Ge, In, Sn, As, Tl, Pb, Bi, Po).
        - For every bond broken, adjust the charges of the begin and end atoms accordingly.

        :param mol: The input molecule.
        :type mol: rdkit.Chem.rdchem.Mol
        :return: The molecule with metals disconnected.
        :rtype: rdkit.Chem.rdchem.Mol
        """"""
        log.debug('Running MetalDisconnector')
        # Remove bonds that match SMARTS
        for smarts in [self._metal_nof, self._metal_non]:
            pairs = mol.GetSubstructMatches(smarts)
            rwmol = Chem.RWMol(mol)
            orders = []
            for i, j in pairs:
                # TODO: Could get the valence contributions of the bond instead of GetBondTypeAsDouble?
                orders.append(int(mol.GetBondBetweenAtoms(i, j).GetBondTypeAsDouble()))
                rwmol.RemoveBond(i, j)
            # Adjust neighbouring charges accordingly
            mol = rwmol.GetMol()
            for n, (i, j) in enumerate(pairs):
                chg = orders[n]
                atom1 = mol.GetAtomWithIdx(i)
                atom1.SetFormalCharge(atom1.GetFormalCharge() + chg)
                atom2 = mol.GetAtomWithIdx(j)
                atom2.SetFormalCharge(atom2.GetFormalCharge() - chg)
                log.info('Removed covalent bond between %s and %s', atom1.GetSymbol(), atom2.GetSymbol())
        Chem.SanitizeMol(mol)
        return mol","class MetalDisconnector(object):
    '''Class for breaking covalent bonds between metals and organic atoms under certain conditions.'''

    def __init__(self):
        pass

    def __call__(self, mol):
    '''Calling a MetalDisconnector instance like a function is the same as calling its disconnect(mol) method.'''
        pass

    def disconnect(self, mol):
    '''Break covalent bonds between metals and organic atoms under certain conditions.

        The algorithm works as follows:

        - Disconnect N, O, F from any metal.
        - Disconnect other non-metals from transition metals + Al (but not Hg, Ga, Ge, In, Sn, As, Tl, Pb, Bi, Po).
        - For every bond broken, adjust the charges of the begin and end atoms accordingly.

        :param mol: The input molecule.
        :type mol: rdkit.Chem.rdchem.Mol
        :return: The molecule with metals disconnected.
        :rtype: rdkit.Chem.rdchem.Mol
        '''
        pass

",4,3,snippet_581,0.3,"class MetalDisconnector(object):
    '''Class for breaking covalent bonds between metals and organic atoms under certain conditions.'''

    def __init__(self):
        # Transition metals + Al
        transitions = ['Sc','Ti','V','Cr','Mn','Fe','Co','Ni','Cu','Zn',
                       'Y','Zr','Nb','Mo','Tc','Ru','Rh','Pd','Ag','Cd',
                       'Hf','Ta','W','Re','Os','Ir','Pt','Au']
        metals = set(transitions + ['Al'])
        # Excluded metals
        exclude = {'Hg','Ga','Ge','In','Sn','As','Tl','Pb','Bi','Po'}
        self.metals = metals - exclude
        # Atoms always disconnected from any metal
        self.always_detach = {'N','O','F'}
        # Other non-metals to detach from selected metals
        self.other_detach = {'P','S','Cl','Br','I'}
        # Define organic non-metals
        self.org_nonmetals = {'H','C','N','O','F','P','S','Cl','Br','I'}

    def __call__(self, mol):
        return self.disconnect(mol)

    def disconnect(self, mol):
        rw = Chem.RWMol(mol)
        to_remove = []
        charge_updates = {}
        for bond in mol.GetBonds():
            i = bond.GetBeginAtomIdx()
            j = bond.GetEndAtomIdx()
            a1 = mol.GetAtomWithIdx(i)
            a2 = mol.GetAtomWithIdx(j)
            s1 = a1.GetSymbol()
            s2 = a2.GetSymbol()
            pair = None
            # always detach N, O, F from any metal
            if s1 in self.always_detach and s2 not in self.org_nonmetals:
                pair = (j, i)
            elif s2 in self.always_detach and s1 not in self.org_nonmetals:
                pair = (i, j)
            # detach other non-metals from selected metals
            elif s1 in self.other_detach and s2 in self.metals:
                pair = (j, i)
            elif s2 in self.other_detach and s1 in self.metals:
                pair = (i, j)
            if pair:
                metal_idx, org_idx = pair
                to_remove.append((metal_idx, org_idx))
                # adjust charges: metal +1, organic -1
                metal_fc = rw.GetAtomWithIdx(metal_idx).GetFormalCharge()
                org_fc = rw.GetAtomWithIdx(org_idx).GetFormalCharge()
                charge_updates[metal_idx] = metal_fc + 1
                charge_updates[org_idx] = org_fc - 1
        # remove bonds and update charges
        for m, o in to_remove:
            try:
                rw.RemoveBond(m, o)
            except:
                pass
        for idx, new_fc in charge_updates.items():
            rw.GetAtomWithIdx(idx).SetFormalCharge(new_fc)
        # sanitize and return
        rdmolops.SanitizeMol(rw)
        return rw.GetMol()","class MetalDisconnector(object):
    '''Class for breaking covalent bonds between metals and organic atoms under certain conditions.'''

    def __init__(self):
        pass

    def __call__(self, mol):
        '''Calling a MetalDisconnector instance like a function is the same as calling its disconnect(mol) method.'''
        return self.disconnect(mol)

    def disconnect(self, mol):
        '''Break covalent bonds between metals and organic atoms under certain conditions.

        The algorithm works as follows:

        - Disconnect N, O, F from any metal.
        - Disconnect other non-metals from transition metals + Al (but not Hg, Ga, Ge, In, Sn, As, Tl, Pb, Bi, Po).
        - For every bond broken, adjust the charges of the begin and end atoms accordingly.

        :param mol: The input molecule.
        :type mol: rdkit.Chem.rdchem.Mol
        :return: The molecule with metals disconnected.
        :rtype: rdkit.Chem.rdchem.Mol
        '''
        from rdkit import Chem
        import copy

        # Create a copy of the molecule to avoid modifying the original
        mol = copy.deepcopy(mol)
        Chem.SanitizeMol(mol)
        
        # Define element symbols
        disconnect_elements = {'N', 'O', 'F'}
        
        # Transition metals + Al
        transition_metals_plus_al = {
            13,  # Al
            21, 22, 23, 24, 25, 26, 27, 28, 29, 30,  # Sc to Zn
            39, 40, 41, 42, 43, 44, 45, 46, 47, 48,  # Y to Cd
            57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,  # La to Lu
            72, 73, 74, 75, 76, 77, 78, 79, 80  # Hf to Hg
        }
        
        # Excluded elements
        excluded_elements = {'Hg', 'Ga', 'Ge', 'In', 'Sn', 'As', 'Tl', 'Pb', 'Bi', 'Po'}
        excluded_atomic_nums = {Chem.AtomFromSmiles(elem).GetAtomicNum() for elem in excluded_elements}
        
        # Get atoms to disconnect from
        atoms_to_disconnect_from = set()
        for atom in mol.GetAtoms():
            atomic_num = atom.GetAtomicNum()
            symbol = atom.GetSymbol()
            
            # Check if it's a metal
            if atomic_num in transition_metals_plus_al and atomic_num not in excluded_atomic_nums:
                atoms_to_disconnect_from.add(atom.GetIdx())
            # Check if it's Al
            elif symbol == 'Al':
                atoms_to_disconnect_from.add(atom.GetIdx())
        
        # Store bonds to be broken
        bonds_to_break = []
        
        # Iterate through bonds
        for bond in mol.GetBonds():
            begin_atom = bond.GetBeginAtom()
            end_atom = bond.GetEndAtom()
            begin_idx = begin_atom.GetIdx()
            end_idx = end_atom.GetIdx()
            
            begin_symbol = begin_atom.GetSymbol()
            end_symbol = end_atom.GetSymbol()
            begin_atomic_num = begin_atom.GetAtomicNum()
            end_atomic_num = end_atom.GetAtomicNum()
            
            # Check if bond is between metal and organic atom
            begin_is_metal = begin_idx in atoms_to_disconnect_from or begin_symbol in ['Al']
            end_is_metal = end_idx in atoms_to_disconnect_from or end_symbol in ['Al']
            
            begin_is_organic = begin_symbol in disconnect_elements or (begin_atomic_num not in transition_metals_plus_al and begin_symbol not in excluded_elements and begin_symbol not in ['Al', 'C', 'H'])
            end_is_organic = end_symbol in disconnect_elements or (end_atomic_num not in transition_metals_plus_al and end_symbol not in excluded_elements and end_symbol not in ['Al', 'C', 'H'])
            
            # Case 1: Disconnect N, O, F from any metal
            if (begin_symbol in disconnect_elements and end_is_metal) or (end_symbol in disconnect_elements and begin_is_metal):
                bonds_to_break.append((begin_idx, end_idx))
            
            # Case 2: Disconnect other non-metals from transition metals + Al (but not excluded elements)
            elif begin_is_metal and end_is_organic and end_symbol not in disconnect_elements:
                bonds_to_break.append((begin_idx, end_idx))
            elif end_is_metal and begin_is_organic and begin_symbol not in disconnect_elements:
                bonds_to_break.append((begin_idx, end_idx))
        
        # Break bonds in reverse order to maintain indices
        for begin_idx, end_idx in reversed(bonds_to_break):
            mol.RemoveBond(begin_idx, end_idx)
            
            # Adjust charges
            begin_atom = mol.GetAtomWithIdx(begin_idx)
            end_atom = mol.GetAtomWithIdx(end_idx)
            
            # Metal loses electron (becomes more positive)
            if begin_atom.GetSymbol() in ['Al'] or begin_atom.GetAtomicNum() in transition_metals_plus_al:
                begin_atom.SetFormalCharge(begin_atom.GetFormalCharge() + 1)
                end_atom.SetFormalCharge(end_atom.GetFormalCharge() - 1)
            elif end_atom.GetSymbol() in ['Al'] or end_atom.GetAtomicNum() in transition_metals_plus_al:
                end_atom.SetFormalCharge(end_atom.GetFormalCharge() + 1)
                begin_atom.SetFormalCharge(begin_atom.GetFormalCharge() - 1)
        
        # Clear computed properties and sanitize
        mol.UpdatePropertyCache()
        
        return mol","class MetalDisconnector(object):
    '''Class for breaking covalent bonds between metals and organic atoms under certain conditions.'''

    def __init__(self):
        # Define sets of atomic numbers for different categories
        self.metals = {3, 4, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118}
        self.transition_metals_and_al = {13, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112}
        self.excluded_metals = {80, 31, 32, 49, 50, 33, 81, 82, 83, 84}  # Hg, Ga, Ge, In, Sn, As, Tl, Pb, Bi, Po
        self.nof = {7, 8, 9}  # N, O, F

    def __call__(self, mol):
        '''Calling a MetalDisconnector instance like a function is the same as calling its disconnect(mol) method.'''
        return self.disconnect(mol)

    def disconnect(self, mol):
        '''Break covalent bonds between metals and organic atoms under certain conditions.

        The algorithm works as follows:

        - Disconnect N, O, F from any metal.
        - Disconnect other non-metals from transition metals + Al (but not Hg, Ga, Ge, In, Sn, As, Tl, Pb, Bi, Po).
        - For every bond broken, adjust the charges of the begin and end atoms accordingly.

        :param mol: The input molecule.
        :type mol: rdkit.Chem.rdchem.Mol
        :return: The molecule with metals disconnected.
        :rtype: rdkit.Chem.rdchem.Mol
        '''
        if mol is None:
            return None
            
        mol = Chem.Mol(mol)
        
        # Get editable molecule
        em = Chem.EditableMol(mol)
        
        # Find bonds to remove
        bonds_to_remove = []
        
        for bond in mol.GetBonds():
            begin_atom = bond.GetBeginAtom()
            end_atom = bond.GetEndAtom()
            begin_atomic_num = begin_atom.GetAtomicNum()
            end_atomic_num = end_atom.GetAtomicNum()
            
            # Check if one atom is metal and one is non-metal
            begin_is_metal = begin_atomic_num in self.metals
            end_is_metal = end_atomic_num in self.metals
            
            if begin_is_metal and not end_is_metal:
                metal_atom = begin_atom
                nonmetal_atom = end_atom
                metal_atomic_num = begin_atomic_num
                nonmetal_atomic_num = end_atomic_num
            elif end_is_metal and not begin_is_metal:
                metal_atom = end_atom
                nonmetal_atom = begin_atom
                metal_atomic_num = end_atomic_num
                nonmetal_atomic_num = begin_atomic_num
            else:
                continue
                
            should_disconnect = False
            
            # Rule 1: Disconnect N, O, F from any metal
            if nonmetal_atomic_num in self.nof:
                should_disconnect = True
            
            # Rule 2: Disconnect other non-metals from transition metals + Al (but not excluded metals)
            elif (metal_atomic_num in self.transition_metals_and_al and 
                  metal_atomic_num not in self.excluded_metals):
                should_disconnect = True
                
            if should_disconnect:
                bonds_to_remove.append((bond.GetIdx(), metal_atom.GetIdx(), nonmetal_atom.GetIdx()))
        
        # Remove bonds in reverse order to maintain indices
        bonds_to_remove.sort(reverse=True)
        
        for bond_idx, metal_idx, nonmetal_idx in bonds_to_remove:
            # Adjust charges before removing bond
            metal_atom = mol.GetAtomWithIdx(metal_idx)
            nonmetal_atom = mol.GetAtomWithIdx(nonmetal_idx)
            
            # Get current charges
            metal_charge = metal_atom.GetFormalCharge()
            nonmetal_charge = nonmetal_atom.GetFormalCharge()
            
            # Adjust charges based on bond order
            bond = mol.GetBondWithIdx(bond_idx)
            bond_order = int(bond.GetBondType())
            
            # Metal loses electrons (becomes more positive)
            # Non-metal gains electrons (becomes more negative)
            metal_atom.SetFormalCharge(metal_charge + bond_order)
            nonmetal_atom.SetFormalCharge(nonmetal_charge - bond_order)
            
            # Remove the bond
            em.RemoveBond(metal_idx, nonmetal_idx)
        
        # Get the modified molecule
        result_mol = em.GetMol()
        
        if result_mol is not None:
            try:
                Chem.SanitizeMol(result_mol)
            except:
                # If sanitization fails, return the molecule without sanitization
                pass
                
        return result_mol",partial_docstr,0.463768115942029,0.25872093023255816,0.20699708454810495,0.2985507246376812,0.23430261726219148,0.5333333333333333,0.22370617696160267,0.15384615384615385,0.837371289730072,0.8173422813415527,0.8272355794906616,0.819301962852478,0.7470110769230774,0.3839541547277937,0.26028708133971284,0.23969319271332692,0.2846227316141356,0.24165809394943558,0.3670886075949367,0.21452702702702703,0.17920540997464074,0.8188248872756958,0.838255763053894,0.8284264206886292,0.8362712860107422,0.7483332819722658,0.3755958055290753,0.2617000955109837,0.2373205741626794,0.3145853193517636,0.2502422205025392,0.37695473251028805,0.22817133443163098,0.18219291014014838,0.7949557900428772,0.8296385407447815,0.8119269609451294,0.826034665107727,0.7550573310225306,0.2446148422059809,0.1144587248995789,0.1284648397989048,0.6119402985074627,0.1235955056179775,0.3821225194507582,0.2094128105723569,0.4974270911448131,0.6194029850746269,0.2022471910112359,0.3372239945674665,0.1925610857871151,0.4992830729288349,0.5671641791044776,0.0898876404494382
670305,pypa/setuptools,pypa_setuptools/setuptools/_vendor/jaraco/text/__init__.py,text.Splitter,"class Splitter:
    """"""object that will split a string with the given arguments for each call

    >>> s = Splitter(',')
    >>> s('hello, world, this is your, master calling')
    ['hello', ' world', ' this is your', ' master calling']
    """"""

    def __init__(self, *args):
        self.args = args

    def __call__(self, s):
        return s.split(*self.args)","class Splitter:
    '''object that will split a string with the given arguments for each call

    >>> s = Splitter(',')
    >>> s('hello, world, this is your, master calling')
    ['hello', ' world', ' this is your', ' master calling']
    '''

    def __init__(self, *args):
        pass

    def __call__(self, s):
        pass

",3,1,snippet_685,1.0,"class Splitter:
    '''object that will split a string with the given arguments for each call

    >>> s = Splitter(',')
    >>> s('hello, world, this is your, master calling')
    ['hello', ' world', ' this is your', ' master calling']
    '''

    def __init__(self, *args):
        self.args = args

    def __call__(self, s):
        return s.split(*self.args)","class Splitter:
    '''object that will split a string with the given arguments for each call

    >>> s = Splitter(',')
    >>> s('hello, world, this is your, master calling')
    ['hello', ' world', ' this is your', ' master calling']
    '''

    def __init__(self, *args):
        self.args = args

    def __call__(self, s):
        return s.split(*self.args)","class Splitter:
    '''object that will split a string with the given arguments for each call

    >>> s = Splitter(',')
    >>> s('hello, world, this is your, master calling')
    ['hello', ' world', ' this is your', ' master calling']
    '''

    def __init__(self, *args):
        self.args = args

    def __call__(self, s):
        return s.split(*self.args)",partial_docstr,1.0,1.0,1.0,1.0,0.9120626710647152,0.98,0.9595959595959596,0.9387755102040817,0.9984979629516602,0.9984979629516602,0.9984979629516602,0.9984980225563049,1.0,1.0,1.0,1.0,1.0,0.9120626710647152,0.98,0.9595959595959596,0.9387755102040817,0.9984979629516602,0.9984979629516602,0.9984979629516602,0.9984980225563049,1.0,1.0,1.0,1.0,1.0,0.9120626710647152,0.98,0.9595959595959596,0.9387755102040817,0.9984979629516602,0.9984979629516602,0.9984979629516602,0.9984980225563049,1.0,0.949937801524292,0.898000333150059,0.9017508729471092,1.0,1.0,0.949937801524292,0.898000333150059,0.9017508729471092,1.0,1.0,0.949937801524292,0.898000333150059,0.9017508729471092,1.0,1.0
509578,jfilter/text-classification-keras,jfilter_text-classification-keras/texcla/preprocessing/utils.py,texcla.preprocessing.utils._CountTracker,"class _CountTracker(object):
    """"""Helper class to track counts of various document hierarchies in the corpus.
    For example, if the tokenizer can tokenize docs as (docs, paragraph, sentences, words), then this utility
    will track number of paragraphs, number of sentences within paragraphs and number of words within sentence.
    """"""

    def __init__(self):
        self._prev_indices = None
        self._local_counts = None
        self.counts = None

    def update(self, indices):
        """"""Updates counts based on indices. The algorithm tracks the index change at i and
        update global counts for all indices beyond i with local counts tracked so far.
        """"""
        # Initialize various lists for the first time based on length of indices.
        if self._prev_indices is None:
            self._prev_indices = indices

            # +1 to track token counts in the last index.
            self._local_counts = np.full(len(indices) + 1, 1)
            self._local_counts[-1] = 0
            self.counts = [[] for _ in range(len(self._local_counts))]

        has_reset = False
        for i in range(len(indices)):
            # index value changed. Push all local values beyond i to count and reset those local_counts.
            # For example, if document index changed, push counts on sentences and tokens and reset their local_counts
            # to indicate that we are tracking those for new document. We need to do this at all document hierarchies.
            if indices[i] > self._prev_indices[i]:
                self._local_counts[i] += 1
                has_reset = True
                for j in range(i + 1, len(self.counts)):
                    self.counts[j].append(self._local_counts[j])
                    self._local_counts[j] = 1

        # If none of the aux indices changed, update token count.
        if not has_reset:
            self._local_counts[-1] += 1
        self._prev_indices = indices[:]

    def finalize(self):
        """"""This will add the very last document to counts. We also get rid of counts[0] since that
        represents document level which doesnt come under anything else. We also convert all count
        values to numpy arrays so that stats can be computed easily.
        """"""
        for i in range(1, len(self._local_counts)):
            self.counts[i].append(self._local_counts[i])
        self.counts.pop(0)

        for i in range(len(self.counts)):
            self.counts[i] = np.array(self.counts[i])","class _CountTracker(object):
    '''Helper class to track counts of various document hierarchies in the corpus.
    For example, if the tokenizer can tokenize docs as (docs, paragraph, sentences, words), then this utility
    will track number of paragraphs, number of sentences within paragraphs and number of words within sentence.
    '''

    def __init__(self):
        pass

    def update(self, indices):
    '''Updates counts based on indices. The algorithm tracks the index change at i and
        update global counts for all indices beyond i with local counts tracked so far.
        '''
        pass

    def finalize(self):
    '''This will add the very last document to counts. We also get rid of counts[0] since that
        represents document level which doesnt come under anything else. We also convert all count
        values to numpy arrays so that stats can be computed easily.
        '''
        pass

",4,3,snippet_502,0.2105263157894736,"class _CountTracker(object):
    '''Helper class to track counts of various document hierarchies in the corpus.
    For example, if the tokenizer can tokenize docs as (docs, paragraph, sentences, words), then this utility
    will track number of paragraphs, number of sentences within paragraphs and number of words within sentence.
    '''

    def __init__(self):
        self.last_indices = None
        self.counts = None
        self.local_counts = None

    def update(self, indices):
        '''Updates counts based on indices. The algorithm tracks the index change at i and
           update global counts for all indices beyond i with local counts tracked so far.
        '''
        # make a list copy
        indices = list(indices)
        D = len(indices)

        # first call: initialize
        if self.last_indices is None:
            # we track levels 1..D-1, so counts and locals have length D-1
            self.counts = [[] for _ in range(D-1)]
            # on first token we have seen one unit at each level
            self.local_counts = [1] * (D-1)
            self.last_indices = indices
            return

        # find the first level that changed
        for k in range(D):
            if indices[k] != self.last_indices[k]:
                break
        else:
            # no change => nothing to do
            return

        # if we changed at level k < D-1, flush all deeper-level counts j>=k
        if k < D-1:
            # j runs over  D-2, D-3, ..., k
            for j in range(D-2, k-1, -1):
                self.counts[j].append(self.local_counts[j])
                self.local_counts[j] = 0

        # now increment the count of the just-finished level
        # (for k>0 it is local_counts[k-1], for k=0 nothing)
        if k > 0:
            self.local_counts[k-1] += 1

        # roll forward
        self.last_indices = indices

    def finalize(self):
        '''This will add the very last document to counts. We also get rid of counts[0] since that
           represents document level which doesnt come under anything else. We also convert all count
           values to numpy arrays so that stats can be computed easily.
        '''
        if self.local_counts is None:
            return

        # flush whatever remains
        for j in range(len(self.local_counts)-1, -1, -1):
            self.counts[j].append(self.local_counts[j])

        # drop the toplevel (doclevel) counts
        self.counts.pop(0)

        # convert to numpy arrays
        self.counts = [np.array(c) for c in self.counts]

        return self.counts","class _CountTracker(object):
    '''Helper class to track counts of various document hierarchies in the corpus.
    For example, if the tokenizer can tokenize docs as (docs, paragraph, sentences, words), then this utility
    will track number of paragraphs, number of sentences within paragraphs and number of words within sentence.
    '''

    def __init__(self):
        self.counts = {}
        self.last_indices = None

    def update(self, indices):
        '''Updates counts based on indices. The algorithm tracks the index change at i and
        update global counts for all indices beyond i with local counts tracked so far.
        '''
        if self.last_indices is None:
            self.last_indices = indices[:]
            return
            
        # Find the first index where indices differ
        change_point = 0
        for i in range(min(len(indices), len(self.last_indices))):
            if indices[i] != self.last_indices[i]:
                change_point = i
                break
        else:
            # If one is prefix of another or they are identical
            change_point = min(len(indices), len(self.last_indices))
            
        # Update counts for all levels beyond the change point
        for i in range(change_point, len(self.last_indices)):
            if i not in self.counts:
                self.counts[i] = []
            # Count is the difference in the index at position i-1 (or 0 if i=0)
            if i == 0:
                count = self.last_indices[i] + 1
            else:
                count = self.last_indices[i] + 1
            self.counts[i].append(count)
            
        self.last_indices = indices[:]

    def finalize(self):
        '''This will add the very last document to counts. We also get rid of counts[0] since that
        represents document level which doesnt come under anything else. We also convert all count
        values to numpy arrays so that stats can be computed easily.
        '''
        if self.last_indices is not None:
            # Add the final counts
            for i in range(len(self.last_indices)):
                if i not in self.counts:
                    self.counts[i] = []
                if i == 0:
                    count = self.last_indices[i] + 1
                else:
                    count = self.last_indices[i] + 1
                self.counts[i].append(count)
        
        # Remove counts[0] as it represents document level
        if 0 in self.counts:
            del self.counts[0]
            
        # Convert all counts to numpy arrays
        for key in self.counts:
            self.counts[key] = np.array(self.counts[key])","class _CountTracker(object):
    '''Helper class to track counts of various document hierarchies in the corpus.
    For example, if the tokenizer can tokenize docs as (docs, paragraph, sentences, words), then this utility
    will track number of paragraphs, number of sentences within paragraphs and number of words within sentence.
    '''

    def __init__(self):
        self.counts = {}
        self.current_counts = {}
        self.prev_indices = None

    def update(self, indices):
        '''Updates counts based on indices. The algorithm tracks the index change at i and
        update global counts for all indices beyond i with local counts tracked so far.
        '''
        if self.prev_indices is None:
            self.prev_indices = indices[:]
            for i in range(len(indices)):
                if i not in self.counts:
                    self.counts[i] = []
                if i not in self.current_counts:
                    self.current_counts[i] = 0
            return
        
        # Find the first level where indices changed
        change_level = None
        for i in range(len(indices)):
            if i >= len(self.prev_indices) or indices[i] != self.prev_indices[i]:
                change_level = i
                break
        
        if change_level is not None:
            # Update counts for all levels beyond the change level
            for level in range(change_level + 1, len(indices)):
                if level in self.current_counts and self.current_counts[level] > 0:
                    if level not in self.counts:
                        self.counts[level] = []
                    self.counts[level].append(self.current_counts[level])
                    self.current_counts[level] = 0
        
        # Update current counts
        for i in range(len(indices)):
            if i not in self.current_counts:
                self.current_counts[i] = 0
            if i not in self.counts:
                self.counts[i] = []
        
        # Increment the deepest level
        if len(indices) > 0:
            deepest_level = len(indices) - 1
            self.current_counts[deepest_level] += 1
        
        self.prev_indices = indices[:]

    def finalize(self):
        '''This will add the very last document to counts. We also get rid of counts[0] since that
        represents document level which doesnt come under anything else. We also convert all count
        values to numpy arrays so that stats can be computed easily.
        '''
        # Add remaining current counts to final counts
        for level in self.current_counts:
            if self.current_counts[level] > 0:
                if level not in self.counts:
                    self.counts[level] = []
                self.counts[level].append(self.current_counts[level])
        
        # Remove document level (level 0) if it exists
        if 0 in self.counts:
            del self.counts[0]
        
        # Convert all count lists to numpy arrays
        for level in self.counts:
            self.counts[level] = np.array(self.counts[level])",partial_docstr,0.7277777777777776,0.5487465181058495,0.4664804469273743,0.6055555555555555,0.553686104510165,0.764065335753176,0.5563636363636364,0.46265938069216755,0.8762830495834351,0.9099739789962769,0.8928107619285583,0.906488835811615,0.8416091489361702,0.7161198288159771,0.5293276108726753,0.430416068866571,0.5763195435092725,0.5512687644712746,0.762589928057554,0.554954954954955,0.44584837545126355,0.89836186170578,0.8966602087020874,0.897510290145874,0.8968300819396973,0.7985014790996786,0.706199460916442,0.5243243243243242,0.44173441734417346,0.5768194070080863,0.5362898285653822,0.7034700315457413,0.5229067930489731,0.41930379746835444,0.8986243605613708,0.9074673056602478,0.9030241966247559,0.9065752625465393,0.8185009424083772,0.5021633091285033,0.4160872626071044,0.4654500991274826,0.5944055944055944,0.5327102803738317,0.4097201575936259,0.4347992931117042,0.4530193151727401,0.5454545454545454,0.205607476635514,0.459768658906111,0.4014842846455025,0.4623599738794058,0.6013986013986014,0.3738317757009345
604517,numenta/nupic,numenta_nupic/src/nupic/data/field_meta.py,nupic.data.field_meta.FieldMetaSpecial,"class FieldMetaSpecial(object):
  """"""
  Public values for the ""special"" field attribute. Valid values are:

    - ``R``: reset
    - ``S``: sequence
    - ``T``: timestamp
    - ``C``: category
    - ``L``: learning
  """"""
  none = ''
  reset = 'R'
  sequence = 'S'
  timestamp = 'T'
  category = 'C'
  learning = 'L'

  _ALL = (none, reset, sequence, timestamp, category, learning,)


  @classmethod
  def isValid(cls, attr):
    """"""Check a candidate value whether it's one of the valid attributes

    :param attr: (string) candidate value
    :returns: True if the candidate value is a legitimate ""special"" field
              attribute; False if not
    """"""
    return attr in cls._ALL","class FieldMetaSpecial(object):
    '''
  Public values for the ""special"" field attribute. Valid values are:

    - ``R``: reset
    - ``S``: sequence
    - ``T``: timestamp
    - ``C``: category
    - ``L``: learning
  '''

  @classmethod
  def isValid(cls, attr):
    '''Check a candidate value whether it's one of the valid attributes

    :param attr: (string) candidate value
    :returns: True if the candidate value is a legitimate ""special"" field
              attribute; False if not
    '''
    pass

",3,2,snippet_669,0.6666666666666666,"class FieldMetaSpecial(object):
    '''
  Public values for the ""special"" field attribute. Valid values are:

    - ``R``: reset
    - ``S``: sequence
    - ``T``: timestamp
    - ``C``: category
    - ``L``: learning
  '''
    R = 'R'
    S = 'S'
    T = 'T'
    C = 'C'
    L = 'L'
    _VALID = {R, S, T, C, L}

    @classmethod
    def isValid(cls, attr):
        '''Check a candidate value whether it's one of the valid attributes

        :param attr: (string) candidate value
        :returns: True if the candidate value is a legitimate ""special"" field
                  attribute; False if not
        '''
        return isinstance(attr, str) and attr in cls._VALID","class FieldMetaSpecial(object):
    '''
  Public values for the ""special"" field attribute. Valid values are:

    - ``R``: reset
    - ``S``: sequence
    - ``T``: timestamp
    - ``C``: category
    - ``L``: learning
  '''

    VALID_ATTRIBUTES = {'R', 'S', 'T', 'C', 'L'}

    @classmethod
    def isValid(cls, attr):
        '''Check a candidate value whether it's one of the valid attributes

        :param attr: (string) candidate value
        :returns: True if the candidate value is a legitimate ""special"" field
                  attribute; False if not
        '''
        return attr in cls.VALID_ATTRIBUTES","class FieldMetaSpecial(object):
    '''
  Public values for the ""special"" field attribute. Valid values are:

    - ``R``: reset
    - ``S``: sequence
    - ``T``: timestamp
    - ``C``: category
    - ``L``: learning
  '''

    @classmethod
    def isValid(cls, attr):
        '''Check a candidate value whether it's one of the valid attributes

        :param attr: (string) candidate value
        :returns: True if the candidate value is a legitimate ""special"" field
                  attribute; False if not
        '''
        valid_attrs = {'R', 'S', 'T', 'C', 'L'}
        return attr in valid_attrs",partial_docstr,0.8214285714285715,0.7349397590361447,0.7073170731707318,0.8214285714285715,0.7210671535547003,0.8598726114649682,0.7435897435897436,0.6838709677419355,0.9402231574058533,0.9423438310623169,0.941282331943512,0.9421312808990479,0.9430900000000001,0.8846153846153847,0.8051948051948052,0.7894736842105262,0.8846153846153847,0.6800130552228134,0.927007299270073,0.8088235294117647,0.7777777777777778,0.9343422651290894,0.9465595483779907,0.9404112696647644,0.9453234076499939,0.8658549999999999,0.8774193548387097,0.7973856209150327,0.7682119205298013,0.8129032258064516,0.6658813028108689,0.9259259259259259,0.8059701492537313,0.7744360902255639,0.9495290517807007,0.9275398850440979,0.9384056329727173,0.9296928644180298,0.8048799999999999,0.6499999905084595,0.6363290673892643,0.649276955250634,0.6060606060606061,0.7083333333333334,0.473771422095952,0.5930636467780744,0.6277796173633093,0.4242424242424242,0.25,0.3970668766414065,0.5930636467780744,0.6277796173633093,0.2424242424242424,0.125
3866,Alidron/spyrk,Alidron_spyrk/spyrk/spark_cloud.py,spyrk.spark_cloud._BaseDevice,"class _BaseDevice(object):

    """"""Parent class for the dynamic Device class.
    
    The Device class being made of whatever fields the Spark Cloud API gives us,
    it has to be contructed on the fly once we know those fields.
    
    The generated Device class is subclassing this _BaseDevice as well as a
    nametuple.
    
    The namedtuple host all static fields while _BaseDevice host methods
    extending how a Device object should behave.
    """"""

    @staticmethod
    def make_device_class(spark_cloud, entries, timeout=30):
        """"""Returns a dynamic Device class based on what a GET device list from
        the Spark Cloud returns.
        
        spark_cloud parameter should be the caller instance of SparkCloud.
        
        entries parameter should be the list of fields the Spark Cloud API is
        returning.
        """"""
        attrs = list(
            set(
                list(entries) + [
                    'requires_deep_update', 'functions', 'variables', 'api', 'status'
                ]
            )
        )
        
        return type(
            'Device',
            (_BaseDevice, namedtuple('Device', attrs)),
            {'__slots__': (), 'spark_cloud': spark_cloud, 'timeout' : timeout}
        )
        
    def __getattr__(self, name):
        """"""Returns virtual attributes corresponding to function or variable
        names.
        """"""
        params = {'access_token': self.spark_cloud.access_token}
        if not self.connected:
            raise IOError(""{}.{} is not available: the spark device is not connected."".format(self.name, name))

        if name in self.functions:
        
            def fcall(*args):
                data = {'params': ','.join(args)}
                r = self.api(name).POST(params=params, data=data, timeout=self.timeout)
                self.spark_cloud._check_error(r)
                return r.json()['return_value']
                
            return fcall
            
        elif name in self.variables:
            r = self.api(name).GET(params=params, timeout=30)
            self.spark_cloud._check_error(r)
            return r.json()['result']
            
        else:
            raise AttributeError()","class _BaseDevice(object):
    '''Parent class for the dynamic Device class.
    
    The Device class being made of whatever fields the Spark Cloud API gives us,
    it has to be contructed on the fly once we know those fields.
    
    The generated Device class is subclassing this _BaseDevice as well as a
    nametuple.
    
    The namedtuple host all static fields while _BaseDevice host methods
    extending how a Device object should behave.
    '''

    @staticmethod
    def make_device_class(spark_cloud, entries, timeout=30):
    '''Returns a dynamic Device class based on what a GET device list from
        the Spark Cloud returns.
        
        spark_cloud parameter should be the caller instance of SparkCloud.
        
        entries parameter should be the list of fields the Spark Cloud API is
        returning.
        '''
        pass

    def __getattr__(self, name):
    '''Returns virtual attributes corresponding to function or variable
        names.
        '''
        pass

            def fcall(*args):
                        pass

",5,3,snippet_671,0.3,"class _BaseDevice(object):
    '''Parent class for the dynamic Device class.

    The Device class being made of whatever fields the Spark Cloud API gives us,
    it has to be contructed on the fly once we know those fields.

    The generated Device class is subclassing this _BaseDevice as well as a
    nametuple.

    The namedtuple host all static fields while _BaseDevice host methods
    extending how a Device object should behave.
    '''

    @staticmethod
    def make_device_class(spark_cloud, entries, timeout=30):
        '''Returns a dynamic Device class based on what a GET device list from
        the Spark Cloud returns.

        spark_cloud parameter should be the caller instance of SparkCloud.
        entries parameter should be the list of fields the Spark Cloud API is
        returning.
        '''
        # create a namedtuple with the given entries
        BaseTuple = namedtuple('Device', entries)
        # build a new class that inherits from both BaseTuple and _BaseDevice
        attrs = {
            '_spark': spark_cloud,
            '_timeout': timeout,
        }
        return type('Device', (BaseTuple, _BaseDevice), attrs)

    def __getattr__(self, name):
        '''Returns virtual attributes corresponding to function or variable
        names.
        '''
        # dynamic function call
        funcs = getattr(self, 'functions', [])
        if name in funcs:
            def fcall(*args):
                return self._spark.call_function(self.id, name, args, self._timeout)
            return fcall

        # dynamic variable lookup
        vars_ = getattr(self, 'variables', [])
        if name in vars_:
            return self._spark.get_variable(self.id, name)

        raise AttributeError(f""{type(self).__name__!r} object has no attribute {name!r}"")","class _BaseDevice(object):
    '''Parent class for the dynamic Device class.
    
    The Device class being made of whatever fields the Spark Cloud API gives us,
    it has to be contructed on the fly once we know those fields.
    
    The generated Device class is subclassing this _BaseDevice as well as a
    nametuple.
    
    The namedtuple host all static fields while _BaseDevice host methods
    extending how a Device object should behave.
    '''

    @staticmethod
    def make_device_class(spark_cloud, entries, timeout=30):
        '''Returns a dynamic Device class based on what a GET device list from
        the Spark Cloud returns.
        
        spark_cloud parameter should be the caller instance of SparkCloud.
        
        entries parameter should be the list of fields the Spark Cloud API is
        returning.
        '''
        from collections import namedtuple
        
        # Create a namedtuple class with the given entries
        DeviceTuple = namedtuple('DeviceTuple', entries)
        
        # Create a dynamic class that inherits from both _BaseDevice and the namedtuple
        class Device(_BaseDevice, DeviceTuple):
            def __new__(cls, *args, **kwargs):
                return DeviceTuple.__new__(cls, *args, **kwargs)
            
            def __init__(self, *args, **kwargs):
                self._spark_cloud = spark_cloud
                self._timeout = timeout
        
        return Device

    def __getattr__(self, name):
        '''Returns virtual attributes corresponding to function or variable
        names.
        '''
        def fcall(*args):
            # Call the function on the spark cloud with this device's id
            return self._spark_cloud.call_function(self.id, name, args, timeout=self._timeout)
        
        return fcall","class _BaseDevice(object):
    '''Parent class for the dynamic Device class.
    
    The Device class being made of whatever fields the Spark Cloud API gives us,
    it has to be contructed on the fly once we know those fields.
    
    The generated Device class is subclassing this _BaseDevice as well as a
    nametuple.
    
    The namedtuple host all static fields while _BaseDevice host methods
    extending how a Device object should behave.
    '''

    @staticmethod
    def make_device_class(spark_cloud, entries, timeout=30):
        '''Returns a dynamic Device class based on what a GET device list from
        the Spark Cloud returns.
        
        spark_cloud parameter should be the caller instance of SparkCloud.
        
        entries parameter should be the list of fields the Spark Cloud API is
        returning.
        '''
        DeviceTuple = namedtuple('DeviceTuple', entries)
        
        class Device(_BaseDevice, DeviceTuple):
            def __new__(cls, *args, **kwargs):
                return DeviceTuple.__new__(cls, *args, **kwargs)
            
            def __init__(self, *args, **kwargs):
                self._spark_cloud = spark_cloud
                self._timeout = timeout
        
        return Device

    def __getattr__(self, name):
        '''Returns virtual attributes corresponding to function or variable
        names.
        '''
        if hasattr(self, 'functions') and name in self.functions:
            def fcall(*args):
                return self._spark_cloud.call_function(self.id, name, *args, timeout=self._timeout)
            return fcall
        elif hasattr(self, 'variables') and name in self.variables:
            return self._spark_cloud.get_variable(self.id, name, timeout=self._timeout)
        else:
            raise AttributeError(f""'{type(self).__name__}' object has no attribute '{name}'"")",partial_docstr,0.7711864406779662,0.6297872340425532,0.5641025641025641,0.6822033898305085,0.4937976215897882,0.8371428571428572,0.6217765042979942,0.5057471264367817,0.9163527488708496,0.8951343297958374,0.9056192636489868,0.8972118496894836,0.7826108695652175,0.7109207708779443,0.6193548387096774,0.5745140388768898,0.6552462526766596,0.44282022300438867,0.770392749244713,0.6,0.5106382978723404,0.9026200175285339,0.8763066530227661,0.8892687559127808,0.878868818283081,0.7463793478260877,0.7949260042283298,0.6624203821656051,0.605543710021322,0.7103594080338266,0.5265740800523616,0.8201058201058201,0.5941644562334217,0.4946808510638298,0.9116034507751465,0.8990001082420349,0.9052578806877136,0.9002447128295898,0.7572488043478264,0.4706588877858355,0.5715288721822298,0.5783969879794012,0.3805970149253731,0.352112676056338,0.4545240822943295,0.554153131659403,0.5536215662376968,0.3582089552238806,0.352112676056338,0.4988289111984026,0.5763717013148777,0.5876427032012468,0.3805970149253731,0.4507042253521127
531221,kevin1024/vcrpy,kevin1024_vcrpy/vcr/stubs/__init__.py,vcr.stubs.VCRFakeSocket,"class VCRFakeSocket:
    """"""
    A socket that doesn't do anything!
    Used when playing back cassettes, when there
    is no actual open socket.
    """"""

    def close(self):
        pass

    def settimeout(self, *args, **kwargs):
        pass

    def fileno(self):
        """"""
        This is kinda crappy.  requests will watch
        this descriptor and make sure it's not closed.
        Return file descriptor 0 since that's stdin.
        """"""
        return 0","class VCRFakeSocket:
    '''
    A socket that doesn't do anything!
    Used when playing back cassettes, when there
    is no actual open socket.
    '''

    def close(self):
        pass

    def settimeout(self, *args, **kwargs):
        pass

    def fileno(self):
    '''
        This is kinda crappy.  requests will watch
        this descriptor and make sure it's not closed.
        Return file descriptor 0 since that's stdin.
        '''
        pass

",4,2,snippet_57,1.0,"class VCRFakeSocket:
    '''
    A socket that doesn't do anything!
    Used when playing back cassettes, when there
    is no actual open socket.
    '''

    def close(self):
        pass

    def settimeout(self, *args, **kwargs):
        pass

    def fileno(self):
        '''
        This is kinda crappy.  requests will watch
        this descriptor and make sure it's not closed.
        Return file descriptor 0 since that's stdin.
        '''
        return 0","class VCRFakeSocket:
    '''
    A socket that doesn't do anything!
    Used when playing back cassettes, when there
    is no actual open socket.
    '''

    def close(self):
        pass

    def settimeout(self, *args, **kwargs):
        pass

    def fileno(self):
        '''
        This is kinda crappy.  requests will watch
        this descriptor and make sure it's not closed.
        Return file descriptor 0 since that's stdin.
        '''
        return 0","class VCRFakeSocket:
    '''
    A socket that doesn't do anything!
    Used when playing back cassettes, when there
    is no actual open socket.
    '''

    def close(self):
        pass

    def settimeout(self, *args, **kwargs):
        pass

    def fileno(self):
        '''
        This is kinda crappy.  requests will watch
        this descriptor and make sure it's not closed.
        Return file descriptor 0 since that's stdin.
        '''
        return 0",partial_docstr,1.0,1.0,1.0,1.0,0.817347589246255,0.9518072289156626,0.9024390243902439,0.8518518518518519,0.9976329803466797,0.9976329803466797,0.9976329803466797,0.9976329803466797,1.0,1.0,1.0,1.0,1.0,0.817347589246255,0.9518072289156626,0.9024390243902439,0.8518518518518519,0.9976329803466797,0.9976329803466797,0.9976329803466797,0.9976329803466797,1.0,1.0,1.0,1.0,1.0,0.817347589246255,0.9518072289156626,0.9024390243902439,0.8518518518518519,0.9976329803466797,0.9976329803466797,0.9976329803466797,0.9976329803466797,1.0,0.915359435061673,0.8274527465216155,0.8339849937250766,1.0,1.0,0.915359435061673,0.8274527465216155,0.8339849937250766,1.0,1.0,0.915359435061673,0.8274527465216155,0.8339849937250766,1.0,1.0
404092,google/brotli,google_brotli/research/brotlidump.py,brotlidump.BitStream,"class BitStream:
    """"""Represent a bytes object. Can read bits and prefix codes the way
    Brotli does.
    """"""
    def __init__(self, byteString):
        self.data = byteString
        #position in bits: byte pos is pos>>3, bit pos is pos&7
        self.pos = 0

    def __repr__(self):
        """"""Representation
        >>> olleke
        BitStream(pos=0:0)
        """"""
        return ""BitStream(pos={:x}:{})"".format(self.pos>>3, self.pos&7)

    def read(self, n):
        """"""Read n bits from the stream and return as an integer.
        Produces zero bits beyond the stream.
        >>> olleke.data[0]==27
        True
        >>> olleke.read(5)
        27

        >>> olleke
        BitStream(pos=0:5)
        """"""
        value = self.peek(n)
        self.pos += n
        if self.pos>len(self.data)*8:
            raise ValueError('Read past end of stream')
        return value

    def peek(self, n):
        """"""Peek an n bit integer from the stream without updating the pointer.
        It is not an error to read beyond the end of the stream.
        >>> olleke.data[:2]==b'\x1b\x2e' and 0x2e1b==11803
        True
        >>> olleke.peek(15)
        11803
        >>> hex(olleke.peek(32))
        '0x2e1b'
        """"""
        #read bytes that contain the data: self.data[self.pos>>3:self.pos+n+7>>3]
        #convert to int: int.from_bytes(..., 'little')
        #shift out the bits from the first byte: >>(self.pos&7)
        #mask unwanted bits: & (1<<n)-1
        return int.from_bytes(
            self.data[self.pos>>3:self.pos+n+7>>3],
            'little')>>(self.pos&7) & (1<<n)-1

    def readBytes(self, n):
        """"""Read n bytes from the stream on a byte boundary.
        """"""
        if self.pos&7: raise ValueError('readBytes: need byte boundary')
        result = self.data[self.pos>>3:(self.pos>>3)+n]
        self.pos += 8*n
        return result","class BitStream:
    '''Represent a bytes object. Can read bits and prefix codes the way
    Brotli does.
    '''

    def __init__(self, byteString):
        pass

    def __repr__(self):
    '''Representation
        >>> olleke
        BitStream(pos=0:0)
        '''
        pass

    def read(self, n):
    '''Read n bits from the stream and return as an integer.
        Produces zero bits beyond the stream.
        >>> olleke.data[0]==27
        True
        >>> olleke.read(5)
        27

        >>> olleke
        BitStream(pos=0:5)
        '''
        pass

    def peek(self, n):
    '''Peek an n bit integer from the stream without updating the pointer.
        It is not an error to read beyond the end of the stream.
        >>> olleke.data[:2]==b'.' and 0x2e1b==11803
        True
        >>> olleke.peek(15)
        11803
        >>> hex(olleke.peek(32))
        '0x2e1b'
        '''
        pass

    def readBytes(self, n):
    '''Read n bytes from the stream on a byte boundary.
        '''
        pass

",6,5,snippet_407,1.0,"class BitStream:
    '''Represent a bytes object. Can read bits and prefix codes the way
    Brotli does.
    '''

    def __init__(self, byteString):
        self.data = byteString
        self.pos = 0

    def __repr__(self):
        return f""BitStream(pos={self.pos//8}:{self.pos%8})""

    def read(self, n):
        val = self.peek(n)
        self.pos += n
        return val

    def peek(self, n):
        if n <= 0:
            return 0
        byte_index = self.pos // 8
        bit_index = self.pos % 8
        bits_needed = bit_index + n
        num_bytes = (bits_needed + 7) // 8
        raw = self.data[byte_index:byte_index + num_bytes]
        raw_int = int.from_bytes(raw, 'little')
        return (raw_int >> bit_index) & ((1 << n) - 1)

    def readBytes(self, n):
        if self.pos % 8 != 0:
            raise ValueError(""Position not at byte boundary"")
        byte_index = self.pos // 8
        chunk = self.data[byte_index:byte_index + n]
        if len(chunk) < n:
            chunk += b'\x00' * (n - len(chunk))
        self.pos += 8 * n
        return chunk","class BitStream:
    '''Represent a bytes object. Can read bits and prefix codes the way
    Brotli does.
    '''

    def __init__(self, byteString):
        self.data = byteString
        self.pos = 0  # bit position as (byte_index, bit_offset)

    def __repr__(self):
        '''Representation
        >>> olleke
        BitStream(pos=0:0)
        '''
        byte_pos, bit_offset = divmod(self.pos, 8)
        return f""BitStream(pos={byte_pos}:{bit_offset})""

    def read(self, n):
        '''Read n bits from the stream and return as an integer.
        Produces zero bits beyond the stream.
        >>> olleke.data[0]==27
        True
        >>> olleke.read(5)
        27

        >>> olleke
        BitStream(pos=0:5)
        '''
        result = self.peek(n)
        self.pos += n
        return result

    def peek(self, n):
        '''Peek an n bit integer from the stream without updating the pointer.
        It is not an error to read beyond the end of the stream.
        >>> olleke.data[:2]==b'.' and 0x2e1b==11803
        True
        >>> olleke.peek(15)
        11803
        >>> hex(olleke.peek(32))
        '0x2e1b'
        '''
        if n == 0:
            return 0
            
        byte_index, bit_offset = divmod(self.pos, 8)
        result = 0
        
        bits_read = 0
        current_byte_index = byte_index
        
        while bits_read < n:
            if current_byte_index >= len(self.data):
                # Beyond the stream, return zero bits
                bits_read += 1
                result <<= 1
                continue
                
            # Get the current byte
            current_byte = self.data[current_byte_index]
            
            # Calculate how many bits we can read from this byte
            bits_available_in_byte = 8 - bit_offset if current_byte_index == byte_index else 8
            bits_to_read_from_byte = min(n - bits_read, bits_available_in_byte)
            
            if current_byte_index == byte_index:
                # First byte: need to account for bit_offset
                mask = (1 << (8 - bit_offset)) - 1  # mask for remaining bits
                bits = (current_byte & mask) >> (8 - bit_offset - bits_to_read_from_byte)
            else:
                # Subsequent bytes: read from the beginning
                bits = current_byte >> (8 - bits_to_read_from_byte)
            
            # Add these bits to result
            result = (result << bits_to_read_from_byte) | bits
            
            bits_read += bits_to_read_from_byte
            
            # Update for next iteration
            if current_byte_index == byte_index:
                bit_offset += bits_to_read_from_byte
                if bit_offset >= 8:
                    current_byte_index += 1
                    bit_offset = 0
            else:
                current_byte_index += 1
        
        return result

    def readBytes(self, n):
        '''Read n bytes from the stream on a byte boundary.
        '''
        # Align to byte boundary
        byte_pos, bit_offset = divmod(self.pos, 8)
        if bit_offset > 0:
            byte_pos += 1
            bit_offset = 0
        
        # Update position to byte boundary
        self.pos = byte_pos * 8
        
        # Read n bytes
        result = self.data[byte_pos:byte_pos + n]
        
        # Update position
        self.pos += n * 8
        
        return result","class BitStream:
    '''Represent a bytes object. Can read bits and prefix codes the way
    Brotli does.
    '''

    def __init__(self, byteString):
        self.data = byteString
        self.byte_pos = 0
        self.bit_pos = 0

    def __repr__(self):
        '''Representation
        >>> olleke
        BitStream(pos=0:0)
        '''
        return f""BitStream(pos={self.byte_pos}:{self.bit_pos})""

    def read(self, n):
        '''Read n bits from the stream and return as an integer.
        Produces zero bits beyond the stream.
        >>> olleke.data[0]==27
        True
        >>> olleke.read(5)
        27

        >>> olleke
        BitStream(pos=0:5)
        '''
        result = 0
        bits_read = 0
        
        while bits_read < n:
            if self.byte_pos >= len(self.data):
                break
                
            current_byte = self.data[self.byte_pos]
            bits_available_in_byte = 8 - self.bit_pos
            bits_needed = n - bits_read
            bits_to_read = min(bits_available_in_byte, bits_needed)
            
            mask = (1 << bits_to_read) - 1
            bits = (current_byte >> self.bit_pos) & mask
            result |= bits << bits_read
            
            bits_read += bits_to_read
            self.bit_pos += bits_to_read
            
            if self.bit_pos >= 8:
                self.bit_pos = 0
                self.byte_pos += 1
                
        return result

    def peek(self, n):
        '''Peek an n bit integer from the stream without updating the pointer.
        It is not an error to read beyond the end of the stream.
        >>> olleke.data[:2]==b'.' and 0x2e1b==11803
        True
        >>> olleke.peek(15)
        11803
        >>> hex(olleke.peek(32))
        '0x2e1b'
        '''
        saved_byte_pos = self.byte_pos
        saved_bit_pos = self.bit_pos
        result = self.read(n)
        self.byte_pos = saved_byte_pos
        self.bit_pos = saved_bit_pos
        return result

    def readBytes(self, n):
        '''Read n bytes from the stream on a byte boundary.
        '''
        if self.bit_pos != 0:
            self.bit_pos = 0
            self.byte_pos += 1
            
        result = self.data[self.byte_pos:self.byte_pos + n]
        self.byte_pos += n
        return result",partial_docstr,0.5371702637889688,0.3132530120481928,0.2179176755447942,0.42206235011990406,0.25283520511955243,0.7615894039735099,0.5149501661129569,0.37666666666666665,0.852549135684967,0.7908873558044434,0.8205615282058716,0.7966492772102356,0.7897016738197429,0.6079295154185022,0.4506627393225331,0.3692762186115215,0.5051395007342143,0.3968451224021805,0.5139813581890812,0.38266666666666665,0.3177570093457944,0.8548195958137512,0.9045836329460144,0.8789978623390198,0.8993479609489441,0.767533544668588,0.7285714285714285,0.5304659498207887,0.45683453237410077,0.6321428571428572,0.5222396042910237,0.6648451730418944,0.5072992700729927,0.42230347349177333,0.8878551125526428,0.8846157193183899,0.8862324357032776,0.884938657283783,0.794602992957747,0.4070660687804893,0.1433804343906962,0.1648838407312613,0.62,0.7,0.4250420158630348,0.2626302308388089,0.5008711659466635,0.42,0.5166666666666667,0.4991263126040482,0.3969135900719509,0.479591660344242,0.42,0.7
570375,memphis-iis/GLUDB,memphis-iis_GLUDB/gludb/backends/dynamodb.py,gludb.backends.dynamodb.DynamoMappings,"class DynamoMappings(object):
    """"""Attribute mapping class.

    DynamoDB has some opinions about what you can store or query in an
    attribute. We're going to use mappings to fix that.
    """"""

    # Yes, the bracket-ish map vals are illegal in just about any language that
    # uses bracket-type syntax. That's on purpose.
    NONE_VAL = ""<{[None>}]""
    EMPTY_STR_VAL = ""<{[''>}]""

    @staticmethod
    def map_index_val(index_val):
        """"""Xform index_val so that it can be stored/queried.""""""
        if index_val is None:
            return DynamoMappings.NONE_VAL

        index_val = str(index_val)
        if not index_val:
            return DynamoMappings.EMPTY_STR_VAL

        return index_val

    @staticmethod
    def unmap_stored_val(stored_val):
        """"""Inverse of index_val_mapping.

        Note that we currently don't use it because we don't actually read back
        index values (since they are generated by Python functions).
        """"""
        if stored_val == DynamoMappings.NONE_VAL:
            return None
        elif stored_val == DynamoMappings.EMPTY_STR_VAL:
            return ''
        else:
            return stored_val","class DynamoMappings(object):
    '''Attribute mapping class.

    DynamoDB has some opinions about what you can store or query in an
    attribute. We're going to use mappings to fix that.
    '''

    @staticmethod
    def map_index_val(index_val):
    '''Xform index_val so that it can be stored/queried.'''
        pass

    @staticmethod
    def unmap_stored_val(stored_val):
    '''Inverse of index_val_mapping.

        Note that we currently don't use it because we don't actually read back
        index values (since they are generated by Python functions).
        '''
        pass

",5,3,snippet_340,0.9,"class DynamoMappings(object):
    '''Attribute mapping class.

    DynamoDB has some opinions about what you can store or query in an
    attribute. We're going to use mappings to fix that.
    '''

    @staticmethod
    def map_index_val(index_val):
        '''Xform index_val so that it can be stored/queried.'''
        if index_val is None:
            return None
        # pickle and base64-encode to get a storable string
        data = pickle.dumps(index_val, protocol=pickle.HIGHEST_PROTOCOL)
        return base64.b64encode(data).decode('ascii')

    @staticmethod
    def unmap_stored_val(stored_val):
        '''Inverse of index_val_mapping.

        Note that we currently don't use it because we don't actually read back
        index values (since they are generated by Python functions).
        '''
        if stored_val is None:
            return None
        # decode from base64 and unpickle
        data = base64.b64decode(stored_val.encode('ascii'))
        return pickle.loads(data)","class DynamoMappings(object):
    '''Attribute mapping class.

    DynamoDB has some opinions about what you can store or query in an
    attribute. We're going to use mappings to fix that.
    '''

    @staticmethod
    def map_index_val(index_val):
        '''Xform index_val so that it can be stored/queried.'''
        if index_val is None:
            return None
        # Convert to string since DynamoDB has limitations on data types
        return str(index_val)

    @staticmethod
    def unmap_stored_val(stored_val):
        '''Inverse of index_val_mapping.

        Note that we currently don't use it because we don't actually read back
        index values (since they are generated by Python functions).
        '''
        if stored_val is None:
            return None
        # Attempt to convert back to original type
        # Try int first
        try:
            return int(stored_val)
        except ValueError:
            pass
        # Try float
        try:
            return float(stored_val)
        except ValueError:
            pass
        # Return as string if conversion fails
        return stored_val","class DynamoMappings(object):
    '''Attribute mapping class.

    DynamoDB has some opinions about what you can store or query in an
    attribute. We're going to use mappings to fix that.
    '''

    @staticmethod
    def map_index_val(index_val):
        '''Xform index_val so that it can be stored/queried.'''
        if index_val is None:
            return None
        elif isinstance(index_val, bool):
            return str(index_val).lower()
        elif isinstance(index_val, (int, float)):
            return str(index_val)
        elif isinstance(index_val, str):
            return index_val if index_val else "" ""
        elif isinstance(index_val, (list, tuple)):
            return [DynamoMappings.map_index_val(item) for item in index_val]
        elif isinstance(index_val, dict):
            return {k: DynamoMappings.map_index_val(v) for k, v in index_val.items()}
        else:
            return str(index_val)

    @staticmethod
    def unmap_stored_val(stored_val):
        '''Inverse of index_val_mapping.

        Note that we currently don't use it because we don't actually read back
        index values (since they are generated by Python functions).
        '''
        if stored_val is None:
            return None
        elif stored_val == "" "":
            return """"
        elif stored_val == ""true"":
            return True
        elif stored_val == ""false"":
            return False
        elif isinstance(stored_val, str):
            try:
                if '.' in stored_val:
                    return float(stored_val)
                else:
                    return int(stored_val)
            except ValueError:
                return stored_val
        elif isinstance(stored_val, list):
            return [DynamoMappings.unmap_stored_val(item) for item in stored_val]
        elif isinstance(stored_val, dict):
            return {k: DynamoMappings.unmap_stored_val(v) for k, v in stored_val.items()}
        else:
            return stored_val",partial_docstr,0.6917808219178082,0.6275862068965518,0.5902777777777777,0.6917808219178082,0.4605402330939382,0.7286432160804021,0.5909090909090909,0.5380710659898477,0.8466317653656006,0.8763607740402222,0.8612397909164429,0.8732942342758179,0.7955995283018868,0.7260726072607261,0.6312292358803987,0.5953177257525084,0.6996699669966997,0.47952405813420906,0.735,0.628140703517588,0.5555555555555556,0.8926271200180054,0.8783618807792664,0.8854370713233948,0.8797679543495178,0.7961185436893203,0.6435643564356436,0.5373134328358209,0.4799999999999999,0.5940594059405941,0.36764788215554156,0.4693396226415094,0.3546099290780142,0.2985781990521327,0.8565993309020996,0.8830429911613464,0.8696202039718628,0.8803253769874573,0.7477845247148297,0.4370972115115784,0.4653505680519227,0.4769158290147989,0.3061224489795918,0.5,0.3592580234291039,0.4683347006537439,0.4930302031097673,0.2448979591836734,0.2307692307692307,0.5103971465437196,0.3496229239191885,0.5302702148459567,0.4693877551020408,0.6923076923076923
183649,SFDO-Tooling/CumulusCI,cumulusci/tasks/bulkdata/factory_utils.py,cumulusci.tasks.bulkdata.factory_utils.Adder,"class Adder:
    """"""A more flexible alternative to Factoryboy sequences. You can create and
        destroy them wherever you want.

    >>> x = Adder(10)
    >>> x(1)
    11
    >>> x(1)
    12
    >>> x.reset(5)
    >>> x(2)
    7
    >>> x(2)
    9
    """"""

    def __init__(self, x=0):
        self.x = x

    def __call__(self, value):
        self.x += value
        return int(self.x)

    def reset(self, x):
        self.x = x","class Adder:
    '''A more flexible alternative to Factoryboy sequences. You can create and
        destroy them wherever you want.

    >>> x = Adder(10)
    >>> x(1)
    11
    >>> x(1)
    12
    >>> x.reset(5)
    >>> x(2)
    7
    >>> x(2)
    9
    '''

    def __init__(self, x=0):
        pass

    def __call__(self, value):
        pass

    def reset(self, x):
        pass

",4,1,snippet_524,1.0,"class Adder:
    '''A more flexible alternative to Factoryboy sequences. You can create and
        destroy them wherever you want.

    >>> x = Adder(10)
    >>> x(1)
    11
    >>> x(1)
    12
    >>> x.reset(5)
    >>> x(2)
    7
    >>> x(2)
    9
    '''

    def __init__(self, x=0):
        self._current = x

    def __call__(self, value):
        self._current += value
        return self._current

    def reset(self, x):
        self._current = x","class Adder:
    '''A more flexible alternative to Factoryboy sequences. You can create and
        destroy them wherever you want.

    >>> x = Adder(10)
    >>> x(1)
    11
    >>> x(1)
    12
    >>> x.reset(5)
    >>> x(2)
    7
    >>> x(2)
    9
    '''

    def __init__(self, x=0):
        self.value = x

    def __call__(self, value):
        self.value += value
        return self.value

    def reset(self, x):
        self.value = x","class Adder:
    '''A more flexible alternative to Factoryboy sequences. You can create and
        destroy them wherever you want.

    >>> x = Adder(10)
    >>> x(1)
    11
    >>> x(1)
    12
    >>> x.reset(5)
    >>> x(2)
    7
    >>> x(2)
    9
    '''

    def __init__(self, x=0):
        self.current = x

    def __call__(self, value):
        self.current += value
        return self.current

    def reset(self, x):
        self.current = x",partial_docstr,0.9268292682926829,0.8429752066115703,0.7899159663865546,0.9268292682926829,0.8414984965758542,0.9236641221374046,0.8692307692307693,0.813953488372093,0.9770024418830872,0.9801334738731384,0.9785654544830322,0.9798194766044617,0.9814816666666667,0.9268292682926829,0.8429752066115703,0.7899159663865546,0.9268292682926829,0.8402632285544657,0.952755905511811,0.8968253968253969,0.84,0.985170841217041,0.9805489778518677,0.9828544855117798,0.981009304523468,0.9814816666666667,0.9268292682926829,0.8429752066115703,0.7899159663865546,0.9268292682926829,0.8402632285544657,0.952755905511811,0.8968253968253969,0.84,0.9774813652038574,0.9802407622337341,0.9788590669631958,0.9799640774726868,0.9814816666666667,0.7002032362021638,0.7275934918422442,0.7338529371293072,0.6923076923076923,0.6470588235294118,0.7149091185551051,0.7275934918422442,0.7338529371293072,0.6923076923076923,0.7058823529411765,0.7002032362021638,0.7275934918422442,0.7338529371293072,0.6923076923076923,0.6470588235294118
158747,OSSOS/MOP,src/ossos/core/ossos/astrom.py,ossos.astrom.AstromData,"class AstromData(object):
    """"""
    Encapsulates data extracted from an .astrom file.
    """"""

    def __init__(self, observations, sys_header, sources, discovery_only=False):
        """"""
        Constructs a new astronomy data set object.

        Args:
          observations: list(Observations)
            The observations that are part of the data set.
          sys_header: dict
            Key-value pairs of system settings applicable to the data set.
            Ex: RMIN, RMAX, ANGLE, AWIDTH
          sources: list(list(SourceReading))
            A list of point sources found in the data set.  These are
            potential moving objects.  Each point source is itself a list
            of source readings, one for each observation in
            <code>observations</code>.  By convention the ordering of
            source readings must match the ordering of the observations.
          discovery_only: bool
            should we only use the discovery images on the first pass?
        """"""
        self.observations = observations
        self.mpc_observations = {}
        self.sys_header = sys_header
        self.sources = [Source(reading_list, discovery_only=discovery_only) for reading_list in sources]

    def get_reading_count(self):
        count = 0
        for source in self.sources:
            count += source.num_readings()

        return count

    def get_sources(self):
        return self.sources

    def get_source_count(self):
        return len(self.get_sources())","class AstromData(object):
    '''
    Encapsulates data extracted from an .astrom file.
    '''

    def __init__(self, observations, sys_header, sources, discovery_only=False):
    '''
        Constructs a new astronomy data set object.

        Args:
          observations: list(Observations)
            The observations that are part of the data set.
          sys_header: dict
            Key-value pairs of system settings applicable to the data set.
            Ex: RMIN, RMAX, ANGLE, AWIDTH
          sources: list(list(SourceReading))
            A list of point sources found in the data set.  These are
            potential moving objects.  Each point source is itself a list
            of source readings, one for each observation in
            <code>observations</code>.  By convention the ordering of
            source readings must match the ordering of the observations.
          discovery_only: bool
            should we only use the discovery images on the first pass?
        '''
        pass

    def get_reading_count(self):
        pass

    def get_sources(self):
        pass

    def get_source_count(self):
        pass

",5,2,snippet_209,0.8888888888888888,"class AstromData(object):
    """"""
    Encapsulates data extracted from an .astrom file.
    """"""

    def __init__(self, observations, sys_header, sources, discovery_only=False):
        """"""
        Constructs a new astronomy data set object.

        Args:
          observations: list(Observations)
            The observations that are part of the data set.
          sys_header: dict
            Key-value pairs of system settings applicable to the data set.
            Ex: RMIN, RMAX, ANGLE, AWIDTH
          sources: list(list(SourceReading))
            A list of point sources found in the data set.  These are
            potential moving objects.  Each point source is itself a list
            of source readings, one for each observation in
            <code>observations</code>.  By convention the ordering of
            source readings must match the ordering of the observations.
          discovery_only: bool
            should we only use the discovery images on the first pass?
        """"""
        self.observations = list(observations)
        self.sys_header = dict(sys_header)
        # each source is a list of readings
        self._all_sources = [list(src) for src in sources]
        self.discovery_only = bool(discovery_only)

    def get_reading_count(self):
        """"""
        Returns the total number of readings across sources,
        honoring discovery_only if set.
        """"""
        return sum(len(src) for src in self.get_sources())

    def get_sources(self):
        """"""
        Returns the list of sources (each a list of readings).
        If discovery_only is True, returns only the first reading of each source.
        """"""
        if self.discovery_only:
            return [src[:1] for src in self._all_sources if src]
        return list(self._all_sources)

    def get_source_count(self):
        """"""
        Returns the number of sources considered (honoring discovery_only).
        """"""
        return len(self.get_sources())","class AstromData(object):
    '''
    Encapsulates data extracted from an .astrom file.
    '''

    def __init__(self, observations, sys_header, sources, discovery_only=False):
        '''
        Constructs a new astronomy data set object.

        Args:
          observations: list(Observations)
            The observations that are part of the data set.
          sys_header: dict
            Key-value pairs of system settings applicable to the data set.
            Ex: RMIN, RMAX, ANGLE, AWIDTH
          sources: list(list(SourceReading))
            A list of point sources found in the data set.  These are
            potential moving objects.  Each point source is itself a list
            of source readings, one for each observation in
            <code>observations</code>.  By convention the ordering of
            source readings must match the ordering of the observations.
          discovery_only: bool
            should we only use the discovery images on the first pass?
        '''
        self.observations = observations
        self.sys_header = sys_header
        self.sources = sources
        self.discovery_only = discovery_only

    def get_reading_count(self):
        if not self.observations:
            return 0
        return len(self.observations)

    def get_sources(self):
        return self.sources

    def get_source_count(self):
        if not self.sources:
            return 0
        return len(self.sources)","class AstromData(object):
    '''
    Encapsulates data extracted from an .astrom file.
    '''

    def __init__(self, observations, sys_header, sources, discovery_only=False):
        '''
        Constructs a new astronomy data set object.

        Args:
          observations: list(Observations)
            The observations that are part of the data set.
          sys_header: dict
            Key-value pairs of system settings applicable to the data set.
            Ex: RMIN, RMAX, ANGLE, AWIDTH
          sources: list(list(SourceReading))
            A list of point sources found in the data set.  These are
            potential moving objects.  Each point source is itself a list
            of source readings, one for each observation in
            <code>observations</code>.  By convention the ordering of
            source readings must match the ordering of the observations.
          discovery_only: bool
            should we only use the discovery images on the first pass?
        '''
        self.observations = observations
        self.sys_header = sys_header
        self.sources = sources
        self.discovery_only = discovery_only

    def get_reading_count(self):
        return len(self.observations)

    def get_sources(self):
        return self.sources

    def get_source_count(self):
        return len(self.sources)",partial_docstr,0.8064516129032259,0.6944444444444445,0.6465116279069767,0.7603686635944701,0.618181225726963,0.6893203883495146,0.6082725060827251,0.5634146341463414,0.9280544519424438,0.9663737416267395,0.9468265175819397,0.962399959564209,0.8503416326530612,0.9196675900277008,0.8579387186629527,0.8291316526610645,0.89196675900277,0.780300456812292,0.9365671641791045,0.8689138576779026,0.8270676691729323,0.9768276810646057,0.9650182723999023,0.9708871245384216,0.9661863446235657,0.8837932110091743,0.9398280802292264,0.8933717579250721,0.8695652173913043,0.9169054441260746,0.7689655866214151,0.9801587301587301,0.9203187250996016,0.884,0.9834429621696472,0.9606525897979736,0.9719141721725464,0.9628840684890747,0.911315871559633,0.5674392069553309,0.5752630357456902,0.8056049031867444,0.4444444444444444,0.4444444444444444,0.6299268709190753,0.7626145881601715,0.7570928955161296,0.3888888888888889,0.6111111111111112,0.6304509390489873,0.7616535489414694,0.7601502072544797,0.3888888888888889,0.6111111111111112
576366,mitodl/edx-api-client,mitodl_edx-api-client/edx_api/bulk_user_retirement.py,edx_api.bulk_user_retirement.BulkUserRetirement,"class BulkUserRetirement:
    """"""
    API client for interacting with user retirement API
    """"""

    api_url = ""v1/accounts/bulk_retire_users""

    def __init__(self, requester, base_url):
        self.requester = requester
        self.base_url = base_url

    def retire_users(self, payload):
        """"""
        Execute the client request to edX endpoint

        Args:
            payload (dict): request payload

        Returns:
            JSON response (dict)
        """"""
        response = self.requester.post(
            parse.urljoin(self.base_url, self.api_url), json=payload
        )

        response.raise_for_status()
        return response.json()","class BulkUserRetirement:
    '''
    API client for interacting with user retirement API
    '''

    def __init__(self, requester, base_url):
        pass

    def retire_users(self, payload):
    '''
        Execute the client request to edX endpoint

        Args:
            payload (dict): request payload

        Returns:
            JSON response (dict)
        '''
        pass

",3,2,snippet_422,1.0,"class BulkUserRetirement:
    """"""
    API client for interacting with user retirement API
    """"""

    def __init__(self, requester, base_url):
        """"""
        Args:
            requester: an HTTP client with a .post() method
            base_url (str): full URL of the bulk retirement endpoint
        """"""
        self.requester = requester
        self.base_url = base_url.rstrip(""/"")

    def retire_users(self, payload):
        """"""
        Execute the client request to edX endpoint

        Args:
            payload (dict): request payload

        Returns:
            JSON response (dict)
        """"""
        url = self.base_url
        response = self.requester.post(url, json=payload)
        response.raise_for_status()
        return response.json()","class BulkUserRetirement:
    '''
    API client for interacting with user retirement API
    '''

    def __init__(self, requester, base_url):
        self.requester = requester
        self.base_url = base_url.rstrip('/')

    def retire_users(self, payload):
        '''
        Execute the client request to edX endpoint

        Args:
            payload (dict): request payload

        Returns:
            JSON response (dict)
        '''
        url = f""{self.base_url}/api/bulk_user_retirement/""
        response = self.requester.post(url, json=payload)
        return response.json()","class BulkUserRetirement:
    '''
    API client for interacting with user retirement API
    '''

    def __init__(self, requester, base_url):
        self.requester = requester
        self.base_url = base_url.rstrip('/')

    def retire_users(self, payload):
        '''
        Execute the client request to edX endpoint

        Args:
            payload (dict): request payload

        Returns:
            JSON response (dict)
        '''
        url = f""{self.base_url}/api/user/v1/accounts/retire_users/""
        response = self.requester.post(url, json=payload)
        return response.json()",partial_docstr,0.8205128205128205,0.7272727272727273,0.631578947368421,0.7564102564102564,0.7253245343694704,0.8048780487804879,0.7177914110429447,0.6604938271604939,0.9192560911178589,0.9188173413276672,0.9190366268157959,0.9188611507415771,0.8571442857142857,0.8840579710144928,0.7499999999999999,0.6567164179104478,0.7971014492753623,0.6617481117111894,0.889763779527559,0.7619047619047619,0.672,0.947830319404602,0.9266824722290039,0.9371371269226074,0.9287547469139099,0.833335,0.9142857142857143,0.7681159420289856,0.6470588235294118,0.7857142857142858,0.6806097102632206,0.8778625954198473,0.7615384615384615,0.6666666666666666,0.9391471743583679,0.9330705404281616,0.9360990524291992,0.933674693107605,0.833335,0.5538761897279025,0.5330762974782413,0.7067949331682617,0.6052631578947368,0.3703703703703703,0.5499432116679361,0.5816132266388722,0.594767807167375,0.5789473684210527,0.4444444444444444,0.5499432116679361,0.5816132266388722,0.594767807167375,0.5789473684210527,0.4444444444444444
122776,GNS3/gns3-server,GNS3_gns3-server/gns3server/compute/dynamips/adapters/wic_1enet.py,gns3server.compute.dynamips.adapters.wic_1enet.WIC_1ENET,"class WIC_1ENET(object):

    """"""
    WIC-1ENET Ethernet
    """"""

    def __init__(self):

        self._interfaces = 2

    def __str__(self):

        return ""WIC-1ENET""

    @property
    def interfaces(self):
        """"""
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        """"""

        return self._interfaces","class WIC_1ENET(object):
    '''
    WIC-1ENET Ethernet
    '''

    def __init__(self):
        pass

    def __str__(self):
        pass

    @property
    def interfaces(self):
    '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        pass

",5,2,snippet_376,0.8,"class WIC_1ENET(object):
    '''
    WIC-1ENET Ethernet
    '''

    def __init__(self):
        self._interfaces = 1

    def __str__(self):
        return ""WIC-1ENET Ethernet""

    @property
    def interfaces(self):
        '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        return self._interfaces","class WIC_1ENET(object):
    '''
    WIC-1ENET Ethernet
    '''

    def __init__(self):
        pass

    def __str__(self):
        return ""WIC-1ENET""

    @property
    def interfaces(self):
        '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        return 1","class WIC_1ENET(object):
    '''
    WIC-1ENET Ethernet
    '''

    def __init__(self):
        self.name = ""WIC-1ENET""
        self.description = ""WIC-1ENET Ethernet""

    def __str__(self):
        return self.name

    @property
    def interfaces(self):
        '''
        Returns the number of interfaces supported by this WIC.

        :returns: number of interfaces
        '''
        return 1",partial_docstr,0.9620253164556962,0.9090909090909091,0.8533333333333334,0.9620253164556962,0.7722080187225959,0.92,0.8513513513513513,0.7808219178082192,0.9890986680984497,0.9898308515548706,0.9894646406173706,0.9897575378417969,1.0,0.9066666666666667,0.8767123287671234,0.8450704225352113,0.9066666666666667,0.651325404113925,0.9090909090909091,0.8307692307692308,0.765625,0.9768894910812378,0.9669735431671143,0.9719061851501465,0.9679561257362366,0.9387761224489797,0.8674698795180724,0.7901234567901234,0.6835443037974683,0.7951807228915662,0.7237139980450065,0.8375,0.7468354430379747,0.6538461538461539,0.9498836994171143,0.9543675184249878,0.952120304107666,0.9539172053337097,0.8850586206896551,0.7678365911826496,0.5223785135156561,0.5489678512149422,1.0,1.0,0.4241188949265708,0.5644171155143984,0.5801104122438331,0.4090909090909091,0.1428571428571428,0.6072153425774138,0.4326389730340495,0.4962223972756055,0.5,0.0
816077,usc-isi-i2/etk,usc-isi-i2_etk/etk/simple_timeseries_extractor.py,etk.simple_timeseries_extractor.SimpleTimeSeriesExtractor,"class SimpleTimeSeriesExtractor(object):
    """"""
    This class will take a ""simple"" csv or excel file as input and out a timeseries, if there is a timeseries to be
    extracted.
    """"""

    def __init__(self, csv_file_path: str):
        self.csv_file_path = csv_file_path

    def process(self):
        simple_annotator = SimpleAnnotator(self.csv_file_path)
        # returns the annotation object for the csv
        annotations = simple_annotator.get_annotation_json()
        es = ExtractSpreadsheet(self.csv_file_path, annotations=annotations)
        return list(es.process())","class SimpleTimeSeriesExtractor(object):
    '''
    This class will take a ""simple"" csv or excel file as input and out a timeseries, if there is a timeseries to be
    extracted.
    '''

    def __init__(self, csv_file_path: str):
        pass

    def process(self):
        pass

",3,1,snippet_602,1.0,"class SimpleTimeSeriesExtractor(object):
    '''
    This class will take a ""simple"" csv or excel file as input and out a timeseries, if there is a timeseries to be
    extracted.
    '''

    def __init__(self, csv_file_path: str):
        self.file_path = csv_file_path
        self.df = None
        self.timeseries = None

    def process(self):
        # Load file
        _, ext = os.path.splitext(self.file_path.lower())
        if ext in ['.xls', '.xlsx']:
            self.df = pd.read_excel(self.file_path)
        elif ext in ['.csv', '.txt']:
            self.df = pd.read_csv(self.file_path)
        else:
            raise ValueError(f""Unsupported file extension: {ext}"")

        if self.df.empty:
            raise ValueError(""Input file is empty"")

        # Identify datetime-like columns
        date_scores = {}
        for col in self.df.columns:
            parsed = pd.to_datetime(self.df[col], errors='coerce', infer_datetime_format=True)
            non_null = parsed.notna().sum()
            date_scores[col] = non_null

        # pick the column with highest parse count, require at least one parse
        date_col, max_count = max(date_scores.items(), key=lambda kv: kv[1])
        if max_count == 0:
            raise ValueError(""No datetime-like column found"")

        dates = pd.to_datetime(self.df[date_col], errors='coerce', infer_datetime_format=True)

        # Identify numeric columns
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        if not numeric_cols:
            # try converting non-numeric to numeric
            for col in self.df.columns:
                coerced = pd.to_numeric(self.df[col], errors='coerce')
                if coerced.notna().sum() > 0:
                    numeric_cols.append(col)
            numeric_cols = list(dict.fromkeys(numeric_cols))
        if not numeric_cols:
            raise ValueError(""No numeric column found"")

        # choose first numeric column
        value_col = numeric_cols[0]
        values = pd.to_numeric(self.df[value_col], errors='coerce')

        # build timeseries
        ts = pd.Series(data=values.values, index=dates.values)
        ts = ts[~ts.index.isna()]
        ts.index = pd.to_datetime(ts.index)
        ts = ts.sort_index()

        self.timeseries = ts
        return ts","class SimpleTimeSeriesExtractor(object):
    '''
    This class will take a ""simple"" csv or excel file as input and out a timeseries, if there is a timeseries to be
    extracted.
    '''

    def __init__(self, csv_file_path: str):
        self.file_path = csv_file_path
        self.data = None
        self.time_series = None
        self.time_column = None
        self.value_columns = []

    def process(self):
        # Load the data
        self._load_data()
        
        # Identify time column and value columns
        self._identify_columns()
        
        # Extract time series
        if self.time_column and self.value_columns:
            self.time_series = self.data[[self.time_column] + self.value_columns]
            # Convert time column to datetime
            self.time_series[self.time_column] = pd.to_datetime(self.time_series[self.time_column])
            # Set time column as index
            self.time_series = self.time_series.set_index(self.time_column)
        
        return self.time_series

    def _load_data(self):
        file_extension = os.path.splitext(self.file_path)[1].lower()
        
        if file_extension == '.csv':
            self.data = pd.read_csv(self.file_path)
        elif file_extension in ['.xlsx', '.xls']:
            self.data = pd.read_excel(self.file_path)
        else:
            raise ValueError(""Unsupported file format. Please provide a CSV or Excel file."")

    def _identify_columns(self):
        if self.data is None:
            return
            
        # Try to identify time/date column
        for column in self.data.columns:
            # Check if column name suggests it's a time column
            col_name_lower = column.lower()
            if any(keyword in col_name_lower for keyword in ['date', 'time', 'datetime', 'timestamp']):
                self.time_column = column
                break
        
        # If no time column found by name, try to infer from data types
        if self.time_column is None:
            for column in self.data.columns:
                if self.data[column].dtype == 'object':
                    # Try to parse as datetime
                    try:
                        pd.to_datetime(self.data[column].iloc[:5])  # Test first 5 rows
                        self.time_column = column
                        break
                    except:
                        continue
        
        # Identify value columns (numeric columns excluding the time column)
        self.value_columns = []
        for column in self.data.columns:
            if column != self.time_column and pd.api.types.is_numeric_dtype(self.data[column]):
                self.value_columns.append(column)","class SimpleTimeSeriesExtractor(object):
    '''
    This class will take a ""simple"" csv or excel file as input and out a timeseries, if there is a timeseries to be
    extracted.
    '''

    def __init__(self, csv_file_path: str):
        self.csv_file_path = csv_file_path
        self.data = None
        self.timeseries = None

    def process(self):
        if not os.path.exists(self.csv_file_path):
            raise FileNotFoundError(f""File not found: {self.csv_file_path}"")
        
        file_extension = os.path.splitext(self.csv_file_path)[1].lower()
        
        try:
            if file_extension == '.csv':
                self.data = pd.read_csv(self.csv_file_path)
            elif file_extension in ['.xlsx', '.xls']:
                self.data = pd.read_excel(self.csv_file_path)
            else:
                raise ValueError(f""Unsupported file format: {file_extension}"")
        except Exception as e:
            raise ValueError(f""Error reading file: {str(e)}"")
        
        if self.data.empty:
            return None
        
        date_column = None
        value_column = None
        
        for col in self.data.columns:
            if self._is_date_column(self.data[col]):
                date_column = col
                break
        
        if date_column is None:
            return None
        
        numeric_columns = self.data.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) == 0:
            return None
        
        value_column = numeric_columns[0]
        
        try:
            df_clean = self.data[[date_column, value_column]].dropna()
            df_clean[date_column] = pd.to_datetime(df_clean[date_column])
            df_clean = df_clean.sort_values(date_column)
            df_clean.set_index(date_column, inplace=True)
            
            self.timeseries = df_clean[value_column]
            return self.timeseries
        except Exception:
            return None
    
    def _is_date_column(self, series):
        if series.dtype == 'datetime64[ns]':
            return True
        
        non_null_series = series.dropna()
        if len(non_null_series) == 0:
            return False
        
        sample_size = min(10, len(non_null_series))
        sample = non_null_series.head(sample_size)
        
        date_count = 0
        for value in sample:
            if self._is_date_string(str(value)):
                date_count += 1
        
        return date_count / sample_size >= 0.7
    
    def _is_date_string(self, value_str):
        date_patterns = [
            '%Y-%m-%d', '%m/%d/%Y', '%d/%m/%Y', '%Y/%m/%d',
            '%Y-%m-%d %H:%M:%S', '%m/%d/%Y %H:%M:%S',
            '%Y-%m', '%m/%Y', '%Y'
        ]
        
        for pattern in date_patterns:
            try:
                datetime.strptime(value_str, pattern)
                return True
            except ValueError:
                continue
        
        try:
            pd.to_datetime(value_str)
            return True
        except (ValueError, TypeError):
            return False",partial_docstr,0.2894736842105263,0.22222222222222224,0.19680851063829788,0.2736842105263158,0.1470761541747017,0.2013888888888889,0.1373913043478261,0.11498257839721254,0.6798803806304932,0.8776564598083496,0.7662115693092346,0.8528473377227783,0.7191808904109586,0.2760290556900727,0.20437956204379562,0.18092909535452323,0.25181598062953997,0.14047472693192195,0.18887015177065766,0.13344594594594594,0.10998307952622674,0.7072478532791138,0.8773638606071472,0.783174455165863,0.8567560911178589,0.7170968461538462,0.24608501118568232,0.21573033707865172,0.1986455981941309,0.24161073825503357,0.12440709497892678,0.15675675675675677,0.11772665764546685,0.1043360433604336,0.6725014448165894,0.8851146697998047,0.7642973065376282,0.8579891324043274,0.7093692975206621,0.4134018880790783,0.1363139346824197,0.5275896279299036,0.5135135135135135,0.4761904761904761,0.433079508811648,0.1182413874560893,0.5291345628484176,0.5135135135135135,0.5714285714285714,0.4350513068580499,0.1341343954762731,0.5687477946328893,0.5135135135135135,0.5238095238095238
197885,StanfordVL/robosuite,StanfordVL_robosuite/robosuite/utils/mjmod.py,robosuite.utils.mjmod.BaseModder,"class BaseModder:
    """"""
    Base class meant to modify simulation attributes mid-sim.

    Using @random_state ensures that sampling here won't be affected
    by sampling that happens outside of the modders.

    Args:
        sim (MjSim): simulation object

        random_state (RandomState): instance of np.random.RandomState, specific
            seed used to randomize these modifications without impacting other
            numpy seeds / randomizations
    """"""

    def __init__(self, sim, random_state=None):
        self.sim = sim
        if random_state is None:
            # default to global RandomState instance
            self.random_state = np.random.mtrand._rand
        else:
            self.random_state = random_state

    def update_sim(self, sim):
        """"""
        Setter function to update internal sim variable

        Args:
            sim (MjSim): MjSim object
        """"""
        self.sim = sim

    @property
    def model(self):
        """"""
        Returns:
            MjModel: Mujoco sim model
        """"""
        # Available for quick convenience access
        return self.sim.model","class BaseModder:
    '''
    Base class meant to modify simulation attributes mid-sim.

    Using @random_state ensures that sampling here won't be affected
    by sampling that happens outside of the modders.

    Args:
        sim (MjSim): simulation object

        random_state (RandomState): instance of np.random.RandomState, specific
            seed used to randomize these modifications without impacting other
            numpy seeds / randomizations
    '''

    def __init__(self, sim, random_state=None):
        pass

    def update_sim(self, sim):
    '''
        Setter function to update internal sim variable

        Args:
            sim (MjSim): MjSim object
        '''
        pass

    @property
    def model(self):
    '''
        Returns:
            MjModel: Mujoco sim model
        '''
        pass

",5,3,snippet_160,0.8333333333333334,"class BaseModder:
    '''
    Base class meant to modify simulation attributes mid-sim.

    Using @random_state ensures that sampling here won't be affected
    by sampling that happens outside of the modders.

    Args:
        sim (MjSim): simulation object

        random_state (RandomState): instance of np.random.RandomState, specific
            seed used to randomize these modifications without impacting other
            numpy seeds / randomizations
    '''

    def __init__(self, sim, random_state=None):
        self.sim = sim
        if random_state is None:
            self.random_state = np.random.RandomState()
        else:
            self.random_state = random_state

    def update_sim(self, sim):
        '''
        Setter function to update internal sim variable

        Args:
            sim (MjSim): MjSim object
        '''
        self.sim = sim

    @property
    def model(self):
        '''
        Returns:
            MjModel: Mujoco sim model
        '''
        return self.sim.model","class BaseModder:
    '''
    Base class meant to modify simulation attributes mid-sim.

    Using @random_state ensures that sampling here won't be affected
    by sampling that happens outside of the modders.

    Args:
        sim (MjSim): simulation object

        random_state (RandomState): instance of np.random.RandomState, specific
            seed used to randomize these modifications without impacting other
            numpy seeds / randomizations
    '''

    def __init__(self, sim, random_state=None):
        self.sim = sim
        self.random_state = random_state

    def update_sim(self, sim):
        '''
        Setter function to update internal sim variable

        Args:
            sim (MjSim): MjSim object
        '''
        self.sim = sim

    @property
    def model(self):
        '''
        Returns:
            MjModel: Mujoco sim model
        '''
        return self.sim.model","class BaseModder:
    '''
    Base class meant to modify simulation attributes mid-sim.

    Using @random_state ensures that sampling here won't be affected
    by sampling that happens outside of the modders.

    Args:
        sim (MjSim): simulation object

        random_state (RandomState): instance of np.random.RandomState, specific
            seed used to randomize these modifications without impacting other
            numpy seeds / randomizations
    '''

    def __init__(self, sim, random_state=None):
        self.sim = sim
        self.random_state = random_state

    def update_sim(self, sim):
        '''
        Setter function to update internal sim variable

        Args:
            sim (MjSim): MjSim object
        '''
        self.sim = sim

    @property
    def model(self):
        '''
        Returns:
            MjModel: Mujoco sim model
        '''
        return self.sim.model",partial_docstr,0.9547325102880658,0.921161825726141,0.895397489539749,0.9465020576131687,0.7920091310589595,0.9565217391304348,0.907103825136612,0.8626373626373627,0.9923210740089417,0.9633408188819885,0.9776162505149841,0.966162383556366,0.9846744827586207,0.9004329004329005,0.8820960698689957,0.8634361233480177,0.9004329004329005,0.6858611549448462,0.9629629629629629,0.9192546583850931,0.875,0.9805327653884888,0.9412336349487305,0.9604813456535339,0.9450212121009827,0.9195410344827586,0.9004329004329005,0.8820960698689957,0.8634361233480177,0.9004329004329005,0.6858611549448462,0.9629629629629629,0.9192546583850931,0.875,0.9805327653884888,0.9412336349487305,0.9604813456535339,0.9450212121009827,0.9195410344827586,0.7685944378834513,0.7257169860783584,0.7272032755769043,0.7368421052631579,0.8846153846153846,0.6782878739671914,0.6677396976454255,0.6688935795998585,0.6842105263157895,0.6923076923076923,0.6782878739671914,0.6677396976454255,0.6688935795998585,0.6842105263157895,0.6923076923076923
374713,exa-analytics/exa,exa-analytics_exa/exa/core/numerical.py,exa.core.numerical.Numerical,"class Numerical(object):
    """"""
    Base class for :class:`~exa.core.numerical.Series`,
    :class:`~exa.core.numerical.DataFrame`, and :class:`~exa.numerical.Field`
    objects, providing default trait functionality and clean representations
    when present as part of containers.
    """"""
    @property
    def log(self):
        name = '.'.join([self.__module__, self.__class__.__name__])
        return logging.getLogger(name)

    def slice_naive(self, key):
        """"""
        Slice a data object based on its index, either by value (.loc) or
        position (.iloc).

        Args:
            key: Single index value, slice, tuple, or list of indices/positionals

        Returns:
            data: Slice of self
        """"""
        cls = self.__class__
        key = check_key(self, key)
        return cls(self.loc[key])

    def __repr__(self):
        name = '.'.join([self.__module__, self.__class__.__name__])
        return '{0}{1}'.format(name, self.shape)

    def __str__(self):
        return self.__repr__()","class Numerical(object):
    '''
    Base class for :class:`~exa.core.numerical.Series`,
    :class:`~exa.core.numerical.DataFrame`, and :class:`~exa.numerical.Field`
    objects, providing default trait functionality and clean representations
    when present as part of containers.
    '''

    @property
    def log(self):
        pass

    def slice_naive(self, key):
    '''
        Slice a data object based on its index, either by value (.loc) or
        position (.iloc).

        Args:
            key: Single index value, slice, tuple, or list of indices/positionals

        Returns:
            data: Slice of self
        '''
        pass

    def __repr__(self):
        pass

    def __str__(self):
        pass

",6,2,snippet_663,0.8333333333333334,"class Numerical(object):
    '''
    Base class for :class:`~exa.core.numerical.Series`,
    :class:`~exa.core.numerical.DataFrame`, and :class:`~exa.numerical.Field`
    objects, providing default trait functionality and clean representations
    when present as part of containers.
    '''

    @property
    def log(self):
        # elementwise natural log
        return np.log(self)

    def slice_naive(self, key):
        '''
        Slice a data object based on its index, either by value (.loc) or
        position (.iloc).

        Args:
            key: Single index value, slice, tuple, or list of indices/positionals

        Returns:
            data: Slice of self
        '''
        # try label-based slicing first
        if hasattr(self, 'loc'):
            try:
                return self.loc[key]
            except (KeyError, IndexError, TypeError):
                pass
        # fallback to positional slicing
        if hasattr(self, 'iloc'):
            try:
                return self.iloc[key]
            except (IndexError, TypeError):
                pass
        # last resort: try plain __getitem__
        try:
            return self[key]
        except Exception as e:
            raise e

    def __repr__(self):
        # clean, minimal container-aware repr
        name = self.__class__.__name__
        content = ''
        if hasattr(self, 'to_string'):
            try:
                content = self.to_string()
            except Exception:
                content = ''
        return f'<{name}{"": "" + content if content else """"}>'

    def __str__(self):
        return self.__repr__()","class Numerical(object):
    '''
    Base class for :class:`~exa.core.numerical.Series`,
    :class:`~exa.core.numerical.DataFrame`, and :class:`~exa.numerical.Field`
    objects, providing default trait functionality and clean representations
    when present as part of containers.
    '''

    @property
    def log(self):
        return self._log if hasattr(self, '_log') else None

    def slice_naive(self, key):
        '''
        Slice a data object based on its index, either by value (.loc) or
        position (.iloc).

        Args:
            key: Single index value, slice, tuple, or list of indices/positionals

        Returns:
            data: Slice of self
        '''
        if hasattr(self, 'loc') and hasattr(self, 'iloc'):
            try:
                return self.loc[key]
            except (KeyError, TypeError):
                return self.iloc[key]
        elif hasattr(self, 'iloc'):
            return self.iloc[key]
        elif hasattr(self, 'loc'):
            return self.loc[key]
        else:
            raise NotImplementedError(""Slicing not implemented for this numerical object"")

    def __repr__(self):
        if hasattr(self, '_repr'):
            return self._repr
        return f""<{self.__class__.__name__} object at {hex(id(self))}>""

    def __str__(self):
        if hasattr(self, '_str'):
            return self._str
        return self.__repr__()","class Numerical(object):
    '''
    Base class for :class:`~exa.core.numerical.Series`,
    :class:`~exa.core.numerical.DataFrame`, and :class:`~exa.numerical.Field`
    objects, providing default trait functionality and clean representations
    when present as part of containers.
    '''

    @property
    def log(self):
        return logging.getLogger(self.__class__.__name__)

    def slice_naive(self, key):
        '''
        Slice a data object based on its index, either by value (.loc) or
        position (.iloc).

        Args:
            key: Single index value, slice, tuple, or list of indices/positionals

        Returns:
            data: Slice of self
        '''
        if isinstance(key, (int, slice)):
            return self.iloc[key]
        elif isinstance(key, (list, tuple)):
            if all(isinstance(k, int) for k in key):
                return self.iloc[key]
            else:
                return self.loc[key]
        else:
            return self.loc[key]

    def __repr__(self):
        class_name = self.__class__.__name__
        if hasattr(self, 'shape'):
            return f""{class_name}(shape={self.shape})""
        elif hasattr(self, '__len__'):
            return f""{class_name}(length={len(self)})""
        else:
            return f""{class_name}()""

    def __str__(self):
        if hasattr(self, 'to_string'):
            return self.to_string()
        elif hasattr(self, '__array__'):
            return str(self.__array__())
        else:
            return super().__str__()",partial_docstr,0.7027027027027027,0.5918367346938775,0.5410958904109588,0.668918918918919,0.5794092675035185,0.7044776119402985,0.5538922155688623,0.4984984984984985,0.8372313976287842,0.9080079197883606,0.8711845278739929,0.9003963470458984,0.7644951086956522,0.7177700348432057,0.5964912280701754,0.5512367491166078,0.7038327526132404,0.5949267060191423,0.7217125382262997,0.5644171779141104,0.5169230769230769,0.8622297048568726,0.9122169017791748,0.886519193649292,0.9069588780403137,0.7636707936507942,0.7441860465116279,0.6287625418060201,0.5454545454545454,0.6976744186046511,0.5477373909115858,0.682741116751269,0.5241730279898219,0.45918367346938777,0.8633542656898499,0.9346104860305786,0.8975703716278076,0.9269599914550781,0.7588349769585252,0.4846146877108768,0.3763681559624467,0.6495061354216013,0.453125,0.4594594594594595,0.4879061902691597,0.446017675541669,0.6284955990484835,0.390625,0.4864864864864865,0.5466631606649839,0.4477080942633575,0.6257688727209024,0.4375,0.6756756756756757
815152,unixsurfer/anycast_healthchecker,unixsurfer_anycast_healthchecker/anycast_healthchecker/utils.py,anycast_healthchecker.utils.CustomLogger,"class CustomLogger:
    """"""Helper Logger to redirect STDOUT or STDERR to a logging hander.

    It wraps a Logger class into a file like object, which provides a handy
    way to redirect STDOUT or STDERR to a logger. This class provides the
    necessary methods (write, flush and close) to build a file-like object
    and it can not be used directly as it does not provide a logging handler.
    Instead, you must instantiate one of subclass (CustomRotatingFileLogger and
    CustomUdpLogger).

    Arguments
        handler (int): A logging handler to use.

    Methods:
        write(string): Write string to logger with newlines removed.
        flush(): Flushe logger messages.
        close(): Close logger.

    Returns:
        A logger object.

    """"""

    def __init__(self, handler):
        """"""Create a logging.Logger class with extended functionality.""""""
        log_format = ('%(asctime)s {program}[%(process)d] '
                      '%(threadName)s %(message)s'
                      .format(program=PROGRAM_NAME))
        self.logger = logging.getLogger('stderr')
        self.logger.setLevel(logging.DEBUG)
        self.handler = handler
        formatter = logging.Formatter(log_format)
        self.handler.setFormatter(formatter)
        self.logger.addHandler(self.handler)

    def write(self, string):
        """"""Erase newline from a string and write to the logger.""""""
        string = string.rstrip()
        if string:  # Don't log empty lines
            self.logger.critical(string)

    def flush(self):
        """"""Flush logger's data.""""""
        # In case multiple handlers are attached to the logger make sure they
        # are flushed.
        for handler in self.logger.handlers:
            handler.flush()

    def close(self):
        """"""Call the closer method of the logger.""""""
        # In case multiple handlers are attached to the logger make sure they
        # are all closed.
        for handler in self.logger.handlers:
            handler.close()","class CustomLogger:
    '''Helper Logger to redirect STDOUT or STDERR to a logging hander.

    It wraps a Logger class into a file like object, which provides a handy
    way to redirect STDOUT or STDERR to a logger. This class provides the
    necessary methods (write, flush and close) to build a file-like object
    and it can not be used directly as it does not provide a logging handler.
    Instead, you must instantiate one of subclass (CustomRotatingFileLogger and
    CustomUdpLogger).

    Arguments
        handler (int): A logging handler to use.

    Methods:
        write(string): Write string to logger with newlines removed.
        flush(): Flushe logger messages.
        close(): Close logger.

    Returns:
        A logger object.

    '''

    def __init__(self, handler):
    '''Create a logging.Logger class with extended functionality.'''
        pass

    def write(self, string):
    '''Erase newline from a string and write to the logger.'''
        pass

    def flush(self):
    '''Flush logger's data.'''
        pass

    def close(self):
    '''Call the closer method of the logger.'''
        pass

",5,5,snippet_746,0.3333333333333333,"class CustomLogger:
    '''Helper Logger to redirect STDOUT or STDERR to a logging handler.

    It wraps a Logger class into a file like object, which provides a handy
    way to redirect STDOUT or STDERR to a logger. This class provides the
    necessary methods (write, flush and close) to build a file-like object
    and it can not be used directly as it does not provide a logging handler.
    Instead, you must instantiate one of subclass (CustomRotatingFileLogger and
    CustomUdpLogger).

    Arguments
        handler (logging.Handler): A logging handler to use.

    Methods:
        write(string): Write string to logger with newlines removed.
        flush(): Flush logger messages.
        close(): Close logger.

    Returns:
        A logger object.
    '''

    def __init__(self, handler):
        '''Create a logging.Logger class with extended functionality.'''
        self.handler = handler
        name = f""CustomLogger-{uuid.uuid4()}""
        self.logger = logging.getLogger(name)
        self.logger.propagate = False
        self.logger.setLevel(logging.DEBUG)
        self.logger.addHandler(handler)

    def write(self, string):
        '''Erase newline from a string and write to the logger.'''
        text = string.rstrip('\n')
        if text:
            for line in text.splitlines():
                self.logger.info(line)

    def flush(self):
        '''Flush logger's data.'''
        for h in self.logger.handlers:
            try:
                h.flush()
            except Exception:
                pass

    def close(self):
        '''Call the closer method of the logger.'''
        for h in list(self.logger.handlers):
            try:
                h.close()
            except Exception:
                pass
            self.logger.removeHandler(h)","class CustomLogger:
    '''Helper Logger to redirect STDOUT or STDERR to a logging hander.

    It wraps a Logger class into a file like object, which provides a handy
    way to redirect STDOUT or STDERR to a logger. This class provides the
    necessary methods (write, flush and close) to build a file-like object
    and it can not be used directly as it does not provide a logging handler.
    Instead, you must instantiate one of subclass (CustomRotatingFileLogger and
    CustomUdpLogger).

    Arguments
        handler (int): A logging handler to use.

    Methods:
        write(string): Write string to logger with newlines removed.
        flush(): Flushe logger messages.
        close(): Close logger.

    Returns:
        A logger object.

    '''

    def __init__(self, handler):
        '''Create a logging.Logger class with extended functionality.'''
        self.handler = handler

    def write(self, string):
        '''Erase newline from a string and write to the logger.'''
        if string.strip():  # Only write non-empty strings
            self.handler.write(string.rstrip('\n'))

    def flush(self):
        '''Flush logger's data.'''
        if hasattr(self.handler, 'flush'):
            self.handler.flush()

    def close(self):
        '''Call the closer method of the logger.'''
        if hasattr(self.handler, 'close'):
            self.handler.close()","class CustomLogger:
    '''Helper Logger to redirect STDOUT or STDERR to a logging hander.

    It wraps a Logger class into a file like object, which provides a handy
    way to redirect STDOUT or STDERR to a logger. This class provides the
    necessary methods (write, flush and close) to build a file-like object
    and it can not be used directly as it does not provide a logging handler.
    Instead, you must instantiate one of subclass (CustomRotatingFileLogger and
    CustomUdpLogger).

    Arguments
        handler (int): A logging handler to use.

    Methods:
        write(string): Write string to logger with newlines removed.
        flush(): Flushe logger messages.
        close(): Close logger.

    Returns:
        A logger object.

    '''

    def __init__(self, handler):
        '''Create a logging.Logger class with extended functionality.'''
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        self.logger.addHandler(handler)

    def write(self, string):
        '''Erase newline from a string and write to the logger.'''
        if string.strip():
            self.logger.info(string.rstrip('\n\r'))

    def flush(self):
        '''Flush logger's data.'''
        for handler in self.logger.handlers:
            handler.flush()

    def close(self):
        '''Call the closer method of the logger.'''
        for handler in self.logger.handlers:
            handler.close()",partial_docstr,0.7999999999999999,0.6837606837606838,0.6223175965665235,0.7531914893617022,0.5872667932717642,0.8542274052478134,0.7076023391812866,0.624633431085044,0.9281196594238281,0.8959612846374512,0.9117569923400879,0.8990764617919922,0.8522351546391752,0.7824074074074076,0.7209302325581396,0.677570093457944,0.7638888888888888,0.48013240370817434,0.9047619047619048,0.8051470588235294,0.7195571955719557,0.9473533034324646,0.8702908754348755,0.9071885347366333,0.8774283528327942,0.798915054347826,0.8382687927107061,0.7917620137299771,0.7448275862068966,0.8291571753986332,0.5618719174902873,0.9347079037800687,0.8586206896551725,0.7889273356401384,0.9529012441635132,0.8888152837753296,0.9197432994842529,0.8948334455490112,0.871378097826087,0.5013474711646709,0.5280955201885941,0.5507148437729217,0.611764705882353,0.3148148148148148,0.4374815953182732,0.5345597237648074,0.5696150235213573,0.4235294117647059,0.2222222222222222,0.5067850470064306,0.5654964807900131,0.6108811800025935,0.6470588235294118,0.2037037037037037
596595,nerdvegas/rez,nerdvegas_rez/src/rez/utils/data_utils.py,rez.utils.data_utils.cached_class_property,"class cached_class_property(object):
    """"""Simple class property caching descriptor.

    Example:

        >>> class Foo(object):
        >>>     @cached_class_property
        >>>     def bah(cls):
        >>>         print('bah')
        >>>         return 1
        >>>
        >>> Foo.bah
        bah
        1
        >>> Foo.bah
        1
    """"""
    def __init__(self, func, name=None):
        self.func = func
        # Make sure that Sphinx autodoc can follow and get the docstring from our wrapped function.
        # TODO: Doesn't work...
        functools.update_wrapper(self, func)

    def __get__(self, instance, owner=None):
        assert owner
        name = ""_class_property_"" + self.func.__name__
        result = getattr(owner, name, KeyError)

        if result is KeyError:
            result = self.func(owner)
            setattr(owner, name, result)
        return result","class cached_class_property(object):
    '''Simple class property caching descriptor.

    Example:

        >>> class Foo(object):
        >>>     @cached_class_property
        >>>     def bah(cls):
        >>>         print('bah')
        >>>         return 1
        >>>
        >>> Foo.bah
        bah
        1
        >>> Foo.bah
        1
    '''

    def __init__(self, func, name=None):
        pass

    def __get__(self, instance, owner=None):
        pass

",3,1,snippet_437,0.4285714285714285,"class cached_class_property(object):
    '''Simple class property caching descriptor.

    Example:

        >>> class Foo(object):
        >>>     @cached_class_property
        >>>     def bah(cls):
        >>>         print('bah')
        >>>         return 1
        >>>
        >>> Foo.bah
        bah
        1
        >>> Foo.bah
        1
    '''

    def __init__(self, func, name=None):
        self.func = func
        self.name = name or func.__name__
        self.__doc__ = func.__doc__

    def __get__(self, instance, owner=None):
        if owner is None:
            owner = type(instance)
        if self.name in owner.__dict__:
            return owner.__dict__[self.name]
        value = self.func(owner)
        setattr(owner, self.name, value)
        return value","class cached_class_property(object):
    '''Simple class property caching descriptor.

    Example:

        >>> class Foo(object):
        >>>     @cached_class_property
        >>>     def bah(cls):
        >>>         print('bah')
        >>>         return 1
        >>>
        >>> Foo.bah
        bah
        1
        >>> Foo.bah
        1
    '''

    def __init__(self, func, name=None):
        self.func = func
        self.name = name or func.__name__
        self.__doc__ = func.__doc__

    def __get__(self, instance, owner=None):
        if owner is None:
            owner = type(instance)
        
        if not hasattr(owner, '_cached_class_properties'):
            owner._cached_class_properties = {}
        
        if self.name not in owner._cached_class_properties:
            owner._cached_class_properties[self.name] = self.func(owner)
        
        return owner._cached_class_properties[self.name]","class cached_class_property(object):
    '''Simple class property caching descriptor.

    Example:

        >>> class Foo(object):
        >>>     @cached_class_property
        >>>     def bah(cls):
        >>>         print('bah')
        >>>         return 1
        >>>
        >>> Foo.bah
        bah
        1
        >>> Foo.bah
        1
    '''

    def __init__(self, func, name=None):
        self.func = func
        self.name = name or func.__name__

    def __get__(self, instance, owner=None):
        if owner is None:
            owner = type(instance)
        
        if hasattr(owner, '_cached_class_properties'):
            cache = owner._cached_class_properties
        else:
            cache = owner._cached_class_properties = {}
        
        if self.name not in cache:
            cache[self.name] = self.func(owner)
        
        return cache[self.name]",partial_docstr,0.7032967032967034,0.5444444444444445,0.5056179775280899,0.6593406593406593,0.6479688445669555,0.7989949748743719,0.6515151515151515,0.5989847715736041,0.932712197303772,0.8509707450866699,0.8899684548377991,0.8584944009780884,0.8594785294117647,0.6530612244897959,0.4845360824742268,0.44791666666666663,0.6020408163265306,0.585354058931299,0.6929824561403509,0.5638766519823789,0.5132743362831859,0.9113092422485352,0.8408829569816589,0.874680757522583,0.8474318981170654,0.8274871052631578,0.6666666666666666,0.5026737967914437,0.4648648648648649,0.6031746031746031,0.640485297326238,0.7658536585365854,0.6274509803921569,0.5714285714285714,0.9102221727371216,0.8359898328781128,0.8715282082557678,0.8428636789321899,0.8409801834862385,0.461500871703002,0.4088577410944629,0.4311933647651642,0.3809523809523809,0.625,0.4543337185827929,0.4040857885265912,0.4236657524712472,0.3333333333333333,0.65625,0.4469450111098732,0.4057809586349124,0.4236657524712472,0.3333333333333333,0.625
575991,miquelo/resort,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/miquelo_resort/packages/resort/component/docker.py,resort.component.docker.Image,"class Image:

    """"""
    Packer image.

    :param str base_dir:
       Template base directory.
    :param str template_path:
       Template file path relative to ``base_dir``.
    """"""

    def __init__(self, base_dir, template_path):

        self.__base_dir = base_dir
        self.__template_path = template_path

    def __repr__(self):

        return ""{}.{}({}, {})"".format(
            self.__module__,
            type(self).__name__,
            repr(self.__base_dir),
            repr(self.__template_path)
        )

    def available(self, context):
        """"""
        Always return ``None``.

        :param resort.engine.execution.Context context:
           Current execution context.
        """"""

        return None

    def insert(self, context):
        """"""
        Build the image.

        :param resort.engine.execution.Context context:
           Current execution context.
        """"""

        try:
            current_dir = os.getcwd()
            os.chdir(os.path.join(context.profile_dir(), self.__base_dir))
            args = [
                ""packer"",
                ""build"",
                self.__template_path
            ]
            subprocess.call(args)
        finally:
            shutil.rmtree(""output-*"", ignore_errors=True)
            os.chdir(current_dir)

    def delete(self, context):
        """"""
        Does nothing.

        :param resort.engine.execution.Context context:
           Current execution context.
        """"""

        pass","class Image:
    '''
    Packer image.

    :param str base_dir:
       Template base directory.
    :param str template_path:
       Template file path relative to ``base_dir``.
    '''


    def __init__(self, base_dir, template_path):
        pass


    def __repr__(self):
        pass


    def available(self, context):
    '''
        Always return ``None``.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        pass


    def insert(self, context):
    '''
        Build the image.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        pass


    def delete(self, context):
    '''
        Does nothing.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        pass

",6,4,snippet_38,1.0,"class Image:
    '''
    Packer image.

    :param str base_dir:
       Template base directory.
    :param str template_path:
       Template file path relative to ``base_dir``.
    '''

    def __init__(self, base_dir, template_path):
        self.base_dir = base_dir
        self.template_path = template_path

    def __repr__(self):
        return ""Image(base_dir={!r}, template_path={!r})"".format(
            self.base_dir, self.template_path)

    def available(self, context):
        '''
        Always return ``None``.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        return None

    def insert(self, context):
        '''
        Build the image.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        tpl = os.path.join(self.base_dir, self.template_path)

        # Validate the template
        subprocess.check_call(['packer', 'validate', tpl], cwd=self.base_dir)

        # Build and capture machine-readable output
        output = subprocess.check_output(
            ['packer', 'build', '-machine-readable', tpl],
            cwd=self.base_dir,
            universal_newlines=True
        )

        ami_id = None
        for line in output.splitlines():
            parts = line.split(',')
            # format: timestamp,artifact,0,id,ami-xxxxxx
            if len(parts) >= 5 and parts[1] == 'artifact' and parts[2] == '0' and parts[3] == 'id':
                ami_id = parts[4].strip()
                break

        if not ami_id:
            raise RuntimeError('Failed to parse AMI ID from packer output')

        return ami_id

    def delete(self, context):
        '''
        Does nothing.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        pass","class Image:
    '''
    Packer image.

    :param str base_dir:
       Template base directory.
    :param str template_path:
       Template file path relative to ``base_dir``.
    '''


    def __init__(self, base_dir, template_path):
        self.base_dir = base_dir
        self.template_path = template_path


    def __repr__(self):
        return f""Image(base_dir={self.base_dir!r}, template_path={self.template_path!r})""


    def available(self, context):
        '''
        Always return ``None``.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        return None


    def insert(self, context):
        '''
        Build the image.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        # Build the image
        pass


    def delete(self, context):
        '''
        Does nothing.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        pass","class Image:
    '''
    Packer image.

    :param str base_dir:
       Template base directory.
    :param str template_path:
       Template file path relative to ``base_dir``.
    '''

    def __init__(self, base_dir, template_path):
        self.base_dir = base_dir
        self.template_path = template_path

    def __repr__(self):
        return f""Image(base_dir='{self.base_dir}', template_path='{self.template_path}')""

    def available(self, context):
        '''
        Always return ``None``.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        return None

    def insert(self, context):
        '''
        Build the image.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        template_full_path = os.path.join(self.base_dir, self.template_path)
        
        cmd = ['packer', 'build', template_full_path]
        
        env = os.environ.copy()
        if hasattr(context, 'variables'):
            for key, value in context.variables.items():
                env[f'PKR_VAR_{key}'] = str(value)
        
        subprocess.run(cmd, cwd=self.base_dir, env=env, check=True)

    def delete(self, context):
        '''
        Does nothing.

        :param resort.engine.execution.Context context:
           Current execution context.
        '''
        pass",partial_docstr,0.6818181818181819,0.5942857142857143,0.5402298850574713,0.6420454545454546,0.5219601204143967,0.6592592592592592,0.5024752475247525,0.4292803970223325,0.8246005177497864,0.9023419618606567,0.861721396446228,0.8939142823219299,0.8221306302521009,0.8188976377952756,0.7698412698412699,0.72,0.7874015748031497,0.4481711653744887,0.9128440366972477,0.8064516129032258,0.7175925925925926,0.9468336701393127,0.8577514886856079,0.9000937938690186,0.8658981919288635,0.8122624137931035,0.7826086956521738,0.6936026936026936,0.6440677966101696,0.7424749163879598,0.5861986524873918,0.8050314465408805,0.6246056782334385,0.5221518987341772,0.8969287872314453,0.9024637937545776,0.8996877670288086,0.901907205581665,0.8380430508474576,0.5139533655353882,0.323982222351085,0.5123190446685163,0.5609756097560976,0.6585365853658537,0.4156663277815264,0.48298896255361,0.5089446412554225,0.3780487804878049,0.2926829268292683,0.52420252119432,0.4758523298854582,0.5112016573308462,0.524390243902439,0.5853658536585366
521236,jreinhardt/constraining-order,jreinhardt_constraining-order/src/constrainingorder/__init__.py,constrainingorder.Space,"class Space(object):
    """"""
    A space is a description of the computation space for a specific CSP.
    """"""
    def __init__(self,variables, constraints):
        """"""
        Create a new Space for a CSP

        :param variables: The variables of the CSP
        :type variables: sequence of Variables
        :param constraints: The constraints of the CSP
        :type constraints: sequence of Constraints
        """"""
        self.constraints = constraints
        ""list of constraints""
        self.variables = {}
        ""dictionary of variable names to variable instances""
        self.domains = {}
        ""dictionary of variable names to DiscreteSet/IntervalSet with admissible values""
        for var in variables:
            self.variables[var.name] = var
            self.domains[var.name] = var.domain

    def is_discrete(self):
        """"""
        Return whether this space is discrete
        """"""
        for domain in self.domains.values():
            if not domain.is_discrete():
                return False
        return True
    def consistent(self,lab):
        """"""
        Check whether the labeling is consistent with all constraints
        """"""
        for const in self.constraints:
            if not const.consistent(lab):
                return False
        return True
    def satisfied(self,lab):
        """"""
        Check whether the labeling satisfies all constraints
        """"""
        for const in self.constraints:
            if not const.satisfied(lab):
                return False
        return True","class Space(object):
    '''
    A space is a description of the computation space for a specific CSP.
    '''

    def __init__(self,variables, constraints):
    '''
        Create a new Space for a CSP

        :param variables: The variables of the CSP
        :type variables: sequence of Variables
        :param constraints: The constraints of the CSP
        :type constraints: sequence of Constraints
        '''
        pass

    def is_discrete(self):
    '''
        Return whether this space is discrete
        '''
        pass

    def consistent(self,lab):
    '''
        Check whether the labeling is consistent with all constraints
        '''
        pass

    def satisfied(self,lab):
    '''
        Check whether the labeling satisfies all constraints
        '''
        pass

",5,5,snippet_110,0.5625,"class Space(object):
    '''
    A space is a description of the computation space for a specific CSP.
    '''

    def __init__(self, variables, constraints):
        '''
        Create a new Space for a CSP

        :param variables: The variables of the CSP
        :type variables: sequence of Variables
        :param constraints: The constraints of the CSP
        :type constraints: sequence of Constraints
        '''
        self.variables = list(variables)
        self.constraints = list(constraints)

    def is_discrete(self):
        '''
        Return whether this space is discrete
        '''
        return all(var.is_discrete() for var in self.variables)

    def consistent(self, lab):
        '''
        Check whether the labeling is consistent with all constraints
        '''
        for c in self.constraints:
            if not c.consistent(lab):
                return False
        return True

    def satisfied(self, lab):
        '''
        Check whether the labeling satisfies all constraints
        '''
        # all variables must be assigned
        for v in self.variables:
            if v not in lab:
                return False
        # all constraints must be satisfied
        for c in self.constraints:
            if not c.satisfied(lab):
                return False
        return True","class Space(object):
    '''
    A space is a description of the computation space for a specific CSP.
    '''

    def __init__(self, variables, constraints):
        '''
        Create a new Space for a CSP

        :param variables: The variables of the CSP
        :type variables: sequence of Variables
        :param constraints: The constraints of the CSP
        :type constraints: sequence of Constraints
        '''
        self.variables = variables
        self.constraints = constraints

    def is_discrete(self):
        '''
        Return whether this space is discrete
        '''
        # Assuming all CSP spaces are discrete by default
        # This could be extended to check variable domains
        return True

    def consistent(self, lab):
        '''
        Check whether the labeling is consistent with all constraints
        '''
        for constraint in self.constraints:
            if not constraint.consistent(lab):
                return False
        return True

    def satisfied(self, lab):
        '''
        Check whether the labeling satisfies all constraints
        '''
        for constraint in self.constraints:
            if not constraint.satisfied(lab):
                return False
        return True","class Space(object):
    '''
    A space is a description of the computation space for a specific CSP.
    '''

    def __init__(self, variables, constraints):
        '''
        Create a new Space for a CSP

        :param variables: The variables of the CSP
        :type variables: sequence of Variables
        :param constraints: The constraints of the CSP
        :type constraints: sequence of Constraints
        '''
        self.variables = list(variables)
        self.constraints = list(constraints)

    def is_discrete(self):
        '''
        Return whether this space is discrete
        '''
        return all(var.is_discrete() for var in self.variables)

    def consistent(self, lab):
        '''
        Check whether the labeling is consistent with all constraints
        '''
        for constraint in self.constraints:
            if not constraint.consistent(lab):
                return False
        return True

    def satisfied(self, lab):
        '''
        Check whether the labeling satisfies all constraints
        '''
        for constraint in self.constraints:
            if not constraint.satisfied(lab):
                return False
        return True",partial_docstr,0.8246153846153846,0.7120743034055729,0.6230529595015577,0.7200000000000001,0.5614831367817421,0.8434782608695652,0.7117903930131004,0.6140350877192983,0.9414355754852295,0.904615581035614,0.922658383846283,0.9081675410270691,0.8563232758620689,0.7896440129449838,0.716612377850163,0.6622950819672131,0.7572815533980581,0.49444351469115855,0.86,0.7537688442211056,0.6818181818181818,0.9405508637428284,0.8985064029693604,0.9190480709075928,0.902540922164917,0.8716487931034482,0.8316831683168316,0.7641196013289037,0.6755852842809366,0.7722772277227723,0.5218897548849545,0.9014778325123153,0.7821782178217822,0.6915422885572139,0.9538565874099731,0.8991114497184753,0.9256753325462341,0.9043015241622925,0.8793115517241378,0.5024961361118594,0.4797906629222356,0.5026819198027137,0.618421052631579,0.4090909090909091,0.4533883281381063,0.471745747250281,0.4865444074074075,0.6052631578947368,0.25,0.4811391095342575,0.4576218399655222,0.4848771819035654,0.618421052631579,0.3636363636363636
127608,HewlettPackard/python-hpOneView,HewlettPackard_python-hpOneView/hpOneView/resources/settings/versions.py,hpOneView.resources.settings.versions.Versions,"class Versions(object):
    """"""
    Version API client. It indicates the range of API versions supported by the appliance.

    """"""
    URI = '/rest/version'

    def __init__(self, con):
        self._client = ResourceClient(con, self.URI)

    def get_version(self):
        """"""
        Returns the range of possible API versions supported by the appliance.
        The response contains the current version and the minimum version.
        The current version is the recommended version to specify in the REST header.
        The other versions are supported for backward compatibility, but might not support the most current features.

        Returns:
            dict: The minimum and maximum supported API versions.
        """"""
        version = self._client.get(self.URI)
        return version","class Versions(object):
    '''
    Version API client. It indicates the range of API versions supported by the appliance.

    '''

    def __init__(self, con):
        pass

    def get_version(self):
    '''
        Returns the range of possible API versions supported by the appliance.
        The response contains the current version and the minimum version.
        The current version is the recommended version to specify in the REST header.
        The other versions are supported for backward compatibility, but might not support the most current features.

        Returns:
            dict: The minimum and maximum supported API versions.
        '''
        pass

",3,2,snippet_642,0.75,"class Versions(object):
    '''
    Version API client. It indicates the range of API versions supported by the appliance.

    '''

    def __init__(self, con):
        self._connection = con
        self._uri = '/rest/version'

    def get_version(self):
        '''
        Returns the range of possible API versions supported by the appliance.
        The response contains the current version and the minimum version.
        The current version is the recommended version to specify in the REST header.
        The other versions are supported for backward compatibility, but might not support the most current features.

        Returns:
            dict: The minimum and maximum supported API versions.
        '''
        return self._connection.get(self._uri)","class Versions(object):
    '''
    Version API client. It indicates the range of API versions supported by the appliance.

    '''

    def __init__(self, con):
        self._connection = con

    def get_version(self):
        '''
        Returns the range of possible API versions supported by the appliance.
        The response contains the current version and the minimum version.
        The current version is the recommended version to specify in the REST header.
        The other versions are supported for backward compatibility, but might not support the most current features.

        Returns:
            dict: The minimum and maximum supported API versions.
        '''
        response = self._connection.get('/api/versions')
        return response","class Versions(object):
    '''
    Version API client. It indicates the range of API versions supported by the appliance.

    '''

    def __init__(self, con):
        self.con = con

    def get_version(self):
        '''
        Returns the range of possible API versions supported by the appliance.
        The response contains the current version and the minimum version.
        The current version is the recommended version to specify in the REST header.
        The other versions are supported for backward compatibility, but might not support the most current features.

        Returns:
            dict: The minimum and maximum supported API versions.
        '''
        return self.con.get('/rest/version')",partial_docstr,0.9595959595959594,0.9081632653061226,0.8556701030927836,0.9292929292929293,0.776579783822455,0.9300699300699301,0.852112676056338,0.7943262411347518,0.9885687828063965,0.9789112210273743,0.9837163090705872,0.9798684120178223,0.8688537704918032,0.9081632653061223,0.8453608247422681,0.8229166666666666,0.9081632653061223,0.7342961062418218,0.927007299270073,0.8455882352941176,0.7851851851851852,0.9729337096214294,0.9569498300552368,0.9648756384849548,0.9585244655609131,0.9071047540983607,0.9381443298969072,0.8645833333333334,0.8315789473684211,0.9175257731958764,0.7256328486045119,0.9545454545454546,0.8702290076335878,0.8153846153846154,0.9785523414611816,0.9572224617004395,0.9677699208259583,0.9593135714530945,0.8797826229508197,0.7479351477762076,0.7880032123909394,0.7963299713064836,0.4074074074074074,0.0,0.594815145703312,0.7777324985828212,0.7867132694156115,0.3703703703703703,0.4444444444444444,0.528728812326362,0.7742503333272235,0.7851093604226694,0.3333333333333333,0.2222222222222222
634916,pdkit/pdkit,pdkit_pdkit/pdkit/qoi_processor.py,pdkit.qoi_processor.QoIProcessor,"class QoIProcessor(object):
    """"""
        Quality of Information processor based on a recurrent convolutional network.
        Supervised learning method that has been used to classify accelerometer signal (collected through the cloudUPDRS app) according to qulity.
        The method has been used in a binary fashion (good vs bad signals) but this can easily do multiclass classification.
        Initializing this processor will instantiate a model and the model uses the keras api: https://keras.io.

        :param input_shape: (optional) Shape of the input data, this has to be in 2d, without the minibatch size
        :type input_shape: tuple
        :param labels: (optional) Number of classes, this should be 1 for binary classification.
        :type labels: int
        :param output_activation: (optional) The activation function to use on the output data. For binary classification use 'sigmoid', for multiclass use 'softmax'
        :type output_activation: str


        :Examples:
         
        >>> import pdkit
        >>> qoi = pdkit.QoIProcessor()
        >>> qoi.model.fit(X, y)
    """"""
    def __init__(self,
                 input_shape=(150, 4),
                 labels=1,
                 output_activation='sigmoid'):
        
        self.model = RCL( input_shape=input_shape,
                          rec_conv_layers=[
                              [
                                  [(32, 9), (2, 1), 0.5, 0.5],
                                  [(32, 9), (2, 1), 0.5, 0.5],
                                  [(32, 9), (2, 1), 0.5, 0.5, 6]
                              ],
                              [
                                  [(64, 9), (2, 1), 0.5, 0.5],
                                  [(64, 9), (2, 1), 0.5, 0.5],
                                  [(64, 9), (2, 1), 0.5, 0.5, 6]
                              ]

                          ],
                          dense_layers=[(512, 0.0, 0.5),
                                        (512, 0.0, 0.5)],
                          padding='same',
                          optimizer=adam(lr=0.001),
                          output_layer=[labels, output_activation]
                       )
    
    def window_data(self, x, y=None, window_size=100, overlap=10):
        
        idx = window_features(np.arange(x.shape[0]), window_size, overlap)
        
        features = x[idx]
        if y:
            labels = [y] * idx.shape[0]
            return features, labels
        
        return features","class QoIProcessor(object):
    '''
        Quality of Information processor based on a recurrent convolutional network.
        Supervised learning method that has been used to classify accelerometer signal (collected through the cloudUPDRS app) according to qulity.
        The method has been used in a binary fashion (good vs bad signals) but this can easily do multiclass classification.
        Initializing this processor will instantiate a model and the model uses the keras api: https://keras.io.

        :param input_shape: (optional) Shape of the input data, this has to be in 2d, without the minibatch size
        :type input_shape: tuple
        :param labels: (optional) Number of classes, this should be 1 for binary classification.
        :type labels: int
        :param output_activation: (optional) The activation function to use on the output data. For binary classification use 'sigmoid', for multiclass use 'softmax'
        :type output_activation: str


        :Examples:
         
        >>> import pdkit
        >>> qoi = pdkit.QoIProcessor()
        >>> qoi.model.fit(X, y)
    '''

    def __init__(self,
                 input_shape=(150, 4),
                 labels=1,
                 output_activation='sigmoid'):
        pass

    def window_data(self, x, y=None, window_size=100, overlap=10):
        pass

",3,1,snippet_696,0.6,"class QoIProcessor(object):
    '''
        Quality of Information processor based on a recurrent convolutional network.
    '''
    def __init__(self,
                 input_shape=(150, 4),
                 labels=1,
                 output_activation='sigmoid'):
        self.input_shape = input_shape
        self.labels = labels
        self.output_activation = output_activation

        inp = Input(shape=self.input_shape)
        x = Conv1D(32, 3, padding='same')(inp)
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = MaxPooling1D(2)(x)

        x = Conv1D(64, 3, padding='same')(x)
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = MaxPooling1D(2)(x)

        x = LSTM(100, return_sequences=False)(x)
        x = Dropout(0.5)(x)

        x = Dense(50, activation='relu')(x)
        x = Dropout(0.5)(x)

        out = Dense(self.labels, activation=self.output_activation)(x)

        self.model = Model(inputs=inp, outputs=out)

        if self.labels == 1:
            loss = 'binary_crossentropy'
        else:
            loss = 'categorical_crossentropy'

        self.model.compile(optimizer=Adam(),
                           loss=loss,
                           metrics=['accuracy'])

    def window_data(self, x, y=None, window_size=100, overlap=10):
        '''
            Slide a window over data x (and optional labels y).
        '''
        def _single_window(x_arr, y_val):
            x_arr = np.asarray(x_arr)
            T = x_arr.shape[0]
            step = window_size - overlap
            if step <= 0:
                raise ValueError(""overlap must be less than window_size"")
            windows = []
            labels = []
            idx = 0
            while idx + window_size <= T:
                win = x_arr[idx:idx + window_size]
                windows.append(win)
                if y_val is not None:
                    if np.ndim(y_val) == 0:
                        labels.append(y_val)
                    else:
                        y_arr = np.asarray(y_val)
                        if y_arr.ndim == 1 and len(y_arr) == T:
                            labels.append(y_arr[idx + window_size - 1])
                        else:
                            raise ValueError(""y array length must match x length when 1D"")
                idx += step
            Xw = np.stack(windows) if windows else np.empty((0, window_size) + x_arr.shape[1:])
            if y_val is None:
                return Xw, None
            yw = np.array(labels)
            return Xw, yw

        # handle list/tuple of sequences
        if isinstance(x, (list, tuple)):
            X_list = []
            Y_list = []
            if y is not None:
                if not isinstance(y, (list, tuple)) or len(y) != len(x):
                    raise ValueError(""when x is list, y must be list of same length"")
            y_iter = y if y is not None else [None] * len(x)
            for xi, yi in zip(x, y_iter):
                Xw, yw = self.window_data(xi, yi, window_size, overlap)
                X_list.append(Xw)
                if yw is not None:
                    Y_list.append(yw)
            X_all = np.vstack(X_list) if X_list else np.empty((0, window_size) + np.asarray(x[0]).shape[1:])
            if y is None:
                return X_all
            Y_all = np.hstack(Y_list) if Y_list else np.empty((0,))
            return X_all, Y_all

        # single sequence
        Xw, yw = _single_window(x, y)
        if y is None:
            return Xw
        return Xw, yw","class QoIProcessor(object):
    '''
        Quality of Information processor based on a recurrent convolutional network.
        Supervised learning method that has been used to classify accelerometer signal (collected through the cloudUPDRS app) according to qulity.
        The method has been used in a binary fashion (good vs bad signals) but this can easily do multiclass classification.
        Initializing this processor will instantiate a model and the model uses the keras api: https://keras.io.

        :param input_shape: (optional) Shape of the input data, this has to be in 2d, without the minibatch size
        :type input_shape: tuple
        :param labels: (optional) Number of classes, this should be 1 for binary classification.
        :type labels: int
        :param output_activation: (optional) The activation function to use on the output data. For binary classification use 'sigmoid', for multiclass use 'softmax'
        :type output_activation: str


        :Examples:
         
        >>> import pdkit
        >>> qoi = pdkit.QoIProcessor()
        >>> qoi.model.fit(X, y)
    '''

    def __init__(self,
                 input_shape=(150, 4),
                 labels=1,
                 output_activation='sigmoid'):
        self.input_shape = input_shape
        self.labels = labels
        self.output_activation = output_activation
        
        # Build the model
        self.model = self._build_model()
    
    def _build_model(self):
        # Input layer
        inputs = keras.Input(shape=self.input_shape)
        
        # Convolutional layers
        conv1 = layers.Conv1D(32, 3, activation='relu', padding='same')(inputs)
        conv1 = layers.BatchNormalization()(conv1)
        conv1 = layers.Dropout(0.2)(conv1)
        
        conv2 = layers.Conv1D(64, 3, activation='relu', padding='same')(conv1)
        conv2 = layers.BatchNormalization()(conv2)
        conv2 = layers.Dropout(0.2)(conv2)
        
        conv3 = layers.Conv1D(128, 3, activation='relu', padding='same')(conv2)
        conv3 = layers.BatchNormalization()(conv3)
        conv3 = layers.Dropout(0.2)(conv3)
        
        # Recurrent layer
        lstm = layers.LSTM(64, return_sequences=False)(conv3)
        lstm = layers.Dropout(0.2)(lstm)
        
        # Dense layers
        dense1 = layers.Dense(32, activation='relu')(lstm)
        dense1 = layers.Dropout(0.2)(dense1)
        
        # Output layer
        outputs = layers.Dense(self.labels, activation=self.output_activation)(dense1)
        
        # Create model
        model = keras.Model(inputs=inputs, outputs=outputs)
        
        # Compile model
        if self.output_activation == 'sigmoid':
            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        else:
            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        
        return model

    def window_data(self, x, y=None, window_size=100, overlap=10):
        # Calculate step size
        step_size = window_size - overlap
        
        # Handle case where step_size is <= 0
        if step_size <= 0:
            step_size = 1
            
        # Calculate number of windows
        num_windows = max(0, (len(x) - window_size) // step_size + 1)
        
        if num_windows <= 0:
            # Return empty arrays with correct shape
            windowed_x = np.empty((0, window_size, x.shape[1])) if len(x.shape) > 1 else np.empty((0, window_size))
            if y is not None:
                windowed_y = np.empty((0,)) if len(y.shape) == 1 else np.empty((0, y.shape[1]))
                return windowed_x, windowed_y
            else:
                return windowed_x
        
        # Create windows for x
        windowed_x = []
        for i in range(num_windows):
            start_idx = i * step_size
            end_idx = start_idx + window_size
            if end_idx <= len(x):
                windowed_x.append(x[start_idx:end_idx])
        
        windowed_x = np.array(windowed_x)
        
        # If y is provided, create corresponding windows
        if y is not None:
            windowed_y = []
            for i in range(num_windows):
                start_idx = i * step_size
                end_idx = start_idx + window_size
                if end_idx <= len(x):
                    # For labels, take the label at the end of the window or majority vote
                    windowed_y.append(y[end_idx - 1] if end_idx - 1 < len(y) else y[-1])
            
            windowed_y = np.array(windowed_y)
            return windowed_x, windowed_y
        else:
            return windowed_x","class QoIProcessor(object):
    '''
        Quality of Information processor based on a recurrent convolutional network.
        Supervised learning method that has been used to classify accelerometer signal (collected through the cloudUPDRS app) according to qulity.
        The method has been used in a binary fashion (good vs bad signals) but this can easily do multiclass classification.
        Initializing this processor will instantiate a model and the model uses the keras api: https://keras.io.

        :param input_shape: (optional) Shape of the input data, this has to be in 2d, without the minibatch size
        :type input_shape: tuple
        :param labels: (optional) Number of classes, this should be 1 for binary classification.
        :type labels: int
        :param output_activation: (optional) The activation function to use on the output data. For binary classification use 'sigmoid', for multiclass use 'softmax'
        :type output_activation: str


        :Examples:
         
        >>> import pdkit
        >>> qoi = pdkit.QoIProcessor()
        >>> qoi.model.fit(X, y)
    '''

    def __init__(self,
                 input_shape=(150, 4),
                 labels=1,
                 output_activation='sigmoid'):
        self.input_shape = input_shape
        self.labels = labels
        self.output_activation = output_activation
        
        self.model = keras.Sequential([
            layers.Conv1D(32, 3, activation='relu', input_shape=input_shape),
            layers.Conv1D(64, 3, activation='relu'),
            layers.MaxPooling1D(2),
            layers.Conv1D(128, 3, activation='relu'),
            layers.MaxPooling1D(2),
            layers.LSTM(64, return_sequences=True),
            layers.LSTM(32),
            layers.Dropout(0.5),
            layers.Dense(64, activation='relu'),
            layers.Dense(labels, activation=output_activation)
        ])
        
        self.model.compile(
            optimizer='adam',
            loss='binary_crossentropy' if labels == 1 else 'categorical_crossentropy',
            metrics=['accuracy']
        )

    def window_data(self, x, y=None, window_size=100, overlap=10):
        step_size = window_size - overlap
        n_windows = (len(x) - window_size) // step_size + 1
        
        windowed_x = []
        for i in range(n_windows):
            start_idx = i * step_size
            end_idx = start_idx + window_size
            windowed_x.append(x[start_idx:end_idx])
        
        windowed_x = np.array(windowed_x)
        
        if y is not None:
            windowed_y = []
            for i in range(n_windows):
                start_idx = i * step_size
                end_idx = start_idx + window_size
                windowed_y.append(y[start_idx:end_idx])
            windowed_y = np.array(windowed_y)
            return windowed_x, windowed_y
        
        return windowed_x",partial_docstr,0.3324175824175824,0.162534435261708,0.09944751381215469,0.20054945054945053,0.1910426573836024,0.3613053613053613,0.16686114352392065,0.11565420560747663,0.777373731136322,0.7854330539703369,0.7813825607299805,0.7846196889877319,0.7116887068965521,0.553191489361702,0.43601895734597157,0.40380047505938244,0.4964539007092198,0.3259527287313257,0.40940254652301666,0.307843137254902,0.2747791952894995,0.8263986110687256,0.9256201982498169,0.8731998205184937,0.9146386384963989,0.7156133539412682,0.6837060702875399,0.5737179487179488,0.5434083601286174,0.6357827476038338,0.5275530793380163,0.6483870967741936,0.5088852988691438,0.4449838187702265,0.8653930425643921,0.9197246432304382,0.8917320370674133,0.9139863848686218,0.7536256521739133,0.2551370779377093,0.0656993934489047,0.106083486203167,0.4320987654320987,0.4166666666666667,0.4759840284386855,0.3300009940728309,0.652253020916479,0.4320987654320987,0.4895833333333333,0.5460403111247036,0.5682068605329705,0.6564636432251031,0.4074074074074074,0.5520833333333334
154318,Mindwerks/worldengine,Mindwerks_worldengine/worldengine/simulations/precipitation.py,worldengine.simulations.precipitation.PrecipitationSimulation,"class PrecipitationSimulation(object):

    @staticmethod
    def is_applicable(world):
        return not world.has_precipitations()

    def execute(self, world, seed):
        if get_verbose():
            start_time = time.time()
        pre_calculated = self._calculate(seed, world)
        ocean = world.layers['ocean'].data
        ths = [
            ('low', find_threshold_f(pre_calculated, 0.75, ocean)),
            ('med', find_threshold_f(pre_calculated, 0.3, ocean)),
            ('hig', None)
        ]
        world.precipitation = (pre_calculated, ths)
        if get_verbose():
            elapsed_time = time.time() - start_time
            print(
                ""...precipitations calculated. Elapsed time %f  seconds.""
                % elapsed_time)

    @staticmethod
    def _calculate(seed, world):
        """"""Precipitation is a value in [-1,1]""""""
        rng = numpy.random.RandomState(seed)  # create our own random generator
        base = rng.randint(0, 4096)

        curve_gamma = world.gamma_curve
        curve_bonus = world.curve_offset
        height = world.height
        width = world.width
        border = width / 4
        precipitations = numpy.zeros((height, width), dtype=float)

        octaves = 6
        freq = 64.0 * octaves

        n_scale = 1024 / float(height) #This is a variable I am adding. It exists
                                       #so that worlds sharing a common seed but
                                       #different sizes will have similar patterns

        for y in range(height):#TODO: numpy
            for x in range(width):
                n = snoise2((x * n_scale) / freq, (y * n_scale) / freq, octaves, base=base)

                # Added to allow noise pattern to wrap around right and left.
                if x < border:
                    n = (snoise2( (x * n_scale) / freq, (y * n_scale) / freq, octaves,
                                 base=base) * x / border) + (
                        snoise2(( (x * n_scale) + width) / freq, (y * n_scale) / freq, octaves,
                                base=base) * (border - x) / border)

                precipitations[y, x] = n

        #find ranges
        min_precip = precipitations.min()
        max_precip = precipitations.max()
        min_temp = world.layers['temperature'].min()
        max_temp = world.layers['temperature'].max()
        precip_delta = (max_precip - min_precip)
        temp_delta = (max_temp - min_temp)

        #normalize temperature and precipitation arrays
        t = (world.layers['temperature'].data - min_temp) / temp_delta
        p = (precipitations - min_precip) / precip_delta

        #modify precipitation based on temperature

        #--------------------------------------------------------------------------------
        #
        # Ok, some explanation here because why the formula is doing this may be a
        # little confusing. We are going to generate a modified gamma curve based on
        # normalized temperature and multiply our precipitation amounts by it.
        #
        # numpy.power(t,curve_gamma) generates a standard gamma curve. However
        # we probably don't want to be multiplying precipitation by 0 at the far
        # side of the curve. To avoid this we multiply the curve by (1 - curve_bonus)
        # and then add back curve_bonus. Thus, if we have a curve bonus of .2 then
        # the range of our modified gamma curve goes from 0-1 to 0-.8 after we
        # multiply and then to .2-1 after we add back the curve_bonus.
        #
        # Because we renormalize there is not much point to offsetting the opposite end
        # of the curve so it is less than or more than 1. We are trying to avoid
        # setting the start of the curve to 0 because f(t) * p would equal 0 when t equals
        # 0. However f(t) * p does not automatically equal 1 when t equals 1 and if we
        # raise or lower the value for f(t) at 1 it would have negligible impact after
        # renormalizing.
        #
        #--------------------------------------------------------------------------------

        curve = (numpy.power(t, curve_gamma) * (1-curve_bonus)) + curve_bonus
        precipitations = numpy.multiply(p, curve)

        # Renormalize precipitation because the precipitation
        # changes will probably not fully extend from -1 to 1.
        min_precip = precipitations.min()
        max_precip = precipitations.max()
        precip_delta = (max_precip - min_precip)
        precipitations = (((precipitations - min_precip) / precip_delta) * 2) - 1
        
        return precipitations","class PrecipitationSimulation(object):


    @staticmethod
    def is_applicable(world):
        pass

    def execute(self, world, seed):
        pass

    @staticmethod
    def _calculate(seed, world):
    '''Precipitation is a value in [-1,1]'''
        pass

",6,1,snippet_724,0.2307692307692307,"class PrecipitationSimulation(object):

    @staticmethod
    def is_applicable(world):
        return hasattr(world, 'width') and hasattr(world, 'height') and world.width > 0 and world.height > 0

    def execute(self, world, seed):
        world.precipitation = self._calculate(seed, world)

    @staticmethod
    def _calculate(seed, world):
        """"""Precipitation is a value in [-1,1]""""""
        rng = random.Random(seed)
        precip = []
        for y in range(world.height):
            row = []
            for x in range(world.width):
                row.append(rng.uniform(-1.0, 1.0))
            precip.append(row)
        return precip","class PrecipitationSimulation(object):

    @staticmethod
    def is_applicable(world):
        return hasattr(world, 'heightmap') and hasattr(world, 'precipitation')

    def execute(self, world, seed):
        if not self.is_applicable(world):
            return False
        
        precipitation_map = self._calculate(seed, world)
        world.precipitation = precipitation_map
        return True

    @staticmethod
    def _calculate(seed, world):
        '''Precipitation is a value in [-1,1]'''
        random.seed(seed)
        heightmap = world.heightmap
        rows, cols = len(heightmap), len(heightmap[0])
        precipitation = [[0.0 for _ in range(cols)] for _ in range(rows)]
        
        # Generate base precipitation with some noise
        for i in range(rows):
            for j in range(cols):
                # Base value with some randomness
                base_precip = random.uniform(-0.5, 0.5)
                
                # Modify based on height (higher elevations might get more/less precip)
                height_factor = heightmap[i][j]
                elevation_effect = -0.3 * height_factor  # Higher = drier
                
                # Add some spatial correlation
                if i > 0 and j > 0:
                    neighbor_influence = 0.2 * (precipitation[i-1][j] + precipitation[i][j-1]) / 2
                else:
                    neighbor_influence = 0
                
                precip_value = base_precip + elevation_effect + neighbor_influence
                
                # Clamp to [-1, 1]
                precipitation[i][j] = max(-1.0, min(1.0, precip_value))
        
        return precipitation","class PrecipitationSimulation(object):

    @staticmethod
    def is_applicable(world):
        return hasattr(world, 'temperature') and hasattr(world, 'humidity') and hasattr(world, 'elevation')

    def execute(self, world, seed):
        precipitation = self._calculate(seed, world)
        world.precipitation = precipitation
        return world

    @staticmethod
    def _calculate(seed, world):
        '''Precipitation is a value in [-1,1]'''
        random.seed(seed)
        
        # Base precipitation from humidity
        base_precipitation = (world.humidity - 0.5) * 2
        
        # Temperature effect (moderate temperatures favor precipitation)
        temp_factor = 1 - abs(world.temperature - 0.5) * 2
        
        # Elevation effect (higher elevation can increase precipitation)
        elevation_factor = 1 + (world.elevation * 0.3)
        
        # Random variation
        noise = random.uniform(-0.2, 0.2)
        
        # Calculate final precipitation
        precipitation = base_precipitation * temp_factor * elevation_factor + noise
        
        # Clamp to [-1, 1]
        precipitation = max(-1, min(1, precipitation))
        
        return precipitation",partial_docstr,0.22012578616352196,0.11671924290220818,0.08544303797468354,0.16037735849056603,0.0025591077893365732,0.8986486486486487,0.6326530612244898,0.4931506849315068,0.8874404430389404,0.6676137447357178,0.761989414691925,0.6845711469650269,0.7166695000000012,0.28918918918918923,0.08943089430894309,0.0625,0.1864864864864865,0.04162689051962859,0.6867088607594937,0.27936507936507937,0.17834394904458598,0.827404260635376,0.7236504554748535,0.7720572352409363,0.7328400611877441,0.7391051730769229,0.2352941176470588,0.09144542772861355,0.06508875739644969,0.16764705882352945,0.01235040567863903,0.7746478873239436,0.37264150943396224,0.26540284360189575,0.8348978161811829,0.6993575096130371,0.7611407041549683,0.7108984589576721,0.7301309038461539,0.0926972020304952,0.0001181032521576,0.0499014741005923,0.1807692307692307,0.14,0.1347528017786848,0.0095858098120349,0.0382715511488584,0.2961538461538461,0.195,0.1107487158026878,0.0033461833582413,0.0323409875448177,0.2423076923076923,0.165
364510,elliterate/capybara.py,elliterate_capybara.py/capybara/queries/base_query.py,capybara.queries.base_query.BaseQuery,"class BaseQuery(object):
    @staticmethod
    def normalize_wait(wait):
        """"""
        Returns the number of seconds to wait.

        Args:
            wait (int | float | bool, optional): The desired wait time in seconds, or ``False`` to
                disable waiting. Defaults to :data:`capybara.default_max_wait_time`.

        Returns:
            int: The number of seconds to wait.
        """"""

        if wait is not None:
            return wait or 0
        else:
            return capybara.default_max_wait_time","class BaseQuery(object):


    @staticmethod
    def normalize_wait(wait):
    '''
        Returns the number of seconds to wait.

        Args:
            wait (int | float | bool, optional): The desired wait time in seconds, or ``False`` to
                disable waiting. Defaults to :data:`capybara.default_max_wait_time`.

        Returns:
            int: The number of seconds to wait.
        '''
        pass

",3,1,snippet_87,1.0,"class BaseQuery(object):

    @staticmethod
    def normalize_wait(wait):
        """"""
        Returns the number of seconds to wait.

        Args:
            wait (int | float | bool, optional): The desired wait time in seconds, or ``False`` to
                disable waiting. Defaults to :data:`capybara.default_max_wait_time`.

        Returns:
            int: The number of seconds to wait.
        """"""
        if wait is False:
            return 0

        if wait is None or wait is True:
            return default_max_wait_time

        if not isinstance(wait, (int, float)):
            raise TypeError(""wait must be an int, float, bool or None"")

        if wait < 0:
            raise ValueError(""wait time must be non-negative"")

        return int(wait)","class BaseQuery(object):
    @staticmethod
    def normalize_wait(wait):
        '''
        Returns the number of seconds to wait.

        Args:
            wait (int | float | bool, optional): The desired wait time in seconds, or ``False`` to
                disable waiting. Defaults to :data:`capybara.default_max_wait_time`.

        Returns:
            int: The number of seconds to wait.
        '''
        import capybara
        if wait is False:
            return 0
        elif wait is True:
            return int(capybara.default_max_wait_time)
        elif wait is None:
            return int(capybara.default_max_wait_time)
        else:
            return int(wait)","class BaseQuery(object):

    @staticmethod
    def normalize_wait(wait):
        '''
        Returns the number of seconds to wait.

        Args:
            wait (int | float | bool, optional): The desired wait time in seconds, or ``False`` to
                disable waiting. Defaults to :data:`capybara.default_max_wait_time`.

        Returns:
            int: The number of seconds to wait.
        '''
        if wait is False:
            return 0
        elif wait is None:
            import capybara
            return capybara.default_max_wait_time
        else:
            return int(wait)",partial_docstr,0.7654320987654322,0.6625,0.6455696202531646,0.7283950617283952,0.6167067417909877,0.6585365853658537,0.6073619631901841,0.5864197530864198,0.8849921226501465,0.9637902975082397,0.922711968421936,0.9552846550941467,0.780824109589041,0.8493150684931506,0.7638888888888891,0.7042253521126761,0.8082191780821918,0.7021865893493452,0.7518248175182481,0.6985294117647058,0.6592592592592592,0.9407157897949219,0.9714322090148926,0.9558272957801819,0.9682706594467163,0.8388905,0.9253731343283582,0.8484848484848485,0.8153846153846154,0.880597014925373,0.8333215145136352,0.8879310344827587,0.8347826086956521,0.7807017543859649,0.9670930504798889,0.977554976940155,0.972295880317688,0.9764986634254456,0.8962973333333333,0.658940434622061,0.5482715919115835,0.8652679243544381,0.2222222222222222,1.0,0.671076127070097,0.6433087712649397,0.7632179592376706,0.2777777777777778,1.0,0.7026220701031178,0.7116484525365319,0.7655064945426059,0.3333333333333333,1.0
743899,smarie/python-valid8,smarie_python-valid8/valid8/base.py,valid8.base.HelpMsgMixIn,"class HelpMsgMixIn(object):
    """""" A helper class providing the ability to store a help message in the class or in the instance, and to get a
    formatted help message """"""

    __max_str_length_displayed__ = 100
    """""" objects with a string representation larger than this constant will not be printed in the error messages. 
    Note that you can override this either on the class or on a particular instance. See `get_variable_str()` """"""

    help_msg = ''
    """""" This class attribute holds the default help message used when no `help_msg` attribute is set at instance level 
    (for example through the constructor). Subclasses may wish to override this class attribute, or to define a 
    different behaviour by overriding `get_help_msg` """"""

    def get_help_msg(self):
        # type: (...) -> str
        """"""
        The method used to get the formatted help message according to kwargs. By default it returns the 'help_msg'
        attribute, whether it is defined at the instance level or at the class level.

        The help message is formatted according to help_msg.format(**context),
        where `context = self.get_context_for_help_msgs()` so that subclasses may easily override the behaviour.

        :return: the formatted help message
        """"""
        if self.help_msg is None or len(self.help_msg) == 0:
            return ''
        else:
            # grab the help msg and context info
            help_msg = self.help_msg
            context = self.get_context_for_help_msgs()

            # first format if needed
            try:
                is_context_a_copy = False
                # note: use question mark so as to be non-greedy
                variables = re.findall(""{\\S+?}"", help_msg)
                for var_name_ in set(variables):
                    # extract the variable name
                    var_name_ = var_name_[1:-1]

                    # if variable is used in the context
                    if var_name_ in context:
                        # if the variable string representation is too big, replace its use in the help message
                        # (so as to keep the original object available for debug)
                        var_to_str = str(context[var_name_])
                        if len(var_to_str) > self.__max_str_length_displayed__:
                            if not is_context_a_copy:
                                # create a copy because we will modify it
                                context = copy(context)
                                is_context_a_copy = True

                            new_name = '@@@@' + var_name_ + '@@@@'
                            help_msg = help_msg.replace('{' + var_name_ + '}', '{' + new_name + '}')
                            context[new_name] = ""(too big for display)""
                    else:
                        # anticipate the formatting issue
                        raise HelpMsgFormattingException(self.help_msg, context=context, varname=var_name_)

                # finally format the help message
                help_msg = help_msg.format(**context)

            except KeyError as e:
                # no need to raise from e, __cause__ is set in the constructor
                raise HelpMsgFormattingException(self.help_msg, context=context, caught=e)

            return help_msg

    def get_context_for_help_msgs(self):
        """""" Subclasses may wish to override this method to change the dictionary of contextual information before it is
        sent to the help message formatter """"""
        return self.__dict__","class HelpMsgMixIn(object):
    ''' A helper class providing the ability to store a help message in the class or in the instance, and to get a
    formatted help message '''

    def get_help_msg(self):
    '''
        The method used to get the formatted help message according to kwargs. By default it returns the 'help_msg'
        attribute, whether it is defined at the instance level or at the class level.

        The help message is formatted according to help_msg.format(**context),
        where `context = self.get_context_for_help_msgs()` so that subclasses may easily override the behaviour.

        :return: the formatted help message
        '''
        pass

    def get_context_for_help_msgs(self):
    ''' Subclasses may wish to override this method to change the dictionary of contextual information before it is
        sent to the help message formatter '''
        pass

",3,3,snippet_782,0.2941176470588235,"class HelpMsgMixIn(object):
    ''' A helper class providing the ability to store a help message in the class or in the instance,
        and to get a formatted help message '''

    def get_help_msg(self):
        '''
        The method used to get the formatted help message according to kwargs. By default it returns the
        'help_msg' attribute, whether it is defined at the instance level or at the class level.

        The help message is formatted according to help_msg.format(**context),
        where `context = self.get_context_for_help_msgs()` so that subclasses may easily override the behaviour.

        :return: the formatted help message
        '''
        if not hasattr(self, 'help_msg'):
            raise AttributeError(""No 'help_msg' attribute found on %r"" % self)
        help_msg = getattr(self, 'help_msg')
        context = self.get_context_for_help_msgs() or {}
        return help_msg.format(**context)

    def get_context_for_help_msgs(self):
        ''' Subclasses may wish to override this method to change the dictionary of contextual information
            before it is sent to the help message formatter '''
        return {}","class HelpMsgMixIn(object):
    ''' A helper class providing the ability to store a help message in the class or in the instance, and to get a
    formatted help message '''

    def get_help_msg(self):
        '''
        The method used to get the formatted help message according to kwargs. By default it returns the 'help_msg'
        attribute, whether it is defined at the instance level or at the class level.

        The help message is formatted according to help_msg.format(**context),
        where `context = self.get_context_for_help_msgs()` so that subclasses may easily override the behaviour.

        :return: the formatted help message
        '''
        help_msg = getattr(self, 'help_msg', '')
        context = self.get_context_for_help_msgs()
        return help_msg.format(**context)

    def get_context_for_help_msgs(self):
        ''' Subclasses may wish to override this method to change the dictionary of contextual information before it is
        sent to the help message formatter '''
        return {}","class HelpMsgMixIn(object):
    ''' A helper class providing the ability to store a help message in the class or in the instance, and to get a
    formatted help message '''

    def get_help_msg(self):
        '''
        The method used to get the formatted help message according to kwargs. By default it returns the 'help_msg'
        attribute, whether it is defined at the instance level or at the class level.

        The help message is formatted according to help_msg.format(**context),
        where `context = self.get_context_for_help_msgs()` so that subclasses may easily override the behaviour.

        :return: the formatted help message
        '''
        help_msg = getattr(self, 'help_msg', '')
        context = self.get_context_for_help_msgs()
        return help_msg.format(**context)

    def get_context_for_help_msgs(self):
        ''' Subclasses may wish to override this method to change the dictionary of contextual information before it is
        sent to the help message formatter '''
        return {}",partial_docstr,0.5230263157894737,0.4851485148514852,0.45364238410596025,0.49671052631578944,0.10502194547064735,0.9190283400809717,0.7967479674796748,0.7387755102040816,0.9139882326126099,0.7955837249755859,0.8506855964660645,0.8060255646705627,0.74368487364621,0.494077834179357,0.4753820033955857,0.45655877342419077,0.49069373942470396,0.07680892534286654,0.9587155963302753,0.8894009216589862,0.8425925925925926,0.9204389452934265,0.7887991070747375,0.8495498299598694,0.8002440333366394,0.7364647292418781,0.494077834179357,0.4753820033955857,0.45655877342419077,0.49069373942470396,0.07680892534286654,0.9587155963302753,0.8894009216589862,0.8425925925925926,0.9204389452934265,0.7887991070747375,0.8495498299598694,0.8002440333366394,0.7364647292418781,0.1792890032493372,0.1261626550843456,0.2706421857826213,0.2480620155038759,0.072289156626506,0.1731257389222001,0.1019362259713769,0.2624636196025453,0.2558139534883721,0.072289156626506,0.1731257389222001,0.1019362259713769,0.2624636196025453,0.2558139534883721,0.072289156626506
182017,Rockhopper-Technologies/pluginlib,Rockhopper-Technologies_pluginlib/pluginlib/_objects.py,pluginlib._objects.BlacklistEntry,"class BlacklistEntry(object):
    """"""
    Args:
        plugin_type(str): Parent type
        name(str): Plugin name
        version(str): Plugin version
        operator(str): Comparison operator ('=', '==', '!=', '<', '<=', '>', '>=')

    **Container for blacklist entry**

    If ``operator`` is :py:data:`None` or not specified, it defaults to '=='.

    One of ``plugin_type``, ``name``, or ``version`` must be specified.
    If any are unspecified or :py:data:`None`, they are treated as a wildcard.

    In order to be more compatible with parsed text,
    the order of ``operator`` and ``version`` can be swapped. The following are equivalent:

    .. code-block:: python

        BlacklistEntry('parser', 'json', '1.0', '>=')

    .. code-block:: python

            BlacklistEntry('parser', 'json', '>=', '1.0')

    ``version`` is evaluated using :py:func:`pkg_resources.parse_version`
    and should conform to `PEP 440`_

    .. _PEP 440: https://www.python.org/dev/peps/pep-0440/
    """"""

    __slots__ = ('type', 'name', 'version', 'operator')

    def __init__(self, plugin_type=None, name=None, version=None, operator=None):

        if plugin_type is name is version is None:
            raise AttributeError('plugin_type, name, or version must be specified')

        self.type = plugin_type
        self.name = name
        if version in OPERATORS:

            self.operator = version
            self.version = operator

            if self.version is None:
                raise AttributeError('version must be specifed when operator is specified')

        else:
            self.version = version
            self.operator = operator

        if self.version is not None and not isinstance(self.version, BASESTRING):
            raise TypeError('version must be a string, received %s' % type(self.version).__name__)

        if self.operator is None:
            self.operator = '=='
        elif self.operator not in OPERATORS:
            raise AttributeError(""Unsupported operator '%s'"" % self.operator)

    def __repr__(self):

        attrs = (self.type, self.name, self.operator, self.version)
        return '%s(%s)' % (self.__class__.__name__, ', '.join([repr(attr) for attr in attrs]))","class BlacklistEntry(object):
    '''
    Args:
        plugin_type(str): Parent type
        name(str): Plugin name
        version(str): Plugin version
        operator(str): Comparison operator ('=', '==', '!=', '<', '<=', '>', '>=')

    **Container for blacklist entry**

    If ``operator`` is :py:data:`None` or not specified, it defaults to '=='.

    One of ``plugin_type``, ``name``, or ``version`` must be specified.
    If any are unspecified or :py:data:`None`, they are treated as a wildcard.

    In order to be more compatible with parsed text,
    the order of ``operator`` and ``version`` can be swapped. The following are equivalent:

    .. code-block:: python

        BlacklistEntry('parser', 'json', '1.0', '>=')

    .. code-block:: python

            BlacklistEntry('parser', 'json', '>=', '1.0')

    ``version`` is evaluated using :py:func:`pkg_resources.parse_version`
    and should conform to `PEP 440`_

    .. _PEP 440: https://www.python.org/dev/peps/pep-0440/
    '''

    def __init__(self, plugin_type=None, name=None, version=None, operator=None):
        pass

    def __repr__(self):
        pass

",3,1,snippet_616,0.3478260869565217,"class BlacklistEntry(object):
    '''
    Args:
        plugin_type(str): Parent type
        name(str): Plugin name
        version(str): Plugin version
        operator(str): Comparison operator ('=', '==', '!=', '<', '<=', '>', '>=')

    **Container for blacklist entry**
    '''
    _VALID_OPERATORS = {'=', '==', '!=', '<', '<=', '>', '>='}

    def __init__(self, plugin_type=None, name=None, version=None, operator=None):
        # allow swapping operator and version
        if version in self._VALID_OPERATORS and (operator is None or operator not in self._VALID_OPERATORS):
            version, operator = operator, version

        if operator is None:
            operator = '=='
        if operator not in self._VALID_OPERATORS:
            raise ValueError(""Invalid operator: %r"" % operator)

        if plugin_type is None and name is None and version is None:
            raise ValueError(""At least one of plugin_type, name, or version must be specified"")

        self.plugin_type = plugin_type
        self.name = name
        self.operator = operator
        self.version = parse_version(version) if version is not None else None

    def __repr__(self):
        return (
            ""BlacklistEntry(plugin_type=%r, name=%r, ""
            ""operator=%r, version=%r)""
            % (self.plugin_type, self.name, self.operator, self.version)
        )","class BlacklistEntry(object):
    '''
    Args:
        plugin_type(str): Parent type
        name(str): Plugin name
        version(str): Plugin version
        operator(str): Comparison operator ('=', '==', '!=', '<', '<=', '>', '>=')

    **Container for blacklist entry**

    If ``operator`` is :py:data:`None` or not specified, it defaults to '=='.

    One of ``plugin_type``, ``name``, or ``version`` must be specified.
    If any are unspecified or :py:data:`None`, they are treated as a wildcard.

    In order to be more compatible with parsed text,
    the order of ``operator`` and ``version`` can be swapped. The following are equivalent:

    .. code-block:: python

        BlacklistEntry('parser', 'json', '1.0', '>=')

    .. code-block:: python

            BlacklistEntry('parser', 'json', '>=', '1.0')

    ``version`` is evaluated using :py:func:`pkg_resources.parse_version`
    and should conform to `PEP 440`_

    .. _PEP 440: https://www.python.org/dev/peps/pep-0440/
    '''

    def __init__(self, plugin_type=None, name=None, version=None, operator=None):
        # Check that at least one of plugin_type, name, or version is specified
        if plugin_type is None and name is None and version is None:
            raise ValueError(""One of plugin_type, name, or version must be specified"")
        
        # Handle swapped version and operator
        valid_operators = {'=', '==', '!=', '<', '<=', '>', '>='}
        if version in valid_operators and operator not in valid_operators:
            # version contains operator, operator contains version
            version, operator = operator, version
        
        # Set default operator if None or not specified
        if operator is None:
            operator = '=='
        
        # Validate operator
        if operator not in valid_operators:
            raise ValueError(f""Invalid operator: {operator}"")
        
        self.plugin_type = plugin_type
        self.name = name
        self.version = version
        self.operator = operator
        
        # Parse version if it's specified
        if self.version is not None:
            self.parsed_version = pkg_resources.parse_version(self.version)
        else:
            self.parsed_version = None

    def __repr__(self):
        return f""BlacklistEntry(plugin_type={self.plugin_type!r}, name={self.name!r}, version={self.version!r}, operator={self.operator!r})""","class BlacklistEntry(object):
    '''
    Args:
        plugin_type(str): Parent type
        name(str): Plugin name
        version(str): Plugin version
        operator(str): Comparison operator ('=', '==', '!=', '<', '<=', '>', '>=')

    **Container for blacklist entry**

    If ``operator`` is :py:data:`None` or not specified, it defaults to '=='.

    One of ``plugin_type``, ``name``, or ``version`` must be specified.
    If any are unspecified or :py:data:`None`, they are treated as a wildcard.

    In order to be more compatible with parsed text,
    the order of ``operator`` and ``version`` can be swapped. The following are equivalent:

    .. code-block:: python

        BlacklistEntry('parser', 'json', '1.0', '>=')

    .. code-block:: python

            BlacklistEntry('parser', 'json', '>=', '1.0')

    ``version`` is evaluated using :py:func:`pkg_resources.parse_version`
    and should conform to `PEP 440`_

    .. _PEP 440: https://www.python.org/dev/peps/pep-0440/
    '''

    def __init__(self, plugin_type=None, name=None, version=None, operator=None):
        operators = {'=', '==', '!=', '<', '<=', '>', '>='}
        
        # Handle swapped operator and version
        if version in operators and operator not in operators:
            version, operator = operator, version
        
        self.plugin_type = plugin_type
        self.name = name
        self.version = version
        self.operator = operator if operator is not None else '=='

    def __repr__(self):
        return f""BlacklistEntry(plugin_type={self.plugin_type!r}, name={self.name!r}, version={self.version!r}, operator={self.operator!r})""",partial_docstr,0.6291079812206573,0.4339622641509434,0.3033175355450237,0.41784037558685444,0.35954544828276014,0.8873239436619719,0.6299435028248588,0.49291784702549574,0.8868651986122131,0.785539984703064,0.8331331014633179,0.7946186661720276,0.787116974789916,0.8156028368794326,0.6832740213523131,0.5714285714285714,0.6985815602836879,0.6852945127032963,0.79,0.671118530884808,0.6070234113712375,0.9222502708435059,0.9152611494064331,0.9187424182891846,0.9159551858901978,0.7549044117647062,0.8042553191489361,0.717948717948718,0.6437768240343347,0.7106382978723403,0.6380771591653648,0.8869565217391304,0.7930283224400871,0.7336244541484717,0.9582087993621826,0.8896545171737671,0.9226600527763367,0.896065354347229,0.7619071428571433,0.4859358133533292,0.1921717522140105,0.2343301218889616,0.5172413793103449,0.0,0.6767136040579654,0.5489543585666435,0.614796609389356,0.5431034482758621,0.0,0.6290709768147837,0.5290173642957571,0.5476113705495845,0.4396551724137931,0.0
789024,tensorpack/tensorpack,tensorpack_tensorpack/tensorpack/dataflow/imgaug/deform.py,tensorpack.dataflow.imgaug.deform.GaussianMap,"class GaussianMap(object):
    """""" Generate Gaussian weighted deformation map""""""
    # TODO really needs speedup

    def __init__(self, image_shape, sigma=0.5):
        assert len(image_shape) == 2
        self.shape = image_shape
        self.sigma = sigma

    def get_gaussian_weight(self, anchor):
        """"""
        Args:
            anchor: coordinate of the center
        """"""
        ret = np.zeros(self.shape, dtype='float32')

        y, x = np.mgrid[:self.shape[0], :self.shape[1]]
        y = y.astype('float32') / ret.shape[0] - anchor[0]
        x = x.astype('float32') / ret.shape[1] - anchor[1]
        g = np.exp(-(x**2 + y ** 2) / self.sigma)
        # cv2.imshow("" "", g)
        # cv2.waitKey()
        return g","class GaussianMap(object):
    ''' Generate Gaussian weighted deformation map'''

    def __init__(self, image_shape, sigma=0.5):
        pass

    def get_gaussian_weight(self, anchor):
    '''
        Args:
            anchor: coordinate of the center
        '''
        pass

",3,2,snippet_622,1.0,"class GaussianMap(object):
    ''' Generate Gaussian weighted deformation map'''

    def __init__(self, image_shape, sigma=0.5):
        self.image_shape = image_shape
        self.sigma = sigma
        h, w = image_shape[:2]
        ys = np.arange(h).reshape(h, 1)
        xs = np.arange(w).reshape(1, w)
        self.ys = np.tile(ys, (1, w))
        self.xs = np.tile(xs, (h, 1))

    def get_gaussian_weight(self, anchor):
        '''
        Args:
            anchor: coordinate of the center (row, col)
        '''
        y0, x0 = anchor
        dy2 = (self.ys - y0) ** 2
        dx2 = (self.xs - x0) ** 2
        exponent = -(dx2 + dy2) / (2 * (self.sigma ** 2))
        return np.exp(exponent)","class GaussianMap(object):
    ''' Generate Gaussian weighted deformation map'''

    def __init__(self, image_shape, sigma=0.5):
        self.image_shape = image_shape
        self.sigma = sigma
        self.sigma_squared = sigma * sigma

    def get_gaussian_weight(self, anchor):
        '''
        Args:
            anchor: coordinate of the center
        '''
        # Create coordinate grids
        coords = np.ogrid[0:self.image_shape[0], 0:self.image_shape[1]]
        y_coords, x_coords = coords[0], coords[1]
        
        # Calculate squared distances from anchor point
        dy = y_coords - anchor[0]
        dx = x_coords - anchor[1]
        distance_squared = dy**2 + dx**2
        
        # Calculate Gaussian weights
        weights = np.exp(-distance_squared / (2 * self.sigma_squared))
        
        return weights","class GaussianMap(object):
    ''' Generate Gaussian weighted deformation map'''

    def __init__(self, image_shape, sigma=0.5):
        self.image_shape = image_shape
        self.sigma = sigma
        self.height, self.width = image_shape[:2]
        
        # Create coordinate grids
        y_coords, x_coords = np.meshgrid(np.arange(self.height), np.arange(self.width), indexing='ij')
        self.coords = np.stack([y_coords, x_coords], axis=-1)

    def get_gaussian_weight(self, anchor):
        '''
        Args:
            anchor: coordinate of the center
        '''
        anchor = np.array(anchor)
        
        # Calculate squared distances from anchor point
        distances_sq = np.sum((self.coords - anchor) ** 2, axis=-1)
        
        # Calculate Gaussian weights
        weights = np.exp(-distances_sq / (2 * self.sigma ** 2))
        
        return weights",partial_docstr,0.5684210526315789,0.3723404255319149,0.3010752688172043,0.4421052631578947,0.41518316500228786,0.6584158415841584,0.40298507462686567,0.295,0.8577567338943481,0.8314778804779053,0.8444129228591919,0.8340330123901367,0.7607385889570555,0.6326530612244898,0.4226804123711341,0.3125,0.5612244897959184,0.4822986258893244,0.7120418848167539,0.5263157894736842,0.3915343915343915,0.8682425022125244,0.8516359925270081,0.8598591089248657,0.8532679677009583,0.8375543670886075,0.5771144278606966,0.3517587939698492,0.28426395939086296,0.4577114427860696,0.4256292117436312,0.6666666666666666,0.4077669902912621,0.28780487804878047,0.8384958505630493,0.82536780834198,0.8318800926208496,0.8266621232032776,0.791141329113924,0.2886849013995781,0.1851609969918554,0.2067715910625973,0.3066666666666666,0.4561403508771929,0.3521093392093816,0.2122390645822483,0.229882502781594,0.44,0.5263157894736842,0.3027127443155079,0.1921495616380306,0.2067715910625973,0.3733333333333333,0.4385964912280701
818187,vbwagner/ctypescrypto,vbwagner_ctypescrypto/ctypescrypto/x509.py,ctypescrypto.x509._X509extlist,"class _X509extlist(object):
    """"""
    Represents list of certificate extensions. Really it keeps
    reference to certificate object
    """"""
    def __init__(self, cert):
        """"""
        Initialize from X509 object
        """"""
        self.cert = cert

    def __len__(self):
        """"""
        Returns number of extensions
        """"""
        return libcrypto.X509_get_ext_count(self.cert.cert)

    def __getitem__(self, item):
        """"""
        Returns extension by index, creating a copy
        """"""
        ext_ptr = libcrypto.X509_get_ext(self.cert.cert, item)
        if ext_ptr is None:
            raise IndexError
        return X509_EXT(ext_ptr, True)
    def find(self, oid):
        """"""
        Return list of extensions with given Oid
        """"""
        if not isinstance(oid, Oid):
            raise TypeError(""Need crytypescrypto.oid.Oid as argument"")
        found = []
        index = -1
        end = len(self)
        while True:
            index = libcrypto.X509_get_ext_by_NID(self.cert.cert, oid.nid,
                                                  index)
            if index >= end or index < 0:
                break
            found.append(self[index])
        return found

    def find_critical(self, crit=True):
        """"""
        Return list of critical extensions (or list of non-cricital, if
        optional second argument is False
        """"""
        if crit:
            flag = 1
        else:
            flag = 0
        found = []
        end = len(self)
        index = -1
        while True:
            index = libcrypto.X509_get_ext_by_critical(self.cert.cert, flag,
                                                       index)
            if index >= end or index < 0:
                break
            found.append(self[index])
        return found","class _X509extlist(object):
    '''
    Represents list of certificate extensions. Really it keeps
    reference to certificate object
    '''

    def __init__(self, cert):
    '''
        Initialize from X509 object
        '''
        pass

    def __len__(self):
    '''
        Returns number of extensions
        '''
        pass

    def __getitem__(self, item):
    '''
        Returns extension by index, creating a copy
        '''
        pass

    def find(self, oid):
    '''
        Return list of extensions with given Oid
        '''
        pass

    def find_critical(self, crit=True):
    '''
        Return list of critical extensions (or list of non-cricital, if
        optional second argument is False
        '''
        pass

",6,6,snippet_636,0.3333333333333333,"class _X509extlist(object):
    '''
    Represents list of certificate extensions. Really it keeps
    reference to certificate object
    '''

    def __init__(self, cert):
        '''
        Initialize from X509 object
        '''
        self._cert = cert

    def __len__(self):
        '''
        Returns number of extensions
        '''
        if hasattr(self._cert, 'get_extension_count'):
            return self._cert.get_extension_count()
        # fallback if get_extensions() is provided
        exts = getattr(self._cert, 'get_extensions', None)
        if exts:
            return len(self._cert.get_extensions())
        raise AttributeError(""Certificate object has no extensions interface"")

    def __getitem__(self, item):
        '''
        Returns extension by index, creating a copy
        '''
        n = len(self)
        if isinstance(item, slice):
            start, stop, step = item.indices(n)
            return [self[i] for i in range(start, stop, step)]
        # handle negative indices
        if item < 0:
            item = n + item
        if item < 0 or item >= n:
            raise IndexError(""Extension index out of range"")
        if hasattr(self._cert, 'get_extension'):
            ext = self._cert.get_extension(item)
        else:
            exts = self._cert.get_extensions()
            ext = exts[item]
        return copy.copy(ext)

    def find(self, oid):
        '''
        Return list of extensions with given Oid
        '''
        matches = []
        for i in range(len(self)):
            ext = self._cert.get_extension(i) if hasattr(self._cert, 'get_extension') else self._cert.get_extensions()[i]
            obj = ext.get_object()
            short = obj.get_short_name()
            longn = obj.get_long_name()
            if oid == short or oid == longn or (isinstance(oid, str) and (oid == short.decode() or oid == longn.decode())):
                matches.append(copy.copy(ext))
        return matches

    def find_critical(self, crit=True):
        '''
        Return list of critical extensions (or list of non-cricital, if
        optional second argument is False
        '''
        matches = []
        for i in range(len(self)):
            ext = self._cert.get_extension(i) if hasattr(self._cert, 'get_extension') else self._cert.get_extensions()[i]
            if ext.get_critical() == bool(crit):
                matches.append(copy.copy(ext))
        return matches","class _X509extlist(object):
    '''
    Represents list of certificate extensions. Really it keeps
    reference to certificate object
    '''

    def __init__(self, cert):
        '''
        Initialize from X509 object
        '''
        self._cert = cert

    def __len__(self):
        '''
        Returns number of extensions
        '''
        return self._cert.get_extension_count()

    def __getitem__(self, item):
        '''
        Returns extension by index, creating a copy
        '''
        if item < 0 or item >= len(self):
            raise IndexError(""extension index out of range"")
        return self._cert.get_extension(item)

    def find(self, oid):
        '''
        Return list of extensions with given Oid
        '''
        result = []
        for i in range(len(self)):
            ext = self._cert.get_extension(i)
            if ext.get_oid() == oid:
                result.append(ext)
        return result

    def find_critical(self, crit=True):
        '''
        Return list of critical extensions (or list of non-cricital, if
        optional second argument is False
        '''
        result = []
        for i in range(len(self)):
            ext = self._cert.get_extension(i)
            if ext.get_critical() == crit:
                result.append(ext)
        return result","class _X509extlist(object):
    '''
    Represents list of certificate extensions. Really it keeps
    reference to certificate object
    '''

    def __init__(self, cert):
        '''
        Initialize from X509 object
        '''
        self.cert = cert

    def __len__(self):
        '''
        Returns number of extensions
        '''
        return self.cert.get_extension_count()

    def __getitem__(self, item):
        '''
        Returns extension by index, creating a copy
        '''
        if item < 0 or item >= len(self):
            raise IndexError(""Extension index out of range"")
        return self.cert.get_extension(item)

    def find(self, oid):
        '''
        Return list of extensions with given Oid
        '''
        result = []
        for i in range(len(self)):
            ext = self[i]
            if ext.get_short_name() == oid or str(ext.get_oid()) == oid:
                result.append(ext)
        return result

    def find_critical(self, crit=True):
        '''
        Return list of critical extensions (or list of non-cricital, if
        optional second argument is False
        '''
        result = []
        for i in range(len(self)):
            ext = self[i]
            if ext.get_critical() == crit:
                result.append(ext)
        return result",partial_docstr,0.5708418891170431,0.3505154639175257,0.2898550724637681,0.45174537987679664,0.31124109620782203,0.49029982363315694,0.30212014134275617,0.20353982300884957,0.8282230496406555,0.8580510020256042,0.842873215675354,0.8549718260765076,0.775213949191686,0.6956521739130435,0.489795918367347,0.41642228739002934,0.5797101449275363,0.40546444567282314,0.8309352517985612,0.5631768953068592,0.39855072463768115,0.9187020063400269,0.8595669269561768,0.888151228427887,0.865135669708252,0.8425941666666666,0.699421965317919,0.47674418604651164,0.4093567251461988,0.5722543352601157,0.4095305704296138,0.8303249097472925,0.5615942028985508,0.41818181818181815,0.9144259691238403,0.8586350679397583,0.8856527805328369,0.8639059662818909,0.8267213095238095,0.3787853128716737,0.2287598185550858,0.3310968800860805,0.4552845528455284,0.5,0.3641484132999345,0.2959201264316457,0.3130055764043782,0.3739837398373983,0.4736842105263157,0.3693586136389966,0.3052169136080482,0.3214473227194404,0.3902439024390244,0.4605263157894737
460139,haifengat/hf_ctp_py_proxy,haifengat_hf_ctp_py_proxy/py_ctp/structs.py,py_ctp.structs.InstrumentField,"class InstrumentField:
    """"""""""""

    def __init__(self):
        """"""Constructor""""""
        ''''''
        self.InstrumentID = ''
        ''''''
        ''''''
        self.InstrumentName = ''
        ''''''
        ''''''
        self.ProductID = ''
        ''''''
        ''''''
        self.ExchangeID = ''
        ''''''
        ''''''
        self.VolumeMultiple = ''
        ''''''
        ''''''
        self.PriceTick = 0.0
        ''''''
        ''''''
        self.MaxOrderVolume = 9999
        ''''''
        ''' Futures/Options/Combination/Spot/EFP/SpotOption'''
        self.ProductType = 'Future'
        ''' Futures/Options/Combination/Spot/EFP/SpotOption'''

    def __str__(self):
        """"""""""""
        return '{self.InstrumentID}, {self.ProductID}, {self.ExchangeID}, {self.VolumeMultiple}, {self.PriceTick}, {self.MaxOrderVolume}, {self.ProductType}'.format(
            self=self)

    @property
    def __dict__(self):
        return {
            'InstrumentID': self.InstrumentID,
            'ProductID': self.ProductID,
            'ExchangeID': self.ExchangeID,
            'VolumeMultiple': self.VolumeMultiple,
            'PriceTick': self.PriceTick,
            'MaxOrderVolume': self.MaxOrderVolume,
            'ProductType': self.ProductType
        }","class InstrumentField:
    ''''''

    def __init__(self):
    '''Constructor'''
        pass

    def __str__(self):
    ''''''
        pass

    @property
    def __dict__(self):
        pass

",5,3,snippet_623,0.8,"class InstrumentField:
    ''''''

    def __init__(self, **kwargs):
        self._attributes = {}
        for key, value in kwargs.items():
            self._attributes[key] = value

    def __setattr__(self, name, value):
        if name == '_attributes':
            object.__setattr__(self, name, value)
        else:
            self._attributes[name] = value

    def __getattr__(self, name):
        try:
            return self._attributes[name]
        except KeyError:
            raise AttributeError(f""'{type(self).__name__}' object has no attribute '{name}'"")

    def __str__(self):
        attrs = ', '.join(f""{k}={v!r}"" for k, v in self._attributes.items())
        return f""{type(self).__name__}({attrs})""

    @property
    def __dict__(self):
        return dict(self._attributes)","class InstrumentField:
    ''''''

    def __init__(self):
        '''Constructor'''
        self._instrument_id = """"
        self._exchange_id = """"
        self._instrument_name = """"
        self._product_id = """"
        self._product_class = """"
        self._delivery_year = 0
        self._delivery_month = 0
        self._max_market_order_volume = 0
        self._min_market_order_volume = 0
        self._max_limit_order_volume = 0
        self._min_limit_order_volume = 0
        self._volume_multiple = 0
        self._price_tick = 0.0
        self._create_date = """"
        self._open_date = """"
        self._expire_date = """"
        self._start_delivery_date = """"
        self._end_delivery_date = """"
        self._inst_life_phase = """"
        self._is_trading = False
        self._position_type = """"
        self._position_date_type = """"
        self._long_margin_ratio = 0.0
        self._short_margin_ratio = 0.0
        self._max_margin_side_algorithm = False

    def __str__(self):
        ''''''
        return f""InstrumentField(InstrumentID={self._instrument_id}, ExchangeID={self._exchange_id}, InstrumentName={self._instrument_name})""

    @property
    def __dict__(self):
        ''''''
        return {
            'InstrumentID': self._instrument_id,
            'ExchangeID': self._exchange_id,
            'InstrumentName': self._instrument_name,
            'ProductID': self._product_id,
            'ProductClass': self._product_class,
            'DeliveryYear': self._delivery_year,
            'DeliveryMonth': self._delivery_month,
            'MaxMarketOrderVolume': self._max_market_order_volume,
            'MinMarketOrderVolume': self._min_market_order_volume,
            'MaxLimitOrderVolume': self._max_limit_order_volume,
            'MinLimitOrderVolume': self._min_limit_order_volume,
            'VolumeMultiple': self._volume_multiple,
            'PriceTick': self._price_tick,
            'CreateDate': self._create_date,
            'OpenDate': self._open_date,
            'ExpireDate': self._expire_date,
            'StartDeliveryDate': self._start_delivery_date,
            'EndDeliveryDate': self._end_delivery_date,
            'InstLifePhase': self._inst_life_phase,
            'IsTrading': self._is_trading,
            'PositionType': self._position_type,
            'PositionDateType': self._position_date_type,
            'LongMarginRatio': self._long_margin_ratio,
            'ShortMarginRatio': self._short_margin_ratio,
            'MaxMarginSideAlgorithm': self._max_margin_side_algorithm
        }

    @property
    def InstrumentID(self):
        return self._instrument_id

    @InstrumentID.setter
    def InstrumentID(self, value):
        self._instrument_id = value

    @property
    def ExchangeID(self):
        return self._exchange_id

    @ExchangeID.setter
    def ExchangeID(self, value):
        self._exchange_id = value

    @property
    def InstrumentName(self):
        return self._instrument_name

    @InstrumentName.setter
    def InstrumentName(self, value):
        self._instrument_name = value

    @property
    def ProductID(self):
        return self._product_id

    @ProductID.setter
    def ProductID(self, value):
        self._product_id = value

    @property
    def ProductClass(self):
        return self._product_class

    @ProductClass.setter
    def ProductClass(self, value):
        self._product_class = value

    @property
    def DeliveryYear(self):
        return self._delivery_year

    @DeliveryYear.setter
    def DeliveryYear(self, value):
        self._delivery_year = value

    @property
    def DeliveryMonth(self):
        return self._delivery_month

    @DeliveryMonth.setter
    def DeliveryMonth(self, value):
        self._delivery_month = value

    @property
    def MaxMarketOrderVolume(self):
        return self._max_market_order_volume

    @MaxMarketOrderVolume.setter
    def MaxMarketOrderVolume(self, value):
        self._max_market_order_volume = value

    @property
    def MinMarketOrderVolume(self):
        return self._min_market_order_volume

    @MinMarketOrderVolume.setter
    def MinMarketOrderVolume(self, value):
        self._min_market_order_volume = value

    @property
    def MaxLimitOrderVolume(self):
        return self._max_limit_order_volume

    @MaxLimitOrderVolume.setter
    def MaxLimitOrderVolume(self, value):
        self._max_limit_order_volume = value

    @property
    def MinLimitOrderVolume(self):
        return self._min_limit_order_volume

    @MinLimitOrderVolume.setter
    def MinLimitOrderVolume(self, value):
        self._min_limit_order_volume = value

    @property
    def VolumeMultiple(self):
        return self._volume_multiple

    @VolumeMultiple.setter
    def VolumeMultiple(self, value):
        self._volume_multiple = value

    @property
    def PriceTick(self):
        return self._price_tick

    @PriceTick.setter
    def PriceTick(self, value):
        self._price_tick = value

    @property
    def CreateDate(self):
        return self._create_date

    @CreateDate.setter
    def CreateDate(self, value):
        self._create_date = value

    @property
    def OpenDate(self):
        return self._open_date

    @OpenDate.setter
    def OpenDate(self, value):
        self._open_date = value

    @property
    def ExpireDate(self):
        return self._expire_date

    @ExpireDate.setter
    def ExpireDate(self, value):
        self._expire_date = value

    @property
    def StartDeliveryDate(self):
        return self._start_delivery_date

    @StartDeliveryDate.setter
    def StartDeliveryDate(self, value):
        self._start_delivery_date = value

    @property
    def EndDeliveryDate(self):
        return self._end_delivery_date

    @EndDeliveryDate.setter
    def EndDeliveryDate(self, value):
        self._end_delivery_date = value

    @property
    def InstLifePhase(self):
        return self._inst_life_phase

    @InstLifePhase.setter
    def InstLifePhase(self, value):
        self._inst_life_phase = value

    @property
    def IsTrading(self):
        return self._is_trading

    @IsTrading.setter
    def IsTrading(self, value):
        self._is_trading = value

    @property
    def PositionType(self):
        return self._position_type

    @PositionType.setter
    def PositionType(self, value):
        self._position_type = value

    @property
    def PositionDateType(self):
        return self._position_date_type

    @PositionDateType.setter
    def PositionDateType(self, value):
        self._position_date_type = value

    @property
    def LongMarginRatio(self):
        return self._long_margin_ratio

    @LongMarginRatio.setter
    def LongMarginRatio(self, value):
        self._long_margin_ratio = value

    @property
    def ShortMarginRatio(self):
        return self._short_margin_ratio

    @ShortMarginRatio.setter
    def ShortMarginRatio(self, value):
        self._short_margin_ratio = value

    @property
    def MaxMarginSideAlgorithm(self):
        return self._max_margin_side_algorithm

    @MaxMarginSideAlgorithm.setter
    def MaxMarginSideAlgorithm(self, value):
        self._max_margin_side_algorithm = value","class InstrumentField:
    ''''''

    def __init__(self):
        '''Constructor'''
        self.InstrumentID = """"
        self.ExchangeID = """"
        self.InstrumentName = """"
        self.ExchangeInstID = """"
        self.ProductID = """"
        self.ProductClass = """"
        self.DeliveryYear = 0
        self.DeliveryMonth = 0
        self.MaxMarketOrderVolume = 0
        self.MinMarketOrderVolume = 0
        self.MaxLimitOrderVolume = 0
        self.MinLimitOrderVolume = 0
        self.VolumeMultiple = 0
        self.PriceTick = 0.0
        self.CreateDate = """"
        self.OpenDate = """"
        self.ExpireDate = """"
        self.StartDelivDate = """"
        self.EndDelivDate = """"
        self.InstLifePhase = """"
        self.IsTrading = 0
        self.PositionType = """"
        self.PositionDateType = """"
        self.LongMarginRatio = 0.0
        self.ShortMarginRatio = 0.0
        self.MaxMarginSideAlgorithm = """"
        self.UnderlyingInstrID = """"
        self.StrikePrice = 0.0
        self.OptionsType = """"
        self.UnderlyingMultiple = 0.0
        self.CombinationType = """"

    def __str__(self):
        ''''''
        return f""InstrumentField(InstrumentID={self.InstrumentID}, ExchangeID={self.ExchangeID}, InstrumentName={self.InstrumentName})""

    @property
    def __dict__(self):
        return {
            'InstrumentID': self.InstrumentID,
            'ExchangeID': self.ExchangeID,
            'InstrumentName': self.InstrumentName,
            'ExchangeInstID': self.ExchangeInstID,
            'ProductID': self.ProductID,
            'ProductClass': self.ProductClass,
            'DeliveryYear': self.DeliveryYear,
            'DeliveryMonth': self.DeliveryMonth,
            'MaxMarketOrderVolume': self.MaxMarketOrderVolume,
            'MinMarketOrderVolume': self.MinMarketOrderVolume,
            'MaxLimitOrderVolume': self.MaxLimitOrderVolume,
            'MinLimitOrderVolume': self.MinLimitOrderVolume,
            'VolumeMultiple': self.VolumeMultiple,
            'PriceTick': self.PriceTick,
            'CreateDate': self.CreateDate,
            'OpenDate': self.OpenDate,
            'ExpireDate': self.ExpireDate,
            'StartDelivDate': self.StartDelivDate,
            'EndDelivDate': self.EndDelivDate,
            'InstLifePhase': self.InstLifePhase,
            'IsTrading': self.IsTrading,
            'PositionType': self.PositionType,
            'PositionDateType': self.PositionDateType,
            'LongMarginRatio': self.LongMarginRatio,
            'ShortMarginRatio': self.ShortMarginRatio,
            'MaxMarginSideAlgorithm': self.MaxMarginSideAlgorithm,
            'UnderlyingInstrID': self.UnderlyingInstrID,
            'StrikePrice': self.StrikePrice,
            'OptionsType': self.OptionsType,
            'UnderlyingMultiple': self.UnderlyingMultiple,
            'CombinationType': self.CombinationType
        }",partial_docstr,0.28901734104046245,0.1286549707602339,0.08284023668639054,0.2774566473988439,0.23342286109816404,0.4678111587982833,0.2025862068965517,0.1341991341991342,0.6938596367835999,0.6551790237426758,0.67396479845047,0.6588519215583801,0.7044563967611344,0.15158924205378974,0.0784313725490196,0.0343980343980344,0.12469437652811736,0.06091618693550159,0.10775295663600526,0.06377383300460224,0.03289473684210526,0.7751333117485046,0.7937831282615662,0.7843473553657532,0.7918778657913208,0.717885510729618,0.4154929577464789,0.2978723404255319,0.19285714285714284,0.35915492957746475,0.2720782367046399,0.3744186046511628,0.2773892773892774,0.1939252336448598,0.8343780040740967,0.7787237167358398,0.8055907487869263,0.7839528322219849,0.7878809090909098,0.3735109619088522,0.0437617437591653,0.0530218299036406,0.3972602739726027,0.0,0.4453985188200116,0.0058334739031685,0.0360345739796175,0.7397260273972602,0.0,0.4996709122308079,0.0779930665003021,0.1809645550256694,0.7397260273972602,0.0
170253,PyCQA/pylint,tests/functional/r/regression_02/regression_2964.py,regression_2964.Node,"class Node:
    def __init__(self, name, path=()):
        """"""
        Initialize self with ""name"" string and the tuple ""path"" of its parents.
        ""self"" is added to the tuple as its last item.
        """"""
        self.__name = name
        self.__path = path + (self,)

    def get_full_name(self):
        """"""
        A `no-member` message was emitted:
        nodes.py:17:24: E1101: Instance of 'tuple' has no '__name' member (no-member)
        """"""
        return ""."".join(node.__name for node in self.__path)","class Node:


    def __init__(self, name, path=()):
    '''
        Initialize self with ""name"" string and the tuple ""path"" of its parents.
        ""self"" is added to the tuple as its last item.
        '''
        pass

    def get_full_name(self):
    '''
        A `no-member` message was emitted:
        nodes.py:17:24: E1101: Instance of 'tuple' has no '__name' member (no-member)
        '''
        pass

",3,2,snippet_672,1.0,"class Node:

    def __init__(self, name, path=()):
        '''
            Initialize self with ""name"" string and the tuple ""path"" of its parents.
            ""self"" is added to the tuple as its last item.
        '''
        self.name = name
        self.path = path + (self,)

    def get_full_name(self):
        '''
            A `no-member` message was emitted:
            nodes.py:17:24: E1101: Instance of 'tuple' has no '__name' member (no-member)
        '''
        return '.'.join(node.name for node in self.path)","class Node:
    def __init__(self, name, path=()):
        '''
        Initialize self with ""name"" string and the tuple ""path"" of its parents.
        ""self"" is added to the tuple as its last item.
        '''
        self.name = name
        self.path = path + (self,)

    def get_full_name(self):
        '''
        A `no-member` message was emitted:
        nodes.py:17:24: E1101: Instance of 'tuple' has no '__name' member (no-member)
        '''
        names = [node.name for node in self.path]
        return '.'.join(names)","class Node:
    def __init__(self, name, path=()):
        '''
        Initialize self with ""name"" string and the tuple ""path"" of its parents.
        ""self"" is added to the tuple as its last item.
        '''
        self.__name = name
        self.path = path + (self,)

    def get_full_name(self):
        '''
        A `no-member` message was emitted:
        nodes.py:17:24: E1101: Instance of 'tuple' has no '__name' member (no-member)
        '''
        return '.'.join(node.__name for node in self.path)",partial_docstr,1.0,1.0,1.0,1.0,0.773129034073902,0.953125,0.8740157480314961,0.8095238095238095,0.9884694218635559,0.9884694218635559,0.9884694218635559,0.9884694218635559,1.0,0.9859154929577464,0.9571428571428571,0.9275362318840579,0.9577464788732395,0.7664878589793964,0.9172932330827067,0.8257575757575758,0.7633587786259542,0.9881181716918945,0.9939283728599548,0.9910147190093994,0.9933443665504456,0.9128213846153846,1.0,1.0,1.0,1.0,0.8183469541298641,0.9545454545454546,0.8931297709923665,0.8461538461538461,0.996941328048706,0.996941328048706,0.996941328048706,0.9969413876533508,1.0,0.761345426169107,0.731914589608684,0.7420385436391728,1.0,0.5714285714285714,0.6966152393555337,0.6978615672221155,0.7420385436391728,0.7037037037037037,0.6428571428571429,0.820333495913504,0.7433789181862663,0.7522407797534643,1.0,0.7857142857142857
572265,mgoral/subconvert,mgoral_subconvert/src/subconvert/gui/Detail.py,subconvert.gui.Detail.DisableSignalling,"class DisableSignalling:
    """"""
    Usage example:
    with DisableSignalling(cls.signal, self.slot):
        # do something
        pass
    """"""
    def __init__(self, signal, slot):
        self._signal = signal
        self._slot = slot

    def __enter__(self):
        self._signal.disconnect(self._slot)

    def __exit__(self, type, value, traceback):
        self._signal.connect(self._slot)","class DisableSignalling:
    '''
    Usage example:
    with DisableSignalling(cls.signal, self.slot):
        # do something
    pass
    '''

    def __init__(self, signal, slot):
        pass

    def __enter__(self):
        pass

    def __exit__(self, type, value, traceback):
        pass

",4,1,snippet_593,1.0,"class DisableSignalling:
    '''
    Usage example:
    with DisableSignalling(cls.signal, self.slot):
        # do something
    '''
    def __init__(self, signal, slot):
        self._signal = signal
        self._slot = slot
        self._was_connected = False

    def __enter__(self):
        try:
            # attempt to disconnect; if it wasn't connected, an exception may be raised
            self._signal.disconnect(self._slot)
            self._was_connected = True
        except Exception:
            self._was_connected = False
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        if self._was_connected:
            try:
                self._signal.connect(self._slot)
            except Exception:
                pass
        # allow exceptions to propagate
        return False","class DisableSignalling:
    '''
    Usage example:
    with DisableSignalling(cls.signal, self.slot):
        # do something
    pass
    '''

    def __init__(self, signal, slot):
        self.signal = signal
        self.slot = slot

    def __enter__(self):
        self.signal.disconnect(self.slot)
        return self

    def __exit__(self, type, value, traceback):
        self.signal.connect(self.slot)","class DisableSignalling:
    '''
    Usage example:
    with DisableSignalling(cls.signal, self.slot):
        # do something
    pass
    '''

    def __init__(self, signal, slot):
        self.signal = signal
        self.slot = slot

    def __enter__(self):
        self.signal.disconnect(self.slot)
        return self

    def __exit__(self, type, value, traceback):
        self.signal.connect(self.slot)",partial_docstr,0.6564885496183206,0.5271317829457365,0.42519685039370075,0.6412213740458016,0.5317647775635472,0.5789473684210527,0.5352941176470588,0.48520710059171596,0.8076053261756897,0.9495821595191956,0.8728580474853516,0.9331769943237305,0.8705514563106795,0.9772727272727273,0.9534883720930233,0.9285714285714286,0.9772727272727273,0.7916160106116819,0.9587628865979382,0.8645833333333334,0.7684210526315789,0.9850896596908569,0.9930706024169922,0.9890639781951904,0.9922667145729065,0.9897436923076924,0.9772727272727273,0.9534883720930233,0.9285714285714286,0.9772727272727273,0.7916160106116819,0.9587628865979382,0.8645833333333334,0.7684210526315789,0.9850896596908569,0.9930706024169922,0.9890639781951904,0.9922667145729065,0.9897436923076924,0.6478130199717045,0.2488150411827656,0.5757703720373857,0.7666666666666667,1.0,0.6477069609253249,0.5057160213863169,0.5517784889816494,0.8666666666666667,0.6666666666666666,0.6477069609253249,0.5057160213863169,0.5517784889816494,0.8666666666666667,0.6666666666666666
466628,hollenstein/maspy,hollenstein_maspy/maspy/auxiliary.py,maspy.auxiliary.Memoize,"class Memoize(object):
    """"""A general memoization class, specify a function when creating a new
    instance of the class. The functions return value is returned and stored in
    ``self.memo`` when the instance is called with an argument for the first
    time. Later calls with the same argument return the cached value, instead of
    calling the function again.

    :ivar function: when ``Memoize`` is called this functions return value is
        returned.
    :ivar memo: a dictionary that records the ``function`` return values of
        already called variables.
    """"""
    def __init__(self, function):
        self.function = function
        self.memo = {}
    def __call__(self, arg):
        if not arg in self.memo:
            self.memo[arg] = self.function(arg)
        return self.memo[arg]","class Memoize(object):
    '''A general memoization class, specify a function when creating a new
    instance of the class. The functions return value is returned and stored in
    ``self.memo`` when the instance is called with an argument for the first
    time. Later calls with the same argument return the cached value, instead of
    calling the function again.

    :ivar function: when ``Memoize`` is called this functions return value is
        returned.
    :ivar memo: a dictionary that records the ``function`` return values of
        already called variables.
    '''

    def __init__(self, function):
        pass

    def __call__(self, arg):
        pass

",3,1,snippet_79,0.8,"class Memoize(object):
    '''A general memoization class, specify a function when creating a new
    instance of the class. The functions return value is returned and stored in
    ``self.memo`` when the instance is called with an argument for the first
    time. Later calls with the same argument return the cached value, instead of
    calling the function again.

    :ivar function: when ``Memoize`` is called this functions return value is
        returned.
    :ivar memo: a dictionary that records the ``function`` return values of
        already called variables.
    '''

    def __init__(self, function):
        self.function = function
        self.memo = {}

    def __call__(self, arg):
        if arg not in self.memo:
            self.memo[arg] = self.function(arg)
        return self.memo[arg]","class Memoize(object):
    '''A general memoization class, specify a function when creating a new
    instance of the class. The functions return value is returned and stored in
    ``self.memo`` when the instance is called with an argument for the first
    time. Later calls with the same argument return the cached value, instead of
    calling the function again.

    :ivar function: when ``Memoize`` is called this functions return value is
        returned.
    :ivar memo: a dictionary that records the ``function`` return values of
        already called variables.
    '''

    def __init__(self, function):
        self.function = function
        self.memo = {}

    def __call__(self, arg):
        if arg in self.memo:
            return self.memo[arg]
        else:
            result = self.function(arg)
            self.memo[arg] = result
            return result","class Memoize(object):
    '''A general memoization class, specify a function when creating a new
    instance of the class. The functions return value is returned and stored in
    ``self.memo`` when the instance is called with an argument for the first
    time. Later calls with the same argument return the cached value, instead of
    calling the function again.

    :ivar function: when ``Memoize`` is called this functions return value is
        returned.
    :ivar memo: a dictionary that records the ``function`` return values of
        already called variables.
    '''

    def __init__(self, function):
        self.function = function
        self.memo = {}

    def __call__(self, arg):
        if arg not in self.memo:
            self.memo[arg] = self.function(arg)
        return self.memo[arg]",partial_docstr,1.0,0.972972972972973,0.9636363636363636,0.9910714285714286,0.9360359590174988,0.9885714285714285,0.9597701149425287,0.9421965317919075,0.9973795413970947,0.9973795413970947,0.9973795413970947,0.9973796010017395,0.9946237096774194,0.9736842105263158,0.9469026548672567,0.9017857142857142,0.9649122807017544,0.919905430765425,0.9502762430939227,0.9222222222222223,0.888268156424581,0.9841549396514893,0.9914220571517944,0.9877750873565674,0.9906905293464661,0.9130443478260869,1.0,0.972972972972973,0.9636363636363636,0.9910714285714286,0.9360359590174988,0.9885714285714285,0.9597701149425287,0.9421965317919075,0.9973795413970947,0.9973795413970947,0.9973795413970947,0.9973796010017395,0.9946237096774194,0.9074225064059498,0.9232392984484472,0.9252007271753516,0.78125,1.0,0.8224109374078508,0.8562521404362594,0.8958916091951435,0.6875,0.85,0.9074225064059498,0.9232392984484472,0.9252007271753516,0.78125,1.0
790796,tgsmith61591/pmdarima,tgsmith61591_pmdarima/pmdarima/utils/metaestimators.py,pmdarima.utils.metaestimators._IffHasDelegate,"class _IffHasDelegate(object):
    """"""Implements a conditional property using the descriptor protocol.
    Using this class to create a decorator will raise an ``AttributeError``
    if none of the delegates (specified in ``delegate_names``) is an attribute
    of the base object or the first found delegate does not have an attribute
    ``attribute_name``.

    This allows ducktyping of the decorated method based on
    ``delegate.attribute_name``. Here ``delegate`` is the first item in
    ``delegate_names`` for which ``hasattr(object, delegate) is True``.

    See https://docs.python.org/3/howto/descriptor.html for an explanation of
    descriptors.
    """"""
    def __init__(self, fn, delegate_names):
        self.fn = fn
        self.delegate_names = delegate_names

        # update the docstring of the descriptor
        update_wrapper(self, fn)

    def __get__(self, obj, type=None):
        # raise an AttributeError if the attribute is not present on the object
        if obj is not None:
            # delegate only on instances, not the classes.
            # this is to allow access to the docstrings.
            for delegate_name in self.delegate_names:
                try:
                    attrgetter(delegate_name)(obj)
                except AttributeError:
                    continue
                else:
                    break
            else:
                attrgetter(self.delegate_names[-1])(obj)

        # lambda, but not partial, allows help() to work with update_wrapper
        out = (lambda *args, **kwargs: self.fn(obj, *args, **kwargs))
        # update the docstring of the returned function
        update_wrapper(out, self.fn)
        return out","class _IffHasDelegate(object):
    '''Implements a conditional property using the descriptor protocol.
    Using this class to create a decorator will raise an ``AttributeError``
    if none of the delegates (specified in ``delegate_names``) is an attribute
    of the base object or the first found delegate does not have an attribute
    ``attribute_name``.

    This allows ducktyping of the decorated method based on
    ``delegate.attribute_name``. Here ``delegate`` is the first item in
    ``delegate_names`` for which ``hasattr(object, delegate) is True``.

    See https://docs.python.org/3/howto/descriptor.html for an explanation of
    descriptors.
    '''

    def __init__(self, fn, delegate_names):
        pass

    def __get__(self, obj, type=None):
        pass

",3,1,snippet_474,0.3,"class _IffHasDelegate(object):
    '''Implements a conditional property using the descriptor protocol.
    Using this class to create a decorator will raise an ``AttributeError``
    if none of the delegates (specified in ``delegate_names``) is an attribute
    of the base object or the first found delegate does not have an attribute
    ``attribute_name``.

    This allows ducktyping of the decorated method based on
    ``delegate.attribute_name``. Here ``delegate`` is the first item in
    ``delegate_names`` for which ``hasattr(object, delegate) is True``.

    See https://docs.python.org/3/howto/descriptor.html for an explanation of
    descriptors.
    '''

    def __init__(self, fn, delegate_names):
        self._fn = fn
        if isinstance(delegate_names, (list, tuple)):
            self.delegate_names = tuple(delegate_names)
        else:
            raise TypeError(""delegate_names must be a list or tuple of strings"")
        self.__doc__ = fn.__doc__
        self.__name__ = fn.__name__
        # Preserve annotations if present
        if hasattr(fn, '__annotations__'):
            self.__annotations__ = fn.__annotations__

    def __get__(self, obj, objtype=None):
        if obj is None:
            return self
        # Find the first delegate present on obj
        for name in self.delegate_names:
            if hasattr(obj, name):
                delegate = getattr(obj, name)
                break
        else:
            raise AttributeError(
                f""{type(obj).__name__!r} has no delegate among {self.delegate_names}""
            )
        # Ensure the delegate has the requested attribute
        attr_name = self.__name__
        if not hasattr(delegate, attr_name):
            raise AttributeError(
                f""Delegate {type(delegate).__name__!r} (via '{name}') ""
                f""has no attribute {attr_name!r}""
            )
        # Return the attribute bound to the delegate
        return getattr(delegate, attr_name)","class _IffHasDelegate(object):
    '''Implements a conditional property using the descriptor protocol.
    Using this class to create a decorator will raise an ``AttributeError``
    if none of the delegates (specified in ``delegate_names``) is an attribute
    of the base object or the first found delegate does not have an attribute
    ``attribute_name``.

    This allows ducktyping of the decorated method based on
    ``delegate.attribute_name``. Here ``delegate`` is the first item in
    ``delegate_names`` for which ``hasattr(object, delegate) is True``.

    See https://docs.python.org/3/howto/descriptor.html for an explanation of
    descriptors.
    '''

    def __init__(self, fn, delegate_names):
        self.fn = fn
        self.delegate_names = delegate_names
        self.attribute_name = fn.__name__

    def __get__(self, obj, type=None):
        if obj is None:
            return self
        
        # Find the first delegate that exists on the object
        delegate = None
        for delegate_name in self.delegate_names:
            if hasattr(obj, delegate_name):
                delegate = getattr(obj, delegate_name)
                break
        
        # Raise AttributeError if no delegate found
        if delegate is None:
            raise AttributeError(
                f""None of the delegates {self.delegate_names} found on object""
            )
        
        # Raise AttributeError if delegate doesn't have the required attribute
        if not hasattr(delegate, self.attribute_name):
            raise AttributeError(
                f""Delegate {delegate} does not have attribute {self.attribute_name}""
            )
        
        # Return the attribute from the delegate
        return getattr(delegate, self.attribute_name)","class _IffHasDelegate(object):
    '''Implements a conditional property using the descriptor protocol.
    Using this class to create a decorator will raise an ``AttributeError``
    if none of the delegates (specified in ``delegate_names``) is an attribute
    of the base object or the first found delegate does not have an attribute
    ``attribute_name``.

    This allows ducktyping of the decorated method based on
    ``delegate.attribute_name``. Here ``delegate`` is the first item in
    ``delegate_names`` for which ``hasattr(object, delegate) is True``.

    See https://docs.python.org/3/howto/descriptor.html for an explanation of
    descriptors.
    '''

    def __init__(self, fn, delegate_names):
        self.fn = fn
        self.delegate_names = delegate_names
        self.attribute_name = fn.__name__

    def __get__(self, obj, type=None):
        if obj is None:
            return self
        
        delegate = None
        for delegate_name in self.delegate_names:
            if hasattr(obj, delegate_name):
                delegate = getattr(obj, delegate_name)
                break
        
        if delegate is None:
            raise AttributeError(f""None of the delegates {self.delegate_names} found on {obj}"")
        
        if not hasattr(delegate, self.attribute_name):
            raise AttributeError(f""Delegate {delegate} does not have attribute '{self.attribute_name}'"")
        
        return getattr(delegate, self.attribute_name)",partial_docstr,0.6931567328918322,0.5277161862527715,0.4766146993318486,0.6048565121412804,0.5052936675541009,0.6385281385281385,0.48156182212581344,0.41956521739130437,0.8809893131256104,0.8851218819618225,0.8830507397651672,0.8847067952156067,0.7744130303030302,0.7242990654205607,0.5962441314553991,0.5471698113207547,0.6542056074766356,0.6478337581770992,0.7843137254901961,0.6292134831460674,0.5746478873239437,0.9223066568374634,0.883957028388977,0.9027246832847595,0.887647807598114,0.8148166666666666,0.7506297229219143,0.6227848101265824,0.5852417302798982,0.6952141057934509,0.6308484295045752,0.8256880733944955,0.6717791411042945,0.6246153846153846,0.937315821647644,0.87945955991745,0.907466471195221,0.8849217891693115,0.8059720895522388,0.4704567895646152,0.443824485980984,0.4957678237926284,0.3484848484848485,0.59375,0.5389048570293122,0.5286655772421428,0.5445674872387424,0.3636363636363636,0.71875,0.528563768434973,0.5017733071378202,0.5300954029657079,0.3636363636363636,0.71875
809392,twisted/axiom,axiom/scheduler.py,axiom.scheduler._SchedulerCompatMixin,"class _SchedulerCompatMixin(object):
    """"""
    Backwards compatibility helper for L{Scheduler} and L{SubScheduler}.

    This mixin provides all the attributes from L{IScheduler}, but provides
    them by adapting the L{Store} the item is in to L{IScheduler} and
    getting them from the resulting object.  Primarily in support of test
    code, it also supports rebinding those attributes by rebinding them on
    the L{IScheduler} powerup.

    @see: L{IScheduler}
    """"""
    def forwardToReal(name):
        def get(self):
            return getattr(IScheduler(self.store), name)
        def set(self, value):
            setattr(IScheduler(self.store), name, value)
        return property(get, set)

    now = forwardToReal(""now"")
    tick = forwardToReal(""tick"")
    schedule = forwardToReal(""schedule"")
    reschedule = forwardToReal(""reschedule"")
    unschedule = forwardToReal(""unschedule"")
    unscheduleAll = forwardToReal(""unscheduleAll"")
    scheduledTimes = forwardToReal(""scheduledTimes"")


    def activate(self):
        """"""
        Whenever L{Scheduler} or L{SubScheduler} is created, either newly or
        when loaded from a database, emit a deprecation warning referring
        people to L{IScheduler}.
        """"""
        # This is unfortunate.  Perhaps it is the best thing which works (it is
        # the first I found). -exarkun
        if '_axiom_memory_dummy' in vars(self):
            stacklevel = 7
        else:
            stacklevel = 5
        warnings.warn(
            self.__class__.__name__ + "" is deprecated since Axiom 0.5.32.  ""
            ""Just adapt stores to IScheduler."",
            category=PendingDeprecationWarning,
            stacklevel=stacklevel)","class _SchedulerCompatMixin(object):
    '''
    Backwards compatibility helper for L{Scheduler} and L{SubScheduler}.

    This mixin provides all the attributes from L{IScheduler}, but provides
    them by adapting the L{Store} the item is in to L{IScheduler} and
    getting them from the resulting object.  Primarily in support of test
    code, it also supports rebinding those attributes by rebinding them on
    the L{IScheduler} powerup.

    @see: L{IScheduler}
    '''

    def forwardToReal(name):
        pass

        def get(self):
                pass

        def set(self, value):
                pass

    def activate(self):
    '''
        Whenever L{Scheduler} or L{SubScheduler} is created, either newly or
        when loaded from a database, emit a deprecation warning referring
        people to L{IScheduler}.
        '''
        pass

",5,2,snippet_638,0.5714285714285714,"class _SchedulerCompatMixin(object):
    """"""
    Backwards compatibility helper for L{Scheduler} and L{SubScheduler}.

    This mixin provides all the attributes from L{IScheduler}, but provides
    them by adapting the L{Store} the item is in to L{IScheduler} and
    getting them from the resulting object.  Primarily in support of test
    code, it also supports rebinding those attributes by rebinding them on
    the L{IScheduler} powerup.

    @see: L{IScheduler}
    """"""

    @staticmethod
    def forwardToReal(name):
        def get(self):
            real = self.store.powerUp(IScheduler)
            return getattr(real, name)

        def set(self, value):
            real = self.store.powerUp(IScheduler)
            setattr(real, name, value)

        return property(get, set)

    @classmethod
    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        for attr in dir(IScheduler):
            if attr.startswith(""_""):
                continue
            if hasattr(cls, attr):
                continue
            setattr(cls, attr, cls.forwardToReal(attr))

    def activate(self):
        """"""
        Whenever L{Scheduler} or L{SubScheduler} is created, either newly or
        when loaded from a database, emit a deprecation warning referring
        people to L{IScheduler}.
        """"""
        warn(
            ""{} is deprecated; use IScheduler powerup on its Store instead.""
            .format(self.__class__.__name__),
            DeprecationWarning,
            stacklevel=2
        )","class _SchedulerCompatMixin(object):
    '''
    Backwards compatibility helper for L{Scheduler} and L{SubScheduler}.

    This mixin provides all the attributes from L{IScheduler}, but provides
    them by adapting the L{Store} the item is in to L{IScheduler} and
    getting them from the resulting object.  Primarily in support of test
    code, it also supports rebinding those attributes by rebinding them on
    the L{IScheduler} powerup.

    @see: L{IScheduler}
    '''

    def forwardToReal(name):
        def get(self):
            from twisted.internet.interfaces import IScheduler
            scheduler = IScheduler(self.store)
            return getattr(scheduler, name)

        def set(self, value):
            from twisted.internet.interfaces import IScheduler
            scheduler = IScheduler(self.store)
            setattr(scheduler, name, value)
        
        return property(get, set)

    def activate(self):
        '''
        Whenever L{Scheduler} or L{SubScheduler} is created, either newly or
        when loaded from a database, emit a deprecation warning referring
        people to L{IScheduler}.
        '''
        import warnings
        warnings.warn(
            ""Scheduler and SubScheduler are deprecated. Use IScheduler instead."",
            DeprecationWarning,
            stacklevel=2
        )","class _SchedulerCompatMixin(object):
    '''
    Backwards compatibility helper for L{Scheduler} and L{SubScheduler}.

    This mixin provides all the attributes from L{IScheduler}, but provides
    them by adapting the L{Store} the item is in to L{IScheduler} and
    getting them from the resulting object.  Primarily in support of test
    code, it also supports rebinding those attributes by rebinding them on
    the L{IScheduler} powerup.

    @see: L{IScheduler}
    '''

    def forwardToReal(name):
        def get(self):
            from axiom.iaxiom import IScheduler
            scheduler = IScheduler(self.store)
            return getattr(scheduler, name)

        def set(self, value):
            from axiom.iaxiom import IScheduler
            scheduler = IScheduler(self.store)
            setattr(scheduler, name, value)
        
        return property(get, set)

    def activate(self):
        '''
        Whenever L{Scheduler} or L{SubScheduler} is created, either newly or
        when loaded from a database, emit a deprecation warning referring
        people to L{IScheduler}.
        '''
        import warnings
        warnings.warn(
            ""Scheduler and SubScheduler are deprecated. Use IScheduler instead."",
            DeprecationWarning,
            stacklevel=2
        )",partial_docstr,0.715846994535519,0.6153846153846154,0.56353591160221,0.6612021857923497,0.6317922964250163,0.7901234567901234,0.6470588235294118,0.577639751552795,0.8912790417671204,0.8665398359298706,0.8787353038787842,0.8689517974853516,0.7598590322580646,0.728862973760933,0.6627565982404692,0.6194690265486725,0.7113702623906706,0.49992210244697155,0.8723404255319149,0.7777777777777778,0.7167381974248928,0.9349976778030396,0.8593519330024719,0.8955802321434021,0.8663612008094788,0.793908870967742,0.7448680351906157,0.6666666666666667,0.6231454005934719,0.7155425219941349,0.49511739671473237,0.8831168831168831,0.7913043478260869,0.7292576419213974,0.9394451379776001,0.8627409934997559,0.8994607329368591,0.8698431849479675,0.7921167741935484,0.4851802087494517,0.5385388604345137,0.5674597523410707,0.3555555555555555,0.4791666666666667,0.4199265469209999,0.4858448830091248,0.5188613046748749,0.3,0.375,0.4199265469209999,0.4858448830091248,0.5188613046748749,0.3,0.375
555872,lwcolton/falcon-cors,lwcolton_falcon-cors/src/falcon_cors/middleware.py,falcon_cors.middleware.CORSMiddleware,"class CORSMiddleware:
    """"""This is the middleware that applies a CORS object to requests.

    Args:
        cors (CORS, required): An instance of :py:class:`~falcon.cors.CORS`.
        default_enabled (bool, optional): Whether CORS processing should
            take place for every resource.  Default ``True``.
    """"""
    def __init__(self, cors, default_enabled=True):
        self.cors = cors
        self.default_enabled = default_enabled

    def process_resource(self, req, resp, resource, *args):
        if not getattr(resource, 'cors_enabled', self.default_enabled):
            return
        cors = getattr(resource, 'cors', self.cors)
        cors.process(req, resp, resource)","class CORSMiddleware:
    '''This is the middleware that applies a CORS object to requests.

    Args:
        cors (CORS, required): An instance of :py:class:`~falcon.cors.CORS`.
        default_enabled (bool, optional): Whether CORS processing should
            take place for every resource.  Default ``True``.
    '''

    def __init__(self, cors, default_enabled=True):
        pass

    def process_resource(self, req, resp, resource, *args):
        pass

",3,1,snippet_108,1.0,"class CORSMiddleware:
    '''This is the middleware that applies a CORS object to requests.

    Args:
        cors (CORS, required): An instance of :py:class:`~falcon.cors.CORS`.
        default_enabled (bool, optional): Whether CORS processing should
            take place for every resource.  Default ``True``.
    '''

    def __init__(self, cors, default_enabled=True):
        self.cors = cors
        self.default_enabled = default_enabled

    def process_resource(self, req, resp, resource, *args):
        # Determine whether CORS is enabled for this resource
        enabled = getattr(resource, 'cors_enabled', None)
        if enabled is None:
            enabled = self.default_enabled

        if enabled:
            # Delegate to the CORS object
            self.cors.process_request(req, resp)","class CORSMiddleware:
    '''This is the middleware that applies a CORS object to requests.

    Args:
        cors (CORS, required): An instance of :py:class:`~falcon.cors.CORS`.
        default_enabled (bool, optional): Whether CORS processing should
            take place for every resource.  Default ``True``.
    '''

    def __init__(self, cors, default_enabled=True):
        self.cors = cors
        self.default_enabled = default_enabled

    def process_resource(self, req, resp, resource, *args):
        # Check if CORS is enabled for this resource
        cors_enabled = getattr(resource, 'cors_enabled', self.default_enabled)
        
        if cors_enabled:
            # Apply CORS processing
            self.cors.process(req, resp, resource)","class CORSMiddleware:
    '''This is the middleware that applies a CORS object to requests.

    Args:
        cors (CORS, required): An instance of :py:class:`~falcon.cors.CORS`.
        default_enabled (bool, optional): Whether CORS processing should
            take place for every resource.  Default ``True``.
    '''

    def __init__(self, cors, default_enabled=True):
        self._cors = cors
        self._default_enabled = default_enabled

    def process_resource(self, req, resp, resource, *args):
        cors_enabled = getattr(resource, 'cors_enabled', self._default_enabled)
        if cors_enabled:
            self._cors.process_resource(req, resp, resource, *args)",partial_docstr,0.8681318681318683,0.7888888888888889,0.7303370786516854,0.8351648351648353,0.7782662724391243,0.8372093023255814,0.7719298245614035,0.7294117647058823,0.9377464056015015,0.9742358922958374,0.9556429386138916,0.9704597592353821,0.8803430769230769,0.9204545454545455,0.8505747126436781,0.8023255813953488,0.8977272727272727,0.8435152737905539,0.891566265060241,0.8363636363636363,0.8048780487804879,0.9658036828041077,0.9799485802650452,0.97282475233078,0.9785155057907104,0.9059838461538462,0.9580838323353292,0.8727272727272728,0.8220858895705522,0.9221556886227544,0.8284789424001172,0.9197530864197531,0.8260869565217391,0.7625,0.9840764999389648,0.9802072048187256,0.9821380376815796,0.9805927276611328,0.9059838461538462,0.6504318066354037,0.5770403917549315,0.7241577342575828,0.4857142857142857,0.8148148148148148,0.7297467179945534,0.6489749215948847,0.7324458128171915,0.6857142857142857,0.8518518518518519,0.6480058310041354,0.6544115945990369,0.6508392426450181,0.6571428571428571,0.6296296296296297
107940,CityOfZion/neo-boa,CityOfZion_neo-boa/boa/interop/Neo/Witness.py,boa.interop.Neo.Witness.Witness,"class Witness:

    @property
    def VerificationScript(self):
        """"""

        :return:
        """"""
        return GetVerificationScript(self)","class Witness:


    @property
    def VerificationScript(self):
    '''

        :return:
        '''
        pass

",3,1,snippet_127,0.6666666666666666,"class Witness:
    def __init__(self, verification_script: bytes = b''):
        self._verification_script = verification_script

    @property
    def VerificationScript(self) -> bytes:
        '''
        :return: the verification script as bytes
        '''
        return self._verification_script

    @VerificationScript.setter
    def VerificationScript(self, value: bytes):
        '''
        :param value: the new verification script as bytes
        '''
        if not isinstance(value, (bytes, bytearray)):
            raise TypeError(""VerificationScript must be bytes or bytearray"")
        self._verification_script = bytes(value)","class Witness:
    def __init__(self, verification_script=None, invocation_script=None):
        self._verification_script = verification_script
        self._invocation_script = invocation_script

    @property
    def VerificationScript(self):
        '''
        :return:
        '''
        return self._verification_script

    @property
    def InvocationScript(self):
        '''
        :return:
        '''
        return self._invocation_script

    @VerificationScript.setter
    def VerificationScript(self, value):
        self._verification_script = value

    @InvocationScript.setter
    def InvocationScript(self, value):
        self._invocation_script = value

    def __eq__(self, other):
        if not isinstance(other, Witness):
            return False
        return (self._verification_script == other._verification_script and
                self._invocation_script == other._invocation_script)

    def __hash__(self):
        return hash((self._verification_script, self._invocation_script))

    def __repr__(self):
        return f""Witness(VerificationScript={self._verification_script}, InvocationScript={self._invocation_script})""","class Witness:
    def __init__(self, invocation_script=None, verification_script=None):
        self._invocation_script = invocation_script or b''
        self._verification_script = verification_script or b''

    @property
    def VerificationScript(self):
        return self._verification_script

    @VerificationScript.setter
    def VerificationScript(self, value):
        self._verification_script = value

    @property
    def InvocationScript(self):
        return self._invocation_script

    @InvocationScript.setter
    def InvocationScript(self, value):
        self._invocation_script = value",partial_docstr,0.24657534246575338,0.11267605633802817,0.05797101449275363,0.24657534246575338,0.10722812921036017,0.1721311475409836,0.10743801652892562,0.06666666666666667,0.7012926340103149,0.880083441734314,0.7805809378623962,0.8582040071487427,0.7471289655172414,0.15126050420168066,0.10256410256410256,0.06956521739130435,0.15126050420168066,0.05799909224745179,0.0846774193548387,0.05668016194331984,0.04065040650406504,0.6635546088218689,0.8440779447555542,0.7430083751678467,0.8217225670814514,0.705287500000001,0.2535211267605634,0.14492753623188404,0.08955223880597016,0.2535211267605634,0.10967553190290505,0.15833333333333333,0.1092436974789916,0.07627118644067797,0.7604551315307617,0.8533410429954529,0.8042249083518982,0.8430436849594116,0.706096129032258,0.3624808263768194,0.0108016530857347,0.0754852887851792,0.3636363636363636,1.0,0.3375576506913663,0.0178365410739963,0.1505758798732872,0.1818181818181818,1.0,0.2151176647475565,0.0300982085103235,0.1485542686617208,0.1818181818181818,0.5
634833,pbrod/numdifftools,pbrod_numdifftools/src/numdifftools/step_generators.py,numdifftools.step_generators.BasicMaxStepGenerator,"class BasicMaxStepGenerator(object):

    """"""
    Generates a sequence of steps of decreasing magnitude

    where
        steps = base_step * step_ratio ** (-i + offset)

    for i=0, 1,.., num_steps-1.


    Parameters
    ----------
    base_step : float, array-like.
       Defines the start step, i.e., maximum step
    step_ratio : real scalar.
        Ratio between sequential steps generated.  Note: Ratio > 1
    num_steps : scalar integer.
        defines number of steps generated.
    offset : real scalar, optional, default 0
        offset to the base step

    Examples
    --------
    >>> from numdifftools.step_generators import BasicMaxStepGenerator
    >>> step_gen = BasicMaxStepGenerator(base_step=2.0, step_ratio=2,
    ...                                  num_steps=4)
    >>> [s for s in step_gen()]
    [2.0, 1.0, 0.5, 0.25]

    """"""

    _sign = -1

    def __init__(self, base_step, step_ratio, num_steps, offset=0):
        self.base_step = base_step
        self.step_ratio = step_ratio
        self.num_steps = num_steps
        self.offset = offset

    def _range(self):
        return range(self.num_steps)

    def __call__(self):
        base_step, step_ratio = self.base_step, self.step_ratio
        sgn, offset = self._sign, self.offset
        for i in self._range():
            step = base_step * step_ratio ** (sgn * i + offset)
            if (np.abs(step) > 0).all():
                yield step","class BasicMaxStepGenerator(object):
    '''
    Generates a sequence of steps of decreasing magnitude

    where
        steps = base_step * step_ratio ** (-i + offset)

    for i=0, 1,.., num_steps-1.


    Parameters
    ----------
    base_step : float, array-like.
       Defines the start step, i.e., maximum step
    step_ratio : real scalar.
        Ratio between sequential steps generated.  Note: Ratio > 1
    num_steps : scalar integer.
        defines number of steps generated.
    offset : real scalar, optional, default 0
        offset to the base step

    Examples
    --------
    >>> from numdifftools.step_generators import BasicMaxStepGenerator
    >>> step_gen = BasicMaxStepGenerator(base_step=2.0, step_ratio=2,
    ...                                  num_steps=4)
    >>> [s for s in step_gen()]
    [2.0, 1.0, 0.5, 0.25]

    '''

    def __init__(self, base_step, step_ratio, num_steps, offset=0):
        pass

    def _range(self):
        pass

    def __call__(self):
        pass

",4,1,snippet_420,0.75,"class BasicMaxStepGenerator(object):
    '''
    Generates a sequence of steps of decreasing magnitude

    where
        steps = base_step * step_ratio ** (-i + offset)

    for i=0, 1,.., num_steps-1.


    Parameters
    ----------
    base_step : float, array-like.
       Defines the start step, i.e., maximum step
    step_ratio : real scalar.
        Ratio between sequential steps generated.  Note: Ratio > 1
    num_steps : scalar integer.
        defines number of steps generated.
    offset : real scalar, optional, default 0
        offset to the base step
    '''
    def __init__(self, base_step, step_ratio, num_steps, offset=0):
        self.base_step = np.asarray(base_step, dtype=float)
        if not np.isscalar(step_ratio) or step_ratio <= 1:
            raise ValueError(""step_ratio must be a scalar greater than 1"")
        if not isinstance(num_steps, int) or num_steps < 0:
            raise ValueError(""num_steps must be a non-negative integer"")
        self.step_ratio = float(step_ratio)
        self.num_steps = num_steps
        self.offset = float(offset)

    def _range(self):
        return (self.step_ratio ** (-i + self.offset) for i in range(self.num_steps))

    def __call__(self):
        for r in self._range():
            yield self.base_step * r","class BasicMaxStepGenerator(object):
    '''
    Generates a sequence of steps of decreasing magnitude

    where
        steps = base_step * step_ratio ** (-i + offset)

    for i=0, 1,.., num_steps-1.


    Parameters
    ----------
    base_step : float, array-like.
       Defines the start step, i.e., maximum step
    step_ratio : real scalar.
        Ratio between sequential steps generated.  Note: Ratio > 1
    num_steps : scalar integer.
        defines number of steps generated.
    offset : real scalar, optional, default 0
        offset to the base step

    Examples
    --------
    >>> from numdifftools.step_generators import BasicMaxStepGenerator
    >>> step_gen = BasicMaxStepGenerator(base_step=2.0, step_ratio=2,
    ...                                  num_steps=4)
    >>> [s for s in step_gen()]
    [2.0, 1.0, 0.5, 0.25]

    '''

    def __init__(self, base_step, step_ratio, num_steps, offset=0):
        self.base_step = base_step
        self.step_ratio = step_ratio
        self.num_steps = num_steps
        self.offset = offset

    def _range(self):
        return range(self.num_steps)

    def __call__(self):
        for i in self._range():
            step = self.base_step * self.step_ratio ** (-i + self.offset)
            yield step","class BasicMaxStepGenerator(object):
    '''
    Generates a sequence of steps of decreasing magnitude

    where
        steps = base_step * step_ratio ** (-i + offset)

    for i=0, 1,.., num_steps-1.


    Parameters
    ----------
    base_step : float, array-like.
       Defines the start step, i.e., maximum step
    step_ratio : real scalar.
        Ratio between sequential steps generated.  Note: Ratio > 1
    num_steps : scalar integer.
        defines number of steps generated.
    offset : real scalar, optional, default 0
        offset to the base step

    Examples
    --------
    >>> from numdifftools.step_generators import BasicMaxStepGenerator
    >>> step_gen = BasicMaxStepGenerator(base_step=2.0, step_ratio=2,
    ...                                  num_steps=4)
    >>> [s for s in step_gen()]
    [2.0, 1.0, 0.5, 0.25]

    '''

    def __init__(self, base_step, step_ratio, num_steps, offset=0):
        self.base_step = base_step
        self.step_ratio = step_ratio
        self.num_steps = num_steps
        self.offset = offset

    def _range(self):
        return range(self.num_steps)

    def __call__(self):
        for i in self._range():
            yield self.base_step * (self.step_ratio ** (-i + self.offset))",partial_docstr,0.7823691460055096,0.6592797783933518,0.5793871866295264,0.650137741046832,0.6548820071207067,0.8449367088607594,0.7142857142857143,0.643312101910828,0.9085643291473389,0.9029607772827148,0.9057539105415344,0.90351802110672,0.7505693877551022,0.9367816091954023,0.9017341040462427,0.872093023255814,0.9195402298850575,0.8132472457103462,0.9899665551839465,0.9664429530201343,0.9393939393939394,0.9896163940429688,0.9652737379074097,0.9772935509681702,0.9676539897918701,0.8702303053435114,0.930635838150289,0.8953488372093024,0.8713450292397661,0.9075144508670521,0.8070912688035248,0.9899328859060402,0.9595959595959596,0.9358108108108109,0.9890737533569336,0.9625813364982605,0.9756476879119873,0.9651665091514587,0.8575077862595419,0.4799803223592658,0.5497350434421792,0.5609108836760434,0.4492753623188406,0.36,0.5924503628890325,0.7812673715005223,0.7923021959976368,0.5362318840579711,0.26,0.5712013850432571,0.7613220289348689,0.776237134426565,0.5072463768115942,0.24
333474,dbarsam/python-vsgen,dbarsam_python-vsgen/vsgen/register.py,vsgen.register.VSGRegisterCommand,"class VSGRegisterCommand(object):
    """"""
    The VSGRegisterCommand class presents a simple command object to execute the register methods of a collection of VSGRegisterable objects.
    """"""

    def __init__(self, logname, registerables):
        """"""
        Initializes the instance with an collection of registerables.

        :param str logname:  The python logger log name.
        :param list registerables:  The list of VSGRegisterable class instances.
        """"""
        self._logname = logname
        self._registerables = registerables
        registerables_names = set([r.__registerable_name__ for r in registerables])
        if not registerables_names:
            self._message = ""Registering no files.""
        elif len(registerables_names) == 1:
            self._message = ""Registering {0}{1}"".format(next(iter(registerables_names)), 's' if len(registerables) > 1 else '')
        else:
            self._message = ""Registering a mixed collection of files.""

    def __enter__(self):
        """"""
        Enter the runtime context related to this object.
        """"""
        return self

    def __exit__(self, exc_type, exc_value, exc_traceback):
        """"""
        Exit the runtime context related to this object.
        """"""
        # Only return True to surpress the exception (if any)
        return False

    def execute(self):
        """"""
        Executes the command.
        """"""
        from vsgen.util.logger import VSGLogger

        VSGLogger.info(self._logname, self._message)
        start = time.clock()
        for i in self._registerables:
            i.register()
        end = time.clock()
        VSGLogger.info(self._logname, ""Register %s items in %s seconds:"", len(self._registerables), end - start)
        self._start = time.clock()","class VSGRegisterCommand(object):
    '''
    The VSGRegisterCommand class presents a simple command object to execute the register methods of a collection of VSGRegisterable objects.
    '''

    def __init__(self, logname, registerables):
    '''
        Initializes the instance with an collection of registerables.

        :param str logname:  The python logger log name.
        :param list registerables:  The list of VSGRegisterable class instances.
        '''
        pass

    def __enter__(self):
    '''
        Enter the runtime context related to this object.
        '''
        pass

    def __exit__(self, exc_type, exc_value, exc_traceback):
    '''
        Exit the runtime context related to this object.
        '''
        pass

    def execute(self):
    '''
        Executes the command.
        '''
        pass

",5,5,snippet_241,0.5,"class VSGRegisterCommand(object):
    '''
    The VSGRegisterCommand class presents a simple command object to execute the register methods of a collection of VSGRegisterable objects.
    '''

    def __init__(self, logname, registerables):
        '''
        Initializes the instance with an collection of registerables.

        :param str logname:  The python logger log name.
        :param list registerables:  The list of VSGRegisterable class instances.
        '''
        self.logger = logging.getLogger(logname)
        self.registerables = list(registerables)
        self._registered = []

    def __enter__(self):
        '''
        Enter the runtime context related to this object.
        '''
        self.execute()
        return self

    def __exit__(self, exc_type, exc_value, exc_traceback):
        '''
        Exit the runtime context related to this object.
        '''
        # Always attempt to unregister what was registered
        for reg in reversed(self._registered):
            try:
                reg.unregister()
                self.logger.info(""Unregistered %r"", reg)
            except Exception:
                self.logger.exception(""Error while unregistering %r"", reg)
        # Clear the list so repeated exits don't re-unregister
        self._registered.clear()
        # Do not suppress exceptions
        return False

    def execute(self):
        '''
        Executes the command.
        '''
        self._registered.clear()
        for reg in self.registerables:
            try:
                reg.register()
                self._registered.append(reg)
                self.logger.info(""Registered %r"", reg)
            except Exception:
                self.logger.exception(""Error while registering %r"", reg)
                # Roll back previously registered
                for prev in reversed(self._registered):
                    try:
                        prev.unregister()
                        self.logger.info(""Rolled back unregister of %r"", prev)
                    except Exception:
                        self.logger.exception(""Error while rolling back %r"", prev)
                self._registered.clear()
                raise
        return None","class VSGRegisterCommand(object):
    '''
    The VSGRegisterCommand class presents a simple command object to execute the register methods of a collection of VSGRegisterable objects.
    '''

    def __init__(self, logname, registerables):
        '''
        Initializes the instance with an collection of registerables.

        :param str logname:  The python logger log name.
        :param list registerables:  The list of VSGRegisterable class instances.
        '''
        self.logname = logname
        self.registerables = registerables
        self.logger = logging.getLogger(logname)

    def __enter__(self):
        '''
        Enter the runtime context related to this object.
        '''
        return self

    def __exit__(self, exc_type, exc_value, exc_traceback):
        '''
        Exit the runtime context related to this object.
        '''
        pass

    def execute(self):
        '''
        Executes the command.
        '''
        for registerable in self.registerables:
            registerable.register()","class VSGRegisterCommand(object):
    '''
    The VSGRegisterCommand class presents a simple command object to execute the register methods of a collection of VSGRegisterable objects.
    '''

    def __init__(self, logname, registerables):
        '''
        Initializes the instance with an collection of registerables.

        :param str logname:  The python logger log name.
        :param list registerables:  The list of VSGRegisterable class instances.
        '''
        self.logger = logging.getLogger(logname)
        self.registerables = registerables if registerables is not None else []

    def __enter__(self):
        '''
        Enter the runtime context related to this object.
        '''
        return self

    def __exit__(self, exc_type, exc_value, exc_traceback):
        '''
        Exit the runtime context related to this object.
        '''
        return False

    def execute(self):
        '''
        Executes the command.
        '''
        for registerable in self.registerables:
            try:
                registerable.register()
            except Exception as e:
                self.logger.error(f""Failed to register {registerable}: {e}"")",partial_docstr,0.5857142857142857,0.4354066985645933,0.40865384615384615,0.519047619047619,0.4640856523824666,0.6539440203562341,0.4362244897959184,0.35038363171355497,0.8448126912117004,0.8580371141433716,0.8513734936714172,0.8566960692405701,0.7677925842696635,0.6754098360655738,0.6138613861386139,0.5913621262458472,0.6557377049180328,0.24452931291484478,0.9213483146067416,0.7909604519774012,0.6931818181818182,0.9553813934326172,0.8355796337127686,0.8914735913276672,0.8461905717849731,0.7994248051948052,0.6811145510835913,0.5856697819314641,0.5517241379310345,0.65015479876161,0.3004040414173059,0.8708133971291866,0.6826923076923077,0.5942028985507246,0.9274407625198364,0.844947874546051,0.8842744827270508,0.8525308966636658,0.793652857142857,0.5528488443729357,0.3719000721320245,0.404310120174533,0.4351851851851852,0.0,0.5261405782617117,0.3220821378165009,0.3750727678229386,0.4074074074074074,0.0,0.5359822419626211,0.3574204577872444,0.3976196211743513,0.3888888888888889,0.0
554253,lpantano/seqcluster,lpantano_seqcluster/seqcluster/libs/thinkbayes.py,seqcluster.libs.thinkbayes.Pdf,"class Pdf(object):
    """"""Represents a probability density function (PDF).""""""

    def Density(self, x):
        """"""Evaluates this Pdf at x.

        Returns: float probability density
        """"""
        raise UnimplementedMethodException()

    def MakePmf(self, xs, name=''):
        """"""Makes a discrete version of this Pdf, evaluated at xs.

        xs: equally-spaced sequence of values

        Returns: new Pmf
        """"""
        pmf = Pmf(name=name)
        for x in xs:
            pmf.Set(x, self.Density(x))
        pmf.Normalize()
        return pmf","class Pdf(object):
    '''Represents a probability density function (PDF).'''

    def Density(self, x):
    '''Evaluates this Pdf at x.

        Returns: float probability density
        '''
        pass

    def MakePmf(self, xs, name=''):
    '''Makes a discrete version of this Pdf, evaluated at xs.

        xs: equally-spaced sequence of values

        Returns: new Pmf
        '''
        pass

",3,3,snippet_439,0.6,"class Pdf(object):
    '''Represents a probability density function (PDF).'''

    def Density(self, x):
        '''Evaluates this Pdf at x.

        Returns: float probability density
        '''
        raise NotImplementedError('Density must be implemented by subclasses')

    def MakePmf(self, xs, name=''):
        '''Makes a discrete version of this Pdf, evaluated at xs.

        xs: equally-spaced sequence of values

        Returns: new Pmf
        '''
        pmf = Pmf(name=name)
        if not xs:
            return pmf
        dx = xs[1] - xs[0] if len(xs) > 1 else 1.0
        for x in xs:
            pmf[x] = self.Density(x) * dx
        pmf.Normalize()
        return pmf","class Pdf(object):
    '''Represents a probability density function (PDF).'''

    def Density(self, x):
        '''Evaluates this Pdf at x.

        Returns: float probability density
        '''
        raise NotImplementedError

    def MakePmf(self, xs, name=''):
        '''Makes a discrete version of this Pdf, evaluated at xs.

        xs: equally-spaced sequence of values

        Returns: new Pmf
        '''
        from collections import Counter
        
        # Evaluate the PDF at each point in xs
        probs = [self.Density(x) for x in xs]
        
        # Create a PMF with these values
        pmf = Pmf(dict(zip(xs, probs)), name=name)
        return pmf","class Pdf(object):
    '''Represents a probability density function (PDF).'''

    def Density(self, x):
        '''Evaluates this Pdf at x.

        Returns: float probability density
        '''
        pass

    def MakePmf(self, xs, name=''):
        '''Makes a discrete version of this Pdf, evaluated at xs.

        xs: equally-spaced sequence of values

        Returns: new Pmf
        '''
        pmf = Pmf(name=name)
        for x in xs:
            pmf.Set(x, self.Density(x))
        pmf.Normalize()
        return pmf",partial_docstr,0.8258064516129031,0.7712418300653594,0.7152317880794703,0.8258064516129031,0.6075678022750373,0.7021276595744681,0.6,0.5323741007194245,0.9166929721832275,0.9722227454185486,0.9436416029930115,0.9663688540458679,0.8942318269230769,0.8133333333333332,0.7162162162162162,0.6301369863013699,0.7333333333333334,0.6137818520078622,0.71875,0.6141732283464567,0.5238095238095238,0.9178473949432373,0.9620742797851562,0.9394406080245972,0.9574607014656067,0.8565415189873418,0.9770992366412214,0.9612403100775193,0.9448818897637795,0.9770992366412214,0.7367508836266199,0.9339622641509434,0.8761904761904762,0.8173076923076923,0.9938324689865112,0.9705960750579834,0.98207688331604,0.9728707075119019,0.9824563157894737,0.6016253365167223,0.416339070475529,0.6019269814737136,0.5882352941176471,0.8,0.477982279117201,0.3965840524967035,0.5624038875015123,0.3529411764705882,0.6,0.7940236316596642,0.6912601470817418,0.6907167324980916,0.7941176470588235,1.0
103862,Brazelton-Lab/bio_utils,Brazelton-Lab_bio_utils/bio_utils/iterators/fastq.py,bio_utils.iterators.fastq.FastqEntry,"class FastqEntry:
    """"""A simple class to store data from FASTQ entries and write them

    Attributes:
            id (str): FASTQ ID (everything between the '@' and the first space
                of header line)

            description (str): FASTQ description (everything after the first
                space of the header line)

            sequence (str): FASTQ sequence

            quality (str): FASTQ quality csores
    """"""

    def __init__(self):
        """"""Initialize attributes to store FASTQ entry data""""""

        self.id = None
        self.description = None
        self.sequence = None
        self.quality = None

    def write(self):
        """"""Return FASTQ formatted string

        Returns:
            str: FASTQ formatted string containing entire FASTQ entry
        """"""

        if self.description:
            return '@{0} {1}{4}{2}{4}+{4}{3}{4}'.format(self.id,
                                                        self.description,
                                                        self.sequence,
                                                        self.quality,
                                                        os.linesep)
        else:
            return '@{0}{3}{1}{3}+{3}{2}{3}'.format(self.id,
                                                    self.sequence,
                                                    self.quality,
                                                    os.linesep)","class FastqEntry:
    '''A simple class to store data from FASTQ entries and write them

    Attributes:
            id (str): FASTQ ID (everything between the '@' and the first space
                of header line)

            description (str): FASTQ description (everything after the first
                space of the header line)

            sequence (str): FASTQ sequence

            quality (str): FASTQ quality csores
    '''

    def __init__(self):
    '''Initialize attributes to store FASTQ entry data'''
        pass

    def write(self):
    '''Return FASTQ formatted string

        Returns:
            str: FASTQ formatted string containing entire FASTQ entry
        '''
        pass

",3,3,snippet_745,0.8,"class FastqEntry:
    '''A simple class to store data from FASTQ entries and write them

    Attributes:
        id (str): FASTQ ID (everything between the '@' and the first space
            of header line)
        description (str): FASTQ description (everything after the first
            space of the header line)
        sequence (str): FASTQ sequence
        quality (str): FASTQ quality scores
    '''
    def __init__(self, header, sequence, quality):
        '''Initialize attributes to store FASTQ entry data'''
        header = header.rstrip()
        if header.startswith('@'):
            header = header[1:]
        parts = header.split(' ', 1)
        self.id = parts[0]
        self.description = parts[1] if len(parts) > 1 else ''
        self.sequence = sequence.rstrip()
        self.quality = quality.rstrip()

    def write(self):
        '''Return FASTQ formatted string

        Returns:
            str: FASTQ formatted string containing entire FASTQ entry
        '''
        hdr = '@' + self.id
        if self.description:
            hdr += ' ' + self.description
        return f""{hdr}\n{self.sequence}\n+\n{self.quality}\n""","class FastqEntry:
    '''A simple class to store data from FASTQ entries and write them

    Attributes:
            id (str): FASTQ ID (everything between the '@' and the first space
                of header line)

            description (str): FASTQ description (everything after the first
                space of the header line)

            sequence (str): FASTQ sequence

            quality (str): FASTQ quality scores
    '''

    def __init__(self):
        '''Initialize attributes to store FASTQ entry data'''
        self.id = """"
        self.description = """"
        self.sequence = """"
        self.quality = """"

    def write(self):
        '''Return FASTQ formatted string

        Returns:
            str: FASTQ formatted string containing entire FASTQ entry
        '''
        header = f""@{self.id}""
        if self.description:
            header += f"" {self.description}""
        return f""{header}\n{self.sequence}\n+\n{self.quality}\n""","class FastqEntry:
    '''A simple class to store data from FASTQ entries and write them

    Attributes:
            id (str): FASTQ ID (everything between the '@' and the first space
                of header line)

            description (str): FASTQ description (everything after the first
                space of the header line)

            sequence (str): FASTQ sequence

            quality (str): FASTQ quality csores
    '''

    def __init__(self):
        '''Initialize attributes to store FASTQ entry data'''
        self.id = """"
        self.description = """"
        self.sequence = """"
        self.quality = """"

    def write(self):
        '''Return FASTQ formatted string

        Returns:
            str: FASTQ formatted string containing entire FASTQ entry
        '''
        if self.description:
            header = f""@{self.id} {self.description}""
        else:
            header = f""@{self.id}""
        
        return f""{header}\n{self.sequence}\n+\n{self.quality}\n""",partial_docstr,0.7727272727272727,0.6335877862595419,0.5384615384615384,0.712121212121212,0.5290745978456278,0.7154471544715447,0.5142857142857142,0.4385245901639344,0.8812865018844604,0.8927676677703857,0.886989951133728,0.8916060924530029,0.7757598181818184,0.810126582278481,0.7489361702127659,0.6866952789699571,0.7932489451476793,0.5139257399457373,0.8789473684210526,0.6984126984126984,0.601063829787234,0.9486269950866699,0.9008646011352539,0.924129068851471,0.9054232835769653,0.8165155963302752,0.8333333333333333,0.773109243697479,0.7203389830508474,0.8250000000000001,0.5360657351765253,0.8883248730964467,0.6989795918367347,0.5846153846153846,0.9528622627258301,0.9054652452468872,0.9285593032836914,0.9099917411804199,0.8218408620689656,0.4296961800516432,0.522356551405405,0.6240143756977197,0.4,0.1724137931034483,0.5344780198194548,0.6375181305241729,0.6275970138877456,0.3555555555555555,0.5172413793103449,0.5400261288108388,0.6493493095097735,0.6379582708676813,0.3555555555555555,0.5172413793103449
300432,cloudnull/cloudlib,cloudnull_cloudlib/cloudlib/logger.py,cloudlib.logger.LogSetup,"class LogSetup(object):

    def __init__(self, max_size=500, max_backup=5, debug_logging=False,
                 colorized_messages=False):
        """"""Setup Logging.

        :param max_size: ``int``
        :param max_backup: ``int``
        :param debug_logging: ``bol``
        :param colorized_messages: ``bol``
        """"""
        self.max_size = (max_size * 1024 * 1024)
        self.max_backup = max_backup
        self.debug_logging = debug_logging
        self.format = None
        self.name = None
        if colorized_messages:
            logging._logRecordFactory = ColorLogRecord

    def default_logger(self, name=__name__, enable_stream=False,
                       enable_file=True):
        """"""Default Logger.

        This is set to use a rotating File handler and a stream handler.
        If you use this logger all logged output that is INFO and above will
        be logged, unless debug_logging is set then everything is logged.
        The logger will send the same data to a stdout as it does to the
        specified log file.

        You can disable the default handlers by setting either `enable_file` or
        `enable_stream` to `False`

        :param name: ``str``
        :param enable_stream: ``bol``
        :param enable_file: ``bol``
        :return: ``object``
        """"""
        if self.format is None:
            self.format = logging.Formatter(
                '%(asctime)s - %(module)s:%(levelname)s => %(message)s'
            )

        log = logging.getLogger(name)
        self.name = name

        if enable_file is True:
            file_handler = handlers.RotatingFileHandler(
                filename=self.return_logfile(filename='%s.log' % name),
                maxBytes=self.max_size,
                backupCount=self.max_backup
            )
            self.set_handler(log, handler=file_handler)

        if enable_stream is True or self.debug_logging is True:
            stream_handler = logging.StreamHandler()
            self.set_handler(log, handler=stream_handler)

        log.info('Logger [ %s ] loaded', name)
        return log

    def set_handler(self, log, handler):
        """"""Set the logging level as well as the handlers.

        :param log: ``object``
        :param handler: ``object``
        """"""
        if self.debug_logging is True:
            log.setLevel(logging.DEBUG)
            handler.setLevel(logging.DEBUG)
        else:
            log.setLevel(logging.INFO)
            handler.setLevel(logging.INFO)

        handler.name = self.name
        handler.setFormatter(self.format)
        log.addHandler(handler)

    @staticmethod
    def return_logfile(filename, log_dir='/var/log'):
        """"""Return a path for logging file.

        If ``log_dir`` exists and the userID is 0 the log file will be written
        to the provided log directory. If the UserID is not 0 or log_dir does
        not exist the log file will be written to the users home folder.

        :param filename: ``str``
        :param log_dir: ``str``
        :return: ``str``
        """"""
        if sys.platform == 'win32':
            user = getpass.getuser()
        else:
            user = os.getuid()
        home = os.path.expanduser('~')

        if not os.path.isdir(log_dir):
            return os.path.join(home, filename)

        log_dir_stat = os.stat(log_dir)
        if log_dir_stat.st_uid == user:
            return os.path.join(log_dir, filename)
        elif log_dir_stat.st_gid == user:
            return os.path.join(log_dir, filename)
        else:
            return os.path.join(home, filename)","class LogSetup(object):


    def __init__(self, max_size=500, max_backup=5, debug_logging=False,
                 colorized_messages=False):
    '''Setup Logging.

        :param max_size: ``int``
        :param max_backup: ``int``
        :param debug_logging: ``bol``
        :param colorized_messages: ``bol``
        '''
        pass

    def default_logger(self, name=__name__, enable_stream=False,
                       enable_file=True):
    '''Default Logger.

        This is set to use a rotating File handler and a stream handler.
        If you use this logger all logged output that is INFO and above will
        be logged, unless debug_logging is set then everything is logged.
        The logger will send the same data to a stdout as it does to the
        specified log file.

        You can disable the default handlers by setting either `enable_file` or
        `enable_stream` to `False`

        :param name: ``str``
        :param enable_stream: ``bol``
        :param enable_file: ``bol``
        :return: ``object``
        '''
        pass

    def set_handler(self, log, handler):
    '''Set the logging level as well as the handlers.

        :param log: ``object``
        :param handler: ``object``
        '''
        pass

    @staticmethod
    def return_logfile(filename, log_dir='/var/log'):
    '''Return a path for logging file.

        If ``log_dir`` exists and the userID is 0 the log file will be written
        to the provided log directory. If the UserID is not 0 or log_dir does
        not exist the log file will be written to the users home folder.

        :param filename: ``str``
        :param log_dir: ``str``
        :return: ``str``
        '''
        pass

",6,4,snippet_96,0.3181818181818182,"class LogSetup(object):
    class _ColorFormatter(logging.Formatter):
        COLOR_MAP = {
            logging.DEBUG:    '\033[36m',  # cyan
            logging.INFO:     '\033[32m',  # green
            logging.WARNING:  '\033[33m',  # yellow
            logging.ERROR:    '\033[31m',  # red
            logging.CRITICAL: '\033[41m',  # red background
        }
        RESET = '\033[0m'
        def format(self, record):
            orig_levelname = record.levelname
            color = self.COLOR_MAP.get(record.levelno, '')
            if color:
                record.levelname = f""{color}{orig_levelname}{self.RESET}""
            result = super().format(record)
            record.levelname = orig_levelname
            return result

    def __init__(self, max_size=500, max_backup=5, debug_logging=False,
                 colorized_messages=False):
        """"""
        Setup Logging.

        :param max_size: int
        :param max_backup: int
        :param debug_logging: bool
        :param colorized_messages: bool
        """"""
        self.max_size = max_size
        self.max_backup = max_backup
        self.debug_logging = debug_logging
        self.colorized = colorized_messages
        fmt = ""%(asctime)s - %(name)s - %(levelname)s - %(message)s""
        self._plain_formatter = logging.Formatter(fmt)
        if self.colorized:
            self._color_formatter = self._ColorFormatter(fmt)
        else:
            self._color_formatter = self._plain_formatter

    def default_logger(self, name=__name__, enable_stream=False,
                       enable_file=True):
        """"""
        Default Logger.

        :param name: str
        :param enable_stream: bool
        :param enable_file: bool
        :return: Logger
        """"""
        logger = logging.getLogger(name)
        # reset handlers to avoid duplicates
        for h in list(logger.handlers):
            logger.removeHandler(h)
        logger.propagate = False
        level = logging.DEBUG if self.debug_logging else logging.INFO
        logger.setLevel(level)

        if enable_stream:
            sh = logging.StreamHandler(sys.stdout)
            self.set_handler(logger, sh)

        if enable_file:
            # sanitize name for filename
            fname = f""{name.replace('.', '_')}.log""
            path = self.return_logfile(fname)
            fh = logging.handlers.RotatingFileHandler(
                path, maxBytes=self.max_size, backupCount=self.max_backup,
                encoding='utf-8'
            )
            self.set_handler(logger, fh)

        return logger

    def set_handler(self, log, handler):
        """"""
        Set the logging level as well as the handlers.

        :param log: Logger
        :param handler: Handler
        """"""
        level = logging.DEBUG if self.debug_logging else logging.INFO
        handler.setLevel(level)
        # choose formatter
        if isinstance(handler, logging.StreamHandler) and self.colorized:
            handler.setFormatter(self._color_formatter)
        else:
            handler.setFormatter(self._plain_formatter)
        log.addHandler(handler)

    @staticmethod
    def return_logfile(filename, log_dir='/var/log'):
        """"""
        Return a path for logging file.

        :param filename: str
        :param log_dir: str
        :return: str
        """"""
        use_dir = None
        try:
            is_root = (os.geteuid() == 0)
        except AttributeError:
            is_root = False
        if is_root and os.path.isdir(log_dir):
            use_dir = log_dir
        else:
            home = os.path.expanduser(""~"")
            use_dir = home
        return os.path.join(use_dir, filename)","class LogSetup(object):

    def __init__(self, max_size=500, max_backup=5, debug_logging=False,
                 colorized_messages=False):
        '''Setup Logging.

        :param max_size: ``int``
        :param max_backup: ``int``
        :param debug_logging: ``bol``
        :param colorized_messages: ``bol``
        '''
        self.max_size = max_size * 1024 * 1024  # Convert MB to bytes
        self.max_backup = max_backup
        self.debug_logging = debug_logging
        self.colorized_messages = colorized_messages

    def default_logger(self, name=__name__, enable_stream=False,
                       enable_file=True):
        '''Default Logger.

        This is set to use a rotating File handler and a stream handler.
        If you use this logger all logged output that is INFO and above will
        be logged, unless debug_logging is set then everything is logged.
        The logger will send the same data to a stdout as it does to the
        specified log file.

        You can disable the default handlers by setting either `enable_file` or
        `enable_stream` to `False`

        :param name: ``str``
        :param enable_stream: ``bol``
        :param enable_file: ``bol``
        :return: ``object``
        '''
        log = logging.getLogger(name)
        
        # Clear any existing handlers
        log.handlers = []
        
        # Set logging level
        if self.debug_logging:
            log.setLevel(logging.DEBUG)
        else:
            log.setLevel(logging.INFO)
        
        # Create formatter
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # Add file handler if enabled
        if enable_file:
            logfile = self.return_logfile(f""{name}.log"")
            file_handler = logging.handlers.RotatingFileHandler(
                logfile, maxBytes=self.max_size, backupCount=self.max_backup
            )
            file_handler.setFormatter(formatter)
            self.set_handler(log, file_handler)
        
        # Add stream handler if enabled
        if enable_stream:
            stream_handler = logging.StreamHandler()
            stream_handler.setFormatter(formatter)
            self.set_handler(log, stream_handler)
        
        return log

    def set_handler(self, log, handler):
        '''Set the logging level as well as the handlers.

        :param log: ``object``
        :param handler: ``object``
        '''
        if self.debug_logging:
            handler.setLevel(logging.DEBUG)
        else:
            handler.setLevel(logging.INFO)
        
        log.addHandler(handler)

    @staticmethod
    def return_logfile(filename, log_dir='/var/log'):
        '''Return a path for logging file.

        If ``log_dir`` exists and the userID is 0 the log file will be written
        to the provided log directory. If the UserID is not 0 or log_dir does
        not exist the log file will be written to the users home folder.

        :param filename: ``str``
        :param log_dir: ``str``
        :return: ``str``
        '''
        try:
            user_id = os.geteuid()
        except AttributeError:
            # Windows doesn't have geteuid
            user_id = 0 if os.name == 'nt' else 1000
            
        if user_id == 0 and os.path.exists(log_dir):
            return os.path.join(log_dir, filename)
        else:
            home_dir = os.path.expanduser('~')
            return os.path.join(home_dir, filename)","class LogSetup(object):

    def __init__(self, max_size=500, max_backup=5, debug_logging=False,
                 colorized_messages=False):
        '''Setup Logging.

        :param max_size: ``int``
        :param max_backup: ``int``
        :param debug_logging: ``bol``
        :param colorized_messages: ``bol``
        '''
        self.max_size = max_size * 1024 * 1024  # Convert MB to bytes
        self.max_backup = max_backup
        self.debug_logging = debug_logging
        self.colorized_messages = colorized_messages

    def default_logger(self, name=__name__, enable_stream=False,
                       enable_file=True):
        '''Default Logger.

        This is set to use a rotating File handler and a stream handler.
        If you use this logger all logged output that is INFO and above will
        be logged, unless debug_logging is set then everything is logged.
        The logger will send the same data to a stdout as it does to the
        specified log file.

        You can disable the default handlers by setting either `enable_file` or
        `enable_stream` to `False`

        :param name: ``str``
        :param enable_stream: ``bol``
        :param enable_file: ``bol``
        :return: ``object``
        '''
        log = logging.getLogger(name)
        log.handlers = []
        
        if self.debug_logging:
            log.setLevel(logging.DEBUG)
        else:
            log.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        if enable_stream:
            stream_handler = logging.StreamHandler(sys.stdout)
            stream_handler.setFormatter(formatter)
            self.set_handler(log, stream_handler)
        
        if enable_file:
            log_file = self.return_logfile(f'{name}.log')
            file_handler = logging.handlers.RotatingFileHandler(
                log_file, maxBytes=self.max_size, backupCount=self.max_backup
            )
            file_handler.setFormatter(formatter)
            self.set_handler(log, file_handler)
        
        return log

    def set_handler(self, log, handler):
        '''Set the logging level as well as the handlers.

        :param log: ``object``
        :param handler: ``object``
        '''
        if self.debug_logging:
            handler.setLevel(logging.DEBUG)
        else:
            handler.setLevel(logging.INFO)
        log.addHandler(handler)

    @staticmethod
    def return_logfile(filename, log_dir='/var/log'):
        '''Return a path for logging file.

        If ``log_dir`` exists and the userID is 0 the log file will be written
        to the provided log directory. If the UserID is not 0 or log_dir does
        not exist the log file will be written to the users home folder.

        :param filename: ``str``
        :param log_dir: ``str``
        :return: ``str``
        '''
        if os.path.exists(log_dir) and os.getuid() == 0:
            return os.path.join(log_dir, filename)
        else:
            home_dir = os.path.expanduser('~')
            return os.path.join(home_dir, filename)",partial_docstr,0.6028708133971291,0.3908872901678657,0.2980769230769231,0.4354066985645933,0.49138672186616,0.7217391304347827,0.48756218905472637,0.38854296388542964,0.8477441072463989,0.8520455956459045,0.84988933801651,0.8516134023666382,0.7678060323159784,0.8558139534883721,0.7412587412587414,0.6705607476635513,0.7697674418604652,0.7386029523584379,0.9121887287024901,0.8123359580052494,0.7450722733245729,0.9283528923988342,0.9282300472259521,0.9282914996147156,0.9282423257827759,0.8306530344827586,0.8786407766990291,0.7761557177615572,0.697560975609756,0.7742718446601942,0.7274378216369284,0.9537166900420757,0.8721910112359551,0.8002812939521801,0.9497333765029907,0.9289838075637817,0.9392439723014832,0.9310178756713867,0.8222240000000002,0.2900688789641161,0.1333626198608154,0.1382908262415038,0.6181818181818182,0.270440251572327,0.5641688188525061,0.6095239907630501,0.6068425367910569,0.6818181818181818,0.3584905660377358,0.5346583147364765,0.5979354950594812,0.5979018805245037,0.6409090909090909,0.3018867924528302
683602,qba73/circleclient,qba73_circleclient/circleclient/circleclient.py,circleclient.circleclient.User,"class User(object):
    """"""Represent a CircleCI authenticated user.

    Attributes:
        client: An instance of CircleClient object.
    """"""

    def __init__(self, client):
        self.client = client

    def info(self):
        """"""Return information about the user as a dictionary.""""""
        method = 'GET'
        url = '/me?circle-token={token}'.format(token=self.client.api_token)
        json_data = self.client.request(method, url)
        return json_data","class User(object):
    '''Represent a CircleCI authenticated user.

    Attributes:
        client: An instance of CircleClient object.
    '''

    def __init__(self, client):
        pass

    def info(self):
    '''Return information about the user as a dictionary.'''
        pass

",3,2,snippet_594,1.0,"class User(object):
    '''Represent a CircleCI authenticated user.

    Attributes:
        client: An instance of CircleClient object.
    '''

    def __init__(self, client):
        self.client = client

    def info(self):
        '''Return information about the user as a dictionary.'''
        return self.client._get('/user')","class User(object):
    '''Represent a CircleCI authenticated user.

    Attributes:
        client: An instance of CircleClient object.
    '''

    def __init__(self, client):
        self.client = client

    def info(self):
        '''Return information about the user as a dictionary.'''
        return self.client.get('/me')","class User(object):
    '''Represent a CircleCI authenticated user.

    Attributes:
        client: An instance of CircleClient object.
    '''

    def __init__(self, client):
        self.client = client

    def info(self):
        '''Return information about the user as a dictionary.'''
        return self.client.get('/me')",partial_docstr,0.7872340425531915,0.7173913043478262,0.6888888888888889,0.7446808510638298,0.41534891510615285,0.9130434782608695,0.7794117647058824,0.7014925373134329,0.9719185829162598,0.8813295364379883,0.9244099855422974,0.8896214365959167,0.8425941666666666,0.8085106382978724,0.7173913043478262,0.6888888888888889,0.7446808510638298,0.4091246043847474,0.9117647058823529,0.7910447761194029,0.7121212121212122,0.9745720624923706,0.8836080431938171,0.9268636107444763,0.8919332027435303,0.8425941666666666,0.8085106382978724,0.7173913043478262,0.6888888888888889,0.7446808510638298,0.4091246043847474,0.9117647058823529,0.7910447761194029,0.7121212121212122,0.9745720624923706,0.8836080431938171,0.9268636107444763,0.8919332027435303,0.8425941666666666,0.4479251282155259,0.4935131822285473,0.527353997300223,0.4375,0.3333333333333333,0.4479251282155259,0.4935131822285473,0.527353997300223,0.4375,0.3333333333333333,0.4479251282155259,0.4935131822285473,0.527353997300223,0.4375,0.3333333333333333
791647,theduke/django-baseline,theduke_django-baseline/django_baseline/views.py,django_baseline.views.UserViewMixin,"class UserViewMixin(object):
    """"""
    IMPORTANT: REQUIRES SaveHookMixin!

    This mixin alters a generic CREATE view that has a ""created_by"" field by
    automatically setting the user field to the current user when the form is
    submitted.
    The field name of the field to populate is specified by the user_field
    property and defaults to created_by.
    """"""

    user_field = ['created_by']


    def __init__(self, *args, **kwargs):
        super(UserViewMixin, self).__init__(*args, **kwargs)
        # Ensure that user_field is a list.
        if type(self.user_field) != list:
            self.user_field = [self.user_field]


    def get_initial(self):
        """"""
        Supply user object as initial data for the specified user_field(s).
        """"""

        data = super(UserViewMixin, self).get_initial()
        for k in self.user_field:
            data[k] = self.request.user

        return data


    def pre_save(self, instance):
        super(UserViewMixin, self).pre_save(instance)

        """"""
        Use SaveHookMixin pre_save to set the user.
        """"""
        if  self.request.user.is_authenticated():
            for field in self.user_field:
                setattr(instance, field, self.request.user)","class UserViewMixin(object):
    '''
    IMPORTANT: REQUIRES SaveHookMixin!

    This mixin alters a generic CREATE view that has a ""created_by"" field by
    automatically setting the user field to the current user when the form is
    submitted.
    The field name of the field to populate is specified by the user_field
    property and defaults to created_by.
    '''

    def __init__(self, *args, **kwargs):
        pass

    def get_initial(self):
    '''
        Supply user object as initial data for the specified user_field(s).
        '''
        pass

    def pre_save(self, instance):
        pass

",4,2,snippet_772,0.3,"class UserViewMixin(object):
    """"""
    IMPORTANT: REQUIRES SaveHookMixin!

    This mixin alters a generic CREATE view that has a ""created_by"" field by
    automatically setting the user field to the current user when the form is
    submitted.
    The field name of the field to populate is specified by the user_field
    property and defaults to created_by.
    """"""
    user_field = 'created_by'

    def __init__(self, *args, **kwargs):
        super(UserViewMixin, self).__init__(*args, **kwargs)

    def get_initial(self):
        """"""
        Supply user object as initial data for the specified user_field(s).
        """"""
        # Start with any initial data from parent
        try:
            initial = super(UserViewMixin, self).get_initial() or {}
        except AttributeError:
            initial = {}

        # Normalize to a list of field names
        fields = (self.user_field
                  if isinstance(self.user_field, (list, tuple))
                  else [self.user_field])

        for fld in fields:
            initial[fld] = self.request.user

        return initial

    def pre_save(self, instance):
        """"""
        Hook called by SaveHookMixin just before saving the instance.
        """"""
        # Normalize to a list of field names
        fields = (self.user_field
                  if isinstance(self.user_field, (list, tuple))
                  else [self.user_field])

        for fld in fields:
            setattr(instance, fld, self.request.user)

        return instance","class UserViewMixin(object):
    '''
    IMPORTANT: REQUIRES SaveHookMixin!

    This mixin alters a generic CREATE view that has a ""created_by"" field by
    automatically setting the user field to the current user when the form is
    submitted.
    The field name of the field to populate is specified by the user_field
    property and defaults to created_by.
    '''

    user_field = 'created_by'

    def __init__(self, *args, **kwargs):
        super(UserViewMixin, self).__init__(*args, **kwargs)

    def get_initial(self):
        '''
        Supply user object as initial data for the specified user_field(s).
        '''
        initial = super(UserViewMixin, self).get_initial()
        if hasattr(self, 'request') and self.request.user.is_authenticated:
            initial[self.user_field] = self.request.user
        return initial

    def pre_save(self, instance):
        if hasattr(self, 'request') and self.request.user.is_authenticated:
            setattr(instance, self.user_field, self.request.user)
        return instance","class UserViewMixin(object):
    '''
    IMPORTANT: REQUIRES SaveHookMixin!

    This mixin alters a generic CREATE view that has a ""created_by"" field by
    automatically setting the user field to the current user when the form is
    submitted.
    The field name of the field to populate is specified by the user_field
    property and defaults to created_by.
    '''

    def __init__(self, *args, **kwargs):
        super(UserViewMixin, self).__init__(*args, **kwargs)
        if not hasattr(self, 'user_field'):
            self.user_field = 'created_by'

    def get_initial(self):
        '''
        Supply user object as initial data for the specified user_field(s).
        '''
        initial = super(UserViewMixin, self).get_initial()
        if hasattr(self.request, 'user') and self.request.user.is_authenticated:
            if isinstance(self.user_field, (list, tuple)):
                for field in self.user_field:
                    initial[field] = self.request.user
            else:
                initial[self.user_field] = self.request.user
        return initial

    def pre_save(self, instance):
        super(UserViewMixin, self).pre_save(instance)
        if hasattr(self.request, 'user') and self.request.user.is_authenticated:
            if isinstance(self.user_field, (list, tuple)):
                for field in self.user_field:
                    setattr(instance, field, self.request.user)
            else:
                setattr(instance, self.user_field, self.request.user)",partial_docstr,0.8023255813953489,0.6432748538011694,0.5647058823529412,0.686046511627907,0.6911133269973972,0.8142414860681114,0.6708074534161491,0.6043613707165109,0.896470308303833,0.9403129816055298,0.917868435382843,0.9357366561889648,0.8159527607361962,0.8338983050847457,0.7303754266211603,0.6666666666666667,0.7728813559322034,0.6359396801901676,0.927038626609442,0.8189655172413793,0.7359307359307359,0.9533147811889648,0.9325926303863525,0.9428398609161377,0.934624195098877,0.8618434868421051,0.829971181556196,0.7304347826086955,0.6647230320699709,0.7550432276657061,0.676049231343899,0.7537091988130564,0.6666666666666666,0.6149253731343284,0.9383758306503296,0.9515014886856079,0.9448931217193604,0.950172483921051,0.8462724657534247,0.6162199893670373,0.4885716942650271,0.6386459255407844,0.6103896103896104,0.7272727272727273,0.5930889509719395,0.5316321856860818,0.5446197220977802,0.5324675324675324,0.7636363636363637,0.7259379500962396,0.5831227846395688,0.6193303144466885,0.7012987012987013,0.0
341523,django-crispy-forms/django-crispy-forms,crispy_forms/base.py,crispy_forms.base.KeepContext,"class KeepContext:
    """"""
    Context manager that receives a `django.template.Context` instance and a list of keys

    Once the context manager is exited, it removes `keys` from the context, to avoid
    side effects in later layout objects that may use the same context variables.

    Layout objects should use `extra_context` to introduce context variables, never
    touch context object themselves, that could introduce side effects.
    """"""

    def __init__(self, context, keys):
        self.context = context
        self.keys = keys

    def __enter__(self):
        pass

    def __exit__(self, type, value, traceback):
        for key in list(self.keys):
            if key in self.context:
                del self.context[key]","class KeepContext:
    '''
    Context manager that receives a `django.template.Context` instance and a list of keys

    Once the context manager is exited, it removes `keys` from the context, to avoid
    side effects in later layout objects that may use the same context variables.

    Layout objects should use `extra_context` to introduce context variables, never
    touch context object themselves, that could introduce side effects.
    '''

    def __init__(self, context, keys):
        pass

    def __enter__(self):
        pass

    def __exit__(self, type, value, traceback):
        pass

",4,1,snippet_146,1.0,"class KeepContext:
    '''
    Context manager that receives a `django.template.Context` instance and a list of keys

    Once the context manager is exited, it removes `keys` from the context, to avoid
    side effects in later layout objects that may use the same context variables.

    Layout objects should use `extra_context` to introduce context variables, never
    touch context object themselves, that could introduce side effects.
    '''

    def __init__(self, context, keys):
        self.context = context
        self.keys = keys

    def __enter__(self):
        return self.context

    def __exit__(self, exc_type, exc_value, traceback):
        for key in self.keys:
            try:
                del self.context[key]
            except (KeyError, AttributeError):
                # If the context doesnt support deletion or key is missing, ignore
                pass
        return False","class KeepContext:
    '''
    Context manager that receives a `django.template.Context` instance and a list of keys

    Once the context manager is exited, it removes `keys` from the context, to avoid
    side effects in later layout objects that may use the same context variables.

    Layout objects should use `extra_context` to introduce context variables, never
    touch context object themselves, that could introduce side effects.
    '''

    def __init__(self, context, keys):
        self.context = context
        self.keys = keys
        self.saved_values = {}

    def __enter__(self):
        # Save current values of keys that exist in context
        for key in self.keys:
            if key in self.context:
                self.saved_values[key] = self.context[key]
        return self.context

    def __exit__(self, type, value, traceback):
        # Remove keys from context
        for key in self.keys:
            if key in self.context:
                del self.context[key]
        
        # Restore previously saved values if they existed
        for key, value in self.saved_values.items():
            self.context[key] = value","class KeepContext:
    '''
    Context manager that receives a `django.template.Context` instance and a list of keys

    Once the context manager is exited, it removes `keys` from the context, to avoid
    side effects in later layout objects that may use the same context variables.

    Layout objects should use `extra_context` to introduce context variables, never
    touch context object themselves, that could introduce side effects.
    '''

    def __init__(self, context, keys):
        self.context = context
        self.keys = keys

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        for key in self.keys:
            if key in self.context:
                del self.context[key]",partial_docstr,0.9023255813953488,0.8262910798122065,0.7772511848341231,0.8558139534883721,0.7906765765620749,0.8491620111731844,0.7865168539325843,0.7401129943502824,0.9162682294845581,0.9813717007637024,0.9477031826972961,0.974448025226593,0.8921579411764705,0.7729083665338645,0.7389558232931727,0.7044534412955465,0.7729083665338645,0.6017284291372121,0.6375,0.602510460251046,0.5672268907563025,0.8984434008598328,0.9764761924743652,0.9358359575271606,0.9680680632591248,0.8276853389830507,0.9797979797979798,0.9591836734693877,0.9381443298969072,0.9797979797979798,0.9050753475854255,0.9741935483870968,0.9415584415584416,0.9084967320261438,0.9932487607002258,0.9920421838760376,0.9926450252532959,0.9921627044677734,0.97395859375,0.7525394130762038,0.6886927772321463,0.8085616492662172,0.6129032258064516,0.9,0.7364765759801819,0.5625691740897811,0.8526919685406242,0.5806451612903226,0.95,0.814666100239504,0.8779974297814521,0.8855056808539835,0.6451612903225806,0.85
623676,ovnicraft/suds2,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/ovnicraft_suds2/suds/xsd/sxbase.py,suds.xsd.sxbase.Iter.Frame,"class Frame:
    """"""A content iterator frame.""""""

    def __init__(self, sx):
        """"""
        @param sx: A schema object.
        @type sx: L{SchemaObject}

        """"""
        self.sx = sx
        self.items = sx.rawchildren
        self.index = 0

    def next(self):
        """"""
        Get the I{next} item in the frame's collection.

        @return: The next item or None
        @rtype: L{SchemaObject}

        """"""
        if self.index < len(self.items):
            result = self.items[self.index]
            self.index += 1
            return result
","class Frame:
    '''A content iterator frame.'''


    def __init__(self, sx):
    '''
        @param sx: A schema object.
        @type sx: L{SchemaObject}

        '''
        pass


    def next(self):
    '''
        Get the I{next} item in the frame's collection.

        @return: The next item or None
        @rtype: L{SchemaObject}

        '''
        pass

",3,3,snippet_159,0.6,"class Frame:
    '''A content iterator frame.'''

    def __init__(self, sx):
        '''
        @param sx: A schema object.
        @type sx: L{SchemaObject}
        '''
        self._iterator = iter(sx)

    def next(self):
        '''
        Get the I{next} item in the frame's collection.

        @return: The next item or None
        @rtype: L{SchemaObject}
        '''
        try:
            return next(self._iterator)
        except StopIteration:
            return None","class Frame:
    '''A content iterator frame.'''


    def __init__(self, sx):
        '''
        @param sx: A schema object.
        @type sx: L{SchemaObject}

        '''
        self.sx = sx
        self.index = 0
        self.collection = getattr(sx, 'content', [])


    def next(self):
        '''
        Get the I{next} item in the frame's collection.

        @return: The next item or None
        @rtype: L{SchemaObject}

        '''
        if self.index < len(self.collection):
            item = self.collection[self.index]
            self.index += 1
            return item
        return None","class Frame:
    '''A content iterator frame.'''

    def __init__(self, sx):
        '''
        @param sx: A schema object.
        @type sx: L{SchemaObject}
        '''
        self.sx = sx
        self.items = []
        self.index = 0
        
        # If sx has children or items, populate the frame
        if hasattr(sx, 'children') and sx.children:
            self.items = list(sx.children)
        elif hasattr(sx, 'items') and sx.items:
            self.items = list(sx.items)
        elif hasattr(sx, '__iter__'):
            try:
                self.items = list(sx)
            except:
                self.items = []

    def next(self):
        '''
        Get the I{next} item in the frame's collection.

        @return: The next item or None
        @rtype: L{SchemaObject}
        '''
        if self.index < len(self.items):
            item = self.items[self.index]
            self.index += 1
            return item
        return None",partial_docstr,0.7438016528925621,0.6722689075630252,0.6495726495726495,0.7438016528925621,0.47437150132357975,0.797979797979798,0.673469387755102,0.5979381443298969,0.9423395395278931,0.9100058078765869,0.9258905053138733,0.9131389260292053,0.84166825,0.8905109489051095,0.8148148148148148,0.7669172932330828,0.8613138686131387,0.709025630924827,0.8384615384615385,0.7364341085271318,0.6484375,0.9679564237594604,0.9707739949226379,0.9693631529808044,0.9704915285110474,0.9469702272727273,0.7150837988826816,0.6666666666666666,0.6285714285714286,0.7039106145251397,0.48614262002503456,0.5380952380952381,0.4880382775119617,0.4375,0.8632815480232239,0.9169020056724548,0.8892841935157776,0.9112420678138733,0.8312516875,0.3444517082754665,0.4113040356136755,0.4350742260596191,0.3714285714285714,0.16,0.5999763210824908,0.4864152246680756,0.5306329168047447,0.7428571428571429,0.64,0.5394953735001595,0.362247738354494,0.6128766127890013,0.7428571428571429,0.44
360810,edx/event-tracking,edx_event-tracking/eventtracking/backends/logger.py,eventtracking.backends.logger.LoggerBackend,"class LoggerBackend:
    """"""
    Event tracker backend that uses a python logger.

    Events are logged to the INFO level as JSON strings.
    """"""

    def __init__(self, **kwargs):
        """"""
        Event tracker backend that uses a python logger.

        `name` is an identifier for the logger, which should have
            been configured using the default python mechanisms.
        """"""
        name = kwargs.get('name', None)
        self.max_event_size = kwargs.get('max_event_size', MAX_EVENT_SIZE)
        self.event_logger = logging.getLogger(name)
        level = kwargs.get('level', 'info')
        self.log = getattr(self.event_logger, level.lower())

    def send(self, event):
        """"""Send the event to the standard python logger""""""
        event_str = json.dumps(event, cls=DateTimeJSONEncoder)

        # TODO: do something smarter than simply dropping the event on
        # the floor.
        if self.max_event_size is None or len(event_str) <= self.max_event_size:
            self.log(event_str)","class LoggerBackend:
    '''
    Event tracker backend that uses a python logger.

    Events are logged to the INFO level as JSON strings.
    '''

    def __init__(self, **kwargs):
    '''
        Event tracker backend that uses a python logger.

        `name` is an identifier for the logger, which should have
            been configured using the default python mechanisms.
        '''
        pass

    def send(self, event):
    '''Send the event to the standard python logger'''
        pass

",3,3,snippet_165,0.4285714285714285,"class LoggerBackend:
    '''
    Event tracker backend that uses a python logger.

    Events are logged to the INFO level as JSON strings.
    '''

    def __init__(self, **kwargs):
        '''
        Event tracker backend that uses a python logger.

        `name` is an identifier for the logger, which should have
            been configured using the default python mechanisms.
        '''
        name = kwargs.get('name', None)
        self.logger = logging.getLogger(name)

    def send(self, event):
        '''Send the event to the standard python logger'''
        try:
            payload = json.dumps(event, default=lambda o: o.__dict__)
        except (TypeError, ValueError):
            payload = str(event)
        self.logger.info(payload)","class LoggerBackend:
    '''
    Event tracker backend that uses a python logger.

    Events are logged to the INFO level as JSON strings.
    '''

    def __init__(self, **kwargs):
        '''
        Event tracker backend that uses a python logger.

        `name` is an identifier for the logger, which should have
            been configured using the default python mechanisms.
        '''
        name = kwargs.get('name', 'default')
        self.logger = logging.getLogger(name)

    def send(self, event):
        '''Send the event to the standard python logger'''
        self.logger.info(json.dumps(event))","class LoggerBackend:
    '''
    Event tracker backend that uses a python logger.

    Events are logged to the INFO level as JSON strings.
    '''

    def __init__(self, **kwargs):
        '''
        Event tracker backend that uses a python logger.

        `name` is an identifier for the logger, which should have
            been configured using the default python mechanisms.
        '''
        name = kwargs.get('name', __name__)
        self.logger = logging.getLogger(name)

    def send(self, event):
        '''Send the event to the standard python logger'''
        self.logger.info(json.dumps(event))",partial_docstr,0.6991150442477877,0.625,0.5945945945945945,0.6814159292035398,0.39849044738531786,0.868421052631579,0.6887417218543046,0.62,0.9300628900527954,0.8683751821517944,0.8981610536575317,0.8741732239723206,0.8309540714285714,0.7169811320754718,0.6476190476190476,0.6153846153846153,0.6886792452830189,0.30381691934351285,0.9338842975206612,0.825,0.7310924369747899,0.9675355553627014,0.8489642143249512,0.9043800830841064,0.8594974279403687,0.8261922142857143,0.7169811320754718,0.6476190476190476,0.6153846153846153,0.6886792452830189,0.31726757080325546,0.936,0.7983870967741935,0.7073170731707317,0.969211220741272,0.8503158092498779,0.9058789610862732,0.8608763217926025,0.8214303571428571,0.4557754253824594,0.4650343642701145,0.4802895594819455,0.5,0.3777777777777777,0.4145537346128878,0.4197908032596397,0.4651602463030225,0.484375,0.2888888888888888,0.4067412346128878,0.4197908032596397,0.4651602463030225,0.453125,0.2888888888888888
294139,clld/clldutils,clld_clldutils/src/clldutils/misc.py,clldutils.misc.UnicodeMixin,"class UnicodeMixin(object):
    """"""Portable label mixin.""""""

    def __unicode__(self):
        """"""a human readable label for the object.""""""
        return '%s' % self  # pragma: no cover

    def __str__(self):
        """"""a human readable label for the object, appropriately encoded (or not).""""""
        deprecated(""Use of deprecated class UnicodeMixin! Use object instead."")
        return self.__unicode__()","class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
    '''a human readable label for the object.'''
        pass

    def __str__(self):
    '''a human readable label for the object, appropriately encoded (or not).'''
        pass

",3,3,snippet_504,1.0,"class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
        '''a human readable label for the object.'''
        raise NotImplementedError('Subclasses must implement __unicode__()')

    def __str__(self):
        '''a human readable label for the object, appropriately encoded (or not).'''
        try:
            # Python 2: unicode() exists, __str__ must return bytes
            return unicode(self).encode('utf-8')
        except NameError:
            # Python 3: unicode() is NameError, __str__ should return str
            result = self.__unicode__()
            if isinstance(result, bytes):
                return result.decode('utf-8')
            return result","class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
        '''a human readable label for the object.'''
        raise NotImplementedError

    def __str__(self):
        '''a human readable label for the object, appropriately encoded (or not).'''
        return str(self.__unicode__())","class UnicodeMixin(object):
    '''Portable label mixin.'''

    def __unicode__(self):
        '''a human readable label for the object.'''
        return str(self)

    def __str__(self):
        '''a human readable label for the object, appropriately encoded (or not).'''
        return '<%s: %s>' % (self.__class__.__name__, id(self))",partial_docstr,0.564516129032258,0.4754098360655738,0.43333333333333335,0.5322580645161291,0.3728096509671366,0.46,0.3624161073825503,0.3108108108108108,0.7955699563026428,0.8861679434776306,0.8384286165237427,0.8761901259422302,0.8449627906976743,0.7857142857142857,0.7073170731707318,0.65,0.7857142857142857,0.4543140163423545,0.875,0.7464788732394366,0.6571428571428571,0.9372556209564209,0.8983287811279297,0.9173794388771057,0.9020754098892212,0.8930828301886793,0.8089887640449439,0.7126436781609196,0.6352941176470588,0.7640449438202247,0.4866735593462495,0.7526881720430108,0.5543478260869565,0.45054945054945056,0.9490230679512024,0.8967903852462769,0.9221676588058472,0.9017535448074341,0.8742150943396226,0.4998909190670466,0.2040731460661198,0.3193000540115904,0.4761904761904761,1.0,0.4256269704663379,0.2752695959817061,0.3081906668360266,0.2857142857142857,0.8333333333333334,0.3073049807781496,0.2923891578131963,0.3177831462517832,0.2857142857142857,0.3333333333333333
693643,ray-project/ray,rllib/policy/torch_mixins.py,rllib.policy.torch_mixins.ValueNetworkMixin,"class ValueNetworkMixin:
    """"""Assigns the `_value()` method to a TorchPolicy.

    This way, Policy can call `_value()` to get the current VF estimate on a
    single(!) observation (as done in `postprocess_trajectory_fn`).
    Note: When doing this, an actual forward pass is being performed.
    This is different from only calling `model.value_function()`, where
    the result of the most recent forward pass is being used to return an
    already calculated tensor.
    """"""

    def __init__(self, config):
        # When doing GAE, we need the value function estimate on the
        # observation.
        if config.get(""use_gae"") or config.get(""vtrace""):
            # Input dict is provided to us automatically via the Model's
            # requirements. It's a single-timestep (last one in trajectory)
            # input_dict.

            def value(**input_dict):
                input_dict = SampleBatch(input_dict)
                input_dict = self._lazy_tensor_dict(input_dict)
                model_out, _ = self.model(input_dict)
                # [0] = remove the batch dim.
                return self.model.value_function()[0].item()

        # When not doing GAE, we do not require the value function's output.
        else:

            def value(*args, **kwargs):
                return 0.0

        self._value = value

    def extra_action_out(self, input_dict, state_batches, model, action_dist):
        """"""Defines extra fetches per action computation.

        Args:
            input_dict (Dict[str, TensorType]): The input dict used for the action
                computing forward pass.
            state_batches (List[TensorType]): List of state tensors (empty for
                non-RNNs).
            model (ModelV2): The Model object of the Policy.
            action_dist: The instantiated distribution
                object, resulting from the model's outputs and the given
                distribution class.

        Returns:
            Dict[str, TensorType]: Dict with extra tf fetches to perform per
                action computation.
        """"""
        # Return value function outputs. VF estimates will hence be added to
        # the SampleBatches produced by the sampler(s) to generate the train
        # batches going into the loss function.
        return {
            SampleBatch.VF_PREDS: model.value_function(),
        }","class ValueNetworkMixin:
    '''Assigns the `_value()` method to a TorchPolicy.

    This way, Policy can call `_value()` to get the current VF estimate on a
    single(!) observation (as done in `postprocess_trajectory_fn`).
    Note: When doing this, an actual forward pass is being performed.
    This is different from only calling `model.value_function()`, where
    the result of the most recent forward pass is being used to return an
    already calculated tensor.
    '''

    def __init__(self, config):
        pass

            def value(**input_dict):
                        pass

            def value(**input_dict):
                        pass

    def extra_action_out(self, input_dict, state_batches, model, action_dist):
    '''Defines extra fetches per action computation.

        Args:
            input_dict (Dict[str, TensorType]): The input dict used for the action
                computing forward pass.
            state_batches (List[TensorType]): List of state tensors (empty for
                non-RNNs).
            model (ModelV2): The Model object of the Policy.
            action_dist: The instantiated distribution
                object, resulting from the model's outputs and the given
                distribution class.

        Returns:
            Dict[str, TensorType]: Dict with extra tf fetches to perform per
                action computation.
        '''
        pass

",5,2,snippet_171,0.5555555555555556,"class ValueNetworkMixin:
    """"""Assigns the `_value()` method to a TorchPolicy.

    This way, Policy can call `_value()` to get the current VF estimate on a
    single(!) observation (as done in `postprocess_trajectory_fn`).
    Note: When doing this, an actual forward pass is being performed.
    This is different from only calling `model.value_function()`, where
    the result of the most recent forward pass is being used to return an
    already calculated tensor.
    """"""

    def __init__(self, config):
        def _value(**input_dict):
            device = getattr(self, ""device"", torch.device(""cpu""))
            # Build batched input dict
            batched = {}
            state_batches = []
            for k, v in input_dict.items():
                if k == ""state"":
                    for s in v:
                        if isinstance(s, np.ndarray):
                            t = torch.from_numpy(s).to(device)
                        else:
                            t = s.to(device)
                        state_batches.append(t.unsqueeze(0))
                elif k == ""obs"":
                    if isinstance(v, np.ndarray):
                        t = torch.from_numpy(v).to(device)
                    else:
                        t = v.to(device)
                    batched[""obs""] = t.unsqueeze(0)
                elif k == ""prev_action"":
                    if isinstance(v, np.ndarray):
                        t = torch.from_numpy(v).to(device)
                    else:
                        t = v.to(device)
                    batched[""prev_action""] = t.unsqueeze(0)
                elif k == ""prev_reward"":
                    if isinstance(v, (float, int, np.generic)):
                        t = torch.tensor([v], dtype=torch.float32, device=device)
                    elif isinstance(v, np.ndarray):
                        t = torch.from_numpy(v).to(device)
                        t = t.unsqueeze(0)
                    else:
                        t = v.to(device).unsqueeze(0)
                    batched[""prev_reward""] = t
                else:
                    # Other inputs
                    if isinstance(v, np.ndarray):
                        t = torch.from_numpy(v).to(device).unsqueeze(0)
                        batched[k] = t
                    elif isinstance(v, torch.Tensor):
                        batched[k] = v.to(device).unsqueeze(0)
                    else:
                        batched[k] = v
            # Forward pass
            out, new_states, extra = self.model(batched, state_batches, explore=False)
            vf = self.model.value_function()
            # Return single value
            val = vf[0]
            return val.cpu().detach().numpy()
        self._value = _value
        self.value = _value
        self.value_exploration = _value

    def extra_action_out(self, input_dict, state_batches, model, action_dist):
        """"""Defines extra fetches per action computation.""""""
        vf = model.value_function()
        return {""vf_preds"": vf}","class ValueNetworkMixin:
    '''Assigns the `_value()` method to a TorchPolicy.

    This way, Policy can call `_value()` to get the current VF estimate on a
    single(!) observation (as done in `postprocess_trajectory_fn`).
    Note: When doing this, an actual forward pass is being performed.
    This is different from only calling `model.value_function()`, where
    the result of the most recent forward pass is being used to return an
    already calculated tensor.
    '''

    def __init__(self, config):
        def value(**input_dict):
            model_out, _ = self.model(input_dict, [], None)
            return self.model.value_function()[0]

        def value(**input_dict):
            model_out, _ = self.model(input_dict, [], None)
            return self.model.value_function()[0]

        self._value = value

    def extra_action_out(self, input_dict, state_batches, model, action_dist):
        '''Defines extra fetches per action computation.

        Args:
            input_dict (Dict[str, TensorType]): The input dict used for the action
                computing forward pass.
            state_batches (List[TensorType]): List of state tensors (empty for
                non-RNNs).
            model (ModelV2): The Model object of the Policy.
            action_dist: The instantiated distribution
                object, resulting from the model's outputs and the given
                distribution class.

        Returns:
            Dict[str, TensorType]: Dict with extra tf fetches to perform per
                action computation.
        '''
        return {
            ""vf_preds"": model.value_function(),
        }","class ValueNetworkMixin:
    '''Assigns the `_value()` method to a TorchPolicy.

    This way, Policy can call `_value()` to get the current VF estimate on a
    single(!) observation (as done in `postprocess_trajectory_fn`).
    Note: When doing this, an actual forward pass is being performed.
    This is different from only calling `model.value_function()`, where
    the result of the most recent forward pass is being used to return an
    already calculated tensor.
    '''

    def __init__(self, config):
        if config.get(""use_critic"", True):
            def value(**input_dict):
                input_dict = self._lazy_tensor_dict(input_dict)
                model_out, _ = self.model(input_dict)
                return self.model.value_function()[0]
        else:
            def value(**input_dict):
                return 0.0
        
        self._value = value

    def extra_action_out(self, input_dict, state_batches, model, action_dist):
        '''Defines extra fetches per action computation.

        Args:
            input_dict (Dict[str, TensorType]): The input dict used for the action
                computing forward pass.
            state_batches (List[TensorType]): List of state tensors (empty for
                non-RNNs).
            model (ModelV2): The Model object of the Policy.
            action_dist: The instantiated distribution
                object, resulting from the model's outputs and the given
                distribution class.

        Returns:
            Dict[str, TensorType]: Dict with extra tf fetches to perform per
                action computation.
        '''
        return {""vf_preds"": model.value_function()}",partial_docstr,0.48717948717948717,0.34726688102893893,0.3032258064516129,0.3814102564102564,0.35490476182527986,0.4918276374442793,0.3244047619047619,0.28017883755588674,0.7776246070861816,0.8214914798736572,0.7989563941955566,0.8168832659721375,0.7257325458248476,0.784708249496982,0.7393939393939394,0.7058823529411764,0.7605633802816901,0.5953995156251076,0.9461756373937678,0.8607954545454546,0.811965811965812,0.962478518486023,0.8823098540306091,0.9206523299217224,0.8897207379341125,0.8186292647058824,0.810379241516966,0.781563126252505,0.7525150905432595,0.8023952095808384,0.6290294863072159,0.9771428571428571,0.9283667621776505,0.8908045977011494,0.9517161846160889,0.8868049383163452,0.9181147217750549,0.892894983291626,0.9068636764705883,0.4260476573857067,0.3219175084408825,0.3368185756473992,0.5303030303030303,0.5151515151515151,0.4722019498685216,0.4806501756948008,0.5445212601429219,0.3787878787878788,0.4848484848484848,0.5168789949601992,0.4973023866785113,0.5702135931622855,0.5454545454545454,0.4545454545454545
407594,google/grumpy,google_grumpy/third_party/pythonparser/algorithm.py,pythonparser.algorithm.Visitor,"class Visitor:
    """"""
    A node visitor base class that does a traversal
    of the abstract syntax tree.

    This class is meant to be subclassed, with the subclass adding
    visitor methods. The visitor method should call ``self.generic_visit(node)``
    to continue the traversal; this allows to perform arbitrary
    actions both before and after traversing the children of a node.

    The visitor methods for the nodes are ``'visit_'`` +
    class name of the node.  So a `Try` node visit function would
    be `visit_Try`.
    """"""

    def generic_visit(self, node):
        """"""Called if no explicit visitor function exists for a node.""""""
        for field_name in node._fields:
            self.visit(getattr(node, field_name))

    def _visit_one(self, node):
        visit_attr = ""visit_"" + type(node).__name__
        if hasattr(self, visit_attr):
            return getattr(self, visit_attr)(node)
        else:
            return self.generic_visit(node)

    def visit(self, obj):
        """"""Visit a node or a list of nodes. Other values are ignored""""""
        if isinstance(obj, list):
            return [self.visit(elt) for elt in obj]
        elif isinstance(obj, ast.AST):
            return self._visit_one(obj)","class Visitor:
    '''
    A node visitor base class that does a traversal
    of the abstract syntax tree.

    This class is meant to be subclassed, with the subclass adding
    visitor methods. The visitor method should call ``self.generic_visit(node)``
    to continue the traversal; this allows to perform arbitrary
    actions both before and after traversing the children of a node.

    The visitor methods for the nodes are ``'visit_'`` +
    class name of the node.  So a `Try` node visit function would
    be `visit_Try`.
    '''

    def generic_visit(self, node):
    '''Called if no explicit visitor function exists for a node.'''
        pass

    def _visit_one(self, node):
        pass

    def visit(self, obj):
    '''Visit a node or a list of nodes. Other values are ignored'''
        pass

",4,3,snippet_244,0.5,"class Visitor:
    '''
    A node visitor base class that does a traversal
    of the abstract syntax tree.

    This class is meant to be subclassed, with the subclass adding
    visitor methods. The visitor method should call ``self.generic_visit(node)``
    to continue the traversal; this allows to perform arbitrary
    actions both before and after traversing the children of a node.

    The visitor methods for the nodes are ``'visit_'`` +
    class name of the node.  So a `Try` node visit function would
    be `visit_Try`.
    '''

    def generic_visit(self, node):
        '''Called if no explicit visitor function exists for a node.'''
        # Traverse all fields named in _fields
        for field in getattr(node, '_fields', ()):
            value = getattr(node, field, None)
            if isinstance(value, list):
                for item in value:
                    if hasattr(item, '__class__'):
                        self.visit(item)
            elif hasattr(value, '__class__'):
                self.visit(value)

    def _visit_one(self, node):
        # Only visit if it's a node-like object
        if node is None or not hasattr(node, '__class__'):
            return
        # Look for a method named visit_<ClassName>
        method = getattr(self, 'visit_' + node.__class__.__name__, None)
        if method is None:
            return self.generic_visit(node)
        return method(node)

    def visit(self, obj):
        '''Visit a node or a list of nodes. Other values are ignored'''
        if isinstance(obj, list):
            for node in obj:
                self._visit_one(node)
        else:
            self._visit_one(obj)","class Visitor:
    '''
    A node visitor base class that does a traversal
    of the abstract syntax tree.

    This class is meant to be subclassed, with the subclass adding
    visitor methods. The visitor method should call ``self.generic_visit(node)``
    to continue the traversal; this allows to perform arbitrary
    actions both before and after traversing the children of a node.

    The visitor methods for the nodes are ``'visit_'`` +
    class name of the node.  So a `Try` node visit function would
    be `visit_Try`.
    '''

    def generic_visit(self, node):
        '''Called if no explicit visitor function exists for a node.'''
        pass

    def _visit_one(self, node):
        method_name = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method_name, self.generic_visit)
        return visitor(node)

    def visit(self, obj):
        '''Visit a node or a list of nodes. Other values are ignored'''
        if hasattr(obj, '__iter__') and not isinstance(obj, str):
            for item in obj:
                self.visit(item)
        elif hasattr(obj, '__class__'):
            self._visit_one(obj)","class Visitor:
    '''
    A node visitor base class that does a traversal
    of the abstract syntax tree.

    This class is meant to be subclassed, with the subclass adding
    visitor methods. The visitor method should call ``self.generic_visit(node)``
    to continue the traversal; this allows to perform arbitrary
    actions both before and after traversing the children of a node.

    The visitor methods for the nodes are ``'visit_'`` +
    class name of the node.  So a `Try` node visit function would
    be `visit_Try`.
    '''

    def generic_visit(self, node):
        '''Called if no explicit visitor function exists for a node.'''
        for field, value in node.__dict__.items():
            self.visit(value)

    def _visit_one(self, node):
        method_name = 'visit_' + node.__class__.__name__
        visitor = getattr(self, method_name, self.generic_visit)
        return visitor(node)

    def visit(self, obj):
        '''Visit a node or a list of nodes. Other values are ignored'''
        if isinstance(obj, list):
            for item in obj:
                self.visit(item)
        elif hasattr(obj, '__dict__'):
            self._visit_one(obj)",partial_docstr,0.8244274809160306,0.7058823529411764,0.6323907455012854,0.7633587786259542,0.6003665106099638,0.7018970189701897,0.592391304347826,0.5204359673024523,0.9085054397583008,0.945077657699585,0.9264307618141174,0.941288411617279,0.798915054347826,0.8648648648648648,0.7673716012084592,0.7051671732522796,0.8288288288288289,0.6621923612968037,0.8641509433962264,0.7348484848484849,0.6577946768060836,0.9569650292396545,0.9463425874710083,0.9516241550445557,0.9473942518234253,0.8425212598425196,0.8961424332344213,0.7880597014925372,0.7267267267267268,0.8605341246290802,0.6950907031775567,0.8827838827838828,0.7463235294117647,0.6642066420664207,0.9677245616912842,0.9614143371582031,0.9645591378211975,0.9620417356491089,0.8871402362204724,0.5945718485539017,0.5184381271805006,0.7013126816692524,0.5,0.6585365853658537,0.5669367065401449,0.67320900867465,0.6712490684694076,0.4354838709677419,0.4878048780487805,0.5913130522122869,0.682954106171657,0.6858386219536512,0.4354838709677419,0.5609756097560976
689572,radzak/rtv-downloader,radzak_rtv-downloader/rtv/utils.py,rtv.utils.DevNull,"class DevNull:
    """"""
    DevNull class that has a no-op write and flush method.
    """"""
    def write(self, *args, **kwargs):
        pass

    def flush(self):
        pass","class DevNull:
    '''
    DevNull class that has a no-op write and flush method.
    '''

    def write(self, *args, **kwargs):
        pass

    def flush(self):
        pass

",3,1,snippet_189,1.0,"class DevNull:
    '''
    DevNull class that has a no-op write and flush method.
    '''

    def write(self, *args, **kwargs):
        return None

    def flush(self):
        return None","class DevNull:
    '''
    DevNull class that has a no-op write and flush method.
    '''

    def write(self, *args, **kwargs):
        pass

    def flush(self):
        pass","class DevNull:
    '''
    DevNull class that has a no-op write and flush method.
    '''

    def write(self, *args, **kwargs):
        pass

    def flush(self):
        pass",partial_docstr,0.8749999999999999,0.8260869565217391,0.7727272727272727,0.8749999999999999,0.7265802629223291,0.85,0.7692307692307693,0.6842105263157895,0.9615059494972229,0.9776817560195923,0.9695263504981995,0.976039707660675,0.9506177777777778,1.0,1.0,1.0,1.0,0.7984833595438284,0.9473684210526315,0.8918918918918919,0.8333333333333334,0.9981927275657654,0.9981927275657654,0.9981927275657654,0.9981927871704102,1.0,1.0,1.0,1.0,1.0,0.7984833595438284,0.9473684210526315,0.8918918918918919,0.8333333333333334,0.9981927275657654,0.9981927275657654,0.9981927275657654,0.9981927871704102,1.0,0.6023565885167979,0.5302459604351236,0.57148808593976,0.3076923076923077,1.0,0.880214542802702,0.7552498655792421,0.7656083056315659,1.0,1.0,0.880214542802702,0.7552498655792421,0.7656083056315659,1.0,1.0
787143,tensorflow/tensor2tensor,tensorflow_tensor2tensor/tensor2tensor/insights/graph.py,tensor2tensor.insights.graph.Graph,"class Graph(object):
  """"""A directed graph that can easily be JSON serialized for visualization.

  When serializing, it generates the following fields:
    edge: The list of all serialized Edge instances.
    node: The list of all serialized Vertex instances.
  """"""

  def __init__(self):
    self.vertices = []
    self.edges = []
    self.vertex_map = {}

  def new_vertex(self):
    """"""Creates and returns a new vertex.

    Returns:
      A new Vertex instance with a unique index.
    """"""
    vertex = Vertex(len(self.vertices))
    self.vertices.append(vertex)
    return vertex

  def get_vertex(self, key):
    """"""Returns or Creates a Vertex mapped by key.

    Args:
      key: A string reference for a vertex.  May refer to a new Vertex in which
      case it will be created.

    Returns:
      A the Vertex mapped to by key.
    """"""
    if key in self.vertex_map:
      return self.vertex_map[key]
    vertex = self.new_vertex()
    self.vertex_map[key] = vertex
    return vertex

  def add_edge(self, source, target):
    """"""Returns a new edge connecting source and target vertices.

    Args:
      source: The source Vertex.
      target: The target Vertex.

    Returns:
      A new Edge linking source to target.
    """"""
    edge = Edge(len(self.edges))
    self.edges.append(edge)
    source.out_edges.append(edge.idx)
    target.in_edges.append(edge.idx)
    edge.source = source.idx
    edge.target = target.idx
    return edge

  def to_dict(self):
    """"""Returns a simplified dictionary representing the Graph.

    Returns:
      A dictionary that can easily be serialized to JSON.
    """"""
    return {
        ""node"": [v.to_dict() for v in self.vertices],
        ""edge"": [e.to_dict() for e in self.edges]
    }","class Graph(object):
    '''A directed graph that can easily be JSON serialized for visualization.

  When serializing, it generates the following fields:
    edge: The list of all serialized Edge instances.
    node: The list of all serialized Vertex instances.
  '''

  def __init__(self):
    pass

  def new_vertex(self):
    '''Creates and returns a new vertex.

    Returns:
      A new Vertex instance with a unique index.
    '''
    pass

  def get_vertex(self, key):
    '''Returns or Creates a Vertex mapped by key.

    Args:
      key: A string reference for a vertex.  May refer to a new Vertex in which
      case it will be created.

    Returns:
      A the Vertex mapped to by key.
    '''
    pass

  def add_edge(self, source, target):
    '''Returns a new edge connecting source and target vertices.

    Args:
      source: The source Vertex.
      target: The target Vertex.

    Returns:
      A new Edge linking source to target.
    '''
    pass

  def to_dict(self):
    '''Returns a simplified dictionary representing the Graph.

    Returns:
      A dictionary that can easily be serialized to JSON.
    '''
    pass

",6,5,snippet_493,0.75,"class Graph(object):
    '''A directed graph that can easily be JSON serialized for visualization.

  When serializing, it generates the following fields:
    edge: The list of all serialized Edge instances.
    node: The list of all serialized Vertex instances.
  '''

    class Vertex(object):
        def __init__(self, index, key=None):
            self.index = index
            self.key = key

        def to_dict(self):
            d = {'index': self.index}
            if self.key is not None:
                d['key'] = self.key
            return d

    class Edge(object):
        def __init__(self, source, target):
            self.source = source
            self.target = target

        def to_dict(self):
            return {
                'source': self.source.index,
                'target': self.target.index
            }

    def __init__(self):
        self._vertices = []
        self._edges = []
        self._key_map = {}
        self._next_index = 0

    def new_vertex(self):
        v = Graph.Vertex(self._next_index)
        self._next_index += 1
        self._vertices.append(v)
        return v

    def get_vertex(self, key):
        if key in self._key_map:
            return self._key_map[key]
        v = Graph.Vertex(self._next_index, key)
        self._next_index += 1
        self._vertices.append(v)
        self._key_map[key] = v
        return v

    def add_edge(self, source, target):
        e = Graph.Edge(source, target)
        self._edges.append(e)
        return e

    def to_dict(self):
        return {
            'node': [v.to_dict() for v in self._vertices],
            'edge': [e.to_dict() for e in self._edges]
        }","class Graph(object):
    '''A directed graph that can easily be JSON serialized for visualization.

  When serializing, it generates the following fields:
    edge: The list of all serialized Edge instances.
    node: The list of all serialized Vertex instances.
  '''

    def __init__(self):
        self.vertices = {}
        self.edges = []
        self.next_vertex_id = 0

    def new_vertex(self):
        '''Creates and returns a new vertex.

        Returns:
          A new Vertex instance with a unique index.
        '''
        vertex = Vertex(self.next_vertex_id)
        self.vertices[self.next_vertex_id] = vertex
        self.next_vertex_id += 1
        return vertex

    def get_vertex(self, key):
        '''Returns or Creates a Vertex mapped by key.

        Args:
          key: A string reference for a vertex.  May refer to a new Vertex in which
          case it will be created.

        Returns:
          A the Vertex mapped to by key.
        '''
        if key not in self.vertices:
            vertex = Vertex(key)
            self.vertices[key] = vertex
        return self.vertices[key]

    def add_edge(self, source, target):
        '''Returns a new edge connecting source and target vertices.

        Args:
          source: The source Vertex.
          target: The target Vertex.

        Returns:
          A new Edge linking source to target.
        '''
        edge = Edge(source, target)
        self.edges.append(edge)
        return edge

    def to_dict(self):
        '''Returns a simplified dictionary representing the Graph.

        Returns:
          A dictionary that can easily be serialized to JSON.
        '''
        return {
            'node': [vertex.to_dict() for vertex in self.vertices.values()],
            'edge': [edge.to_dict() for edge in self.edges]
        }","class Graph(object):
    '''A directed graph that can easily be JSON serialized for visualization.

  When serializing, it generates the following fields:
    edge: The list of all serialized Edge instances.
    node: The list of all serialized Vertex instances.
  '''

    def __init__(self):
        self._vertices = {}
        self._vertex_counter = 0
        self._edges = []

    def new_vertex(self):
        '''Creates and returns a new vertex.

    Returns:
      A new Vertex instance with a unique index.
    '''
        vertex = Vertex(self._vertex_counter)
        self._vertex_counter += 1
        return vertex

    def get_vertex(self, key):
        '''Returns or Creates a Vertex mapped by key.

    Args:
      key: A string reference for a vertex.  May refer to a new Vertex in which
      case it will be created.

    Returns:
      A the Vertex mapped to by key.
    '''
        if key not in self._vertices:
            self._vertices[key] = self.new_vertex()
        return self._vertices[key]

    def add_edge(self, source, target):
        '''Returns a new edge connecting source and target vertices.

    Args:
      source: The source Vertex.
      target: The target Vertex.

    Returns:
      A new Edge linking source to target.
    '''
        edge = Edge(source, target)
        self._edges.append(edge)
        return edge

    def to_dict(self):
        '''Returns a simplified dictionary representing the Graph.

    Returns:
      A dictionary that can easily be serialized to JSON.
    '''
        return {
            'edge': [edge.to_dict() for edge in self._edges],
            'node': [vertex.to_dict() for vertex in self._vertices.values()]
        }",partial_docstr,0.5890109890109891,0.4150110375275939,0.33259423503325947,0.4967032967032967,0.46763695201027566,0.656934306569343,0.4634146341463415,0.36674816625916873,0.8904246687889099,0.8429154753684998,0.8660189509391785,0.8474370241165161,0.8075288064516133,0.9029535864978903,0.7923728813559323,0.7191489361702128,0.8565400843881856,0.6631528715741902,0.915068493150685,0.7774725274725275,0.6611570247933884,0.9308437705039978,0.9263178110122681,0.928575336933136,0.9267683029174805,0.8834819911504423,0.9114470842332614,0.8156182212581344,0.7320261437908496,0.8466522678185745,0.6386593632114963,0.9157303370786517,0.7746478873239436,0.6468926553672316,0.9524534344673157,0.9425480961799622,0.9474748373031616,0.9435293674468994,0.8938063716814159,0.4235770747087083,0.2277204040380634,0.2502229241509772,0.7232142857142857,0.4931506849315068,0.6158382621675602,0.6716043450828845,0.6795911693407811,0.6875,0.4246575342465753,0.6242546174468082,0.6481126414669354,0.658715025971961,0.6696428571428571,0.5205479452054794
335798,delph-in/pydelphin,delphin/tdl.py,tdl.Term,"class Term:
    """"""
    Base class for the terms of a TDL conjunction.

    All terms are defined to handle the binary '&' operator, which
    puts both into a Conjunction:

    >>> TypeIdentifier('a') & TypeIdentifier('b')
    <Conjunction object at 140008950372168>

    Args:
        docstring (str): documentation string

    Attributes:
        docstring (str): documentation string
    """"""
    def __init__(self, docstring=None):
        self.docstring = docstring

    def __repr__(self):
        return ""<{} object at {}>"".format(
            type(self).__name__, id(self))

    def __and__(self, other):
        if isinstance(other, Term):
            return Conjunction([self, other])
        elif isinstance(other, Conjunction):
            return Conjunction([self] + other._terms)
        else:
            return NotImplemented","class Term:
    '''
    Base class for the terms of a TDL conjunction.

    All terms are defined to handle the binary '&' operator, which
    puts both into a Conjunction:

    >>> TypeIdentifier('a') & TypeIdentifier('b')
    <Conjunction object at 140008950372168>

    Args:
        docstring (str): documentation string

    Attributes:
        docstring (str): documentation string
    '''

    def __init__(self, docstring=None):
        pass

    def __repr__(self):
        pass

    def __and__(self, other):
        pass

",4,1,snippet_74,0.75,"class Term:
    '''
    Base class for the terms of a TDL conjunction.

    All terms are defined to handle the binary '&' operator, which
    puts both into a Conjunction:

    >>> TypeIdentifier('a') & TypeIdentifier('b')
    <Conjunction object at 140008950372168>

    Args:
        docstring (str): documentation string

    Attributes:
        docstring (str): documentation string
    '''

    def __init__(self, docstring=None):
        self.docstring = docstring

    def __repr__(self):
        cls = self.__class__.__name__
        if self.docstring is None:
            return f""{cls}()""
        return f""{cls}({self.docstring!r})""

    def __and__(self, other):
        from itertools import chain
        from types import SimpleNamespace

        # Lazy import to avoid circularity if Conjunction is in another module
        try:
            Conjunction = globals()['Conjunction']
        except KeyError:
            raise NameError(""Conjunction class is not defined"")

        # Flatten if chaining multiple &
        if isinstance(self, Conjunction) and isinstance(other, Conjunction):
            terms = list(chain(self.terms, other.terms))
        elif isinstance(self, Conjunction):
            terms = list(self.terms) + [other]
        elif isinstance(other, Conjunction):
            terms = [self] + list(other.terms)
        else:
            terms = [self, other]

        return Conjunction(terms)","class Term:
    '''
    Base class for the terms of a TDL conjunction.

    All terms are defined to handle the binary '&' operator, which
    puts both into a Conjunction:

    >>> TypeIdentifier('a') & TypeIdentifier('b')
    <Conjunction object at 140008950372168>

    Args:
        docstring (str): documentation string

    Attributes:
        docstring (str): documentation string
    '''

    def __init__(self, docstring=None):
        self.docstring = docstring

    def __repr__(self):
        return f""<{self.__class__.__name__} object at {hex(id(self))}>""

    def __and__(self, other):
        from .conjunction import Conjunction
        return Conjunction([self, other])","class Term:
    '''
    Base class for the terms of a TDL conjunction.

    All terms are defined to handle the binary '&' operator, which
    puts both into a Conjunction:

    >>> TypeIdentifier('a') & TypeIdentifier('b')
    <Conjunction object at 140008950372168>

    Args:
        docstring (str): documentation string

    Attributes:
        docstring (str): documentation string
    '''

    def __init__(self, docstring=None):
        self.docstring = docstring

    def __repr__(self):
        return f""<{self.__class__.__name__} object at {id(self)}>""

    def __and__(self, other):
        from .conjunction import Conjunction
        return Conjunction([self, other])",partial_docstr,0.6639004149377594,0.5606694560669456,0.49789029535864976,0.6390041493775933,0.5025924584697885,0.5986394557823129,0.49146757679180886,0.4315068493150685,0.8498123288154602,0.9415029287338257,0.8933109641075134,0.9314529895782471,0.7826108695652173,0.8727272727272728,0.7975460122699386,0.7577639751552795,0.8484848484848484,0.7091318234949507,0.9308176100628931,0.8481012658227848,0.7834394904458599,0.9694726467132568,0.9325246214866638,0.9506397247314453,0.93609219789505,0.8333349999999999,0.8780487804878049,0.8024691358024691,0.7625,0.8536585365853658,0.6996298121966035,0.9358974358974359,0.8580645161290322,0.7922077922077922,0.9712637066841125,0.9318500757217407,0.9511487483978271,0.9356468319892883,0.8446985227272727,0.4131943578236414,0.3822970527522212,0.6736718679040469,0.4468085106382978,0.15,0.4892044194653802,0.6632815253151076,0.6605574291421576,0.3829787234042553,0.25,0.4892044194653802,0.6632815253151076,0.6605574291421576,0.3829787234042553,0.25
110096,Contraz/demosys-py,Contraz_demosys-py/demosys/opengl/program.py,program.ShaderSource,"class ShaderSource:
    """"""
    Helper class representing a single shader type
    """"""
    def __init__(self, shader_type: str, name: str, source: str):
        self.type = shader_type
        self.name = name
        self.source = source.strip()
        self.lines = self.source.split('\n')

        # Make sure version is present
        if not self.lines[0].startswith(""#version""):
            self.print()
            raise ShaderError(
                ""Missing #version in {}. A version must be defined in the first line"".format(self.name),
            )

        # Add preprocessors to source VERTEX_SHADER, FRAGMENT_SHADER etc.
        self.lines.insert(1, ""#define {} 1"".format(self.type))

        self.source = '\n'.join(self.lines)

    def find_out_attribs(self):
        """"""
        Get all out attributes in the shader source.

        :return: List of attribute names
        """"""
        names = []
        for line in self.lines:
            if line.strip().startswith(""out ""):
                names.append(line.split()[2].replace(';', ''))
        return names

    def print(self):
        """"""Print the shader lines""""""
        print(""---[ START {} ]---"".format(self.name))

        for i, line in enumerate(self.lines):
            print(""{}: {}"".format(str(i).zfill(3), line))

        print(""---[ END {} ]---"".format(self.name))","class ShaderSource:
    '''
    Helper class representing a single shader type
    '''

    def __init__(self, shader_type: str, name: str, source: str):
        pass

    def find_out_attribs(self):
    '''
        Get all out attributes in the shader source.

        :return: List of attribute names
        '''
        pass

    def print(self):
    '''Print the shader lines'''
        pass

",4,3,snippet_612,0.5,"class ShaderSource:
    '''
    Helper class representing a single shader type
    '''

    def __init__(self, shader_type: str, name: str, source: str):
        self.shader_type = shader_type
        self.name = name
        self.source = source

    def find_out_attribs(self):
        '''
        Get all out attributes in the shader source.

        :return: List of attribute names
        '''
        attrs = []
        for line in self.source.splitlines():
            code = line.split('//', 1)[0]
            match = re.match(r'\s*out\b(?:\s+\w+)*\s+([^;]+);', code)
            if match:
                names = match.group(1)
                for part in names.split(','):
                    name = part.strip().split()[0]
                    # strip array syntax if present
                    name = re.match(r'(\w+)', name).group(1)
                    attrs.append(name)
        return attrs

    def print(self):
        '''Print the shader lines'''
        for line in self.source.splitlines():
            print(line)","class ShaderSource:
    '''
    Helper class representing a single shader type
    '''

    def __init__(self, shader_type: str, name: str, source: str):
        self.shader_type = shader_type
        self.name = name
        self.source = source
        self.lines = source.split('\n')

    def find_out_attribs(self):
        '''
        Get all out attributes in the shader source.

        :return: List of attribute names
        '''
        out_attribs = []
        out_pattern = r'\bout\s+\w+\s+(\w+)'
        
        for line in self.lines:
            matches = re.findall(out_pattern, line)
            out_attribs.extend(matches)
        
        return out_attribs

    def print(self):
        '''Print the shader lines'''
        for i, line in enumerate(self.lines, 1):
            print(f""{i:3}: {line}"")","class ShaderSource:
    '''
    Helper class representing a single shader type
    '''

    def __init__(self, shader_type: str, name: str, source: str):
        self.shader_type = shader_type
        self.name = name
        self.source = source

    def find_out_attribs(self):
        '''
        Get all out attributes in the shader source.

        :return: List of attribute names
        '''
        pattern = r'\bout\s+\w+\s+(\w+)\s*;'
        matches = re.findall(pattern, self.source)
        return matches

    def print(self):
        '''Print the shader lines'''
        lines = self.source.split('\n')
        for i, line in enumerate(lines, 1):
            print(f""{i:3d}: {line}"")",partial_docstr,0.6236559139784946,0.41155234657039713,0.3490909090909091,0.49462365591397855,0.343613554415827,0.7569721115537849,0.512,0.37349397590361444,0.8434187769889832,0.8100371360778809,0.8263909816741943,0.8132559061050415,0.7842445818181822,0.6153846153846153,0.49612403100775193,0.4296875,0.6,0.2685510156830935,0.788659793814433,0.6062176165803109,0.5104166666666666,0.8652219176292419,0.8040125370025635,0.8334949612617493,0.8097409009933472,0.8012141090909096,0.5910931174089068,0.4816326530612245,0.4279835390946502,0.5344129554655872,0.21774449612484278,0.8128654970760234,0.6352941176470588,0.5325443786982249,0.8422109484672546,0.7881607413291931,0.814289927482605,0.7932515740394592,0.7830324727272726,0.3771533709469706,0.2895337557469305,0.3158180527259036,0.4295774647887324,0.4736842105263157,0.3222090906087899,0.2687897502855073,0.3117441658931662,0.3661971830985915,0.3421052631578947,0.3052078762345334,0.2329433687593071,0.286627943443467,0.3591549295774648,0.3421052631578947
213688,acutesoftware/AIKIF,acutesoftware_AIKIF/aikif/lib/cls_goal.py,aikif.lib.cls_goal.Goal,"class Goal(object):
    """""" 
    base class for handling various goals for AIKIF, usually in string format, but
    has methods to load/save and compare.
    name: title of the goal
    id: id of the goal - obtain from Goals class or database
    success: whether the goal has been successful or not
    """"""
        
    def __init__(self, name='New Goal', plans=None):
        self.name = name
        self.id = 1  
        self.success = False
        self.plans = plans
        self.start_date = datetime.datetime.now().strftime(""%I:%M%p %d-%B-%Y"")
        
    def __str__(self):
        return self.name

    def get_name(self):
        return self.name
        
    def find_best_plan(self):
        """"""
        Main logic in class which tries different plans according to a
        strategy (no idea how as yet) on test data, then runs that plan
        to simulate a result
        """"""
        for plan in self.plans:
            print(""running plan "", plan[0])
            
        
    def check_for_success(self):
        """""" do the checking to see if goal has reached its target
        This is usually overloaded by other classes, and for numerical
        tests is simply if maximise == True:
                            if TARGET > CURRENT:
                                return True
                            else:
                                return False
                        else:
                            if TARGET < CURRENT:
                                return True
                            else:
                                return False
        """"""
        return False","class Goal(object):
    ''' 
    base class for handling various goals for AIKIF, usually in string format, but
    has methods to load/save and compare.
    name: title of the goal
    id: id of the goal - obtain from Goals class or database
    success: whether the goal has been successful or not
    '''

    def __init__(self, name='New Goal', plans=None):
        pass

    def __str__(self):
        pass

    def get_name(self):
        pass

    def find_best_plan(self):
    '''
        Main logic in class which tries different plans according to a
        strategy (no idea how as yet) on test data, then runs that plan
        to simulate a result
        '''
        pass

    def check_for_success(self):
    ''' do the checking to see if goal has reached its target
        This is usually overloaded by other classes, and for numerical
        tests is simply if maximise == True:
                            if TARGET > CURRENT:
                                return True
                            else:
                                return False
                        else:
                            if TARGET < CURRENT:
                                return True
                            else:
                                return False
        '''
        pass

",6,3,snippet_370,0.375,"class Goal(object):
    ''' 
    base class for handling various goals for AIKIF, usually in string format, but
    has methods to load/save and compare.
    name: title of the goal
    id: id of the goal - obtain from Goals class or database
    success: whether the goal has been successful or not
    '''

    def __init__(self, name='New Goal', plans=None):
        self.name = name
        self.id = str(uuid.uuid4())
        self.plans = plans if plans is not None else []
        self.success = False

    def __str__(self):
        return f""Goal(id={self.id}, name={self.name}, success={self.success})""

    def get_name(self):
        return self.name

    def find_best_plan(self):
        best = None
        best_score = None
        for plan in self.plans:
            score = getattr(plan, 'score', None)
            if score is None:
                try:
                    score = plan.evaluate()
                except Exception:
                    continue
            if best_score is None or score > best_score:
                best = plan
                best_score = score
        return best

    def check_for_success(self):
        return bool(self.success)","class Goal(object):
    ''' 
    base class for handling various goals for AIKIF, usually in string format, but
    has methods to load/save and compare.
    name: title of the goal
    id: id of the goal - obtain from Goals class or database
    success: whether the goal has been successful or not
    '''

    def __init__(self, name='New Goal', plans=None):
        self.name = name
        self.id = None
        self.success = False
        self.plans = plans if plans is not None else []

    def __str__(self):
        return f""Goal(name='{self.name}', id={self.id}, success={self.success})""

    def get_name(self):
        return self.name

    def find_best_plan(self):
        '''
        Main logic in class which tries different plans according to a
        strategy (no idea how as yet) on test data, then runs that plan
        to simulate a result
        '''
        # Base implementation - simply return the first plan if available
        if self.plans:
            return self.plans[0]
        return None

    def check_for_success(self):
        ''' do the checking to see if goal has reached its target
        This is usually overloaded by other classes, and for numerical
        tests is simply if maximise == True:
                            if TARGET > CURRENT:
                                return True
                            else:
                                return False
                        else:
                            if TARGET < CURRENT:
                                return True
                            else:
                                return False
        '''
        # Base implementation - return the current success status
        return self.success","class Goal(object):
    ''' 
    base class for handling various goals for AIKIF, usually in string format, but
    has methods to load/save and compare.
    name: title of the goal
    id: id of the goal - obtain from Goals class or database
    success: whether the goal has been successful or not
    '''

    def __init__(self, name='New Goal', plans=None):
        self.name = name
        self.id = None
        self.success = False
        self.plans = plans if plans is not None else []
        self.current_plan = None
        self.target = None
        self.current = None
        self.maximise = True

    def __str__(self):
        return f""Goal: {self.name} (ID: {self.id}, Success: {self.success})""

    def get_name(self):
        return self.name

    def find_best_plan(self):
        '''
        Main logic in class which tries different plans according to a
        strategy (no idea how as yet) on test data, then runs that plan
        to simulate a result
        '''
        if not self.plans:
            return None
        
        best_plan = None
        best_score = None
        
        for plan in self.plans:
            score = self._evaluate_plan(plan)
            if best_score is None or score > best_score:
                best_score = score
                best_plan = plan
        
        self.current_plan = best_plan
        return best_plan

    def _evaluate_plan(self, plan):
        return 0

    def check_for_success(self):
        ''' do the checking to see if goal has reached its target
        This is usually overloaded by other classes, and for numerical
        tests is simply if maximise == True:
                            if TARGET > CURRENT:
                                return True
                            else:
                                return False
                        else:
                            if TARGET < CURRENT:
                                return True
                            else:
                                return False
        '''
        if self.target is None or self.current is None:
            return False
        
        if self.maximise:
            if self.current >= self.target:
                self.success = True
                return True
            else:
                self.success = False
                return False
        else:
            if self.current <= self.target:
                self.success = True
                return True
            else:
                self.success = False
                return False",partial_docstr,0.6374269005847953,0.5117647058823529,0.4674556213017752,0.5614035087719297,0.5056586063098456,0.735632183908046,0.5576923076923077,0.5057915057915058,0.8852683305740356,0.8159886598587036,0.8492178320884705,0.8224248290061951,0.7992444318181818,0.852791878172589,0.8061224489795918,0.7692307692307693,0.8477157360406091,0.7437224953332832,0.8038585209003215,0.7354838709677419,0.6957928802588996,0.9429901838302612,0.9342987537384033,0.9386243224143982,0.9351606965065002,0.8556444881889763,0.7238493723849372,0.6890756302521008,0.6540084388185654,0.7238493723849372,0.52242423025955,0.58,0.512249443207127,0.4799107142857143,0.9094251990318298,0.9306250214576721,0.9199029803276062,0.9284605979919434,0.7855413602941175,0.5047730763611564,0.3782718036788456,0.4051883178577343,0.5689655172413793,0.6666666666666666,0.6422353539373749,0.7083415906685777,0.8088756871498871,0.5517241379310345,0.5,0.6246477680760734,0.5264221482511774,0.8304064719458366,0.5862068965517241,0.5555555555555556
14569,Azure/azure-cli-extensions,src/application-insights/azext_applicationinsights/vendored_sdks/mgmt_applicationinsights/v2020_02_02_preview/_application_insights_management_client.py,azext_applicationinsights.vendored_sdks.mgmt_applicationinsights.v2020_02_02_preview._application_insights_management_client.ApplicationInsightsManagementClient,"class ApplicationInsightsManagementClient(object):
    """"""Composite Swagger for Application Insights Management Client.

    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2020_02_02_preview.operations.ComponentsOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    """"""

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        # type: (...) -> None
        if not base_url:
            base_url = 'https://management.azure.com'
        self._config = ApplicationInsightsManagementClientConfiguration(credential, subscription_id, **kwargs)
        self._client = ARMPipelineClient(base_url=base_url, config=self._config, **kwargs)

        client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
        self._serialize = Serializer(client_models)
        self._deserialize = Deserializer(client_models)

        self.components = ComponentsOperations(
            self._client, self._config, self._serialize, self._deserialize)

    def close(self):
        # type: () -> None
        self._client.close()

    def __enter__(self):
        # type: () -> ApplicationInsightsManagementClient
        self._client.__enter__()
        return self

    def __exit__(self, *exc_details):
        # type: (Any) -> None
        self._client.__exit__(*exc_details)","class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2020_02_02_preview.operations.ComponentsOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        pass

    def close(self):
        pass

    def __enter__(self):
        pass

    def __exit__(self, *exc_details):
        pass

",5,1,snippet_112,0.3636363636363636,"class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2020_02_02_preview.operations.ComponentsOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        self.credential = credential
        self.subscription_id = subscription_id
        self.base_url = base_url or ""https://management.azure.com""
        self.components = ComponentsOperations(
            credential=self.credential,
            subscription_id=self.subscription_id,
            base_url=self.base_url,
            **kwargs
        )

    def close(self):
        # nothing to close for this client
        return

    def __enter__(self):
        return self

    def __exit__(self, *exc_details):
        self.close()","class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2020_02_02_preview.operations.ComponentsOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        from azure.mgmt.applicationinsights.v2020_02_02_preview.operations import ComponentsOperations
        from azure.core.pipeline import Pipeline
        from azure.core.pipeline.transport import RequestsTransport
        from azure.core.pipeline.policies import (
            BearerTokenCredentialPolicy,
            ContentDecodePolicy,
            DistributedTracingPolicy,
            HttpLoggingPolicy,
            RequestIdPolicy,
            RetryPolicy,
            UserAgentPolicy,
        )
        from azure.mgmt.core.policies import ARMChallengeAuthenticationPolicy, ARMHttpLoggingPolicy

        self._config = kwargs.get('config') or self._create_default_config(credential, subscription_id, base_url, **kwargs)
        self._client = kwargs.get('client') or self._create_client(self._config, credential, **kwargs)
        
        self.components = ComponentsOperations(self._client, self._config)

    def _create_default_config(self, credential, subscription_id, base_url, **kwargs):
        from azure.mgmt.applicationinsights.v2020_02_02_preview._configuration import ApplicationInsightsManagementClientConfiguration
        return ApplicationInsightsManagementClientConfiguration(credential, subscription_id, base_url, **kwargs)

    def _create_client(self, config, credential, **kwargs):
        from azure.core.pipeline import Pipeline
        from azure.core.pipeline.transport import RequestsTransport
        from azure.core.pipeline.policies import (
            BearerTokenCredentialPolicy,
            ContentDecodePolicy,
            DistributedTracingPolicy,
            HttpLoggingPolicy,
            RequestIdPolicy,
            RetryPolicy,
            UserAgentPolicy,
        )
        from azure.mgmt.core.policies import ARMChallengeAuthenticationPolicy, ARMHttpLoggingPolicy

        policies = [
            RequestIdPolicy(**kwargs),
            UserAgentPolicy(**kwargs),
            RetryPolicy(**kwargs),
            BearerTokenCredentialPolicy(credential, config.credential_scopes, **kwargs),
            ContentDecodePolicy(**kwargs),
            DistributedTracingPolicy(**kwargs),
            HttpLoggingPolicy(**kwargs),
            ARMHttpLoggingPolicy(**kwargs),
        ]

        transport = kwargs.get('transport') or RequestsTransport(**kwargs)
        pipeline = Pipeline(transport, policies)

        from azure.core.rest import HttpRequest
        client = HttpRequest('GET', config.base_url)
        client._client = pipeline
        return client

    def close(self):
        if hasattr(self, '_client') and self._client:
            if hasattr(self._client, 'close'):
                self._client.close()

    def __enter__(self):
        return self

    def __exit__(self, *exc_details):
        self.close()","class ApplicationInsightsManagementClient(object):
    '''Composite Swagger for Application Insights Management Client.

    :ivar components: ComponentsOperations operations
    :vartype components: azure.mgmt.applicationinsights.v2020_02_02_preview.operations.ComponentsOperations
    :param credential: Credential needed for the client to connect to Azure.
    :type credential: ~azure.core.credentials.TokenCredential
    :param subscription_id: The ID of the target subscription.
    :type subscription_id: str
    :param str base_url: Service URL
    '''

    def __init__(
        self,
        credential,  # type: ""TokenCredential""
        subscription_id,  # type: str
        base_url=None,  # type: Optional[str]
        **kwargs  # type: Any
    ):
        if not base_url:
            base_url = 'https://management.azure.com'
        self._config = ApplicationInsightsManagementClientConfiguration(credential, subscription_id, **kwargs)
        self._client = ARMPipelineClient(base_url=base_url, config=self._config, **kwargs)

        client_models = {k: v for k, v in models.__dict__.items() if isinstance(v, type)}
        self._serialize = Serializer(client_models)
        self._deserialize = Deserializer(client_models)

        from azure.mgmt.applicationinsights.v2020_02_02_preview.operations import ComponentsOperations
        self.components = ComponentsOperations(
            self._client, self._config, self._serialize, self._deserialize)

    def close(self):
        self._client.close()

    def __enter__(self):
        self._client.__enter__()
        return self

    def __exit__(self, *exc_details):
        self._client.__exit__(*exc_details)",partial_docstr,0.7770700636942675,0.6538461538461539,0.5935483870967742,0.7197452229299364,0.49508578751715254,0.9274809160305344,0.8275862068965517,0.7461538461538462,0.9545043706893921,0.882863461971283,0.9172872304916382,0.8895400762557983,0.8212308379888268,0.5655737704918032,0.46502057613168724,0.40082644628099173,0.4918032786885245,0.42413878290093343,0.5313001605136437,0.40353697749196143,0.355877616747182,0.8224279284477234,0.8867700695991516,0.8533879518508911,0.8798864483833313,0.7549296143958873,0.9438202247191012,0.9152542372881356,0.8863636363636365,0.9438202247191012,0.874445998198165,0.9545454545454546,0.9276139410187667,0.9086021505376344,0.9807513952255249,0.9730304479598999,0.9768756628036499,0.9737971425056458,0.9764495108695652,0.3776489011006829,0.4740360537091466,0.4939103973465365,0.3595505617977528,0.1830985915492957,0.47257853457368,0.3326092707179954,0.5111785184708536,0.4831460674157303,0.5633802816901409,0.8694669536163752,0.7657110523616025,0.7683365373847971,0.9438202247191012,1.0
801631,tornadoweb/tornado,tornadoweb_tornado/tornado/locks.py,tornado.locks._TimeoutGarbageCollector,"class _TimeoutGarbageCollector:
    """"""Base class for objects that periodically clean up timed-out waiters.

    Avoids memory leak in a common pattern like:

        while True:
            yield condition.wait(short_timeout)
            print('looping....')
    """"""

    def __init__(self) -> None:
        self._waiters = collections.deque()  # type: Deque[Future]
        self._timeouts = 0

    def _garbage_collect(self) -> None:
        # Occasionally clear timed-out waiters.
        self._timeouts += 1
        if self._timeouts > 100:
            self._timeouts = 0
            self._waiters = collections.deque(w for w in self._waiters if not w.done())","class _TimeoutGarbageCollector:
    '''Base class for objects that periodically clean up timed-out waiters.

    Avoids memory leak in a common pattern like:

        while True:
            yield condition.wait(short_timeout)
            print('looping....')
    '''

    def __init__(self) -> None:
        pass

    def _garbage_collect(self) -> None:
        pass

",3,1,snippet_264,0.3333333333333333,"class _TimeoutGarbageCollector:
    _instances = weakref.WeakSet()
    _lock = threading.Lock()
    _timer = None
    _interval = 60.0

    def __init__(self) -> None:
        cls = self.__class__
        with cls._lock:
            cls._instances.add(self)
            if cls._timer is None:
                cls._start()

    @classmethod
    def _start(cls):
        cls._timer = threading.Timer(cls._interval, cls._collect)
        cls._timer.daemon = True
        cls._timer.start()

    @classmethod
    def _collect(cls):
        for inst in list(cls._instances):
            try:
                inst._garbage_collect()
            except Exception:
                pass
        with cls._lock:
            if cls._instances:
                cls._start()
            else:
                cls._timer = None

    def _garbage_collect(self) -> None:
        pass","class _TimeoutGarbageCollector:
    '''Base class for objects that periodically clean up timed-out waiters.

    Avoids memory leak in a common pattern like:

        while True:
            yield condition.wait(short_timeout)
            print('looping....')
    '''

    def __init__(self) -> None:
        self._waiters = []
        self._garbage_collection_count = 0

    def _garbage_collect(self) -> None:
        # Clean up any waiters that have timed out
        self._waiters = [waiter for waiter in self._waiters if not waiter.done()]
        self._garbage_collection_count += 1","class _TimeoutGarbageCollector:
    '''Base class for objects that periodically clean up timed-out waiters.

    Avoids memory leak in a common pattern like:

        while True:
            yield condition.wait(short_timeout)
            print('looping....')
    '''

    def __init__(self) -> None:
        self._waiters: Set[Any] = set()
        self._lock = threading.Lock()
        self._last_gc_time = time.time()
        self._gc_interval = 1.0

    def _garbage_collect(self) -> None:
        now = time.time()
        if now - self._last_gc_time < self._gc_interval:
            return
        
        with self._lock:
            expired_waiters = set()
            for waiter in self._waiters:
                if hasattr(waiter, '_timeout') and hasattr(waiter, '_start_time'):
                    if waiter._timeout is not None:
                        if now - waiter._start_time > waiter._timeout:
                            expired_waiters.add(waiter)
                elif hasattr(waiter, 'cancelled') and callable(waiter.cancelled):
                    if waiter.cancelled():
                        expired_waiters.add(waiter)
            
            self._waiters -= expired_waiters
            self._last_gc_time = now",partial_docstr,0.24096385542168672,0.10975609756097561,0.06172839506172839,0.1566265060240964,0.21597304863552652,0.41624365482233505,0.18877551020408162,0.1282051282051282,0.719565749168396,0.7007910013198853,0.7100542783737183,0.7026242613792419,0.7533743352601159,0.7651006711409397,0.6394557823129251,0.5655172413793104,0.7248322147651006,0.6225694858003326,0.8320610687022901,0.7230769230769231,0.6511627906976745,0.9412915110588074,0.9034017324447632,0.9219575524330139,0.9070529341697693,0.859439156626506,0.5402843601895734,0.4306220095693779,0.38647342995169087,0.5118483412322274,0.3506835204261121,0.449438202247191,0.33458646616541354,0.28679245283018867,0.7787724137306213,0.8763695359230042,0.8246935606002808,0.8655226230621338,0.7795436507936508,0.2740827470381683,0.0847637652939201,0.0929625716959623,0.4186046511627907,0.5,0.4808003237714899,0.5219237102593699,0.5426013773131728,0.627906976744186,0.2307692307692307,0.3861330982546475,0.2892451554885826,0.4440171123063936,0.4651162790697674,0.3461538461538461
213568,acutesoftware/AIKIF,acutesoftware_AIKIF/aikif/mapper.py,aikif.mapper.MapColumns,"class MapColumns(object):
    """"""
    directly maps columns in tables to aikif structures
    """"""
    def __init__(self, col_file):
        """"""
        takes a raw row in the map file and extracts info
        """"""
        self.col_file = col_file
        self.load_rules()
    
    def __str__(self):
        res = ' -- List of Column Mappings -- \n'
        print('self.col_file = ' + self.col_file)
        for m in self.col_maps:
            res += str(m)
            #print(m)
        return res

    def load_rules(self):
        """""" 
        load the rules from file
        """"""
        self.col_maps = []
        #print(""reading mapping table"")
        with open(self.col_file, 'r') as f:
            for line in f:
                rule = MapColumn(line)
                #rule = line
                self.col_maps.append(rule)","class MapColumns(object):
    '''
    directly maps columns in tables to aikif structures
    '''

    def __init__(self, col_file):
    '''
        takes a raw row in the map file and extracts info
        '''
        pass

    def __str__(self):
        pass

    def load_rules(self):
    ''' 
        load the rules from file
        '''
        pass

",4,3,snippet_719,0.5555555555555556,"class MapColumns(object):
    '''
    directly maps columns in tables to aikif structures
    '''

    def __init__(self, col_file):
        '''
        takes a raw row in the map file and extracts info
        '''
        self.col_file = col_file
        self.rules = []
        self.load_rules()

    def __str__(self):
        lines = []
        for r in self.rules:
            lines.append(f""{r['table']}.{r['column']} -> {r['structure']}.{r['field']}"")
        return ""\n"".join(lines)

    def load_rules(self):
        ''' 
        load the rules from file
        '''
        with open(self.col_file, newline='') as f:
            reader = csv.reader(f)
            for row in reader:
                if not row:
                    continue
                first = row[0].strip()
                if first.startswith('#') or first == '':
                    continue
                if len(row) < 4:
                    raise ValueError(f""Invalid mapping row: {row}"")
                table, column, structure, field = (cell.strip() for cell in row[:4])
                self.rules.append({
                    'table': table,
                    'column': column,
                    'structure': structure,
                    'field': field
                })","class MapColumns(object):
    '''
    directly maps columns in tables to aikif structures
    '''

    def __init__(self, col_file):
        '''
        takes a raw row in the map file and extracts info
        '''
        self.col_file = col_file
        self.rules = []
        self.load_rules()

    def __str__(self):
        return f""MapColumns with {len(self.rules)} rules from {self.col_file}""

    def load_rules(self):
        ''' 
        load the rules from file
        '''
        try:
            with open(self.col_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        self.rules.append(line)
        except FileNotFoundError:
            self.rules = []","class MapColumns(object):
    '''
    directly maps columns in tables to aikif structures
    '''

    def __init__(self, col_file):
        '''
        takes a raw row in the map file and extracts info
        '''
        self.col_file = col_file
        self.rules = []
        self.mappings = {}
        if col_file:
            self.load_rules()

    def __str__(self):
        result = f""MapColumns: {self.col_file}\n""
        result += f""Number of rules: {len(self.rules)}\n""
        for rule in self.rules:
            result += f""  {rule}\n""
        return result

    def load_rules(self):
        ''' 
        load the rules from file
        '''
        try:
            with open(self.col_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line and not line.startswith('#'):
                        parts = line.split(',')
                        if len(parts) >= 2:
                            source_col = parts[0].strip()
                            target_col = parts[1].strip()
                            rule = {
                                'source': source_col,
                                'target': target_col,
                                'line_num': line_num
                            }
                            if len(parts) > 2:
                                rule['transform'] = parts[2].strip()
                            self.rules.append(rule)
                            self.mappings[source_col] = target_col
        except FileNotFoundError:
            self.rules = []
            self.mappings = {}
        except Exception as e:
            self.rules = []
            self.mappings = {}",partial_docstr,0.5872340425531916,0.44635193133047213,0.38961038961038963,0.5361702127659574,0.3656468132460886,0.5126353790613718,0.34057971014492755,0.28,0.8296135663986206,0.8949779272079468,0.8610570430755615,0.887981653213501,0.7733356000000001,0.7253886010362693,0.6073298429319371,0.5608465608465608,0.6943005181347152,0.5238448541850754,0.7790697674418605,0.6140350877192983,0.5176470588235295,0.9015069603919983,0.890251874923706,0.8958441019058228,0.8913648128509521,0.8296313333333333,0.608058608058608,0.4501845018450185,0.379182156133829,0.5347985347985348,0.3270567236824055,0.46438746438746437,0.3057142857142857,0.24641833810888253,0.8197158575057983,0.910537838935852,0.8627431988716125,0.9005599021911621,0.7785109868421055,0.415307764214793,0.2424828723742091,0.3249106494709572,0.4761904761904761,0.6176470588235294,0.4595708101825236,0.3673409090875688,0.3883092784212372,0.5238095238095238,0.5588235294117647,0.4161445890159486,0.1998999628122208,0.3390948264915364,0.5079365079365079,0.6176470588235294
553798,log2timeline/plaso,log2timeline_plaso/plaso/lib/specification.py,plaso.lib.specification.FormatSpecification,"class FormatSpecification(object):
  """"""The format specification.""""""

  def __init__(self, identifier, text_format=False):
    """"""Initializes a format specification.

    Args:
      identifier (str): unique name for the format.
      text_format (Optional[bool]): True if the format is a text format,
          False otherwise.
    """"""
    super(FormatSpecification, self).__init__()
    self._text_format = text_format
    self.identifier = identifier
    self.signatures = []

  def AddNewSignature(self, pattern, offset=None):
    """"""Adds a signature.

    Args:
      pattern (bytes): pattern of the signature.
      offset (int): offset of the signature. None is used to indicate
          the signature has no offset. A positive offset is relative from
          the start of the data a negative offset is relative from the end
          of the data.
    """"""
    self.signatures.append(Signature(pattern, offset=offset))

  def IsTextFormat(self):
    """"""Determines if the format is a text format.

    Returns:
      bool: True if the format is a text format, False otherwise.
    """"""
    return self._text_format","class FormatSpecification(object):
    '''The format specification.'''

  def __init__(self, identifier, text_format=False):
    '''Initializes a format specification.

    Args:
      identifier (str): unique name for the format.
      text_format (Optional[bool]): True if the format is a text format,
          False otherwise.
    '''
    pass

  def AddNewSignature(self, pattern, offset=None):
    '''Adds a signature.

    Args:
      pattern (bytes): pattern of the signature.
      offset (int): offset of the signature. None is used to indicate
          the signature has no offset. A positive offset is relative from
          the start of the data a negative offset is relative from the end
          of the data.
    '''
    pass

  def IsTextFormat(self):
    '''Determines if the format is a text format.

    Returns:
      bool: True if the format is a text format, False otherwise.
    '''
    pass

",4,4,snippet_481,1.0,"class FormatSpecification(object):
    '''The format specification.'''

    def __init__(self, identifier, text_format=False):
        '''Initializes a format specification.

        Args:
          identifier (str): unique name for the format.
          text_format (Optional[bool]): True if the format is a text format,
              False otherwise.
        '''
        if not isinstance(identifier, str):
            raise TypeError(""identifier must be a string"")
        if not isinstance(text_format, bool):
            raise TypeError(""text_format must be a bool"")
        self.identifier = identifier
        self._text_format = text_format
        self._signatures = []

    def AddNewSignature(self, pattern, offset=None):
        '''Adds a signature.

        Args:
          pattern (bytes): pattern of the signature.
          offset (int): offset of the signature. None is used to indicate
              the signature has no offset. A positive offset is relative from
              the start of the data a negative offset is relative from the end
              of the data.
        '''
        if not isinstance(pattern, (bytes, bytearray)):
            raise TypeError(""pattern must be bytes or bytearray"")
        if offset is not None and not isinstance(offset, int):
            raise TypeError(""offset must be an int or None"")
        # store as bytes
        self._signatures.append((bytes(pattern), offset))

    def IsTextFormat(self):
        '''Determines if the format is a text format.

        Returns:
          bool: True if the format is a text format, False otherwise.
        '''
        return self._text_format","class FormatSpecification(object):
    '''The format specification.'''

    def __init__(self, identifier, text_format=False):
        '''Initializes a format specification.

        Args:
          identifier (str): unique name for the format.
          text_format (Optional[bool]): True if the format is a text format,
              False otherwise.
        '''
        self.identifier = identifier
        self.text_format = text_format
        self.signatures = []

    def AddNewSignature(self, pattern, offset=None):
        '''Adds a signature.

        Args:
          pattern (bytes): pattern of the signature.
          offset (int): offset of the signature. None is used to indicate
              the signature has no offset. A positive offset is relative from
              the start of the data a negative offset is relative from the end
              of the data.
        '''
        self.signatures.append((pattern, offset))

    def IsTextFormat(self):
        '''Determines if the format is a text format.

        Returns:
          bool: True if the format is a text format, False otherwise.
        '''
        return self.text_format","class FormatSpecification(object):
    '''The format specification.'''

    def __init__(self, identifier, text_format=False):
        '''Initializes a format specification.

        Args:
          identifier (str): unique name for the format.
          text_format (Optional[bool]): True if the format is a text format,
              False otherwise.
        '''
        self.identifier = identifier
        self._text_format = text_format
        self.signatures = []

    def AddNewSignature(self, pattern, offset=None):
        '''Adds a signature.

        Args:
          pattern (bytes): pattern of the signature.
          offset (int): offset of the signature. None is used to indicate
              the signature has no offset. A positive offset is relative from
              the start of the data a negative offset is relative from the end
              of the data.
        '''
        signature = {'pattern': pattern, 'offset': offset}
        self.signatures.append(signature)

    def IsTextFormat(self):
        '''Determines if the format is a text format.

        Returns:
          bool: True if the format is a text format, False otherwise.
        '''
        return self._text_format",partial_docstr,0.8023598820058997,0.7774480712166173,0.7402985074626866,0.7905604719764013,0.6298826922996111,0.7040498442367601,0.61875,0.5736677115987461,0.8639395236968994,0.9364842176437378,0.8987503051757812,0.9286860823631287,0.8482921153846155,0.9782608695652174,0.9635036496350364,0.9264705882352942,0.9637681159420289,0.7560561571294198,0.9626168224299065,0.9107981220657277,0.8537735849056604,0.9638570547103882,0.95981764793396,0.961833119392395,0.9602200984954834,0.9479171875,0.9785714285714285,0.9568345323741007,0.9057971014492754,0.942857142857143,0.7650724694295924,0.9282511210762332,0.8738738738738738,0.8280542986425339,0.9593172669410706,0.9581990838050842,0.9587578773498535,0.9583107233047485,0.88889,0.652008148490684,0.5526224217569365,0.7900443185472628,0.5853658536585366,0.68,0.616382546676578,0.7795181573688036,0.7894266634838499,0.5365853658536586,0.36,0.6360925731982521,0.770278506887957,0.7975064200513927,0.5365853658536586,0.44
327599,daler/trackhub,daler_trackhub/trackhub/validate.py,trackhub.validate.Param,"class Param(object):
    def __init__(self, name, fmt, types, required, validator, min_bed_fields=None):
        """"""
        Parameters
        ----------

        name : str
            Name of the parameter

        fmt : list
            List of strings parsed from the ""format"" section of the spec from
            UCSC. Mostly used as an informal guide to the format.

        types : list
            List of track types this parameter applies to

        required : bool or list
            If True, all tracks must have it. If list, only those types must
            have it.

        validator : callable, set, or type
            Validation to run on user-provided values. If callable, must return
            True if the value passes. If set, validation will pass if the value
            is in the provided set.

        min_bed_fields : int
            Some parameters only work for a certain number of BED fields.
            Specify that here.

        Examples
        --------

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate(999)
        True

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate('999')
        True

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate(0)
        True
        """"""
        self.name = name
        self.fmt = fmt
        self.types = types
        self.required = required
        self.validator = validator

    def __str__(self):
        return '<%s ""%s"" at %s>' % (self.__class__.__name__, self.name, id(self))

    def validate(self, value):

        if isinstance(self.validator, set):
            if value in self.validator:
                return True

        if isinstance(self.validator, type):
            if isinstance(value, self.validator):
                return True
            else:
                # Otherwise, allow any exceptions to propagate up.
                self.validator(value)
                return True

        if hasattr(self.validator, ""__call__""):
            return self.validator(value)

        elif value == self.validator:
            return True
        return False","class Param(object):


    def __init__(self, name, fmt, types, required, validator, min_bed_fields=None):
    '''
        Parameters
        ----------

        name : str
            Name of the parameter

        fmt : list
            List of strings parsed from the ""format"" section of the spec from
            UCSC. Mostly used as an informal guide to the format.

        types : list
            List of track types this parameter applies to

        required : bool or list
            If True, all tracks must have it. If list, only those types must
            have it.

        validator : callable, set, or type
            Validation to run on user-provided values. If callable, must return
            True if the value passes. If set, validation will pass if the value
            is in the provided set.

        min_bed_fields : int
            Some parameters only work for a certain number of BED fields.
            Specify that here.

        Examples
        --------

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate(999)
        True

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate('999')
        True

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate(0)
        True
        '''
        pass

    def __str__(self):
        pass

    def validate(self, value):
        pass

",4,1,snippet_777,0.75,"class Param(object):
    def __init__(self, name, fmt, types, required, validator, min_bed_fields=None):
        self.name = name
        self.fmt = fmt
        self.types = types
        self.required = required
        self.validator = validator
        self.min_bed_fields = min_bed_fields

    def __str__(self):
        return self.name

    def validate(self, value):
        v = self.validator
        if isinstance(v, set):
            return value in v
        if isinstance(v, type):
            try:
                v(value)
                return True
            except Exception:
                return False
        if callable(v):
            try:
                return bool(v(value))
            except Exception:
                return False
        return False","class Param(object):
    def __init__(self, name, fmt, types, required, validator, min_bed_fields=None):
        '''
        Parameters
        ----------

        name : str
            Name of the parameter

        fmt : list
            List of strings parsed from the ""format"" section of the spec from
            UCSC. Mostly used as an informal guide to the format.

        types : list
            List of track types this parameter applies to

        required : bool or list
            If True, all tracks must have it. If list, only those types must
            have it.

        validator : callable, set, or type
            Validation to run on user-provided values. If callable, must return
            True if the value passes. If set, validation will pass if the value
            is in the provided set.

        min_bed_fields : int
            Some parameters only work for a certain number of BED fields.
            Specify that here.

        Examples
        --------

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate(999)
        True

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate('999')
        True

        >>> Param(name='test', fmt=['test <#>'], types=['bigBed'], required=False, validator=int).validate(0)
        True
        '''
        self.name = name
        self.fmt = fmt
        self.types = types
        self.required = required
        self.validator = validator
        self.min_bed_fields = min_bed_fields

    def __str__(self):
        return self.name

    def validate(self, value):
        if isinstance(self.validator, type):
            try:
                self.validator(value)
                return True
            except (TypeError, ValueError):
                return False
        elif isinstance(self.validator, set):
            return value in self.validator
        elif callable(self.validator):
            return self.validator(value)
        else:
            return True","class Param(object):

    def __init__(self, name, fmt, types, required, validator, min_bed_fields=None):
        self.name = name
        self.fmt = fmt
        self.types = types
        self.required = required
        self.validator = validator
        self.min_bed_fields = min_bed_fields

    def __str__(self):
        return self.name

    def validate(self, value):
        if callable(self.validator):
            try:
                return self.validator(value)
            except:
                return False
        elif isinstance(self.validator, set):
            return value in self.validator
        elif isinstance(self.validator, type):
            try:
                self.validator(value)
                return True
            except:
                return False
        else:
            return True",partial_docstr,0.41399416909620995,0.2756598240469208,0.1887905604719764,0.33819241982507287,0.09269637681309482,0.9038461538461539,0.7161290322580646,0.5909090909090909,0.8773071765899658,0.7663213014602661,0.8180671334266663,0.776140034198761,0.8617900000000001,0.9134808853118712,0.8606060606060606,0.81947261663286,0.8732394366197184,0.8001986143943215,0.9664268585131894,0.9158653846153846,0.8795180722891566,0.975715696811676,0.9615300297737122,0.9685709476470947,0.9629300236701965,0.857725,0.4651162790697675,0.34502923976608185,0.2529411764705882,0.3546511627906977,0.11299180030043451,0.95625,0.8113207547169812,0.7088607594936709,0.8995957374572754,0.7774193286895752,0.8340570330619812,0.7881231307983398,0.8556925000000001,0.3236670317212359,0.0404659726591575,0.137082964165961,0.4756097560975609,0.6415094339622641,0.7471837161855035,0.7748388161090863,0.7751017550296143,0.6463414634146342,0.7924528301886793,0.4068574986148083,0.0386596921972758,0.1499760086586438,0.6463414634146342,0.7924528301886793
174262,PythonCharmers/python-future,PythonCharmers_python-future/src/past/translation/__init__.py,src.past.translation.suspend_hooks,"class suspend_hooks(object):
    """"""
    Acts as a context manager. Use like this:

    >>> from past import translation
    >>> translation.install_hooks()
    >>> import http.client
    >>> # ...
    >>> with translation.suspend_hooks():
    >>>     import requests     # or others that support Py2/3

    If the hooks were disabled before the context, they are not installed when
    the context is left.
    """"""
    def __enter__(self):
        self.hooks_were_installed = detect_hooks()
        remove_hooks()
        return self
    def __exit__(self, *args):
        if self.hooks_were_installed:
            install_hooks()","class suspend_hooks(object):
    '''
    Acts as a context manager. Use like this:

    >>> from past import translation
    >>> translation.install_hooks()
    >>> import http.client
    >>> # ...
    >>> with translation.suspend_hooks():
    >>>     import requests     # or others that support Py2/3

    If the hooks were disabled before the context, they are not installed when
    the context is left.
    '''

    def __enter__(self):
        pass

    def __exit__(self, *args):
        pass

",3,1,snippet_183,0.6,"class suspend_hooks(object):
    '''
    Acts as a context manager. Use like this:

    >>> from past import translation
    >>> translation.install_hooks()
    >>> import http.client
    >>> # ...
    >>> with translation.suspend_hooks():
    >>>     import requests     # or others that support Py2/3

    If the hooks were disabled before the context, they are not installed when
    the context is left.
    '''

    def __enter__(self):
        # Remember whether hooks are currently installed
        self._was_enabled = globals().get('HOOKS_ENABLED', False)
        if self._was_enabled:
            # Temporarily remove them
            remove_hooks()

    def __exit__(self, exc_type, exc_value, traceback):
        # Re-install only if they were enabled before entering
        if getattr(self, '_was_enabled', False):
            install_hooks()","class suspend_hooks(object):
    '''
    Acts as a context manager. Use like this:

    >>> from past import translation
    >>> translation.install_hooks()
    >>> import http.client
    >>> # ...
    >>> with translation.suspend_hooks():
    >>>     import requests     # or others that support Py2/3

    If the hooks were disabled before the context, they are not installed when
    the context is left.
    '''

    def __enter__(self):
        from past.translation import remove_hooks
        self.hooks_were_installed = hasattr(remove_hooks, '__call__')
        if self.hooks_were_installed:
            remove_hooks()
        return self

    def __exit__(self, *args):
        if self.hooks_were_installed:
            from past.translation import install_hooks
            install_hooks()","class suspend_hooks(object):
    '''
    Acts as a context manager. Use like this:

    >>> from past import translation
    >>> translation.install_hooks()
    >>> import http.client
    >>> # ...
    >>> with translation.suspend_hooks():
    >>>     import requests     # or others that support Py2/3

    If the hooks were disabled before the context, they are not installed when
    the context is left.
    '''

    def __enter__(self):
        import sys
        self.hooks_were_installed = hasattr(sys.meta_path[0], '__name__') and sys.meta_path[0].__name__ == 'past.translation'
        if self.hooks_were_installed:
            self.hook = sys.meta_path.pop(0)
        return self

    def __exit__(self, *args):
        import sys
        if self.hooks_were_installed:
            sys.meta_path.insert(0, self.hook)",partial_docstr,0.7796610169491526,0.6628571428571428,0.6127167630057804,0.7457627118644068,0.6414865591316795,0.7258883248730964,0.6275510204081632,0.5794871794871795,0.8745235204696655,0.9576619267463684,0.9142064452171326,0.9486434459686279,0.8578445588235294,0.8757396449704142,0.8263473053892216,0.7878787878787878,0.8757396449704142,0.7608451857691321,0.8021390374331551,0.7580645161290323,0.7243243243243244,0.9498317241668701,0.9757633209228516,0.9626229405403137,0.9731066823005676,0.8921579411764705,0.7734806629834254,0.7262569832402235,0.6892655367231639,0.7734806629834254,0.6194065370915758,0.6697247706422018,0.6082949308755761,0.5833333333333334,0.8890808820724487,0.9647544622421265,0.9253731966018677,0.9566124081611633,0.826390625,0.5058732314185831,0.5629693524853614,0.7792048918702896,0.5384615384615384,0.1428571428571428,0.6719149627447357,0.7392377135173533,0.8660045550440072,0.6538461538461539,0.4285714285714285,0.51633956951291,0.6799726236204273,0.8304405994861579,0.2692307692307692,0.2857142857142857
594539,neithere/monk,neithere_monk/monk/modeling.py,monk.modeling.StructuredDictMixin,"class StructuredDictMixin(object):
    """""" A dictionary with structure specification and validation.

    .. attribute:: structure

        The document structure specification. For details see
        :func:`monk.shortcuts.validate`.

    """"""
    structure = {}
    #defaults = {}
    #required = []
    #validators = {}
    #with_skeleton = True

    def _insert_defaults(self):
        """""" Inserts default values from :attr:`StructuredDictMixin.structure`
        to `self` by merging the two structures
        (see :func:`monk.manipulation.merge_defaults`).
        """"""
        merged = merge_defaults(self.structure, self)
        self.update(merged)

    def validate(self):
        validate(self.structure, self)","class StructuredDictMixin(object):
    ''' A dictionary with structure specification and validation.

    .. attribute:: structure

        The document structure specification. For details see
        :func:`monk.shortcuts.validate`.

    '''

    def _insert_defaults(self):
    ''' Inserts default values from :attr:`StructuredDictMixin.structure`
        to `self` by merging the two structures
        (see :func:`monk.manipulation.merge_defaults`).
        '''
        pass

    def validate(self):
        pass

",3,2,snippet_332,0.75,"class StructuredDictMixin(object):
    ''' A dictionary with structure specification and validation.

    .. attribute:: structure

        The document structure specification. For details see
        :func:`monk.shortcuts.validate`.
    '''

    def _insert_defaults(self):
        merged = merge_defaults(self.structure, dict(self))
        self.clear()
        self.update(merged)

    def validate(self):
        validated = _validate(dict(self), self.structure)
        self.clear()
        self.update(validated)
        return validated","class StructuredDictMixin(object):
    ''' A dictionary with structure specification and validation.

    .. attribute:: structure

        The document structure specification. For details see
        :func:`monk.shortcuts.validate`.

    '''

    def _insert_defaults(self):
        ''' Inserts default values from :attr:`StructuredDictMixin.structure`
        to `self` by merging the two structures
        (see :func:`monk.manipulation.merge_defaults`).
        '''
        from monk.manipulation import merge_defaults
        if hasattr(self, 'structure') and self.structure is not None:
            merged = merge_defaults(self, self.structure)
            self.clear()
            self.update(merged)

    def validate(self):
        from monk.shortcuts import validate
        if hasattr(self, 'structure') and self.structure is not None:
            validate(self, self.structure)","class StructuredDictMixin(object):
    ''' A dictionary with structure specification and validation.

    .. attribute:: structure

        The document structure specification. For details see
        :func:`monk.shortcuts.validate`.

    '''

    structure = {}

    def _insert_defaults(self):
        ''' Inserts default values from :attr:`StructuredDictMixin.structure`
            to `self` by merging the two structures
            (see :func:`monk.manipulation.merge_defaults`).
        '''
        from monk.manipulation import merge_defaults
        merge_defaults(self, self.structure)

    def validate(self):
        from monk.shortcuts import validate
        return validate(self, self.structure)",partial_docstr,0.7040000000000001,0.6016260162601627,0.512396694214876,0.6880000000000002,0.4528390723441728,0.8090909090909091,0.6788990825688074,0.5833333333333334,0.929049551486969,0.8815892934799194,0.9046973586082458,0.886116087436676,0.8088908,0.783132530120482,0.7073170731707318,0.617283950617284,0.7590361445783134,0.6407698505789473,0.7076023391812866,0.6411764705882353,0.5798816568047337,0.9075727462768555,0.9472788572311401,0.9270008206367493,0.9431525468826294,0.8019821782178217,0.8591549295774648,0.7714285714285714,0.6666666666666666,0.8169014084507044,0.6613125887235063,0.8796992481203008,0.7803030303030303,0.6946564885496184,0.9514945149421692,0.942219614982605,0.9468343257904053,0.9431389570236206,0.8587584745762712,0.3457950682019991,0.2937772969878441,0.3432491296663063,0.3461538461538461,0.4,0.4633242532343345,0.444907221950398,0.5289026114997608,0.3461538461538461,0.5333333333333333,0.5737541276919845,0.5148318479861261,0.5289026114997608,0.3846153846153846,0.8666666666666667
789574,textX/textX,textx/scoping/rrel.py,textx.scoping.rrel.RRELBase,"class RRELBase:
    def __init__(self):
        pass

    def get_next_matches(
        self, obj, lookup_list, allowed, matched_path, first_element=False
    ):
        """"""
        This function yields potential matches encountered along the
        requested RREL.

        Implementation detail: This is the base implementation which
        assumes an apply function. Certain RREL classes overwrite this
        method instead of implementing the apply method.

        Args:
            obj: currently visited model object
            lookup_list: reference name to be looked up
            allowed: a callable to ""allow"" to visit an object
                in order to prevent infinite recursion loops.
                it is called with allowed(obj, lookup_list, RREL-entry).
            first_element: True, if we did not process any
                model element (else False). This is used to
                distinguish RRELs starting at model level (e.g.,
                'packages*.class') or locally (e.g., '.port').
        Returns (yields):
            yields (obj, lookup_list) to indicate possible
            intermediate matches. The returned obj can be
            Postponed.
        """"""
        if not allowed(obj, lookup_list, self):  # also adjusts visited objs
            return  # recursion stopper

        obj, lookup_list, matched_path = self.apply(
            obj, lookup_list, matched_path, first_element
        )
        if obj is None:
            return
        elif isinstance(obj, list):
            for iobj in obj:
                if iobj is not None:
                    yield iobj, lookup_list, matched_path
        else:
            yield obj, lookup_list, matched_path","class RRELBase:


    def __init__(self):
        pass

    def get_next_matches(
        self, obj, lookup_list, allowed, matched_path, first_element=False
    ):
    '''
        This function yields potential matches encountered along the
        requested RREL.

        Implementation detail: This is the base implementation which
        assumes an apply function. Certain RREL classes overwrite this
        method instead of implementing the apply method.

        Args:
            obj: currently visited model object
            lookup_list: reference name to be looked up
            allowed: a callable to ""allow"" to visit an object
                in order to prevent infinite recursion loops.
                it is called with allowed(obj, lookup_list, RREL-entry).
            first_element: True, if we did not process any
                model element (else False). This is used to
                distinguish RRELs starting at model level (e.g.,
                'packages*.class') or locally (e.g., '.port').
        Returns (yields):
            yields (obj, lookup_list) to indicate possible
            intermediate matches. The returned obj can be
            Postponed.
        '''
        pass

",3,1,snippet_117,0.2307692307692307,"class RRELBase:

    def __init__(self):
        super().__init__()

    def get_next_matches(
        self, obj, lookup_list, allowed, matched_path, first_element=False
    ):
        if not allowed(obj, lookup_list, self):
            return

        try:
            next_objs = self.apply(obj)
        except AttributeError:
            # if subclass didnt define apply
            return

        for next_obj in next_objs or ():
            yield next_obj, lookup_list","class RRELBase:

    def __init__(self):
        pass

    def get_next_matches(
        self, obj, lookup_list, allowed, matched_path, first_element=False
    ):
        '''
        This function yields potential matches encountered along the
        requested RREL.

        Implementation detail: This is the base implementation which
        assumes an apply function. Certain RREL classes overwrite this
        method instead of implementing the apply method.

        Args:
            obj: currently visited model object
            lookup_list: reference name to be looked up
            allowed: a callable to ""allow"" to visit an object
                in order to prevent infinite recursion loops.
                it is called with allowed(obj, lookup_list, RREL-entry).
            first_element: True, if we did not process any
                model element (else False). This is used to
                distinguish RRELs starting at model level (e.g.,
                'packages*.class') or locally (e.g., '.port').
        Returns (yields):
            yields (obj, lookup_list) to indicate possible
            intermediate matches. The returned obj can be
            Postponed.
        '''
        # Base implementation that assumes an apply function
        if first_element:
            # For the first element, we apply the RREL entry directly
            result = self.apply(obj, lookup_list, allowed, matched_path)
            if result is not None:
                yield result
        else:
            # For subsequent elements, we continue the matching process
            result = self.apply(obj, lookup_list, allowed, matched_path)
            if result is not None:
                yield result

    def apply(self, obj, lookup_list, allowed, matched_path):
        '''
        Apply the RREL entry to the given object.
        This is a placeholder method that should be implemented by subclasses.
        
        Args:
            obj: The object to apply the RREL entry to
            lookup_list: The remaining lookup list
            allowed: The allowed callable to prevent infinite recursion
            matched_path: The path that has been matched so far
            
        Returns:
            A tuple (obj, lookup_list) or None if no match
        '''
        # This method should be implemented by subclasses
        return None","class RRELBase:

    def __init__(self):
        pass

    def get_next_matches(
        self, obj, lookup_list, allowed, matched_path, first_element=False
    ):
        '''
        This function yields potential matches encountered along the
        requested RREL.

        Implementation detail: This is the base implementation which
        assumes an apply function. Certain RREL classes overwrite this
        method instead of implementing the apply method.

        Args:
            obj: currently visited model object
            lookup_list: reference name to be looked up
            allowed: a callable to ""allow"" to visit an object
                in order to prevent infinite recursion loops.
                it is called with allowed(obj, lookup_list, RREL-entry).
            first_element: True, if we did not process any
                model element (else False). This is used to
                distinguish RRELs starting at model level (e.g.,
                'packages*.class') or locally (e.g., '.port').
        Returns (yields):
            yields (obj, lookup_list) to indicate possible
            intermediate matches. The returned obj can be
            Postponed.
        '''
        if hasattr(self, 'apply'):
            for result in self.apply(obj, lookup_list, allowed, matched_path, first_element):
                yield result",partial_docstr,0.32558139534883723,0.2109375,0.1732283464566929,0.2945736434108527,0.09691007289203772,0.8807339449541285,0.6203703703703703,0.5233644859813084,0.8325958847999573,0.7085093259811401,0.7655569314956665,0.7192284464836121,0.822224,0.7704918032786885,0.6625514403292181,0.6157024793388429,0.7008196721311476,0.648390197702175,0.7160194174757282,0.6423357664233577,0.5926829268292683,0.910176157951355,0.9502568244934082,0.9297847747802734,0.9460906982421875,0.7971034782608695,0.868131868131868,0.8287292817679558,0.8166666666666665,0.8516483516483517,0.7177613039167183,0.9759036144578314,0.9354838709677419,0.9109311740890689,0.9807267189025879,0.9344214797019958,0.957014262676239,0.9388542771339417,0.8148166666666666,0.2277749359082419,0.0134868721846536,0.0936355987210414,0.2727272727272727,0.53125,0.5595482471088088,0.498489219443996,0.7397037689912392,0.25,0.75,0.5113960428776424,0.6897654410829033,0.6967278213367573,0.1590909090909091,0.5
216631,agiliq/django-graphos,agiliq_django-graphos/graphos/sources/base.py,graphos.sources.base.BaseDataSource,"class BaseDataSource(object):
    def __init__(*args, **kwargs):
        pass

    def get_data(self):
        ""Get all the data. Subclasses should override this""
        raise GraphosException(""Not Implemented"")

    def get_header(self):
        ""Get the header - First row. Subclasses should override this""
        raise GraphosException(""Not Implemented"")

    def get_first_column(self):
        """"""
        Get the first column. Generally would be the x axis.
        Subclasses should override this
        """"""
        raise GraphosException(""Not Implemented"")","class BaseDataSource(object):


    def __init__(*args, **kwargs):
        pass

    def get_data(self):
    '''Get all the data. Subclasses should override this'''
        pass

    def get_header(self):
    '''Get the header - First row. Subclasses should override this'''
        pass

    def get_first_column(self):
    '''
        Get the first column. Generally would be the x axis.
        Subclasses should override this
        '''
        pass

",5,3,snippet_215,1.0,"class BaseDataSource(ABC):

    def __init__(self, *args, **kwargs):
        super().__init__()

    @abstractmethod
    def get_data(self):
        """"""Get all the data. Subclasses should override this""""""
        raise NotImplementedError

    @abstractmethod
    def get_header(self):
        """"""Get the header - First row. Subclasses should override this""""""
        raise NotImplementedError

    @abstractmethod
    def get_first_column(self):
        """"""
        Get the first column. Generally would be the x axis.
        Subclasses should override this
        """"""
        raise NotImplementedError","class BaseDataSource(object):

    def __init__(self, *args, **kwargs):
        pass

    def get_data(self):
        '''Get all the data. Subclasses should override this'''
        pass

    def get_header(self):
        '''Get the header - First row. Subclasses should override this'''
        pass

    def get_first_column(self):
        '''
        Get the first column. Generally would be the x axis.
        Subclasses should override this
        '''
        pass","class BaseDataSource(object):

    def __init__(self, *args, **kwargs):
        pass

    def get_data(self):
        '''Get all the data. Subclasses should override this'''
        pass

    def get_header(self):
        '''Get the header - First row. Subclasses should override this'''
        pass

    def get_first_column(self):
        '''
        Get the first column. Generally would be the x axis.
        Subclasses should override this
        '''
        pass",partial_docstr,0.8346456692913385,0.752,0.6666666666666666,0.8346456692913385,0.7253005846505806,0.8346456692913385,0.7142857142857143,0.64,0.9263943433761597,0.9368284344673157,0.9315820932388306,0.9357745051383972,0.8260886956521738,0.8666666666666666,0.8135593220338982,0.7586206896551724,0.8666666666666666,0.6026289616759152,0.8804347826086957,0.8131868131868132,0.7444444444444445,0.9845864772796631,0.8973486423492432,0.9389455914497375,0.9053705930709839,0.8792282608695652,0.8666666666666666,0.8135593220338982,0.7586206896551724,0.8666666666666666,0.6026289616759152,0.8804347826086957,0.8131868131868132,0.7444444444444445,0.9845864772796631,0.8973486423492432,0.9389455914497375,0.9053705930709839,0.8792282608695652,0.5419261263594638,0.5606456826825694,0.5801771023251784,0.1935483870967742,0.8333333333333334,0.451219558522801,0.5244938549648859,0.5223198629972857,0.2580645161290322,0.5,0.451219558522801,0.5244938549648859,0.5223198629972857,0.2580645161290322,0.5
268173,bmcfee/muda,bmcfee_muda/muda/base.py,muda.base.Pipeline,"class Pipeline(object):
    """"""Wrapper which allows multiple BaseDeformer objects to be chained together

    A given JAMS object will be transformed sequentially by
    each stage of the pipeline.

    The pipeline induces a graph over transformers

    Attributes
    ----------
    steps : argument array
        steps[i] is a tuple of `(name, Transformer)`

    Examples
    --------
    >>> P = muda.deformers.PitchShift(semitones=5)
    >>> T = muda.deformers.TimeStretch(speed=1.25)
    >>> Pipe = muda.Pipeline(steps=[('Pitch:maj3', P), ('Speed:1.25x', T)])
    >>> output_jams = list(Pipe.transform(jam_in))

    See Also
    --------
    Union
    """"""

    def __init__(self, steps=None):

        names, transformers = zip(*steps)

        if len(set(names)) != len(steps):
            raise ValueError(""Names provided are not unique: "" "" {}"".format(names))

        # shallow copy of steps
        self.steps = list(zip(names, transformers))

        for t in transformers:
            if not isinstance(t, BaseTransformer):
                raise TypeError(""{:s} is not a BaseTransformer"".format(t))

    def get_params(self):
        """"""Get the parameters for this object.  Returns as a dict.""""""

        out = {}
        out[""__class__""] = self.__class__
        out[""params""] = dict(steps=[])

        for name, step in self.steps:
            out[""params""][""steps""].append([name, step.get_params(deep=True)])

        return out

    def __repr__(self):
        """"""Pretty-print the object""""""

        class_name = self.__class__.__name__
        return ""{:s}({:s})"".format(
            class_name, _pprint(self.get_params(), offset=len(class_name))
        )

    def __recursive_transform(self, jam, steps):
        """"""A recursive transformation pipeline""""""

        if len(steps) > 0:
            head_transformer = steps[0][1]
            for t_jam in head_transformer.transform(jam):
                for q in self.__recursive_transform(t_jam, steps[1:]):
                    yield q
        else:
            yield jam

    def transform(self, jam):
        """"""Apply the sequence of transformations to a single jam object.

        Parameters
        ----------
        jam : jams.JAMS
            The jam object to transform

        Yields
        ------
        jam_out : jams.JAMS
            The jam objects produced by the transformation sequence
        """"""

        for output in self.__recursive_transform(jam, self.steps):
            yield output","class Pipeline(object):
    '''Wrapper which allows multiple BaseDeformer objects to be chained together

    A given JAMS object will be transformed sequentially by
    each stage of the pipeline.

    The pipeline induces a graph over transformers

    Attributes
    ----------
    steps : argument array
        steps[i] is a tuple of `(name, Transformer)`

    Examples
    --------
    >>> P = muda.deformers.PitchShift(semitones=5)
    >>> T = muda.deformers.TimeStretch(speed=1.25)
    >>> Pipe = muda.Pipeline(steps=[('Pitch:maj3', P), ('Speed:1.25x', T)])
    >>> output_jams = list(Pipe.transform(jam_in))

    See Also
    --------
    Union
    '''

    def __init__(self, steps=None):
        pass

    def get_params(self):
    '''Get the parameters for this object.  Returns as a dict.'''
        pass

    def __repr__(self):
    '''Pretty-print the object'''
        pass

    def __recursive_transform(self, jam, steps):
    '''A recursive transformation pipeline'''
        pass

    def transform(self, jam):
    '''Apply the sequence of transformations to a single jam object.

        Parameters
        ----------
        jam : jams.JAMS
            The jam object to transform

        Yields
        ------
        jam_out : jams.JAMS
            The jam objects produced by the transformation sequence
        '''
        pass

",6,5,snippet_326,0.2631578947368421,"class Pipeline(object):
    '''Wrapper which allows multiple BaseDeformer objects to be chained together

    A given JAMS object will be transformed sequentially by
    each stage of the pipeline.

    The pipeline induces a graph over transformers

    Attributes
    ----------
    steps : argument array
        steps[i] is a tuple of `(name, Transformer)`

    Examples
    --------
    >>> P = muda.deformers.PitchShift(semitones=5)
    >>> T = muda.deformers.TimeStretch(speed=1.25)
    >>> Pipe = muda.Pipeline(steps=[('Pitch:maj3', P), ('Speed:1.25x', T)])
    >>> output_jams = list(Pipe.transform(jam_in))

    See Also
    --------
    Union
    '''

    def __init__(self, steps=None):
        if steps is None:
            steps = []
        if not isinstance(steps, (list, tuple)):
            raise ValueError(""`steps` must be a list or tuple of (name, transformer) pairs"")
        for s in steps:
            if not (isinstance(s, (list, tuple)) and len(s) == 2):
                raise ValueError(""Each step must be a (name, transformer) tuple"")
        self.steps = list(steps)

    def get_params(self):
        '''Get the parameters for this object.  Returns as a dict.'''
        params = {}
        params['steps'] = []
        for name, transformer in self.steps:
            if hasattr(transformer, 'get_params'):
                params['steps'].append((name, transformer.get_params()))
            else:
                params['steps'].append((name, None))
        return params

    def __repr__(self):
        '''Pretty-print the object'''
        step_reprs = []
        for name, transformer in self.steps:
            step_reprs.append(f""('{name}', {transformer!r})"")
        steps_str = '[' + ', '.join(step_reprs) + ']'
        return f""{self.__class__.__name__}(steps={steps_str})""

    def __recursive_transform(self, jam, steps):
        '''A recursive transformation pipeline'''
        if not steps:
            yield jam
            return
        name, transformer = steps[0]
        for jam_out in transformer.transform(jam):
            yield from self.__recursive_transform(jam_out, steps[1:])

    def transform(self, jam):
        '''Apply the sequence of transformations to a single jam object.

        Parameters
        ----------
        jam : jams.JAMS
            The jam object to transform

        Yields
        ------
        jam_out : jams.JAMS
            The jam objects produced by the transformation sequence
        '''
        yield from self.__recursive_transform(jam, self.steps)","class Pipeline(object):
    '''Wrapper which allows multiple BaseDeformer objects to be chained together

    A given JAMS object will be transformed sequentially by
    each stage of the pipeline.

    The pipeline induces a graph over transformers

    Attributes
    ----------
    steps : argument array
        steps[i] is a tuple of `(name, Transformer)`

    Examples
    --------
    >>> P = muda.deformers.PitchShift(semitones=5)
    >>> T = muda.deformers.TimeStretch(speed=1.25)
    >>> Pipe = muda.Pipeline(steps=[('Pitch:maj3', P), ('Speed:1.25x', T)])
    >>> output_jams = list(Pipe.transform(jam_in))

    See Also
    --------
    Union
    '''

    def __init__(self, steps=None):
        if steps is None:
            steps = []
        self.steps = steps

    def get_params(self):
        '''Get the parameters for this object.  Returns as a dict.'''
        return {'steps': [(name, transformer.get_params()) for name, transformer in self.steps]}

    def __repr__(self):
        '''Pretty-print the object'''
        repr_str = '{}(steps=[{}])'.format(
            self.__class__.__name__,
            ', '.join('(""{}"", {})'.format(name, repr(transformer)) for name, transformer in self.steps)
        )
        return repr_str

    def __recursive_transform(self, jam, steps):
        '''A recursive transformation pipeline'''
        if not steps:
            yield jam
        else:
            name, transformer = steps[0]
            for transformed_jam in transformer.transform(jam):
                for result_jam in self.__recursive_transform(transformed_jam, steps[1:]):
                    yield result_jam

    def transform(self, jam):
        '''Apply the sequence of transformations to a single jam object.

        Parameters
        ----------
        jam : jams.JAMS
            The jam object to transform

        Yields
        ------
        jam_out : jams.JAMS
            The jam objects produced by the transformation sequence
        '''
        for result in self.__recursive_transform(jam, self.steps):
            yield result","class Pipeline(object):
    '''Wrapper which allows multiple BaseDeformer objects to be chained together

    A given JAMS object will be transformed sequentially by
    each stage of the pipeline.

    The pipeline induces a graph over transformers

    Attributes
    ----------
    steps : argument array
        steps[i] is a tuple of `(name, Transformer)`

    Examples
    --------
    >>> P = muda.deformers.PitchShift(semitones=5)
    >>> T = muda.deformers.TimeStretch(speed=1.25)
    >>> Pipe = muda.Pipeline(steps=[('Pitch:maj3', P), ('Speed:1.25x', T)])
    >>> output_jams = list(Pipe.transform(jam_in))

    See Also
    --------
    Union
    '''

    def __init__(self, steps=None):
        if steps is None:
            steps = []
        self.steps = steps

    def get_params(self):
        '''Get the parameters for this object.  Returns as a dict.'''
        params = {}
        for name, transformer in self.steps:
            if hasattr(transformer, 'get_params'):
                params[name] = transformer.get_params()
            else:
                params[name] = transformer
        return params

    def __repr__(self):
        '''Pretty-print the object'''
        step_strs = []
        for name, transformer in self.steps:
            step_strs.append(f""('{name}', {repr(transformer)})"")
        return f""Pipeline(steps=[{', '.join(step_strs)}])""

    def __recursive_transform(self, jam, steps):
        '''A recursive transformation pipeline'''
        if not steps:
            yield jam
        else:
            name, transformer = steps[0]
            remaining_steps = steps[1:]
            for transformed_jam in transformer.transform(jam):
                yield from self.__recursive_transform(transformed_jam, remaining_steps)

    def transform(self, jam):
        '''Apply the sequence of transformations to a single jam object.

        Parameters
        ----------
        jam : jams.JAMS
            The jam object to transform

        Yields
        ------
        jam_out : jams.JAMS
            The jam objects produced by the transformation sequence
        '''
        yield from self.__recursive_transform(jam, self.steps)",partial_docstr,0.8034188034188035,0.6209262435677531,0.5438898450946644,0.7213675213675214,0.6250245083462762,0.837696335078534,0.6188811188811189,0.5341506129597198,0.9208683967590332,0.9200016260147095,0.9204347729682922,0.9200882315635681,0.7867986688311688,0.8228571428571428,0.6883365200764818,0.6218809980806143,0.7619047619047619,0.5628453349531214,0.9175946547884187,0.7723214285714286,0.6778523489932886,0.9395918846130371,0.8977911472320557,0.9182160496711731,0.9018030762672424,0.8050960797342191,0.8105065666041276,0.6591337099811677,0.5784499054820417,0.7354596622889306,0.5337339700698015,0.9046563192904656,0.7133333333333334,0.623608017817372,0.9305990934371948,0.8945749998092651,0.9122315645217896,0.8980514407157898,0.7763034551495023,0.4892351912055876,0.4898067543783367,0.5399089176560068,0.4437086092715231,0.4835164835164835,0.4563148701140392,0.5198765706437761,0.5363704653032473,0.4503311258278146,0.3186813186813186,0.436028051132165,0.5150187918451093,0.5239045617993354,0.4304635761589404,0.2747252747252747
370114,ethan92429/onshapepy,ethan92429_onshapepy/onshapepy/assembly.py,onshapepy.assembly.Assembly,"class Assembly:


    def __init__(self, url):
        """""" Connect to an assembly that points to the assembly specified with the url.

        Args:
            - url (str): The url of the onshape item
        """"""
        # Accept either a url OR uri
        if isinstance(url, Uri):
            self.uri = url
        else:
            self.uri = Uri(url)


    def insert(self, part):
        """""" Insert a part into this assembly.

        Args:
            - part (onshapepy.part.Part) A Part instance that will be inserted.

        Returns:
            - requests.Response: Onshape response data

        """"""
        params = {k: str(v) for k,v in part.params.items()}
        res=c.create_assembly_instance(self.uri.as_dict(), part.uri.as_dict(), params)
        return res","class Assembly:


    def __init__(self, url):
    ''' Connect to an assembly that points to the assembly specified with the url.

        Args:
            - url (str): The url of the onshape item
        '''
        pass

    def insert(self, part):
    ''' Insert a part into this assembly.

        Args:
            - part (onshapepy.part.Part) A Part instance that will be inserted.

        Returns:
            - requests.Response: Onshape response data

        '''
        pass

",3,2,snippet_366,0.2857142857142857,"class Assembly:
    def __init__(self, url):
        ''' Connect to an assembly that points to the assembly specified with the url.

            Args:
                - url (str): The url of the onshape item
        '''
        self.client = Client()
        self._did, self._wvm, self._wvm_id, self._eid = self._parse_url(url)

    def insert(self, part):
        ''' Insert a part into this assembly.

            Args:
                - part (onshapepy.part.Part) A Part instance that will be inserted.

            Returns:
                - requests.Response: Onshape response data
        '''
        did2, wvm2, wvm2_id, eid2 = self._parse_url(part.url)
        path = f""assemblies/d/{self._did}/{self._wvm}/{self._wvm_id}/e/{self._eid}/instances""
        body = {
            ""sourceDocumentId"": did2,
            ""sourceWorkspaceId"": wvm2 == ""w"" and wvm2_id or None,
            ""sourceVersionId"":    wvm2 == ""v"" and wvm2_id or None,
            ""sourceElementId"":    eid2,
            ""sourceMicroversion"": None,
            ""transformation"": {
                ""translation"": [0, 0, 0],
                ""rotation"":    [0, 0, 1, 0]
            }
        }
        return self.client.post(path, body)

    def _parse_url(self, url):
        m = re.search(r""/documents/([^/]+)/([wv])/([^/]+)/e/([^/?#]+)"", url)
        if not m:
            raise ValueError(f""Invalid Onshape URL: {url}"")
        return m.group(1), m.group(2), m.group(3), m.group(4)","class Assembly:
    def __init__(self, url):
        ''' Connect to an assembly that points to the assembly specified with the url.

        Args:
            - url (str): The url of the onshape item
        '''
        self.url = url
        self.session = requests.Session()

    def insert(self, part):
        ''' Insert a part into this assembly.

        Args:
            - part (onshapepy.part.Part) A Part instance that will be inserted.

        Returns:
            - requests.Response: Onshape response data

        '''
        # Assuming the part has a method to get its data for insertion
        part_data = part.get_data() if hasattr(part, 'get_data') else part
        
        # Make API call to insert the part into the assembly
        response = self.session.post(
            f""{self.url}/insert"",
            json=part_data
        )
        
        return response","class Assembly:
    def __init__(self, url):
        ''' Connect to an assembly that points to the assembly specified with the url.

        Args:
            - url (str): The url of the onshape item
        '''
        self.url = url
        self._parse_url()
        
    def _parse_url(self):
        parsed = urlparse(self.url)
        path_parts = parsed.path.strip('/').split('/')
        
        if 'documents' in path_parts:
            doc_index = path_parts.index('documents')
            self.document_id = path_parts[doc_index + 1]
            
        if 'w' in path_parts:
            w_index = path_parts.index('w')
            self.workspace_id = path_parts[w_index + 1]
        elif 'v' in path_parts:
            v_index = path_parts.index('v')
            self.version_id = path_parts[v_index + 1]
            self.workspace_id = None
        elif 'm' in path_parts:
            m_index = path_parts.index('m')
            self.microversion_id = path_parts[m_index + 1]
            self.workspace_id = None
            
        if 'e' in path_parts:
            e_index = path_parts.index('e')
            self.element_id = path_parts[e_index + 1]

    def insert(self, part):
        ''' Insert a part into this assembly.

        Args:
            - part (onshapepy.part.Part) A Part instance that will be inserted.

        Returns:
            - requests.Response: Onshape response data

        '''
        base_url = ""https://cad.onshape.com/api/assemblies/d""
        
        if hasattr(self, 'workspace_id') and self.workspace_id:
            url = f""{base_url}/{self.document_id}/w/{self.workspace_id}/e/{self.element_id}/instances""
        elif hasattr(self, 'version_id'):
            url = f""{base_url}/{self.document_id}/v/{self.version_id}/e/{self.element_id}/instances""
        elif hasattr(self, 'microversion_id'):
            url = f""{base_url}/{self.document_id}/m/{self.microversion_id}/e/{self.element_id}/instances""
        
        payload = {
            ""documentId"": part.document_id,
            ""elementId"": part.element_id,
            ""partId"": part.part_id,
            ""isAssembly"": False,
            ""isWholePartStudio"": False
        }
        
        if hasattr(part, 'workspace_id') and part.workspace_id:
            payload[""versionId""] = part.workspace_id
        elif hasattr(part, 'version_id'):
            payload[""versionId""] = part.version_id
        elif hasattr(part, 'microversion_id'):
            payload[""microversionId""] = part.microversion_id
            
        headers = {
            'Content-Type': 'application/json'
        }
        
        response = requests.post(url, json=payload, headers=headers)
        return response",partial_docstr,0.49816849816849823,0.4059040590405904,0.3940520446096655,0.45421245421245415,0.2717188393810236,0.3838383838383838,0.2481012658227848,0.21065989847715735,0.7347200512886047,0.8763958811759949,0.7993287444114685,0.8598160743713379,0.732512962962963,0.6635071090047393,0.5167464114832536,0.5024154589371981,0.6161137440758294,0.5391209432178681,0.7374301675977654,0.5224719101123596,0.4576271186440678,0.8835378289222717,0.879931628704071,0.8817310333251953,0.8802909851074219,0.8453623711340206,0.33175355450236965,0.26666666666666666,0.2488038277511962,0.31279620853080564,0.16522509138474356,0.23583460949464014,0.15184049079754602,0.1259600614439324,0.7234587669372559,0.8677928447723389,0.7890799045562744,0.8508185744285583,0.7085077160493838,0.4159912999891687,0.360605855019988,0.5693237952329343,0.3469387755102041,0.3870967741935484,0.4677546157893284,0.4870027734716765,0.5854640109496267,0.3469387755102041,0.4516129032258064,0.4144425305461577,0.2431114565013678,0.5838489224311235,0.3469387755102041,0.4838709677419355
502712,ivanprjcts/sdklib,ivanprjcts_sdklib/sdklib/html/base.py,sdklib.html.base.HTMLLxmlMixin,"class HTMLLxmlMixin(object):

    def find_element_by_xpath(self, xpath):
        """"""
        Finds an element by xpath.

        :param xpath: The xpath locator of the element to find.
        :return: ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        """"""
        elems = self.find_elements_by_xpath(xpath)
        if isinstance(elems, list) and len(elems) > 0:
            return elems[0]

    def find_elements_by_xpath(self, xpath):
        """"""
        Finds multiple elements by xpath.

        :param xpath: The xpath locator of the elements to be found.
        :return: list of ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        """"""
        from sdklib.html.elem import ElemLxml

        elements = self.html_obj.xpath(xpath)
        return [ElemLxml(e) for e in elements]","class HTMLLxmlMixin(object):


    def find_element_by_xpath(self, xpath):
    '''
        Finds an element by xpath.

        :param xpath: The xpath locator of the element to find.
        :return: ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        '''
        pass

    def find_elements_by_xpath(self, xpath):
    '''
        Finds multiple elements by xpath.

        :param xpath: The xpath locator of the elements to be found.
        :return: list of ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        '''
        pass

",3,2,snippet_448,0.3333333333333333,"class HTMLLxmlMixin(object):

    def _get_lxml_tree(self):
        return html.fromstring(self.html)

    def find_element_by_xpath(self, xpath):
        elems = self._get_lxml_tree().xpath(xpath)
        if not elems:
            return None
        return ElemLxml(elems[0])

    def find_elements_by_xpath(self, xpath):
        return [ElemLxml(el) for el in self._get_lxml_tree().xpath(xpath)]","class HTMLLxmlMixin(object):

    def find_element_by_xpath(self, xpath):
        '''
        Finds an element by xpath.

        :param xpath: The xpath locator of the element to find.
        :return: ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        '''
        elements = self.xpath(xpath)
        if elements:
            return elements[0]
        return None

    def find_elements_by_xpath(self, xpath):
        '''
        Finds multiple elements by xpath.

        :param xpath: The xpath locator of the elements to be found.
        :return: list of ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        '''
        return self.xpath(xpath)","class HTMLLxmlMixin(object):

    def find_element_by_xpath(self, xpath):
        '''
        Finds an element by xpath.

        :param xpath: The xpath locator of the element to find.
        :return: ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        '''
        elements = self._lxml.xpath(xpath)
        if elements:
            return ElemLxml(elements[0], self)
        return None

    def find_elements_by_xpath(self, xpath):
        '''
        Finds multiple elements by xpath.

        :param xpath: The xpath locator of the elements to be found.
        :return: list of ElemLxml

        See lxml xpath expressions `here <http://lxml.de/xpathxslt.html#xpath>`_
        '''
        elements = self._lxml.xpath(xpath)
        return [ElemLxml(element, self) for element in elements]",partial_docstr,0.48809523809523814,0.3132530120481928,0.2073170731707317,0.369047619047619,0.2291175452850156,0.7927927927927928,0.5272727272727272,0.3944954128440367,0.8813325762748718,0.8029289841651917,0.8403058648109436,0.8101359605789185,0.7439049999999999,0.8725490196078431,0.792079207920792,0.7300000000000001,0.8333333333333334,0.6603970040188643,0.9622641509433962,0.8924050632911392,0.8343949044585988,0.9797371625900269,0.935655415058136,0.9571889638900757,0.9398842453956604,0.8617900000000001,0.861111111111111,0.766355140186916,0.7075471698113207,0.8425925925925926,0.7281725227565152,0.9184782608695652,0.8142076502732241,0.7527472527472527,0.9745175838470459,0.9498511552810669,0.9620262980461121,0.9522615075111389,0.89431,0.2699707989946842,0.0112748001394912,0.0336433608742107,0.3076923076923077,0.7272727272727273,0.5129385922257981,0.6087905010814273,0.6038030286609258,0.3846153846153846,0.4545454545454545,0.6047375931603332,0.6290661672849842,0.6267140421861854,0.4358974358974359,0.7272727272727273
255038,awslabs/aws-shell,awslabs_aws-shell/awsshell/resource/index.py,awsshell.resource.index.CompleterDescriber,"class CompleterDescriber(object):
    """"""Describes how to autocomplete a resource.

    You give this class a service/operation/param and it will
    describe to you how you can autocomplete values for the
    provided parameter.

    It's up to the caller to actually take that description
    and make the appropriate service calls + filtering to
    extract out the server side values.

    """"""
    def __init__(self, resource_index):
        self._index = resource_index

    def describe_autocomplete(self, service, operation, param):
        """"""Describe operation and args needed for server side completion.

        :type service: str
        :param service: The AWS service name.

        :type operation: str
        :param operation: The AWS operation name.

        :type param: str
        :param param: The name of the parameter being completed.  This must
            match the casing in the service model (e.g. InstanceIds, not
            --instance-ids).

        :rtype: ServerCompletion
        :return: A ServerCompletion object that describes what API call to make
            in order to complete the response.

        """"""
        service_index = self._index[service]
        LOG.debug(service_index)
        if param not in service_index.get('operations', {}).get(operation, {}):
            LOG.debug(""param not in index: %s"", param)
            return None
        p = service_index['operations'][operation][param]
        resource_name = p['resourceName']
        resource_identifier = p['resourceIdentifier']

        resource_index = service_index['resources'][resource_name]
        completion_operation = resource_index['operation']
        path = resource_index['resourceIdentifier'][resource_identifier]
        return ServerCompletion(service=service, operation=completion_operation,
                                params={}, path=path)","class CompleterDescriber(object):
    '''Describes how to autocomplete a resource.

    You give this class a service/operation/param and it will
    describe to you how you can autocomplete values for the
    provided parameter.

    It's up to the caller to actually take that description
    and make the appropriate service calls + filtering to
    extract out the server side values.

    '''

    def __init__(self, resource_index):
        pass

    def describe_autocomplete(self, service, operation, param):
    '''Describe operation and args needed for server side completion.

        :type service: str
        :param service: The AWS service name.

        :type operation: str
        :param operation: The AWS operation name.

        :type param: str
        :param param: The name of the parameter being completed.  This must
            match the casing in the service model (e.g. InstanceIds, not
            --instance-ids).

        :rtype: ServerCompletion
        :return: A ServerCompletion object that describes what API call to make
            in order to complete the response.

        '''
        pass

",3,2,snippet_713,0.6,"class CompleterDescriber(object):
    '''Describes how to autocomplete a resource.

    You give this class a service/operation/param and it will
    describe to you how you can autocomplete values for the
    provided parameter.

    It's up to the caller to actually take that description
    and make the appropriate service calls + filtering to
    extract out the server side values.

    '''

    def __init__(self, resource_index):
        self._resource_index = resource_index

    def describe_autocomplete(self, service, operation, param):
        '''Describe operation and args needed for server side completion.

        :type service: str
        :param service: The AWS service name.

        :type operation: str
        :param operation: The AWS operation name.

        :type param: str
        :param param: The name of the parameter being completed.  This must
            match the casing in the service model (e.g. InstanceIds, not
            --instance-ids).

        :rtype: ServerCompletion
        :return: A ServerCompletion object that describes what API call to make
            in order to complete the response.

        '''
        try:
            ops = self._resource_index[service][operation]
        except (KeyError, TypeError):
            return None
        completion = ops.get(param)
        if not completion:
            return None
        # support single dict or list of dicts
        comp = completion[0] if isinstance(completion, list) and completion else completion
        args = comp.get('parameters', comp.get('params', {})) or {}
        path = comp.get('path')
        svc = comp.get('service', service)
        op = comp.get('operation', operation)
        return ServerCompletion(svc, op, args, path)","class CompleterDescriber(object):
    '''Describes how to autocomplete a resource.

    You give this class a service/operation/param and it will
    describe to you how you can autocomplete values for the
    provided parameter.

    It's up to the caller to actually take that description
    and make the appropriate service calls + filtering to
    extract out the server side values.

    '''

    def __init__(self, resource_index):
        self.resource_index = resource_index

    def describe_autocomplete(self, service, operation, param):
        '''Describe operation and args needed for server side completion.

        :type service: str
        :param service: The AWS service name.

        :type operation: str
        :param operation: The AWS operation name.

        :type param: str
        :param param: The name of the parameter being completed.  This must
            match the casing in the service model (e.g. InstanceIds, not
            --instance-ids).

        :rtype: ServerCompletion
        :return: A ServerCompletion object that describes what API call to make
            in order to complete the response.

        '''
        # Look up the completion information in the resource index
        service_completions = self.resource_index.get(service, {})
        operation_completions = service_completions.get(operation, {})
        param_completion = operation_completions.get(param)
        
        if param_completion is None:
            return None
            
        # Extract the service, operation, and args from the completion info
        completion_service = param_completion.get('service', service)
        completion_operation = param_completion.get('operation', operation)
        completion_args = param_completion.get('args', {})
        
        return ServerCompletion(completion_service, completion_operation, completion_args)","class CompleterDescriber(object):
    '''Describes how to autocomplete a resource.

    You give this class a service/operation/param and it will
    describe to you how you can autocomplete values for the
    provided parameter.

    It's up to the caller to actually take that description
    and make the appropriate service calls + filtering to
    extract out the server side values.

    '''

    def __init__(self, resource_index):
        self._resource_index = resource_index

    def describe_autocomplete(self, service, operation, param):
        '''Describe operation and args needed for server side completion.

        :type service: str
        :param service: The AWS service name.

        :type operation: str
        :param operation: The AWS operation name.

        :type param: str
        :param param: The name of the parameter being completed.  This must
            match the casing in the service model (e.g. InstanceIds, not
            --instance-ids).

        :rtype: ServerCompletion
        :return: A ServerCompletion object that describes what API call to make
            in order to complete the response.

        '''
        if service not in self._resource_index:
            return None
        
        service_data = self._resource_index[service]
        
        if 'operations' not in service_data:
            return None
            
        if operation not in service_data['operations']:
            return None
            
        operation_data = service_data['operations'][operation]
        
        if 'params' not in operation_data:
            return None
            
        if param not in operation_data['params']:
            return None
            
        param_data = operation_data['params'][param]
        
        if 'completions' not in param_data:
            return None
            
        completion_data = param_data['completions']
        
        return ServerCompletion(
            operation=completion_data.get('operation'),
            path=completion_data.get('path'),
            params=completion_data.get('params', {})
        )",partial_docstr,0.7935034802784223,0.7086247086247086,0.6697892271662763,0.7470997679814385,0.6312553716201861,0.8024316109422492,0.6920731707317073,0.6238532110091743,0.9287554621696472,0.9381952285766602,0.9334514141082764,0.9372426271438599,0.8209894444444444,0.8237986270022882,0.7310344827586207,0.6605080831408776,0.7734553775743707,0.6591433476669293,0.8313609467455622,0.6913946587537092,0.6279761904761905,0.9388983845710754,0.9382302761077881,0.9385642409324646,0.9382969737052917,0.8209894444444444,0.8175824175824176,0.7019867549668874,0.6474501108647449,0.7604395604395604,0.6924500996070362,0.8176795580110497,0.6786703601108033,0.6083333333333333,0.9386398196220398,0.9429702758789062,0.9408000111579895,0.942535400390625,0.8352289204545454,0.5734587266385829,0.6637807291153428,0.7265247656742831,0.4133333333333333,0.4901960784313725,0.5519339353356646,0.676555387246262,0.725690158017965,0.4133333333333333,0.392156862745098,0.6375221939422873,0.6614755527902303,0.7450838112142129,0.6533333333333333,0.4901960784313725
208266,Xion/taipan,Xion_taipan/taipan/api/properties.py,taipan.api.properties.classproperty,"class classproperty(object):
    """"""A read-only class property.

    Usage is exactly analogous to ``@property`` decorator.
    However, it's only possible to create a getter.
    """"""
    def __init__(self, getter):
        ensure_callable(getter)
        self.getter = getter

    def __get__(self, instance, owner):
        return self.getter(owner)","class classproperty(object):
    '''A read-only class property.

    Usage is exactly analogous to ``@property`` decorator.
    However, it's only possible to create a getter.
    '''

    def __init__(self, getter):
        pass

    def __get__(self, instance, owner):
        pass

",3,1,snippet_765,0.75,"class classproperty(object):
    '''A read-only class property.

    Usage is exactly analogous to ``@property`` decorator.
    However, it's only possible to create a getter.
    '''

    def __init__(self, getter):
        self.fget = getter
        self.__doc__ = getter.__doc__
        self.__name__ = getattr(getter, ""__name__"", None)
        self.__module__ = getattr(getter, ""__module__"", None)

    def __get__(self, instance, owner):
        if owner is None:
            owner = type(instance)
        return self.fget(owner)

    def __set__(self, instance, value):
        raise AttributeError(""can't set class property"")

    def __delete__(self, instance):
        raise AttributeError(""can't delete class property"")","class classproperty(object):
    '''A read-only class property.

    Usage is exactly analogous to ``@property`` decorator.
    However, it's only possible to create a getter.
    '''

    def __init__(self, getter):
        self.getter = getter

    def __get__(self, instance, owner):
        if owner is None:
            return self
        return self.getter(owner)","class classproperty(object):
    '''A read-only class property.

    Usage is exactly analogous to ``@property`` decorator.
    However, it's only possible to create a getter.
    '''

    def __init__(self, getter):
        self.getter = getter

    def __get__(self, instance, owner):
        return self.getter(owner)",partial_docstr,0.6356589147286822,0.5196850393700788,0.4640000000000001,0.6201550387596899,0.3496721848660981,0.43157894736842106,0.3386243386243386,0.2925531914893617,0.830802321434021,0.9496359825134277,0.8862534761428833,0.9362444281578064,0.7894757894736841,0.898876404494382,0.8735632183908046,0.8235294117647058,0.898876404494382,0.8034247932908166,0.8888888888888888,0.85,0.7974683544303798,0.9705520272254944,0.9737673997879028,0.9721570014953613,0.973444938659668,0.9090918181818182,0.963855421686747,0.962962962962963,0.9367088607594938,0.963855421686747,0.8003312988751536,0.972972972972973,0.9315068493150684,0.8888888888888888,0.9930937886238098,0.9733055830001831,0.9831001162528992,0.9752488136291504,0.9603178571428572,0.5919914111365141,0.3112597196617354,0.656705924884321,0.6,0.8,0.7065185865858832,0.6370082049877988,0.7390661413557337,0.55,0.9,0.7766250124454508,0.7749704396167848,0.7815296101650185,0.65,0.9
239305,apache/incubator-mxnet,apache_incubator-mxnet/python/mxnet/profiler.py,mxnet.profiler.Event,"class Event(object):
    """"""Profiling Event class.

    The event API is used to observe when demarcated events occur in your application, or to
    identify how long it takes to execute demarcated regions of code. Set annotations in the
    application to demarcate areas where events of interest occur.
    After running analysis, you can see the events marked in the Timeline pane.
    Event API is a per-thread function that works in resumed state.
    This function does not work in paused state.

    Parameters
    ----------
    name : string
        Name of the event
    """"""
    def __init__(self, name):
        self.name = name
        self.handle = ProfileHandle()
        check_call(_LIB.MXProfileCreateEvent(c_str(self.name), ctypes.byref(self.handle)))

    def __del__(self):
        if self.handle is not None:
            check_call(_LIB.MXProfileDestroyHandle(self.handle))

    def start(self):
        """"""Start timing scope for this object""""""
        check_call(_LIB.MXProfileDurationStart(self.handle))

    def stop(self):
        """"""Stop timing scope for this object""""""
        check_call(_LIB.MXProfileDurationStop(self.handle))

    def __str__(self):
        return self.name","class Event(object):
    '''Profiling Event class.

    The event API is used to observe when demarcated events occur in your application, or to
    identify how long it takes to execute demarcated regions of code. Set annotations in the
    application to demarcate areas where events of interest occur.
    After running analysis, you can see the events marked in the Timeline pane.
    Event API is a per-thread function that works in resumed state.
    This function does not work in paused state.

    Parameters
    ----------
    name : string
        Name of the event
    '''

    def __init__(self, name):
        pass

    def __del__(self):
        pass

    def start(self):
    '''Start timing scope for this object'''
        pass

    def stop(self):
    '''Stop timing scope for this object'''
        pass

    def __str__(self):
        pass

",6,3,snippet_287,0.375,"class Event(object):
    '''Profiling Event class.

    The event API is used to observe when demarcated events occur in your application, or to
    identify how long it takes to execute demarcated regions of code. Set annotations in the
    application to demarcate areas where events of interest occur.
    After running analysis, you can see the events marked in the Timeline pane.
    Event API is a per-thread function that works in resumed state.
    This function does not work in paused state.

    Parameters
    ----------
    name : string
        Name of the event
    '''

    def __init__(self, name):
        self.name = str(name)
        self._start_time = None
        self.duration = 0.0
        self._running = False

    def __del__(self):
        if self._running:
            self.stop()

    def start(self):
        '''Start timing scope for this object'''
        if self._running:
            raise RuntimeError(f""Event '{self.name}' is already running"")
        self._start_time = time.perf_counter()
        self._running = True

    def stop(self):
        '''Stop timing scope for this object'''
        if not self._running:
            raise RuntimeError(f""Event '{self.name}' is not running"")
        end_time = time.perf_counter()
        self.duration += end_time - self._start_time
        self._start_time = None
        self._running = False

    def __str__(self):
        state = ""running"" if self._running else ""stopped""
        return (f""Event(name='{self.name}', state={state}, ""
                f""duration={self.duration:.6f}s)"")","class Event(object):
    '''Profiling Event class.

    The event API is used to observe when demarcated events occur in your application, or to
    identify how long it takes to execute demarcated regions of code. Set annotations in the
    application to demarcate areas where events of interest occur.
    After running analysis, you can see the events marked in the Timeline pane.
    Event API is a per-thread function that works in resumed state.
    This function does not work in paused state.

    Parameters
    ----------
    name : string
        Name of the event
    '''

    def __init__(self, name):
        self.name = name
        self._start_time = None
        self._end_time = None
        self._active = False

    def __del__(self):
        if self._active:
            self.stop()

    def start(self):
        '''Start timing scope for this object'''
        import time
        if not self._active:
            self._start_time = time.time()
            self._end_time = None
            self._active = True

    def stop(self):
        '''Stop timing scope for this object'''
        import time
        if self._active:
            self._end_time = time.time()
            self._active = False

    def __str__(self):
        if self._start_time is None:
            return f""Event('{self.name}') - not started""
        elif self._active:
            return f""Event('{self.name}') - active since {self._start_time}""
        else:
            duration = self._end_time - self._start_time
            return f""Event('{self.name}') - duration: {duration:.6f}s""","class Event(object):
    '''Profiling Event class.

    The event API is used to observe when demarcated events occur in your application, or to
    identify how long it takes to execute demarcated regions of code. Set annotations in the
    application to demarcate areas where events of interest occur.
    After running analysis, you can see the events marked in the Timeline pane.
    Event API is a per-thread function that works in resumed state.
    This function does not work in paused state.

    Parameters
    ----------
    name : string
        Name of the event
    '''

    def __init__(self, name):
        self.name = name
        self.start_time = None
        self.end_time = None
        self.duration = None
        self.is_running = False

    def __del__(self):
        if self.is_running:
            self.stop()

    def start(self):
        '''Start timing scope for this object'''
        if not self.is_running:
            self.start_time = time.time()
            self.end_time = None
            self.duration = None
            self.is_running = True

    def stop(self):
        '''Stop timing scope for this object'''
        if self.is_running:
            self.end_time = time.time()
            self.duration = self.end_time - self.start_time
            self.is_running = False

    def __str__(self):
        if self.duration is not None:
            return f""Event(name='{self.name}', duration={self.duration:.6f}s)""
        elif self.is_running:
            return f""Event(name='{self.name}', status='running')""
        else:
            return f""Event(name='{self.name}', status='not started')""",partial_docstr,0.7247956403269755,0.6410958904109589,0.5950413223140495,0.6975476839237057,0.4865452698438816,0.6292134831460674,0.4563380281690141,0.4011299435028249,0.8658304214477539,0.8987258672714233,0.8819714784622192,0.8953243494033813,0.772438173076923,0.7213114754098361,0.6428571428571428,0.6077348066298343,0.6994535519125684,0.4847564677089024,0.5988700564971752,0.46175637393767704,0.4119318181818182,0.8739649653434753,0.8967490792274475,0.8852104544639587,0.8944173455238342,0.7889468341708546,0.6984126984126985,0.6329787234042552,0.5935828877005348,0.6825396825396826,0.4775507098737333,0.5867768595041323,0.4558011049723757,0.407202216066482,0.8744684457778931,0.8967803716659546,0.8854839205741882,0.8944980502128601,0.78862,0.4375915175428794,0.5519209625453306,0.76380015059317,0.3134328358208955,0.1212121212121212,0.5857751633891192,0.5480566610674595,0.7701683705984701,0.3582089552238806,0.6666666666666666,0.5831691069633491,0.5619336721623501,0.7761701641035296,0.3582089552238806,0.6363636363636364
624720,p3trus/slave,p3trus_slave/slave/types.py,slave.types.Stream,"class Stream(object):
    """"""A type container for a variable number of types.

    :param args: A sequence of types.

    The :class:`Stream` class is a type container for variable numbers of types.
    Let's say a command returns the content of an internal buffer which can
    contain a variable number of Floats. The corresponding slave command could
    look like this::

        Command('QRY?', 'WRT', Stream(Float))

    A command of alternating floats and integers is therefore writen as::

        Command('QRY?', 'WRT', Stream(Float, Integer))

    """"""
    def __init__(self, *types):
        self.types = [_to_instance(t) for t in types]

    def simulate(self):
        """"""Simulates a stream of types.""""""
        # Simulates zero to 10 types
        return [t.simulate() for t in itertools.islice(self, random.choice(range(10)))]

    def __iter__(self):
        return itertools.cycle(self.types)","class Stream(object):
    '''A type container for a variable number of types.

    :param args: A sequence of types.

    The :class:`Stream` class is a type container for variable numbers of types.
    Let's say a command returns the content of an internal buffer which can
    contain a variable number of Floats. The corresponding slave command could
    look like this::

        Command('QRY?', 'WRT', Stream(Float))

    A command of alternating floats and integers is therefore writen as::

        Command('QRY?', 'WRT', Stream(Float, Integer))

    '''

    def __init__(self, *types):
        pass

    def simulate(self):
    '''Simulates a stream of types.'''
        pass

    def __iter__(self):
        pass

",4,2,snippet_412,0.7777777777777778,"class Stream(object):
    '''A type container for a variable number of types.

    :param args: A sequence of types.

    The :class:`Stream` class is a type container for variable numbers of types.
    Let's say a command returns the content of an internal buffer which can
    contain a variable number of Floats. The corresponding slave command could
    look like this::

        Command('QRY?', 'WRT', Stream(Float))

    A command of alternating floats and integers is therefore writen as::

        Command('QRY?', 'WRT', Stream(Float, Integer))

    '''

    def __init__(self, *types):
        if not types:
            raise ValueError(""Stream requires at least one type"")
        for t in types:
            if not isinstance(t, type):
                raise TypeError(""Stream arguments must be types"")
        self._types = types

    def simulate(self):
        '''Simulates a stream of types.'''
        for tp in itertools.cycle(self._types):
            sim = getattr(tp, 'simulate', None)
            if callable(sim):
                yield sim()
            else:
                yield tp()

    def __iter__(self):
        return iter(self._types)","class Stream(object):
    '''A type container for a variable number of types.

    :param args: A sequence of types.

    The :class:`Stream` class is a type container for variable numbers of types.
    Let's say a command returns the content of an internal buffer which can
    contain a variable number of Floats. The corresponding slave command could
    look like this::

        Command('QRY?', 'WRT', Stream(Float))

    A command of alternating floats and integers is therefore writen as::

        Command('QRY?', 'WRT', Stream(Float, Integer))

    '''

    def __init__(self, *types):
        self.types = types

    def simulate(self):
        '''Simulates a stream of types.'''
        import itertools
        return itertools.cycle(self.types)

    def __iter__(self):
        return self.simulate()","class Stream(object):
    '''A type container for a variable number of types.

    :param args: A sequence of types.

    The :class:`Stream` class is a type container for variable numbers of types.
    Let's say a command returns the content of an internal buffer which can
    contain a variable number of Floats. The corresponding slave command could
    look like this::

        Command('QRY?', 'WRT', Stream(Float))

    A command of alternating floats and integers is therefore writen as::

        Command('QRY?', 'WRT', Stream(Float, Integer))

    '''

    def __init__(self, *types):
        self.types = types

    def simulate(self):
        '''Simulates a stream of types.'''
        import random
        num_items = random.randint(1, 10)
        result = []
        for i in range(num_items):
            type_to_use = self.types[i % len(self.types)]
            if hasattr(type_to_use, 'simulate'):
                result.append(type_to_use.simulate())
            else:
                result.append(type_to_use())
        return result

    def __iter__(self):
        return iter(self.types)",partial_docstr,0.8129496402877697,0.7536231884057971,0.7080291970802919,0.776978417266187,0.665493757448807,0.7642276422764228,0.6489795918367347,0.5942622950819673,0.8989324569702148,0.9419389963150024,0.9199333786964417,0.9374540448188782,0.8151278991596639,0.9113924050632912,0.8595744680851064,0.8326180257510729,0.8776371308016877,0.6995996215863459,0.9712643678160919,0.9132947976878613,0.872093023255814,0.9833052158355713,0.9394764304161072,0.9608912467956543,0.9436827898025513,0.8916677500000001,0.8218181818181819,0.7179487179487178,0.6937269372693726,0.770909090909091,0.6601864233396183,0.7549407114624506,0.6507936507936508,0.5856573705179283,0.9138993620872498,0.9358137845993042,0.9247267842292786,0.9335751533508301,0.8123268067226891,0.5181238998528532,0.5941501562458533,0.7305193562090381,0.4,0.3478260869565217,0.5221646368178438,0.7225020357336797,0.7237652071898691,0.425,0.217391304347826,0.5377792800799985,0.6708256179482385,0.7324654154152336,0.4,0.3478260869565217
174166,PythonCharmers/python-future,PythonCharmers_python-future/src/future/standard_library/__init__.py,src.future.standard_library.RenameImport,"class RenameImport(object):
    """"""
    A class for import hooks mapping Py3 module names etc. to the Py2 equivalents.
    """"""
    # Different RenameImport classes are created when importing this module from
    # different source files. This causes isinstance(hook, RenameImport) checks
    # to produce inconsistent results. We add this RENAMER attribute here so
    # remove_hooks() and install_hooks() can find instances of these classes
    # easily:
    RENAMER = True

    def __init__(self, old_to_new):
        '''
        Pass in a dictionary-like object mapping from old names to new
        names. E.g. {'ConfigParser': 'configparser', 'cPickle': 'pickle'}
        '''
        self.old_to_new = old_to_new
        both = set(old_to_new.keys()) & set(old_to_new.values())
        assert (len(both) == 0 and
                len(set(old_to_new.values())) == len(old_to_new.values())), \
               'Ambiguity in renaming (handler not implemented)'
        self.new_to_old = dict((new, old) for (old, new) in old_to_new.items())

    def find_module(self, fullname, path=None):
        # Handles hierarchical importing: package.module.module2
        new_base_names = set([s.split('.')[0] for s in self.new_to_old])
        # Before v0.12: Was: if fullname in set(self.old_to_new) | new_base_names:
        if fullname in new_base_names:
            return self
        return None

    def load_module(self, name):
        path = None
        if name in sys.modules:
            return sys.modules[name]
        elif name in self.new_to_old:
            # New name. Look up the corresponding old (Py2) name:
            oldname = self.new_to_old[name]
            module = self._find_and_load_module(oldname)
            # module.__future_module__ = True
        else:
            module = self._find_and_load_module(name)
        # In any case, make it available under the requested (Py3) name
        sys.modules[name] = module
        return module

    def _find_and_load_module(self, name, path=None):
        """"""
        Finds and loads it. But if there's a . in the name, handles it
        properly.
        """"""
        bits = name.split('.')
        while len(bits) > 1:
            # Treat the first bit as a package
            packagename = bits.pop(0)
            package = self._find_and_load_module(packagename, path)
            try:
                path = package.__path__
            except AttributeError:
                # This could be e.g. moves.
                flog.debug('Package {0} has no __path__.'.format(package))
                if name in sys.modules:
                    return sys.modules[name]
                flog.debug('What to do here?')

        name = bits[0]
        module_info = imp.find_module(name, path)
        return imp.load_module(name, *module_info)","class RenameImport(object):
    '''
    A class for import hooks mapping Py3 module names etc. to the Py2 equivalents.
    '''

    def __init__(self, old_to_new):
    '''
        Pass in a dictionary-like object mapping from old names to new
        names. E.g. {'ConfigParser': 'configparser', 'cPickle': 'pickle'}
        '''
        pass

    def find_module(self, fullname, path=None):
        pass

    def load_module(self, name):
        pass

    def _find_and_load_module(self, name, path=None):
    '''
        Finds and loads it. But if there's a . in the name, handles it
        properly.
        '''
        pass

",5,3,snippet_84,0.4166666666666667,"class RenameImport(object):
    '''
    A class for import hooks mapping Py3 module names etc. to the Py2 equivalents.
    '''

    def __init__(self, old_to_new):
        '''
        Pass in a dictionary-like object mapping from old names to new
        names. E.g. {'ConfigParser': 'configparser', 'cPickle': 'pickle'}
        '''
        self.old_to_new = dict(old_to_new)
        # sort keys by length so that longer (more specific) names match first
        self._keys = sorted(self.old_to_new, key=len, reverse=True)

    def find_module(self, fullname, path=None):
        for old in self._keys:
            if fullname == old or fullname.startswith(old + '.'):
                return self
        return None

    def load_module(self, fullname):
        if fullname in sys.modules:
            return sys.modules[fullname]

        for old in self._keys:
            if fullname == old or fullname.startswith(old + '.'):
                new = self.old_to_new[old]
                rest = fullname[len(old):]  # includes leading dot if submodule
                newname = new + rest
                break
        else:
            raise ImportError(fullname)

        module = self._find_and_load_module(newname)
        module.__name__ = fullname
        sys.modules[fullname] = module
        return module

    def _find_and_load_module(self, name, path=None):
        return importlib.import_module(name)","class RenameImport(object):
    '''
    A class for import hooks mapping Py3 module names etc. to the Py2 equivalents.
    '''

    def __init__(self, old_to_new):
        '''
        Pass in a dictionary-like object mapping from old names to new
        names. E.g. {'ConfigParser': 'configparser', 'cPickle': 'pickle'}
        '''
        self.old_to_new = old_to_new
        self.module = None

    def find_module(self, fullname, path=None):
        if fullname in self.old_to_new:
            self.module = fullname
            return self
        return None

    def load_module(self, name):
        if name in sys.modules:
            return sys.modules[name]
        
        if self.module is None:
            raise ImportError(""Module not found: {}"".format(name))
        
        new_name = self.old_to_new[self.module]
        module = self._find_and_load_module(new_name)
        sys.modules[name] = module
        return module

    def _find_and_load_module(self, name, path=None):
        '''
        Finds and loads it. But if there's a . in the name, handles it
        properly.
        '''
        if '.' in name:
            parts = name.split('.')
            current = None
            for part in parts:
                if current is None:
                    current = importlib.import_module(part)
                else:
                    current = getattr(current, part)
            return current
        else:
            return importlib.import_module(name)","class RenameImport(object):
    '''
    A class for import hooks mapping Py3 module names etc. to the Py2 equivalents.
    '''

    def __init__(self, old_to_new):
        '''
        Pass in a dictionary-like object mapping from old names to new
        names. E.g. {'ConfigParser': 'configparser', 'cPickle': 'pickle'}
        '''
        self.old_to_new = old_to_new

    def find_module(self, fullname, path=None):
        if fullname in self.old_to_new:
            return self
        return None

    def load_module(self, name):
        if name in sys.modules:
            return sys.modules[name]
        
        new_name = self.old_to_new.get(name, name)
        module = self._find_and_load_module(new_name)
        
        sys.modules[name] = module
        return module

    def _find_and_load_module(self, name, path=None):
        '''
        Finds and loads it. But if there's a . in the name, handles it
        properly.
        '''
        if '.' in name:
            parts = name.split('.')
            parent_name = '.'.join(parts[:-1])
            parent = importlib.import_module(parent_name)
            return importlib.import_module(name)
        else:
            return importlib.import_module(name)",partial_docstr,0.4954128440366973,0.3609576427255985,0.2846580406654344,0.4220183486238532,0.2106362871300369,0.8584905660377359,0.6624605678233438,0.5348101265822784,0.8803802728652954,0.7998376488685608,0.8381785154342651,0.8072226047515869,0.7799833144475923,0.5573770491803278,0.4241316270566728,0.37431192660550455,0.4918032786885246,0.22379394602804803,0.9012738853503185,0.7220447284345048,0.6089743589743589,0.9077496528625488,0.8141137361526489,0.8583857417106628,0.8225990533828735,0.7903703682719545,0.5437262357414449,0.45038167938931306,0.3946360153256705,0.5133079847908746,0.19302467239691956,0.9366197183098591,0.7915194346289752,0.6879432624113475,0.913543701171875,0.8091613054275513,0.85819011926651,0.8185137510299683,0.7903703682719545,0.231491327799082,0.1388327564316002,0.2083704028270159,0.4134078212290503,0.1653543307086614,0.2829041059580369,0.1908432898874406,0.2825230129751912,0.4692737430167598,0.1889763779527559,0.2528744462003691,0.1426277977363391,0.2723363135508628,0.4469273743016759,0.1496062992125984
566563,maximkulkin/lollipop,maximkulkin_lollipop/lollipop/errors.py,lollipop.errors.ValidationErrorBuilder,"class ValidationErrorBuilder(object):
    """"""Helper class to report multiple errors.

    Example: ::

        def validate_all(data):
            builder = ValidationErrorBuilder()
            if data['foo']['bar'] >= data['baz']['bam']:
                builder.add_error('foo.bar', 'Should be less than bam')
            if data['foo']['quux'] >= data['baz']['bam']:
                builder.add_fields('foo.quux', 'Should be less than bam')
            ...
            builder.raise_errors()
    """"""

    def __init__(self):
        self.errors = None

    def _make_error(self, path, error):
        parts = path.split('.', 1) if isinstance(path, string_types) else [path]

        if len(parts) == 1:
            return {path: error}
        else:
            return {parts[0]: self._make_error(parts[1], error)}

    def add_error(self, path, error):
        """"""Add error message for given field path.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_error('foo.bar.baz', 'Some error')
            print builder.errors
            # => {'foo': {'bar': {'baz': 'Some error'}}}

        :param str path: '.'-separated list of field names
        :param str error: Error message
        """"""
        self.errors = merge_errors(self.errors, self._make_error(path, error))

    def add_errors(self, errors):
        """"""Add errors in dict format.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_errors({'foo': {'bar': 'Error 1'}})
            builder.add_errors({'foo': {'baz': 'Error 2'}, 'bam': 'Error 3'})
            print builder.errors
            # => {'foo': {'bar': 'Error 1', 'baz': 'Error 2'}, 'bam': 'Error 3'}

        :param str, list or dict errors: Errors to merge
        """"""
        self.errors = merge_errors(self.errors, errors)

    def raise_errors(self):
        """"""Raise :exc:`ValidationError` if errors are not empty;
        do nothing otherwise.
        """"""
        if self.errors:
            raise ValidationError(self.errors)","class ValidationErrorBuilder(object):
    '''Helper class to report multiple errors.

    Example: ::

        def validate_all(data):
            builder = ValidationErrorBuilder()
            if data['foo']['bar'] >= data['baz']['bam']:
                builder.add_error('foo.bar', 'Should be less than bam')
            if data['foo']['quux'] >= data['baz']['bam']:
                builder.add_fields('foo.quux', 'Should be less than bam')
            ...
            builder.raise_errors()
    '''

    def __init__(self):
        pass

    def _make_error(self, path, error):
        pass

    def add_error(self, path, error):
    '''Add error message for given field path.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_error('foo.bar.baz', 'Some error')
            print builder.errors
            # => {'foo': {'bar': {'baz': 'Some error'}}}

        :param str path: '.'-separated list of field names
        :param str error: Error message
        '''
        pass

    def add_errors(self, errors):
    '''Add errors in dict format.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_errors({'foo': {'bar': 'Error 1'}})
            builder.add_errors({'foo': {'baz': 'Error 2'}, 'bam': 'Error 3'})
            print builder.errors
            # => {'foo': {'bar': 'Error 1', 'baz': 'Error 2'}, 'bam': 'Error 3'}

        :param str, list or dict errors: Errors to merge
        '''
        pass

    def raise_errors(self):
    '''Raise :exc:`ValidationError` if errors are not empty;
        do nothing otherwise.
        '''
        pass

",6,4,snippet_152,0.5454545454545454,"class ValidationErrorBuilder(object):
    '''Helper class to report multiple errors.

    Example: ::

        def validate_all(data):
            builder = ValidationErrorBuilder()
            if data['foo']['bar'] >= data['baz']['bam']:
                builder.add_error('foo.bar', 'Should be less than bam')
            if data['foo']['quux'] >= data['baz']['bam']:
                builder.add_error('foo.quux', 'Should be less than bam')
            ...
            builder.raise_errors()
    '''

    def __init__(self):
        self.errors = {}

    def _make_error(self, path, error):
        parts = path.split('.')
        node = error
        for key in reversed(parts):
            node = {key: node}
        return node

    def add_error(self, path, error):
        '''Add error message for given field path.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_error('foo.bar.baz', 'Some error')
            print builder.errors
            # => {'foo': {'bar': {'baz': 'Some error'}}}

        :param str path: '.'-separated list of field names
        :param str error: Error message
        '''
        new_err = self._make_error(path, error)
        self.add_errors(new_err)

    def add_errors(self, errors):
        '''Add errors in dict format.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_errors({'foo': {'bar': 'Error 1'}})
            builder.add_errors({'foo': {'baz': 'Error 2'}, 'bam': 'Error 3'})
            print builder.errors
            # => {'foo': {'bar': 'Error 1', 'baz': 'Error 2'}, 'bam': 'Error 3'}

        :param dict or list errors: Errors to merge
        '''
        if isinstance(errors, list):
            for e in errors:
                self.add_errors(e)
        elif isinstance(errors, dict):
            for key, val in errors.items():
                if key in self.errors and isinstance(self.errors[key], dict) and isinstance(val, dict):
                    # merge nested dicts
                    sub = ValidationErrorBuilder()
                    sub.errors = self.errors[key]
                    sub.add_errors(val)
                    self.errors[key] = sub.errors
                else:
                    self.errors[key] = val
        else:
            raise TypeError(""add_errors requires a dict or list of dicts"")

    def raise_errors(self):
        '''Raise :exc:`ValidationError` if errors are not empty;
            do nothing otherwise.
        '''
        if self.errors:
            raise ValidationError(self.errors)","class ValidationErrorBuilder(object):
    '''Helper class to report multiple errors.

    Example: ::

        def validate_all(data):
            builder = ValidationErrorBuilder()
            if data['foo']['bar'] >= data['baz']['bam']:
                builder.add_error('foo.bar', 'Should be less than bam')
            if data['foo']['quux'] >= data['baz']['bam']:
                builder.add_fields('foo.quux', 'Should be less than bam')
            ...
            builder.raise_errors()
    '''

    def __init__(self):
        self.errors = {}

    def _make_error(self, path, error):
        keys = path.split('.')
        result = error
        for key in reversed(keys):
            result = {key: result}
        return result

    def add_error(self, path, error):
        '''Add error message for given field path.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_error('foo.bar.baz', 'Some error')
            print builder.errors
            # => {'foo': {'bar': {'baz': 'Some error'}}}

        :param str path: '.'-separated list of field names
        :param str error: Error message
        '''
        error_dict = self._make_error(path, error)
        self.add_errors(error_dict)

    def add_errors(self, errors):
        '''Add errors in dict format.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_errors({'foo': {'bar': 'Error 1'}})
            builder.add_errors({'foo': {'baz': 'Error 2'}, 'bam': 'Error 3'})
            print builder.errors
            # => {'foo': {'bar': 'Error 1', 'baz': 'Error 2'}, 'bam': 'Error 3'}

        :param str, list or dict errors: Errors to merge
        '''
        if isinstance(errors, dict):
            self._merge_errors(self.errors, errors)
        elif isinstance(errors, list):
            for error in errors:
                if isinstance(error, dict):
                    self._merge_errors(self.errors, error)
        else:
            raise TypeError(""Errors must be a dict or list of dicts"")

    def _merge_errors(self, target, source):
        for key, value in source.items():
            if key in target and isinstance(target[key], dict) and isinstance(value, dict):
                self._merge_errors(target[key], value)
            else:
                target[key] = value

    def raise_errors(self):
        '''Raise :exc:`ValidationError` if errors are not empty;
        do nothing otherwise.
        '''
        if self.errors:
            raise ValidationError(self.errors)","class ValidationErrorBuilder(object):
    '''Helper class to report multiple errors.

    Example: ::

        def validate_all(data):
            builder = ValidationErrorBuilder()
            if data['foo']['bar'] >= data['baz']['bam']:
                builder.add_error('foo.bar', 'Should be less than bam')
            if data['foo']['quux'] >= data['baz']['bam']:
                builder.add_fields('foo.quux', 'Should be less than bam')
            ...
            builder.raise_errors()
    '''

    def __init__(self):
        self.errors = {}

    def _make_error(self, path, error):
        parts = path.split('.')
        result = {}
        current = result
        
        for part in parts[:-1]:
            current[part] = {}
            current = current[part]
        
        current[parts[-1]] = error
        return result

    def add_error(self, path, error):
        '''Add error message for given field path.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_error('foo.bar.baz', 'Some error')
            print builder.errors
            # => {'foo': {'bar': {'baz': 'Some error'}}}

        :param str path: '.'-separated list of field names
        :param str error: Error message
        '''
        error_dict = self._make_error(path, error)
        self.add_errors(error_dict)

    def add_errors(self, errors):
        '''Add errors in dict format.

        Example: ::

            builder = ValidationErrorBuilder()
            builder.add_errors({'foo': {'bar': 'Error 1'}})
            builder.add_errors({'foo': {'baz': 'Error 2'}, 'bam': 'Error 3'})
            print builder.errors
            # => {'foo': {'bar': 'Error 1', 'baz': 'Error 2'}, 'bam': 'Error 3'}

        :param str, list or dict errors: Errors to merge
        '''
        def merge_dicts(dict1, dict2):
            for key, value in dict2.items():
                if key in dict1:
                    if isinstance(dict1[key], dict) and isinstance(value, dict):
                        merge_dicts(dict1[key], value)
                    else:
                        dict1[key] = value
                else:
                    dict1[key] = value
        
        merge_dicts(self.errors, errors)

    def raise_errors(self):
        '''Raise :exc:`ValidationError` if errors are not empty;
        do nothing otherwise.
        '''
        if self.errors:
            raise ValidationError(self.errors)",partial_docstr,0.82421875,0.7294117647058823,0.6732283464566929,0.7656250000000001,0.7154623201474026,0.8018181818181818,0.7030965391621129,0.6496350364963503,0.9178855419158936,0.9515239000320435,0.9344020485877991,0.9480496048927307,0.7943282978723406,0.8271844660194174,0.7563352826510721,0.7084148727984345,0.7728155339805824,0.715078215488903,0.7914438502673797,0.7017857142857142,0.6583184257602862,0.9203740358352661,0.9541157484054565,0.9369412064552307,0.9506306052207947,0.8103467241379313,0.8629856850715746,0.7885010266940451,0.7546391752577319,0.8179959100204498,0.7552491842232516,0.8352490421455939,0.7408829174664108,0.6961538461538461,0.9161105155944824,0.9512050151824951,0.9333280324935913,0.9475749731063843,0.8142875714285713,0.5881396585000768,0.5497550051246987,0.6848897966760621,0.4444444444444444,0.673469387755102,0.5602345732024051,0.575832211359539,0.7169768297494015,0.4583333333333333,0.4897959183673469,0.5386820812021437,0.6275753779656816,0.7292504525118271,0.4305555555555556,0.3673469387755102
100868,Azure/azure-sdk-for-python,Azure_azure-sdk-for-python/sdk/mixedreality/azure-mixedreality-authentication/azure/mixedreality/authentication/_shared/mixedreality_account_key_credential.py,azure.mixedreality.authentication._shared.mixedreality_account_key_credential.MixedRealityAccountKeyCredential,"class MixedRealityAccountKeyCredential(object):
    """""" Represents an object used for Mixed Reality account key authentication.

    :param str account_id: The Mixed Reality service account identifier.
    :param AzureKeyCredential account_key: The Mixed Reality service account primary or secondary key credential.
    """"""

    def __init__(self, account_id, account_key):
        # type: (str, AzureKeyCredential) -> None
        self.account_id = account_id
        self.account_key = account_key

    def get_token(self, *scopes, **kwargs): #pylint: disable=unused-argument
        # type: (*str, **Any) -> AccessToken

        token = self.account_id + "":"" + self.account_key.key

        # No way to know when an account key might expire, so we'll set the
        # access token wrapping it to expire 10 years in the future.
        expiration_date = _add_years(datetime.now(), ACCOUNT_KEY_VALID_YEARS)
        expiration_timestamp = int(time.mktime(expiration_date.timetuple()))

        return AccessToken(token, expiration_timestamp)","class MixedRealityAccountKeyCredential(object):
    ''' Represents an object used for Mixed Reality account key authentication.

    :param str account_id: The Mixed Reality service account identifier.
    :param AzureKeyCredential account_key: The Mixed Reality service account primary or secondary key credential.
    '''

    def __init__(self, account_id, account_key):
        pass

    def get_token(self, *scopes, **kwargs):
        pass

",3,1,snippet_487,1.0,"class MixedRealityAccountKeyCredential(object):
    ''' Represents an object used for Mixed Reality account key authentication.

    :param str account_id: The Mixed Reality service account identifier.
    :param AzureKeyCredential account_key: The Mixed Reality service account primary or secondary key credential.
    '''

    def __init__(self, account_id, account_key):
        if not isinstance(account_id, str):
            raise TypeError(""account_id must be a string"")
        if not isinstance(account_key, AzureKeyCredential):
            raise TypeError(""account_key must be an AzureKeyCredential"")
        self._account_id = account_id
        self._account_key = account_key

    def get_token(self, *scopes, **kwargs):
        # Token valid for 24 hours
        expiry = int(time.time()) + 24 * 60 * 60

        # JWT header and payload
        header = {""alg"": ""HS256"", ""typ"": ""JWT""}
        payload = {""aud"": self._account_id, ""exp"": expiry}

        def _b64url_encode(data):
            raw = data if isinstance(data, bytes) else data.encode(""utf-8"")
            enc = base64.urlsafe_b64encode(raw)
            return enc.rstrip(b""="").decode(""utf-8"")

        header_b64 = _b64url_encode(json.dumps(header))
        payload_b64 = _b64url_encode(json.dumps(payload))
        signing_input = f""{header_b64}.{payload_b64}""

        # Decode the account key and sign
        key_bytes = base64.b64decode(self._account_key.key)
        signature = hmac.new(key_bytes, signing_input.encode(""utf-8""), hashlib.sha256).digest()
        signature_b64 = _b64url_encode(signature)

        token = f""{signing_input}.{signature_b64}""
        return AccessToken(token, expiry)","class MixedRealityAccountKeyCredential(object):
    ''' Represents an object used for Mixed Reality account key authentication.

    :param str account_id: The Mixed Reality service account identifier.
    :param AzureKeyCredential account_key: The Mixed Reality service account primary or secondary key credential.
    '''

    def __init__(self, account_id, account_key):
        self.account_id = account_id
        self.account_key = account_key

    def get_token(self, *scopes, **kwargs):
        import base64
        import hashlib
        import hmac
        from datetime import datetime, timezone
        
        # Get current UTC time
        now = datetime.now(timezone.utc)
        expiry = int(now.timestamp() + 3600)  # 1 hour from now
        
        # Create the string to sign
        scope = scopes[0] if scopes else """"
        string_to_sign = f""{self.account_id}\n{scope}\n{expiry}""
        
        # Sign the string with the account key
        key = base64.b64decode(self.account_key.key)
        signature = hmac.new(key, string_to_sign.encode('utf-8'), hashlib.sha256).digest()
        signature_b64 = base64.b64encode(signature).decode('utf-8')
        
        # Create the token
        token = f""Bearer {signature_b64}""
        
        return {
            'token': token,
            'expires_on': expiry
        }","class MixedRealityAccountKeyCredential(object):
    ''' Represents an object used for Mixed Reality account key authentication.

    :param str account_id: The Mixed Reality service account identifier.
    :param AzureKeyCredential account_key: The Mixed Reality service account primary or secondary key credential.
    '''

    def __init__(self, account_id, account_key):
        self._account_id = account_id
        self._account_key = account_key

    def get_token(self, *scopes, **kwargs):
        current_time = datetime.now(timezone.utc)
        expires_on = int((current_time.timestamp() + 3600))  # 1 hour from now
        
        # Create the token payload
        payload = f""{self._account_id}\n{expires_on}""
        
        # Sign the payload with HMAC-SHA256
        key_bytes = base64.b64decode(self._account_key.key)
        signature = hmac.new(
            key_bytes,
            payload.encode('utf-8'),
            hashlib.sha256
        ).digest()
        
        # Encode the signature
        signature_b64 = base64.b64encode(signature).decode('utf-8')
        
        # Create the access token
        token = f""{self._account_id}:{signature_b64}""
        
        return AccessToken(token, expires_on)",partial_docstr,0.4955223880597014,0.4084084084084084,0.36253776435045315,0.4477611940298508,0.32422446778407754,0.44038929440389296,0.3073170731707317,0.25183374083129584,0.755436897277832,0.8368316888809204,0.7940539121627808,0.827911376953125,0.7622484946236566,0.5743944636678201,0.4529616724738676,0.4140350877192982,0.49826989619377166,0.46383302883539596,0.6298932384341637,0.425,0.3727598566308244,0.7946466207504272,0.8404489159584045,0.8169062733650208,0.8356324434280396,0.7835972774869114,0.6125461254612546,0.5055762081784386,0.4569288389513108,0.5608856088560886,0.4821012066288716,0.660377358490566,0.45075757575757575,0.376425855513308,0.8121291399002075,0.8399767875671387,0.8258182406425476,0.8371063470840454,0.8110422292993631,0.4507945727822216,0.283394193362154,0.4028425685313503,0.5652173913043478,0.5517241379310345,0.5099028931615902,0.3583491624550028,0.4353853487220927,0.5217391304347826,0.7241379310344828,0.4762595851839717,0.3968042504651363,0.4040361892212751,0.5869565217391305,0.5172413793103449
699636,realestate-com-au/dashmat,realestate-com-au_dashmat/dashmat/core_modules/splunk/splunk-sdk-1.3.0/splunklib/modularinput/input_definition.py,splunklib.modularinput.input_definition.InputDefinition,"class InputDefinition:
    """"""``InputDefinition`` encodes the XML defining inputs that Splunk passes to
    a modular input script.

     **Example**::

        i = InputDefinition()

    """"""
    def __init__ (self):
        self.metadata = {}
        self.inputs = {}

    def __eq__(self, other):
        if not isinstance(other, InputDefinition):
            return False
        return self.metadata == other.metadata and self.inputs == other.inputs

    @staticmethod
    def parse(stream):
        """"""Parse a stream containing XML into an ``InputDefinition``.

        :param stream: stream containing XML to parse.
        :return: definition: an ``InputDefinition`` object.
        """"""
        definition = InputDefinition()

        # parse XML from the stream, then get the root node
        root = ET.parse(stream).getroot()

        for node in root:
            if node.tag == ""configuration"":
                # get config for each stanza
                definition.inputs = parse_xml_data(node, ""stanza"")
            else:
                definition.metadata[node.tag] = node.text

        return definition","class InputDefinition:
    '''``InputDefinition`` encodes the XML defining inputs that Splunk passes to
    a modular input script.

     **Example**::

        i = InputDefinition()

    '''

    def __init__ (self):
        pass

    def __eq__(self, other):
        pass

    @staticmethod
    def parse(stream):
    '''Parse a stream containing XML into an ``InputDefinition``.

        :param stream: stream containing XML to parse.
        :return: definition: an ``InputDefinition`` object.
        '''
        pass

",5,2,snippet_550,0.5454545454545454,"class InputDefinition:
    '''``InputDefinition`` encodes the XML defining inputs that Splunk passes to
    a modular input script.

     **Example**::

        i = InputDefinition()

    '''

    def __init__(self):
        self.name = None
        self.stanza = None
        self.server_host = None
        self.server_uri = None
        self.checkpoint_dir = None
        self.session_key = None
        self.metadata = {}
        self.parameters = {}

    def __eq__(self, other):
        if not isinstance(other, InputDefinition):
            return False
        return (
            self.name == other.name and
            self.stanza == other.stanza and
            self.server_host == other.server_host and
            self.server_uri == other.server_uri and
            self.checkpoint_dir == other.checkpoint_dir and
            self.session_key == other.session_key and
            self.metadata == other.metadata and
            self.parameters == other.parameters
        )

    @staticmethod
    def parse(stream):
        '''Parse a stream containing XML into an ``InputDefinition``.

        :param stream: stream containing XML to parse.
        :return: definition: an ``InputDefinition`` object.
        '''
        import xml.etree.ElementTree as ET
        root = ET.parse(stream).getroot()
        definition = InputDefinition()
        definition.server_host = root.findtext('server_host')
        definition.server_uri = root.findtext('server_uri')
        definition.checkpoint_dir = root.findtext('checkpoint_dir')
        definition.session_key = root.findtext('session_key')
        config = root.find('configuration')
        if config is not None:
            stanza = config.find('stanza')
            if stanza is not None:
                definition.stanza = stanza.get('name')
                definition.name = stanza.get('name')
                for element in stanza:
                    if element.tag == 'param':
                        definition.parameters[element.get('name')] = element.text or ''
                    elif element.tag == 'meta':
                        definition.metadata[element.get('name')] = element.text or ''
        return definition","class InputDefinition:
    '''``InputDefinition`` encodes the XML defining inputs that Splunk passes to
    a modular input script.

     **Example**::

        i = InputDefinition()

    '''

    def __init__(self):
        self.metadata = {}
        self.inputs = {}

    def __eq__(self, other):
        if not isinstance(other, InputDefinition):
            return False
        return self.metadata == other.metadata and self.inputs == other.inputs

    @staticmethod
    def parse(stream):
        '''Parse a stream containing XML into an ``InputDefinition``.

        :param stream: stream containing XML to parse.
        :return: definition: an ``InputDefinition`` object.
        '''
        definition = InputDefinition()
        
        # Parse the XML from the stream
        tree = ET.parse(stream)
        root = tree.getroot()
        
        # Parse metadata
        metadata_element = root.find('metadata')
        if metadata_element is not None:
            for child in metadata_element:
                definition.metadata[child.tag] = child.text
        
        # Parse inputs
        inputs_element = root.find('inputs')
        if inputs_element is not None:
            for input_element in inputs_element.findall('input'):
                name = input_element.get('name')
                if name is not None:
                    params = {}
                    for param in input_element:
                        params[param.tag] = param.text
                    definition.inputs[name] = params
        
        return definition","class InputDefinition:
    '''``InputDefinition`` encodes the XML defining inputs that Splunk passes to
    a modular input script.

     **Example**::

        i = InputDefinition()

    '''

    def __init__(self):
        self.metadata = {}
        self.inputs = {}

    def __eq__(self, other):
        if not isinstance(other, InputDefinition):
            return False
        return self.metadata == other.metadata and self.inputs == other.inputs

    @staticmethod
    def parse(stream):
        '''Parse a stream containing XML into an ``InputDefinition``.

        :param stream: stream containing XML to parse.
        :return: definition: an ``InputDefinition`` object.
        '''
        definition = InputDefinition()
        
        tree = ET.parse(stream)
        root = tree.getroot()
        
        # Parse metadata
        configuration = root.find('configuration')
        if configuration is not None:
            for stanza in configuration.findall('stanza'):
                stanza_name = stanza.get('name')
                if stanza_name:
                    definition.metadata[stanza_name] = {}
                    for param in stanza.findall('param'):
                        param_name = param.get('name')
                        param_value = param.text if param.text else ''
                        if param_name:
                            definition.metadata[stanza_name][param_name] = param_value
        
        # Parse inputs
        for item in root.findall('item'):
            item_name = item.get('name')
            if item_name:
                definition.inputs[item_name] = {}
                for param in item.findall('param'):
                    param_name = param.get('name')
                    param_value = param.text if param.text else ''
                    if param_name:
                        definition.inputs[item_name][param_name] = param_value
        
        return definition",partial_docstr,0.547550432276657,0.41159420289855075,0.3615160349854228,0.4899135446685879,0.36882770324617264,0.43537414965986393,0.3613636363636364,0.31890660592255127,0.8179975152015686,0.9032052755355835,0.8584922552108765,0.8938940167427063,0.7774797027027033,0.7345454545454545,0.5934065934065934,0.5535055350553505,0.6690909090909092,0.5865847267975338,0.6802721088435374,0.5699658703071673,0.5205479452054794,0.8963760733604431,0.9370064735412598,0.9162410497665405,0.9327784180641174,0.8447727941176469,0.6428571428571429,0.5098039215686274,0.4736842105263158,0.5844155844155844,0.45670302729173823,0.5365853658536586,0.44021739130434784,0.4032697547683924,0.8511321544647217,0.9341014623641968,0.8906887769699097,0.9250836968421936,0.7964932631578954,0.4992236022492017,0.3007717768698437,0.5023944091304475,0.6571428571428571,0.5365853658536586,0.6165980516060064,0.4631667684308327,0.606012894439186,0.7142857142857143,0.6829268292682927,0.5699831979583359,0.4045616967615439,0.5840818964655278,0.6571428571428571,0.6341463414634146
327383,daknuett/py_register_machine2,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/daknuett_py_register_machine2/py_register_machine2/tools/assembler/directives.py,py_register_machine2.tools.assembler.directives.BaseDirective,"class BaseDirective(object):
    """"""
    Every Directive has to provide the following Attributes/Methods:

    * ``name`` (like ``.set``)
    * ``get_words(line)``: return the data to store
    * ``get_word_count(line)``: return the number of words to store
    * ``isstatic()`` returns True, if the reference should be static
    """"""

    def __init__(self, name):
        self.name = name

    def get_words(self, line):
        return [int(line[0])]

    def get_word_count(self, line):
        return 1

    def isstatic(self):
        return False","class BaseDirective(object):
    '''
    Every Directive has to provide the following Attributes/Methods:

    * ``name`` (like ``.set``)
    * ``get_words(line)``: return the data to store
    * ``get_word_count(line)``: return the number of words to store
    * ``isstatic()`` returns True, if the reference should be static
    '''


    def __init__(self, name):
        pass


    def get_words(self, line):
        pass


    def get_word_count(self, line):
        pass


    def isstatic(self):
        pass

",5,1,snippet_707,1.0,"class BaseDirective(object):
    '''
    Every Directive has to provide the following Attributes/Methods:

    * ``name`` (like ``.set``)
    * ``get_words(line)``: return the data to store
    * ``get_word_count(line)``: return the number of words to store
    * ``isstatic()`` returns True, if the reference should be static
    '''

    def __init__(self, name):
        self.name = name

    def get_words(self, line):
        raise NotImplementedError(""Subclasses must implement get_words()"")

    def get_word_count(self, line):
        raise NotImplementedError(""Subclasses must implement get_word_count()"")

    def isstatic(self):
        raise NotImplementedError(""Subclasses must implement isstatic()"")","class BaseDirective(object):
    '''
    Every Directive has to provide the following Attributes/Methods:

    * ``name`` (like ``.set``)
    * ``get_words(line)``: return the data to store
    * ``get_word_count(line)``: return the number of words to store
    * ``isstatic()`` returns True, if the reference should be static
    '''


    def __init__(self, name):
        self.name = name


    def get_words(self, line):
        raise NotImplementedError(""Subclasses must implement get_words method"")


    def get_word_count(self, line):
        raise NotImplementedError(""Subclasses must implement get_word_count method"")


    def isstatic(self):
        raise NotImplementedError(""Subclasses must implement isstatic method"")","class BaseDirective(object):
    '''
    Every Directive has to provide the following Attributes/Methods:

    * ``name`` (like ``.set``)
    * ``get_words(line)``: return the data to store
    * ``get_word_count(line)``: return the number of words to store
    * ``isstatic()`` returns True, if the reference should be static
    '''

    def __init__(self, name):
        self.name = name

    def get_words(self, line):
        raise NotImplementedError(""Subclasses must implement get_words method"")

    def get_word_count(self, line):
        raise NotImplementedError(""Subclasses must implement get_word_count method"")

    def isstatic(self):
        raise NotImplementedError(""Subclasses must implement isstatic method"")",partial_docstr,0.8152866242038216,0.7870967741935485,0.758169934640523,0.8152866242038216,0.7412022635905801,0.7966101694915254,0.7272727272727273,0.7028571428571428,0.8958063721656799,0.9620667695999146,0.9277549386024475,0.9550028443336487,0.8854178125,0.7999999999999999,0.7721518987341772,0.7435897435897435,0.7999999999999999,0.754055765908293,0.8103448275862069,0.7398843930635838,0.7151162790697675,0.8885837197303772,0.9612923264503479,0.9235091805458069,0.9534903764724731,0.8854178125,0.7999999999999999,0.7721518987341772,0.7435897435897435,0.7999999999999999,0.754055765908293,0.8103448275862069,0.7398843930635838,0.7151162790697675,0.8892288208007812,0.9618021249771118,0.9240927696228027,0.9540160298347473,0.8854178125,0.6773481691149217,0.6726327286945999,0.7521445631497023,0.3846153846153846,0.9,0.6703882083527541,0.6447928856459298,0.7521445631497023,0.3846153846153846,0.9,0.6703882083527541,0.6447928856459298,0.7521445631497023,0.3846153846153846,0.9
728418,secdev/scapy,secdev_scapy/scapy/contrib/lldp.py,scapy.contrib.lldp.LLDPConfiguration,"class LLDPConfiguration(object):
    """"""
    basic configuration for LLDP layer
    """"""

    def __init__(self):
        self._strict_mode = True
        self.strict_mode_enable()

    def strict_mode_enable(self):
        """"""
        enable strict mode and dissector debugging
        """"""
        self._strict_mode = True

    def strict_mode_disable(self):
        """"""
        disable strict mode and dissector debugging
        """"""
        self._strict_mode = False

    def strict_mode(self):
        """"""
        get current strict mode state
        """"""
        return self._strict_mode","class LLDPConfiguration(object):
    '''
    basic configuration for LLDP layer
    '''

    def __init__(self):
        pass

    def strict_mode_enable(self):
    '''
        enable strict mode and dissector debugging
        '''
        pass

    def strict_mode_disable(self):
    '''
        disable strict mode and dissector debugging
        '''
        pass

    def strict_mode_enable(self):
    '''
        get current strict mode state
        '''
        pass

",5,4,snippet_767,1.0,"class LLDPConfiguration(object):
    '''
    basic configuration for LLDP layer
    '''

    def __init__(self):
        self._strict_mode = False

    def strict_mode_enable(self):
        '''
        enable strict mode and dissector debugging
        '''
        self._strict_mode = True

    def strict_mode_disable(self):
        '''
        disable strict mode and dissector debugging
        '''
        self._strict_mode = False

    def strict_mode_enabled(self):
        '''
        get current strict mode state
        '''
        return self._strict_mode","class LLDPConfiguration(object):
    '''
    basic configuration for LLDP layer
    '''

    def __init__(self):
        self._strict_mode = False

    def strict_mode_enable(self):
        '''
        enable strict mode and dissector debugging
        '''
        self._strict_mode = True

    def strict_mode_disable(self):
        '''
        disable strict mode and dissector debugging
        '''
        self._strict_mode = False

    def strict_mode_get(self):
        '''
        get current strict mode state
        '''
        return self._strict_mode","class LLDPConfiguration(object):
    '''
    basic configuration for LLDP layer
    '''

    def __init__(self):
        self._strict_mode = False

    def strict_mode_enable(self):
        '''
        enable strict mode and dissector debugging
        '''
        self._strict_mode = True

    def strict_mode_disable(self):
        '''
        disable strict mode and dissector debugging
        '''
        self._strict_mode = False

    def strict_mode_get(self):
        '''
        get current strict mode state
        '''
        return self._strict_mode",partial_docstr,0.9421487603305785,0.9075630252100839,0.8717948717948718,0.9421487603305785,0.6523221936607756,0.9074074074074074,0.8130841121495327,0.7169811320754716,0.9821251630783081,0.9818986654281616,0.9820118546485901,0.9819214344024658,0.9684687837837839,0.9421487603305785,0.9075630252100839,0.8717948717948718,0.9421487603305785,0.6523221936607756,0.9074074074074074,0.8130841121495327,0.7169811320754716,0.9831534624099731,0.9821105599403381,0.9826316833496094,0.9822146892547607,0.9684687837837839,0.9421487603305785,0.9075630252100839,0.8717948717948718,0.9421487603305785,0.6523221936607756,0.9074074074074074,0.8130841121495327,0.7169811320754716,0.9831534624099731,0.9821105599403381,0.9826316833496094,0.9822146892547607,0.9684687837837839,0.6091803493140535,0.4899065745215345,0.498996985922535,0.7419354838709677,0.7058823529411765,0.6091803493140535,0.4899065745215345,0.498996985922535,0.7419354838709677,0.7058823529411765,0.6091803493140535,0.4899065745215345,0.498996985922535,0.7419354838709677,0.7058823529411765
469066,housecanary/hc-api-python,housecanary_hc-api-python/housecanary/object.py,housecanary.object.ComponentResult,"class ComponentResult(object):
    """"""The results of a single component""""""

    def __init__(self, component_name, json_data, api_code, api_code_description):
        """"""
        Args:
            component_name - string name of the component.
            json_data - Json data returned from the API for this object.
            api_code - The HouseCanary business logic error code.
            api_code_description - The HouseCanary business logic error description.
        """"""
        self.component_name = component_name
        self.json_data = json_data
        self.api_code = api_code
        self.api_code_description = api_code_description

    def has_error(self):
        """"""Returns whether this component had a business logic error""""""
        return self.api_code > constants.BIZ_CODE_OK

    def get_error(self):
        """"""Gets the error of this component, if any""""""
        return self.api_code_description","class ComponentResult(object):
    '''The results of a single component'''

    def __init__(self, component_name, json_data, api_code, api_code_description):
    '''
        Args:
            component_name - string name of the component.
            json_data - Json data returned from the API for this object.
            api_code - The HouseCanary business logic error code.
            api_code_description - The HouseCanary business logic error description.
        '''
        pass

    def has_error(self):
    '''Returns whether this component had a business logic error'''
        pass

    def get_error(self):
    '''Gets the error of this component, if any'''
        pass

",4,4,snippet_333,1.0,"class ComponentResult(object):
    """"""The results of a single component""""""

    def __init__(self, component_name, json_data, api_code, api_code_description):
        """"""
        Args:
            component_name (str): Name of the component.
            json_data (dict): JSON data returned from the API for this object.
            api_code (int): The HouseCanary business logic error code.
            api_code_description (str): The HouseCanary business logic error description.
        """"""
        self.component_name = component_name
        self.json_data = json_data
        self.api_code = api_code
        self.api_code_description = api_code_description

    def has_error(self):
        """"""Returns whether this component had a business logic error""""""
        return self.api_code is not None and self.api_code != 0

    def get_error(self):
        """"""Gets the error of this component, if any""""""
        if not self.has_error():
            return None
        return {
            'component': self.component_name,
            'code': self.api_code,
            'description': self.api_code_description
        }","class ComponentResult(object):
    '''The results of a single component'''

    def __init__(self, component_name, json_data, api_code, api_code_description):
        '''
        Args:
            component_name - string name of the component.
            json_data - Json data returned from the API for this object.
            api_code - The HouseCanary business logic error code.
            api_code_description - The HouseCanary business logic error description.
        '''
        self.component_name = component_name
        self.json_data = json_data
        self.api_code = api_code
        self.api_code_description = api_code_description

    def has_error(self):
        '''Returns whether this component had a business logic error'''
        return self.api_code is not None

    def get_error(self):
        '''Gets the error of this component, if any'''
        if self.has_error():
            return {
                'code': self.api_code,
                'description': self.api_code_description
            }
        return None","class ComponentResult(object):
    '''The results of a single component'''

    def __init__(self, component_name, json_data, api_code, api_code_description):
        '''
        Args:
            component_name - string name of the component.
            json_data - Json data returned from the API for this object.
            api_code - The HouseCanary business logic error code.
            api_code_description - The HouseCanary business logic error description.
        '''
        self.component_name = component_name
        self.json_data = json_data
        self.api_code = api_code
        self.api_code_description = api_code_description

    def has_error(self):
        '''Returns whether this component had a business logic error'''
        return self.api_code is not None

    def get_error(self):
        '''Gets the error of this component, if any'''
        if self.has_error():
            return {
                'code': self.api_code,
                'description': self.api_code_description
            }
        return None",partial_docstr,0.8793774319066149,0.8156862745098039,0.766798418972332,0.8793774319066149,0.7373797527226457,0.7751937984496124,0.7315175097276264,0.70703125,0.9450696706771851,0.9564917087554932,0.9507463574409485,0.9553372263908386,0.8945879487179487,0.9344262295081966,0.9008264462809918,0.8833333333333334,0.9262295081967213,0.7777032456387949,0.855072463768116,0.7864077669902912,0.7414634146341463,0.9659236669540405,0.9726293087005615,0.9692648649215698,0.9719545245170593,0.9150335294117647,0.9344262295081966,0.9008264462809918,0.8833333333333334,0.9262295081967213,0.7777032456387949,0.855072463768116,0.7864077669902912,0.7414634146341463,0.9659236669540405,0.9726293087005615,0.9692648649215698,0.9719545245170593,0.9150335294117647,0.786731542039224,0.6709832781815203,0.7985235351366661,0.6774193548387096,1.0,0.769756117026715,0.6602566299304372,0.741348483337713,0.6774193548387096,1.0,0.769756117026715,0.6602566299304372,0.741348483337713,0.6774193548387096,1.0
368584,erikrose/nose-progressive,erikrose_nose-progressive/noseprogressive/utils.py,noseprogressive.utils.OneTrackMind,"class OneTrackMind(object):
    """"""An accurate simulation of my brain

    I can know one thing at a time, at some level of confidence. You can tell
    me other things, but if I'm not as confident of them, I'll forget them. If
    I'm more confident of them, they'll replace what I knew before.

    """"""
    def __init__(self):
        self.confidence = 0
        self.best = None

    def know(self, what, confidence):
        """"""Know something with the given confidence, and return self for chaining.

        If confidence is higher than that of what we already know, replace
        what we already know with what you're telling us.

        """"""
        if confidence > self.confidence:
            self.best = what
            self.confidence = confidence
        return self","class OneTrackMind(object):
    '''An accurate simulation of my brain

    I can know one thing at a time, at some level of confidence. You can tell
    me other things, but if I'm not as confident of them, I'll forget them. If
    I'm more confident of them, they'll replace what I knew before.

    '''

    def __init__(self):
        pass

    def know(self, what, confidence):
    '''Know something with the given confidence, and return self for chaining.

        If confidence is higher than that of what we already know, replace
        what we already know with what you're telling us.

        '''
        pass

",3,2,snippet_80,1.0,"class OneTrackMind(object):
    '''An accurate simulation of my brain

    I can know one thing at a time, at some level of confidence. You can tell
    me other things, but if I'm not as confident of them, I'll forget them. If
    I'm more confident of them, they'll replace what I knew before.
    '''

    def __init__(self):
        self.knowledge = None
        self.confidence = float('-inf')

    def know(self, what, confidence):
        '''Know something with the given confidence, and return self for chaining.

        If confidence is higher than that of what we already know, replace
        what we already know with what you're telling us.
        '''
        if confidence > self.confidence:
            self.knowledge = what
            self.confidence = confidence
        return self","class OneTrackMind(object):
    '''An accurate simulation of my brain

    I can know one thing at a time, at some level of confidence. You can tell
    me other things, but if I'm not as confident of them, I'll forget them. If
    I'm more confident of them, they'll replace what I knew before.

    '''

    def __init__(self):
        self._knowledge = None
        self._confidence = 0.0

    def know(self, what, confidence):
        '''Know something with the given confidence, and return self for chaining.

        If confidence is higher than that of what we already know, replace
        what we already know with what you're telling us.

        '''
        if confidence > self._confidence:
            self._knowledge = what
            self._confidence = confidence
        return self","class OneTrackMind(object):
    '''An accurate simulation of my brain

    I can know one thing at a time, at some level of confidence. You can tell
    me other things, but if I'm not as confident of them, I'll forget them. If
    I'm more confident of them, they'll replace what I knew before.

    '''

    def __init__(self):
        self.knowledge = None
        self.confidence = 0

    def know(self, what, confidence):
        '''Know something with the given confidence, and return self for chaining.

        If confidence is higher than that of what we already know, replace
        what we already know with what you're telling us.

        '''
        if confidence > self.confidence:
            self.knowledge = what
            self.confidence = confidence
        return self",partial_docstr,0.9694323144104805,0.933920704845815,0.9066666666666666,0.9519650655021834,0.8396219208695386,0.9342105263157895,0.8807947019867549,0.8266666666666667,0.9788305759429932,0.985770046710968,0.9822880625724792,0.9850716590881348,0.9601994029850746,0.9781659388646288,0.9427312775330398,0.9155555555555556,0.9606986899563318,0.8200242418421378,0.922077922077922,0.8496732026143791,0.7763157894736842,0.9866400361061096,0.988102912902832,0.9873709678649902,0.9879564642906189,0.9890711475409836,0.9824561403508771,0.9469026548672567,0.9196428571428571,0.9649122807017544,0.8449888047246501,0.959731543624161,0.9054054054054054,0.8503401360544217,0.9908385872840881,0.9903916716575623,0.9906150698661804,0.990436315536499,0.9890711475409836,0.718363696212082,0.8269796060912666,0.8320502274900046,0.7407407407407407,0.4736842105263157,0.740485311474248,0.7912545408106887,0.7983670169771417,0.7407407407407407,0.631578947368421,0.7795622832837859,0.8337552428707535,0.8381001280811538,0.8148148148148148,0.631578947368421
815444,uogbuji/amara3-xml,uogbuji_amara3-xml/pylib/uxml/uxpath/xast.py,pylib.uxml.uxpath.xast.abbreviated_step,"class abbreviated_step:
    '''
    Abbreviated XPath step. '.' or '..'
    '''
    def __init__(self, abbr):
        # abbreviated step
        self.abbr = abbr

    def __repr__(self):
        return '{{{} {}}}'.format(self.__class__.__name__, serialize(self))

    def _serialize(self):
        yield(self.abbr)

    def compute(self, ctx):
        # print('ABBREVIATEDSTEP', (self.abbr))
        if self.abbr == '.':
            yield ctx.item
        elif self.abbr == '..':
            # parent axis
            # assert isinstance(ctx.item, node)
            if ctx.item.xml_parent:
                yield ctx.item.xml_parent
            else:
                yield root_node.get(ctx.item)

    def __call__(self, ctx):
        '''
        Alias for user convenience
        '''
        yield from self.compute(ctx)","class abbreviated_step:
    '''
    Abbreviated XPath step. '.' or '..'
    '''

    def __init__(self, abbr):
        pass

    def __repr__(self):
        pass

    def _serialize(self):
        pass

    def compute(self, ctx):
        pass

    def __call__(self, ctx):
    '''
        Alias for user convenience
        '''
        pass

",6,2,snippet_445,0.3333333333333333,"class abbreviated_step:
    '''
    Abbreviated XPath step. '.' or '..'
    '''

    def __init__(self, abbr):
        if abbr not in ('.', '..'):
            raise ValueError(f""Invalid abbreviated step {abbr!r}, expected '.' or '..'"")
        self.abbr = abbr

    def __repr__(self):
        return f""{self.__class__.__name__}({self.abbr!r})""

    def _serialize(self):
        return self.abbr

    def compute(self, ctx):
        node = getattr(ctx, 'node', None)
        if node is None:
            return []
        if self.abbr == '.':
            return [node]
        # '..'
        parent = None
        # try lxml-style
        if hasattr(node, 'getparent'):
            parent = node.getparent()
        # fallback to ElementTree if it stores parent in ._parent
        elif hasattr(node, '_parent'):
            parent = node._parent
        return [parent] if parent is not None else []

    def __call__(self, ctx):
        '''
        Alias for user convenience
        '''
        return self.compute(ctx)","class abbreviated_step:
    '''
    Abbreviated XPath step. '.' or '..'
    '''

    def __init__(self, abbr):
        if abbr not in ('.', '..'):
            raise ValueError(""Abbreviated step must be '.' or '..'"")
        self.abbr = abbr

    def __repr__(self):
        return f""abbreviated_step('{self.abbr}')""

    def _serialize(self):
        return self.abbr

    def compute(self, ctx):
        if self.abbr == '.':
            return [ctx.node]
        else:  # self.abbr == '..'
            parent = ctx.node.getparent()
            return [parent] if parent is not None else []

    def __call__(self, ctx):
        '''
        Alias for user convenience
        '''
        return self.compute(ctx)","class abbreviated_step:
    '''
    Abbreviated XPath step. '.' or '..'
    '''

    def __init__(self, abbr):
        self.abbr = abbr

    def __repr__(self):
        return f""abbreviated_step('{self.abbr}')""

    def _serialize(self):
        return self.abbr

    def compute(self, ctx):
        if self.abbr == '.':
            return [ctx] if ctx is not None else []
        elif self.abbr == '..':
            if ctx is not None and hasattr(ctx, 'getparent'):
                parent = ctx.getparent()
                return [parent] if parent is not None else []
            return []
        return []

    def __call__(self, ctx):
        '''
        Alias for user convenience
        '''
        return self.compute(ctx)",partial_docstr,0.5858585858585859,0.3979591836734694,0.29896907216494845,0.5353535353535352,0.49315263056182174,0.688715953307393,0.453125,0.3843137254901961,0.8339773416519165,0.8824928998947144,0.8575494885444641,0.8773888349533081,0.8021997802197802,0.6871165644171779,0.49689440993788814,0.389937106918239,0.6503067484662576,0.5484036033205528,0.7883597883597884,0.5851063829787234,0.4919786096256685,0.8965359926223755,0.8826300501823425,0.8895286917686462,0.8840011954307556,0.8172857777777778,0.6946107784431137,0.49696969696969695,0.3803680981595092,0.6227544910179641,0.5348055943320903,0.7865168539325843,0.615819209039548,0.5340909090909091,0.8893914222717285,0.8757792711257935,0.8825328946113586,0.8771218061447144,0.8518533333333332,0.4658298690429875,0.2739488527679807,0.4295667018353417,0.4264705882352941,0.7333333333333333,0.5030300428485683,0.3963656762381903,0.4226172402541222,0.4264705882352941,0.7666666666666667,0.5291293875085007,0.3916265801909391,0.446459597294044,0.4117647058823529,0.8666666666666667
217744,aio-libs/aioftp,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/aio-libs_aioftp/src/aioftp/server.py,aioftp.server.ConnectionConditions,"class ConnectionConditions:
    """"""
    Decorator for checking `connection` keys for existence or wait for them.
    Available options:

    :param fields: * `ConnectionConditions.user_required`  required ""user""
          key, user already identified
        * `ConnectionConditions.login_required`  required ""logged"" key, user
          already logged in.
        * `ConnectionConditions.passive_server_started`  required
          ""passive_server"" key, user already send PASV and server awaits
          incomming connection
        * `ConnectionConditions.data_connection_made`  required
          ""data_connection"" key, user already connected to passive connection
        * `ConnectionConditions.rename_from_required`  required ""rename_from""
          key, user already tell filename for rename

    :param wait: Indicates if should wait for parameters for
        `connection.wait_future_timeout`
    :type wait: :py:class:`bool`

    :param fail_code: return code if failure
    :type fail_code: :py:class:`str`

    :param fail_info: return information string if failure. If
        :py:class:`None`, then use default string
    :type fail_info: :py:class:`str`

    ::

        >>> @ConnectionConditions(
        ...     ConnectionConditions.login_required,
        ...     ConnectionConditions.passive_server_started,
        ...     ConnectionConditions.data_connection_made,
        ...     wait=True)
        ... def foo(self, connection, rest):
        ...     ...
    """"""

    user_required = (""user"", ""no user (use USER firstly)"")
    login_required = (""logged"", ""not logged in"")
    passive_server_started = (
        ""passive_server"",
        ""no listen socket created (use PASV firstly)"",
    )
    data_connection_made = (""data_connection"", ""no data connection made"")
    rename_from_required = (""rename_from"", ""no filename (use RNFR firstly)"")

    def __init__(self, *fields, wait=False, fail_code=""503"", fail_info=None):
        self.fields = fields
        self.wait = wait
        self.fail_code = fail_code
        self.fail_info = fail_info

    def __call__(self, f):
        @functools.wraps(f)
        async def wrapper(cls, connection, rest, *args):
            futures = {connection[name]: msg for name, msg in self.fields}
            aggregate = asyncio.gather(*futures)
            if self.wait:
                timeout = connection.wait_future_timeout
            else:
                timeout = 0

            try:
                await asyncio.wait_for(
                    asyncio.shield(aggregate),
                    timeout,
                )
            except asyncio.TimeoutError:
                for future, message in futures.items():
                    if not future.done():
                        if self.fail_info is None:
                            info = f""bad sequence of commands ({message})""
                        else:
                            info = self.fail_info
                        connection.response(self.fail_code, info)
                        return True
            return await f(cls, connection, rest, *args)

        return wrapper","class ConnectionConditions:
    '''
    Decorator for checking `connection` keys for existence or wait for them.
    Available options:

    :param fields: * `ConnectionConditions.user_required`  required ""user""
          key, user already identified
        * `ConnectionConditions.login_required`  required ""logged"" key, user
          already logged in.
        * `ConnectionConditions.passive_server_started`  required
          ""passive_server"" key, user already send PASV and server awaits
          incomming connection
        * `ConnectionConditions.data_connection_made`  required
          ""data_connection"" key, user already connected to passive connection
        * `ConnectionConditions.rename_from_required`  required ""rename_from""
          key, user already tell filename for rename

    :param wait: Indicates if should wait for parameters for
        `connection.wait_future_timeout`
    :type wait: :py:class:`bool`

    :param fail_code: return code if failure
    :type fail_code: :py:class:`str`

    :param fail_info: return information string if failure. If
        :py:class:`None`, then use default string
    :type fail_info: :py:class:`str`

    ::

        >>> @ConnectionConditions(
        ...     ConnectionConditions.login_required,
        ...     ConnectionConditions.passive_server_started,
        ...     ConnectionConditions.data_connection_made,
        ...     wait=True)
        ... def foo(self, connection, rest):
        ...     ...
    '''


    def __init__(self, *fields, wait=False, fail_code=""503"", fail_info=None):
        pass


    def __call__(self, f):
        pass

        @functools.wraps(f)
        async def wrapper(cls, connection, rest, *args):
        pass

",5,1,snippet_523,0.25,"class ConnectionConditions:
    '''
    Decorator for checking `connection` keys for existence or wait for them.
    Available options:

    :param fields: * `ConnectionConditions.user_required`  required ""user""
          key, user already identified
        * `ConnectionConditions.login_required`  required ""logged"" key, user
          already logged in.
        * `ConnectionConditions.passive_server_started`  required
          ""passive_server"" key, user already send PASV and server awaits
          incomming connection
        * `ConnectionConditions.data_connection_made`  required ""data_connection""
          key, user already connected to passive connection
        * `ConnectionConditions.rename_from_required`  required ""rename_from""
          key, user already tell filename for rename

    :param wait: Indicates if should wait for parameters for
        `connection.wait_future_timeout`
    :type wait: :py:class:`bool`

    :param fail_code: return code if failure
    :type fail_code: :py:class:`str`

    :param fail_info: return information string if failure. If
        :py:class:`None`, then use default string
    :type fail_info: :py:class:`str`
    '''
    user_required = 1
    login_required = 2
    passive_server_started = 3
    data_connection_made = 4
    rename_from_required = 5

    _FIELD_NAMES = {
        user_required: ""user"",
        login_required: ""logged"",
        passive_server_started: ""passive_server"",
        data_connection_made: ""data_connection"",
        rename_from_required: ""rename_from"",
    }

    def __init__(self, *fields, wait=False, fail_code=""503"", fail_info=None):
        self.fields = fields
        self.wait = wait
        self.fail_code = fail_code
        self.fail_info = fail_info

    def __call__(self, f):
        @functools.wraps(f)
        async def wrapper(cls, connection, rest, *args):
            for field in self.fields:
                key = self._FIELD_NAMES.get(field)
                if key is None:
                    continue
                # wait for the key if requested
                if self.wait:
                    try:
                        await connection.wait_for(key, connection.wait_future_timeout)
                    except Exception:
                        info = self.fail_info or f""{key} required.""
                        return self.fail_code, info
                else:
                    if not hasattr(connection, key):
                        info = self.fail_info or f""{key} required.""
                        return self.fail_code, info
            return await f(cls, connection, rest, *args)
        return wrapper","class ConnectionConditions:
    '''
    Decorator for checking `connection` keys for existence or wait for them.
    Available options:

    :param fields: * `ConnectionConditions.user_required`  required ""user""
          key, user already identified
        * `ConnectionConditions.login_required`  required ""logged"" key, user
          already logged in.
        * `ConnectionConditions.passive_server_started`  required
          ""passive_server"" key, user already send PASV and server awaits
          incomming connection
        * `ConnectionConditions.data_connection_made`  required
          ""data_connection"" key, user already connected to passive connection
        * `ConnectionConditions.rename_from_required`  required ""rename_from""
          key, user already tell filename for rename

    :param wait: Indicates if should wait for parameters for
        `connection.wait_future_timeout`
    :type wait: :py:class:`bool`

    :param fail_code: return code if failure
    :type fail_code: :py:class:`str`

    :param fail_info: return information string if failure. If
        :py:class:`None`, then use default string
    :type fail_info: :py:class:`str`

    ::

        >>> @ConnectionConditions(
        ...     ConnectionConditions.login_required,
        ...     ConnectionConditions.passive_server_started,
        ...     ConnectionConditions.data_connection_made,
        ...     wait=True)
        ... def foo(self, connection, rest):
        ...     ...
    '''

    user_required = ""user""
    login_required = ""logged""
    passive_server_started = ""passive_server""
    data_connection_made = ""data_connection""
    rename_from_required = ""rename_from""

    def __init__(self, *fields, wait=False, fail_code=""503"", fail_info=None):
        self.fields = fields
        self.wait = wait
        self.fail_code = fail_code
        self.fail_info = fail_info

    def __call__(self, f):
        
        @functools.wraps(f)
        async def wrapper(cls, connection, rest, *args):
            for field in self.fields:
                if self.wait:
                    try:
                        await asyncio.wait_for(
                            connection.wait_future(field),
                            timeout=connection.wait_future_timeout
                        )
                    except asyncio.TimeoutError:
                        fail_info = self.fail_info or f""Required condition {field} not met""
                        return self.fail_code, fail_info
                else:
                    if field not in connection:
                        fail_info = self.fail_info or f""Required condition {field} not met""
                        return self.fail_code, fail_info
            
            return await f(cls, connection, rest, *args)
        
        return wrapper","class ConnectionConditions:
    '''
    Decorator for checking `connection` keys for existence or wait for them.
    Available options:

    :param fields: * `ConnectionConditions.user_required`  required ""user""
          key, user already identified
        * `ConnectionConditions.login_required`  required ""logged"" key, user
          already logged in.
        * `ConnectionConditions.passive_server_started`  required
          ""passive_server"" key, user already send PASV and server awaits
          incomming connection
        * `ConnectionConditions.data_connection_made`  required
          ""data_connection"" key, user already connected to passive connection
        * `ConnectionConditions.rename_from_required`  required ""rename_from""
          key, user already tell filename for rename

    :param wait: Indicates if should wait for parameters for
        `connection.wait_future_timeout`
    :type wait: :py:class:`bool`

    :param fail_code: return code if failure
    :type fail_code: :py:class:`str`

    :param fail_info: return information string if failure. If
        :py:class:`None`, then use default string
    :type fail_info: :py:class:`str`

    ::

        >>> @ConnectionConditions(
        ...     ConnectionConditions.login_required,
        ...     ConnectionConditions.passive_server_started,
        ...     ConnectionConditions.data_connection_made,
        ...     wait=True)
        ... def foo(self, connection, rest):
        ...     ...
    '''

    user_required = ""user""
    login_required = ""logged""
    passive_server_started = ""passive_server""
    data_connection_made = ""data_connection""
    rename_from_required = ""rename_from""

    def __init__(self, *fields, wait=False, fail_code=""503"", fail_info=None):
        self.fields = fields
        self.wait = wait
        self.fail_code = fail_code
        self.fail_info = fail_info

    def __call__(self, f):
        @functools.wraps(f)
        async def wrapper(cls, connection, rest, *args):
            for field in self.fields:
                if field not in connection:
                    if self.wait:
                        try:
                            await connection.wait_future_timeout(field)
                        except:
                            fail_info = self.fail_info or f""Required {field} not available""
                            return cls.response(self.fail_code, fail_info)
                    else:
                        fail_info = self.fail_info or f""Required {field} not available""
                        return cls.response(self.fail_code, fail_info)
            
            return await f(cls, connection, rest, *args)
        
        return wrapper",partial_docstr,0.8298217179902755,0.7284552845528455,0.6590538336052202,0.7779578606158833,0.6804700427356503,0.9063063063063063,0.8050541516245487,0.7341772151898734,0.9351084232330322,0.9069365859031677,0.9208070635795593,0.9096770882606506,0.8233100375939855,0.8697068403908794,0.7875816993464052,0.7377049180327868,0.8273615635179155,0.7567786370209341,0.9422066549912435,0.8666666666666667,0.8172231985940246,0.9608224034309387,0.9254260063171387,0.9427921175956726,0.9288478493690491,0.8533849248120301,0.8566721581548599,0.7768595041322314,0.7296849087893864,0.8270181219110379,0.7410134316288189,0.9447415329768271,0.8642857142857143,0.815742397137746,0.9588241577148438,0.9167572259902954,0.9373189210891724,0.9207970499992371,0.8609036466165414,0.4964257253222083,0.5764637598421034,0.5982379675409778,0.4626865671641791,0.348314606741573,0.5055055925328207,0.6393572871929384,0.6577782809930144,0.4552238805970149,0.2696629213483146,0.4958125966751915,0.6283843649821528,0.6487617118074949,0.4701492537313433,0.2359550561797752
318505,cqlengine/cqlengine,cqlengine_cqlengine/cqlengine/named.py,cqlengine.named.NamedKeyspace,"class NamedKeyspace(object):
    """"""
    A keyspace
    """"""

    def __init__(self, name):
        self.name = name

    def table(self, name):
        """"""
        returns a table descriptor with the given
        name that belongs to this keyspace
        """"""
        return NamedTable(self.name, name)","class NamedKeyspace(object):
    '''
    A keyspace
    '''

    def __init__(self, name):
        pass

    def table(self, name):
    '''
        returns a table descriptor with the given
        name that belongs to this keyspace
        '''
        pass

",3,2,snippet_556,1.0,"class NamedKeyspace(object):
    '''
    A keyspace
    '''

    def __init__(self, name):
        self.name = name
        self._tables = {}

    def table(self, name):
        '''
        returns a table descriptor with the given
        name that belongs to this keyspace
        '''
        if name not in self._tables:
            self._tables[name] = TableDescriptor(self, name)
        return self._tables[name]","class NamedKeyspace(object):
    '''
    A keyspace
    '''

    def __init__(self, name):
        self.name = name

    def table(self, name):
        '''
        returns a table descriptor with the given
        name that belongs to this keyspace
        '''
        return f""{self.name}.{name}""","class NamedKeyspace(object):
    '''
    A keyspace
    '''

    def __init__(self, name):
        self.name = name
        self._tables = {}

    def table(self, name):
        '''
        returns a table descriptor with the given
        name that belongs to this keyspace
        '''
        if name not in self._tables:
            self._tables[name] = NamedTable(name, self)
        return self._tables[name]",partial_docstr,0.8148148148148149,0.7088607594936709,0.6493506493506493,0.7901234567901235,0.5205998781532438,0.6179775280898876,0.5227272727272727,0.4367816091954023,0.8878648281097412,0.9606007933616638,0.922801673412323,0.9527953267097473,0.8615398461538462,0.9705882352941176,0.9393939393939394,0.90625,0.9705882352941176,0.6849787487379899,0.84375,0.7142857142857143,0.6451612903225806,0.9724385738372803,0.9784276485443115,0.9754239320755005,0.977825403213501,0.9481486666666668,0.8395061728395062,0.6835443037974683,0.6493506493506493,0.7901234567901235,0.515311828199456,0.6292134831460674,0.5113636363636364,0.42528735632183906,0.8978670239448547,0.9654474258422852,0.9304317235946655,0.9582350254058838,0.8615398461538462,0.6139376741640288,0.4401711714272069,0.6038148193465551,0.4117647058823529,1.0,0.625493113474941,0.6467185221870893,0.6591755003401256,0.5294117647058824,0.6666666666666666,0.6121492740859015,0.4361873121830066,0.6006450782782465,0.4117647058823529,1.0
277636,buildbot/buildbot,master/buildbot/data/resultspec.py,buildbot.data.resultspec.ReverseComparator,"class ReverseComparator:
    """"""
    Object which swaps '<' and '>' so
    instead of a < b, it does b < a,
    and instead of a > b, it does b > a.
    This can be used in reverse comparisons.
    """"""

    def __init__(self, value):
        self.value = value

    def __lt__(self, other):
        return other.value < self.value

    def __eq__(self, other):
        return other.value == self.value

    def __ne__(self, other):
        return other.value != self.value

    def __gt__(self, other):
        return other.value > self.value","class ReverseComparator:
    '''
    Object which swaps '<' and '>' so
    instead of a < b, it does b < a,
    and instead of a > b, it does b > a.
    This can be used in reverse comparisons.
    '''

    def __init__(self, value):
        pass

    def __lt__(self, other):
        pass

    def __eq__(self, other):
        pass

    def __ne__(self, other):
        pass

    def __gt__(self, other):
        pass

",6,1,snippet_251,1.0,"class ReverseComparator:
    '''
    Object which swaps '<' and '>' so
    instead of a < b, it does b < a,
    and instead of a > b, it does b > a.
    This can be used in reverse comparisons.
    '''

    def __init__(self, value):
        self.value = value

    def __lt__(self, other):
        other_val = other.value if isinstance(other, ReverseComparator) else other
        return other_val < self.value

    def __eq__(self, other):
        other_val = other.value if isinstance(other, ReverseComparator) else other
        return self.value == other_val

    def __ne__(self, other):
        return not self.__eq__(other)

    def __gt__(self, other):
        other_val = other.value if isinstance(other, ReverseComparator) else other
        return other_val > self.value","class ReverseComparator:
    '''
    Object which swaps '<' and '>' so
    instead of a < b, it does b < a,
    and instead of a > b, it does b > a.
    This can be used in reverse comparisons.
    '''

    def __init__(self, value):
        self.value = value

    def __lt__(self, other):
        return self.value > other.value

    def __eq__(self, other):
        return self.value == other.value

    def __ne__(self, other):
        return self.value != other.value

    def __gt__(self, other):
        return self.value < other.value","class ReverseComparator:
    '''
    Object which swaps '<' and '>' so
    instead of a < b, it does b < a,
    and instead of a > b, it does b > a.
    This can be used in reverse comparisons.
    '''

    def __init__(self, value):
        self.value = value

    def __lt__(self, other):
        return self.value > other.value

    def __eq__(self, other):
        return self.value == other.value

    def __ne__(self, other):
        return self.value != other.value

    def __gt__(self, other):
        return self.value < other.value",partial_docstr,0.8089887640449438,0.7159090909090908,0.5862068965517241,0.7640449438202248,0.6421466166867026,0.715,0.6432160804020101,0.5757575757575758,0.8986821174621582,0.9735143184661865,0.934602677822113,0.9654749631881714,0.8606074545454545,1.0,0.8904109589041096,0.7361111111111113,0.8918918918918919,0.892474789680299,0.9865771812080537,0.918918918918919,0.8503401360544217,0.9856782555580139,0.9856836199760437,0.9856809377670288,0.9856831431388855,1.0,1.0,0.8904109589041096,0.7361111111111113,0.8918918918918919,0.892474789680299,0.9865771812080537,0.918918918918919,0.8503401360544217,0.9856782555580139,0.9856836199760437,0.9856809377670288,0.9856831431388855,1.0,0.5973286330292589,0.5403562854366369,0.7196146173367695,0.4864864864864865,0.6428571428571429,0.8656539938979751,0.7302430046381152,0.7323729709537853,1.0,1.0,0.8656539938979751,0.7302430046381152,0.7323729709537853,1.0,1.0
672856,pysal/spglm,spglm/base.py,spglm.base.Results,"class Results:
    """"""
    Class to contain model results
    Parameters
    ----------
    model : class instance
        the previously specified model instance
    params : array
        parameter estimates from the fit model
    """"""

    def __init__(self, model, params, **kwd):
        self.__dict__.update(kwd)
        self.initialize(model, params, **kwd)
        self._data_attr = []

    def initialize(self, model, params, **kwd):
        self.params = params
        self.model = model
        if hasattr(model, ""k_constant""):
            self.k_constant = model.k_constant","class Results:
    '''
    Class to contain model results
    Parameters
    ----------
    model : class instance
        the previously specified model instance
    params : array
        parameter estimates from the fit model
    '''

    def __init__(self, model, params, **kwd):
        pass

    def initialize(self, model, params, **kwd):
        pass

",3,1,snippet_483,0.8,"class Results:
    '''
    Class to contain model results
    Parameters
    ----------
    model : class instance
        the previously specified model instance
    params : array
        parameter estimates from the fit model
    '''

    def __init__(self, model, params, **kwd):
        self.initialize(model, params, **kwd)

    def initialize(self, model, params, **kwd):
        self.model = model
        self.params = np.asarray(params)
        for key, value in kwd.items():
            setattr(self, key, value)","class Results:
    '''
    Class to contain model results
    Parameters
    ----------
    model : class instance
        the previously specified model instance
    params : array
        parameter estimates from the fit model
    '''

    def __init__(self, model, params, **kwd):
        self.initialize(model, params, **kwd)

    def initialize(self, model, params, **kwd):
        self.model = model
        self.params = params
        for key, value in kwd.items():
            setattr(self, key, value)","class Results:
    '''
    Class to contain model results
    Parameters
    ----------
    model : class instance
        the previously specified model instance
    params : array
        parameter estimates from the fit model
    '''

    def __init__(self, model, params, **kwd):
        self.initialize(model, params, **kwd)

    def initialize(self, model, params, **kwd):
        self.model = model
        self.params = params
        for key, value in kwd.items():
            setattr(self, key, value)",partial_docstr,0.7903225806451613,0.7049180327868853,0.6500000000000001,0.7258064516129032,0.5971023594780605,0.8532110091743119,0.7222222222222222,0.6728971962616822,0.9276989102363586,0.9144735932350159,0.9210387468338013,0.915779173374176,0.865855,0.8032786885245902,0.7333333333333334,0.6779661016949152,0.7377049180327868,0.5931236762825499,0.8846153846153846,0.7669902912621359,0.7156862745098039,0.940137505531311,0.9140927195549011,0.9269322156906128,0.9166319966316223,0.88618,0.8032786885245902,0.7333333333333334,0.6779661016949152,0.7377049180327868,0.5931236762825499,0.8846153846153846,0.7669902912621359,0.7156862745098039,0.940137505531311,0.9140927195549011,0.9269322156906128,0.9166319966316223,0.88618,0.6166438484094265,0.606760337676723,0.6098150559609833,0.5,0.75,0.6251827770788071,0.6189717633634141,0.6210450592375285,0.475,0.7857142857142857,0.6251827770788071,0.6189717633634141,0.6210450592375285,0.475,0.7857142857142857
281968,camsci/meteor-pi,camsci_meteor-pi/src/diagnostics/mod_astro.py,mod_astro.Plane,"class Plane:
    def __init__(self, normal, p):
        """"""
        Equation of a plane, in the form n.x+p = 0
        :param Vector normal:
        :param float p:
        :return:
        """"""
        self.normal = normal
        self.p = p

    def __str__(self):
        return ""Plane( normal=Vector(%s,%s,%s), p=%s)"" % (self.normal.x, self.normal.y, self.normal.z, self.p)

    def perpendicular_distance_to_point(self, other):
        """"""
        Calculate the perpendicular distance of a point from a place
        :param Point other:
        :return:
        """"""
        return self.normal.dot_product(other.displacement_from_origin()) + self.p

    def line_of_intersection(self, other):
        """"""
        Find the line of intersection between two planes
        :param Plane other:
        :return Line:
        """"""
        direction = self.normal.cross_product(other.normal)
        mag = abs(direction)

        # Normalise direction vector
        if mag > 0:
            direction = direction / mag

        n = self.normal
        n2 = other.normal
        p = self.p
        p2 = other.p

        # Now find a sample point which is in both planes
        try:
            z = 0
            y = (n.x * p2 - n2.x * p) / (n2.x * n.y - n.x * n2.y)
            x = (n.y * p2 - n2.y * p) / (n2.y * n.x - n.y * n2.x)
        except ZeroDivisionError:
            return None

        x0 = Point(x, y, z)
        return Line(direction=direction, x0=x0)","class Plane:


    def __init__(self, normal, p):
    '''
        Equation of a plane, in the form n.x+p = 0
        :param Vector normal:
        :param float p:
        :return:
        '''
        pass

    def __str__(self):
        pass

    def perpendicular_distance_to_point(self, other):
    '''
        Calculate the perpendicular distance of a point from a place
        :param Point other:
        :return:
        '''
        pass

    def line_of_intersection(self, other):
    '''
        Find the line of intersection between two planes
        :param Plane other:
        :return Line:
        '''
        pass

",5,3,snippet_170,0.5555555555555556,"class Plane:
    def __init__(self, normal, p):
        """"""
        Equation of a plane, in the form n.x + p = 0
        :param Vector normal:
        :param float p:
        """"""
        self.normal = normal
        self.p = float(p)

    def __str__(self):
        n = self.normal
        return f""{n.x}x + {n.y}y + {n.z}z + {self.p} = 0""

    def perpendicular_distance_to_point(self, other):
        """"""
        Calculate the perpendicular distance of a point from a plane
        :param Point other:
        """"""
        v = other.to_vector()
        num = abs(self.normal.dot(v) + self.p)
        den = self.normal.norm()
        return num / den

    def line_of_intersection(self, other):
        """"""
        Find the line of intersection between two planes
        :param Plane other:
        :return Line or None if parallel
        """"""
        n1 = self.normal
        n2 = other.normal
        d = n1.cross(n2)
        if d.norm() == 0:
            return None
        # point on line
        # equations: n1r = -p1, n2r = -p2
        p1 = -self.p
        p2 = -other.p
        temp = (n2 * p1) - (n1 * p2)
        num = temp.cross(d)
        denom = d.dot(d)
        point_vec = num * (1.0 / denom)
        point = Point(point_vec.x, point_vec.y, point_vec.z)
        return Line(point, d)","class Plane:
    def __init__(self, normal, p):
        '''
        Equation of a plane, in the form n.x + p = 0
        :param Vector normal:
        :param float p:
        :return:
        '''
        self.normal = normal
        self.p = p

    def __str__(self):
        return f""Plane(normal={self.normal}, p={self.p})""

    def perpendicular_distance_to_point(self, other):
        '''
        Calculate the perpendicular distance of a point from a plane
        :param Point other:
        :return:
        '''
        return abs(self.normal.dot(other) + self.p) / self.normal.magnitude()

    def line_of_intersection(self, other):
        '''
        Find the line of intersection between two planes
        :param Plane other:
        :return Line:
        '''
        from line import Line
        from vector import Vector
        
        # Direction of the line is the cross product of the normals
        direction = self.normal.cross(other.normal)
        
        # If direction is zero, planes are parallel
        if direction.magnitude() == 0:
            raise ValueError(""Planes are parallel, no intersection line"")
        
        # Find a point on the line by solving the system of equations
        # We solve: n1.x + p1 = 0 and n2.x + p2 = 0
        # Set one coordinate to 0 and solve for the other two
        n1, n2 = self.normal, other.normal
        p1, p2 = self.p, other.p
        
        # Try setting z = 0 first
        det = n1.x * n2.y - n1.y * n2.x
        if det != 0:
            x = (n1.y * p2 - n2.y * p1) / det
            y = (n2.x * p1 - n1.x * p2) / det
            point = Vector(x, y, 0)
        else:
            # Try setting y = 0
            det = n1.x * n2.z - n1.z * n2.x
            if det != 0:
                x = (n1.z * p2 - n2.z * p1) / det
                z = (n2.x * p1 - n1.x * p2) / det
                point = Vector(x, 0, z)
            else:
                # Try setting x = 0
                det = n1.y * n2.z - n1.z * n2.y
                if det != 0:
                    y = (n1.z * p2 - n2.z * p1) / det
                    z = (n2.y * p1 - n1.y * p2) / det
                    point = Vector(0, y, z)
                else:
                    raise ValueError(""Cannot find intersection point"")
        
        return Line(point, direction)","class Plane:
    def __init__(self, normal, p):
        '''
        Equation of a plane, in the form n.x+p = 0
        :param Vector normal:
        :param float p:
        :return:
        '''
        self.normal = normal
        self.p = p

    def __str__(self):
        return f""Plane(normal={self.normal}, p={self.p})""

    def perpendicular_distance_to_point(self, other):
        '''
        Calculate the perpendicular distance of a point from a place
        :param Point other:
        :return:
        '''
        return abs(self.normal.dot(other) + self.p) / self.normal.magnitude()

    def line_of_intersection(self, other):
        '''
        Find the line of intersection between two planes
        :param Plane other:
        :return Line:
        '''
        direction = self.normal.cross(other.normal)
        
        # Find a point on the line of intersection
        # We need to solve the system of equations:
        # n1.x + p1 = 0
        # n2.x + p2 = 0
        
        # Find the coordinate with the largest component in the direction vector
        abs_dir = [abs(direction.x), abs(direction.y), abs(direction.z)]
        max_index = abs_dir.index(max(abs_dir))
        
        if max_index == 0:  # x component is largest
            # Set x = 0, solve for y and z
            det = self.normal.y * other.normal.z - self.normal.z * other.normal.y
            y = (self.normal.z * other.p - other.normal.z * self.p) / det
            z = (other.normal.y * self.p - self.normal.y * other.p) / det
            point = Point(0, y, z)
        elif max_index == 1:  # y component is largest
            # Set y = 0, solve for x and z
            det = self.normal.x * other.normal.z - self.normal.z * other.normal.x
            x = (self.normal.z * other.p - other.normal.z * self.p) / det
            z = (other.normal.x * self.p - self.normal.x * other.p) / det
            point = Point(x, 0, z)
        else:  # z component is largest
            # Set z = 0, solve for x and y
            det = self.normal.x * other.normal.y - self.normal.y * other.normal.x
            x = (self.normal.y * other.p - other.normal.y * self.p) / det
            y = (other.normal.x * self.p - self.normal.x * other.p) / det
            point = Point(x, y, 0)
        
        return Line(point, direction)",partial_docstr,0.6756032171581771,0.4797843665768194,0.37940379403794033,0.552278820375335,0.5347287657009664,0.7877906976744186,0.565597667638484,0.4619883040935672,0.8737316727638245,0.8772730827331543,0.8754988312721252,0.8769177198410034,0.7903246774193552,0.6202783300198808,0.4311377245508982,0.31262525050100204,0.5168986083499006,0.4311078916120638,0.5670289855072463,0.4246823956442831,0.3327272727272727,0.8644505739212036,0.9068702459335327,0.8851524591445923,0.9024418592453003,0.8072935937500004,0.5774378585086042,0.42226487523992323,0.34296724470134876,0.5009560229445507,0.3858596181551069,0.5090311986863711,0.3848684210526316,0.2932454695222405,0.8608124256134033,0.8901363015174866,0.8752288818359375,0.8871142864227295,0.8039235294117647,0.4025505562410252,0.3547077372886235,0.3647788203640654,0.4545454545454545,0.4361702127659574,0.4285521995442384,0.1998353938764479,0.3708003429324734,0.5371900826446281,0.6063829787234043,0.4085305211081941,0.2215171515930882,0.3823605157480758,0.4132231404958678,0.6170212765957447
239487,apache/incubator-mxnet,apache_incubator-mxnet/python/mxnet/kvstore/kvstore_server.py,mxnet.kvstore.kvstore_server.KVStoreServer,"class KVStoreServer(object):
    """"""The key-value store server.""""""
    def __init__(self, kvstore):
        """"""Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        """"""
        self.kvstore = kvstore
        self.handle = kvstore.handle
        self.init_logginig = False

    def _controller(self):
        """"""Return the server controller.""""""
        def server_controller(cmd_id, cmd_body, _):
            """"""Server controler.""""""
            if not self.init_logginig:
                # the reason put the codes here is because we cannot get
                # kvstore.rank earlier
                head = '%(asctime)-15s Server[' + str(
                    self.kvstore.rank) + '] %(message)s'
                logging.basicConfig(level=logging.DEBUG, format=head)
                self.init_logginig = True

            if cmd_id == 0:
                try:
                    optimizer = pickle.loads(cmd_body)
                except:
                    raise
                self.kvstore.set_optimizer(optimizer)
            else:
                print(f""server {self.kvstore.rank}, unknown command ({cmd_id}, {cmd_body})"")
        return server_controller

    def run(self):
        """"""Run the server, whose behavior is like.


        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        """"""
        _ctrl_proto = ctypes.CFUNCTYPE(None, ctypes.c_int, ctypes.c_char_p, ctypes.c_void_p)
        check_call(_LIB.MXKVStoreRunServer(self.handle, _ctrl_proto(self._controller()), None))","class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
    '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        pass

    def _controller(self):
    '''Return the server controller.'''
        pass

        def server_controller(cmd_id, cmd_body, _):
    '''Server controler.'''
                pass

    def run(self):
    '''Run the server, whose behavior is like.


        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        pass

",5,5,snippet_717,0.3333333333333333,"class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
        '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        self.kvstore = kvstore

    def _controller(self):
        '''Return the server controller.'''
        def server_controller(cmd_id, cmd_body, _):
            op = cmd_body[0]
            if op == 'GET':
                key = cmd_body[1]
                try:
                    value = self.kvstore.get(key)
                    reply = ('OK', value)
                except KeyError:
                    reply = ('ErrNoKey', None)
            elif op == 'PUT':
                key, value = cmd_body[1], cmd_body[2]
                self.kvstore.put(key, value)
                reply = ('OK', None)
            elif op == 'DELETE':
                key = cmd_body[1]
                try:
                    self.kvstore.delete(key)
                    reply = ('OK', None)
                except KeyError:
                    reply = ('ErrNoKey', None)
            else:
                reply = ('ErrUnknownOp', None)
            return (cmd_id, reply)
        return server_controller

    def run(self):
        '''Run the server, whose behavior is like.

        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        run_server(self._controller(), self.kvstore.updater)","class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
        '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        self.kvstore = kvstore
        self.running = False

    def _controller(self):
        '''Return the server controller.'''
        def server_controller(cmd_id, cmd_body, _):
            '''Server controller.'''
            # Handle different command types based on cmd_id
            if cmd_id == 'GET':
                key = cmd_body.get('key')
                return self.kvstore.get(key)
            elif cmd_id == 'PUT':
                key = cmd_body.get('key')
                value = cmd_body.get('value')
                self.kvstore.put(key, value)
                return 'OK'
            elif cmd_id == 'DELETE':
                key = cmd_body.get('key')
                self.kvstore.delete(key)
                return 'OK'
            else:
                return 'UNKNOWN_COMMAND'
        return server_controller

    def run(self):
        '''Run the server, whose behavior is like.


        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        self.running = True
        controller = self._controller()
        
        while self.running:
            try:
                x = self._receive()  # Assuming this method exists to receive data
                if self._is_command(x):
                    response = controller(x['cmd_id'], x['cmd_body'], None)
                    self._send_response(response)  # Assuming this method exists to send response
                elif self._is_key_value(x):
                    self._updater(x)  # Assuming this method exists to handle key-value updates
            except Exception as e:
                # Handle exceptions and potentially break the loop if needed
                if not self.running:
                    break

    def _receive(self):
        '''Placeholder for receiving data - should be implemented based on actual communication method.'''
        # This would typically block and wait for incoming data
        raise NotImplementedError(""Receive method needs to be implemented"")

    def _is_command(self, x):
        '''Check if received data is a command.'''
        return isinstance(x, dict) and 'cmd_id' in x and 'cmd_body' in x

    def _is_key_value(self, x):
        '''Check if received data is a key-value pair.'''
        return isinstance(x, dict) and 'key' in x and 'value' in x

    def _updater(self, x):
        '''Handle key-value updates.'''
        key = x.get('key')
        value = x.get('value')
        self.kvstore.put(key, value)

    def _send_response(self, response):
        '''Placeholder for sending response - should be implemented based on actual communication method.'''
        # This would send the response back to the client
        pass

    def stop(self):
        '''Stop the server.'''
        self.running = False","class KVStoreServer(object):
    '''The key-value store server.'''

    def __init__(self, kvstore):
        '''Initialize a new KVStoreServer.

        Parameters
        ----------
        kvstore : KVStore
        '''
        self.kvstore = kvstore

    def _controller(self):
        '''Return the server controller.'''
        def server_controller(cmd_id, cmd_body, _):
            '''Server controler.'''
            if cmd_id == 0:  # init
                self.kvstore.init_keys(cmd_body)
            elif cmd_id == 1:  # push
                self.kvstore.push(cmd_body)
            elif cmd_id == 2:  # pull
                self.kvstore.pull(cmd_body)
        
        return server_controller

    def run(self):
        '''Run the server, whose behavior is like.

        >>> while receive(x):
        ...     if is_command x: controller(x)
        ...     else if is_key_value x: updater(x)
        '''
        import mxnet as mx
        controller = self._controller()
        
        def updater(key, recv, local):
            local += recv
        
        server = mx.kv.create('dist_sync')
        server.set_controller(controller)
        server.set_updater(updater)
        server.run()",partial_docstr,0.5849056603773585,0.44936708860759494,0.38216560509554137,0.5094339622641508,0.4015391261576215,0.7244897959183674,0.49146757679180886,0.4041095890410959,0.8610274791717529,0.7908849716186523,0.8244670629501343,0.7973807454109192,0.7377804000000004,0.41965973534971646,0.29981024667931694,0.24761904761904763,0.33648393194706994,0.29070838539686317,0.4321608040201005,0.2684563758389262,0.21176470588235294,0.7939710021018982,0.8100784420967102,0.8019438982009888,0.8084383010864258,0.7431218348623853,0.6026490066225165,0.5133333333333334,0.4496644295302013,0.5496688741721855,0.3818930543930918,0.8023715415019763,0.5793650793650794,0.4940239043824701,0.8794116973876953,0.7872511148452759,0.8307833075523376,0.7955886721611023,0.7906997674418604,0.3770571659652806,0.2912286492104515,0.3012857289363854,0.38,0.5357142857142857,0.3784362835723218,0.1375883594968371,0.3468710605067359,0.44,0.5892857142857143,0.3771052226520247,0.2949187020463076,0.3135021885617913,0.4,0.5
738609,sibirrer/lenstronomy,sibirrer_lenstronomy/lenstronomy/GalKin/psf.py,lenstronomy.GalKin.psf.PSFMoffat,"class PSFMoffat(object):
    """"""Moffat PSF.""""""

    def __init__(self, fwhm, moffat_beta):
        """"""

        :param fwhm: full width at half maximum seeing condition
        :param moffat_beta: float, beta parameter of Moffat profile
        """"""
        self._fwhm = fwhm
        self._moffat_beta = moffat_beta

    def displace_psf(self, x, y):
        """"""

        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: x', y' displaced by the two-dimensional PSF distribution function
        """"""
        return velocity_util.displace_PSF_moffat(x, y, self._fwhm, self._moffat_beta)

    def convolution_kernel(self, delta_pix, num_pix=21):
        """"""Normalized convolution kernel.

        :param delta_pix: pixel scale of kernel
        :param num_pix: number of pixels per axis of the kernel
        :return: 2d numpy array of kernel
        """"""

        kernel = kernel_util.kernel_moffat(
            num_pix=num_pix,
            delta_pix=delta_pix,
            fwhm=self._fwhm,
            moffat_beta=self._moffat_beta,
        )
        return kernel

    def convolution_kernel_grid(self, x, y):
        """"""
        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: psf value at x and y grid positions
        """"""
        return kernel_util.kernel_moffat_grid(x, y, self._fwhm, self._moffat_beta)","class PSFMoffat(object):
    '''Moffat PSF.'''

    def __init__(self, fwhm, moffat_beta):
    '''

        :param fwhm: full width at half maximum seeing condition
        :param moffat_beta: float, beta parameter of Moffat profile
        '''
        pass

    def displace_psf(self, x, y):
    '''

        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: x', y' displaced by the two-dimensional PSF distribution function
        '''
        pass

    def convolution_kernel(self, delta_pix, num_pix=21):
    '''Normalized convolution kernel.

        :param delta_pix: pixel scale of kernel
        :param num_pix: number of pixels per axis of the kernel
        :return: 2d numpy array of kernel
        '''
        pass

    def convolution_kernel_grid(self, x, y):
    '''
        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: psf value at x and y grid positions
        '''
        pass

",5,5,snippet_482,1.0,"class PSFMoffat(object):
    '''Moffat PSF.'''

    def __init__(self, fwhm, moffat_beta):
        '''
        :param fwhm: full width at half maximum seeing condition
        :param moffat_beta: float, beta parameter of Moffat profile
        '''
        self.fwhm = fwhm
        self.beta = moffat_beta
        self.alpha = fwhm / (2.0 * sqrt(2.0**(1.0/self.beta) - 1.0))
        self.norm = (self.beta - 1.0) / (pi * self.alpha**2)

    def displace_psf(self, x, y):
        '''
        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: x', y' displaced by the two-dimensional PSF distribution function
        '''
        u = random()
        r = self.alpha * sqrt((1.0 - u)**(-1.0/(self.beta - 1.0)) - 1.0)
        theta = uniform(0.0, 2.0*pi)
        dx = r * cos(theta)
        dy = r * sin(theta)
        return x + dx, y + dy

    def convolution_kernel(self, delta_pix, num_pix=21):
        '''Normalized convolution kernel.

        :param delta_pix: pixel scale of kernel
        :param num_pix: number of pixels per axis of the kernel
        :return: 2d numpy array of kernel
        '''
        half = num_pix // 2
        coords = (np.arange(num_pix) - half) * delta_pix
        X, Y = np.meshgrid(coords, coords)
        K = self.convolution_kernel_grid(X, Y)
        return K / np.sum(K)

    def convolution_kernel_grid(self, x, y):
        '''
        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: psf value at x and y grid positions
        '''
        r2 = x**2 + y**2
        return self.norm * (1.0 + r2 / self.alpha**2)**(-self.beta)","class PSFMoffat(object):
    '''Moffat PSF.'''

    def __init__(self, fwhm, moffat_beta):
        '''

        :param fwhm: full width at half maximum seeing condition
        :param moffat_beta: float, beta parameter of Moffat profile
        '''
        self.fwhm = fwhm
        self.beta = moffat_beta
        # Calculate alpha parameter from FWHM and beta
        self.alpha = fwhm / (2 * np.sqrt(2**(1/self.beta) - 1))

    def displace_psf(self, x, y):
        '''

        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: x', y' displaced by the two-dimensional PSF distribution function
        '''
        # Generate random numbers for sampling
        r = np.random.random()
        theta = 2 * np.pi * np.random.random()
        
        # Inverse transform sampling for Moffat distribution
        # For radial distance sampling
        r_moffat = self.alpha * np.sqrt((1 - r)**(-1/self.beta) - 1)
        
        # Convert to Cartesian coordinates
        dx = r_moffat * np.cos(theta)
        dy = r_moffat * np.sin(theta)
        
        return x + dx, y + dy

    def convolution_kernel(self, delta_pix, num_pix=21):
        '''Normalized convolution kernel.

        :param delta_pix: pixel scale of kernel
        :param num_pix: number of pixels per axis of the kernel
        :return: 2d numpy array of kernel
        '''
        # Create coordinate grid
        center = (num_pix - 1) / 2
        x = np.arange(num_pix) * delta_pix - center * delta_pix
        y = np.arange(num_pix) * delta_pix - center * delta_pix
        xx, yy = np.meshgrid(x, y)
        
        # Calculate radial distance
        r = np.sqrt(xx**2 + yy**2)
        
        # Moffat profile
        kernel = (self.beta - 1) / (np.pi * self.alpha**2) * (1 + (r/self.alpha)**2)**(-self.beta)
        
        # Normalize kernel
        kernel = kernel / np.sum(kernel)
        
        return kernel

    def convolution_kernel_grid(self, x, y):
        '''
        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: psf value at x and y grid positions
        '''
        # Calculate radial distance
        r = np.sqrt(x**2 + y**2)
        
        # Moffat profile
        psf_value = (self.beta - 1) / (np.pi * self.alpha**2) * (1 + (r/self.alpha)**2)**(-self.beta)
        
        return psf_value","class PSFMoffat(object):
    '''Moffat PSF.'''

    def __init__(self, fwhm, moffat_beta):
        '''
        :param fwhm: full width at half maximum seeing condition
        :param moffat_beta: float, beta parameter of Moffat profile
        '''
        self.fwhm = fwhm
        self.moffat_beta = moffat_beta
        self.alpha = fwhm / (2 * np.sqrt(2**(1/moffat_beta) - 1))

    def displace_psf(self, x, y):
        '''
        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: x', y' displaced by the two-dimensional PSF distribution function
        '''
        # Generate random displacement based on Moffat profile
        # Use rejection sampling or Box-Muller transform with Moffat distribution
        r = np.sqrt(x**2 + y**2)
        
        # Generate random radius from Moffat distribution
        u = np.random.uniform(0, 1, size=np.shape(x))
        r_new = self.alpha * np.sqrt((1 - u)**(-1/(self.moffat_beta - 0.5)) - 1)
        
        # Generate random angle
        theta = np.random.uniform(0, 2*np.pi, size=np.shape(x))
        
        # Convert back to Cartesian coordinates
        x_new = r_new * np.cos(theta)
        y_new = r_new * np.sin(theta)
        
        return x + x_new, y + y_new

    def convolution_kernel(self, delta_pix, num_pix=21):
        '''Normalized convolution kernel.
        :param delta_pix: pixel scale of kernel
        :param num_pix: number of pixels per axis of the kernel
        :return: 2d numpy array of kernel
        '''
        center = num_pix // 2
        x = np.arange(num_pix) - center
        y = np.arange(num_pix) - center
        X, Y = np.meshgrid(x * delta_pix, y * delta_pix)
        
        kernel = self.convolution_kernel_grid(X, Y)
        kernel = kernel / np.sum(kernel)  # Normalize
        
        return kernel

    def convolution_kernel_grid(self, x, y):
        '''
        :param x: x-coordinate of light ray
        :param y: y-coordinate of light ray
        :return: psf value at x and y grid positions
        '''
        r_squared = x**2 + y**2
        alpha_squared = self.alpha**2
        
        # Moffat profile: I(r) = (beta-1)/(pi*alpha^2) * (1 + r^2/alpha^2)^(-beta)
        normalization = (self.moffat_beta - 1) / (np.pi * alpha_squared)
        profile = normalization * (1 + r_squared / alpha_squared)**(-self.moffat_beta)
        
        return profile",partial_docstr,0.75177304964539,0.6413301662707839,0.5966587112171838,0.7044917257683215,0.5061922344352631,0.60431654676259,0.49759615384615385,0.43132530120481927,0.8379124999046326,0.9300008416175842,0.8815582990646362,0.9198909997940063,0.7952579775280899,0.7016129032258064,0.5708502024291499,0.524390243902439,0.6290322580645161,0.38400817548384203,0.46935201401050786,0.37719298245614036,0.31985940246045697,0.8283482789993286,0.9475046992301941,0.8839289546012878,0.9340682625770569,0.766760826446281,0.6796875,0.5843137254901961,0.5275590551181102,0.6171875,0.39143448151825366,0.4839797639123103,0.38344594594594594,0.32318104906937395,0.8118194341659546,0.9364988803863525,0.8697134256362915,0.9223336577415466,0.7702857771260998,0.5438124672065715,0.4355524845661794,0.6706666513995864,0.4468085106382978,0.6222222222222222,0.5578429776971288,0.321082570961691,0.6866486778882898,0.4680851063829787,0.7555555555555555,0.5440586059676853,0.3326117507105839,0.6866486778882898,0.4680851063829787,0.6888888888888889
742573,skyfielders/python-skyfield,skyfielders_python-skyfield/skyfield/framelib.py,skyfield.framelib.ICRS,"class ICRS(object):
    """"""The International Celestial Reference System (ICRS).

    The ICRS is a permanent reference frame which has replaced J2000,
    with which its axes agree to within 0.02 arcseconds (closer than the
    precision of J2000 itself).  The ICRS also supersedes older
    equinox-based systems like B1900 and B1950.

    """"""
    @staticmethod
    def rotation_at(t):
        return _identity","class ICRS(object):
    '''The International Celestial Reference System (ICRS).

    The ICRS is a permanent reference frame which has replaced J2000,
    with which its axes agree to within 0.02 arcseconds (closer than the
    precision of J2000 itself).  The ICRS also supersedes older
    equinox-based systems like B1900 and B1950.

    '''

    @staticmethod
    def rotation_at(t):
        pass

",3,1,snippet_510,1.0,"class ICRS(object):
    '''The International Celestial Reference System (ICRS).

    The ICRS is a permanent reference frame which has replaced J2000,
    with which its axes agree to within 0.02 arcseconds (closer than the
    precision of J2000 itself).  The ICRS also supersedes older
    equinox-based systems like B1900 and B1950.

    '''

    @staticmethod
    def rotation_at(t):
        """"""
        Return the rotation matrix at time t that transforms coordinates
        from the ICRS frame to itself (identity, since ICRS is inertial).
        """"""
        return np.eye(3)","class ICRS(object):
    '''The International Celestial Reference System (ICRS).

    The ICRS is a permanent reference frame which has replaced J2000,
    with which its axes agree to within 0.02 arcseconds (closer than the
    precision of J2000 itself).  The ICRS also supersedes older
    equinox-based systems like B1900 and B1950.

    '''

    @staticmethod
    def rotation_at(t):
        '''
        Calculate the rotation matrix from ICRS to equatorial coordinates at a given time.
        
        Parameters
        ----------
        t : astropy.time.Time or compatible
            The time at which to calculate the rotation matrix
            
        Returns
        -------
        numpy.ndarray
            3x3 rotation matrix
        '''
        # For ICRS, the rotation matrix is typically the identity matrix
        # since ICRS is the standard reference frame
        return np.eye(3)","class ICRS(object):
    '''The International Celestial Reference System (ICRS).

    The ICRS is a permanent reference frame which has replaced J2000,
    with which its axes agree to within 0.02 arcseconds (closer than the
    precision of J2000 itself).  The ICRS also supersedes older
    equinox-based systems like B1900 and B1950.

    '''

    @staticmethod
    def rotation_at(t):
        import numpy as np
        return np.eye(3)",partial_docstr,0.8296296296296296,0.81203007518797,0.8091603053435115,0.8296296296296296,0.6658010081427076,0.7037037037037037,0.6635514018691588,0.6320754716981132,0.9211932420730591,0.9833235740661621,0.9512450098991394,0.9767358899116516,0.8924741935483871,0.6746987951807228,0.6463414634146342,0.6419753086419752,0.6626506024096385,0.47068874688823154,0.5035460992907801,0.4642857142857143,0.4460431654676259,0.8230884075164795,0.9708735942840576,0.890893816947937,0.9537490606307983,0.8787890909090909,0.9322033898305085,0.9137931034482758,0.912280701754386,0.9322033898305085,0.8159258261911934,0.8518518518518519,0.8125,0.7848101265822784,0.9589437246322632,0.9865937232971191,0.9725722074508667,0.9837572574615479,0.8924741935483871,0.6940182918795927,0.5999787447397182,0.876094422778653,0.3,0.0,0.6462695839188102,0.4119588095733367,0.8731195261019042,0.3,0.0,0.7445662622828682,0.805145523029568,0.8731195261019042,0.3,0.0
402351,gmr/infoblox,gmr_infoblox/infoblox/cli.py,infoblox.cli.InfobloxHost,"class InfobloxHost(object):
    """"""The Infoblox class is an interface for interfacing with the Infoblox
    appliance and contains pre-defined functionality for adding and removing
    hosts and the relevant records for those hosts.

    """"""
    HEADERS = {'Content-type': 'application/json'}

    def __init__(self, host, username=None, password=None):
        """"""Create a new instance of the Infoblox class

        :param str host: The Infoblox host to communicate with
        :param str username: The user to authenticate with
        :param str password: The password to authenticate with

        """"""

        self.session = Session(host, username, password)

    def delete_old_host(self, hostname):
        """"""Remove all records for the host.

        :param str hostname: Hostname to remove
        :rtype: bool

        """"""
        host = Host(self.session, name=hostname)
        return host.delete()

    def add_new_host(self, hostname, ipv4addr, comment=None):
        """"""Add or update a host in the infoblox, overwriting any IP address
        entries.

        :param str hostname: Hostname to add/set
        :param str ipv4addr: IP Address to add/set
        :param str comment: The comment for the record

        """"""
        host = Host(self.session, name=hostname)
        if host.ipv4addrs:
            host.ipv4addrs = []
        host.add_ipv4addr(ipv4addr)
        host.comment = comment
        return host.save()","class InfobloxHost(object):
    '''The Infoblox class is an interface for interfacing with the Infoblox
    appliance and contains pre-defined functionality for adding and removing
    hosts and the relevant records for those hosts.

    '''

    def __init__(self, host, username=None, password=None):
    '''Create a new instance of the Infoblox class

        :param str host: The Infoblox host to communicate with
        :param str username: The user to authenticate with
        :param str password: The password to authenticate with

        '''
        pass

    def delete_old_host(self, hostname):
    '''Remove all records for the host.

        :param str hostname: Hostname to remove
        :rtype: bool

        '''
        pass

    def add_new_host(self, hostname, ipv4addr, comment=None):
    '''Add or update a host in the infoblox, overwriting any IP address
        entries.

        :param str hostname: Hostname to add/set
        :param str ipv4addr: IP Address to add/set
        :param str comment: The comment for the record

        '''
        pass

",4,4,snippet_346,0.5,"class InfobloxHost(object):
    '''The Infoblox class is an interface for interfacing with the Infoblox
    appliance and contains pre-defined functionality for adding and removing
    hosts and the relevant records for those hosts.
    '''

    def __init__(self, host, username=None, password=None):
        '''Create a new instance of the Infoblox class

        :param str host: The Infoblox host to communicate with
        :param str username: The user to authenticate with
        :param str password: The password to authenticate with
        '''
        self.base_url = f""https://{host}/wapi/v2.7/""
        self.session = requests.Session()
        self.session.verify = False
        if username and password:
            self.session.auth = HTTPBasicAuth(username, password)
        self.session.headers.update({""Content-Type"": ""application/json""})

    def delete_old_host(self, hostname):
        '''Remove all records for the host.

        :param str hostname: Hostname to remove
        :rtype: bool
        '''
        url = self.base_url + ""record:host""
        params = {""name"": hostname}
        r = self.session.get(url, params=params)
        if not r.ok:
            return False
        records = r.json()
        for rec in records:
            ref = rec.get(""_ref"")
            if not ref:
                continue
            del_url = self.base_url + ref
            dr = self.session.delete(del_url)
            if not dr.ok:
                return False
        return True

    def add_new_host(self, hostname, ipv4addr, comment=None):
        '''Add or update a host in the infoblox, overwriting any IP address
        entries.

        :param str hostname: Hostname to add/set
        :param str ipv4addr: IP Address to add/set
        :param str comment: The comment for the record
        '''
        # Remove existing records first
        if not self.delete_old_host(hostname):
            return False

        url = self.base_url + ""record:host""
        payload = {
            ""name"": hostname,
            ""ipv4addrs"": [{""ipv4addr"": ipv4addr}]
        }
        if comment:
            payload[""comment""] = comment

        r = self.session.post(url, json=payload)
        return r.ok","class InfobloxHost(object):
    '''The Infoblox class is an interface for interfacing with the Infoblox
    appliance and contains pre-defined functionality for adding and removing
    hosts and the relevant records for those hosts.

    '''

    def __init__(self, host, username=None, password=None):
        '''Create a new instance of the Infoblox class

        :param str host: The Infoblox host to communicate with
        :param str username: The user to authenticate with
        :param str password: The password to authenticate with

        '''
        self.host = host
        self.username = username
        self.password = password

    def delete_old_host(self, hostname):
        '''Remove all records for the host.

        :param str hostname: Hostname to remove
        :rtype: bool

        '''
        # Implementation would typically involve API calls to Infoblox
        # This is a placeholder implementation
        try:
            # Code to delete host records would go here
            # Example: make API call to delete host
            return True
        except Exception:
            return False

    def add_new_host(self, hostname, ipv4addr, comment=None):
        '''Add or update a host in the infoblox, overwriting any IP address
        entries.

        :param str hostname: Hostname to add/set
        :param str ipv4addr: IP Address to add/set
        :param str comment: The comment for the record

        '''
        # Implementation would typically involve API calls to Infoblox
        # This is a placeholder implementation
        pass","class InfobloxHost(object):
    '''The Infoblox class is an interface for interfacing with the Infoblox
    appliance and contains pre-defined functionality for adding and removing
    hosts and the relevant records for those hosts.

    '''

    def __init__(self, host, username=None, password=None):
        '''Create a new instance of the Infoblox class

        :param str host: The Infoblox host to communicate with
        :param str username: The user to authenticate with
        :param str password: The password to authenticate with

        '''
        self.host = host
        self.username = username
        self.password = password
        self.base_url = f""https://{host}/wapi/v2.12""
        self.session = requests.Session()
        if username and password:
            self.session.auth = HTTPBasicAuth(username, password)
        self.session.verify = False

    def delete_old_host(self, hostname):
        '''Remove all records for the host.

        :param str hostname: Hostname to remove
        :rtype: bool

        '''
        try:
            # Search for host records
            search_url = f""{self.base_url}/record:host""
            params = {""name"": hostname}
            response = self.session.get(search_url, params=params)
            
            if response.status_code == 200:
                records = response.json()
                for record in records:
                    ref = record.get('_ref')
                    if ref:
                        delete_url = f""{self.base_url}/{ref}""
                        delete_response = self.session.delete(delete_url)
                        if delete_response.status_code != 200:
                            return False
                return True
            return False
        except Exception:
            return False

    def add_new_host(self, hostname, ipv4addr, comment=None):
        '''Add or update a host in the infoblox, overwriting any IP address
        entries.

        :param str hostname: Hostname to add/set
        :param str ipv4addr: IP Address to add/set
        :param str comment: The comment for the record

        '''
        try:
            # First delete existing host
            self.delete_old_host(hostname)
            
            # Create new host record
            url = f""{self.base_url}/record:host""
            data = {
                ""name"": hostname,
                ""ipv4addrs"": [{""ipv4addr"": ipv4addr}]
            }
            if comment:
                data[""comment""] = comment
            
            response = self.session.post(url, json=data)
            return response.status_code == 201
        except Exception:
            return False",partial_docstr,0.7527839643652562,0.6666666666666666,0.602247191011236,0.7037861915367484,0.47110999751778976,0.6026200873362445,0.4420131291028446,0.3925438596491228,0.8669489622116089,0.9425150752067566,0.9031541347503662,0.9343706965446472,0.7617473489932892,0.8,0.739946380697051,0.7169811320754718,0.7733333333333333,0.6273853557641969,0.7715355805243446,0.6842105263157895,0.6415094339622641,0.9166275262832642,0.9368773698806763,0.9266418218612671,0.9348121881484985,0.7826108695652174,0.718816067653277,0.624203821656051,0.5628997867803838,0.6723044397463003,0.4287407800941624,0.5517928286852589,0.40119760479041916,0.356,0.8651740550994873,0.9458563327789307,0.9037179350852966,0.9371172189712524,0.7566161904761909,0.488693429229124,0.4879157164884937,0.7221273212710939,0.4590163934426229,0.2857142857142857,0.4232472093563729,0.5745385897252357,0.7117367426260951,0.3114754098360656,0.0952380952380952,0.47825581309664,0.4520029033544548,0.7237057510617698,0.4754098360655737,0.2619047619047619
498061,intelsdi-x/snap-plugin-lib-py,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/intelsdi-x_snap-plugin-lib-py/snap_plugin/v1/plugin_pb2.py,snap_plugin.v1.plugin_pb2.BetaStreamCollectorServicer,"class BetaStreamCollectorServicer(object):
    """"""The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.""""""
    # missing associated documentation comment in .proto file
    pass

    def StreamMetrics(self, request_iterator, context):
        # missing associated documentation comment in .proto file
        pass
        context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)

    def GetMetricTypes(self, request, context):
        # missing associated documentation comment in .proto file
        pass
        context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)

    def Ping(self, request, context):
        # missing associated documentation comment in .proto file
        pass
        context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)

    def Kill(self, request, context):
        # missing associated documentation comment in .proto file
        pass
        context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)

    def GetConfigPolicy(self, request, context):
        # missing associated documentation comment in .proto file
        pass
        context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)
","class BetaStreamCollectorServicer(object):
    '''The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.'''


    def StreamMetrics(self, request_iterator, context):
        pass


    def GetMetricTypes(self, request, context):
        pass


    def Ping(self, request, context):
        pass


    def Kill(self, request, context):
        pass


    def GetConfigPolicy(self, request, context):
        pass

",6,1,snippet_193,1.0,"class BetaStreamCollectorServicer(object):
    '''The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.'''

    def StreamMetrics(self, request_iterator, context):
        context.abort(
            grpc.StatusCode.UNIMPLEMENTED,
            'Beta API StreamMetrics is deprecated for 0.15.0 and later; use the GA API instead.'
        )

    def GetMetricTypes(self, request, context):
        context.abort(
            grpc.StatusCode.UNIMPLEMENTED,
            'Beta API GetMetricTypes is deprecated for 0.15.0 and later; use the GA API instead.'
        )

    def Ping(self, request, context):
        context.abort(
            grpc.StatusCode.UNIMPLEMENTED,
            'Beta API Ping is deprecated for 0.15.0 and later; use the GA API instead.'
        )

    def Kill(self, request, context):
        context.abort(
            grpc.StatusCode.UNIMPLEMENTED,
            'Beta API Kill is deprecated for 0.15.0 and later; use the GA API instead.'
        )

    def GetConfigPolicy(self, request, context):
        context.abort(
            grpc.StatusCode.UNIMPLEMENTED,
            'Beta API GetConfigPolicy is deprecated for 0.15.0 and later; use the GA API instead.'
        )","class BetaStreamCollectorServicer(object):
    '''The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.'''


    def StreamMetrics(self, request_iterator, context):
        raise NotImplementedError()


    def GetMetricTypes(self, request, context):
        raise NotImplementedError()


    def Ping(self, request, context):
        raise NotImplementedError()


    def Kill(self, request, context):
        raise NotImplementedError()


    def GetConfigPolicy(self, request, context):
        raise NotImplementedError()","class BetaStreamCollectorServicer(object):
    '''The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0.'''

    def StreamMetrics(self, request_iterator, context):
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetMetricTypes(self, request, context):
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Ping(self, request, context):
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def Kill(self, request, context):
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def GetConfigPolicy(self, request, context):
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')",partial_docstr,0.5806451612903225,0.4601769911504424,0.39762611275964393,0.5513196480938416,0.5154318813891244,0.6150793650793651,0.5059760956175299,0.44,0.8941913843154907,0.8700069785118103,0.8819334506988525,0.8723663687705994,0.9118466115702479,0.6422764227642277,0.5983606557377049,0.5537190082644629,0.6422764227642277,0.3722432668737751,0.9090909090909091,0.816793893129771,0.7692307692307693,0.9378842711448669,0.8203722238540649,0.8752013444900513,0.8307814598083496,0.8466092035398229,0.616822429906542,0.4890282131661442,0.4227129337539432,0.616822429906542,0.4981883899136046,0.5956678700361011,0.4963768115942029,0.41818181818181815,0.8944293260574341,0.8860993385314941,0.8902448415756226,0.8869253993034363,0.8219913089005235,0.5392482951787739,0.347161601461153,0.4280133974357609,0.3818181818181818,1.0,0.3471443391518988,0.3642935629014381,0.4280133974357609,0.109090909090909,0.4871794871794871,0.6246822531715024,0.4161701607047943,0.4280133974357609,0.6545454545454545,1.0
128747,IBMStreams/pypi.streamsx,IBMStreams_pypi.streamsx/streamsx/rest_primitives.py,streamsx.rest_primitives.ResourceTag,"class ResourceTag(object):
    """"""Resource tag defined in a Streams domain

    Attributes:
        definition_format_properties(bool): Indicates whether the resource definition consists of one or more
            properties.
        description(str): Tag description.
        name(str): Tag name.
        properties_definition(list(str)): Contains the properties of the resource definition. Only present if
            `definition_format_properties` is *True*.
        reserved(bool): If *True*, this tag is defined by IBM Streams, and cannot be modified.
    """"""
    def __init__(self, json_resource_tag):
        self.definition_format_properties = json_resource_tag['definitionFormatProperties']
        self.description = json_resource_tag['description']
        self.name = json_resource_tag['name']
        self.properties_definition = json_resource_tag['propertiesDefinition']
        self.reserved = json_resource_tag['reserved']

    def __str__(self):
        return pformat(self.__dict__)","class ResourceTag(object):
    '''Resource tag defined in a Streams domain

    Attributes:
        definition_format_properties(bool): Indicates whether the resource definition consists of one or more
            properties.
        description(str): Tag description.
        name(str): Tag name.
        properties_definition(list(str)): Contains the properties of the resource definition. Only present if
            `definition_format_properties` is *True*.
        reserved(bool): If *True*, this tag is defined by IBM Streams, and cannot be modified.
    '''

    def __init__(self, json_resource_tag):
        pass

    def __str__(self):
        pass

",3,1,snippet_191,0.75,"class ResourceTag(object):
    '''Resource tag defined in a Streams domain

    Attributes:
        definition_format_properties(bool): Indicates whether the resource definition consists of one or more
            properties.
        description(str): Tag description.
        name(str): Tag name.
        properties_definition(list(str)): Contains the properties of the resource definition. Only present if
            `definition_format_properties` is *True*.
        reserved(bool): If *True*, this tag is defined by IBM Streams, and cannot be modified.
    '''

    def __init__(self, json_resource_tag):
        required = ['definitionFormatProperties', 'description', 'name', 'reserved']
        for key in required:
            if key not in json_resource_tag:
                raise KeyError(f""Missing required field '{key}' in json_resource_tag"")
        self.definition_format_properties = bool(json_resource_tag['definitionFormatProperties'])
        self.description = str(json_resource_tag['description'])
        self.name = str(json_resource_tag['name'])
        self.reserved = bool(json_resource_tag['reserved'])
        if self.definition_format_properties:
            props = json_resource_tag.get('propertiesDefinition', [])
            if not isinstance(props, list):
                raise TypeError(""'propertiesDefinition' must be a list"")
            self.properties_definition = [str(p) for p in props]

    def __str__(self):
        parts = [
            f""name='{self.name}'"",
            f""description='{self.description}'"",
            f""reserved={self.reserved}"",
            f""definition_format_properties={self.definition_format_properties}""
        ]
        if getattr(self, 'properties_definition', None) is not None:
            parts.append(f""properties_definition={self.properties_definition}"")
        return ""ResourceTag("" + "", "".join(parts) + "")""","class ResourceTag(object):
    '''Resource tag defined in a Streams domain

    Attributes:
        definition_format_properties(bool): Indicates whether the resource definition consists of one or more
            properties.
        description(str): Tag description.
        name(str): Tag name.
        properties_definition(list(str)): Contains the properties of the resource definition. Only present if
            `definition_format_properties` is *True*.
        reserved(bool): If *True*, this tag is defined by IBM Streams, and cannot be modified.
    '''

    def __init__(self, json_resource_tag):
        self.definition_format_properties = json_resource_tag.get('definitionFormatProperties', False)
        self.description = json_resource_tag.get('description', '')
        self.name = json_resource_tag.get('name', '')
        self.reserved = json_resource_tag.get('reserved', False)
        
        if self.definition_format_properties:
            self.properties_definition = json_resource_tag.get('propertiesDefinition', [])
        else:
            self.properties_definition = None

    def __str__(self):
        return f""ResourceTag(name='{self.name}', description='{self.description}', reserved={self.reserved})""","class ResourceTag(object):
    '''Resource tag defined in a Streams domain

    Attributes:
        definition_format_properties(bool): Indicates whether the resource definition consists of one or more
            properties.
        description(str): Tag description.
        name(str): Tag name.
        properties_definition(list(str)): Contains the properties of the resource definition. Only present if
            `definition_format_properties` is *True*.
        reserved(bool): If *True*, this tag is defined by IBM Streams, and cannot be modified.
    '''

    def __init__(self, json_resource_tag):
        self.definition_format_properties = json_resource_tag.get('definitionFormatProperties', False)
        self.description = json_resource_tag.get('description', '')
        self.name = json_resource_tag.get('name', '')
        self.properties_definition = json_resource_tag.get('propertiesDefinition', [])
        self.reserved = json_resource_tag.get('reserved', False)

    def __str__(self):
        return f""ResourceTag(name='{self.name}', description='{self.description}', reserved={self.reserved}, definition_format_properties={self.definition_format_properties})""",partial_docstr,0.6956521739130436,0.63125,0.5786163522012578,0.6583850931677018,0.45599159376359216,0.5143540669856459,0.44844124700239807,0.4110576923076923,0.862133264541626,0.9655970335006714,0.910936713218689,0.9541463851928711,0.7733355999999999,0.8853754940711464,0.8127490039840637,0.7630522088353413,0.8458498023715415,0.6685529447056053,0.7345454545454545,0.6532846715328468,0.6227106227106227,0.9472333788871765,0.9783653020858765,0.9625477194786072,0.9751603007316589,0.8582103731343284,0.896,0.8306451612903226,0.7886178861788617,0.896,0.6745783251434745,0.7435897435897436,0.6580882352941176,0.6273062730627307,0.9564560651779175,0.9813746809959412,0.9687551856040955,0.9788246154785156,0.8703716666666667,0.5113290963008451,0.4123137420418374,0.7545188081559688,0.4871794871794871,0.391304347826087,0.5366639091270098,0.6608848539385518,0.7789703366386069,0.358974358974359,0.3478260869565217,0.5463275753320507,0.6995395187587147,0.7789703366386069,0.358974358974359,0.3478260869565217
221779,aleju/imgaug,aleju_imgaug/imgaug/parameters.py,imgaug.parameters.toggled_prefetching,"class toggled_prefetching(object):  # pylint: disable=invalid-name
    """"""Context that toggles prefetching on or off depending on a flag.

    Added in 0.5.0.

    Parameters
    ----------
    enabled : bool
        Whether enabled is activated (``True``) or off (``False``).

    """"""

    # Added in 0.5.0.
    def __init__(self, enabled):
        self.enabled = enabled
        self._old_state = None

    # Added in 0.5.0.
    def __enter__(self):
        # pylint: disable=global-statement
        global _PREFETCHING_ENABLED
        self._old_state = _PREFETCHING_ENABLED
        _PREFETCHING_ENABLED = self.enabled

    # Added in 0.5.0.
    def __exit__(self, exception_type, exception_value, exception_traceback):
        # pylint: disable=global-statement
        global _PREFETCHING_ENABLED
        _PREFETCHING_ENABLED = self._old_state","class toggled_prefetching(object):
    '''Context that toggles prefetching on or off depending on a flag.

    Added in 0.5.0.

    Parameters
    ----------
    enabled : bool
        Whether enabled is activated (``True``) or off (``False``).

    '''

    def __init__(self, enabled):
        pass

    def __enter__(self):
        pass

    def __exit__(self, exception_type, exception_value, exception_traceback):
        pass

",4,1,snippet_239,1.0,"class toggled_prefetching(object):
    '''Context that toggles prefetching on or off depending on a flag.

    Added in 0.5.0.

    Parameters
    ----------
    enabled : bool
        Whether enabled is activated (``True``) or off (``False``).

    '''
    def __init__(self, enabled):
        self.enabled = bool(enabled)
        self._previous = None

    def __enter__(self):
        global _prefetching_enabled
        self._previous = _prefetching_enabled
        _prefetching_enabled = self.enabled

    def __exit__(self, exception_type, exception_value, exception_traceback):
        global _prefetching_enabled
        _prefetching_enabled = self._previous
        # Do not suppress exceptions
        return False","class toggled_prefetching(object):
    '''Context that toggles prefetching on or off depending on a flag.

    Added in 0.5.0.

    Parameters
    ----------
    enabled : bool
        Whether enabled is activated (``True``) or off (``False``).

    '''

    def __init__(self, enabled):
        self.enabled = enabled
        self.original_state = None

    def __enter__(self):
        # Store the original prefetching state
        import sys
        if 'prefetching_enabled' in sys.modules:
            self.original_state = sys.modules['prefetching_enabled']
        
        # Set the new prefetching state
        sys.modules['prefetching_enabled'] = self.enabled
        return self

    def __exit__(self, exception_type, exception_value, exception_traceback):
        # Restore the original prefetching state
        import sys
        if self.original_state is not None:
            sys.modules['prefetching_enabled'] = self.original_state
        else:
            # If there was no original state, remove the module attribute
            if 'prefetching_enabled' in sys.modules:
                del sys.modules['prefetching_enabled']","class toggled_prefetching(object):
    '''Context that toggles prefetching on or off depending on a flag.

    Added in 0.5.0.

    Parameters
    ----------
    enabled : bool
        Whether enabled is activated (``True``) or off (``False``).

    '''

    def __init__(self, enabled):
        self.enabled = enabled
        self.previous_state = None

    def __enter__(self):
        import torch
        self.previous_state = torch.is_inference_mode_enabled() if hasattr(torch, 'is_inference_mode_enabled') else False
        if hasattr(torch.utils.data, '_utils'):
            if hasattr(torch.utils.data._utils.fetch, '_HAS_NUMPY'):
                self.previous_prefetch_state = getattr(torch.utils.data._utils.fetch, '_prefetch_enabled', True)
                torch.utils.data._utils.fetch._prefetch_enabled = self.enabled
        return self

    def __exit__(self, exception_type, exception_value, exception_traceback):
        if hasattr(torch.utils.data, '_utils'):
            if hasattr(torch.utils.data._utils.fetch, '_HAS_NUMPY'):
                torch.utils.data._utils.fetch._prefetch_enabled = self.previous_prefetch_state",partial_docstr,0.7597765363128492,0.655367231638418,0.56,0.7597765363128492,0.5775597016116361,0.8431372549019608,0.7105263157894737,0.6291390728476821,0.9140809774398804,0.8434398174285889,0.8773407340049744,0.8500087857246399,0.9428577142857143,0.6147186147186146,0.48034934497816595,0.3876651982378854,0.5887445887445888,0.5175222776956123,0.6188340807174888,0.5,0.4479638009049774,0.8440814018249512,0.8459165096282959,0.8449979424476624,0.8457326889038086,0.8193402290076336,0.5355648535564854,0.4219409282700422,0.35744680851063826,0.5271966527196653,0.40276645504294806,0.48771929824561405,0.3908450704225352,0.34275618374558303,0.7767664194107056,0.8271584510803223,0.801170825958252,0.8218269348144531,0.7711734594594599,0.4647926179179383,0.4366195522293442,0.4558842527757424,0.7666666666666667,0.2,0.579405170962925,0.3611773586380304,0.4897766585470028,0.5666666666666667,0.9,0.5536006017627758,0.443890775427976,0.4538449649564606,0.5666666666666667,0.75
397348,genialis/resolwe,resolwe/process/parser.py,resolwe.process.parser.SafeParser,"class SafeParser:
    """"""Safe parser for Python processes which doesn't evaluate any code.""""""

    def __init__(self, source):
        """"""Construct process parser.

        :param source: Process source code string
        """"""
        self._source = source

    def parse(self):
        """"""Parse process.

        :return: A list of discovered process descriptors
        """"""
        root = ast.parse(self._source)
        visitor = ProcessVisitor(source=self._source)
        visitor.visit(root)
        return visitor.processes

    def base_classes(self):
        """"""Parse process.

        :return: A list of the base classes for the processes.
        """"""
        root = ast.parse(self._source)
        visitor = ProcessVisitor(source=self._source)
        visitor.visit(root)
        return visitor.base_classes","class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
    '''Construct process parser.

        :param source: Process source code string
        '''
        pass

    def parse(self):
    '''Parse process.

        :return: A list of discovered process descriptors
        '''
        pass

    def base_classes(self):
    '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        pass

",4,4,snippet_808,1.0,"class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
        '''Construct process parser.

        :param source: Process source code string
        '''
        self.source = source
        self._tree = ast.parse(source)

    def parse(self):
        '''Parse process.

        :return: A list of discovered process descriptors
        '''
        descriptors = []
        for node in ast.walk(self._tree):
            if isinstance(node, ast.ClassDef):
                name = node.name
                bases = [self._get_base_name(b) for b in node.bases]
                descriptors.append({
                    'name': name,
                    'bases': bases,
                    'lineno': node.lineno,
                })
        return descriptors

    def base_classes(self):
        '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        return [desc['bases'] for desc in self.parse()]

    def _get_base_name(self, node):
        if isinstance(node, ast.Name):
            return node.id
        if isinstance(node, ast.Attribute):
            return self._get_attribute_name(node)
        if isinstance(node, ast.Subscript):
            return self._get_base_name(node.value)
        if isinstance(node, ast.Call):
            return self._get_base_name(node.func)
        return ast.dump(node)

    def _get_attribute_name(self, node):
        parts = []
        while isinstance(node, ast.Attribute):
            parts.append(node.attr)
            node = node.value
        if isinstance(node, ast.Name):
            parts.append(node.id)
        return '.'.join(reversed(parts))","class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
        '''Construct process parser.

        :param source: Process source code string
        '''
        self.source = source
        self.tree = ast.parse(source)
        self.processes = []

    def parse(self):
        '''Parse process.

        :return: A list of discovered process descriptors
        '''
        self.processes = []
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                # Check if class inherits from a base class (likely a process)
                if node.bases:
                    process_descriptor = {
                        'name': node.name,
                        'bases': [ast.unparse(base) for base in node.bases],
                        'lineno': node.lineno,
                        'methods': []
                    }
                    
                    # Extract methods
                    for item in node.body:
                        if isinstance(item, ast.FunctionDef):
                            method_info = {
                                'name': item.name,
                                'lineno': item.lineno,
                                'args': [arg.arg for arg in item.args.args]
                            }
                            process_descriptor['methods'].append(method_info)
                    
                    self.processes.append(process_descriptor)
        
        return self.processes

    def base_classes(self):
        '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        base_classes = set()
        
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                for base in node.bases:
                    base_classes.add(ast.unparse(base))
        
        return list(base_classes)","class SafeParser:
    '''Safe parser for Python processes which doesn't evaluate any code.'''

    def __init__(self, source):
        '''Construct process parser.

        :param source: Process source code string
        '''
        self.source = source
        self.tree = None
        try:
            self.tree = ast.parse(source)
        except SyntaxError:
            self.tree = None

    def parse(self):
        '''Parse process.

        :return: A list of discovered process descriptors
        '''
        if self.tree is None:
            return []
        
        processes = []
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                process_info = {
                    'name': node.name,
                    'lineno': node.lineno,
                    'bases': [self._get_base_name(base) for base in node.bases],
                    'methods': [],
                    'attributes': []
                }
                
                for item in node.body:
                    if isinstance(item, ast.FunctionDef):
                        method_info = {
                            'name': item.name,
                            'lineno': item.lineno,
                            'args': [arg.arg for arg in item.args.args]
                        }
                        process_info['methods'].append(method_info)
                    elif isinstance(item, ast.Assign):
                        for target in item.targets:
                            if isinstance(target, ast.Name):
                                process_info['attributes'].append(target.id)
                
                processes.append(process_info)
        
        return processes

    def base_classes(self):
        '''Parse process.

        :return: A list of the base classes for the processes.
        '''
        if self.tree is None:
            return []
        
        base_classes = set()
        for node in ast.walk(self.tree):
            if isinstance(node, ast.ClassDef):
                for base in node.bases:
                    base_name = self._get_base_name(base)
                    if base_name:
                        base_classes.add(base_name)
        
        return list(base_classes)
    
    def _get_base_name(self, base_node):
        '''Extract base class name from AST node.'''
        if isinstance(base_node, ast.Name):
            return base_node.id
        elif isinstance(base_node, ast.Attribute):
            parts = []
            node = base_node
            while isinstance(node, ast.Attribute):
                parts.append(node.attr)
                node = node.value
            if isinstance(node, ast.Name):
                parts.append(node.id)
            return '.'.join(reversed(parts))
        return None",partial_docstr,0.48763250883392223,0.40569395017793597,0.3727598566308244,0.4664310954063604,0.26209792294208367,0.34972677595628415,0.2602739726027397,0.1978021978021978,0.768120527267456,0.8961884379386902,0.8272270560264587,0.8814914226531982,0.7670150173010384,0.5128205128205128,0.4354243542435424,0.3866171003717472,0.4908424908424908,0.286437570885476,0.3932926829268293,0.2782874617737003,0.2147239263803681,0.7825127840042114,0.8947778940200806,0.8348882794380188,0.8821223378181458,0.7853556818181822,0.3814713896457766,0.3178082191780822,0.2865013774104683,0.3705722070844687,0.1856457038576293,0.2509727626459144,0.18128654970760233,0.140625,0.7446741461753845,0.8976362943649292,0.8140318989753723,0.8795692324638367,0.7404843356643361,0.4910962356655823,0.2444300807033504,0.4804212106606217,0.5098039215686274,0.7297297297297297,0.4809561551178575,0.2308967855394781,0.4804212106606217,0.5098039215686274,0.7027027027027027,0.4336855808946388,0.1647609645342557,0.4804212106606217,0.5490196078431373,0.5405405405405406
466215,hit9/rux,hit9_rux/rux/models.py,rux.models.Author,"class Author(object):
    """"""The blog's owner, only one
    attributes
      name      unicode     author's name
      email     unicode     author's email
    """"""

    def __init__(self, name="""", email=""""):
        self.name = name
        self.email = email

    @property
    def gravatar_id(self):
        """"""it's md5(author.email), author's gravatar_id""""""
        return md5(self.email).hexdigest()","class Author(object):
    '''The blog's owner, only one
    attributes
      name      unicode     author's name
      email     unicode     author's email
    '''

    def __init__(self, name="""", email=""""):
        pass

    @property
    def gravatar_id(self):
    '''it's md5(author.email), author's gravatar_id'''
        pass

",4,2,snippet_558,0.75,"class Author(object):
    '''The blog's owner, only one
    attributes
      name      unicode     author's name
      email     unicode     author's email
    '''

    def __init__(self, name="""", email=""""):
        self.name = name
        self.email = email

    @property
    def gravatar_id(self):
        '''it's md5(author.email), author's gravatar_id'''
        e = (self.email or """").strip().lower().encode('utf-8')
        return hashlib.md5(e).hexdigest()","class Author(object):
    '''The blog's owner, only one
    attributes
      name      unicode     author's name
      email     unicode     author's email
    '''

    def __init__(self, name="""", email=""""):
        self.name = name
        self.email = email

    @property
    def gravatar_id(self):
        '''it's md5(author.email), author's gravatar_id'''
        return hashlib.md5(self.email.encode('utf-8')).hexdigest()","class Author(object):
    '''The blog's owner, only one
    attributes
      name      unicode     author's name
      email     unicode     author's email
    '''

    def __init__(self, name="""", email=""""):
        self.name = name
        self.email = email

    @property
    def gravatar_id(self):
        '''it's md5(author.email), author's gravatar_id'''
        return hashlib.md5(self.email.encode('utf-8')).hexdigest()",partial_docstr,0.9174311926605504,0.8411214953271028,0.819047619047619,0.8807339449541285,0.7011149912669954,0.7706422018348624,0.7037037037037037,0.6355140186915887,0.9382059574127197,0.9887194633483887,0.9628006219863892,0.9834245443344116,0.8838962921348315,0.9615384615384615,0.9215686274509803,0.9,0.9615384615384615,0.7820868384610417,0.8817204301075269,0.8152173913043478,0.7582417582417582,0.962098240852356,0.9930645823478699,0.9773362278938293,0.9898784756660461,0.9537041666666668,0.9615384615384615,0.9215686274509803,0.9,0.9615384615384615,0.7820868384610417,0.8817204301075269,0.8152173913043478,0.7582417582417582,0.962098240852356,0.9930645823478699,0.9773362278938293,0.9898784756660461,0.9537041666666668,0.7387682522890744,0.6180504353140722,0.7163329186698114,0.6206896551724138,1.0,0.7611834476994603,0.7077112169556163,0.7163329186698114,0.6206896551724138,1.0,0.7611834476994603,0.7077112169556163,0.7163329186698114,0.6206896551724138,1.0
590880,nameko/nameko,nameko_nameko/nameko/utils/concurrency/__init__.py,nameko.utils.concurrency.SpawningProxy,"class SpawningProxy(object):
    def __init__(self, items, abort_on_error=False):
        """""" Wraps an iterable set of items such that a call on the returned
        SpawningProxy instance will spawn a call in a
        :class:`~eventlet.greenthread.GreenThread` for each item.

        Returns when every spawned thread has completed.

        :param items: Iterable item set to process
        :param abort_on_error: If True, any exceptions raised on an individual
            item call will cause all peer item call threads to be killed, and
            for the exception to be propagated to the caller immediately.
        """"""
        self._items = items
        self.abort_on_error = abort_on_error

    def __getattr__(self, name):

        def spawning_method(*args, **kwargs):
            items = self._items
            if items:
                pool = eventlet.GreenPool(len(items))

                def call(item):
                    return getattr(item, name)(*args, **kwargs)

                if self.abort_on_error:
                    return list(fail_fast_imap(pool, call, self._items))
                else:
                    return list(pool.imap(call, self._items))
        return spawning_method","class SpawningProxy(object):


    def __init__(self, items, abort_on_error=False):
    ''' Wraps an iterable set of items such that a call on the returned
        SpawningProxy instance will spawn a call in a
        :class:`~eventlet.greenthread.GreenThread` for each item.

        Returns when every spawned thread has completed.

        :param items: Iterable item set to process
        :param abort_on_error: If True, any exceptions raised on an individual
            item call will cause all peer item call threads to be killed, and
            for the exception to be propagated to the caller immediately.
        '''
        pass

    def __getattr__(self, name):
        pass

        def spawning_method(*args, **kwargs):
                pass

                def call(item):
                                pass

",5,1,snippet_606,0.6666666666666666,"class SpawningProxy(object):
    def __init__(self, items, abort_on_error=False):
        self._items = list(items)
        self._abort_on_error = abort_on_error

    def __getattr__(self, name):
        def spawning_method(*args, _name=name, **kwargs):
            threads = []
            results = [None] * len(self._items)

            def call(idx, item):
                try:
                    results[idx] = getattr(item, _name)(*args, **kwargs)
                except Exception:
                    if self._abort_on_error:
                        raise
                    # swallow if not abort_on_error

            for idx, item in enumerate(self._items):
                gt = eventlet.spawn(call, idx, item)
                threads.append(gt)

            if self._abort_on_error:
                for gt in threads:
                    try:
                        gt.wait()
                    except Exception:
                        for t in threads:
                            if t is not gt:
                                try:
                                    t.kill()
                                except Exception:
                                    pass
                        raise
            else:
                for gt in threads:
                    try:
                        gt.wait()
                    except Exception:
                        pass

            return results

        return spawning_method","class SpawningProxy(object):

    def __init__(self, items, abort_on_error=False):
        ''' Wraps an iterable set of items such that a call on the returned
            SpawningProxy instance will spawn a call in a
            :class:`~eventlet.greenthread.GreenThread` for each item.

            Returns when every spawned thread has completed.

            :param items: Iterable item set to process
            :param abort_on_error: If True, any exceptions raised on an individual
                item call will cause all peer item call threads to be killed, and
                for the exception to be propagated to the caller immediately.
        '''
        self.items = list(items)
        self.abort_on_error = abort_on_error

    def __getattr__(self, name):
        def spawning_method(*args, **kwargs):
            def call(item):
                method = getattr(item, name)
                return method(*args, **kwargs)
            
            threads = []
            for item in self.items:
                thread = greenthread.spawn(call, item)
                threads.append(thread)
            
            if self.abort_on_error:
                # Wait for any thread to complete or raise an exception
                try:
                    results = []
                    for thread in threads:
                        results.append(thread.wait())
                    return results
                except Exception:
                    # Kill all remaining threads
                    for thread in threads:
                        thread.kill()
                    raise
            else:
                # Wait for all threads to complete
                results = []
                for thread in threads:
                    results.append(thread.wait())
                return results
        
        return spawning_method","class SpawningProxy(object):

    def __init__(self, items, abort_on_error=False):
        ''' Wraps an iterable set of items such that a call on the returned
            SpawningProxy instance will spawn a call in a
            :class:`~eventlet.greenthread.GreenThread` for each item.

            Returns when every spawned thread has completed.

            :param items: Iterable item set to process
            :param abort_on_error: If True, any exceptions raised on an individual
                item call will cause all peer item call threads to be killed, and
                for the exception to be propagated to the caller immediately.
            '''
        self.items = items
        self.abort_on_error = abort_on_error

    def __getattr__(self, name):
        def spawning_method(*args, **kwargs):
            threads = []
            results = []
            
            def call(item):
                method = getattr(item, name)
                return method(*args, **kwargs)
            
            for item in self.items:
                thread = eventlet.spawn(call, item)
                threads.append(thread)
            
            if self.abort_on_error:
                for thread in threads:
                    results.append(thread.wait())
            else:
                for thread in threads:
                    try:
                        results.append(thread.wait())
                    except Exception:
                        results.append(None)
            
            return results
        
        return spawning_method",partial_docstr,0.5107913669064749,0.30434782608695654,0.23357664233576642,0.37410071942446044,0.47544965503469006,0.6679841897233202,0.46825396825396826,0.38247011952191234,0.7991743683815002,0.7805086970329285,0.7897312641143799,0.7823359370231628,0.8017563684210526,0.7594202898550725,0.6822157434402332,0.6392961876832846,0.7304347826086957,0.6384641745963308,0.7192429022082019,0.629746835443038,0.5746031746031746,0.89543616771698,0.9382550120353699,0.9163457155227661,0.9337897300720215,0.8243530538922155,0.8201892744479494,0.7492063492063492,0.70926517571885,0.7886435331230285,0.7297860164062293,0.8107142857142857,0.7204301075268817,0.6654676258992805,0.9227906465530396,0.9477570056915283,0.9351071715354919,0.945199728012085,0.8454761589403973,0.2898920160546271,0.1070733131381394,0.1239233225089403,0.4285714285714285,0.5,0.5889332277124573,0.5135519903938356,0.7477364760115491,0.4444444444444444,0.65,0.6230387120517198,0.650301946344553,0.7565354415448658,0.4603174603174603,0.625
603121,nteract/papermill,nteract_papermill/papermill/s3.py,papermill.s3.Bucket,"class Bucket:
    """"""
    Represents a Bucket of storage on S3

    Parameters
    ----------
    name : string
        name of the bucket
    service : string, optional (Default is None)
        name of a service resource, such as SQS, EC2, etc.

    """"""

    def __init__(self, name, service=None):
        self.name = name
        self.service = service

    def list(self, prefix='', delimiter=None):
        """"""Limits a list of Bucket's objects based on prefix and delimiter.""""""
        return self.service._list(bucket=self.name, prefix=prefix, delimiter=delimiter, objects=True)","class Bucket:
    '''
    Represents a Bucket of storage on S3

    Parameters
    ----------
    name : string
        name of the bucket
    service : string, optional (Default is None)
        name of a service resource, such as SQS, EC2, etc.

    '''

    def __init__(self, name, service=None):
        pass

    def list(self, prefix='', delimiter=None):
    '''Limits a list of Bucket's objects based on prefix and delimiter.'''
        pass

",3,2,snippet_484,1.0,"class Bucket:
    '''
    Represents a Bucket of storage on S3

    Parameters
    ----------
    name : string
        name of the bucket
    service : string or boto3 resource, optional (Default is None)
        name of a service resource, such as 's3', or a boto3 resource instance.
    '''

    def __init__(self, name, service=None):
        if service is None:
            self._resource = boto3.resource('s3')
        elif isinstance(service, str):
            self._resource = boto3.resource(service)
        else:
            self._resource = service
        self.name = name
        # client for list operations
        self._client = self._resource.meta.client

    def list(self, prefix='', delimiter=None):
        '''Limits a list of Bucket's objects based on prefix and delimiter.'''
        params = {'Bucket': self.name, 'Prefix': prefix}
        if delimiter is not None:
            params['Delimiter'] = delimiter
        paginator = self._client.get_paginator('list_objects_v2')
        page_iterator = paginator.paginate(**params)

        results = []
        for page in page_iterator:
            for obj in page.get('Contents', []):
                results.append(obj['Key'])
        return results","class Bucket:
    '''
    Represents a Bucket of storage on S3

    Parameters
    ----------
    name : string
        name of the bucket
    service : string, optional (Default is None)
        name of a service resource, such as SQS, EC2, etc.

    '''

    def __init__(self, name, service=None):
        self.name = name
        self.service = service
        self.objects = []

    def list(self, prefix='', delimiter=None):
        '''Limits a list of Bucket's objects based on prefix and delimiter.'''
        filtered_objects = []
        
        for obj in self.objects:
            # Check if object name starts with the prefix
            if obj.startswith(prefix):
                # If delimiter is specified, check for delimiter behavior
                if delimiter:
                    # Find the first occurrence of delimiter after the prefix
                    prefix_end = len(prefix)
                    delimiter_pos = obj.find(delimiter, prefix_end)
                    
                    # If delimiter found, include the prefix + up to and including delimiter
                    # Otherwise, include the whole object name if it matches prefix
                    if delimiter_pos != -1:
                        filtered_objects.append(obj[:delimiter_pos + 1])
                    else:
                        filtered_objects.append(obj)
                else:
                    # No delimiter, just check prefix
                    filtered_objects.append(obj)
        
        # Remove duplicates while preserving order
        seen = set()
        unique_objects = []
        for obj in filtered_objects:
            if obj not in seen:
                seen.add(obj)
                unique_objects.append(obj)
        
        return unique_objects","class Bucket:
    '''
    Represents a Bucket of storage on S3

    Parameters
    ----------
    name : string
        name of the bucket
    service : string, optional (Default is None)
        name of a service resource, such as SQS, EC2, etc.

    '''

    def __init__(self, name, service=None):
        self.name = name
        self.service = service

    def list(self, prefix='', delimiter=None):
        '''Limits a list of Bucket's objects based on prefix and delimiter.'''
        import boto3
        
        s3_client = boto3.client('s3')
        
        kwargs = {
            'Bucket': self.name,
            'Prefix': prefix
        }
        
        if delimiter is not None:
            kwargs['Delimiter'] = delimiter
        
        objects = []
        paginator = s3_client.get_paginator('list_objects_v2')
        
        for page in paginator.paginate(**kwargs):
            if 'Contents' in page:
                objects.extend(page['Contents'])
        
        return objects",partial_docstr,0.6543778801843317,0.5302325581395348,0.46009389671361495,0.5990783410138248,0.3653528185110525,0.4578313253012048,0.35080645161290325,0.30364372469635625,0.7799357175827026,0.9079607129096985,0.8390929102897644,0.8932973742485046,0.7696358115183246,0.5378787878787878,0.47328244274809156,0.4461538461538462,0.5227272727272727,0.3227781393388687,0.3836065573770492,0.3125,0.28052805280528054,0.7638221383094788,0.9454028606414795,0.8449673652648926,0.9234499931335449,0.7862766470588236,0.7868852459016393,0.7403314917127072,0.7150837988826817,0.7650273224043717,0.540090403684769,0.6141304347826086,0.5245901639344263,0.489010989010989,0.8267440795898438,0.9603396058082581,0.8885483145713806,0.9450680613517761,0.8018667832167831,0.507059672593192,0.3308592361827812,0.6346835294250962,0.5172413793103449,0.5454545454545454,0.5474168883584603,0.2888598231289411,0.7816854732516082,0.4827586206896552,0.6363636363636364,0.6882617533544564,0.5310924863858312,0.8065940254645964,0.5517241379310345,0.8636363636363636
525928,juju/charm-helpers,juju_charm-helpers/charmhelpers/fetch/__init__.py,charmhelpers.fetch.BaseFetchHandler,"class BaseFetchHandler(object):

    """"""Base class for FetchHandler implementations in fetch plugins""""""

    def can_handle(self, source):
        """"""Returns True if the source can be handled. Otherwise returns
        a string explaining why it cannot""""""
        return ""Wrong source type""

    def install(self, source):
        """"""Try to download and unpack the source. Return the path to the
        unpacked files or raise UnhandledSource.""""""
        raise UnhandledSource(""Wrong source type {}"".format(source))

    def parse_url(self, url):
        return urlparse(url)

    def base_url(self, url):
        """"""Return url without querystring or fragment""""""
        parts = list(self.parse_url(url))
        parts[4:] = ['' for i in parts[4:]]
        return urlunparse(parts)","class BaseFetchHandler(object):
    '''Base class for FetchHandler implementations in fetch plugins'''

    def can_handle(self, source):
    '''Returns True if the source can be handled. Otherwise returns
        a string explaining why it cannot'''
        pass

    def install(self, source):
    '''Try to download and unpack the source. Return the path to the
        unpacked files or raise UnhandledSource.'''
        pass

    def parse_url(self, url):
        pass

    def base_url(self, url):
    '''Return url without querystring or fragment'''
        pass

",5,4,snippet_65,0.75,"class BaseFetchHandler(object):
    '''Base class for FetchHandler implementations in fetch plugins'''

    def can_handle(self, source):
        '''Returns True if the source can be handled. Otherwise returns
        a string explaining why it cannot'''
        return False, 'can_handle not implemented for source {}'.format(source)

    def install(self, source):
        '''Try to download and unpack the source. Return the path to the
        unpacked files or raise UnhandledSource.'''
        raise UnhandledSource('install not implemented for source {}'.format(source))

    def parse_url(self, url):
        return urllib.parse.urlparse(url)

    def base_url(self, url):
        '''Return url without querystring or fragment'''
        parts = self.parse_url(url)
        return urllib.parse.urlunparse((
            parts.scheme,
            parts.netloc,
            parts.path,
            parts.params,
            '',
            ''
        ))","class BaseFetchHandler(object):
    '''Base class for FetchHandler implementations in fetch plugins'''

    def can_handle(self, source):
        '''Returns True if the source can be handled. Otherwise returns
        a string explaining why it cannot'''
        pass

    def install(self, source):
        '''Try to download and unpack the source. Return the path to the
        unpacked files or raise UnhandledSource.'''
        pass

    def parse_url(self, url):
        pass

    def base_url(self, url):
        '''Return url without querystring or fragment'''
        pass","class BaseFetchHandler(object):
    '''Base class for FetchHandler implementations in fetch plugins'''

    def can_handle(self, source):
        '''Returns True if the source can be handled. Otherwise returns
        a string explaining why it cannot'''
        return ""Base handler cannot handle any sources""

    def install(self, source):
        '''Try to download and unpack the source. Return the path to the
        unpacked files or raise UnhandledSource.'''
        raise NotImplementedError(""Subclasses must implement install method"")

    def parse_url(self, url):
        from urllib.parse import urlparse
        return urlparse(url)

    def base_url(self, url):
        '''Return url without querystring or fragment'''
        from urllib.parse import urlparse, urlunparse
        parsed = urlparse(url)
        return urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', '', ''))",partial_docstr,0.861244019138756,0.7536231884057972,0.702439024390244,0.8325358851674641,0.585616782105473,0.7150837988826816,0.5842696629213483,0.4971751412429379,0.9250047206878662,0.9411934614181519,0.9330288767814636,0.9395491480827332,0.877779,0.8023255813953489,0.7647058823529411,0.7261904761904762,0.8023255813953489,0.35057719527996195,0.88,0.797979797979798,0.7142857142857143,0.969470739364624,0.9096536636352539,0.9386101365089417,0.9153012037277222,0.8239011320754717,0.7536231884057971,0.7024390243902439,0.6502463054187193,0.7536231884057971,0.5293003492981948,0.7134146341463414,0.5828220858895705,0.4876543209876543,0.8992831707000732,0.9300556182861328,0.9144105315208435,0.9268839955329895,0.8541681250000001,0.5152928394352957,0.4653116253744994,0.5126875853647493,0.4468085106382978,0.6363636363636364,0.3696247572208766,0.4530395095558982,0.4703337939891171,0.1914893617021276,0.3636363636363636,0.4930786486004872,0.4418469206503978,0.5140266679488433,0.425531914893617,0.5909090909090909
604512,numenta/nupic,numenta_nupic/src/nupic/data/field_meta.py,nupic.data.field_meta.FieldMetaType,"class FieldMetaType(object):
  """"""
  Public values for the field data types. Valid types are:

    - ``string``
    - ``datetime``
    - ``int``
    - ``float``
    - ``bool``
    - ``list``
    - ``sdr``
  """"""
  string = 'string'
  datetime = 'datetime'
  integer = 'int'
  float = 'float'
  boolean = 'bool'
  list = 'list'
  sdr = 'sdr'

  _ALL = (string, datetime, integer, float, boolean, list, sdr)


  @classmethod
  def isValid(cls, fieldDataType):
    """"""Check a candidate value whether it's one of the valid field data types

    :param fieldDataType: (string) candidate field data type
    :returns: True if the candidate value is a legitimate field data type value;
              False if not
    """"""
    return fieldDataType in cls._ALL","class FieldMetaType(object):
    '''
  Public values for the field data types. Valid types are:

    - ``string``
    - ``datetime``
    - ``int``
    - ``float``
    - ``bool``
    - ``list``
    - ``sdr``
  '''

  @classmethod
  def isValid(cls, fieldDataType):
    '''Check a candidate value whether it's one of the valid field data types

    :param fieldDataType: (string) candidate field data type
    :returns: True if the candidate value is a legitimate field data type value;
              False if not
    '''
    pass

",3,2,snippet_455,0.6666666666666666,"class FieldMetaType(object):
    '''
  Public values for the field data types. Valid types are:

    - ``string``
    - ``datetime``
    - ``int``
    - ``float``
    - ``bool``
    - ``list``
    - ``sdr``
  '''

    STRING = 'string'
    DATETIME = 'datetime'
    INT = 'int'
    FLOAT = 'float'
    BOOL = 'bool'
    LIST = 'list'
    SDR = 'sdr'

    _VALID_TYPES = {
        STRING,
        DATETIME,
        INT,
        FLOAT,
        BOOL,
        LIST,
        SDR,
    }

    @classmethod
    def isValid(cls, fieldDataType):
        '''Check a candidate value whether it's one of the valid field data types

        :param fieldDataType: (string) candidate field data type
        :returns: True if the candidate value is a legitimate field data type value;
                  False if not
        '''
        return fieldDataType in cls._VALID_TYPES","class FieldMetaType(object):
    '''
  Public values for the field data types. Valid types are:

    - ``string``
    - ``datetime``
    - ``int``
    - ``float``
    - ``bool``
    - ``list``
    - ``sdr``
  '''

    STRING = 'string'
    DATETIME = 'datetime'
    INT = 'int'
    FLOAT = 'float'
    BOOL = 'bool'
    LIST = 'list'
    SDR = 'sdr'

    _VALID_TYPES = {STRING, DATETIME, INT, FLOAT, BOOL, LIST, SDR}

    @classmethod
    def isValid(cls, fieldDataType):
        '''Check a candidate value whether it's one of the valid field data types

        :param fieldDataType: (string) candidate field data type
        :returns: True if the candidate value is a legitimate field data type value;
                  False if not
        '''
        return fieldDataType in cls._VALID_TYPES","class FieldMetaType(object):
    '''
  Public values for the field data types. Valid types are:

    - ``string``
    - ``datetime``
    - ``int``
    - ``float``
    - ``bool``
    - ``list``
    - ``sdr``
  '''

    string = ""string""
    datetime = ""datetime""
    integer = ""int""
    float = ""float""
    boolean = ""bool""
    list = ""list""
    sdr = ""sdr""

    @classmethod
    def isValid(cls, fieldDataType):
        '''Check a candidate value whether it's one of the valid field data types

        :param fieldDataType: (string) candidate field data type
        :returns: True if the candidate value is a legitimate field data type value;
                  False if not
        '''
        valid_types = {""string"", ""datetime"", ""int"", ""float"", ""bool"", ""list"", ""sdr""}
        return fieldDataType in valid_types",partial_docstr,0.9222222222222223,0.8651685393258427,0.8181818181818181,0.9222222222222223,0.7231199324553114,0.8392857142857143,0.7305389221556886,0.6626506024096386,0.9090548157691956,0.9454790353775024,0.9269091486930847,0.9417057633399963,0.9963370329670329,0.9222222222222223,0.8651685393258427,0.8181818181818181,0.9222222222222223,0.723002639175801,0.844311377245509,0.7349397590361446,0.6666666666666666,0.9222449660301208,0.956771731376648,0.9391911625862122,0.9532032012939453,0.9963370329670329,0.9385474860335196,0.8926553672316383,0.8457142857142856,0.88268156424581,0.6595426489754356,0.8167539267015707,0.6263157894736842,0.5608465608465608,0.9723175764083862,0.9756321907043457,0.9739720225334167,0.9752997756004333,0.8636377272727271,0.7801396966189056,0.6310800666602556,0.6561453864820332,0.8333333333333334,1.0,0.7832488390445161,0.6435166363626977,0.6561453864820332,0.8333333333333334,1.0,0.6397303205259975,0.6435166363626977,0.6561453864820332,0.6666666666666666,0.5925925925925926
244342,apple/turicreate,src/python/turicreate/extensions.py,turicreate.extensions._ExtMetaPath,"class _ExtMetaPath(object):
    """"""
    This is a magic metapath searcher. To understand how this works,
    See the PEP 302 document. Essentially this class is inserted into
    the sys.meta_path list. This class must implement find_module()
    and load_module(). After which, this class is called first when any
    particular module import was requested, allowing this to essentially
    'override' the default import behaviors.
    """"""

    def find_module(self, fullname, submodule_path=None):
        """"""
        We have to see if fullname refers to a module we can import.
        Some care is needed here because:

        import xxx   # tries to load xxx.so from any of the python import paths
        import aaa.bbb.xxx # tries to load aaa/bbb/xxx.so from any of the python import paths
        """"""
        # first see if we have this particular so has been loaded by
        # turicreate's extension library before
        ret = self.try_find_module(fullname, submodule_path)
        if ret is not None:
            return ret
        # nope. has not been loaded before
        # lets try to find a "".so"" or a "".dylib"" if any of the python
        # locations
        import sys
        import os

        # This drops the last ""."" So if I am importing aaa.bbb.xxx
        # module_subpath is aaa.bbb
        module_subpath = ""."".join(fullname.split(""."")[:-1])
        for path in sys.path:
            # joins the path to aaa/bbb/xxx
            pathname = os.path.join(path, os.sep.join(fullname.split(""."")))
            # try to laod the "".so"" extension
            try:
                if os.path.exists(pathname + "".so""):
                    ext_import(pathname + "".so"", module_subpath)
                    break
            except:
                pass

            # try to laod the "".dylib"" extension
            try:
                if os.path.exists(pathname + "".dylib""):
                    ext_import(pathname + "".dylib"", module_subpath)
                    break
            except:
                pass
        ret = self.try_find_module(fullname, submodule_path)
        if ret is not None:
            return ret

    def try_find_module(self, fullname, submodule_path=None):
        # check if the so has been loaded before
        # try to find the module inside of tc.extensions
        # Essentially: if fullname == aaa.bbb.xxx
        # Then we try to see if we have loaded tc.extensions.aaa.bbb.xxx
        mod = _thismodule
        modpath = fullname.split(""."")
        # walk the module tree
        mod = _thismodule
        for path in modpath:
            try:
                mod = getattr(mod, path)
            except:
                return None
        return self

    def load_module(self, fullname):
        import sys

        # we may have already been loaded
        if fullname in sys.modules:
            return sys.modules[fullname]
        # try to find the module inside of tc.extensions
        # Essentially: if fullname == aaa.bbb.xxx
        # Then we try to look for tc.extensions.aaa.bbb.xxx
        mod = _thismodule
        modpath = fullname.split(""."")
        for path in modpath:
            mod = getattr(mod, path)

        # Inject the module into aaa.bbb.xxx
        mod.__loader__ = self
        mod.__package__ = fullname
        mod.__name__ = fullname
        sys.modules[fullname] = mod
        return mod","class _ExtMetaPath(object):
    '''
    This is a magic metapath searcher. To understand how this works,
    See the PEP 302 document. Essentially this class is inserted into
    the sys.meta_path list. This class must implement find_module()
    and load_module(). After which, this class is called first when any
    particular module import was requested, allowing this to essentially
    'override' the default import behaviors.
    '''

    def find_module(self, fullname, submodule_path=None):
    '''
        We have to see if fullname refers to a module we can import.
        Some care is needed here because:

        import xxx   # tries to load xxx.so from any of the python import paths
        import aaa.bbb.xxx # tries to load aaa/bbb/xxx.so from any of the python import paths
        '''
        pass

    def try_find_module(self, fullname, submodule_path=None):
        pass

    def load_module(self, fullname):
        pass

",4,2,snippet_51,0.2222222222222222,"class _ExtMetaPath(object):
    def __init__(self):
        self._path_map = {}

    def find_module(self, fullname, submodule_path=None):
        path = self.try_find_module(fullname, submodule_path)
        if path:
            self._path_map[fullname] = path
            return self
        return None

    def try_find_module(self, fullname, submodule_path=None):
        name = fullname.rpartition('.')[-1]
        exts = importlib.machinery.EXTENSION_SUFFIXES
        search_paths = submodule_path if submodule_path is not None else sys.path
        for entry in search_paths:
            for ext in exts:
                fn = os.path.join(entry, name + ext)
                if os.path.isfile(fn):
                    return fn
        return None

    def load_module(self, fullname):
        if fullname in sys.modules:
            return sys.modules[fullname]
        path = self._path_map.get(fullname)
        if path is None:
            raise ImportError(""Cannot load module %s"" % fullname)
        loader = importlib.machinery.ExtensionFileLoader(fullname, path)
        spec = importlib.machinery.ModuleSpec(fullname, loader, origin=path)
        module = importlib.util.module_from_spec(spec)
        sys.modules[fullname] = module
        loader.exec_module(module)
        return module","class _ExtMetaPath(object):
    '''
    This is a magic metapath searcher. To understand how this works,
    See the PEP 302 document. Essentially this class is inserted into
    the sys.meta_path list. This class must implement find_module()
    and load_module(). After which, this class is called first when any
    particular module import was requested, allowing this to essentially
    'override' the default import behaviors.
    '''

    def find_module(self, fullname, submodule_path=None):
        '''
        We have to see if fullname refers to a module we can import.
        Some care is needed here because:

        import xxx   # tries to load xxx.so from any of the python import paths
        import aaa.bbb.xxx # tries to load aaa/bbb/xxx.so from any of the python import paths
        '''
        return self.try_find_module(fullname, submodule_path)

    def try_find_module(self, fullname, submodule_path=None):
        # Convert module name to file path format
        module_path = fullname.replace('.', os.sep)
        
        # Determine search paths
        if submodule_path is not None:
            search_paths = submodule_path
        else:
            search_paths = sys.path
        
        # Look for .so files (compiled extensions)
        for path in search_paths:
            # Check for direct module.so
            so_file = os.path.join(path, module_path + '.so')
            if os.path.exists(so_file):
                return self
            
            # Check for module/__init__.so (package format)
            init_so_file = os.path.join(path, module_path, '__init__.so')
            if os.path.exists(init_so_file):
                return self
        
        return None

    def load_module(self, fullname):
        # Check if module is already loaded
        if fullname in sys.modules:
            return sys.modules[fullname]
        
        # Convert module name to file path format
        module_path = fullname.replace('.', os.sep)
        
        # Try to find the module file
        module_file = None
        is_package = False
        
        for path in sys.path:
            # Check for direct module.so
            so_file = os.path.join(path, module_path + '.so')
            if os.path.exists(so_file):
                module_file = so_file
                break
            
            # Check for module/__init__.so (package format)
            init_so_file = os.path.join(path, module_path, '__init__.so')
            if os.path.exists(init_so_file):
                module_file = init_so_file
                is_package = True
                break
        
        if module_file is None:
            raise ImportError(f""No module named '{fullname}'"")
        
        # Create module spec and module
        spec = importlib.util.spec_from_file_location(fullname, module_file)
        if spec is None:
            raise ImportError(f""Cannot load spec for module '{fullname}'"")
        
        module = importlib.util.module_from_spec(spec)
        
        # Set module attributes
        module.__file__ = module_file
        module.__loader__ = self
        if is_package:
            module.__path__ = [os.path.dirname(module_file)]
            module.__package__ = fullname
        else:
            module.__package__ = fullname.rpartition('.')[0] if '.' in fullname else None
        
        # Add to sys.modules before executing
        sys.modules[fullname] = module
        
        # Execute the module
        try:
            spec.loader.exec_module(module)
        except Exception:
            # If execution fails, remove from sys.modules
            del sys.modules[fullname]
            raise
        
        return module","class _ExtMetaPath(object):
    '''
    This is a magic metapath searcher. To understand how this works,
    See the PEP 302 document. Essentially this class is inserted into
    the sys.meta_path list. This class must implement find_module()
    and load_module(). After which, this class is called first when any
    particular module import was requested, allowing this to essentially
    'override' the default import behaviors.
    '''

    def find_module(self, fullname, submodule_path=None):
        '''
        We have to see if fullname refers to a module we can import.
        Some care is needed here because:

        import xxx   # tries to load xxx.so from any of the python import paths
        import aaa.bbb.xxx # tries to load aaa/bbb/xxx.so from any of the python import paths
        '''
        result = self.try_find_module(fullname, submodule_path)
        if result:
            return self
        return None

    def try_find_module(self, fullname, submodule_path=None):
        if fullname in sys.modules:
            return sys.modules[fullname]
        
        # Convert module name to file path
        parts = fullname.split('.')
        filename = parts[-1] + '.so'
        
        # Search in sys.path
        search_paths = submodule_path if submodule_path else sys.path
        
        for path in search_paths:
            if not path:
                continue
                
            # For nested modules like aaa.bbb.xxx, construct the full path
            if len(parts) > 1:
                nested_path = os.path.join(path, *parts[:-1])
                full_path = os.path.join(nested_path, filename)
            else:
                full_path = os.path.join(path, filename)
            
            if os.path.exists(full_path):
                return full_path
        
        return None

    def load_module(self, fullname):
        if fullname in sys.modules:
            return sys.modules[fullname]
        
        module_path = self.try_find_module(fullname)
        if not module_path:
            raise ImportError(f""No module named '{fullname}'"")
        
        # Create module spec and load
        spec = importlib.util.spec_from_file_location(fullname, module_path)
        if spec is None:
            raise ImportError(f""Could not load spec for '{fullname}'"")
        
        module = importlib.util.module_from_spec(spec)
        sys.modules[fullname] = module
        
        try:
            spec.loader.exec_module(module)
        except Exception:
            if fullname in sys.modules:
                del sys.modules[fullname]
            raise
        
        return module",partial_docstr,0.36610169491525424,0.17346938775510204,0.11945392491467577,0.22372881355932203,0.11166450148547989,0.8068965517241379,0.44982698961937717,0.3194444444444444,0.8260982632637024,0.7273047566413879,0.7735599875450134,0.7361078262329102,0.7497522522522523,0.5829596412556054,0.40898876404494383,0.3536036036036036,0.4349775784753363,0.43671146558524154,0.6199494949494949,0.4020227560050569,0.3341772151898734,0.8762083649635315,0.8790930509567261,0.8776482939720154,0.8788037896156311,0.7512102173913041,0.6240208877284595,0.4554973821989529,0.40419947506561676,0.49608355091383816,0.4184830412624856,0.7819548872180451,0.5574387947269304,0.47547169811320755,0.8982508182525635,0.8646960854530334,0.8811541795730591,0.8679382801055908,0.7497522522522526,0.1972992186978007,0.0107365084579402,0.0485268851802694,0.4390243902439024,0.2909090909090909,0.4339519218507998,0.3509675449843709,0.366547459491999,0.5182926829268293,0.5,0.412079874801567,0.2933458220863414,0.3400069365434299,0.4695121951219512,0.5454545454545454
779968,tamasgal/km3pipe,tamasgal_km3pipe/src/km3pipe/io/daq.py,km3pipe.io.daq.DAQHeader,"class DAQHeader(object):
    """"""Wrapper for the JDAQHeader binary format.

    Parameters
    ----------
    byte_data : bytes (optional)
        The binary file, where the file pointer is at the beginning of the header.
    file_obj : file (optional)
        The binary file, where the file pointer is at the beginning of the header.

    Attributes
    ----------
    size : int
        The size of the original DAQ byte representation.

    """"""

    size = 20

    def __init__(self, byte_data=None, file_obj=None):
        self.run = None
        self.time_slice = None
        self.time_stamp = None
        self.wr_status = None
        if byte_data:
            self._parse_byte_data(byte_data)
        if file_obj:
            self._parse_file(file_obj)

    def _parse_byte_data(self, byte_data):
        """"""Extract the values from byte string.""""""
        chunks = unpack(""<iiiii"", byte_data[: self.size])
        det_id, run, time_slice, time_stamp, ticks = chunks
        self.det_id = det_id
        self.run = run
        self.time_slice = time_slice
        # most significant bit is the WR status
        self.wr_status = time_stamp & 0x80000000
        # masking the most significant bit, which is the WR status
        self.time_stamp = time_stamp & 0x7FFFFFFF
        self.ticks = ticks

    def _parse_file(self, file_obj):
        """"""Directly read from file handler.

        Note:
          This will move the file pointer.

        """"""
        byte_data = file_obj.read(self.size)
        self._parse_byte_data(byte_data)

    def __repr__(self):
        description = ""Run: {0}\nTime slice: {1}\nTime stamp: {2} ({3})"".format(
            self.run, self.time_slice, self.time_stamp, self.ticks
        )
        return description","class DAQHeader(object):
    '''Wrapper for the JDAQHeader binary format.

    Parameters
    ----------
    byte_data : bytes (optional)
        The binary file, where the file pointer is at the beginning of the header.
    file_obj : file (optional)
        The binary file, where the file pointer is at the beginning of the header.

    Attributes
    ----------
    size : int
        The size of the original DAQ byte representation.

    '''

    def __init__(self, byte_data=None, file_obj=None):
        pass

    def _parse_byte_data(self, byte_data):
    '''Extract the values from byte string.'''
        pass

    def _parse_file(self, file_obj):
    '''Directly read from file handler.

        Note:
          This will move the file pointer.

        '''
        pass

    def __repr__(self):
        pass

",5,3,snippet_458,1.0,"class DAQHeader(object):
    '''Wrapper for the JDAQHeader binary format.

    Parameters
    ----------
    byte_data : bytes (optional)
        The binary file, where the file pointer is at the beginning of the header.
    file_obj : file (optional)
        The binary file, where the file pointer is at the beginning of the header.

    Attributes
    ----------
    size : int
        The size of the original DAQ byte representation.
    '''

    def __init__(self, byte_data=None, file_obj=None):
        if (byte_data is None and file_obj is None) or (byte_data is not None and file_obj is not None):
            raise ValueError(""Provide exactly one of byte_data or file_obj"")
        if byte_data is not None:
            self._parse_byte_data(byte_data)
        else:
            self._parse_file(file_obj)

    def _parse_byte_data(self, byte_data):
        '''Extract the values from byte string.'''
        # Expect first 4 bytes to encode the total header size as a littleendian uint32
        if len(byte_data) < 4:
            raise ValueError(""byte_data too short to contain size field"")
        size_field = struct.unpack('<I', byte_data[:4])[0]
        self.size = size_field
        # Store raw header bytes if you like; at minimum we keep size
        self._raw = byte_data

    def _parse_file(self, file_obj):
        '''Directly read from file handler.

        Note:
          This will move the file pointer.
        '''
        # Read the size field first
        size_bytes = file_obj.read(4)
        if len(size_bytes) < 4:
            raise EOFError(""Could not read header size from file"")
        size_field = struct.unpack('<I', size_bytes)[0]
        self.size = size_field
        # Now read the rest of the header
        remaining = size_field - 4
        if remaining < 0:
            raise ValueError(""Invalid header size"")
        data_bytes = file_obj.read(remaining)
        if len(data_bytes) < remaining:
            raise EOFError(""File ended before reading full header"")
        self._raw = size_bytes + data_bytes

    def __repr__(self):
        return f""<{self.__class__.__name__} size={self.size}>""","class DAQHeader(object):
    '''Wrapper for the JDAQHeader binary format.

    Parameters
    ----------
    byte_data : bytes (optional)
        The binary file, where the file pointer is at the beginning of the header.
    file_obj : file (optional)
        The binary file, where the file pointer is at the beginning of the header.

    Attributes
    ----------
    size : int
        The size of the original DAQ byte representation.

    '''

    def __init__(self, byte_data=None, file_obj=None):
        self.size = 0
        
        if byte_data is not None:
            self._parse_byte_data(byte_data)
        elif file_obj is not None:
            self._parse_file(file_obj)

    def _parse_byte_data(self, byte_data):
        '''Extract the values from byte string.'''
        # Assuming the size is stored as a 4-byte little-endian integer at the beginning
        if len(byte_data) >= 4:
            import struct
            self.size = struct.unpack('<I', byte_data[:4])[0]

    def _parse_file(self, file_obj):
        '''Directly read from file handler.

        Note:
          This will move the file pointer.

        '''
        # Read 4 bytes for the size field
        byte_data = file_obj.read(4)
        if len(byte_data) == 4:
            import struct
            self.size = struct.unpack('<I', byte_data)[0]

    def __repr__(self):
        return f""DAQHeader(size={self.size})""","class DAQHeader(object):
    '''Wrapper for the JDAQHeader binary format.

    Parameters
    ----------
    byte_data : bytes (optional)
        The binary file, where the file pointer is at the beginning of the header.
    file_obj : file (optional)
        The binary file, where the file pointer is at the beginning of the header.

    Attributes
    ----------
    size : int
        The size of the original DAQ byte representation.

    '''

    def __init__(self, byte_data=None, file_obj=None):
        self.size = 0
        self.detector_id = 0
        self.run_id = 0
        self.time_slice = 0
        self.time_stamp = 0
        self.tick = 0
        self.overlays = 0
        self.trigger_counter = 0
        self.trigger_mask = 0
        self.data_type = 0
        
        if byte_data is not None:
            self._parse_byte_data(byte_data)
        elif file_obj is not None:
            self._parse_file(file_obj)

    def _parse_byte_data(self, byte_data):
        '''Extract the values from byte string.'''
        if len(byte_data) < 40:
            raise ValueError(""Insufficient byte data for DAQ header"")
        
        values = struct.unpack('<10I', byte_data[:40])
        self.size = values[0]
        self.detector_id = values[1]
        self.run_id = values[2]
        self.time_slice = values[3]
        self.time_stamp = values[4]
        self.tick = values[5]
        self.overlays = values[6]
        self.trigger_counter = values[7]
        self.trigger_mask = values[8]
        self.data_type = values[9]

    def _parse_file(self, file_obj):
        '''Directly read from file handler.

        Note:
          This will move the file pointer.

        '''
        byte_data = file_obj.read(40)
        if len(byte_data) < 40:
            raise ValueError(""Insufficient data in file for DAQ header"")
        self._parse_byte_data(byte_data)

    def __repr__(self):
        return (f""DAQHeader(size={self.size}, detector_id={self.detector_id}, ""
                f""run_id={self.run_id}, time_slice={self.time_slice}, ""
                f""time_stamp={self.time_stamp}, tick={self.tick}, ""
                f""overlays={self.overlays}, trigger_counter={self.trigger_counter}, ""
                f""trigger_mask={self.trigger_mask}, data_type={self.data_type})"")",partial_docstr,0.5622641509433961,0.45454545454545453,0.3916349809885932,0.5018867924528301,0.45523390345760845,0.5996055226824457,0.424901185770751,0.3702970297029703,0.8298279643058777,0.8467150926589966,0.838186502456665,0.8449955582618713,0.7900784351145042,0.6872037914691943,0.5761904761904763,0.4976076555023924,0.6208530805687205,0.49501669338458204,0.8098159509202454,0.6523076923076923,0.5833333333333334,0.893349289894104,0.8387182354927063,0.8651722073554993,0.8438787460327148,0.7830962679425838,0.680373831775701,0.5478424015009381,0.4595103578154426,0.6093457943925235,0.4858409932169998,0.6239168110918544,0.4635416666666667,0.39652173913043476,0.8548708558082581,0.888683557510376,0.87144935131073,0.8851823806762695,0.8200018,0.3707590562571177,0.3220453276308188,0.4440715523400417,0.5051546391752577,0.2117647058823529,0.3576068029879301,0.416104050518037,0.4357907175282862,0.4020618556701031,0.1764705882352941,0.3520219041178477,0.3905595092211976,0.4507603692271485,0.4020618556701031,0.1647058823529411
620701,orb-framework/orb,orb-framework_orb/orb/core/events.py,orb.core.events.Callback,"class Callback(object):
    """"""
    Helper class used to listen for an event and then trigger a call
    to a waiting method
    """"""
    def __init__(self, method, *args, **kwds):
        self.method = method
        self.args = args
        self.kwds = kwds

    def __call__(self, event):
        self.method(*self.args, **self.kwds)","class Callback(object):
    '''
    Helper class used to listen for an event and then trigger a call
    to a waiting method
    '''

    def __init__(self, method, *args, **kwds):
        pass

    def __call__(self, event):
        pass

",3,1,snippet_740,1.0,"class Callback(object):
    '''
    Helper class used to listen for an event and then trigger a call
    to a waiting method
    '''

    def __init__(self, method, *args, **kwds):
        self._method = method
        self._args = args
        self._kwds = kwds

    def __call__(self, event):
        return self._method(event, *self._args, **self._kwds)","class Callback(object):
    '''
    Helper class used to listen for an event and then trigger a call
    to a waiting method
    '''

    def __init__(self, method, *args, **kwds):
        self.method = method
        self.args = args
        self.kwds = kwds

    def __call__(self, event):
        return self.method(event, *self.args, **self.kwds)","class Callback(object):
    '''
    Helper class used to listen for an event and then trigger a call
    to a waiting method
    '''

    def __init__(self, method, *args, **kwds):
        self.method = method
        self.args = args
        self.kwds = kwds

    def __call__(self, event):
        return self.method(event, *self.args, **self.kwds)",partial_docstr,0.9782608695652174,0.9555555555555557,0.8863636363636364,0.9782608695652174,0.7731958261981602,0.8854166666666666,0.7789473684210526,0.6702127659574468,0.9853046536445618,0.9907130002975464,0.9880014061927795,0.9901695251464844,0.988889,0.9782608695652174,0.9555555555555557,0.8863636363636364,0.9782608695652174,0.8877117111231028,0.9444444444444444,0.898876404494382,0.8522727272727273,0.9872971773147583,0.9928164482116699,0.9900491237640381,0.9922617673873901,0.988889,0.9782608695652174,0.9555555555555557,0.8863636363636364,0.9782608695652174,0.8877117111231028,0.9444444444444444,0.898876404494382,0.8522727272727273,0.9872971773147583,0.9928164482116699,0.9900491237640381,0.9922617673873901,0.988889,0.660369435212791,0.5950492876175587,0.6380799958833331,0.7241379310344828,0.6842105263157895,0.8358386573176508,0.7860665233564094,0.8331501748797114,0.7241379310344828,1.0,0.8358386573176508,0.7860665233564094,0.8331501748797114,0.7241379310344828,1.0
504303,jaraco/jaraco.itertools,jaraco_jaraco.itertools/jaraco/itertools.py,itertools.Peekable,"class Peekable:
    """"""
    Wrapper for a traditional iterable to give it a peek attribute.

    >>> nums = Peekable(range(2))
    >>> nums.peek()
    0
    >>> nums.peek()
    0
    >>> next(nums)
    0
    >>> nums.peek()
    1
    >>> next(nums)
    1
    >>> nums.peek()
    Traceback (most recent call last):
    ...
    StopIteration

    Peekable should accept an iterable and not just an iterator.

    >>> list(Peekable(range(2)))
    [0, 1]
    """"""

    def __new__(cls, iterator):
        # if the iterator is already 'peekable', return it; otherwise
        # wrap it
        if hasattr(iterator, 'peek'):
            return iterator
        else:
            return object.__new__(cls)

    def __init__(self, iterator):
        self.iterator = iter(iterator)

    def __iter__(self):
        return self

    def __next__(self):
        return next(self.iterator)

    def peek(self):
        result, self.iterator = peek(self.iterator)
        return result","class Peekable:
    '''
    Wrapper for a traditional iterable to give it a peek attribute.

    >>> nums = Peekable(range(2))
    >>> nums.peek()
    0
    >>> nums.peek()
    0
    >>> next(nums)
    0
    >>> nums.peek()
    1
    >>> next(nums)
    1
    >>> nums.peek()
    Traceback (most recent call last):
    ...
    StopIteration

    Peekable should accept an iterable and not just an iterator.

    >>> list(Peekable(range(2)))
    [0, 1]
    '''

    def __new__(cls, iterator):
        pass

    def __init__(self, iterator):
        pass

    def __iter__(self):
        pass

    def __next__(self):
        pass

    def peek(self):
        pass

",6,1,snippet_401,1.0,"class Peekable:
    '''
    Wrapper for a traditional iterable to give it a peek attribute.

    >>> nums = Peekable(range(2))
    >>> nums.peek()
    0
    >>> nums.peek()
    0
    >>> next(nums)
    0
    >>> nums.peek()
    1
    >>> next(nums)
    1
    >>> nums.peek()
    Traceback (most recent call last):
    ...
    StopIteration

    Peekable should accept an iterable and not just an iterator.

    >>> list(Peekable(range(2)))
    [0, 1]
    '''

    def __new__(cls, iterator):
        return super().__new__(cls)

    def __init__(self, iterator):
        self._iterator = iter(iterator)
        self._has_peeked = False
        self._peeked_value = None

    def __iter__(self):
        return self

    def __next__(self):
        if self._has_peeked:
            self._has_peeked = False
            value = self._peeked_value
            self._peeked_value = None
            return value
        return next(self._iterator)

    def peek(self):
        if not self._has_peeked:
            self._peeked_value = next(self._iterator)
            self._has_peeked = True
        return self._peeked_value","class Peekable:
    '''
    Wrapper for a traditional iterable to give it a peek attribute.

    >>> nums = Peekable(range(2))
    >>> nums.peek()
    0
    >>> nums.peek()
    0
    >>> next(nums)
    0
    >>> nums.peek()
    1
    >>> next(nums)
    1
    >>> nums.peek()
    Traceback (most recent call last):
    ...
    StopIteration

    Peekable should accept an iterable and not just an iterator.

    >>> list(Peekable(range(2)))
    [0, 1]
    '''

    def __new__(cls, iterator):
        return super().__new__(cls)

    def __init__(self, iterator):
        self.iterator = iter(iterator)
        self._peeked = None
        self._has_peeked = False

    def __iter__(self):
        return self

    def __next__(self):
        if self._has_peeked:
            self._has_peeked = False
            return self._peeked
        return next(self.iterator)

    def peek(self):
        if not self._has_peeked:
            self._peeked = next(self.iterator)
            self._has_peeked = True
        return self._peeked","class Peekable:
    '''
    Wrapper for a traditional iterable to give it a peek attribute.

    >>> nums = Peekable(range(2))
    >>> nums.peek()
    0
    >>> nums.peek()
    0
    >>> next(nums)
    0
    >>> nums.peek()
    1
    >>> next(nums)
    1
    >>> nums.peek()
    Traceback (most recent call last):
    ...
    StopIteration

    Peekable should accept an iterable and not just an iterator.

    >>> list(Peekable(range(2)))
    [0, 1]
    '''

    def __new__(cls, iterator):
        return super().__new__(cls)

    def __init__(self, iterator):
        self._iterator = iter(iterator)
        self._has_peeked = False
        self._peeked_value = None

    def __iter__(self):
        return self

    def __next__(self):
        if self._has_peeked:
            self._has_peeked = False
            value = self._peeked_value
            self._peeked_value = None
            return value
        else:
            return next(self._iterator)

    def peek(self):
        if not self._has_peeked:
            self._peeked_value = next(self._iterator)
            self._has_peeked = True
        return self._peeked_value",partial_docstr,0.7591836734693878,0.6831275720164608,0.6390041493775933,0.7346938775510203,0.6721169078491523,0.7294520547945206,0.6632302405498282,0.6275862068965518,0.8970624804496765,0.937969982624054,0.9170602560043335,0.9337120652198792,0.8136501574803149,0.7914893617021276,0.7124463519313305,0.6666666666666667,0.7659574468085107,0.7387784669116173,0.7888888888888889,0.7286245353159851,0.7014925373134329,0.9175084233283997,0.9434673190116882,0.9303067922592163,0.9408054947853088,0.826212564102564,0.7642276422764228,0.6885245901639345,0.6363636363636364,0.7317073170731708,0.6733219954685453,0.7278911564625851,0.6655290102389079,0.6301369863013698,0.8978496193885803,0.9398258924484253,0.9183582663536072,0.9354525208473206,0.8113713953488372,0.5917274592322856,0.5851681111153921,0.6246904437624686,0.5416666666666666,0.6153846153846154,0.6659364047752372,0.6524832797953827,0.6619033649465921,0.5416666666666666,0.8076923076923077,0.5974835398945282,0.5838318979622841,0.6282176462312133,0.5625,0.6153846153846154
560422,marrow/cinje,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/marrow_cinje/cinje/util.py,cinje.util.Pipe,"class Pipe(object):
    """"""An object representing a pipe-able callable, optionally with preserved arguments.

    Using this you can construct custom subclasses (define a method named ""callable"") or use it as a decorator:

            @Pipe
            def s(text):
                    return str(text)

    """"""

    __slots__ = ('callable', 'args', 'kwargs')

    def __init__(self, callable, *args, **kw):
        super(Pipe, self).__init__()

        self.callable = callable
        self.args = args if args else ()
        self.kwargs = kw if kw else {}

    def __repr__(self):
        return ""Pipe({self.callable!r}{0}{1})"".format(
            (', ' + ', '.join(repr(i) for i in self.args)) if self.args else '',
            (', ' + ', '.join(""{0}={1!r}"".format(i, j)
             for i, j in self.kwargs.items())) if self.kwargs else '',
            self=self,
        )

    def __ror__(self, other):
        """"""The main machinery of the Pipe, calling the chosen callable with the recorded arguments.""""""

        return self.callable(*(self.args + (other, )), **self.kwargs)

    def __call__(self, *args, **kw):
        """"""Allow for the preserved args and kwargs to be updated, returning a mutated copy.

        This allows for usage with arguments, as in the following example:

                ""Hello!"" | encode('utf8')

        This also allows for easy construction of custom mutated copies for use later, a la:

                utf8 = encode('utf8')
                ""Hello!"" | utf8
        """"""

        return self.__class__(self.callable, *args, **kw)","class Pipe(object):
    '''An object representing a pipe-able callable, optionally with preserved arguments.

    Using this you can construct custom subclasses (define a method named ""callable"") or use it as a decorator:

            @Pipe
            def s(text):
                    return str(text)

    '''


    def __init__(self, callable, *args, **kw):
        pass


    def __repr__(self):
        pass


    def __ror__(self, other):
    '''The main machinery of the Pipe, calling the chosen callable with the recorded arguments.'''
        pass


    def __call__(self, *args, **kw):
    '''Allow for the preserved args and kwargs to be updated, returning a mutated copy.

        This allows for usage with arguments, as in the following example:

                ""Hello!"" | encode('utf8')

        This also allows for easy construction of custom mutated copies for use later, a la:

                utf8 = encode('utf8')
                ""Hello!"" | utf8
        '''
        pass

",5,3,snippet_144,1.0,"class Pipe(object):
    '''An object representing a pipe-able callable, optionally with preserved arguments.

    Using this you can construct custom subclasses (define a method named ""callable"") or use it as a decorator:

            @Pipe
            def s(text):
                    return str(text)

    '''

    def __init__(self, callable, *args, **kw):
        self._func = callable if (callable and hasattr(callable, '__call__')) else None
        self.args = args
        self.kw = kw

    def __repr__(self):
        if self._func:
            name = getattr(self._func, '__name__', repr(self._func))
        else:
            name = self.__class__.__name__
        parts = []
        for a in self.args:
            parts.append(repr(a))
        for k, v in self.kw.items():
            parts.append(f""{k}={v!r}"")
        inside = "", "".join(parts)
        return f""{name}({inside})""

    def __ror__(self, other):
        func = self._func if self._func else getattr(self, 'callable')
        return func(other, *self.args, **self.kw)

    def __call__(self, *args, **kw):
        new_args = self.args + args
        new_kw = self.kw.copy()
        new_kw.update(kw)
        return self.__class__(self._func, *new_args, **new_kw)","class Pipe(object):
    '''An object representing a pipe-able callable, optionally with preserved arguments.

    Using this you can construct custom subclasses (define a method named ""callable"") or use it as a decorator:

            @Pipe
            def s(text):
                    return str(text)

    '''

    def __init__(self, callable, *args, **kw):
        self._callable = callable
        self._args = args
        self._kw = kw

    def __repr__(self):
        return f'<Pipe {self._callable.__name__}>'

    def __ror__(self, other):
        '''The main machinery of the Pipe, calling the chosen callable with the recorded arguments.'''
        return self._callable(other, *self._args, **self._kw)

    def __call__(self, *args, **kw):
        '''Allow for the preserved args and kwargs to be updated, returning a mutated copy.

        This allows for usage with arguments, as in the following example:

                ""Hello!"" | encode('utf8')

        This also allows for easy construction of custom mutated copies for use later, a la:

                utf8 = encode('utf8')
                ""Hello!"" | utf8
        '''
        return Pipe(self._callable, *args, **kw)","class Pipe(object):
    '''An object representing a pipe-able callable, optionally with preserved arguments.

    Using this you can construct custom subclasses (define a method named ""callable"") or use it as a decorator:

            @Pipe
            def s(text):
                    return str(text)

    '''

    def __init__(self, callable, *args, **kw):
        self.callable = callable
        self.args = args
        self.kw = kw

    def __repr__(self):
        return f""<Pipe: {self.callable}>""

    def __ror__(self, other):
        '''The main machinery of the Pipe, calling the chosen callable with the recorded arguments.'''
        return self.callable(other, *self.args, **self.kw)

    def __call__(self, *args, **kw):
        '''Allow for the preserved args and kwargs to be updated, returning a mutated copy.

        This allows for usage with arguments, as in the following example:

                ""Hello!"" | encode('utf8')

        This also allows for easy construction of custom mutated copies for use later, a la:

                utf8 = encode('utf8')
                ""Hello!"" | utf8
        '''
        return Pipe(self.callable, *args, **kw)",partial_docstr,0.6218487394957984,0.37183098591549296,0.28895184135977336,0.4985994397759103,0.45385646988068723,0.7696629213483146,0.5211267605633803,0.3870056497175141,0.8764589428901672,0.8281806111335754,0.8516361117362976,0.8327677249908447,0.7568330327868855,0.8405797101449276,0.7755102040816326,0.7155425219941349,0.8289855072463768,0.48915867773578414,0.959409594095941,0.825925925925926,0.7397769516728625,0.9465532302856445,0.8895454406738281,0.9171643257141113,0.8949353098869324,0.8240758333333337,0.8430232558139534,0.7777777777777777,0.7176470588235294,0.8313953488372093,0.4767646075695537,0.9575289575289575,0.872093023255814,0.8054474708171206,0.9495822191238403,0.8903193473815918,0.9189963936805725,0.8959106206893921,0.8225326388888891,0.3704251299991565,0.2311527650815506,0.2668830916387619,0.4757281553398058,0.5079365079365079,0.3836245807202909,0.5353561956238482,0.5588585704689047,0.2815533980582524,0.1587301587301587,0.377457217051762,0.5518310516851653,0.5750420452165971,0.2718446601941747,0.1111111111111111
699644,realestate-com-au/dashmat,realestate-com-au_dashmat/dashmat/core_modules/splunk/splunk-sdk-1.3.0/splunklib/searchcommands/decorators.py,splunklib.searchcommands.decorators.Configuration,"class Configuration(object):
    """""" Defines the configuration settings for a search command.

    Documents, validates, and ensures that only relevant configuration settings
    are applied. Adds a :code:`name` class variable to search command classes
    that don't have one. The :code:`name` is derived from the name of the class.
    By convention command class names end with the word ""Command"". To derive
    :code:`name` the word ""Command"" is removed from the end of the class name
    and then converted to lower case for conformance with the `Search command
    style guide <http://docs.splunk.com/Documentation/Splunk/6.0/Search/Searchcommandstyleguide>`_

    """"""
    def __init__(self, **kwargs):
        self.settings = kwargs

    def __call__(self, o):
        if isfunction(o):
            # We must wait to finalize configuration as the class containing
            # this function is under construction at the time this call to
            # decorate a member function. This will be handled in the call to
            # o.ConfigurationSettings.fix_up(o), below.
            o._settings = self.settings
        elif isclass(o):
            name = o.__name__
            if name.endswith('Command'):
                name = name[:-len('Command')]
            o.name = name.lower()
            if self.settings is not None:
                o.ConfigurationSettings = ConfigurationSettingsType(
                    module='.'.join((o.__module__, o.__name__)),
                    name='ConfigurationSettings',
                    bases=(o.ConfigurationSettings,),
                    settings=self.settings)
            o.ConfigurationSettings.fix_up(o)
            Option.fix_up(o)
        else:
            raise TypeError(
                'Incorrect usage: Configuration decorator applied to %s'
                % (type(o), o.__name__))
        return o","class Configuration(object):
    ''' Defines the configuration settings for a search command.

    Documents, validates, and ensures that only relevant configuration settings
    are applied. Adds a :code:`name` class variable to search command classes
    that don't have one. The :code:`name` is derived from the name of the class.
    By convention command class names end with the word ""Command"". To derive
    :code:`name` the word ""Command"" is removed from the end of the class name
    and then converted to lower case for conformance with the `Search command
    style guide <http://docs.splunk.com/Documentation/Splunk/6.0/Search/Searchcommandstyleguide>`_

    '''

    def __init__(self, **kwargs):
        pass

    def __call__(self, o):
        pass

",3,1,snippet_598,0.2727272727272727,"class Configuration(object):
    """""" Defines configuration settings for a search command. """"""

    def __init__(self, **kwargs):
        self._settings = {}
        for key, val in kwargs.items():
            if not isinstance(key, str) or not key.isidentifier():
                raise ValueError(""Invalid configuration key: %r"" % key)
            if key.startswith('_'):
                raise ValueError(""Configuration key cannot start with underscore: %r"" % key)
            self._settings[key] = val

    def __call__(self, cls):
        for key, val in self._settings.items():
            if hasattr(cls, key):
                existing = getattr(cls, key)
                if callable(existing):
                    raise AttributeError(
                        ""Cannot override existing method %r on %s"" % (key, cls.__name__)
                    )
            setattr(cls, key, val)
        if not hasattr(cls, 'name'):
            name = cls.__name__
            if name.endswith('Command'):
                name = name[:-7]
            cls.name = name.lower()
        return cls","class Configuration(object):
    ''' Defines the configuration settings for a search command.

    Documents, validates, and ensures that only relevant configuration settings
    are applied. Adds a :code:`name` class variable to search command classes
    that don't have one. The :code:`name` is derived from the name of the class.
    By convention command class names end with the word ""Command"". To derive
    :code:`name` the word ""Command"" is removed from the end of the class name
    and then converted to lower case for conformance with the `Search command
    style guide <http://docs.splunk.com/Documentation/Splunk/6.0/Search/Searchcommandstyleguide>`_

    '''

    def __init__(self, **kwargs):
        # Store configuration settings
        for key, value in kwargs.items():
            setattr(self, key, value)

    def __call__(self, o):
        # Add configuration to the decorated class
        for attr_name in dir(self):
            if not attr_name.startswith('_'):
                attr_value = getattr(self, attr_name)
                setattr(o, attr_name, attr_value)
        
        # Add name class variable if it doesn't exist
        if not hasattr(o, 'name'):
            class_name = o.__name__ if hasattr(o, '__name__') else o.__class__.__name__
            if class_name.endswith('Command'):
                name = class_name[:-7].lower()  # Remove 'Command' and convert to lowercase
            else:
                name = class_name.lower()
            o.name = name
            
        return o","class Configuration(object):
    ''' Defines the configuration settings for a search command.

    Documents, validates, and ensures that only relevant configuration settings
    are applied. Adds a :code:`name` class variable to search command classes
    that don't have one. The :code:`name` is derived from the name of the class.
    By convention command class names end with the word ""Command"". To derive
    :code:`name` the word ""Command"" is removed from the end of the class name
    and then converted to lower case for conformance with the `Search command
    style guide <http://docs.splunk.com/Documentation/Splunk/6.0/Search/Searchcommandstyleguide>`_

    '''

    def __init__(self, **kwargs):
        self.settings = kwargs

    def __call__(self, o):
        if hasattr(o, '__name__'):
            # It's a class
            cls = o
        else:
            # It's an instance
            cls = o.__class__
        
        # Apply configuration settings to the class
        for key, value in self.settings.items():
            setattr(cls, key, value)
        
        # Add name if it doesn't exist
        if not hasattr(cls, 'name'):
            class_name = cls.__name__
            if class_name.endswith('Command'):
                name = class_name[:-7].lower()  # Remove 'Command' and convert to lowercase
            else:
                name = class_name.lower()
            cls.name = name
        
        return o",partial_docstr,0.2865671641791045,0.15615615615615616,0.10271903323262839,0.208955223880597,0.23084379912215136,0.6707317073170732,0.37142857142857144,0.29508196721311475,0.7764840126037598,0.7209241986274719,0.7476734519004822,0.7261198163032532,0.7517031632653066,0.6888361045130641,0.5584725536992841,0.5179856115107914,0.6365795724465557,0.570994674966977,0.8069164265129684,0.615606936416185,0.553623188405797,0.886506974697113,0.8695065975189209,0.8779244422912598,0.8711771965026855,0.7569085082872933,0.7076167076167075,0.5975308641975309,0.5508684863523573,0.6535626535626536,0.5488077027593952,0.8612903225806452,0.686084142394822,0.6201298701298701,0.908280611038208,0.8757264614105225,0.8917065262794495,0.8788764476776123,0.7808493370165749,0.2247350003253088,0.0628216354566791,0.0850143915370491,0.4680851063829787,0.2830188679245283,0.4436767182732494,0.5051742156059784,0.5208373543958912,0.4468085106382978,0.3018867924528302,0.4584233095964796,0.5288850383538461,0.545474599068604,0.4574468085106383,0.3018867924528302
145182,LeastAuthority/txkube,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/LeastAuthority_txkube/src/txkube/_model.py,txkube._model.define_behaviors.NamespaceStatus,"class NamespaceStatus(object):
    """"""
    ``NamespaceStatus`` instances model `Kubernetes namespace status
    <https://kubernetes.io/docs/api-reference/v1/definitions/#_v1_namespacestatus>`_.
    """"""
    @classmethod
    def active(cls):
        return cls(phase=u""Active"")

    @classmethod
    def terminating(cls):
        return cls(phase=u""Terminating"")
","class NamespaceStatus(object):
    '''
    ``NamespaceStatus`` instances model `Kubernetes namespace status
    <https://kubernetes.io/docs/api-reference/v1/definitions/#_v1_namespacestatus>`_.
    '''

    @classmethod
    def active(cls):
        pass

    @classmethod
    def terminating(cls):
        pass

",5,1,snippet_157,0.5,"class NamespaceStatus(object):
    '''
    ``NamespaceStatus`` instances model `Kubernetes namespace status
    <https://kubernetes.io/docs/api-reference/v1/definitions/#_v1_namespacestatus>`_.
    '''

    ACTIVE = 'Active'
    TERMINATING = 'Terminating'

    def __init__(self, phase):
        self.phase = phase

    @classmethod
    def active(cls):
        return cls(cls.ACTIVE)

    @classmethod
    def terminating(cls):
        return cls(cls.TERMINATING)

    def __eq__(self, other):
        if not isinstance(other, NamespaceStatus):
            return NotImplemented
        return self.phase == other.phase

    def __ne__(self, other):
        if not isinstance(other, NamespaceStatus):
            return NotImplemented
        return self.phase != other.phase

    def __repr__(self):
        return f'NamespaceStatus(phase={self.phase!r})'

    def __str__(self):
        return self.phase","class NamespaceStatus(object):
    '''
    ``NamespaceStatus`` instances model `Kubernetes namespace status
    <https://kubernetes.io/docs/api-reference/v1/definitions/#_v1_namespacestatus>`_.
    '''

    def __init__(self, phase):
        self.phase = phase

    @classmethod
    def active(cls):
        return cls('Active')

    @classmethod
    def terminating(cls):
        return cls('Terminating')

    def __eq__(self, other):
        if not isinstance(other, NamespaceStatus):
            return False
        return self.phase == other.phase

    def __repr__(self):
        return f""NamespaceStatus(phase='{self.phase}')""","class NamespaceStatus(object):
    '''
    ``NamespaceStatus`` instances model `Kubernetes namespace status
    <https://kubernetes.io/docs/api-reference/v1/definitions/#_v1_namespacestatus>`_.
    '''

    def __init__(self, phase):
        self.phase = phase

    @classmethod
    def active(cls):
        return cls(""Active"")

    @classmethod
    def terminating(cls):
        return cls(""Terminating"")

    def __eq__(self, other):
        if not isinstance(other, NamespaceStatus):
            return False
        return self.phase == other.phase

    def __hash__(self):
        return hash(self.phase)

    def __repr__(self):
        return f""NamespaceStatus(phase='{self.phase}')""",partial_docstr,0.5343511450381679,0.4496124031007752,0.4094488188976378,0.5038167938931297,0.3290911355949409,0.3582089552238806,0.33,0.3015075376884422,0.7905001640319824,0.9576521515846252,0.8660849332809448,0.9378218054771423,0.740478785714286,0.6862745098039216,0.58,0.5306122448979592,0.6470588235294117,0.45494919854309757,0.5034013605442177,0.4520547945205479,0.41379310344827586,0.8725026845932007,0.9676780104637146,0.917629063129425,0.9572362303733826,0.8049664893617021,0.6422018348623854,0.5420560747663551,0.49523809523809526,0.6055045871559633,0.43158598476617005,0.47619047619047616,0.4311377245508982,0.39156626506024095,0.8514882922172546,0.9658336639404297,0.9050636291503906,0.9530354738235474,0.7893102830188679,0.3757313680279686,0.1595947097177549,0.5516640957274528,0.2916666666666667,0.5,0.4910859238258718,0.2460129329093676,0.5516640957274528,0.2916666666666667,0.875,0.4857921174364815,0.2248377073518064,0.5516640957274528,0.2916666666666667,0.875
590188,n8henrie/urlmon,n8henrie_urlmon/urlmon/urlmon.py,urlmon.urlmon.Pushover,"class Pushover(object):
    """"""Pushover client

    args
    api_token -- pushover API token (https://pushover.net/apps)
    user -- pushover user key (https://pushover.net/)
    """"""

    def __init__(self, api_token, user):
        self.api_token = api_token
        self.user = user

    def validate(self):
        """"""Validate the user and token, returns the Requests response.""""""

        validate_url = ""https://api.pushover.net/1/users/validate.json""

        payload = {
            'token': self.api_token,
            'user': self.user,
        }

        return requests.post(validate_url, data=payload)

    def push(self, message, device=None, title=None, url=None, url_title=None,
             priority=None, timestamp=None, sound=None):
        """"""Pushes the notification, returns the Requests response.

        Arguments:
            message -- your message

        Keyword arguments:
            device -- your user's device name to send the message directly to
                that device, rather than all of the user's devices
            title -- your message's title, otherwise your app's name is used
            url -- a supplementary URL to show with your message
            url_title -- a title for your supplementary URL, otherwise just the
                URL is shown
            priority -- send as --1 to always send as a quiet notification, 1
                to display as high--priority and bypass the user's quiet hours,
                or 2 to also require confirmation from the user
            timestamp -- a Unix timestamp of your message's date and time to
                display to the user, rather than the time your message is
                received by our API
            sound -- the name of one of the sounds supported by device clients
                to override the user's default sound choice.
        """"""

        api_url = 'https://api.pushover.net/1/messages.json'

        payload = {
            'token': self.api_token,
            'user': self.user,
            'message': message,
            'device': device,
            'title': title,
            'url': url,
            'url_title': url_title,
            'priority': priority,
            'timestamp': timestamp,
            'sound': sound
        }

        return requests.post(api_url, params=payload)","class Pushover(object):
    '''Pushover client

    args
    api_token -- pushover API token (https://pushover.net/apps)
    user -- pushover user key (https://pushover.net/)
    '''

    def __init__(self, api_token, user):
        pass

    def validate(self):
    '''Validate the user and token, returns the Requests response.'''
        pass

    def push(self, message, device=None, title=None, url=None, url_title=None,
             priority=None, timestamp=None, sound=None):
    '''Pushes the notification, returns the Requests response.

        Arguments:
            message -- your message

        Keyword arguments:
            device -- your user's device name to send the message directly to
                that device, rather than all of the user's devices
            title -- your message's title, otherwise your app's name is used
            url -- a supplementary URL to show with your message
            url_title -- a title for your supplementary URL, otherwise just the
                URL is shown
            priority -- send as --1 to always send as a quiet notification, 1
                to display as high--priority and bypass the user's quiet hours,
                or 2 to also require confirmation from the user
            timestamp -- a Unix timestamp of your message's date and time to
                display to the user, rather than the time your message is
                received by our API
            sound -- the name of one of the sounds supported by device clients
                to override the user's default sound choice.
        '''
        pass

",4,3,snippet_295,1.0,"class Pushover(object):
    '''Pushover client

    args
    api_token -- pushover API token (https://pushover.net/apps)
    user -- pushover user key (https://pushover.net/)
    '''

    VALIDATE_URL = 'https://api.pushover.net/1/users/validate.json'
    MESSAGE_URL = 'https://api.pushover.net/1/messages.json'

    def __init__(self, api_token, user):
        self.api_token = api_token
        self.user = user

    def validate(self):
        '''Validate the user and token, returns the Requests response.'''
        payload = {
            'token': self.api_token,
            'user': self.user,
        }
        return requests.post(self.VALIDATE_URL, data=payload)

    def push(self, message, device=None, title=None, url=None, url_title=None,
             priority=None, timestamp=None, sound=None):
        '''Pushes the notification, returns the Requests response.

        Arguments:
            message -- your message

        Keyword arguments:
            device -- your user's device name to send the message directly to
                that device, rather than all of the user's devices
            title -- your message's title, otherwise your app's name is used
            url -- a supplementary URL to show with your message
            url_title -- a title for your supplementary URL, otherwise just the
                URL is shown
            priority -- send as --1 to always send as a quiet notification, 1
                to display as high--priority and bypass the user's quiet hours,
                or 2 to also require confirmation from the user
            timestamp -- a Unix timestamp of your message's date and time to
                display to the user, rather than the time your message is
                received by our API
            sound -- the name of one of the sounds supported by device clients
                to override the user's default sound choice.
        '''
        payload = {
            'token': self.api_token,
            'user': self.user,
            'message': message,
        }
        if device is not None:
            payload['device'] = device
        if title is not None:
            payload['title'] = title
        if url is not None:
            payload['url'] = url
        if url_title is not None:
            payload['url_title'] = url_title
        if priority is not None:
            payload['priority'] = priority
        if timestamp is not None:
            payload['timestamp'] = timestamp
        if sound is not None:
            payload['sound'] = sound

        return requests.post(self.MESSAGE_URL, data=payload)","class Pushover(object):
    '''Pushover client

    args
    api_token -- pushover API token (https://pushover.net/apps)
    user -- pushover user key (https://pushover.net/)
    '''

    def __init__(self, api_token, user):
        self.api_token = api_token
        self.user = user
        self.api_url = 'https://api.pushover.net/1/'

    def validate(self):
        '''Validate the user and token, returns the Requests response.'''
        data = {
            'token': self.api_token,
            'user': self.user
        }
        response = requests.post(self.api_url + 'users/validate.json', data=data)
        return response

    def push(self, message, device=None, title=None, url=None, url_title=None,
             priority=None, timestamp=None, sound=None):
        '''Pushes the notification, returns the Requests response.

        Arguments:
            message -- your message

        Keyword arguments:
            device -- your user's device name to send the message directly to
                that device, rather than all of the user's devices
            title -- your message's title, otherwise your app's name is used
            url -- a supplementary URL to show with your message
            url_title -- a title for your supplementary URL, otherwise just the
                URL is shown
            priority -- send as -1 to always send as a quiet notification, 1
                to display as high-priority and bypass the user's quiet hours,
                or 2 to also require confirmation from the user
            timestamp -- a Unix timestamp of your message's date and time to
                display to the user, rather than the time your message is
                received by our API
            sound -- the name of one of the sounds supported by device clients
                to override the user's default sound choice.
        '''
        data = {
            'token': self.api_token,
            'user': self.user,
            'message': message
        }
        
        if device is not None:
            data['device'] = device
        if title is not None:
            data['title'] = title
        if url is not None:
            data['url'] = url
        if url_title is not None:
            data['url_title'] = url_title
        if priority is not None:
            data['priority'] = priority
        if timestamp is not None:
            data['timestamp'] = timestamp
        if sound is not None:
            data['sound'] = sound
            
        response = requests.post(self.api_url + 'messages.json', data=data)
        return response","class Pushover(object):
    '''Pushover client

    args
    api_token -- pushover API token (https://pushover.net/apps)
    user -- pushover user key (https://pushover.net/)
    '''

    def __init__(self, api_token, user):
        self.api_token = api_token
        self.user = user
        self.base_url = ""https://api.pushover.net/1""

    def validate(self):
        '''Validate the user and token, returns the Requests response.'''
        url = f""{self.base_url}/users/validate.json""
        data = {
            'token': self.api_token,
            'user': self.user
        }
        return requests.post(url, data=data)

    def push(self, message, device=None, title=None, url=None, url_title=None,
             priority=None, timestamp=None, sound=None):
        '''Pushes the notification, returns the Requests response.

        Arguments:
            message -- your message

        Keyword arguments:
            device -- your user's device name to send the message directly to
                that device, rather than all of the user's devices
            title -- your message's title, otherwise your app's name is used
            url -- a supplementary URL to show with your message
            url_title -- a title for your supplementary URL, otherwise just the
                URL is shown
            priority -- send as --1 to always send as a quiet notification, 1
                to display as high--priority and bypass the user's quiet hours,
                or 2 to also require confirmation from the user
            timestamp -- a Unix timestamp of your message's date and time to
                display to the user, rather than the time your message is
                received by our API
            sound -- the name of one of the sounds supported by device clients
                to override the user's default sound choice.
        '''
        url = f""{self.base_url}/messages.json""
        data = {
            'token': self.api_token,
            'user': self.user,
            'message': message
        }
        
        if device is not None:
            data['device'] = device
        if title is not None:
            data['title'] = title
        if url is not None:
            data['url'] = url
        if url_title is not None:
            data['url_title'] = url_title
        if priority is not None:
            data['priority'] = priority
        if timestamp is not None:
            data['timestamp'] = timestamp
        if sound is not None:
            data['sound'] = sound
            
        return requests.post(url, data=data)",partial_docstr,0.9168026101141925,0.8674304418985269,0.8243021346469622,0.8580750407830343,0.7634082597054831,0.8296146044624746,0.7459349593495935,0.7189409368635438,0.9323228597640991,0.96012282371521,0.946018636226654,0.957268476486206,0.8674553937007875,0.8936170212765957,0.8177339901477833,0.7611202635914334,0.8412438625204584,0.7229240858271643,0.8127572016460906,0.7030927835051546,0.6611570247933884,0.942367434501648,0.9684176445007324,0.9552149176597595,0.9657480716705322,0.8551824719101123,0.8809135399673736,0.8248772504091654,0.7750410509031198,0.8646003262642741,0.7337744105108065,0.8125,0.7191919191919192,0.6761133603238867,0.9422954320907593,0.9699599742889404,0.9559275507926941,0.9671206474304199,0.8926352808988763,0.648905201526454,0.7115122334610281,0.8409035451506797,0.7894736842105263,0.2537313432835821,0.7862708734086754,0.6479462280825796,0.786610949762648,0.7105263157894737,0.0,0.8185074919756745,0.675861534894577,0.8086947487975944,0.7894736842105263,0.0
307709,cltk/cltk,src/cltk/phonology/ang/transcription.py,cltk.phonology.ang.transcription.Word,"class Word:
    """"""
    Transcription of Old English words
    """"""

    def __init__(self, w: str):
        self.word = w

    def remove_diacritics(self) -> str:
        """"""
        :return: str: the input string stripped of its diacritics

        Examples:

        >>> Word('eld').remove_diacritics()
        'geld'

        """"""

        w = """"
        for c in unicodedata.normalize(""NFKD"", self.word):
            if ""LATIN"" == unicodedata.name(c)[:5]:
                w += c

        return w

    def ascii_encoding(self):
        """"""
        :return: str: Returns the ASCII-encoded string

        Thorn (, ) and Ash(, ) are substituted by the digraphs
        'th' and 'ae' respectively. Wynn(, ) and Eth(, ) are replaced
        by 'w' and 'd'.

        Examples:

        >>> Word('eld').ascii_encoding()
        'gelaed'

        >>> Word('eorunga').ascii_encoding()
        'weordunga'

        """"""

        w = self.remove_diacritics()

        for k, val in zip(Normalize.keys(), Normalize.values()):
            w = w.replace(k, val)

        return w","class Word:
    '''
    Transcription of Old English words
    '''

    def __init__(self, w: str):
        pass

    def remove_diacritics(self) -> str:
    '''
        :return: str: the input string stripped of its diacritics

        Examples:

        >>> Word('eld').remove_diacritics()
        'geld'

        '''
        pass

    def ascii_encoding(self):
    '''
        :return: str: Returns the ASCII-encoded string

        Thorn (, ) and Ash(, ) are substituted by the digraphs
        'th' and 'ae' respectively. Wynn(, ) and Eth(, ) are replaced
        by 'w' and 'd'.

        Examples:

        >>> Word('eld').ascii_encoding()
        'gelaed'

        >>> Word('eorunga').ascii_encoding()
        'weordunga'

        '''
        pass

",4,3,snippet_379,0.3333333333333333,"class Word:
    '''
    Transcription of Old English words
    '''

    def __init__(self, w: str):
        self.word = w

    def remove_diacritics(self) -> str:
        '''
            :return: str: the input string stripped of its diacritics

            Examples:

            >>> Word('eld').remove_diacritics()
            'geld'
        '''
        decomposed = unicodedata.normalize('NFD', self.word)
        stripped = ''.join(ch for ch in decomposed if unicodedata.category(ch)[0] != 'M')
        return unicodedata.normalize('NFC', stripped)

    def ascii_encoding(self) -> str:
        '''
            :return: str: Returns the ASCII-encoded string

            Thorn (, ) and Ash(, ) are substituted by the digraphs
            'th' and 'ae' respectively. Wynn(, ) and Eth(, ) are replaced
            by 'w' and 'd'.

            Examples:

            >>> Word('eld').ascii_encoding()
            'gelaed'

            >>> Word('eorunga').ascii_encoding()
            'weordunga'
        '''
        base = self.remove_diacritics()
        mapping = {
            '': 'th', '': 'th',
            '': 'ae', '': 'ae',
            '': 'w',  '': 'w',
            '': 'd',  '': 'd'
        }
        return ''.join(mapping.get(ch, ch) for ch in base)","class Word:
    '''
    Transcription of Old English words
    '''

    def __init__(self, w: str):
        self.word = w

    def remove_diacritics(self) -> str:
        '''
        :return: str: the input string stripped of its diacritics

        Examples:

        >>> Word('eld').remove_diacritics()
        'geld'

        '''
        diacritics_map = {
            '': 'a', '': '', '': 'e', '': 'i', '': 'o', '': 'u', '': 'y',
            '': 'A', '': 'E', '': 'I', '': 'O', '': 'U', '': 'Y',
            '': 'c', '': 'g', '': 'g', '': 'f', '': 'g', '': 'g',
            '': 'C', '': 'G', '': 'F',
            '': '', '': '', '': '', '': '', '': '', '': '',
            '': '', '': ''
        }
        
        result = self.word
        for old_char, new_char in diacritics_map.items():
            result = result.replace(old_char, new_char)
        
        # Remove specific diacritical marks
        diacritics_to_remove = {'', '', '', '', '', ''}
        result = ''.join(char for char in result if char not in diacritics_to_remove)
        
        # More specific handling for the examples
        replacements = {
            '': 'g', '': '', '': 'a', '': 'e', '': 'i', '': 'o', '': 'u', '': 'y'
        }
        
        result = self.word
        for old_char, new_char in replacements.items():
            result = result.replace(old_char, new_char)
            
        return result

    def ascii_encoding(self):
        '''
        :return: str: Returns the ASCII-encoded string

        Thorn (, ) and Ash(, ) are substituted by the digraphs
        'th' and 'ae' respectively. Wynn(, ) and Eth(, ) are replaced
        by 'w' and 'd'.

        Examples:

        >>> Word('eld').ascii_encoding()
        'gelaed'

        >>> Word('eorunga').ascii_encoding()
        'weordunga'

        '''
        # First remove diacritics
        result = self.remove_diacritics()
        
        # Then apply ASCII encoding substitutions
        ascii_replacements = {
            '': 'th', '': 'th',
            '': 'ae', '': 'ae',
            '': 'w', '': 'w',
            '': 'd', '': 'd'
        }
        
        for old_char, new_char in ascii_replacements.items():
            result = result.replace(old_char, new_char)
            
        return result","class Word:
    '''
    Transcription of Old English words
    '''

    def __init__(self, w: str):
        self.word = w

    def remove_diacritics(self) -> str:
        '''
        :return: str: the input string stripped of its diacritics

        Examples:

        >>> Word('eld').remove_diacritics()
        'geld'

        '''
        normalized = unicodedata.normalize('NFD', self.word)
        result = ''
        for char in normalized:
            if unicodedata.category(char) != 'Mn':
                result += char
        return result

    def ascii_encoding(self):
        '''
        :return: str: Returns the ASCII-encoded string

        Thorn (, ) and Ash(, ) are substituted by the digraphs
        'th' and 'ae' respectively. Wynn(, ) and Eth(, ) are replaced
        by 'w' and 'd'.

        Examples:

        >>> Word('eld').ascii_encoding()
        'gelaed'

        >>> Word('eorunga').ascii_encoding()
        'weordunga'

        '''
        # First remove diacritics
        text = self.remove_diacritics()
        
        # Replace Old English characters
        replacements = {
            '': 'th',
            '': 'th',
            '': 'ae',
            '': 'ae',
            '': 'w',
            '': 'w',
            '': 'd',
            '': 'd'
        }
        
        for old_char, new_char in replacements.items():
            text = text.replace(old_char, new_char)
        
        return text",partial_docstr,0.7968127490039841,0.674698795180723,0.6234817813765183,0.756972111553785,0.6469814442440021,0.7627737226277372,0.6190476190476191,0.5735294117647058,0.9159846305847168,0.9268001317977905,0.9213606119155884,0.9257070422172546,0.7826819117647058,0.5823529411764705,0.4970414201183432,0.47023809523809523,0.5529411764705882,0.32514102052935173,0.3843283582089552,0.3121495327102804,0.28651685393258425,0.8235175013542175,0.8842028975486755,0.8527819514274597,0.8777348399162292,0.717274554455446,0.7692307692307693,0.6589147286821705,0.6171874999999999,0.7384615384615384,0.6288331634173476,0.721830985915493,0.6148409893992933,0.5602836879432624,0.9270557165145874,0.9444139003753662,0.9356542825698853,0.9426489472389221,0.8131331818181817,0.5532085660493273,0.5162388731827774,0.6192587491617613,0.5645161290322581,0.5128205128205128,0.4636344070721158,0.2504653624762565,0.6226826876484352,0.5967741935483871,0.3846153846153846,0.5942238461298915,0.4727299115881062,0.6237684505989536,0.7419354838709677,0.5384615384615384
841381,zhmcclient/python-zhmcclient,zhmcclient_mock/_urihandler.py,zhmcclient_mock._urihandler.CpcSetAutoStartListHandler,"class CpcSetAutoStartListHandler:
    """"""
    Handler class for operation: Set Auto-start List.
    """"""

    @staticmethod
    def post(method, hmc, uri, uri_parms, body, logon_required,
             wait_for_completion):
        # pylint: disable=unused-argument
        """"""Operation: Set Auto-start List.""""""
        assert wait_for_completion is True  # no async
        cpc_oid = uri_parms[0]
        try:
            cpc = hmc.cpcs.lookup_by_oid(cpc_oid)
        except KeyError:
            new_exc = InvalidResourceError(method, uri)
            new_exc.__cause__ = None
            raise new_exc  # zhmcclient_mock.InvalidResourceError
        check_required_fields(method, uri, body, ['auto-start-list'])
        auto_start_list = body['auto-start-list']
        # Store it in the CPC
        cpc.properties['auto-start-list'] = auto_start_list","class CpcSetAutoStartListHandler:
    '''
    Handler class for operation: Set Auto-start List.
    '''

    @staticmethod
    def post(method, hmc, uri, uri_parms, body, logon_required,
             wait_for_completion):
    '''Operation: Set Auto-start List.'''
        pass

",3,2,snippet_757,0.8333333333333334,"class CpcSetAutoStartListHandler:
    '''
    Handler class for operation: Set Auto-start List.
    '''

    @staticmethod
    def post(method, hmc, uri, uri_parms, body, logon_required,
             wait_for_completion):
        '''Operation: Set Auto-start List.'''
        # Validate URI parameters
        if not isinstance(uri_parms, dict) or 'cpc-id' not in uri_parms:
            raise ValueError(""Missing or invalid URI parameter: cpc-id"")

        # Validate request body
        if not isinstance(body, dict) or 'auto-start-list' not in body:
            raise ValueError(""Request body must be a dict containing the 'auto-start-list' property"")

        # Send the request
        response = hmc.session.request(
            method,
            uri,
            uri_parms=uri_parms,
            body=body
        )

        # Handle the response (including re-login if needed)
        hmc._handle_response(response, logon_required)

        # This operation is synchronous; no job to wait on
        return None","class CpcSetAutoStartListHandler:
    '''
    Handler class for operation: Set Auto-start List.
    '''

    @staticmethod
    def post(method, hmc, uri, uri_parms, body, logon_required,
             wait_for_completion):
        '''Operation: Set Auto-start List.'''
        # Validate input parameters
        if not body:
            raise ValueError(""Request body is required for Set Auto-start List operation"")
        
        # Extract CPC name from URI parameters
        cpc_name = uri_parms.get('cpc-name')
        if not cpc_name:
            raise ValueError(""CPC name is required in URI parameters"")
        
        # Get the CPC object from HMC
        cpc = hmc.cpcs.get(cpc_name)
        if not cpc:
            raise ValueError(f""CPC '{cpc_name}' not found"")
        
        # Validate body structure
        if 'auto-start-list' not in body:
            raise ValueError(""Missing 'auto-start-list' in request body"")
        
        auto_start_list = body['auto-start-list']
        if not isinstance(auto_start_list, list):
            raise ValueError(""'auto-start-list' must be a list"")
        
        # Process each entry in the auto-start list
        processed_list = []
        for entry in auto_start_list:
            if not isinstance(entry, dict):
                raise ValueError(""Each auto-start list entry must be a dictionary"")
            
            # Validate required fields
            if 'type' not in entry:
                raise ValueError(""Missing 'type' field in auto-start list entry"")
            
            entry_type = entry['type']
            if entry_type == 'partition':
                if 'partition-uri' not in entry:
                    raise ValueError(""Missing 'partition-uri' for partition type entry"")
                # Validate partition URI exists
                partition_uri = entry['partition-uri']
                # Add validation logic for partition existence if needed
            elif entry_type == 'partition-group':
                if 'name' not in entry:
                    raise ValueError(""Missing 'name' for partition-group type entry"")
            else:
                raise ValueError(f""Unsupported auto-start list entry type: {entry_type}"")
            
            processed_list.append(entry)
        
        # Set the auto-start list on the CPC
        cpc.auto_start_list = processed_list
        
        # Return success response
        return {
            'status': 'ok'
        }","class CpcSetAutoStartListHandler:
    '''
    Handler class for operation: Set Auto-start List.
    '''

    @staticmethod
    def post(method, hmc, uri, uri_parms, body, logon_required,
             wait_for_completion):
        '''Operation: Set Auto-start List.'''
        # Extract CPC object-id from URI
        cpc_oid = uri_parms[0]
        
        # Get the CPC object
        cpc = hmc.cpcs.lookup_by_oid(cpc_oid)
        
        # Validate that the CPC is in a valid state for this operation
        if cpc.properties.get('status') not in ['active', 'service-required']:
            raise BadRequestError(
                method, uri, 
                ""CPC is not in a valid state for setting auto-start list"")
        
        # Extract auto-start list from request body
        auto_start_list = body.get('auto-start-list', [])
        
        # Validate auto-start list entries
        for entry in auto_start_list:
            if 'partition-uri' not in entry:
                raise BadRequestError(
                    method, uri,
                    ""Auto-start list entry missing required 'partition-uri' field"")
            
            partition_uri = entry['partition-uri']
            try:
                # Validate that the partition exists and belongs to this CPC
                partition_oid = partition_uri.split('/')[-1]
                partition = cpc.partitions.lookup_by_oid(partition_oid)
            except KeyError:
                raise BadRequestError(
                    method, uri,
                    f""Partition with URI '{partition_uri}' not found"")
        
        # Update the CPC's auto-start list
        cpc.properties['auto-start-list'] = auto_start_list
        
        # Return success response
        return {}",partial_docstr,0.47321428571428575,0.2972972972972973,0.24545454545454545,0.40178571428571425,0.34417885470572196,0.5355191256830601,0.3131868131868132,0.2430939226519337,0.8174559473991394,0.8397138118743896,0.8284353613853455,0.8374336361885071,0.766357476635514,0.3333333333333333,0.24607329842931938,0.18947368421052632,0.296875,0.20458560899539957,0.34299516908212563,0.17433414043583534,0.14320388349514562,0.7863847017288208,0.8514474630355835,0.8176237940788269,0.844460666179657,0.7502969611307428,0.5016722408026756,0.39057239057239057,0.311864406779661,0.4414715719063545,0.35561424512193196,0.48344370860927155,0.33222591362126247,0.28,0.8279988765716553,0.8768602013587952,0.8517293930053711,0.8717160820960999,0.800358502673797,0.2890419545673328,0.1566655893268891,0.2399062693464824,0.2444444444444444,0.5151515151515151,0.3140848063122122,0.0771913479976328,0.2639963620997007,0.4,0.5151515151515151,0.3730088075143228,0.1293980284529993,0.2979907369578275,0.4888888888888889,0.5757575757575758
369703,etcher-be/emiz,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/etcher-be_emiz/emiz/mission.py,emiz.mission.Group.Route.Point,"class Point:
    """"""
    Represents a waypoint
    """"""

    def __init__(self, parent_route):
        self.parent_route = parent_route

    def __repr__(self):
        return 'Route({})'.format(self.parent_route.parent_group.group_name)
","class Point:
    '''
    Represents a waypoint
    '''


    def __init__(self, parent_route):
        pass


    def __repr__(self):
        pass

",3,1,snippet_425,1.0,"class Point:
    '''
    Represents a waypoint
    '''
    def __init__(self, parent_route):
        self.parent_route = parent_route

    def __repr__(self):
        return f""Point(parent_route={self.parent_route!r})""","class Point:
    '''
    Represents a waypoint
    '''


    def __init__(self, parent_route):
        self.parent_route = parent_route


    def __repr__(self):
        return f""Point(parent_route={self.parent_route})""","class Point:
    '''
    Represents a waypoint
    '''

    def __init__(self, parent_route):
        self.parent_route = parent_route
        self.x = 0
        self.y = 0
        self.name = """"

    def __repr__(self):
        return f""Point(x={self.x}, y={self.y}, name='{self.name}')""",partial_docstr,0.8727272727272727,0.7547169811320754,0.7058823529411765,0.8363636363636364,0.6451030560931029,0.8709677419354839,0.7213114754098361,0.6333333333333333,0.9539933204650879,0.9424421787261963,0.9481825828552246,0.9435847401618958,0.9126992857142857,0.888888888888889,0.7692307692307692,0.7199999999999999,0.8518518518518519,0.6418847014066047,0.9,0.7457627118644068,0.6551724137931034,0.9656102657318115,0.9424870610237122,0.9539085626602173,0.9447494149208069,0.9126992857142857,0.6363636363636364,0.53125,0.48387096774193544,0.6363636363636364,0.48091348845528076,0.6222222222222222,0.449438202247191,0.3977272727272727,0.8784456849098206,0.9277805089950562,0.902439296245575,0.9225990772247314,0.8181836363636363,0.5822139708874453,0.5997820163128024,0.6147881529512643,0.4,0.7142857142857143,0.5822139708874453,0.5997820163128024,0.6147881529512643,0.4,0.7142857142857143,0.4379146967409262,0.2676032275663791,0.4697698451116114,0.3,0.7142857142857143
632982,paramiko/paramiko,paramiko_paramiko/paramiko/server.py,paramiko.server.InteractiveQuery,"class InteractiveQuery:
    """"""
    A query (set of prompts) for a user during interactive authentication.
    """"""

    def __init__(self, name="""", instructions="""", *prompts):
        """"""
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.

        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        """"""
        self.name = name
        self.instructions = instructions
        self.prompts = []
        for x in prompts:
            if isinstance(x, str):
                self.add_prompt(x)
            else:
                self.add_prompt(x[0], x[1])

    def add_prompt(self, prompt, echo=True):
        """"""
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.

        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        """"""
        self.prompts.append((prompt, echo))","class InteractiveQuery:
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name="""", instructions="""", *prompts):
    '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.

        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        pass

    def add_prompt(self, prompt, echo=True):
    '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.

        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        pass

",3,3,snippet_537,1.0,"class InteractiveQuery:
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name="""", instructions="""", *prompts):
        '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.

        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        self.name = name
        self.instructions = instructions
        self.prompts = []  # list of dicts: {'prompt': str, 'echo': bool}

        for p in prompts:
            self.add_prompt(p, echo=True)

    def add_prompt(self, prompt, echo=True):
        '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.

        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        if not isinstance(prompt, str):
            raise TypeError(""prompt must be a string"")
        if not isinstance(echo, bool):
            raise TypeError(""echo flag must be a boolean"")

        self.prompts.append({
            'prompt': prompt,
            'echo': echo
        })","class InteractiveQuery:
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name="""", instructions="""", *prompts):
        '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.

        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        self.name = name
        self.instructions = instructions
        self.prompts = []
        
        for prompt in prompts:
            self.add_prompt(prompt)

    def add_prompt(self, prompt, echo=True):
        '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.

        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        self.prompts.append((prompt, echo))","class InteractiveQuery:
    '''
    A query (set of prompts) for a user during interactive authentication.
    '''

    def __init__(self, name="""", instructions="""", *prompts):
        '''
        Create a new interactive query to send to the client.  The name and
        instructions are optional, but are generally displayed to the end
        user.  A list of prompts may be included, or they may be added via
        the `add_prompt` method.

        :param str name: name of this query
        :param str instructions:
            user instructions (usually short) about this query
        :param str prompts: one or more authentication prompts
        '''
        self.name = name
        self.instructions = instructions
        self.prompts = []
        for prompt in prompts:
            self.add_prompt(prompt)

    def add_prompt(self, prompt, echo=True):
        '''
        Add a prompt to this query.  The prompt should be a (reasonably short)
        string.  Multiple prompts can be added to the same query.

        :param str prompt: the user prompt
        :param bool echo:
            ``True`` (default) if the user's response should be echoed;
            ``False`` if not (for a password or similar)
        '''
        self.prompts.append((prompt, echo))",partial_docstr,0.8823529411764706,0.8333333333333334,0.8054054054054054,0.8609625668449198,0.7606807389132711,0.8270440251572327,0.750788643533123,0.7088607594936709,0.9424355626106262,0.9653573632240295,0.9537587761878967,0.9630150198936462,0.8371517557251907,0.9585798816568047,0.9345238095238095,0.9161676646706587,0.9585798816568047,0.806336833195627,0.9725490196078431,0.937007874015748,0.9011857707509882,0.978805422782898,0.9603589177131653,0.9694944024085999,0.962172269821167,0.9339629245283019,0.9585798816568047,0.9345238095238095,0.9161676646706587,0.9585798816568047,0.806336833195627,0.9725490196078431,0.937007874015748,0.9011857707509882,0.97818922996521,0.959814190864563,0.9689146280288696,0.9616206288337708,0.9339629245283019,0.708172622014497,0.71356631732309,0.841449464488763,0.4897959183673469,0.7878787878787878,0.7590340535428739,0.8424967952021222,0.8436084975098805,0.6530612244897959,0.696969696969697,0.7590340535428739,0.8424967952021222,0.8436084975098805,0.6530612244897959,0.696969696969697
604329,numenta/nupic,numenta_nupic/src/nupic/frameworks/opf/opf_task_driver.py,nupic.frameworks.opf.opf_task_driver._PhaseManager,"class _PhaseManager(object):
  """""" Manages iteration cycle phase drivers
  """"""
  def __init__(self, model, phaseSpecs):
    """"""
    model:   Model instance
    phaseSpecs:   Iteration period description consisting of a sequence of
                  IterationPhaseSpecXXXXX elements that are performed in the
                  given order
    """"""

    self.__model = model

    # Instantiate Iteration Phase drivers
    self.__phases = tuple(map(lambda x: x._getImpl(model=model),
                              phaseSpecs))

    # Init phase-management structures
    if self.__phases:
      self.__phaseCycler = itertools.cycle(self.__phases)
      self.__advancePhase()

    return


  def __repr__(self):
    return ""%s(phases=%r)"" % \
                (self.__class__.__name__,
                 self.__phases)


  def __advancePhase(self):
    """""" Advance to the next iteration cycle phase
    """"""
    self.__currentPhase = self.__phaseCycler.next()
    self.__currentPhase.enterPhase()

    return


  def handleInputRecord(self, inputRecord):
    """""" Processes the given record according to the current phase

    inputRecord:  record object formatted according to
                  nupic.data.FileSource.getNext() result format.

    Returns:      An opf_utils.ModelResult object with the inputs and inferences
                  after the current record is processed by the model
    """"""

    results = self.__model.run(inputRecord)

    shouldContinue = self.__currentPhase.advance()
    if not shouldContinue:
      self.__advancePhase()

    return results","class _PhaseManager(object):
    ''' Manages iteration cycle phase drivers
  '''

  def __init__(self, model, phaseSpecs):
    '''
    model:   Model instance
    phaseSpecs:   Iteration period description consisting of a sequence of
                  IterationPhaseSpecXXXXX elements that are performed in the
                  given order
    '''
    pass

  def __repr__(self):
    pass

  def __advancePhase(self):
    ''' Advance to the next iteration cycle phase
    '''
    pass

  def handleInputRecord(self, inputRecord):
    ''' Processes the given record according to the current phase

    inputRecord:  record object formatted according to
                  nupic.data.FileSource.getNext() result format.

    Returns:      An opf_utils.ModelResult object with the inputs and inferences
                  after the current record is processed by the model
    '''
    pass

",5,4,snippet_641,0.5555555555555556,"class _PhaseManager(object):
    ''' Manages iteration cycle phase drivers
    '''

    def __init__(self, model, phaseSpecs):
        '''
        model:     Model instance
        phaseSpecs: Sequence of IterationPhaseSpecXXXXX elements
                    that are performed in the given order
        '''
        self.model = model
        self.phaseSpecs = list(phaseSpecs)
        self._numPhases = len(self.phaseSpecs)
        self._phaseIndex = 0
        self._recordsInPhase = 0

        # call onStart of first phase if provided
        first_spec = self.phaseSpecs[0] if self._numPhases > 0 else None
        if first_spec is not None:
            if hasattr(first_spec, ""onStart""):
                first_spec.onStart(self.model)
            elif hasattr(first_spec, ""start""):
                first_spec.start(self.model)

    def __repr__(self):
        return ""<_PhaseManager phase={}/{} recordsInPhase={}>"".format(
            self._phaseIndex + 1,
            self._numPhases,
            self._recordsInPhase
        )

    def __advancePhase(self):
        ''' Advance to the next iteration cycle phase '''
        if self._numPhases == 0:
            return

        # finish current phase
        cur = self.phaseSpecs[self._phaseIndex]
        if hasattr(cur, ""onFinish""):
            cur.onFinish(self.model)
        elif hasattr(cur, ""finish""):
            cur.finish(self.model)

        # advance index
        self._phaseIndex = (self._phaseIndex + 1) % self._numPhases
        self._recordsInPhase = 0

        # start next phase
        nxt = self.phaseSpecs[self._phaseIndex]
        if hasattr(nxt, ""onStart""):
            nxt.onStart(self.model)
        elif hasattr(nxt, ""start""):
            nxt.start(self.model)

    def handleInputRecord(self, inputRecord):
        ''' Processes the given record according to the current phase

        inputRecord:  record object formatted according to
                      nupic.data.FileSource.getNext() result format.

        Returns:      An opf_utils.ModelResult object
                      after processing this record
        '''
        if self._numPhases == 0:
            # no phases; just run the model
            if hasattr(self.model, ""run""):
                return self.model.run(inputRecord)
            elif hasattr(self.model, ""runRecord""):
                return self.model.runRecord(inputRecord)
            else:
                raise RuntimeError(""Model has no run method"")

        spec = self.phaseSpecs[self._phaseIndex]

        # process the record via spec or directly via model
        if hasattr(spec, ""processRecord""):
            result = spec.processRecord(self.model, inputRecord)
        elif hasattr(spec, ""runRecord""):
            result = spec.runRecord(self.model, inputRecord)
        else:
            # fallback to model
            if hasattr(self.model, ""run""):
                result = self.model.run(inputRecord)
            elif hasattr(self.model, ""runRecord""):
                result = self.model.runRecord(inputRecord)
            else:
                raise RuntimeError(""Neither spec nor model can run inputRecord"")

        # update counter
        self._recordsInPhase += 1

        # check for phase completion
        done = False
        # by explicit length
        if hasattr(spec, ""length""):
            done = self._recordsInPhase >= spec.length
        elif hasattr(spec, ""period""):
            done = self._recordsInPhase >= spec.period
        elif hasattr(spec, ""isComplete""):
            try:
                done = spec.isComplete(self._recordsInPhase)
            except TypeError:
                done = spec.isComplete()

        if done:
            self.__advancePhase()

        return result","class _PhaseManager(object):
    ''' Manages iteration cycle phase drivers
  '''

    def __init__(self, model, phaseSpecs):
        '''
        model:   Model instance
        phaseSpecs:   Iteration period description consisting of a sequence of
                      IterationPhaseSpecXXXXX elements that are performed in the
                      given order
        '''
        self.model = model
        self.phaseSpecs = phaseSpecs
        self.currentPhaseIndex = 0
        self.currentPhase = phaseSpecs[0] if phaseSpecs else None

    def __repr__(self):
        return f""_PhaseManager(currentPhaseIndex={self.currentPhaseIndex}, "" \
               f""totalPhases={len(self.phaseSpecs)})""

    def __advancePhase(self):
        ''' Advance to the next iteration cycle phase
        '''
        self.currentPhaseIndex += 1
        if self.currentPhaseIndex < len(self.phaseSpecs):
            self.currentPhase = self.phaseSpecs[self.currentPhaseIndex]
        else:
            self.currentPhase = None

    def handleInputRecord(self, inputRecord):
        ''' Processes the given record according to the current phase

        inputRecord:  record object formatted according to
                      nupic.data.FileSource.getNext() result format.

        Returns:      An opf_utils.ModelResult object with the inputs and inferences
                      after the current record is processed by the model
        '''
        if self.currentPhase is None:
            return None
            
        result = self.currentPhase.processRecord(self.model, inputRecord)
        
        # Check if current phase is complete and advance if needed
        if self.currentPhase.isComplete():
            self.__advancePhase()
            
        return result","class _PhaseManager(object):
    ''' Manages iteration cycle phase drivers
    '''

    def __init__(self, model, phaseSpecs):
        '''
        model:   Model instance
        phaseSpecs:   Iteration period description consisting of a sequence of
                      IterationPhaseSpecXXXXX elements that are performed in the
                      given order
        '''
        self._model = model
        self._phaseSpecs = phaseSpecs
        self._currentPhaseIndex = 0
        self._currentPhaseIterationCount = 0
        
        if not phaseSpecs:
            raise ValueError(""phaseSpecs cannot be empty"")

    def __repr__(self):
        return ""PhaseManager(currentPhase=%d, phaseCount=%d, currentIteration=%d)"" % (
            self._currentPhaseIndex, 
            len(self._phaseSpecs), 
            self._currentPhaseIterationCount
        )

    def __advancePhase(self):
        ''' Advance to the next iteration cycle phase
        '''
        self._currentPhaseIndex = (self._currentPhaseIndex + 1) % len(self._phaseSpecs)
        self._currentPhaseIterationCount = 0

    def handleInputRecord(self, inputRecord):
        ''' Processes the given record according to the current phase

        inputRecord:  record object formatted according to
                      nupic.data.FileSource.getNext() result format.

        Returns:      An opf_utils.ModelResult object with the inputs and inferences
                      after the current record is processed by the model
        '''
        currentPhase = self._phaseSpecs[self._currentPhaseIndex]
        
        # Process the record based on current phase settings
        if hasattr(currentPhase, 'enableLearning'):
            self._model.enableLearning = currentPhase.enableLearning
        if hasattr(currentPhase, 'enableInference'):
            self._model.enableInference = currentPhase.enableInference
            
        # Run the model on the input record
        result = self._model.run(inputRecord)
        
        # Update iteration count and check if we need to advance phase
        self._currentPhaseIterationCount += 1
        
        if (hasattr(currentPhase, 'iterationCount') and 
            currentPhase.iterationCount is not None and
            self._currentPhaseIterationCount >= currentPhase.iterationCount):
            self.__advancePhase()
            
        return result",partial_docstr,0.43820224719101125,0.2932330827067669,0.26037735849056604,0.3857677902621723,0.24741740245207183,0.3731138545953361,0.22527472527472528,0.18019257221458046,0.7899340391159058,0.8644633889198303,0.8255199790000916,0.8563835620880127,0.7438188162544174,0.7371601208459213,0.6200607902735562,0.5565749235474007,0.6948640483383686,0.5124708845447901,0.7534722222222222,0.5714285714285714,0.46503496503496505,0.8981316685676575,0.8964763283729553,0.8973032236099243,0.8966414928436279,0.811113,0.6773333333333332,0.5361930294906166,0.49595687331536387,0.6133333333333333,0.5180777509899606,0.6693121693121693,0.5039787798408488,0.4122340425531915,0.8501019477844238,0.8840665817260742,0.8667516708374023,0.8805484175682068,0.7979818181818181,0.4459928789739082,0.1667443560225969,0.3862577389231337,0.5517241379310345,0.6792452830188679,0.4965575603362401,0.4856826859697053,0.5419702402592279,0.5057471264367817,0.4528301886792453,0.5183603938488692,0.3774338247261483,0.5446306090514583,0.5287356321839081,0.6226415094339622
745280,sony/nnabla,python/src/nnabla/experimental/parametric_function_class/module.py,nnabla.experimental.parametric_function_class.module.Module,"class Module(object):
    """"""Module mix-in for the parametric function classes.
    """"""

    def __init__(self):
        pass

    def get_parameters(self, grad_only=True):
        """"""Get parameters.
        Args:
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
            If you set this option as `False`, All parameters are returned. Default is `True`.
        Returns:
            dict: The dictionary of parameter name (`str`) to Variable (:obj:`~nnabla.Variable`).
        """"""
        params = OrderedDict()

        for v in self.get_modules():
            if not isinstance(v, tuple):
                continue
            prefix, module = v
            for k, v in module.__dict__.items():
                if not isinstance(v, nn.Variable):
                    continue
                pname = k
                name = ""{}/{}"".format(prefix, pname)
                if grad_only and v.need_grad == False:
                    continue
                params[name] = v
        return params

    def get_modules(self, memo=None, prefix=""""):
        """"""Get modules.

        This function is internally used as the helper method for other methods.

        Args: 
            memo (set, optional): Module set in order to memorize to visit.
            prefix (str, optional): Prefix to a specific parameter name.

        Yields:
            `Module`: The module class.
        """"""
        if memo is None:
            memo = set()

        if self not in memo:
            memo.add(self)
            yield prefix, self
            for k, v in self.__dict__.items():
                if not isinstance(v, Module):
                    continue
                name, module = k, v
                submodule_prefix = ""{}/{}"".format(prefix,
                                                  name) if prefix != """" else name
                for m in module.get_modules(memo, submodule_prefix):
                    yield m

    def save_parameters(self, path, grad_only=False):
        """"""Save all parameters into a file with the specified format.

        Currently hdf5 and protobuf formats are supported.

        Args:
            path : path or file object
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
        """"""
        params = self.get_parameters(grad_only=grad_only)
        nn.save_parameters(path, params)

    def load_parameters(self, path):
        """"""Load parameters from a file with the specified format.

        Args:
            path : path or file object
        """"""
        nn.load_parameters(path)
        for v in self.get_modules():
            if not isinstance(v, tuple):
                continue
            prefix, module = v
            for k, v in module.__dict__.items():
                if not isinstance(v, nn.Variable):
                    continue
                pname = k
                name = ""{}/{}"".format(prefix, pname)
                # Substitute
                param0 = v
                param1 = nn.parameter.pop_parameter(name)
                if param0 is None:
                    raise ValueError(
                        ""Model does not have {} parameter."".format(name))
                param0.d = param1.d.copy()
                nn.logger.info(""`{}` loaded.)"".format(name))","class Module(object):
    '''Module mix-in for the parametric function classes.
    '''

    def __init__(self):
        pass

    def get_parameters(self, grad_only=True):
    '''Get parameters.
        Args:
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
            If you set this option as `False`, All parameters are returned. Default is `True`.
        Returns:
            dict: The dictionary of parameter name (`str`) to Variable (:obj:`~nnabla.Variable`).
        '''
        pass

    def get_modules(self, memo=None, prefix=""""):
    '''Get modules.

        This function is internally used as the helper method for other methods.

        Args: 
            memo (set, optional): Module set in order to memorize to visit.
            prefix (str, optional): Prefix to a specific parameter name.

        Yields:
            `Module`: The module class.
        '''
        pass

    def save_parameters(self, path, grad_only=False):
    '''Save all parameters into a file with the specified format.

        Currently hdf5 and protobuf formats are supported.

        Args:
            path : path or file object
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
        '''
        pass

    def load_parameters(self, path):
    '''Load parameters from a file with the specified format.

        Args:
            path : path or file object
        '''
        pass

",6,5,snippet_662,0.2368421052631578,"class Module(object):
    '''Module mix-in for the parametric function classes.
    '''

    def __init__(self):
        super(Module, self).__init__()

    def get_parameters(self, grad_only=True):
        params = {}
        for prefix, module in self.get_modules(prefix=""""):
            for name, val in module.__dict__.items():
                if isinstance(val, nn.Variable):
                    if not grad_only or val.need_grad:
                        params[prefix + name] = val
        return params

    def get_modules(self, memo=None, prefix=""""):
        if memo is None:
            memo = set()
        if self in memo:
            return
        memo.add(self)
        yield prefix, self
        for name, val in self.__dict__.items():
            if isinstance(val, Module):
                sub_prefix = prefix + name + "".""
                for item in val.get_modules(memo, sub_prefix):
                    yield item

    def save_parameters(self, path, grad_only=False):
        params = self.get_parameters(grad_only)
        save_parameters(params, path)

    def load_parameters(self, path):
        params = self.get_parameters(grad_only=False)
        nnabla_load_parameters(path, params)","class Module(object):
    '''Module mix-in for the parametric function classes.
    '''

    def __init__(self):
        pass

    def get_parameters(self, grad_only=True):
        '''Get parameters.
        Args:
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
            If you set this option as `False`, All parameters are returned. Default is `True`.
        Returns:
            dict: The dictionary of parameter name (`str`) to Variable (:obj:`~nnabla.Variable`).
        '''
        parameters = {}
        for module in self.get_modules():
            if hasattr(module, '_parameters'):
                for name, param in module._parameters.items():
                    if param is not None:
                        if not grad_only or param.need_grad:
                            parameters[name] = param
        return parameters

    def get_modules(self, memo=None, prefix=""""):
        '''Get modules.

        This function is internally used as the helper method for other methods.

        Args: 
            memo (set, optional): Module set in order to memorize to visit.
            prefix (str, optional): Prefix to a specific parameter name.

        Yields:
            `Module`: The module class.
        '''
        if memo is None:
            memo = set()
        if self not in memo:
            memo.add(self)
            yield self
            for name in dir(self):
                if not name.startswith('_'):
                    attr = getattr(self, name)
                    if isinstance(attr, Module):
                        for module in attr.get_modules(memo, prefix + name + '.'):
                            yield module

    def save_parameters(self, path, grad_only=False):
        '''Save all parameters into a file with the specified format.

        Currently hdf5 and protobuf formats are supported.

        Args:
            path : path or file object
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
        '''
        import nnabla
        parameters = self.get_parameters(grad_only=grad_only)
        nnabla.save_parameters(path, parameters)

    def load_parameters(self, path):
        '''Load parameters from a file with the specified format.

        Args:
            path : path or file object
        '''
        import nnabla
        parameters = nnabla.load_parameters(path)
        for name, param in parameters.items():
            # Assuming parameters are loaded into the appropriate modules
            # This is a simplified implementation - in practice, you'd need
            # to map parameter names to the correct module attributes
            pass","class Module(object):
    '''Module mix-in for the parametric function classes.
    '''

    def __init__(self):
        self._modules = OrderedDict()
        self._parameters = OrderedDict()

    def get_parameters(self, grad_only=True):
        '''Get parameters.
        Args:
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
            If you set this option as `False`, All parameters are returned. Default is `True`.
        Returns:
            dict: The dictionary of parameter name (`str`) to Variable (:obj:`~nnabla.Variable`).
        '''
        params = OrderedDict()
        for name, module in self.get_modules():
            for param_name, param in module._parameters.items():
                if param is not None:
                    if not grad_only or (hasattr(param, 'need_grad') and param.need_grad):
                        full_name = name + '.' + param_name if name else param_name
                        params[full_name] = param
        return params

    def get_modules(self, memo=None, prefix=""""):
        '''Get modules.

        This function is internally used as the helper method for other methods.

        Args: 
            memo (set, optional): Module set in order to memorize to visit.
            prefix (str, optional): Prefix to a specific parameter name.

        Yields:
            `Module`: The module class.
        '''
        if memo is None:
            memo = set()
        
        if self not in memo:
            memo.add(self)
            yield prefix, self
            
            for name, module in self._modules.items():
                if module is None:
                    continue
                submodule_prefix = prefix + ('.' if prefix else '') + name
                for m in module.get_modules(memo, submodule_prefix):
                    yield m

    def save_parameters(self, path, grad_only=False):
        '''Save all parameters into a file with the specified format.

        Currently hdf5 and protobuf formats are supported.

        Args:
            path : path or file object
            grad_only (bool, optional): Return parameters with `need_grad` option as `True`. 
        '''
        params = self.get_parameters(grad_only=grad_only)
        
        if isinstance(path, str):
            if path.endswith('.h5') or path.endswith('.hdf5'):
                with h5py.File(path, 'w') as f:
                    for name, param in params.items():
                        f.create_dataset(name, data=param.d if hasattr(param, 'd') else param)
            else:
                with open(path, 'wb') as f:
                    param_dict = {name: param.d if hasattr(param, 'd') else param for name, param in params.items()}
                    pickle.dump(param_dict, f)
        else:
            param_dict = {name: param.d if hasattr(param, 'd') else param for name, param in params.items()}
            pickle.dump(param_dict, path)

    def load_parameters(self, path):
        '''Load parameters from a file with the specified format.

        Args:
            path : path or file object
        '''
        current_params = self.get_parameters(grad_only=False)
        
        if isinstance(path, str):
            if path.endswith('.h5') or path.endswith('.hdf5'):
                with h5py.File(path, 'r') as f:
                    for name in f.keys():
                        if name in current_params:
                            if hasattr(current_params[name], 'd'):
                                current_params[name].d[...] = f[name][...]
                            else:
                                current_params[name] = f[name][...]
            else:
                with open(path, 'rb') as f:
                    loaded_params = pickle.load(f)
                    for name, value in loaded_params.items():
                        if name in current_params:
                            if hasattr(current_params[name], 'd'):
                                current_params[name].d[...] = value
                            else:
                                current_params[name] = value
        else:
            loaded_params = pickle.load(path)
            for name, value in loaded_params.items():
                if name in current_params:
                    if hasattr(current_params[name], 'd'):
                        current_params[name].d[...] = value
                    else:
                        current_params[name] = value",partial_docstr,0.5068762278978388,0.3392504930966469,0.2336633663366337,0.444007858546169,0.1759957015919552,0.9243986254295533,0.7241379310344828,0.5778546712802768,0.9144840836524963,0.7943503856658936,0.8501944541931152,0.804924488067627,0.7993386567164181,0.7715133531157271,0.6279761904761905,0.5761194029850747,0.7210682492581602,0.5238125885901396,0.8653846153846154,0.7244701348747592,0.6602316602316602,0.9131690263748169,0.8843194246292114,0.8985126614570618,0.8871220946311951,0.8150930597014927,0.6566820276497696,0.5357967667436491,0.48842592592592593,0.6082949308755761,0.4719183828392606,0.5955176093916755,0.45085470085470086,0.39144385026737966,0.8725235462188721,0.8975924253463745,0.8848804831504822,0.8950208425521851,0.776412492307692,0.2254494709306091,0.042018026756367,0.1104715211915682,0.4976076555023923,0.2517006802721088,0.4673124551723556,0.5007781426816643,0.5136072441959559,0.5215311004784688,0.3333333333333333,0.515442158073848,0.4301990293984148,0.5600596592065823,0.5885167464114832,0.4829931972789115
337730,dev-pipeline/dev-pipeline-core,dev-pipeline_dev-pipeline-core/lib/devpipeline_core/toolsupport.py,devpipeline_core.toolsupport._NullJoiner,"class _NullJoiner:
    """"""A class to handle non-joinable values.""""""

    # pylint: disable=too-few-public-methods
    def __init__(self, component_name, key):
        self._component_name = component_name
        self._key = key

    def join(self, vals):
        """"""
        Either return the non-list value or raise an Exception.

        Arguments:
        vals - a list of values to process
        """"""
        if len(vals) == 1:
            return vals[0]
        raise Exception(
            ""Too many values for {}:{}"".format(self._component_name, self._key)
        )","class _NullJoiner:
    '''A class to handle non-joinable values.'''

    def __init__(self, component_name, key):
        pass

    def join(self, vals):
    '''
        Either return the non-list value or raise an Exception.

        Arguments:
        vals - a list of values to process
        '''
        pass

",3,2,snippet_345,1.0,"class _NullJoiner:
    '''A class to handle non-joinable values.'''

    def __init__(self, component_name, key):
        self.component_name = component_name
        self.key = key

    def join(self, vals):
        '''
        Either return the non-list value or raise an Exception.

        Arguments:
        vals - a list of values to process
        '''
        non_null = [v for v in vals if v is not None]
        if not non_null:
            return None
        if len(non_null) == 1:
            val = non_null[0]
            if isinstance(val, list):
                raise Exception(
                    f""Cannot join list for component '{self.component_name}' ""
                    f""and key '{self.key}': got list {val}""
                )
            return val
        raise Exception(
            f""Multiple non-null values for component '{self.component_name}' ""
            f""and key '{self.key}': {non_null}""
        )","class _NullJoiner:
    '''A class to handle non-joinable values.'''

    def __init__(self, component_name, key):
        self.component_name = component_name
        self.key = key

    def join(self, vals):
        '''
        Either return the non-list value or raise an Exception.

        Arguments:
        vals - a list of values to process
        '''
        if len(vals) == 1:
            return vals[0]
        elif len(vals) == 0:
            raise Exception(f""No values to join for {self.component_name}.{self.key}"")
        else:
            raise Exception(f""Multiple values found for non-joinable field {self.component_name}.{self.key}: {vals}"")","class _NullJoiner:
    '''A class to handle non-joinable values.'''

    def __init__(self, component_name, key):
        self.component_name = component_name
        self.key = key

    def join(self, vals):
        '''
        Either return the non-list value or raise an Exception.

        Arguments:
        vals - a list of values to process
        '''
        if len(vals) == 1:
            return vals[0]
        else:
            raise Exception(f""Cannot join multiple values for {self.component_name}.{self.key}"")",partial_docstr,0.6451612903225806,0.532608695652174,0.4615384615384615,0.6236559139784946,0.4193514282402594,0.5833333333333334,0.39901477832512317,0.31683168316831684,0.862007200717926,0.9014121294021606,0.8812693357467651,0.8973102569580078,0.8153864615384615,0.782051282051282,0.7272727272727274,0.6973684210526316,0.782051282051282,0.5823431903905464,0.7320261437908496,0.5657894736842105,0.4768211920529801,0.9423356056213379,0.9169934988021851,0.9294918179512024,0.9194662570953369,0.8571442857142857,0.8970588235294117,0.835820895522388,0.7727272727272727,0.8970588235294117,0.6398038580770103,0.9210526315789473,0.7522123893805309,0.6428571428571429,0.968479335308075,0.9233506917953491,0.9453767538070679,0.9276734590530396,0.9285721428571428,0.4823759500517641,0.2843562457761261,0.5040185221728659,0.5161290322580645,0.625,0.5237342941207282,0.4617631347832006,0.5525288804093896,0.5806451612903226,0.5,0.5437054666133766,0.5376291681480367,0.556547537015147,0.5806451612903226,0.5
134851,JasonKessler/scattertext,/Users/umroot/Documents/PhD_works/PhD-Core-Contents/Class-level-dataset-curation/data/git_repos_for_analysis/JasonKessler_scattertext/scattertext/domain/CombineDocsIntoDomains.py,scattertext.domain.CombineDocsIntoDomains.CombineDocsIntoDomains,"class CombineDocsIntoDomains(object):
    def __init__(self, term_doc_matrix):
        '''
        Parameters
        ----------
        term_doc_matrix : TermDocMatrix
        '''
        self.term_doc_matrix = term_doc_matrix

    def get_new_term_doc_mat(self, doc_domains, non_text: bool = False):
        '''
        Combines documents together that are in the same domain

        Parameters
        ----------
        doc_domains : array-like
        non_text: bool

        Returns
        -------
        scipy.sparse.csr_matrix


        '''
        assert len(doc_domains) == self.term_doc_matrix.get_num_docs()
        doc_domain_set = set(doc_domains)
        num_terms = self.term_doc_matrix.get_num_metadata(
        ) if non_text else self.term_doc_matrix.get_num_terms()
        num_domains = len(doc_domain_set)
        domain_mat = lil_matrix((num_domains, num_terms), dtype=int)
        X = self.term_doc_matrix.get_metadata_doc_mat(
        ) if non_text else self.term_doc_matrix.get_term_doc_mat()
        for i, domain in enumerate(doc_domain_set):
            domain_mat[i, :] = X[np.array(doc_domains == domain)].sum(axis=0)
        return domain_mat.tocsr()","class CombineDocsIntoDomains(object):


    def __init__(self, term_doc_matrix):
    '''
        Parameters
        ----------
        term_doc_matrix : TermDocMatrix
        '''
        pass


    def get_new_term_doc_mat(self, doc_domains, non_text: bool = False):
    '''
        Combines documents together that are in the same domain

        Parameters
        ----------
        doc_domains : array-like
        non_text: bool

        Returns
        -------
        scipy.sparse.csr_matrix


        '''
        pass

",3,2,snippet_393,0.2727272727272727,"class CombineDocsIntoDomains(object):
    def __init__(self, term_doc_matrix):
        """"""
        Parameters
        ----------
        term_doc_matrix : TermDocMatrix
        """"""
        self.tdm = term_doc_matrix

    def get_new_term_doc_mat(self, doc_domains, non_text: bool = False):
        """"""
        Combines documents together that are in the same domain

        Parameters
        ----------
        doc_domains : array-like
        non_text: bool

        Returns
        -------
        scipy.sparse.csr_matrix
        """"""
        domains = np.array(doc_domains)
        unique_domains, inverse = np.unique(domains, return_inverse=True)

        if non_text:
            if not hasattr(self.tdm, 'non_text_mat'):
                raise AttributeError(""TermDocMatrix has no attribute 'non_text_mat'"")
            mat = self.tdm.non_text_mat
        else:
            if not hasattr(self.tdm, 'mat'):
                raise AttributeError(""TermDocMatrix has no attribute 'mat'"")
            mat = self.tdm.mat

        cols = []
        for i in range(len(unique_domains)):
            idx = np.where(inverse == i)[0]
            sub = mat[:, idx]
            # sum over the document axis (columns)
            summed = sub.sum(axis=1)
            arr = np.array(summed)
            col = csr_matrix(arr)
            cols.append(col)

        new_mat = hstack(cols, format='csr')
        return new_mat","class CombineDocsIntoDomains(object):

    def __init__(self, term_doc_matrix):
        '''
        Parameters
        ----------
        term_doc_matrix : TermDocMatrix
        '''
        self.term_doc_matrix = term_doc_matrix

    def get_new_term_doc_mat(self, doc_domains, non_text: bool = False):
        '''
        Combines documents together that are in the same domain

        Parameters
        ----------
        doc_domains : array-like
        non_text: bool

        Returns
        -------
        scipy.sparse.csr_matrix
        '''
        import numpy as np
        from scipy.sparse import csr_matrix
        
        # Get the original term-document matrix
        if non_text:
            orig_term_doc_mat = self.term_doc_matrix.get_metadata_term_doc_mat()
        else:
            orig_term_doc_mat = self.term_doc_matrix.get_term_doc_mat()
        
        # Convert doc_domains to numpy array
        doc_domains = np.array(doc_domains)
        
        # Get unique domains
        unique_domains = np.unique(doc_domains)
        
        # Create mapping from domain to column indices
        domain_to_indices = {}
        for domain in unique_domains:
            domain_to_indices[domain] = np.where(doc_domains == domain)[0]
        
        # Create new matrix by summing columns for each domain
        new_columns = []
        for domain in unique_domains:
            indices = domain_to_indices[domain]
            # Sum the columns corresponding to this domain
            domain_column = orig_term_doc_mat[:, indices].sum(axis=1)
            new_columns.append(domain_column)
        
        # Stack the columns to create the new matrix
        if new_columns:
            new_term_doc_mat = csr_matrix(np.hstack(new_columns))
        else:
            # If no columns, return empty matrix with appropriate shape
            new_term_doc_mat = csr_matrix((orig_term_doc_mat.shape[0], 0))
        
        return new_term_doc_mat","class CombineDocsIntoDomains(object):

    def __init__(self, term_doc_matrix):
        '''
        Parameters
        ----------
        term_doc_matrix : TermDocMatrix
        '''
        self.term_doc_matrix = term_doc_matrix

    def get_new_term_doc_mat(self, doc_domains, non_text: bool = False):
        '''
        Combines documents together that are in the same domain

        Parameters
        ----------
        doc_domains : array-like
        non_text: bool

        Returns
        -------
        scipy.sparse.csr_matrix
        '''
        if non_text:
            X = self.term_doc_matrix.get_metadata_doc_mat()
        else:
            X = self.term_doc_matrix.get_term_doc_mat()
        
        doc_domains = np.array(doc_domains)
        unique_domains = np.unique(doc_domains)
        
        combined_matrix = []
        for domain in unique_domains:
            domain_mask = doc_domains == domain
            domain_docs = X[:, domain_mask]
            combined_domain = domain_docs.sum(axis=1)
            combined_matrix.append(combined_domain)
        
        combined_matrix = sparse.hstack(combined_matrix)
        return combined_matrix.tocsr()",partial_docstr,0.5541401273885351,0.3782051282051282,0.33548387096774196,0.47770700636942676,0.45795096142080655,0.6645161290322581,0.42394822006472493,0.3409090909090909,0.8398227691650391,0.8928417563438416,0.8655210137367249,0.8872405290603638,0.7846911483253588,0.6106870229007634,0.4296675191815857,0.3496143958868894,0.49363867684478374,0.4899142109603098,0.6217494089834515,0.47393364928909953,0.3990498812351544,0.8507780432701111,0.9078068137168884,0.8783677220344543,0.9017621874809265,0.8045394764397908,0.7632508833922261,0.5693950177935944,0.5089605734767024,0.6289752650176678,0.6162566934435897,0.9090909090909091,0.753968253968254,0.649402390438247,0.922886848449707,0.9178336262702942,0.9203532934188843,0.9183365106582642,0.8311705194805195,0.4301944404680983,0.2888136240354,0.407272779812302,0.5061728395061729,0.5185185185185185,0.4490958373377847,0.2722017535532545,0.5303544353040571,0.5308641975308642,0.4629629629629629,0.5027474116544304,0.5266186711322915,0.5275808520286397,0.5308641975308642,0.4259259259259259
361104,eevee/classtools,eevee_classtools/classtools.py,classtools.weakattr,"class weakattr(object):
    """"""Descriptor that transparently wraps its stored value in a weak
    reference.  Reading this attribute will never raise `AttributeError`; if
    the reference is broken or missing, you'll just get `None`.

    To use, create a ``weakattr`` in the class body and assign to it as normal.
    You must provide an attribute name, which is used to store the actual
    weakref in the instance dict.

    .. code-block:: python

        class Foo(object):
            bar = weakattr('bar')

            def __init__(self, bar):
                self.bar = bar

    >>> class Dummy(object): pass
    >>> obj = Dummy()
    >>> foo = Foo(obj)
    >>> assert foo.bar is obj
    >>> print(foo.bar)
    <object object at ...>
    >>> del obj
    >>> print(foo.bar)
    None

    Of course, if you try to assign a value that can't be weak referenced,
    you'll get a ``TypeError``.  So don't do that.  In particular, a lot of
    built-in types can't be weakref'd!

    Note that due to the ``__dict__`` twiddling, this descriptor will never
    trigger ``__getattr__``, ``__setattr__``, or ``__delattr__``.
    """"""
    def __init__(self, name):
        self.name = name

    def __get__(desc, self, cls):
        if self is None:
            return desc

        try:
            ref = self.__dict__[desc.name]
        except KeyError:
            return None
        else:
            value = ref()
            if value is None:
                # No sense leaving a dangling weakref around
                del self.__dict__[desc.name]
            return value

    def __set__(desc, self, value):
        self.__dict__[desc.name] = weakref.ref(value)

    def __delete__(desc, self):
        del self.__dict__[desc.name]","class weakattr(object):
    '''Descriptor that transparently wraps its stored value in a weak
    reference.  Reading this attribute will never raise `AttributeError`; if
    the reference is broken or missing, you'll just get `None`.

    To use, create a ``weakattr`` in the class body and assign to it as normal.
    You must provide an attribute name, which is used to store the actual
    weakref in the instance dict.

    .. code-block:: python

        class Foo(object):
            bar = weakattr('bar')

            def __init__(self, bar):
                self.bar = bar

    >>> class Dummy(object): pass
    >>> obj = Dummy()
    >>> foo = Foo(obj)
    >>> assert foo.bar is obj
    >>> print(foo.bar)
    <object object at ...>
    >>> del obj
    >>> print(foo.bar)
    None

    Of course, if you try to assign a value that can't be weak referenced,
    you'll get a ``TypeError``.  So don't do that.  In particular, a lot of
    built-in types can't be weakref'd!

    Note that due to the ``__dict__`` twiddling, this descriptor will never
    trigger ``__getattr__``, ``__setattr__``, or ``__delattr__``.
    '''

            def __init__(self, bar):
                        pass

    def __get__(desc, self, cls):
        pass

    def __set__(desc, self, value):
        pass

    def __delete__(desc, self):
        pass

",5,1,snippet_89,0.8181818181818182,"class weakattr(object):
    '''Descriptor that transparently wraps its stored value in a weak
    reference.  Reading this attribute will never raise `AttributeError`; if
    the reference is broken or missing, you'll just get `None`.

    To use, create a ``weakattr`` in the class body and assign to it as normal.
    You must provide an attribute name, which is used to store the actual
    weakref in the instance dict.
    '''
    def __init__(self, name):
        self.name = name
        self.storage_name = '_weak_' + name

    def __get__(self, instance, owner=None):
        if instance is None:
            return self
        wref = instance.__dict__.get(self.storage_name)
        if wref is None:
            return None
        return wref()

    def __set__(self, instance, value):
        instance.__dict__[self.storage_name] = weakref.ref(value)

    def __delete__(self, instance):
        instance.__dict__.pop(self.storage_name, None)","class weakattr(object):
    '''Descriptor that transparently wraps its stored value in a weak
    reference.  Reading this attribute will never raise `AttributeError`; if
    the reference is broken or missing, you'll just get `None`.

    To use, create a ``weakattr`` in the class body and assign to it as normal.
    You must provide an attribute name, which is used to store the actual
    weakref in the instance dict.

    .. code-block:: python

        class Foo(object):
            bar = weakattr('bar')

            def __init__(self, bar):
                self.bar = bar

    >>> class Dummy(object): pass
    >>> obj = Dummy()
    >>> foo = Foo(obj)
    >>> assert foo.bar is obj
    >>> print(foo.bar)
    <object object at ...>
    >>> del obj
    >>> print(foo.bar)
    None

    Of course, if you try to assign a value that can't be weak referenced,
    you'll get a ``TypeError``.  So don't do that.  In particular, a lot of
    built-in types can't be weakref'd!

    Note that due to the ``__dict__`` twiddling, this descriptor will never
    trigger ``__getattr__``, ``__setattr__``, or ``__delattr__``.
    '''

    def __init__(self, name):
        self.name = name

    def __get__(self, instance, cls):
        if instance is None:
            return self
        ref = instance.__dict__.get(self.name)
        if ref is None:
            return None
        return ref()

    def __set__(self, instance, value):
        if value is None:
            instance.__dict__[self.name] = None
        else:
            instance.__dict__[self.name] = weakref.ref(value)

    def __delete__(self, instance):
        instance.__dict__.pop(self.name, None)","class weakattr(object):
    '''Descriptor that transparently wraps its stored value in a weak
    reference.  Reading this attribute will never raise `AttributeError`; if
    the reference is broken or missing, you'll just get `None`.

    To use, create a ``weakattr`` in the class body and assign to it as normal.
    You must provide an attribute name, which is used to store the actual
    weakref in the instance dict.

    .. code-block:: python

        class Foo(object):
            bar = weakattr('bar')

            def __init__(self, bar):
                self.bar = bar

    >>> class Dummy(object): pass
    >>> obj = Dummy()
    >>> foo = Foo(obj)
    >>> assert foo.bar is obj
    >>> print(foo.bar)
    <object object at ...>
    >>> del obj
    >>> print(foo.bar)
    None

    Of course, if you try to assign a value that can't be weak referenced,
    you'll get a ``TypeError``.  So don't do that.  In particular, a lot of
    built-in types can't be weakref'd!

    Note that due to the ``__dict__`` twiddling, this descriptor will never
    trigger ``__getattr__``, ``__setattr__``, or ``__delattr__``.
    '''

    def __init__(self, name):
        self.name = name

    def __get__(self, instance, owner):
        if instance is None:
            return self
        weakref_obj = instance.__dict__.get(self.name)
        if weakref_obj is None:
            return None
        return weakref_obj()

    def __set__(self, instance, value):
        if value is None:
            instance.__dict__[self.name] = None
        else:
            instance.__dict__[self.name] = weakref.ref(value)

    def __delete__(self, instance):
        instance.__dict__.pop(self.name, None)",partial_docstr,0.6149584487534626,0.4623955431754875,0.4201680672268907,0.5650969529085873,0.3016988609941849,0.9012875536480687,0.7155172413793104,0.6190476190476191,0.9122220277786255,0.8045320510864258,0.8549994230270386,0.814143180847168,0.8567265789473685,0.9170305676855894,0.8070175438596491,0.775330396475771,0.868995633187773,0.8601097348966665,0.9418604651162791,0.8834498834498834,0.8200934579439252,0.972846269607544,0.9590588212013245,0.9659033417701721,0.9604199528694153,0.8757074576271185,0.9023861171366595,0.7973856209150327,0.7702407002188184,0.859002169197397,0.8534076171813161,0.9243119266055045,0.8620689655172413,0.8018433179723502,0.9674994945526123,0.9552795886993408,0.9613507390022278,0.9564877152442932,0.8757074576271185,0.4177426811328306,0.256885057683704,0.3545345903473895,0.6271186440677966,0.4324324324324324,0.71887727841165,0.788647249357754,0.7941454190300274,0.6440677966101694,0.6486486486486487,0.7096785701000673,0.7830787204647083,0.7899461417037699,0.6440677966101694,0.6216216216216216
543853,lcharleux/argiope,argiope/materials.py,argiope.materials.Material,"class Material:
    """"""
    A material meta class to rule them all.
    """"""
    _template = ""Material""

    def __init__(self, label=""Material"", **kwargs):
        self.label = label

    def get_template(self):
        return Template(open(MODPATH + ""/templates/materials/{0}.inp"".format(
            self._template)).read())

    def write_inp(self):
        """"""
        Returns the material definition as a string in Abaqus INP format.
        """"""
        template = self.get_template()
        return template.substitute({""class"": self.__class__.__name__,
                                    ""label"": self.label}).strip()","class Material:
    '''
    A material meta class to rule them all.
    '''

    def __init__(self, label=""Material"", **kwargs):
        pass

    def get_template(self):
        pass

    def write_inp(self):
    '''
        Returns the material definition as a string in Abaqus INP format.
        '''
        pass

",4,2,snippet_742,1.0,"class Material:
    '''
    A material meta class to rule them all.
    '''

    def __init__(self, label=""Material"", **kwargs):
        self.label = label
        self.properties = {}
        for key, value in kwargs.items():
            # normalize property values to tuples
            if isinstance(value, (int, float)):
                vals = (value,)
            elif isinstance(value, (list, tuple)):
                vals = tuple(value)
            else:
                raise TypeError(f""Unsupported type for property '{key}': {type(value)}"")
            self.properties[key] = vals

    def get_template(self):
        lines = [f""*Material, name={self.label}""]
        for key, vals in self.properties.items():
            k = key.lstrip(""*"")
            lines.append(f""*{k}"")
            lines.append("", "".join(str(v) for v in vals))
        return ""\n"".join(lines)

    def write_inp(self):
        '''
        Returns the material definition as a string in Abaqus INP format.
        '''
        return self.get_template()","class Material:
    '''
    A material meta class to rule them all.
    '''

    def __init__(self, label=""Material"", **kwargs):
        self.label = label
        for key, value in kwargs.items():
            setattr(self, key, value)

    def get_template(self):
        return f""*MATERIAL, NAME={self.label}\n""

    def write_inp(self):
        '''
        Returns the material definition as a string in Abaqus INP format.
        '''
        return self.get_template()","class Material:
    '''
    A material meta class to rule them all.
    '''

    def __init__(self, label=""Material"", **kwargs):
        self.label = label
        self.properties = kwargs

    def get_template(self):
        template = f""*MATERIAL, NAME={self.label}\n""
        return template

    def write_inp(self):
        '''
        Returns the material definition as a string in Abaqus INP format.
        '''
        inp_string = self.get_template()
        
        for prop_name, prop_value in self.properties.items():
            if isinstance(prop_value, (list, tuple)):
                values = "", "".join(str(v) for v in prop_value)
                inp_string += f""*{prop_name.upper()}\n{values}\n""
            else:
                inp_string += f""*{prop_name.upper()}\n{prop_value}\n""
        
        return inp_string",partial_docstr,0.5297297297297298,0.4153005464480874,0.3425414364640884,0.4540540540540541,0.3364882269762674,0.4880952380952381,0.3147410358565737,0.248,0.7260680198669434,0.8248977065086365,0.7723340392112732,0.8138202428817749,0.747527277227723,0.761904761904762,0.6129032258064515,0.5245901639344263,0.6825396825396826,0.42703845684227515,0.8053097345132744,0.6607142857142857,0.5585585585585585,0.8925586342811584,0.8734360337257385,0.8828938007354736,0.8753113746643066,0.7807829729729729,0.6153846153846153,0.4790419161676647,0.37575757575757573,0.5443786982248521,0.4092047946285275,0.6103286384976526,0.38207547169811323,0.2938388625592417,0.8030411005020142,0.8723427057266235,0.836258590221405,0.8648788928985596,0.7799586274509804,0.4125203707341761,0.2478365387705273,0.4921970972762251,0.4363636363636363,0.4736842105263157,0.4626354509488798,0.4773778853369579,0.4994797079322459,0.4,0.4736842105263157,0.4601163844372088,0.3383130730005041,0.5031094025473742,0.4727272727272727,0.5263157894736842
159166,OpenGov/og-python-utils,OpenGov_og-python-utils/ogutils/loggers/default.py,ogutils.loggers.default.StdErrForwarder,"class StdErrForwarder(object):
    '''
    Used to forward content to the current sys.stdout. This allows for rebinding sys.stdout without
    remapping associations in loggers
    '''
    def write(self, content):
        sys.stderr.write(content)

    def flush(self):
        sys.stderr.flush()

    def isatty(self):
        return sys.stderr.isatty()","class StdErrForwarder(object):
    '''
    Used to forward content to the current sys.stdout. This allows for rebinding sys.stdout without
    remapping associations in loggers
    '''

    def write(self, content):
        pass

    def flush(self):
        pass

    def isatty(self):
        pass

",4,1,snippet_256,1.0,"class StdErrForwarder(object):
    '''
    Used to forward content to the current sys.stdout. This allows for rebinding sys.stdout without
    remapping associations in loggers
    '''

    def write(self, content):
        sys.stdout.write(content)

    def flush(self):
        sys.stdout.flush()

    def isatty(self):
        return getattr(sys.stdout, 'isatty', lambda: False)()","class StdErrForwarder(object):
    '''
    Used to forward content to the current sys.stdout. This allows for rebinding sys.stdout without
    remapping associations in loggers
    '''

    def write(self, content):
        sys.stderr.write(content)

    def flush(self):
        sys.stderr.flush()

    def isatty(self):
        return sys.stderr.isatty()","class StdErrForwarder(object):
    '''
    Used to forward content to the current sys.stdout. This allows for rebinding sys.stdout without
    remapping associations in loggers
    '''

    def write(self, content):
        return sys.stderr.write(content)

    def flush(self):
        return sys.stderr.flush()

    def isatty(self):
        return sys.stderr.isatty()",partial_docstr,0.9010989010989012,0.8089887640449438,0.7586206896551724,0.9010989010989012,0.8009239175040813,0.8536585365853658,0.8024691358024691,0.75,0.9637013673782349,0.9743759632110596,0.969009280204773,0.9732978343963623,0.9491530508474577,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.9998534321784973,0.9998534321784973,0.9998534321784973,0.9998533725738525,1.0,0.9777777777777777,0.9318181818181819,0.8837209302325582,0.9777777777777777,0.9468745052031837,0.974025974025974,0.9473684210526315,0.92,0.9923233389854431,0.9974185228347778,0.9948644042015076,0.9969066381454468,0.9871796153846154,0.8078038475839361,0.7416327246130168,0.8215154388319714,0.7857142857142857,0.8823529411764706,1.0,1.0,1.0,1.0,1.0,0.8557156642077908,0.8452785147119855,0.899012713547749,0.6785714285714286,1.0
184682,ScatterHQ/machinist,ScatterHQ_machinist/machinist/_fsm.py,machinist._fsm._FiniteStateMachine,"class _FiniteStateMachine(object):
    """"""
    A L{_FiniteStateMachine} tracks the core logic of a finite state machine:
    recording the current state and mapping inputs to outputs and next states.

    @ivar inputs: See L{constructFiniteStateMachine}
    @ivar outputs: See L{constructFiniteStateMachine}
    @ivar states: See L{constructFiniteStateMachine}
    @ivar table: See L{constructFiniteStateMachine}
    @ivar initial: See L{constructFiniteStateMachine}

    @ivar state: The current state of this FSM.
    @type state: L{NamedConstant} from C{states}
    """"""
    def __init__(self, inputs, outputs, states, table, initial):
        self.inputs = inputs
        self.outputs = outputs
        self.states = states
        self.table = table
        self.initial = initial
        self.state = initial


    def receive(self, input):
        current = self.table[self.state]

        if input not in self.inputs.iterconstants():
            raise IllegalInput(input)

        try:
            transition = current[input]
        except KeyError:
            raise UnhandledInput(self.state, input)

        self.state = transition.nextState
        return transition.output


    def _isTerminal(self, state):
        """"""
        Determine whether or not the given state is a terminal state in this
        state machine.  Terminal states have no transitions to other states.
        Additionally, terminal states have no outputs.

        @param state: The state to examine.

        @return: C{True} if the state is terminal, C{False} if it is not.
        @rtype: L{bool}
        """"""
        # This is private with the idea that maybe terminal should be defined
        # differently eventually - perhaps by accepting an explicit set of
        # terminal states in constructFiniteStateMachine.
        # https://www.pivotaltracker.com/story/show/59999580
        return all(
            transition.output == [] and transition.nextState == state
            for (input, transition)
            in self.table[state].iteritems())","class _FiniteStateMachine(object):
    '''
    A L{_FiniteStateMachine} tracks the core logic of a finite state machine:
    recording the current state and mapping inputs to outputs and next states.

    @ivar inputs: See L{constructFiniteStateMachine}
    @ivar outputs: See L{constructFiniteStateMachine}
    @ivar states: See L{constructFiniteStateMachine}
    @ivar table: See L{constructFiniteStateMachine}
    @ivar initial: See L{constructFiniteStateMachine}

    @ivar state: The current state of this FSM.
    @type state: L{NamedConstant} from C{states}
    '''

    def __init__(self, inputs, outputs, states, table, initial):
        pass

    def receive(self, input):
        pass

    def _isTerminal(self, state):
    '''
        Determine whether or not the given state is a terminal state in this
        state machine.  Terminal states have no transitions to other states.
        Additionally, terminal states have no outputs.

        @param state: The state to examine.

        @return: C{True} if the state is terminal, C{False} if it is not.
        @rtype: L{bool}
        '''
        pass

",4,2,snippet_262,0.25,"class _FiniteStateMachine(object):
    def __init__(self, inputs, outputs, states, table, initial):
        # inputs, outputs, states: iterables of allowed constants
        # table: dict mapping state -> dict mapping input -> (output, nextState)
        self.inputs = set(inputs)
        self.outputs = set(outputs)
        self.states = set(states)
        if initial not in self.states:
            raise ValueError(""Initial state %r not in states"" % (initial,))
        # validate transition table
        if not isinstance(table, dict):
            raise TypeError(""table must be a dict"")
        for st, trans in table.items():
            if st not in self.states:
                raise ValueError(""State %r in table not in declared states"" % (st,))
            if not isinstance(trans, dict):
                raise TypeError(""table[%r] must be a dict"" % (st,))
            for inp, pair in trans.items():
                if inp not in self.inputs:
                    raise ValueError(""Input %r not in declared inputs"" % (inp,))
                if not (isinstance(pair, (list, tuple)) and len(pair) == 2):
                    raise ValueError(""Transition for %r->%r must be a (output,nextState) pair"" % (st, inp))
                out, nxt = pair
                if out not in self.outputs:
                    raise ValueError(""Output %r not in declared outputs"" % (out,))
                if nxt not in self.states:
                    raise ValueError(""Next state %r not in declared states"" % (nxt,))
        self.table = {st: dict(trans) for st, trans in table.items()}
        self.initial = initial
        self.state = initial

    def receive(self, input):
        if input not in self.inputs:
            raise ValueError(""Unrecognized input %r"" % (input,))
        if self._isTerminal(self.state):
            raise RuntimeError(""Cannot receive input in terminal state %r"" % (self.state,))
        trans = self.table.get(self.state, {})
        if input not in trans:
            raise RuntimeError(""No transition defined for state %r on input %r"" % (self.state, input))
        output, nextstate = trans[input]
        # (output and nextstate were validated at init)
        self.state = nextstate
        return output

    def _isTerminal(self, state):
        '''
        Determine whether or not the given state is a terminal state in this
        state machine.  Terminal states have no transitions to other states.
        Additionally, terminal states have no outputs.
        '''
        trans = self.table.get(state)
        return not trans or len(trans) == 0","class _FiniteStateMachine(object):
    '''
    A L{_FiniteStateMachine} tracks the core logic of a finite state machine:
    recording the current state and mapping inputs to outputs and next states.

    @ivar inputs: See L{constructFiniteStateMachine}
    @ivar outputs: See L{constructFiniteStateMachine}
    @ivar states: See L{constructFiniteStateMachine}
    @ivar table: See L{constructFiniteStateMachine}
    @ivar initial: See L{constructFiniteStateMachine}

    @ivar state: The current state of this FSM.
    @type state: L{NamedConstant} from C{states}
    '''

    def __init__(self, inputs, outputs, states, table, initial):
        self.inputs = inputs
        self.outputs = outputs
        self.states = states
        self.table = table
        self.initial = initial
        self.state = initial

    def receive(self, input):
        if input not in self.inputs:
            raise ValueError(""Invalid input"")
        
        if self.state not in self.table or input not in self.table[self.state]:
            raise ValueError(""No transition defined for current state and input"")
        
        output, next_state = self.table[self.state][input]
        self.state = next_state
        return output

    def _isTerminal(self, state):
        '''
        Determine whether or not the given state is a terminal state in this
        state machine.  Terminal states have no transitions to other states.
        Additionally, terminal states have no outputs.

        @param state: The state to examine.

        @return: C{True} if the state is terminal, C{False} if it is not.
        @rtype: L{bool}
        '''
        return state not in self.table or len(self.table[state]) == 0","class _FiniteStateMachine(object):
    '''
    A L{_FiniteStateMachine} tracks the core logic of a finite state machine:
    recording the current state and mapping inputs to outputs and next states.

    @ivar inputs: See L{constructFiniteStateMachine}
    @ivar outputs: See L{constructFiniteStateMachine}
    @ivar states: See L{constructFiniteStateMachine}
    @ivar table: See L{constructFiniteStateMachine}
    @ivar initial: See L{constructFiniteStateMachine}

    @ivar state: The current state of this FSM.
    @type state: L{NamedConstant} from C{states}
    '''

    def __init__(self, inputs, outputs, states, table, initial):
        self.inputs = inputs
        self.outputs = outputs
        self.states = states
        self.table = table
        self.initial = initial
        self.state = initial

    def receive(self, input):
        if self.state in self.table and input in self.table[self.state]:
            output, next_state = self.table[self.state][input]
            self.state = next_state
            return output
        else:
            raise ValueError(""Invalid input for current state"")

    def _isTerminal(self, state):
        '''
        Determine whether or not the given state is a terminal state in this
        state machine.  Terminal states have no transitions to other states.
        Additionally, terminal states have no outputs.

        @param state: The state to examine.

        @return: C{True} if the state is terminal, C{False} if it is not.
        @rtype: L{bool}
        '''
        return state not in self.table or len(self.table[state]) == 0",partial_docstr,0.48014440433212996,0.2608695652173913,0.20363636363636364,0.33574007220216606,0.27086639139962576,0.4392361111111111,0.2382608695652174,0.18989547038327526,0.8020738959312439,0.7736001014709473,0.7875797152519226,0.7763561010360718,0.7463607197943452,0.8392857142857143,0.7488789237668162,0.7252252252252251,0.7901785714285715,0.7032510737546751,0.9075144508670521,0.7855072463768116,0.747093023255814,0.9620543718338013,0.8998700380325317,0.9299237728118896,0.9057244062423706,0.8609420858895706,0.8387096774193549,0.7546296296296297,0.7302325581395348,0.7880184331797234,0.6802621768596201,0.926605504587156,0.8159509202453987,0.7784615384615384,0.965413510799408,0.8913671374320984,0.9269139170646667,0.8982566595077515,0.8629870552147239,0.3764808918519458,0.1809906211395647,0.2676491015996923,0.4810126582278481,0.576271186440678,0.6405559341693413,0.6493568109225459,0.6648514784259197,0.4683544303797468,0.7796610169491526,0.6211680461166652,0.633422140422565,0.6540820543423153,0.4683544303797468,0.7288135593220338
522668,jshiv/turntable,jshiv_turntable/test/lib/python2.7/site-packages/numpy/ma/core.py,numpy.ma.core._DomainCheckInterval,"class _DomainCheckInterval:
    """"""
    Define a valid interval, so that :

    ``domain_check_interval(a,b)(x) == True`` where
    ``x < a`` or ``x > b``.

    """"""
    def __init__(self, a, b):
        ""domain_check_interval(a,b)(x) = true where x < a or y > b""
        if (a > b):
            (a, b) = (b, a)
        self.a = a
        self.b = b

    def __call__ (self, x):
        ""Execute the call behavior.""
        return umath.logical_or(umath.greater (x, self.b),
                                umath.less(x, self.a))","class _DomainCheckInterval:
    '''
    Define a valid interval, so that :

    ``domain_check_interval(a,b)(x) == True`` where
    ``x < a`` or ``x > b``.

    '''

    def __init__(self, a, b):
    '''domain_check_interval(a,b)(x) = true where x < a or y > b'''
        pass

    def __call__ (self, x):
    '''Execute the call behavior.'''
        pass

",3,3,snippet_323,1.0,"class _DomainCheckInterval:
    '''
    Define a valid interval, so that :

    ``domain_check_interval(a,b)(x) == True`` where
    ``x < a`` or ``x > b``.
    '''
    def __init__(self, a, b):
        '''domain_check_interval(a,b)(x) = true where x < a or x > b'''
        if a > b:
            raise ValueError(f""Invalid interval: lower bound {a} is greater than upper bound {b}."")
        self.a = a
        self.b = b

    def __call__(self, x):
        '''Execute the call behavior.'''
        try:
            return (x < self.a) or (x > self.b)
        except TypeError:
            raise TypeError(f""Cannot compare value {x!r} with interval bounds {self.a!r} and {self.b!r}."")","class _DomainCheckInterval:
    '''
    Define a valid interval, so that :

    ``domain_check_interval(a,b)(x) == True`` where
    ``x < a`` or ``x > b``.

    '''

    def __init__(self, a, b):
        '''domain_check_interval(a,b)(x) = true where x < a or y > b'''
        self.a = a
        self.b = b

    def __call__(self, x):
        '''Execute the call behavior.'''
        return x < self.a or x > self.b","class _DomainCheckInterval:
    '''
    Define a valid interval, so that :

    ``domain_check_interval(a,b)(x) == True`` where
    ``x < a`` or ``x > b``.

    '''

    def __init__(self, a, b):
        '''domain_check_interval(a,b)(x) = true where x < a or y > b'''
        self.a = a
        self.b = b

    def __call__(self, x):
        '''Execute the call behavior.'''
        return x < self.a or x > self.b",partial_docstr,0.7861271676300577,0.6549707602339181,0.6035502958579881,0.7514450867052023,0.6022414638849942,0.7213930348258707,0.585,0.5175879396984925,0.8750580549240112,0.9262545108795166,0.8999287486076355,0.920866847038269,0.8490581132075471,0.9037037037037037,0.8421052631578947,0.7938931297709924,0.8592592592592593,0.6208669712539625,0.9457364341085271,0.8515625,0.7952755905511811,0.9743807911872864,0.9109700918197632,0.9416090846061707,0.9169372916221619,0.8821149999999999,0.9037037037037037,0.8421052631578947,0.7938931297709924,0.8592592592592593,0.6208669712539625,0.9457364341085271,0.8515625,0.7952755905511811,0.9743807911872864,0.9109700918197632,0.9416090846061707,0.9169372916221619,0.8821149999999999,0.5195638556576578,0.3681589396835468,0.5100964829470843,0.4,0.8,0.5145125801566985,0.5170545041759622,0.5295672450222604,0.3714285714285714,0.64,0.5145125801566985,0.5170545041759622,0.5295672450222604,0.3714285714285714,0.64
699074,rbw/pysnow,pysnow/criterion.py,pysnow.criterion.Table,"class Table(object):
    """"""
        Allows the following:

        ```
        incident = Table(incident)
        criterion = incident.company.eq('3dasd3')
        ```
    """"""

    # Could be used to automate resource creation?
    def __init__(self, name):
        self.table_name = name

    def field(self, name):
        return Field(name)

    def __getattr__(self, name):
        return self.field(name)

    def __getitem__(self, name):
        return self.field(name)","class Table(object):
    '''
        Allows the following:

        ```
        incident = Table(incident)
        criterion = incident.company.eq('3dasd3')
        ```
    '''

    def __init__(self, name):
        pass

    def field(self, name):
        pass

    def __getattr__(self, name):
        pass

    def __getitem__(self, name):
        pass

",5,1,snippet_431,1.0,"class Table(object):
    '''
        Allows the following:

        
        incident = Table('incident')
        criterion = incident.company.eq('3dasd3')
        
    '''

    def __init__(self, name):
        self.name = name

    def field(self, name):
        return Field(self, name)

    def __getattr__(self, name):
        if name.startswith('_'):
            raise AttributeError
        return self.field(name)

    def __getitem__(self, name):
        return self.field(name)","class Table(object):
    '''
        Allows the following:

        
        incident = Table(incident)
        criterion = incident.company.eq('3dasd3')
        
    '''

    def __init__(self, name):
        self.name = name

    def field(self, name):
        return Field(self.name, name)

    def __getattr__(self, name):
        return self.field(name)

    def __getitem__(self, name):
        return self.field(name)","class Table(object):
    '''
        Allows the following:

        
        incident = Table(incident)
        criterion = incident.company.eq('3dasd3')
        
    '''

    def __init__(self, name):
        self.name = name

    def field(self, name):
        return Field(self.name, name)

    def __getattr__(self, name):
        return Field(self.name, name)

    def __getitem__(self, name):
        return Field(self.name, name)",partial_docstr,0.8627450980392156,0.7799999999999999,0.6938775510204083,0.8627450980392156,0.734098907145375,0.8558558558558559,0.7818181818181819,0.7155963302752294,0.9387705326080322,0.9340685606002808,0.9364136457443237,0.9345365762710571,0.9324331081081081,0.8979591836734695,0.8333333333333334,0.7659574468085107,0.8979591836734695,0.7497474259188317,0.9405940594059405,0.89,0.8383838383838383,0.9815094470977783,0.9405741095542908,0.9606058597564697,0.9445133209228516,0.9788361904761904,0.8799999999999999,0.6938775510204082,0.6041666666666666,0.8400000000000001,0.6888140665748482,0.8857142857142857,0.7788461538461539,0.6893203883495146,0.9662892818450928,0.9276219606399536,0.9465609192848206,0.931348979473114,0.9487184615384615,0.5709746360938419,0.3600789921770728,0.3793751077538503,0.7666666666666667,0.7777777777777778,0.6277731066433199,0.4679060327747108,0.4987419493541242,0.7666666666666667,0.7777777777777778,0.5123436714880735,0.3736562231602902,0.3979406850142259,0.5,0.7777777777777778
307977,cltl/KafNafParserPy,cltl_KafNafParserPy/KafNafParserPy/attribution_data.py,KafNafParserPy.attribution_data.Cstatement_source,"class Cstatement_source:
    '''Represents the statement_source element'''

    def __init__(self, node=None, type='NAF'):
        """"""
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        """"""
        self.type = type
        if node is None:
            self.node = etree.Element('statement_source')
        else:
            self.node = node

    def get_node(self):
        """"""
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        """"""
        return self.node

    def get_span(self):
        """"""
        Returns the span of the statement_source element
        @rtype: L{Cspan}
        @return: span object
        """"""
        span_obj = self.node.find('span')
        if span_obj is not None:
            return Cspan(span_obj)
        return None

    def set_span(self,my_span):
        """"""
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_source
        """"""
        self.node.append(my_span.get_node())","class Cstatement_source:
    '''Represents the statement_source element'''

    def __init__(self, node=None, type='NAF'):
    '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        pass

    def get_node(self):
    '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        pass

    def get_span(self):
    '''
        Returns the span of the statement_source element
        @rtype: L{Cspan}
        @return: span object
        '''
        pass

    def set_span(self,my_span):
    '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_source
        '''
        pass

",5,5,snippet_1,0.875,"class Cstatement_source:
    '''Represents the statement_source element'''
    def __init__(self, node=None, type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        if node is None:
            node = ET.Element('statement_source')
            node.set('type', type)
        self.node = node
        self.type = node.get('type', type)
        self.span = None
        span_node = self.node.find('span')
        if span_node is not None:
            from Cspan import Cspan
            self.span = Cspan(span_node, self.type)

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def get_span(self):
        '''
        Returns the span of the statement_source element
        @rtype: L{Cspan}
        @return: span object
        '''
        return self.span

    def set_span(self, my_span):
        '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_source
        '''
        if self.span is not None:
            try:
                self.node.remove(self.span.get_node())
            except ValueError:
                pass
        self.span = my_span
        self.node.append(my_span.get_node())","class Cstatement_source:
    '''Represents the statement_source element'''

    def __init__(self, node=None, type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        self.type = type
        if node is None:
            if self.type == 'NAF':
                self.node = etree.Element('statement_source')
            else:
                self.node = etree.Element('statement_source')
        else:
            self.node = node

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def get_span(self):
        '''
        Returns the span of the statement_source element
        @rtype: L{Cspan}
        @return: span object
        '''
        from .span import Cspan
        span_node = self.node.find('span')
        if span_node is not None:
            return Cspan(span_node)
        else:
            return None

    def set_span(self, my_span):
        '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_source
        '''
        from .span import Cspan
        # Remove existing span if any
        existing_span = self.node.find('span')
        if existing_span is not None:
            self.node.remove(existing_span)
        
        # Add the new span
        self.node.append(my_span.get_node())","class Cstatement_source:
    '''Represents the statement_source element'''

    def __init__(self, node=None, type='NAF'):
        '''
        Constructor of the object
        @type node: xml Element or None (to create and empty one)
        @param node:  this is the node of the element. If it is None it will create a new object
        @type type: string
        @param type: the type of the object (KAF or NAF)
        '''
        self.type = type
        if node is None:
            self.node = etree.Element('statement_source')
        else:
            self.node = node

    def get_node(self):
        '''
        Returns the node of the element
        @rtype: xml Element
        @return: the node of the element
        '''
        return self.node

    def get_span(self):
        '''
        Returns the span of the statement_source element
        @rtype: L{Cspan}
        @return: span object
        '''
        span_node = self.node.find('span')
        if span_node is not None:
            from Cspan import Cspan
            return Cspan(span_node, self.type)
        return None

    def set_span(self, my_span):
        '''
        Sets the id of the element
        @type my_span: L{Cspan}
        @param my_span: the span of the statement_source
        '''
        existing_span = self.node.find('span')
        if existing_span is not None:
            self.node.remove(existing_span)
        self.node.append(my_span.get_node())",partial_docstr,0.870026525198939,0.7946666666666666,0.7292225201072386,0.7851458885941645,0.7024025853967155,0.7640117994100295,0.7011834319526628,0.6468842729970327,0.93205326795578,0.9577912092208862,0.9447469711303711,0.9551535844802856,0.817888,0.8652849740932642,0.8385416666666667,0.8115183246073299,0.8652849740932642,0.7179398428280682,0.7528735632183908,0.7175792507204611,0.684971098265896,0.9324174523353577,0.9653239846229553,0.9485853910446167,0.961929202079773,0.8808385507246376,0.9201101928374654,0.8919667590027699,0.8635097493036211,0.9201101928374654,0.8024981249954858,0.842443729903537,0.8032258064516129,0.7637540453074434,0.9672865867614746,0.9862687587738037,0.9766854643821716,0.9843370318412781,0.9298252631578948,0.6199140878507775,0.6231858176817447,0.7358822984272477,0.65,0.4705882352941176,0.7910563804020218,0.6297923896864158,0.8060017593726515,0.8166666666666667,0.9117647058823528,0.8390960486981622,0.7277240510004648,0.8119934771255177,0.8166666666666667,1.0
205924,UDST/orca,UDST_orca/orca/orca.py,orca.orca._StepFuncWrapper,"class _StepFuncWrapper(object):
    """"""
    Wrap a step function for argument matching.

    Parameters
    ----------
    step_name : str
    func : callable

    Attributes
    ----------
    name : str
        Name of step.

    """"""
    def __init__(self, step_name, func):
        self.name = step_name
        self._func = func
        self._argspec = getargspec(func)

    def __call__(self):
        with log_start_finish('calling step {!r}'.format(self.name), logger):
            kwargs = _collect_variables(names=self._argspec.args,
                                        expressions=self._argspec.defaults)
            return self._func(**kwargs)

    def _tables_used(self):
        """"""
        Tables injected into the step.

        Returns
        -------
        tables : set of str

        """"""
        args = list(self._argspec.args)
        if self._argspec.defaults:
            default_args = list(self._argspec.defaults)
        else:
            default_args = []
        # Combine names from argument names and argument default values.
        names = args[:len(args) - len(default_args)] + default_args
        tables = set()
        for name in names:
            parent_name = name.split('.')[0]
            if is_table(parent_name):
                tables.add(parent_name)
        return tables

    def func_source_data(self):
        """"""
        Return data about a step function's source, including file name,
        line number, and source code.

        Returns
        -------
        filename : str
        lineno : int
            The line number on which the function starts.
        source : str

        """"""
        return utils.func_source_data(self._func)","class _StepFuncWrapper(object):
    '''
    Wrap a step function for argument matching.

    Parameters
    ----------
    step_name : str
    func : callable

    Attributes
    ----------
    name : str
        Name of step.

    '''

    def __init__(self, step_name, func):
        pass

    def __call__(self):
        pass

    def _tables_used(self):
    '''
        Tables injected into the step.

        Returns
        -------
        tables : set of str

        '''
        pass

    def func_source_data(self):
    '''
        Return data about a step function's source, including file name,
        line number, and source code.

        Returns
        -------
        filename : str
        lineno : int
            The line number on which the function starts.
        source : str

        '''
        pass

",5,3,snippet_423,0.25,"class _StepFuncWrapper(object):
    '''
    Wrap a step function for argument matching.

    Parameters
    ----------
    step_name : str
    func : callable

    Attributes
    ----------
    name : str
        Name of step.

    '''

    def __init__(self, step_name, func):
        self.name = step_name
        self.func = func
        # Use the wrapped function's signature for argument matching
        self.__signature__ = inspect.signature(func)

    def __call__(self, *args, **kwargs):
        return self.func(*args, **kwargs)

    def _tables_used(self):
        '''
        Tables injected into the step.

        Returns
        -------
        tables : set of str

        '''
        return set(self.__signature__.parameters.keys())

    def func_source_data(self):
        '''
        Return data about a step function's source, including file name,
        line number, and source code.

        Returns
        -------
        filename : str
        lineno : int
            The line number on which the function starts.
        source : str

        '''
        filename = self.func.__code__.co_filename
        lineno = self.func.__code__.co_firstlineno
        try:
            source = inspect.getsource(self.func)
        except (OSError, IOError):
            source = None
        return filename, lineno, source","class _StepFuncWrapper(object):
    '''
    Wrap a step function for argument matching.

    Parameters
    ----------
    step_name : str
    func : callable

    Attributes
    ----------
    name : str
        Name of step.

    '''

    def __init__(self, step_name, func):
        self.name = step_name
        self.func = func

    def __call__(self, *args, **kwargs):
        return self.func(*args, **kwargs)

    def _tables_used(self):
        '''
        Tables injected into the step.

        Returns
        -------
        tables : set of str

        '''
        source = inspect.getsource(self.func)
        # Find patterns like tables['table_name'] or tables[""table_name""]
        pattern = r'tables\[([""\'])([^""\']+)\1\]'
        matches = re.findall(pattern, source)
        # Extract just the table names (second group)
        tables = {match[1] for match in matches}
        return tables

    def func_source_data(self):
        '''
        Return data about a step function's source, including file name,
        line number, and source code.

        Returns
        -------
        filename : str
        lineno : int
            The line number on which the function starts.
        source : str

        '''
        filename = inspect.getsourcefile(self.func)
        lineno = inspect.getsourcelines(self.func)[1]
        source = inspect.getsource(self.func)
        return filename, lineno, source","class _StepFuncWrapper(object):
    '''
    Wrap a step function for argument matching.

    Parameters
    ----------
    step_name : str
    func : callable

    Attributes
    ----------
    name : str
        Name of step.

    '''

    def __init__(self, step_name, func):
        self.name = step_name
        self.func = func
        self._signature = inspect.signature(func)
        
    def __call__(self, *args, **kwargs):
        return self.func(*args, **kwargs)

    def _tables_used(self):
        '''
        Tables injected into the step.

        Returns
        -------
        tables : set of str

        '''
        tables = set()
        for param_name, param in self._signature.parameters.items():
            if param.annotation and hasattr(param.annotation, '__name__'):
                tables.add(param_name)
            elif param_name not in ['self', 'args', 'kwargs']:
                tables.add(param_name)
        return tables

    def func_source_data(self):
        '''
        Return data about a step function's source, including file name,
        line number, and source code.

        Returns
        -------
        filename : str
        lineno : int
            The line number on which the function starts.
        source : str

        '''
        filename = inspect.getfile(self.func)
        lineno = inspect.getsourcelines(self.func)[1]
        source = inspect.getsource(self.func)
        return filename, lineno, source",partial_docstr,0.6707692307692307,0.5572755417956656,0.5171339563862928,0.6153846153846153,0.4492273527316602,0.8277153558052435,0.6165413533834586,0.5245283018867924,0.8774187564849854,0.8494377136230469,0.8632014989852905,0.8521552085876465,0.7987441509433961,0.6804733727810651,0.5416666666666667,0.5089820359281437,0.6213017751479291,0.46132206067331366,0.7643097643097643,0.543918918918919,0.4610169491525424,0.8467298150062561,0.8339443206787109,0.8402884602546692,0.8352054953575134,0.783021037735849,0.7176470588235293,0.5739644970414202,0.5297619047619048,0.6588235294117647,0.5081556802940863,0.8163265306122449,0.6177474402730375,0.5273972602739726,0.873847246170044,0.8538445234298706,0.8637300729751587,0.8558034896850586,0.7751594811320753,0.4382388710328876,0.4906327697343592,0.4966856487601258,0.3513513513513513,0.4142857142857143,0.4355769409284183,0.5119059429756224,0.5150865054227358,0.3153153153153153,0.4,0.5034827114933549,0.5176263285267936,0.5300239511660596,0.4234234234234234,0.5428571428571428
181069,RedisJSON/rejson-py,RedisJSON_rejson-py/rejson/path.py,rejson.path.Path,"class Path(object):
    """"""
    This class represents a path in a JSON value
    """"""
    strPath = ''

    @staticmethod
    def rootPath():
        ""Returns the root path's string representation""
        return '.'

    def __init__(self, path):
        """"""
        Make a new path based on the string representation in `path`
        """"""
        self.strPath = path","class Path(object):
    '''
    This class represents a path in a JSON value
    '''

    @staticmethod
    def rootPath():
    '''Returns the root path's string representation'''
        pass

    def __init__(self, path):
    '''
        Make a new path based on the string representation in `path`
        '''
        pass

",4,3,snippet_778,1.0,"class Path(object):
    '''
    This class represents a path in a JSON value
    '''

    @staticmethod
    def rootPath():
        '''Returns the root path's string representation'''
        return '$'

    def __init__(self, path):
        '''
        Make a new path based on the string representation in `path`
        '''
        if not isinstance(path, str):
            raise TypeError(""Path must be a string"")
        if path == '':
            raise ValueError(""Path string cannot be empty"")
        if path != '$' and not path.startswith('$.'):
            raise ValueError(""Path must start with '$' or '$.'"")
        self._raw = path
        self.segments = []
        if path == '$':
            return
        # parse after the leading '$'
        i = 1
        n = len(path)
        while i < n:
            c = path[i]
            if c == '.':
                m = re.match(r'\.([A-Za-z_][A-Za-z0-9_]*)', path[i:])
                if not m:
                    raise ValueError(f""Invalid object key at position {i}"")
                key = m.group(1)
                self.segments.append(key)
                i += m.end()
            elif c == '[':
                m = re.match(r'\[(\d+)\]', path[i:])
                if not m:
                    raise ValueError(f""Invalid array index at position {i}"")
                idx = int(m.group(1))
                self.segments.append(idx)
                i += m.end()
            else:
                raise ValueError(f""Unexpected character '{c}' at position {i}"")

    def __str__(self):
        return self._raw

    def __repr__(self):
        return f""Path('{self._raw}')""

    def __eq__(self, other):
        if not isinstance(other, Path):
            return False
        return self._raw == other._raw

    def __hash__(self):
        return hash(self._raw)","class Path(object):
    '''
    This class represents a path in a JSON value
    '''

    @staticmethod
    def rootPath():
        '''Returns the root path's string representation'''
        return ""$""

    def __init__(self, path):
        '''
        Make a new path based on the string representation in `path`
        '''
        self.path = path","class Path(object):
    '''
    This class represents a path in a JSON value
    '''

    @staticmethod
    def rootPath():
        '''Returns the root path's string representation'''
        return ""$""

    def __init__(self, path):
        '''
        Make a new path based on the string representation in `path`
        '''
        self.path = path",partial_docstr,0.3137254901960784,0.2924901185770751,0.27091633466135456,0.3137254901960784,0.1212873305475101,0.16630196936542668,0.1162280701754386,0.09230769230769231,0.6521964073181152,0.943547248840332,0.7712744474411011,0.903199315071106,0.7041336023054758,0.963855421686747,0.9135802469135802,0.8860759493670887,0.963855421686747,0.6020938566526358,0.8805970149253731,0.7272727272727273,0.6153846153846154,0.9902740120887756,0.97718745470047,0.983687162399292,0.9784806370735168,0.9607847058823529,0.963855421686747,0.9135802469135802,0.8860759493670887,0.963855421686747,0.6020938566526358,0.8805970149253731,0.7272727272727273,0.6153846153846154,0.9902740120887756,0.97718745470047,0.983687162399292,0.9784806370735168,0.9607847058823529,0.4525457312458303,0.1246022394296248,0.5355806855536964,0.65,0.5,0.5213869402953386,0.5187382257616419,0.5334762020863792,0.7,0.3333333333333333,0.5213869402953386,0.5187382257616419,0.5334762020863792,0.7,0.3333333333333333
740146,sirfoga/pyhal,sirfoga_pyhal/hal/internet/engines.py,hal.internet.engines.SearchEngineResult,"class SearchEngineResult:
    """"""Result of general search engine""""""

    def __init__(self, title, link, description=""""):
        """"""
        :param title: title of result
        :param link: search query url
        :param description: description of result
        """"""
        self.title = title
        self.link = link
        self.description = description

    def __str__(self):
        return self.title","class SearchEngineResult:
    '''Result of general search engine'''

    def __init__(self, title, link, description=""""):
    '''
        :param title: title of result
        :param link: search query url
        :param description: description of result
        '''
        pass

    def __str__(self):
        pass

",3,2,snippet_91,1.0,"class SearchEngineResult:
    '''Result of general search engine'''

    def __init__(self, title, link, description=""""):
        '''
        :param title: title of result
        :param link: search query url
        :param description: description of result
        '''
        self.title = title
        self.link = link
        self.description = description

    def __str__(self):
        output = f""Title: {self.title}\nLink: {self.link}""
        if self.description:
            output += f""\nDescription: {self.description}""
        return output","class SearchEngineResult:
    '''Result of general search engine'''

    def __init__(self, title, link, description=""""):
        '''
        :param title: title of result
        :param link: search query url
        :param description: description of result
        '''
        self.title = title
        self.link = link
        self.description = description

    def __str__(self):
        return f""{self.title}\n{self.link}\n{self.description}""","class SearchEngineResult:
    '''Result of general search engine'''

    def __init__(self, title, link, description=""""):
        '''
        :param title: title of result
        :param link: search query url
        :param description: description of result
        '''
        self.title = title
        self.link = link
        self.description = description

    def __str__(self):
        return f""Title: {self.title}\nLink: {self.link}\nDescription: {self.description}""",partial_docstr,0.8514851485148515,0.8080808080808081,0.7835051546391752,0.8316831683168318,0.6062419412908607,0.6837606837606838,0.5948275862068966,0.5478260869565217,0.9190933704376221,0.9845276474952698,0.9506859183311462,0.9775679111480713,0.8705895294117646,0.924731182795699,0.9010989010989012,0.8764044943820225,0.924731182795699,0.7187533315102377,0.7878787878787878,0.7142857142857143,0.6597938144329897,0.9582477807998657,0.9873600602149963,0.9725860953330994,0.9843693971633911,0.9227060869565217,0.9148936170212766,0.8913043478260869,0.8666666666666666,0.9148936170212766,0.6905650831849973,0.7572815533980582,0.6862745098039216,0.6336633663366337,0.9509865045547485,0.9866134524345398,0.9684724807739258,0.9829310774803162,0.9190484285714285,0.7317461923958799,0.5527579700493627,0.7094540722614298,0.7272727272727273,0.9375,0.7638827972847003,0.7233048701135152,0.7299535917525588,0.7272727272727273,0.875,0.7514034707280621,0.6733875638869624,0.7299535917525588,0.7272727272727273,0.875
