# Test cases automatically generated by Pynguin (https://www.pynguin.eu).
# Please check them before you use them.
import pytest
import snippet_514 as module_0


@pytest.mark.xfail(strict=True)
def test_case_0():
    str_0 = "}^eUs$j'\x0bG#\\uS@"
    line_tokenizer_0 = module_0.LineTokenizer(str_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == "}^eus$j'\x0bg#\\us@"
    var_0 = line_tokenizer_0.tokenize(str_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == "}^eus$j'\x0bg#\\us@"
    line_tokenizer_1 = module_0.LineTokenizer(str_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == "}^eus$j'\x0bg#\\us@"
    assert (
        f"{type(line_tokenizer_1).__module__}.{type(line_tokenizer_1).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_1.language == "}^eus$j'\x0bg#\\us@"
    module_0.LineTokenizer(line_tokenizer_0)


def test_case_1():
    bytes_0 = b"\xc2\xab6\xfaM"
    line_tokenizer_0 = module_0.LineTokenizer(bytes_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == b"\xc2\xab6\xfam"
    with pytest.raises(AssertionError):
        line_tokenizer_0.tokenize(bytes_0)


@pytest.mark.xfail(strict=True)
def test_case_2():
    bytes_0 = b"QJ\x86\x04\xb4\x1b2\xa1\x9b\x9d\xc5\x9f"
    float_0 = -2801.46
    dict_0 = {bytes_0: float_0, bytes_0: float_0}
    module_0.LineTokenizer(dict_0)


@pytest.mark.xfail(strict=True)
def test_case_3():
    bytes_0 = b"\xe4\x1b\xab"
    line_tokenizer_0 = module_0.LineTokenizer(bytes_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == b"\xe4\x1b\xab"
    str_0 = "O,#c%\x0bW/l"
    var_0 = line_tokenizer_0.tokenize(str_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == b"\xe4\x1b\xab"
    var_1 = line_tokenizer_0.tokenize(str_0, str_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == b"\xe4\x1b\xab"
    var_1.tokenize(var_0)


def test_case_4():
    str_0 = "O,#c\x0bl"
    str_1 = "nK/[ZFn<RN\x0b\nz."
    line_tokenizer_0 = module_0.LineTokenizer(str_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == "o,#c\x0bl"
    var_0 = line_tokenizer_0.tokenize(str_1)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == "o,#c\x0bl"
    line_tokenizer_1 = module_0.LineTokenizer(str_0)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == "o,#c\x0bl"
    assert (
        f"{type(line_tokenizer_1).__module__}.{type(line_tokenizer_1).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_1.language == "o,#c\x0bl"
    str_2 = "1[6%cy"
    line_tokenizer_2 = module_0.LineTokenizer(str_2)
    assert (
        f"{type(line_tokenizer_0).__module__}.{type(line_tokenizer_0).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_0.language == "o,#c\x0bl"
    assert (
        f"{type(line_tokenizer_1).__module__}.{type(line_tokenizer_1).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_1.language == "o,#c\x0bl"
    assert (
        f"{type(line_tokenizer_2).__module__}.{type(line_tokenizer_2).__qualname__}"
        == "snippet_514.LineTokenizer"
    )
    assert line_tokenizer_2.language == "1[6%cy"
